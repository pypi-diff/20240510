# Comparing `tmp/geoserver_restconfig-2.0.8-py3-none-any.whl.zip` & `tmp/geoserver_restconfig-2.0.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,21 +1,21 @@
-Zip file size: 40315 bytes, number of entries: 19
+Zip file size: 40385 bytes, number of entries: 19
 -rwxrwxrwx  2.0 unx      365 b- defN 22-Feb-21 15:00 geoserver/__init__.py
--rwxrwxrwx  2.0 unx    55974 b- defN 22-Jun-08 11:20 geoserver/catalog.py
--rwxrwxrwx  2.0 unx     8194 b- defN 22-Jun-08 11:25 geoserver/layer.py
--rwxrwxrwx  2.0 unx     5595 b- defN 22-Aug-01 14:37 geoserver/layergroup.py
+-rwxrwxrwx  2.0 unx    57292 b- defN 23-May-15 15:05 geoserver/catalog.py
+-rwxrwxrwx  2.0 unx     8265 b- defN 23-May-15 15:05 geoserver/layer.py
+-rwxrwxrwx  2.0 unx     5610 b- defN 23-May-15 15:05 geoserver/layergroup.py
 -rwxrwxrwx  2.0 unx      365 b- defN 22-Feb-21 15:00 geoserver/namespace.py
--rwxrwxrwx  2.0 unx    11390 b- defN 22-Feb-21 19:08 geoserver/resource.py
--rwxrwxrwx  2.0 unx     1394 b- defN 22-Feb-21 19:08 geoserver/security.py
--rwxrwxrwx  2.0 unx    10141 b- defN 22-Feb-21 19:08 geoserver/service.py
--rwxrwxrwx  2.0 unx     6506 b- defN 22-Feb-21 19:30 geoserver/settings.py
--rwxrwxrwx  2.0 unx     9132 b- defN 22-Feb-21 19:08 geoserver/store.py
--rwxrwxrwx  2.0 unx     5187 b- defN 22-Feb-21 19:08 geoserver/style.py
--rwxrwxrwx  2.0 unx    24370 b- defN 22-Feb-21 19:30 geoserver/support.py
--rwxrwxrwx  2.0 unx      473 b- defN 22-Feb-21 19:08 geoserver/util.py
--rwxrwxrwx  2.0 unx     1866 b- defN 22-Feb-21 19:08 geoserver/workspace.py
--rwxrwxrwx  2.0 unx     1086 b- defN 22-Aug-01 14:42 geoserver_restconfig-2.0.8.dist-info/LICENSE.txt
--rwxrwxrwx  2.0 unx    16842 b- defN 22-Aug-01 14:42 geoserver_restconfig-2.0.8.dist-info/METADATA
--rwxrwxrwx  2.0 unx       92 b- defN 22-Aug-01 14:42 geoserver_restconfig-2.0.8.dist-info/WHEEL
--rwxrwxrwx  2.0 unx       10 b- defN 22-Aug-01 14:42 geoserver_restconfig-2.0.8.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1537 b- defN 22-Aug-01 14:42 geoserver_restconfig-2.0.8.dist-info/RECORD
-19 files, 160519 bytes uncompressed, 37829 bytes compressed:  76.4%
+-rwxrwxrwx  2.0 unx    11414 b- defN 23-May-15 15:05 geoserver/resource.py
+-rwxrwxrwx  2.0 unx     1368 b- defN 23-May-15 15:05 geoserver/security.py
+-rwxrwxrwx  2.0 unx    10460 b- defN 23-May-15 15:05 geoserver/service.py
+-rwxrwxrwx  2.0 unx     6533 b- defN 23-May-15 15:05 geoserver/settings.py
+-rwxrwxrwx  2.0 unx     8960 b- defN 23-May-15 15:05 geoserver/store.py
+-rwxrwxrwx  2.0 unx     5280 b- defN 23-May-15 15:05 geoserver/style.py
+-rwxrwxrwx  2.0 unx    24823 b- defN 23-May-15 15:05 geoserver/support.py
+-rwxrwxrwx  2.0 unx      474 b- defN 23-May-15 15:05 geoserver/util.py
+-rwxrwxrwx  2.0 unx     1782 b- defN 23-May-15 15:05 geoserver/workspace.py
+-rwxrwxrwx  2.0 unx     1086 b- defN 23-May-15 15:09 geoserver_restconfig-2.0.9.dist-info/LICENSE.txt
+-rwxrwxrwx  2.0 unx    16842 b- defN 23-May-15 15:09 geoserver_restconfig-2.0.9.dist-info/METADATA
+-rwxrwxrwx  2.0 unx       92 b- defN 23-May-15 15:09 geoserver_restconfig-2.0.9.dist-info/WHEEL
+-rwxrwxrwx  2.0 unx       10 b- defN 23-May-15 15:09 geoserver_restconfig-2.0.9.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1537 b- defN 23-May-15 15:09 geoserver_restconfig-2.0.9.dist-info/RECORD
+19 files, 162558 bytes uncompressed, 37899 bytes compressed:  76.7%
```

## zipnote {}

```diff
@@ -36,23 +36,23 @@
 
 Filename: geoserver/util.py
 Comment: 
 
 Filename: geoserver/workspace.py
 Comment: 
 
-Filename: geoserver_restconfig-2.0.8.dist-info/LICENSE.txt
+Filename: geoserver_restconfig-2.0.9.dist-info/LICENSE.txt
 Comment: 
 
-Filename: geoserver_restconfig-2.0.8.dist-info/METADATA
+Filename: geoserver_restconfig-2.0.9.dist-info/METADATA
 Comment: 
 
-Filename: geoserver_restconfig-2.0.8.dist-info/WHEEL
+Filename: geoserver_restconfig-2.0.9.dist-info/WHEEL
 Comment: 
 
-Filename: geoserver_restconfig-2.0.8.dist-info/top_level.txt
+Filename: geoserver_restconfig-2.0.9.dist-info/top_level.txt
 Comment: 
 
-Filename: geoserver_restconfig-2.0.8.dist-info/RECORD
+Filename: geoserver_restconfig-2.0.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## geoserver/catalog.py

```diff
@@ -16,29 +16,29 @@
 from geoserver.service import service_from_index, ServiceWmsSettings
 from geoserver.store import (
     coveragestore_from_index,
     datastore_from_index,
     wmsstore_from_index,
     UnsavedDataStore,
     UnsavedCoverageStore,
-    UnsavedWmsStore
+    UnsavedWmsStore,
 )
 from geoserver.style import Style
 from geoserver.support import prepare_upload_bundle, build_url
 from geoserver.layergroup import LayerGroup, UnsavedLayerGroup
 from geoserver.workspace import workspace_from_index, Workspace
 from geoserver.security import user_from_index
 from geoserver.settings import GlobalSettings
 import os
 import re
 import base64
 from xml.etree.ElementTree import XML
 from xml.parsers.expat import ExpatError
 import requests
-from requests.packages.urllib3.util.retry import Retry
+from urllib3 import Retry
 from requests.adapters import HTTPAdapter
 from six import string_types
 
 try:
     from past.builtins import basestring
 except ImportError:
     pass
@@ -72,23 +72,23 @@
 
 class FailedRequestError(Exception):
     pass
 
 
 def _name(named):
     """Get the name out of an object.  This varies based on the type of the input:
-       * the "name" of a string is itself
-       * the "name" of None is itself
-       * the "name" of an object with a property named name is that property -
-         as long as it's a string
-       * otherwise, we raise a ValueError
+    * the "name" of a string is itself
+    * the "name" of None is itself
+    * the "name" of an object with a property named name is that property -
+      as long as it's a string
+    * otherwise, we raise a ValueError
     """
     if isinstance(named, string_types) or named is None:
         return named
-    elif hasattr(named, 'name') and isinstance(named.name, string_types):
+    elif hasattr(named, "name") and isinstance(named.name, string_types):
         return named.name
     else:
         raise ValueError(f"Can't interpret {named} as a name or a configuration object")
 
 
 class Catalog(object):
     """
@@ -101,84 +101,96 @@
     - LayerGroups, which alias one or more layers for convenience
     - Workspaces, which provide logical grouping of Stores
     - Maps, which provide a set of OWS services with a subset of the server's
         Layers
     - Namespaces, which provide unique identifiers for resources
     """
 
-    def __init__(self, service_url, username="admin", password="geoserver", validate_ssl_certificate=True, access_token=None, retries=3, backoff_factor=0.9):
+    def __init__(
+        self,
+        service_url,
+        username="admin",
+        password="geoserver",
+        validate_ssl_certificate=True,
+        access_token=None,
+        retries=3,
+        backoff_factor=0.9,
+    ):
         self.service_url = service_url.strip("/")
         self.username = username
         self.password = password
         self.validate_ssl_certificate = validate_ssl_certificate
         self.access_token = access_token
         self.retries = retries
         self.backoff_factor = backoff_factor
         self.setup_connection(retries=self.retries, backoff_factor=self.backoff_factor)
         self._cache = {}
         self._version = None
 
     def __getstate__(self):
-        '''http connection cannot be pickled'''
+        """http connection cannot be pickled"""
         state = dict(vars(self))
-        state.pop('http', None)
-        state['http'] = None
+        state.pop("http", None)
+        state["http"] = None
         return state
 
     def __setstate__(self, state):
-        '''restore http connection upon unpickling'''
+        """restore http connection upon unpickling"""
         self.__dict__.update(state)
         self.setup_connection(retries=self.retries, backoff_factor=self.backoff_factor)
 
     def setup_connection(self, retries=3, backoff_factor=0.9):
         self.client = requests.session()
         self.client.verify = self.validate_ssl_certificate
         parsed_url = urlparse(self.service_url)
         retry = Retry(
-            total = retries or self.retries,
-            status = retries or self.retries,
-            read = retries or self.retries,
-            connect = retries or self.retries,
-            backoff_factor = backoff_factor or self.backoff_factor,
-            status_forcelist = [502, 503, 504],
-            method_whitelist = set(['HEAD', 'TRACE', 'GET', 'PUT', 'POST', 'OPTIONS', 'DELETE'])
+            total=retries or self.retries,
+            status=retries or self.retries,
+            read=retries or self.retries,
+            connect=retries or self.retries,
+            backoff_factor=backoff_factor or self.backoff_factor,
+            status_forcelist=[502, 503, 504],
+            allowed_methods=frozenset(
+                ["HEAD", "TRACE", "GET", "PUT", "POST", "OPTIONS", "DELETE"]
+            ),
         )
         self.client.mount(f"{parsed_url.scheme}://", HTTPAdapter(max_retries=retry))
 
-    def http_request(self, url, data=None, method='get', headers={}, files=None):
+    def http_request(self, url, data=None, method="get", headers={}, files=None):
         req_method = getattr(self.client, method.lower())
 
         if self.access_token:
-            headers['Authorization'] = f"Bearer {self.access_token}"
+            headers["Authorization"] = f"Bearer {self.access_token}"
             parsed_url = urlparse(url)
             params = parse_qsl(parsed_url.query.strip())
-            params.append(('access_token', self.access_token))
+            params.append(("access_token", self.access_token))
             params = urlencode(params)
             url = f"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}?{params}"
         elif self.username and self.password:
             valid_uname_pw = base64.b64encode(
-                f"{self.username}:{self.password}".encode("utf-8")).decode("ascii")
-            headers['Authorization'] = f'Basic {valid_uname_pw}'
+                f"{self.username}:{self.password}".encode("utf-8")
+            ).decode("ascii")
+            headers["Authorization"] = f"Basic {valid_uname_pw}"
 
         return req_method(url, headers=headers, data=data, files=files)
 
     def get_version(self):
-        '''obtain the version or just 2.2.x if < 2.3.x
+        """obtain the version or just 2.2.x if < 2.3.x
         Raises:
             FailedRequestError: If the request fails.
-        '''
+        """
         if self._version:
             return self._version
         url = f"{self.service_url}/about/version.xml"
         resp = self.http_request(url)
         version = None
         if resp.status_code == 200:
             content = resp.content
             if isinstance(content, bytes):
-                content = content.decode('UTF-8')
+                content = content.decode("UTF-8")
             dom = XML(content)
             resources = dom.findall("resource")
             for resource in resources:
                 if resource.attrib["name"] == "GeoServer":
                     try:
                         version = resource.find("Version").text
                         break
@@ -191,19 +203,18 @@
         if version is None:
             # just to inform that version < 2.3.x
             version = "2.2.x"
         self._version = version
         return version
 
     def get_short_version(self):
-        '''obtain the shory geoserver version
-        '''
+        """obtain the shory geoserver version"""
         gs_version = self.get_version()
-        match = re.compile(r'[^\d.]+')
-        return match.sub('', gs_version).strip('.')
+        match = re.compile(r"[^\d.]+")
+        return match.sub("", gs_version).strip(".")
 
     def delete(self, config_object, purge=None, recurse=False):
         """
         send a delete request
         XXX [more here]
         """
         href = urlparse(config_object.href)
@@ -219,32 +230,33 @@
         # recurse deletes the resource when a layer is deleted.
         if recurse:
             params.append("recurse=true")
 
         if params:
             rest_url = f"{rest_url}?{'&'.join(params)}"
 
-        headers = {
-            "Content-type": "application/xml",
-            "Accept": "application/xml"
-        }
-        resp = self.http_request(rest_url, method='delete', headers=headers)
+        headers = {"Content-type": "application/xml", "Accept": "application/xml"}
+        resp = self.http_request(rest_url, method="delete", headers=headers)
         if resp.status_code != 200:
-            raise FailedRequestError(f'Failed to make DELETE request: {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to make DELETE request: {resp.status_code}, {resp.text}"
+            )
 
         self._cache.clear()
 
         # do we really need to return anything other than None?
-        return (resp)
+        return resp
 
     def get_xml(self, rest_url):
         cached_response = self._cache.get(rest_url)
 
         def is_valid(cached_response):
-            return cached_response is not None and datetime.now() - cached_response[0] < timedelta(seconds=5)
+            return cached_response is not None and datetime.now() - cached_response[
+                0
+            ] < timedelta(seconds=5)
 
         def parse_or_raise(xml):
             try:
                 if not isinstance(xml, string_types):
                     xml = xml.decode()
                 return XML(xml)
             except (ExpatError, SyntaxError) as e:
@@ -256,153 +268,171 @@
             raw_text = cached_response[1]
             return parse_or_raise(raw_text)
         else:
             resp = self.http_request(rest_url, headers={"Accept": "application/xml"})
             if resp.status_code == 200:
                 content = resp.content
                 if isinstance(content, bytes):
-                    content = content.decode('UTF-8')
+                    content = content.decode("UTF-8")
                 self._cache[rest_url] = (datetime.now(), content)
                 return parse_or_raise(content)
             else:
                 raise FailedRequestError(resp.content)
 
     def reload(self):
         url = f"{self.service_url}/reload"
-        resp = self.http_request(url, method='post')
+        resp = self.http_request(url, method="post")
         self._cache.clear()
         return resp
 
     def reset(self):
         url = f"{self.service_url}/reset"
-        resp = self.http_request(url, method='post')
+        resp = self.http_request(url, method="post")
         self._cache.clear()
         return resp
 
     def save(self, obj, content_type="application/xml"):
         """
         saves an object to the REST service
         gets the object's REST location and the data from the object,
         then POSTS the request.
         """
         href = urlparse(obj.href)
         netloc = urlparse(self.service_url).netloc
         rest_url = href._replace(netloc=netloc).geturl()
         data = obj.message()
 
-        headers = {
-            "Content-type": content_type,
-            "Accept": content_type
-        }
+        headers = {"Content-type": content_type, "Accept": content_type}
 
         logger.debug(f"{obj.save_method} {obj.href}")
-        resp = self.http_request(rest_url, method=obj.save_method.lower(), data=data, headers=headers)
+        resp = self.http_request(
+            rest_url, method=obj.save_method.lower(), data=data, headers=headers
+        )
 
         if resp.status_code not in (200, 201):
-            raise FailedRequestError(f'Failed to save to Geoserver catalog: {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to save to Geoserver catalog: {resp.status_code}, {resp.text}"
+            )
 
         self._cache.clear()
         return resp
 
     def _return_first_item(self, _list):
         if len(_list) == 0:
             return None
         else:
             return _list[0]
 
     def get_stores(self, names=None, workspaces=None):
-        '''
-          Returns a list of stores in the catalog. If workspaces is specified will only return stores in those workspaces.
-          If names is specified, will only return stores that match.
-          names can either be a comma delimited string or an array.
-          Will return an empty list if no stores are found.
-        '''
+        """
+        Returns a list of stores in the catalog. If workspaces is specified will only return stores in those workspaces.
+        If names is specified, will only return stores that match.
+        names can either be a comma delimited string or an array.
+        Will return an empty list if no stores are found.
+        """
 
         if workspaces:
             if isinstance(workspaces, Workspace):
                 workspaces = [workspaces]
-            elif isinstance(workspaces, list) and [w for w in workspaces if isinstance(w, Workspace)]:
+            elif isinstance(workspaces, list) and [
+                w for w in workspaces if isinstance(w, Workspace)
+            ]:
                 # nothing
                 pass
             else:
                 workspaces = self.get_workspaces(names=workspaces)
         else:
             workspaces = self.get_workspaces()
 
         stores = []
         for ws in workspaces:
             ds_list = self.get_xml(ws.datastore_url)
             cs_list = self.get_xml(ws.coveragestore_url)
             wms_list = self.get_xml(ws.wmsstore_url)
-            stores.extend([datastore_from_index(self, ws, n) for n in ds_list.findall("dataStore")])
-            stores.extend([coveragestore_from_index(self, ws, n) for n in cs_list.findall("coverageStore")])
-            stores.extend([wmsstore_from_index(self, ws, n) for n in wms_list.findall("wmsStore")])
+            stores.extend(
+                [
+                    datastore_from_index(self, ws, n)
+                    for n in ds_list.findall("dataStore")
+                ]
+            )
+            stores.extend(
+                [
+                    coveragestore_from_index(self, ws, n)
+                    for n in cs_list.findall("coverageStore")
+                ]
+            )
+            stores.extend(
+                [wmsstore_from_index(self, ws, n) for n in wms_list.findall("wmsStore")]
+            )
 
         if names is None:
             names = []
         elif isinstance(names, string_types):
-            names = [s.strip() for s in names.split(',') if s.strip()]
+            names = [s.strip() for s in names.split(",") if s.strip()]
         elif not isinstance(names, list):
             names = [names]
             if len(names) and not isinstance(names[0], string_types):
                 names = [_n.name for _n in names]
 
         if stores and names:
             return [_s for _s in stores if _s.name in names]
 
         return stores
 
     def get_store(self, name, workspace=None):
-        '''
-          Returns a single store object.
-          Will return None if no store is found.
-          Will raise an error if more than one store with the same name is found.
-        '''
+        """
+        Returns a single store object.
+        Will return None if no store is found.
+        Will raise an error if more than one store with the same name is found.
+        """
         stores = self.get_stores(workspaces=[workspace], names=name)
         return self._return_first_item(stores)
 
     def create_datastore(self, name, workspace=None):
         if isinstance(workspace, string_types):
             workspace = self.get_workspaces(names=workspace)[0]
         elif workspace is None:
             workspace = self.get_default_workspace()
         return UnsavedDataStore(self, name, workspace)
 
-    def create_wmsstore(self, name, workspace = None, user = None, password = None):
+    def create_wmsstore(self, name, workspace=None, user=None, password=None):
         if workspace is None:
             workspace = self.get_default_workspace()
         return UnsavedWmsStore(self, name, workspace, user, password)
 
     def create_wmslayer(self, workspace, store, name, nativeName=None):
-        headers = {
-            "Content-type": "text/xml",
-            "Accept": "application/xml"
-        }
+        headers = {"Content-type": "text/xml", "Accept": "application/xml"}
         # if not provided, fallback to name - this is what geoserver will do
         # anyway but nativeName needs to be provided if name is invalid xml
         # as this will cause verification errors since geoserver 2.6.1
         if nativeName is None:
             nativeName = name
 
-        url = store.href.replace('.xml', '/wmslayers')
+        url = store.href.replace(".xml", "/wmslayers")
         data = f"<wmsLayer><name>{name}</name><nativeName>{nativeName}</nativeName></wmsLayer>"
-        resp = self.http_request(url, method='post', data=data, headers=headers)
+        resp = self.http_request(url, method="post", data=data, headers=headers)
 
         if resp.status_code not in (200, 201):
-            raise FailedRequestError(f'Failed to create WMS layer: {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to create WMS layer: {resp.status_code}, {resp.text}"
+            )
 
         self._cache.clear()
         return self.get_layer(name)
 
-    def add_data_to_store(self, store, name, data, workspace=None, overwrite = False, charset = None):
+    def add_data_to_store(
+        self, store, name, data, workspace=None, overwrite=False, charset=None
+    ):
         if isinstance(store, string_types):
             store = self.get_stores(names=store, workspaces=[workspace])[0]
         if workspace is not None and workspace:
             workspace = _name(workspace)
-            assert store.workspace.name == workspace, f"Specified store ({store}) is not in specified workspace ({workspace})!"
+            assert (
+                store.workspace.name == workspace
+            ), f"Specified store ({store}) is not in specified workspace ({workspace})!"
         else:
             workspace = store.workspace.name
         store = store.name
 
         if isinstance(data, dict):
             bundle = prepare_upload_bundle(name, data)
         else:
@@ -413,180 +443,187 @@
             params["update"] = "overwrite"
         if charset is not None and charset:
             params["charset"] = charset
         params["filename"] = f"{name}.zip"
         params["target"] = "shp"
         # params["configure"] = "all"
 
-        headers = {'Content-Type': 'application/zip', 'Accept': 'application/xml'}
+        headers = {"Content-Type": "application/zip", "Accept": "application/xml"}
         upload_url = build_url(
             self.service_url,
-            [
-                "workspaces",
-                workspace,
-                "datastores",
-                store,
-                "file.shp"
-            ],
-            params
+            ["workspaces", workspace, "datastores", store, "file.shp"],
+            params,
         )
 
         try:
             with open(bundle, "rb") as f:
                 data = f.read()
-                resp = self.http_request(upload_url, method='put', data=data, headers=headers)
+                resp = self.http_request(
+                    upload_url, method="put", data=data, headers=headers
+                )
                 if resp.status_code != 201:
-                    raise FailedRequestError(f'Failed to add data to store {store} : {resp.status_code}, {resp.text}')
+                    raise FailedRequestError(
+                        f"Failed to add data to store {store} : {resp.status_code}, {resp.text}"
+                    )
                 self._cache.clear()
         finally:
             pass
 
-    def create_featurestore(self, name, data, workspace=None, overwrite=False, charset=None):
+    def create_featurestore(
+        self, name, data, workspace=None, overwrite=False, charset=None
+    ):
         if workspace is None:
             workspace = self.get_default_workspace()
         workspace = _name(workspace)
 
         if not overwrite:
             stores = self.get_stores(names=name, workspaces=[workspace])
             if len(stores) > 0:
                 msg = f"There is already a store named {name} in workspace {workspace}"
                 raise ConflictingDataError(msg)
 
         params = dict()
         if charset is not None and charset:
-            params['charset'] = charset
+            params["charset"] = charset
         url = build_url(
             self.service_url,
-            [
-                "workspaces",
-                workspace,
-                "datastores",
-                name,
-                "file.shp"
-            ],
-            params
+            ["workspaces", workspace, "datastores", name, "file.shp"],
+            params,
         )
 
         # PUT /workspaces/<ws>/datastores/<ds>/file.shp
-        headers = {
-            "Content-type": "application/zip",
-            "Accept": "application/xml"
-        }
+        headers = {"Content-type": "application/zip", "Accept": "application/xml"}
         if isinstance(data, dict):
-            logger.debug('Data is NOT a zipfile')
+            logger.debug("Data is NOT a zipfile")
             archive = prepare_upload_bundle(name, data)
         else:
-            logger.debug('Data is a zipfile')
+            logger.debug("Data is a zipfile")
             archive = data
-        file_obj = open(archive, 'rb')
+        file_obj = open(archive, "rb")
         try:
-            resp = self.http_request(url, method='put', data=file_obj, headers=headers)
+            resp = self.http_request(url, method="put", data=file_obj, headers=headers)
             if resp.status_code != 201:
-                raise FailedRequestError(f'Failed to create FeatureStore {name} : {resp.status_code}, {resp.text}')
+                raise FailedRequestError(
+                    f"Failed to create FeatureStore {name} : {resp.status_code}, {resp.text}"
+                )
             self._cache.clear()
         finally:
             file_obj.close()
 
-    def create_imagemosaic(self, name, data, configure='first', workspace=None, overwrite=False, charset=None, coverageName=None):
+    def create_imagemosaic(
+        self,
+        name,
+        data,
+        configure="first",
+        workspace=None,
+        overwrite=False,
+        charset=None,
+        coverageName=None,
+    ):
         if workspace is None:
             workspace = self.get_default_workspace()
         workspace = _name(workspace)
 
         if not overwrite:
             store = self.get_stores(names=name, workspaces=[workspace])
             if store:
                 raise ConflictingDataError(f"There is already a store named {name}")
 
         params = dict()
         if charset is not None and charset:
-            params['charset'] = charset
-        if configure.lower() not in ('first', 'none', 'all'):
+            params["charset"] = charset
+        if configure.lower() not in ("first", "none", "all"):
             raise ValueError("configure most be one of: first, none, all")
-        params['configure'] = configure.lower()
+        params["configure"] = configure.lower()
         if coverageName:
-            params['coverageName'] = coverageName
+            params["coverageName"] = coverageName
         store_type = "file.imagemosaic"
         contet_type = "application/zip"
 
-        if hasattr(data, 'read'):
+        if hasattr(data, "read"):
             # Adding this check only to pass tests. We should drop support for passing a file object
             upload_data = data
         elif isinstance(data, string_types):
             if os.path.splitext(data)[-1] == ".zip":
-                upload_data = open(data, 'rb')
+                upload_data = open(data, "rb")
             else:
                 store_type = "external.imagemosaic"
                 contet_type = "text/plain"
                 upload_data = data if data.startswith("file:") else f"file:{data}"
         else:
             raise ValueError(f"ImageMosaic Dataset or directory: {data} is incorrect")
 
         url = build_url(
             self.service_url,
-            [
-                "workspaces",
-                workspace,
-                "coveragestores",
-                name,
-                store_type
-            ],
-            params
+            ["workspaces", workspace, "coveragestores", name, store_type],
+            params,
         )
 
         # PUT /workspaces/<ws>/coveragestores/<name>/file.imagemosaic?configure=none
-        headers = {
-            "Content-type": contet_type,
-            "Accept": "application/xml"
-        }
+        headers = {"Content-type": contet_type, "Accept": "application/xml"}
 
         try:
-            resp = self.http_request(url, method='put', data=upload_data, headers=headers)
+            resp = self.http_request(
+                url, method="put", data=upload_data, headers=headers
+            )
             if resp.status_code != 201:
-                raise FailedRequestError(f'Failed to create ImageMosaic {url} : {resp.status_code}, {resp.text}')
+                raise FailedRequestError(
+                    f"Failed to create ImageMosaic {url} : {resp.status_code}, {resp.text}"
+                )
             self._cache.clear()
         finally:
             if hasattr(upload_data, "close"):
                 upload_data.close()
 
         return self.get_stores(names=name, workspaces=[workspace])[0]
 
-    def create_coveragestore(self, name, workspace=None, path=None, type='GeoTIFF',
-                             create_layer=True, layer_name=None, source_name=None, upload_data=False, contet_type="image/tiff",
-                             overwrite=False):
+    def create_coveragestore(
+        self,
+        name,
+        workspace=None,
+        path=None,
+        type="GeoTIFF",
+        create_layer=True,
+        layer_name=None,
+        source_name=None,
+        upload_data=False,
+        contet_type="image/tiff",
+        overwrite=False,
+    ):
         """
         Create a coveragestore for locally hosted rasters.
         If create_layer is set to true, will create a coverage/layer.
         layer_name and source_name are only used if create_layer ia enabled. If not specified, the raster name will be used for both.
         """
         if path is None:
-            raise Exception('You must provide a full path to the raster')
+            raise Exception("You must provide a full path to the raster")
 
         if layer_name is not None and ":" in layer_name:
-            ws_name, layer_name = layer_name.split(':')
+            ws_name, layer_name = layer_name.split(":")
 
         allowed_types = [
-            'ImageMosaic',
-            'GeoTIFF',
-            'Gtopo30',
-            'WorldImage',
-            'AIG',
-            'ArcGrid',
-            'DTED',
-            'EHdr',
-            'ERDASImg',
-            'ENVIHdr',
-            'GeoPackage (mosaic)',
-            'NITF',
-            'RPFTOC',
-            'RST',
-            'VRT'
+            "ImageMosaic",
+            "GeoTIFF",
+            "Gtopo30",
+            "WorldImage",
+            "AIG",
+            "ArcGrid",
+            "DTED",
+            "EHdr",
+            "ERDASImg",
+            "ENVIHdr",
+            "GeoPackage (mosaic)",
+            "NITF",
+            "RPFTOC",
+            "RST",
+            "VRT",
         ]
 
         if type is None:
-            raise Exception('Type must be declared')
+            raise Exception("Type must be declared")
         elif type not in allowed_types:
             raise Exception(f"Type must be one of {', '.join(allowed_types)}")
 
         if workspace is None:
             workspace = self.get_default_workspace()
         workspace = _name(workspace)
 
@@ -608,101 +645,100 @@
                 if source_name is None:
                     source_name = os.path.splitext(os.path.basename(path))[0]
 
                 data = f"<coverage><name>{layer_name}</name><nativeName>{source_name}</nativeName></coverage>"
                 url = f"{self.service_url}/workspaces/{workspace}/coveragestores/{name}/coverages.xml"
                 headers = {"Content-type": "application/xml"}
 
-                resp = self.http_request(url, method='post', data=data, headers=headers)
+                resp = self.http_request(url, method="post", data=data, headers=headers)
                 if resp.status_code != 201:
-                    raise FailedRequestError('Failed to create coverage/layer {} for : {}, {}'.format(layer_name, name,
-                                                                                                      resp.status_code, resp.text))
+                    raise FailedRequestError(
+                        "Failed to create coverage/layer {} for : {}, {}".format(
+                            layer_name, name, resp.status_code, resp.text
+                        )
+                    )
                 self._cache.clear()
                 return self.get_resources(names=layer_name, workspaces=[workspace])[0]
         else:
-            data = open(path, 'rb')
+            data = open(path, "rb")
             params = {"configure": "first", "coverageName": name}
             url = build_url(
                 self.service_url,
                 [
                     "workspaces",
                     workspace,
                     "coveragestores",
                     name,
-                    f"file.{type.lower()}"
+                    f"file.{type.lower()}",
                 ],
-                params
+                params,
             )
 
             headers = {"Content-type": contet_type}
-            resp = self.http_request(url, method='put', data=data, headers=headers)
+            resp = self.http_request(url, method="put", data=data, headers=headers)
 
             if hasattr(data, "close"):
                 data.close()
 
             if resp.status_code != 201:
-                raise FailedRequestError('Failed to create coverage/layer {} for : {}, {}'.format(layer_name, name, resp.status_code, resp.text))
+                raise FailedRequestError(
+                    "Failed to create coverage/layer {} for : {}, {}".format(
+                        layer_name, name, resp.status_code, resp.text
+                    )
+                )
 
         return self.get_stores(names=name, workspaces=[workspace])[0]
 
     def add_granule(self, data, store, workspace=None):
-        '''Harvest/add a granule into an existing imagemosaic'''
+        """Harvest/add a granule into an existing imagemosaic"""
         ext = os.path.splitext(data)[-1]
         if ext == ".zip":
             type = "file.imagemosaic"
-            upload_data = open(data, 'rb')
-            headers = {
-                "Content-type": "application/zip",
-                "Accept": "application/xml"
-            }
+            upload_data = open(data, "rb")
+            headers = {"Content-type": "application/zip", "Accept": "application/xml"}
         else:
             type = "external.imagemosaic"
             upload_data = data if data.startswith("file:") else f"file:{data}"
-            headers = {
-                "Content-type": "text/plain",
-                "Accept": "application/xml"
-            }
+            headers = {"Content-type": "text/plain", "Accept": "application/xml"}
 
         params = dict()
         workspace_name = workspace
         if isinstance(store, string_types):
             store_name = store
         else:
             store_name = store.name
             workspace_name = store.workspace.name
 
         if workspace_name is None:
             raise ValueError("Must specify workspace")
 
         url = build_url(
             self.service_url,
-            [
-                "workspaces",
-                workspace_name,
-                "coveragestores",
-                store_name,
-                type
-            ],
-            params
+            ["workspaces", workspace_name, "coveragestores", store_name, type],
+            params,
         )
 
         try:
-            resp = self.http_request(url, method='post', data=upload_data, headers=headers)
+            resp = self.http_request(
+                url, method="post", data=upload_data, headers=headers
+            )
             if resp.status_code != 202:
-                raise FailedRequestError(f'Failed to add granule to mosaic {store} : {resp.status_code}, {resp.text}')
+                raise FailedRequestError(
+                    f"Failed to add granule to mosaic {store} : {resp.status_code}, {resp.text}"
+                )
             self._cache.clear()
         finally:
             if hasattr(upload_data, "close"):
                 upload_data.close()
 
         # maybe return a list of all granules?
         return None
 
     def delete_granule(self, coverage, store, granule_id, workspace=None):
-        '''Deletes a granule of an existing imagemosaic'''
+        """Deletes a granule of an existing imagemosaic"""
         params = dict()
 
         workspace_name = workspace
         if isinstance(store, string_types):
             store_name = store
         else:
             store_name = store.name
@@ -718,43 +754,44 @@
                 workspace_name,
                 "coveragestores",
                 store_name,
                 "coverages",
                 coverage,
                 "index/granules",
                 granule_id,
-                ".json"
+                ".json",
             ],
-            params
+            params,
         )
 
         # DELETE /workspaces/<ws>/coveragestores/<name>/coverages/<coverage>/index/granules/<granule_id>.json
-        headers = {
-            "Content-type": "application/json",
-            "Accept": "application/json"
-        }
+        headers = {"Content-type": "application/json", "Accept": "application/json"}
 
-        resp = self.http_request(url, method='delete', headers=headers)
+        resp = self.http_request(url, method="delete", headers=headers)
         if resp.status_code != 200:
-            raise FailedRequestError(f'Failed to delete granule from mosaic {store} : {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to delete granule from mosaic {store} : {resp.status_code}, {resp.text}"
+            )
         self._cache.clear()
 
         # maybe return a list of all granules?
         return None
 
-    def list_granules(self, coverage, store, workspace=None, filter=None, limit=None, offset=None):
-        '''List granules of an imagemosaic'''
+    def list_granules(
+        self, coverage, store, workspace=None, filter=None, limit=None, offset=None
+    ):
+        """List granules of an imagemosaic"""
         params = dict()
 
         if filter is not None and filter:
-            params['filter'] = filter
+            params["filter"] = filter
         if limit is not None and limit:
-            params['limit'] = limit
+            params["limit"] = limit
         if offset is not None and offset:
-            params['offset'] = offset
+            params["offset"] = offset
 
         workspace_name = workspace
         if isinstance(store, string_types):
             store_name = store
         else:
             store_name = store.name
             workspace_name = store.workspace.name
@@ -767,159 +804,164 @@
             [
                 "workspaces",
                 workspace_name,
                 "coveragestores",
                 store_name,
                 "coverages",
                 coverage,
-                "index/granules.json"
+                "index/granules.json",
             ],
-            params
+            params,
         )
 
         # GET /workspaces/<ws>/coveragestores/<name>/coverages/<coverage>/index/granules.json
-        headers = {
-            "Content-type": "application/json",
-            "Accept": "application/json"
-        }
+        headers = {"Content-type": "application/json", "Accept": "application/json"}
 
         resp = self.http_request(url, headers=headers)
         if resp.status_code != 200:
-            raise FailedRequestError(f'Failed to list granules in mosaic {store} : {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to list granules in mosaic {store} : {resp.status_code}, {resp.text}"
+            )
 
         self._cache.clear()
         return resp.json()
 
     def mosaic_coverages(self, store):
-        '''Returns all coverages in a coverage store'''
+        """Returns all coverages in a coverage store"""
         params = dict()
         url = build_url(
             self.service_url,
             [
                 "workspaces",
                 store.workspace.name,
                 "coveragestores",
                 store.name,
-                "coverages.json"
+                "coverages.json",
             ],
-            params
+            params,
         )
         # GET /workspaces/<ws>/coveragestores/<name>/coverages.json
-        headers = {
-            "Content-type": "application/json",
-            "Accept": "application/json"
-        }
+        headers = {"Content-type": "application/json", "Accept": "application/json"}
 
         resp = self.http_request(url, headers=headers)
         if resp.status_code != 200:
-            raise FailedRequestError(f'Failed to get mosaic coverages {store} : {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to get mosaic coverages {store} : {resp.status_code}, {resp.text}"
+            )
 
         self._cache.clear()
         return resp.json()
 
     def mosaic_coverage_schema(self, coverage, store, workspace):
-        '''Returns the schema of a coverage in a coverage store'''
+        """Returns the schema of a coverage in a coverage store"""
         params = dict()
         url = build_url(
             self.service_url,
             [
                 "workspaces",
                 workspace,
                 "coveragestores",
                 store,
                 "coverages",
                 coverage,
-                "index.json"
+                "index.json",
             ],
-            params
+            params,
         )
         # GET /workspaces/<ws>/coveragestores/<name>/coverages/<coverage>/index.json
 
-        headers = {
-            "Content-type": "application/json",
-            "Accept": "application/json"
-        }
+        headers = {"Content-type": "application/json", "Accept": "application/json"}
 
         resp = self.http_request(url, headers=headers)
         if resp.status_code != 200:
-            raise FailedRequestError(f'Failed to get mosaic schema {store} : {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to get mosaic schema {store} : {resp.status_code}, {resp.text}"
+            )
 
         self._cache.clear()
         return resp.json()
 
-    def publish_featuretype(self, name, store, native_crs, srs=None, jdbc_virtual_table=None, native_name=None):
-        '''Publish a featuretype from data in an existing store'''
+    def publish_featuretype(
+        self,
+        name,
+        store,
+        native_crs,
+        srs=None,
+        jdbc_virtual_table=None,
+        native_name=None,
+    ):
+        """Publish a featuretype from data in an existing store"""
         # @todo native_srs doesn't seem to get detected, even when in the DB
         # metadata (at least for postgis in geometry_columns) and then there
         # will be a misconfigured layer
         if native_crs is None:
             raise ValueError("must specify native_crs")
 
         srs = srs or native_crs
         feature_type = FeatureType(self, store.workspace, store, name)
         # because name is the in FeatureType base class, work around that
         # and hack in these others that don't have xml properties
-        feature_type.dirty['name'] = name
-        feature_type.dirty['srs'] = srs
-        feature_type.dirty['nativeCRS'] = native_crs
+        feature_type.dirty["name"] = name
+        feature_type.dirty["srs"] = srs
+        feature_type.dirty["nativeCRS"] = native_crs
         feature_type.enabled = True
         feature_type.advertised = True
         feature_type.title = name
 
         if native_name is not None and native_name:
             feature_type.native_name = native_name
 
-        headers = {
-            "Content-type": "application/xml",
-            "Accept": "application/xml"
-        }
+        headers = {"Content-type": "application/xml", "Accept": "application/xml"}
 
         resource_url = store.resource_url
         if jdbc_virtual_table is not None and jdbc_virtual_table:
-            feature_type.metadata = ({'JDBC_VIRTUAL_TABLE': jdbc_virtual_table})
+            feature_type.metadata = {"JDBC_VIRTUAL_TABLE": jdbc_virtual_table}
             params = dict()
             resource_url = build_url(
                 self.service_url,
                 [
                     "workspaces",
                     store.workspace.name,
-                    "datastores", store.name,
-                    "featuretypes.xml"
+                    "datastores",
+                    store.name,
+                    "featuretypes.xml",
                 ],
-                params
+                params,
             )
 
-        resp = self.http_request(resource_url, method='post', data=feature_type.message(), headers=headers)
+        resp = self.http_request(
+            resource_url, method="post", data=feature_type.message(), headers=headers
+        )
         if resp.status_code not in (200, 201, 202):
-            raise FailedRequestError(f'Failed to publish feature type {name} : {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to publish feature type {name} : {resp.status_code}, {resp.text}"
+            )
 
         self._cache.clear()
         feature_type.fetch()
         return feature_type
 
     def get_resources(self, names=None, stores=None, workspaces=None):
-        '''
+        """
         Resources include feature stores, coverage stores and WMS stores, however does not include layer groups.
         names, stores and workspaces can be provided as a comma delimited strings or as arrays, and are used for filtering.
         Will always return an array.
-        '''
+        """
         if workspaces and not isinstance(workspaces, list):
             workspaces = [workspaces]
 
         if not stores:
-            _stores = self.get_stores(
-                workspaces=workspaces
-            )
+            _stores = self.get_stores(workspaces=workspaces)
         elif not isinstance(stores, list):
             _stores = [stores]
         else:
             _stores = stores
 
         if isinstance(names, string_types):
-            names = [s.strip() for s in names.split(',')]
+            names = [s.strip() for s in names.split(",")]
 
         resources = []
         for s in _stores:
             try:
                 if isinstance(s, string_types):
                     if workspaces:
                         for w in workspaces:
@@ -950,27 +992,29 @@
                             resources.append(_res)
                 else:
                     resources.extend(s.get_resources())
             except FailedRequestError:
                 continue
 
         if resources and names:
-            return ([resource for resource in resources if resource.name in names])
+            return [resource for resource in resources if resource.name in names]
 
         return resources
 
     def get_resource(self, name=None, store=None, workspace=None):
-        '''
-          returns a single resource object.
-          Will return None if no resource is found.
-          Will raise an error if more than one resource with the same name is found.
-        '''
+        """
+        returns a single resource object.
+        Will return None if no resource is found.
+        Will raise an error if more than one resource with the same name is found.
+        """
 
         if store:
-            resources = self.get_resources(names=name, stores=[store], workspaces=[workspace])
+            resources = self.get_resources(
+                names=name, stores=[store], workspaces=[workspace]
+            )
         else:
             resources = self.get_resources(names=name, workspaces=[workspace])
         return self._return_first_item(resources)
 
     def get_layer(self, name):
         try:
             lyr = Layer(self, name)
@@ -980,15 +1024,15 @@
             return None
 
     def get_layers(self, resource=None):
         if isinstance(resource, string_types):
             ws_name = None
             if self.get_short_version() >= "2.13":
                 if ":" in resource:
-                    ws_name, resource = resource.split(':')
+                    ws_name, resource = resource.split(":")
 
             if ws_name:
                 resources = self.get_resources(names=resource, workspaces=[ws_name])
             else:
                 resources = self.get_resources(names=resource)
             resource = self._return_first_item(resources)
         layers_url = f"{self.service_url}/layers.xml"
@@ -996,30 +1040,35 @@
         lyrs = [Layer(self, l.find("name").text) for l in data.findall("layer")]
         if resource is not None:
             lyrs = [l for l in lyrs if l.resource.href == resource.href]
         # TODO: Filter by style
         return lyrs
 
     def get_layergroups(self, names=None, workspaces=None):
-        '''
+        """
         names and workspaces can be provided as a comma delimited strings or as arrays, and are used for filtering.
         If no workspaces are provided, will return all layer groups in the catalog (global and workspace specific).
         Will always return an array.
-        '''
+        """
 
         layergroups = []
 
         if workspaces is None or len(workspaces) == 0:
             # Add global layergroups
             url = f"{self.service_url}/layergroups.xml"
             groups = self.get_xml(url)
-            layergroups.extend([LayerGroup(self, g.find("name").text, None) for g in groups.findall("layerGroup")])
+            layergroups.extend(
+                [
+                    LayerGroup(self, g.find("name").text, None)
+                    for g in groups.findall("layerGroup")
+                ]
+            )
             workspaces = []
         elif isinstance(workspaces, string_types):
-            workspaces = [s.strip() for s in workspaces.split(',') if s.strip()]
+            workspaces = [s.strip() for s in workspaces.split(",") if s.strip()]
         elif isinstance(workspaces, Workspace):
             workspaces = [workspaces]
 
         if not workspaces:
             workspaces = self.get_workspaces()
 
         for ws in workspaces:
@@ -1029,65 +1078,83 @@
                 groups = self.get_xml(url)
             except FailedRequestError as e:
                 if "no such workspace" in str(e).lower():
                     continue
                 else:
                     raise FailedRequestError(f"Failed to get layergroups: {e}")
 
-            layergroups.extend([LayerGroup(self, g.find("name").text, ws_name) for g in groups.findall("layerGroup")])
+            layergroups.extend(
+                [
+                    LayerGroup(self, g.find("name").text, ws_name)
+                    for g in groups.findall("layerGroup")
+                ]
+            )
 
         if names is None:
             names = []
         elif isinstance(names, string_types):
-            names = [s.strip() for s in names.split(',') if s.strip()]
+            names = [s.strip() for s in names.split(",") if s.strip()]
 
         if layergroups and names:
-            return ([lg for lg in layergroups if lg.name in names])
+            return [lg for lg in layergroups if lg.name in names]
 
         return layergroups
 
     def get_layergroup(self, name, workspace=None):
-        '''
-          returns a single layergroup object.
-          Will return None if no layergroup is found.
-          Will raise an error if more than one layergroup with the same name is found.
-        '''
+        """
+        returns a single layergroup object.
+        Will return None if no layergroup is found.
+        Will raise an error if more than one layergroup with the same name is found.
+        """
 
         layergroups = self.get_layergroups(names=name, workspaces=[workspace])
         return self._return_first_item(layergroups)
 
-    def create_layergroup(self, name, layers = (), styles = (), bounds = None, mode = "SINGLE", abstract = None,
-                          title = None, workspace = None):
+    def create_layergroup(
+        self,
+        name,
+        layers=(),
+        styles=(),
+        bounds=None,
+        mode="SINGLE",
+        abstract=None,
+        title=None,
+        workspace=None,
+    ):
         if self.get_layergroups(names=name, workspaces=[workspace]):
             raise ConflictingDataError(f"LayerGroup named {name} already exists!")
         else:
-            return UnsavedLayerGroup(self, name, layers, styles, bounds, mode, abstract, title, workspace)
+            return UnsavedLayerGroup(
+                self, name, layers, styles, bounds, mode, abstract, title, workspace
+            )
 
     def get_styles(self, names=None, workspaces=None, recursive=False):
-        '''
+        """
         names and workspaces can be provided as a comma delimited strings or as arrays, and are used for filtering.
         If no workspaces are provided, will return all styles in the catalog (global and workspace specific).
         Will always return an array.
-        '''
+        """
         all_styles = []
 
         # Get Names first to speed up recursive queries
         if names is None:
             names = []
         elif isinstance(names, string_types):
-            names = [s.strip() for s in names.split(',') if s.strip()]
+            names = [s.strip() for s in names.split(",") if s.strip()]
 
         if not workspaces:
             # Add global styles
             url = f"{self.service_url}/styles.xml"
             styles = self.get_xml(url)
-            all_styles += self.__build_style_list(styles, recursive=recursive, names=names)
+            all_styles += self.__build_style_list(
+                styles, recursive=recursive, names=names
+            )
             workspaces = []
         elif isinstance(workspaces, string_types):
-            workspaces = [s.strip() for s in workspaces.split(',') if s.strip()]
+            workspaces = [s.strip() for s in workspaces.split(",") if s.strip()]
         elif isinstance(workspaces, Workspace):
             workspaces = [workspaces]
 
         if not workspaces:
             workspaces = self.get_workspaces()
 
         for ws in workspaces:
@@ -1100,249 +1167,286 @@
             except FailedRequestError as e:
                 if "no such workspace" in str(e).lower():
                     continue
                 elif f"workspace {_name(ws)} not found" in str(e).lower():
                     continue
                 else:
                     raise FailedRequestError(f"Failed to get styles: {e}")
-            all_styles += self.__build_style_list(styles, workspace=ws, recursive=recursive, names=names)
+            all_styles += self.__build_style_list(
+                styles, workspace=ws, recursive=recursive, names=names
+            )
 
         if all_styles and names:
-            return ([style for style in all_styles if style.name in names])
+            return [style for style in all_styles if style.name in names]
 
         return all_styles
 
-    def __build_style_list(self, styles_tree, workspace=None, recursive=False, names=None):
+    def __build_style_list(
+        self, styles_tree, workspace=None, recursive=False, names=None
+    ):
         all_styles = []
         for s in styles_tree.findall("style"):
             try:
-                style_name = s.find('name').text
+                style_name = s.find("name").text
                 if names and style_name not in names:
                     continue
                 if recursive:
-                    style_xml = self.get_xml(s[1].attrib.get('href'))
-                    style_format = style_xml.find('format').text
-                    style_version = style_xml.find('languageVersion').find('version').text.replace('.', '')[:-1]
-                    all_styles.append(
-                        Style(self, style_name, _name(workspace), style_format + style_version)
+                    style_xml = self.get_xml(s[1].attrib.get("href"))
+                    style_format = style_xml.find("format").text
+                    style_version = (
+                        style_xml.find("languageVersion")
+                        .find("version")
+                        .text.replace(".", "")[:-1]
                     )
-                else:
                     all_styles.append(
-                        Style(self, style_name, _name(workspace))
+                        Style(
+                            self,
+                            style_name,
+                            _name(workspace),
+                            style_format + style_version,
+                        )
                     )
+                else:
+                    all_styles.append(Style(self, style_name, _name(workspace)))
             except Exception:
-                all_styles.append(
-                    Style(self, s.find('name').text, _name(workspace))
-                )
+                all_styles.append(Style(self, s.find("name").text, _name(workspace)))
         return all_styles
 
     def get_style(self, name, workspace=None, recursive=False):
-        '''
-          returns a single style object.
-          Will return None if no style is found.
-          Will raise an error if more than one style with the same name is found.
-        '''
+        """
+        returns a single style object.
+        Will return None if no style is found.
+        Will raise an error if more than one style with the same name is found.
+        """
 
-        styles = self.get_styles(names=name, workspaces=[workspace], recursive=recursive)
+        styles = self.get_styles(
+            names=name, workspaces=[workspace], recursive=recursive
+        )
         return self._return_first_item(styles)
 
-    def create_style(self, name, data, overwrite=False, workspace=None, style_format="sld10", raw=False):
+    def create_style(
+        self,
+        name,
+        data,
+        overwrite=False,
+        workspace=None,
+        style_format="sld10",
+        raw=False,
+    ):
         styles = self.get_styles(names=name, workspaces=[workspace], recursive=True)
         if len(styles) > 0:
             style = styles[0]
         else:
             style = None
 
         if not overwrite and style is not None and style:
             raise ConflictingDataError(f"There is already a style named {name}")
 
         if not style:
-            xml = "<style><name>{0}</name><filename>{0}.sld</filename></style>".format(name)
+            xml = "<style><name>{0}</name><filename>{0}.sld</filename></style>".format(
+                name
+            )
             style = Style(self, name, workspace, style_format)
-            headers = {
-                "Content-type": "application/xml",
-                "Accept": "text/plain"
-            }
+            headers = {"Content-type": "application/xml", "Accept": "text/plain"}
             create_url = style.create_href
-            resp = self.http_request(create_url, method='post', data=xml, headers=headers)
+            resp = self.http_request(
+                create_url, method="post", data=xml, headers=headers
+            )
             if resp.status_code == 406:
                 headers["Accept"] = "application/xml"
-                resp = self.http_request(create_url, method='post', data=xml, headers=headers)
+                resp = self.http_request(
+                    create_url, method="post", data=xml, headers=headers
+                )
 
             if resp.status_code not in (200, 201, 202):
-                raise FailedRequestError(f'Failed to create style {name} : {resp.status_code}, {resp.text}')
+                raise FailedRequestError(
+                    f"Failed to create style {name} : {resp.status_code}, {resp.text}"
+                )
 
         if style:
-            headers = {
-                "Content-type": style.content_type,
-                "Accept": "application/xml"
-            }
+            headers = {"Content-type": style.content_type, "Accept": "application/xml"}
 
             body_href = style.body_href
             if raw:
                 body_href += "?raw=true"
 
-            resp = self.http_request(body_href, method='put', data=data, headers=headers)
+            resp = self.http_request(
+                body_href, method="put", data=data, headers=headers
+            )
             if resp.status_code not in (200, 201, 202):
                 body_href = f"{os.path.splitext(style.body_href)[0]}.xml"
                 if raw:
                     body_href += "?raw=true"
 
-                resp = self.http_request(body_href, method='put', data=data, headers=headers)
+                resp = self.http_request(
+                    body_href, method="put", data=data, headers=headers
+                )
                 if resp.status_code not in (200, 201, 202):
-                    raise FailedRequestError(f'Failed to update style {name} : {resp.status_code}, {resp.text}')
+                    raise FailedRequestError(
+                        f"Failed to update style {name} : {resp.status_code}, {resp.text}"
+                    )
 
             self._cache.pop(style.href, None)
             self._cache.pop(style.body_href, None)
             return style
         else:
-            raise FailedRequestError(f'Failed to create style {name}')
+            raise FailedRequestError(f"Failed to create style {name}")
 
     def create_workspace(self, name, uri):
         xml = (
-            "<namespace>"
-            "<prefix>{name}</prefix>"
-            "<uri>{uri}</uri>"
-            "</namespace>"
+            "<namespace>" "<prefix>{name}</prefix>" "<uri>{uri}</uri>" "</namespace>"
         ).format(name=name, uri=uri)
 
         headers = {"Content-Type": "application/xml"}
         workspace_url = f"{self.service_url}/namespaces/"
 
-        resp = self.http_request(workspace_url, method='post', data=xml, headers=headers)
+        resp = self.http_request(
+            workspace_url, method="post", data=xml, headers=headers
+        )
         if resp.status_code not in (200, 201, 202):
-            raise FailedRequestError(f'Failed to create workspace {name} : {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to create workspace {name} : {resp.status_code}, {resp.text}"
+            )
 
         self._cache.pop(f"{self.service_url}/workspaces.xml", None)
         workspaces = self.get_workspaces(names=name)
         # Can only have one workspace with this name
         return workspaces[0] if workspaces else None
 
     def get_workspaces(self, names=None):
-        '''
-          Returns a list of workspaces in the catalog.
-          If names is specified, will only return workspaces that match.
-          names can either be a comma delimited string or an array.
-          Will return an empty list if no workspaces are found.
-        '''
+        """
+        Returns a list of workspaces in the catalog.
+        If names is specified, will only return workspaces that match.
+        names can either be a comma delimited string or an array.
+        Will return an empty list if no workspaces are found.
+        """
         if names is None:
             names = []
         elif isinstance(names, string_types):
-            names = [s.strip() for s in names.split(',') if s.strip()]
+            names = [s.strip() for s in names.split(",") if s.strip()]
 
         data = self.get_xml(f"{self.service_url}/workspaces.xml")
         workspaces = []
-        workspaces.extend([workspace_from_index(self, node) for node in data.findall("workspace")])
+        workspaces.extend(
+            [workspace_from_index(self, node) for node in data.findall("workspace")]
+        )
 
         if workspaces and names:
-            return ([ws for ws in workspaces if ws.name in names])
+            return [ws for ws in workspaces if ws.name in names]
 
         return workspaces
 
     def get_workspace(self, name):
-        '''
-          returns a single workspace object.
-          Will return None if no workspace is found.
-          Will raise an error if more than one workspace with the same name is found.
-        '''
+        """
+        returns a single workspace object.
+        Will return None if no workspace is found.
+        Will raise an error if more than one workspace with the same name is found.
+        """
 
         workspaces = self.get_workspaces(names=name)
         return self._return_first_item(workspaces)
 
     def get_default_workspace(self):
         ws = Workspace(self, "default")
         # must fetch and resolve the 'real' workspace from the response
         ws.fetch()
         return workspace_from_index(self, ws.dom)
 
     def set_default_workspace(self, name):
-        if hasattr(name, 'name'):
+        if hasattr(name, "name"):
             name = name.name
         workspace = self.get_workspaces(names=name)[0]
         if workspace is not None and workspace:
             headers = {"Content-Type": "application/xml"}
             default_workspace_url = f"{self.service_url}/workspaces/default.xml"
             data = f"<workspace><name>{name}</name></workspace>"
 
-            resp = self.http_request(default_workspace_url, method='put', data=data, headers=headers)
+            resp = self.http_request(
+                default_workspace_url, method="put", data=data, headers=headers
+            )
             if resp.status_code not in (200, 201, 202):
-                raise FailedRequestError(f'Failed to set default workspace {name} : {resp.status_code}, {resp.text}')
+                raise FailedRequestError(
+                    f"Failed to set default workspace {name} : {resp.status_code}, {resp.text}"
+                )
 
             self._cache.pop(default_workspace_url, None)
             self._cache.pop(f"{self.service_url}/workspaces.xml", None)
         else:
             raise FailedRequestError(f"no workspace named {name}")
 
-    def list_feature_type_names(self, workspace, store, filter='available'):
+    def list_feature_type_names(self, workspace, store, filter="available"):
         if workspace is None:
             raise ValueError("Must provide workspace")
 
         if store is None:
             raise ValueError("Must provide store")
 
         filter = filter.lower()
         workspace = _name(workspace)
         store = _name(store)
 
         url = f"{self.service_url}/workspaces/{workspace}/datastores/{store}/featuretypes.json?list={filter}"
         resp = self.http_request(url)
         if resp.status_code != 200:
-            raise FailedRequestError('Failed to query feature_type_names')
+            raise FailedRequestError("Failed to query feature_type_names")
 
         data = []
-        if filter in ('available', 'available_with_geom'):
+        if filter in ("available", "available_with_geom"):
             try:
-                data = resp.json()['list']['string']
+                data = resp.json()["list"]["string"]
             except JSONDecodeError:
                 pass
             return data
-        elif filter == 'configured':
-            data = resp.json()['featureTypes']['featureType']
-            return [fn['name'] for fn in data]
-        elif filter == 'all':
+        elif filter == "configured":
+            data = resp.json()["featureTypes"]["featureType"]
+            return [fn["name"] for fn in data]
+        elif filter == "all":
             feature_type_names = []
             url = f"{self.service_url}/workspaces/{workspace}/datastores/{store}/featuretypes.json?list=available"
             resp = self.http_request(url)
             if resp.status_code != 200:
-                raise FailedRequestError('Failed to query feature_type_names')
-            feature_type_names.extend(resp.json()['list']['string'])
+                raise FailedRequestError("Failed to query feature_type_names")
+            feature_type_names.extend(resp.json()["list"]["string"])
 
             url = f"{self.service_url}/workspaces/{workspace}/datastores/{store}/featuretypes.json?list=configured"
             resp = self.http_request(url)
             if resp.status_code != 200:
-                raise FailedRequestError('Failed to query feature_type_names')
-            data = resp.json()['featureTypes']['featureType']
-            feature_type_names.extend([fn['name'] for fn in data])
+                raise FailedRequestError("Failed to query feature_type_names")
+            data = resp.json()["featureTypes"]["featureType"]
+            feature_type_names.extend([fn["name"] for fn in data])
 
             return feature_type_names
 
     def get_services(self, ogc_type="wms"):
-        '''
-          Returns a list of wms services in the catalog.
-          Will return an empty list if no services are found.
-        '''
+        """
+        Returns a list of wms services in the catalog.
+        Will return an empty list if no services are found.
+        """
 
         data = self.get_xml(f"{self.service_url}/services/{ogc_type}/settings")
         services = []
         services.append(service_from_index(self, data))
         workspaces = self.get_workspaces()
         for ws in workspaces:
             try:
-                data = self.get_xml(f"{self.service_url}/services/{ogc_type}/workspaces/{ws.name}/settings")
+                data = self.get_xml(
+                    f"{self.service_url}/services/{ogc_type}/workspaces/{ws.name}/settings"
+                )
                 services.append(service_from_index(self, data))
             except FailedRequestError as e:
                 logger.debug(f"Not found {ogc_type} service for workspace {ws.name}")
         return services
 
     def create_user(self, username, password):
-
         users = self.get_users(names=username)
         if len(users) > 0:
             logging.warning(f"User {username} already exists")
-            tmp_cat = Catalog(service_url=self.service_url, username=username, password=password)
+            tmp_cat = Catalog(
+                service_url=self.service_url, username=username, password=password
+            )
             try:
                 tmp_cat.get_version()
             except FailedRequestError as e:
                 logger.error("And we probably have incorrect password")
                 raise FailedRequestError
 
             return users[0]
@@ -1354,82 +1458,90 @@
             "<enabled>true</enabled>"
             "</user>"
         ).format(username=username, password=password)
 
         headers = {"Content-Type": "application/xml"}
         users_url = f"{self.service_url}/security/usergroup/users/"
 
-        resp = self.http_request(users_url, method='post', data=xml, headers=headers)
+        resp = self.http_request(users_url, method="post", data=xml, headers=headers)
         if resp.status_code not in (200, 201, 202):
-            raise FailedRequestError(f'Failed to create user {username} : {resp.status_code}, {resp.text}')
+            raise FailedRequestError(
+                f"Failed to create user {username} : {resp.status_code}, {resp.text}"
+            )
 
         self._cache.pop(f"{self.service_url}/security/usergroup/users/", None)
         users = self.get_users(names=username)
         return users[0] if users else None
 
     def get_users(self, names=None):
-        '''
-          Returns a list of users in the catalog.
-          If names is specified, will only return users that match.
-          names can either be a comma delimited string or an array.
-          Will return an empty list if no users are found (unlikely).
-        '''
+        """
+        Returns a list of users in the catalog.
+        If names is specified, will only return users that match.
+        names can either be a comma delimited string or an array.
+        Will return an empty list if no users are found (unlikely).
+        """
         if names is None:
             names = []
         elif isinstance(names, string_types):
-            names = [s.strip() for s in names.split(',') if s.strip()]
+            names = [s.strip() for s in names.split(",") if s.strip()]
 
         data = self.get_xml(f"{self.service_url}/security/usergroup/users/")
         users = []
         users.extend([user_from_index(self, node) for node in data.findall("user")])
 
         if users and names:
-            return ([ws for ws in users if ws.user_name in names])
+            return [ws for ws in users if ws.user_name in names]
         return users
 
     def get_master_pwd(self):
         url = f"{self.service_url}/security/masterpw.xml"
         resp = self.http_request(url)
         masterpwd = None
         if resp.status_code == 200:
             content = resp.content
             if isinstance(content, bytes):
-                content = content.decode('UTF-8')
+                content = content.decode("UTF-8")
             dom = XML(content)
-            masterpwd = dom.find("oldMasterPassword").text if dom.find("oldMasterPassword") is not None else None
+            masterpwd = (
+                dom.find("oldMasterPassword").text
+                if dom.find("oldMasterPassword") is not None
+                else None
+            )
         else:
             raise FailedRequestError(resp.content)
 
         return masterpwd
 
     def set_master_pwd(self, new_pwd):
         old_pwd = self.get_master_pwd()
         if old_pwd == new_pwd:
             return new_pwd
 
         headers = {"Content-Type": "application/xml"}
         url = f"{self.service_url}/security/masterpw.xml"
-        body = ("<masterPassword>"
-                "<oldMasterPassword>{old_pwd}</oldMasterPassword>"
-                "<newMasterPassword>{new_pwd}</newMasterPassword>"
-                "</masterPassword>").format(old_pwd=old_pwd, new_pwd=new_pwd)
+        body = (
+            "<masterPassword>"
+            "<oldMasterPassword>{old_pwd}</oldMasterPassword>"
+            "<newMasterPassword>{new_pwd}</newMasterPassword>"
+            "</masterPassword>"
+        ).format(old_pwd=old_pwd, new_pwd=new_pwd)
         resp = self.http_request(url, method="put", data=body, headers=headers)
         if resp.status_code == 200:
             res = new_pwd
             self.reload()
         else:
             raise FailedRequestError(resp.content)
         return res
 
     def set_my_pwd(self, new_pwd):
         headers = {"Content-Type": "application/xml"}
         url = f"{self.service_url}/security/self/password.xml"
-        body = ("<userPassword>"
-                "<newPassword>{new_pwd}</newPassword>"
-                "</userPassword>").format(new_pwd=new_pwd)
+        body = (
+            "<userPassword>" "<newPassword>{new_pwd}</newPassword>" "</userPassword>"
+        ).format(new_pwd=new_pwd)
         resp = self.http_request(url, method="put", data=body, headers=headers)
 
         if resp.status_code == 200:
             res = new_pwd
             self.reload()
             self.password = new_pwd
             self.reload()
```

## geoserver/layer.py

```diff
@@ -14,15 +14,16 @@
     from urlparse import urljoin
 
 from geoserver.support import (
     ResourceInfo,
     xml_property,
     write_bool,
     workspace_from_url,
-    resource_from_url)
+    resource_from_url,
+)
 from geoserver.style import Style
 
 
 class _attribution(object):
     def __init__(self, title, width, height, href, url, type):
         self.title = title
         self.width = width
@@ -82,15 +83,15 @@
         builder.start("logoType", dict())
         builder.data(attr.type)
         builder.end("logoType")
     builder.end("attribution")
 
 
 def _write_style_element(builder, name):
-    ws, name = name.split(':') if ':' in name else (None, name)
+    ws, name = name.split(":") if ":" in name else (None, name)
     builder.start("name", dict())
     builder.data(name)
     builder.end("name")
     if ws:
         builder.start("workspace", dict())
         builder.data(ws)
         builder.end("workspace")
@@ -103,15 +104,15 @@
     builder.end("defaultStyle")
 
 
 def _write_alternate_styles(builder, styles):
     builder.start("styles", dict())
     for s in styles:
         builder.start("style", dict())
-        _write_style_element(builder, getattr(s, 'fqn', s))
+        _write_style_element(builder, getattr(s, "fqn", s))
         builder.end("style")
     builder.end("styles")
 
 
 class Layer(ResourceInfo):
     def __init__(self, catalog, name):
         super(Layer, self).__init__()
@@ -120,53 +121,58 @@
         self.gs_version = self.catalog.get_short_version()
 
     resource_type = "layer"
     save_method = "PUT"
 
     @property
     def href(self):
-        return urljoin(
-            f"{self.catalog.service_url}/",
-            f"layers/{self.name}.xml"
-        )
+        return urljoin(f"{self.catalog.service_url}/", f"layers/{self.name}.xml")
 
     @property
     def resource(self):
         if self.dom is None:
             self.fetch()
         name = self.dom.find("resource/name").text
-        atom_link = [n for n in self.dom.find("resource") if 'href' in n.attrib]
-        ws_name = workspace_from_url(atom_link[0].get('href'))
+        atom_link = [n for n in self.dom.find("resource") if "href" in n.attrib]
+        ws_name = workspace_from_url(atom_link[0].get("href"))
         if self.gs_version >= "2.13":
             if ":" in name:
-                ws_name, name = name.split(':', 1)
-        store_name = resource_from_url(atom_link[0].get('href'), ws_name)
-        _resources = self.catalog.get_resources(names=[name], stores=[store_name], workspaces=[ws_name])
+                ws_name, name = name.split(":", 1)
+        store_name = resource_from_url(atom_link[0].get("href"), ws_name)
+        _resources = self.catalog.get_resources(
+            names=[name], stores=[store_name], workspaces=[ws_name]
+        )
         return _resources[0] if len(_resources) > 0 else _resources
 
     def _get_default_style(self, recursive=False):
-        if 'default_style' in self.dirty:
-            return self.dirty['default_style']
+        if "default_style" in self.dirty:
+            return self.dirty["default_style"]
         if self.dom is None:
             self.fetch()
         element = self.dom.find("defaultStyle")
         # aborted data uploads can result in no default style
         return self._resolve_style(element, recursive) if element is not None else None
 
     def _resolve_style(self, element, recursive=False):
-        if element and element.find('name') is not None and len(element.find('name').text):
-            if ":" in element.find('name').text:
-                ws_name, style_name = element.find('name').text.split(':')
+        if (
+            element
+            and element.find("name") is not None
+            and len(element.find("name").text)
+        ):
+            if ":" in element.find("name").text:
+                ws_name, style_name = element.find("name").text.split(":")
             else:
-                style_name = element.find('name').text
+                style_name = element.find("name").text
                 ws_name = None
-            atom_link = [n for n in element if 'href' in n.attrib]
+            atom_link = [n for n in element if "href" in n.attrib]
             if atom_link and ws_name is None:
                 ws_name = workspace_from_url(atom_link[0].get("href"))
-            return self.catalog.get_styles(names=style_name, workspaces=ws_name, recursive=recursive)[0]
+            return self.catalog.get_styles(
+                names=style_name, workspaces=ws_name, recursive=recursive
+            )[0]
         return None
 
     def _set_default_style(self, style):
         if isinstance(style, Style):
             style = style.fqn
         self.dirty["default_style"] = style
 
@@ -195,42 +201,42 @@
 
     # obtains uncached alternate styles with original format (recursive retrieval)
     def get_full_styles(self):
         return self._get_alternate_styles(True)
 
     def _get_attr_attribution(self):
         obj = {
-            'title': self.attribution_object.title,
-            'width': self.attribution_object.width,
-            'height': self.attribution_object.height,
-            'href': self.attribution_object.href,
-            'url': self.attribution_object.url,
-            'type': self.attribution_object.type
+            "title": self.attribution_object.title,
+            "width": self.attribution_object.width,
+            "height": self.attribution_object.height,
+            "href": self.attribution_object.href,
+            "url": self.attribution_object.url,
+            "type": self.attribution_object.type,
         }
         return obj
 
     def _set_attr_attribution(self, attribution):
         self.dirty["attribution"] = _attribution(
-            attribution['title'],
-            attribution['width'],
-            attribution['height'],
-            attribution['href'],
-            attribution['url'],
-            attribution['type']
+            attribution["title"],
+            attribution["width"],
+            attribution["height"],
+            attribution["href"],
+            attribution["url"],
+            attribution["type"],
         )
 
-        assert self.attribution_object.title == attribution['title']
-        assert self.attribution_object.width == attribution['width']
-        assert self.attribution_object.height == attribution['height']
-        assert self.attribution_object.href == attribution['href']
-        assert self.attribution_object.url == attribution['url']
-        assert self.attribution_object.type == attribution['type']
+        assert self.attribution_object.title == attribution["title"]
+        assert self.attribution_object.width == attribution["width"]
+        assert self.attribution_object.height == attribution["height"]
+        assert self.attribution_object.href == attribution["href"]
+        assert self.attribution_object.url == attribution["url"]
+        assert self.attribution_object.type == attribution["type"]
 
     attribution = property(_get_attr_attribution, _set_attr_attribution)
 
     writers = {
-        'attribution': _write_attribution,
-        'enabled': write_bool("enabled"),
-        'advertised': write_bool("advertised"),
-        'default_style': _write_default_style,
-        'alternate_styles': _write_alternate_styles
+        "attribution": _write_attribution,
+        "enabled": write_bool("enabled"),
+        "advertised": write_bool("advertised"),
+        "default_style": _write_default_style,
+        "alternate_styles": _write_alternate_styles,
     }
```

## geoserver/layergroup.py

```diff
@@ -6,20 +6,28 @@
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE.txt file in the root directory of this source tree.
 #
 #########################################################################
 
 from six import string_types
+
 try:
     from urllib.parse import urljoin
 except BaseException:
     from urlparse import urljoin
 
-from geoserver.support import ResourceInfo, bbox, write_bbox, write_string, xml_property, build_url
+from geoserver.support import (
+    ResourceInfo,
+    bbox,
+    write_bbox,
+    write_string,
+    xml_property,
+    build_url,
+)
 
 try:
     from past.builtins import basestring
 except ImportError:
     pass
 
 
@@ -36,23 +44,23 @@
 
 
 def _style_list(node):
     if node is not None:
         return [_maybe_text(n.find("name")) for n in node.findall("style")]
 
 
-def _write_layers(builder, layers, parent, element, attributes = None):
+def _write_layers(builder, layers, parent, element, attributes=None):
     builder.start(parent, dict())
     for l in layers:
         _name = None
         _attributes = attributes or dict()
         if l is not None:
-            if isinstance (l, dict):
-                _name = l.get('name', None)
-                _attributes = l.get('attributes', _attributes)
+            if isinstance(l, dict):
+                _name = l.get("name", None)
+                _attributes = l.get("attributes", _attributes)
             else:
                 _name = l
         if _name:
             builder.start(element, _attributes)
             if l is not None:
                 builder.start("name", dict())
                 builder.data(_name)
@@ -93,40 +101,36 @@
         # the XML format changed in 2.3.x - the element listing all the layers
         # and the entries themselves have changed
         if self.catalog.get_version() == "2.2.x":
             parent, element, attributes = "layers", "layer", None
         else:
             parent = "publishables"
             element = "published"
-            attributes = {'type': 'layer'}
+            attributes = {"type": "layer"}
         self._layer_parent = parent
         self._layer_element = element
         self._layer_attributes = attributes
         self.writers = {
-            'name': write_string("name"),
-            'styles': _write_styles,
-            'layers': lambda b, l: _write_layers(b, l, parent,
-                                                 element, attributes),
-            'bounds': write_bbox("bounds"),
-            'workspace': write_string("workspace"),
-            'mode': write_string("mode"),
-            'abstractTxt': write_string("abstractTxt"),
-            'title': write_string("title")
+            "name": write_string("name"),
+            "styles": _write_styles,
+            "layers": lambda b, l: _write_layers(b, l, parent, element, attributes),
+            "bounds": write_bbox("bounds"),
+            "workspace": write_string("workspace"),
+            "mode": write_string("mode"),
+            "abstractTxt": write_string("abstractTxt"),
+            "title": write_string("title"),
         }
 
     @property
     def href(self):
         path_parts = f"layergroups/{self.name}.xml"
         if self.workspace is not None and self.workspace:
-            workspace_name = getattr(self.workspace, 'name', self.workspace)
+            workspace_name = getattr(self.workspace, "name", self.workspace)
             path_parts = f"workspaces/{workspace_name}/{path_parts}"
-        return urljoin(
-            f"{self.catalog.service_url}/",
-            path_parts
-        )
+        return urljoin(f"{self.catalog.service_url}/", path_parts)
 
     styles = xml_property("styles", _style_list)
     bounds = xml_property("bounds", bbox)
     mode = xml_property("mode")
     abstract = xml_property("abstractTxt")
     title = xml_property("title")
 
@@ -154,29 +158,40 @@
 
     __repr__ = __str__
 
 
 class UnsavedLayerGroup(LayerGroup):
     save_method = "POST"
 
-    def __init__(self, catalog, name, layers, styles, bounds, mode, abstract, title, workspace = None):
+    def __init__(
+        self,
+        catalog,
+        name,
+        layers,
+        styles,
+        bounds,
+        mode,
+        abstract,
+        title,
+        workspace=None,
+    ):
         super(UnsavedLayerGroup, self).__init__(catalog, name, workspace=workspace)
         self.dirty.update(
-            name = name,
-            layers = layers,
-            styles = styles,
-            workspace = workspace,
-            mode = mode.upper(),
-            abstractTxt = abstract,
-            title = title
+            name=name,
+            layers=layers,
+            styles=styles,
+            workspace=workspace,
+            mode=mode.upper(),
+            abstractTxt=abstract,
+            title=title,
         )
         if bounds is not None:
-            self.dirty.update(bounds = bounds)
+            self.dirty.update(bounds=bounds)
 
     @property
     def href(self):
-        query = {'name': self.name}
-        path_parts = ['layergroups']
+        query = {"name": self.name}
+        path_parts = ["layergroups"]
         if self.workspace is not None and self.workspace:
-            workspace_name = getattr(self.workspace, 'name', self.workspace)
+            workspace_name = getattr(self.workspace, "name", self.workspace)
             path_parts = ["workspaces", workspace_name] + path_parts
         return build_url(self.catalog.service_url, path_parts, query)
```

## geoserver/resource.py

```diff
@@ -6,21 +6,34 @@
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE.txt file in the root directory of this source tree.
 #
 #########################################################################
 
 from six import string_types
+
 try:
     from urllib.parse import urljoin
 except BaseException:
     from urlparse import urljoin
 
-from geoserver.support import (ResourceInfo, xml_property, write_string, bbox, metadata, write_metadata,
-                               write_bbox, string_list, write_string_list, attribute_list, write_bool, build_url)
+from geoserver.support import (
+    ResourceInfo,
+    xml_property,
+    write_string,
+    bbox,
+    metadata,
+    write_metadata,
+    write_bbox,
+    string_list,
+    write_string_list,
+    attribute_list,
+    write_bool,
+    build_url,
+)
 
 try:
     from past.builtins import basestring
 except ImportError:
     pass
 
 
@@ -40,31 +53,32 @@
         return [md_link(n) for n in node.findall("metadataLink")]
 
 
 def write_metadata_link_list(name):
     def write(builder, md_links):
         builder.start(name, dict())
         if md_links:
-            for (mime, md_type, content_url) in md_links:
+            for mime, md_type, content_url in md_links:
                 # geoserver supports only three mime
-                if md_type not in ['ISO19115:2003', 'FGDC', 'TC211']:
-                    mime = 'other'
-                    md_type = 'other'
+                if md_type not in ["ISO19115:2003", "FGDC", "TC211"]:
+                    mime = "other"
+                    md_type = "other"
                 builder.start("metadataLink", dict())
                 builder.start("type", dict())
                 builder.data(mime)
                 builder.end("type")
                 builder.start("metadataType", dict())
                 builder.data(md_type)
                 builder.end("metadataType")
                 builder.start("content", dict())
                 builder.data(content_url)
                 builder.end("content")
                 builder.end("metadataLink")
         builder.end(name)
+
     return write
 
 
 def featuretype_from_index(catalog, workspace, store, node):
     name = node.find("name")
     return FeatureType(catalog, workspace, store, name.text)
 
@@ -76,27 +90,27 @@
 
 def wmslayer_from_index(catalog, workspace, store, node):
     name = node.find("name")
     return WmsLayer(catalog, workspace, store, name.text)
 
 
 class _ResourceBase(ResourceInfo):
-    save_method = 'PUT'
+    save_method = "PUT"
 
     def __init__(self, catalog, workspace, store, name, href=None):
         super(_ResourceBase, self).__init__()
         if not href:
             assert isinstance(store, ResourceInfo)
             assert isinstance(name, string_types)
             assert workspace is not None
         else:
-            parts = href.split('/')
-            self._workspace_name = parts[parts.index('workspaces') + 1]
+            parts = href.split("/")
+            self._workspace_name = parts[parts.index("workspaces") + 1]
             self._store_name = parts[parts.index(self.url_part_stores) + 1]
-            name = parts[-1].replace('.xml', '')
+            name = parts[-1].replace(".xml", "")
         self._href = href
         self.catalog = catalog
         self._workspace = workspace
         self._store = store
         self.name = name
 
     @property
@@ -104,38 +118,39 @@
         if not self._workspace:
             self._workspace = self.catalog.get_workspaces(self._workspace_name)[0]
         return self._workspace
 
     @property
     def store(self):
         if not self._store:
-            self._store = self.catalog.get_stores(names=self._store_name, workspaces=self._workspace_name)
+            self._store = self.catalog.get_stores(
+                names=self._store_name, workspaces=self._workspace_name
+            )
         return self._store
 
     @property
     def href(self):
         url = build_url(
             self.catalog.service_url,
             [
                 "workspaces",
                 self.workspace.name,
                 self.url_part_stores,
                 self.store.name,
                 self.url_part_types,
-                f"{self.name}.xml"
-            ]
+                f"{self.name}.xml",
+            ],
         )
         return url or self._href
 
 
 class FeatureType(_ResourceBase):
-
     resource_type = "featureType"
-    url_part_stores = 'datastores'
-    url_part_types = 'featuretypes'
+    url_part_stores = "datastores"
+    url_part_types = "featuretypes"
 
     title = xml_property("title")
     native_name = xml_property("nativeName")
     abstract = xml_property("abstract")
     enabled = xml_property("enabled")
     advertised = xml_property("advertised", default="true")
     native_bbox = xml_property("nativeBoundingBox", bbox)
@@ -144,28 +159,28 @@
     projection_policy = xml_property("projectionPolicy")
     keywords = xml_property("keywords", string_list)
     attributes = xml_property("attributes", attribute_list)
     metadata_links = xml_property("metadataLinks", metadata_link_list)
     metadata = xml_property("metadata", metadata)
 
     writers = {
-        'name': write_string("name"),
-        'nativeName': write_string("nativeName"),
-        'title': write_string("title"),
-        'abstract': write_string("abstract"),
-        'enabled': write_bool("enabled"),
-        'advertised': write_bool("advertised"),
-        'nativeBoundingBox': write_bbox("nativeBoundingBox"),
-        'latLonBoundingBox': write_bbox("latLonBoundingBox"),
-        'srs': write_string("srs"),
-        'nativeCRS': write_string("nativeCRS"),
-        'projectionPolicy': write_string("projectionPolicy"),
-        'keywords': write_string_list("keywords"),
-        'metadataLinks': write_metadata_link_list("metadataLinks"),
-        'metadata': write_metadata("metadata")
+        "name": write_string("name"),
+        "nativeName": write_string("nativeName"),
+        "title": write_string("title"),
+        "abstract": write_string("abstract"),
+        "enabled": write_bool("enabled"),
+        "advertised": write_bool("advertised"),
+        "nativeBoundingBox": write_bbox("nativeBoundingBox"),
+        "latLonBoundingBox": write_bbox("latLonBoundingBox"),
+        "srs": write_string("srs"),
+        "nativeCRS": write_string("nativeCRS"),
+        "projectionPolicy": write_string("projectionPolicy"),
+        "keywords": write_string_list("keywords"),
+        "metadataLinks": write_metadata_link_list("metadataLinks"),
+        "metadata": write_metadata("metadata"),
     }
 
 
 class CoverageDimension(object):
     def __init__(self, name, description, dimension_range):
         self.name = name
         self.description = description
@@ -208,18 +223,17 @@
         builder.data(str(dimension.range[1]))
         builder.end("max")
         builder.end("range")
     builder.end("coverageDimension")
 
 
 class Coverage(_ResourceBase):
-
     resource_type = "coverage"
-    url_part_stores = 'coveragestores'
-    url_part_types = 'coverages'
+    url_part_stores = "coveragestores"
+    url_part_types = "coverages"
 
     title = xml_property("title")
     native_name = xml_property("nativeName")
     native_format = xml_property("nativeFormat")
     native_crs = xml_property("nativeCRS")
     default_interpolation_method = xml_property("defaultInterpolationMethod")
     abstract = xml_property("abstract")
@@ -235,34 +249,34 @@
     response_srs_list = xml_property("responseSRS", string_list)
     supported_formats = xml_property("supportedFormats", string_list)
     metadata_links = xml_property("metadataLinks", metadata_link_list)
     metadata = xml_property("metadata", metadata)
     interpolation_methods = xml_property("interpolationMethods", string_list)
 
     writers = {
-        'title': write_string("title"),
-        'native_name': write_string("nativeName"),
-        'native_format': write_string("nativeFormat"),
-        'native_crs': write_string("nativeCRS"),
-        'default_interpolation_method': write_string("defaultInterpolationMethod"),
-        'description': write_string("description"),
-        'abstract': write_string("abstract"),
-        'enabled': write_bool("enabled"),
-        'advertised': write_bool("advertised"),
-        'nativeBoundingBox': write_bbox("nativeBoundingBox"),
-        'latLonBoundingBox': write_bbox("latLonBoundingBox"),
-        'srs': write_string("srs"),
-        'projection_policy': write_string("projectionPolicy"),
-        'keywords': write_string_list("keywords"),
-        'metadataLinks': write_metadata_link_list("metadataLinks"),
-        'requestSRS': write_string_list("requestSRS"),
-        'responseSRS': write_string_list("responseSRS"),
-        'supportedFormats': write_string_list("supportedFormats"),
-        'interpolation_methods': write_string_list("interpolationMethods"),
-        'metadata': write_metadata("metadata")
+        "title": write_string("title"),
+        "native_name": write_string("nativeName"),
+        "native_format": write_string("nativeFormat"),
+        "native_crs": write_string("nativeCRS"),
+        "default_interpolation_method": write_string("defaultInterpolationMethod"),
+        "description": write_string("description"),
+        "abstract": write_string("abstract"),
+        "enabled": write_bool("enabled"),
+        "advertised": write_bool("advertised"),
+        "nativeBoundingBox": write_bbox("nativeBoundingBox"),
+        "latLonBoundingBox": write_bbox("latLonBoundingBox"),
+        "srs": write_string("srs"),
+        "projection_policy": write_string("projectionPolicy"),
+        "keywords": write_string_list("keywords"),
+        "metadataLinks": write_metadata_link_list("metadataLinks"),
+        "requestSRS": write_string_list("requestSRS"),
+        "responseSRS": write_string_list("responseSRS"),
+        "supportedFormats": write_string_list("supportedFormats"),
+        "interpolation_methods": write_string_list("interpolationMethods"),
+        "metadata": write_metadata("metadata"),
     }
 
 
 class WmsLayer(ResourceInfo):
     resource_type = "wmsLayer"
     save_method = "PUT"
 
@@ -274,38 +288,37 @@
         self.name = name
 
     @property
     def href(self):
         # Removed Store from this due to error in the Rest API when including store
         return urljoin(
             f"{self.catalog.service_url}/",
-            f"workspaces/{self.workspace.name}/wmslayers/{self.name}.xml"
+            f"workspaces/{self.workspace.name}/wmslayers/{self.name}.xml",
         )
 
     title = xml_property("title")
     description = xml_property("description")
     abstract = xml_property("abstract")
     keywords = xml_property("keywords", string_list)
     # nativeCRS
     projection = xml_property("srs")
     native_bbox = xml_property("nativeBoundingBox", bbox)
     latlon_bbox = xml_property("latLonBoundingBox", bbox)
     projection_policy = xml_property("projectionPolicy")
     enabled = xml_property("enabled", lambda x: x.text == "true")
-    advertised = xml_property("advertised", lambda x: x.text == "true",
-                              default=True)
+    advertised = xml_property("advertised", lambda x: x.text == "true", default=True)
     metadata_links = xml_property("metadataLinks", metadata_link_list)
 
     writers = {
-        'title': write_string("title"),
-        'description': write_string("description"),
-        'abstract': write_string("abstract"),
-        'keywords': write_string_list("keywords"),
+        "title": write_string("title"),
+        "description": write_string("description"),
+        "abstract": write_string("abstract"),
+        "keywords": write_string_list("keywords"),
         # nativeCRS
-        'srs': write_string("srs"),
-        'nativeBoundingBox': write_bbox("nativeBoundingBox"),
-        'latLonBoundingBox': write_bbox("latLonBoundingBox"),
-        'projectionPolicy': write_string("projectionPolicy"),
-        'enabled': write_bool("enabled"),
-        'advertised': write_bool("advertised"),
-        'metadataLinks': write_metadata_link_list("metadataLinks")
+        "srs": write_string("srs"),
+        "nativeBoundingBox": write_bbox("nativeBoundingBox"),
+        "latLonBoundingBox": write_bbox("latLonBoundingBox"),
+        "projectionPolicy": write_string("projectionPolicy"),
+        "enabled": write_bool("enabled"),
+        "advertised": write_bool("advertised"),
+        "metadataLinks": write_metadata_link_list("metadataLinks"),
     }
```

## geoserver/security.py

```diff
@@ -37,18 +37,15 @@
     @property
     def user_name(self):
         return self._user_name
 
     @property
     def href(self):
         return urljoin(
-            f"{self.catalog.service_url}/",
-            f"security/usergroup/users/{self.user_name}"
+            f"{self.catalog.service_url}/", f"security/usergroup/users/{self.user_name}"
         )
 
-    enabled = xml_property("enabled", lambda x: x.lower() == 'true')
-    writers = {
-        'enabled': write_bool("enabled")
-    }
+    enabled = xml_property("enabled", lambda x: x.lower() == "true")
+    writers = {"enabled": write_bool("enabled")}
 
     def __repr__(self):
         return f"{self.user_name} @ {self.href}"
```

## geoserver/service.py

```diff
@@ -19,15 +19,16 @@
     xml_property,
     write_bool,
     write_dict,
     write_string,
     write_int,
     string_list,
     key_value_pairs,
-    write_string_list)
+    write_string_list,
+)
 
 
 def service_from_index(catalog, node):
     if node.tag == "wms":
         bclass = ServiceWmsSettings
     elif node.tag == "wfs":
         bclass = ServiceWfsSettings
@@ -36,15 +37,17 @@
     elif node.tag == "wmts":
         bclass = ServiceWmtsSettings
     else:
         return None
 
     res = bclass(
         catalog=catalog,
-        workspace=node.find("workspace").find("name").text if node.find("workspace") is not None else None
+        workspace=node.find("workspace").find("name").text
+        if node.find("workspace") is not None
+        else None,
     )
 
     return res
 
 
 class Watermark(object):
     def __init__(self, _enabled, _position, _transparency):
@@ -52,15 +55,19 @@
         self.position = _position
         self.transparency = _transparency
 
 
 def watermark(node):
     enabled = node.find("enabled").text if node.find("enabled") is not None else None
     position = node.find("position").text if node.find("position") is not None else None
-    transparency = node.find("transparency").text if node.find("transparency") is not None else None
+    transparency = (
+        node.find("transparency").text
+        if node.find("transparency") is not None
+        else None
+    )
     return Watermark(enabled, position, transparency)
 
 
 def write_watermark_xml(watermark):
     def write(builder, watermark):
         builder.start("watermark", dict())
         # enabled
@@ -112,17 +119,24 @@
 
 
 def gml(node):
     gmls = []
     for ent in node.iter("entry"):
         version = ent.find("version").text if ent.find("version") is not None else None
         el_gml = ent.find("gml")
-        srs = el_gml.find("srsNameStyle").text if el_gml.find("srsNameStyle") is not None else None
-        override = el_gml.find("overrideGMLAttributes").text if el_gml.find(
-            "overrideGMLAttributes") is not None else None
+        srs = (
+            el_gml.find("srsNameStyle").text
+            if el_gml.find("srsNameStyle") is not None
+            else None
+        )
+        override = (
+            el_gml.find("overrideGMLAttributes").text
+            if el_gml.find("overrideGMLAttributes") is not None
+            else None
+        )
         res_gml = Gml(_srsNameStyle=srs, _overrideGMLAttributes=override)
         res = GmlEntry(_version=version, _gml=res_gml)
         gmls.append(res)
     return gmls
 
 
 def write_gml(gml_list):
@@ -171,116 +185,133 @@
             return None
 
     @property
     def href(self):
         if self._workspace_name is not None:
             return urljoin(
                 f"{self.catalog.service_url}/",
-                f"services/{self.resource_type}/workspaces/{self._workspace_name}/settings"
+                f"services/{self.resource_type}/workspaces/{self._workspace_name}/settings",
             )
         else:
             return f"{self.catalog.service_url}/services/{self.resource_type}/settings"
 
-    enabled = xml_property("enabled", lambda x: x.text == 'true')
+    enabled = xml_property("enabled", lambda x: x.text == "true")
     name = xml_property("name")
     title = xml_property("title")
     maintainer = xml_property("maintainer")
     abstrct = xml_property("abstrct")
     accessConstraints = xml_property("accessConstraints")
     fees = xml_property("fees")
     versions = xml_property("versions", util_version)
     keywords = xml_property("keywords", string_list)
-    citeCompliant = xml_property("citeCompliant", lambda x: x.text == 'true')
+    citeCompliant = xml_property("citeCompliant", lambda x: x.text == "true")
     onlineResource = xml_property("onlineResource")
     schemaBaseURL = xml_property("schemaBaseURL")
-    verbose = xml_property("verbose", lambda x: x.text == 'true')
+    verbose = xml_property("verbose", lambda x: x.text == "true")
 
     writers = {
-        'enabled': write_bool("enabled"),
+        "enabled": write_bool("enabled"),
         "name": write_string("name"),
         "title": write_string("title"),
         "versions": write_util_version("versions"),
         "maintainer": write_string("maintainer"),
         "abstrct": write_string("abstrct"),
         "accessConstraints": write_string("accessConstraints"),
         "fees": write_string("fees"),
         "keywords": write_string_list("keywords"),
         "citeCompliant": write_bool("citeCompliant"),
         "onlineResource": write_string("onlineResource"),
         "schemaBaseURL": write_string("schemaBaseURL"),
-        "verbose": write_bool("verbose")
+        "verbose": write_bool("verbose"),
     }
 
 
 class ServiceWmsSettings(ServiceCommon):
     resource_type = "wms"
 
     metadata = xml_property("metadata", key_value_pairs)
     watermark = xml_property("watermark", watermark)
     interpolation = xml_property("interpolation")
-    getFeatureInfoMimeTypeCheckingEnabled = xml_property("getFeatureInfoMimeTypeCheckingEnabled",
-                                                         lambda x: x.text == 'true')
-    dynamicStylingDisabled = xml_property("dynamicStylingDisabled", lambda x: x.text == 'true')
+    getFeatureInfoMimeTypeCheckingEnabled = xml_property(
+        "getFeatureInfoMimeTypeCheckingEnabled", lambda x: x.text == "true"
+    )
+    dynamicStylingDisabled = xml_property(
+        "dynamicStylingDisabled", lambda x: x.text == "true"
+    )
     maxBuffer = xml_property("maxBuffer", lambda x: int(x.text))
     maxRequestMemory = xml_property("maxRequestMemory", lambda x: int(x.text))
     maxRenderingTime = xml_property("maxRenderingTime", lambda x: int(x.text))
     maxRenderingErrors = xml_property("maxRenderingErrors", lambda x: int(x.text))
 
     writers = dict(ServiceCommon.writers)
-    writers.update({
-        "metadata": write_dict("metadata"),
-        "watermark": write_watermark_xml("watermark"),
-        "interpolation": write_string("interpolation"),
-        "getFeatureInfoMimeTypeCheckingEnabled": write_bool("getFeatureInfoMimeTypeCheckingEnabled"),
-        "dynamicStylingDisabled": write_bool("dynamicStylingDisabled"),
-        "maxBuffer": write_int("maxBuffer"),
-        "maxRequestMemory": write_int("maxRequestMemory"),
-        "maxRenderingTime": write_int("maxRenderingTime"),
-        "maxRenderingErrors": write_int("maxRenderingErrors")
-    })
+    writers.update(
+        {
+            "metadata": write_dict("metadata"),
+            "watermark": write_watermark_xml("watermark"),
+            "interpolation": write_string("interpolation"),
+            "getFeatureInfoMimeTypeCheckingEnabled": write_bool(
+                "getFeatureInfoMimeTypeCheckingEnabled"
+            ),
+            "dynamicStylingDisabled": write_bool("dynamicStylingDisabled"),
+            "maxBuffer": write_int("maxBuffer"),
+            "maxRequestMemory": write_int("maxRequestMemory"),
+            "maxRenderingTime": write_int("maxRenderingTime"),
+            "maxRenderingErrors": write_int("maxRenderingErrors"),
+        }
+    )
 
 
 class ServiceWfsSettings(ServiceCommon):
     resource_type = "wfs"
 
     metadataLink = xml_property("metadataLink", key_value_pairs)
     gml = xml_property("gml", gml)
     serviceLevel = xml_property("serviceLevel")
     maxFeatures = xml_property("maxFeatures", lambda x: int(x.text))
-    featureBounding = xml_property("featureBounding", lambda x: x.text == 'true')
-    canonicalSchemaLocation = xml_property("canonicalSchemaLocation", lambda x: x.text == 'true')
-    encodeFeatureMember = xml_property("encodeFeatureMember", lambda x: x.text == 'true')
-    hitsIgnoreMaxFeatures = xml_property("hitsIgnoreMaxFeatures", lambda x: x.text == 'true')
+    featureBounding = xml_property("featureBounding", lambda x: x.text == "true")
+    canonicalSchemaLocation = xml_property(
+        "canonicalSchemaLocation", lambda x: x.text == "true"
+    )
+    encodeFeatureMember = xml_property(
+        "encodeFeatureMember", lambda x: x.text == "true"
+    )
+    hitsIgnoreMaxFeatures = xml_property(
+        "hitsIgnoreMaxFeatures", lambda x: x.text == "true"
+    )
 
     writers = dict(ServiceCommon.writers)
-    writers.update({
-        "gml": write_gml("gml"),
-        "serviceLevel": write_string("serviceLevel"),
-        "maxFeatures": write_int("maxFeatures"),
-        "featureBounding": write_bool("featureBounding"),
-        "canonicalSchemaLocation": write_bool("canonicalSchemaLocation"),
-        "encodeFeatureMember": write_bool("encodeFeatureMember"),
-        "hitsIgnoreMaxFeatures": write_bool("hitsIgnoreMaxFeatures"),
-    })
+    writers.update(
+        {
+            "gml": write_gml("gml"),
+            "serviceLevel": write_string("serviceLevel"),
+            "maxFeatures": write_int("maxFeatures"),
+            "featureBounding": write_bool("featureBounding"),
+            "canonicalSchemaLocation": write_bool("canonicalSchemaLocation"),
+            "encodeFeatureMember": write_bool("encodeFeatureMember"),
+            "hitsIgnoreMaxFeatures": write_bool("hitsIgnoreMaxFeatures"),
+        }
+    )
 
 
 class ServiceWcsSettings(ServiceCommon):
     resource_type = "wcs"
 
     metadataLink = xml_property("metadataLink", key_value_pairs)
-    gmlPrefixing = xml_property("gmlPrefixing", lambda x: x.text == 'true')
-    latLon = xml_property("latLon", lambda x: x.text == 'true')
+    gmlPrefixing = xml_property("gmlPrefixing", lambda x: x.text == "true")
+    latLon = xml_property("latLon", lambda x: x.text == "true")
     maxInputMemory = xml_property("maxInputMemory", lambda x: int(x.text))
     maxOutputMemory = xml_property("maxOutputMemory", lambda x: int(x.text))
 
     writers = dict(ServiceCommon.writers)
-    writers.update({
-        "metadataLink": write_dict("metadataLink"),
-        "gmlPrefixing": write_bool("gmlPrefixing"),
-        "latLon": write_bool("latLon"),
-        "maxInputMemory": write_int("maxInputMemory"),
-        "maxOutputMemory": write_int("maxOutputMemory")
-    })
+    writers.update(
+        {
+            "metadataLink": write_dict("metadataLink"),
+            "gmlPrefixing": write_bool("gmlPrefixing"),
+            "latLon": write_bool("latLon"),
+            "maxInputMemory": write_int("maxInputMemory"),
+            "maxOutputMemory": write_int("maxOutputMemory"),
+        }
+    )
 
 
 class ServiceWmtsSettings(ServiceCommon):
     resource_type = "wmts"
```

## geoserver/settings.py

```diff
@@ -11,23 +11,32 @@
 #########################################################################
 try:
     from urllib.parse import urljoin
 except BaseException:
     from urlparse import urljoin
 
 from geoserver.support import (
-    ResourceInfo, StaticResourceInfo,
+    ResourceInfo,
+    StaticResourceInfo,
     xml_property,
-    read_bool, read_float, read_int, read_string,
-    write_bool, write_float, write_int, write_string)
+    read_bool,
+    read_float,
+    read_int,
+    read_string,
+    write_bool,
+    write_float,
+    write_int,
+    write_string,
+)
 
 
 def write_subclass(sbc):
     def write(builder, sbc):
         sbc.serialize_all(builder)
+
     return write
 
 
 class Contact(StaticResourceInfo):
     resource_type = "contact"
 
     def __init__(self, dom):
@@ -45,15 +54,15 @@
     writers = {
         "addressCity": write_string("addressCity"),
         "addressCountry": write_string("addressCountry"),
         "addressType": write_string("addressType"),
         "contactEmail": write_string("contactEmail"),
         "contactOrganization": write_string("contactOrganization"),
         "contactPerson": write_string("contactPerson"),
-        "contactPosition": write_string("contactPosition")
+        "contactPosition": write_string("contactPosition"),
     }
 
 
 class Settings(StaticResourceInfo):
     resource_type = "settings"
 
     def __init__(self, dom):
@@ -63,30 +72,31 @@
     id = xml_property("id", read_string)
     contact = xml_property("contact", Contact)
     charset = xml_property("charset", read_string)
     numDecimals = xml_property("numDecimals", read_int)
     onlineResource = xml_property("onlineResource", read_string)
     verbose = xml_property("verbose", read_bool)
     verboseExceptions = xml_property("verboseExceptions", read_bool)
-    localWorkspaceIncludesPrefix = xml_property("localWorkspaceIncludesPrefix", read_bool)
+    localWorkspaceIncludesPrefix = xml_property(
+        "localWorkspaceIncludesPrefix", read_bool
+    )
 
     writers = {
         "id": write_string("id"),
         "contact": write_subclass("contact"),
         "charset": write_string("charset"),
         "numDecimals": write_int("numDecimals"),
         "onlineResource": write_string("onlineResource"),
         "verbose": write_bool("verbose"),
         "verboseExceptions": write_bool("verboseExceptions"),
         "localWorkspaceIncludesPrefix": write_bool("localWorkspaceIncludesPrefix"),
     }
 
 
 class Jai(StaticResourceInfo):
-
     def __init__(self, dom):
         super(Jai, self).__init__()
         self.dom = dom
 
     resource_type = "jai"
 
     allowInterpolation = xml_property("allowInterpolation", read_bool)
@@ -108,20 +118,19 @@
         "tileThreads": write_int("tileThreads"),
         "memoryCapacity": write_float("memoryCapacity"),
         "memoryThreshold": write_float("memoryThreshold"),
         "imageIOCache": write_bool("imageIOCache"),
         "pngAcceleration": write_bool("pngAcceleration"),
         "jpegAcceleration": write_bool("jpegAcceleration"),
         "allowNativeMosaic": write_bool("allowNativeMosaic"),
-        "allowNativeWarp": write_bool("allowNativeWarp")
+        "allowNativeWarp": write_bool("allowNativeWarp"),
     }
 
 
 class CoverageAccess(StaticResourceInfo):
-
     def __init__(self, dom):
         super(CoverageAccess, self).__init__()
         self.dom = dom
 
     resource_type = "coverageAccess"
 
     maxPoolSize = xml_property("maxPoolSize", read_int)
@@ -131,15 +140,15 @@
     imageIOCacheThreshold = xml_property("imageIOCacheThreshold", read_int)
 
     writers = {
         "maxPoolSize": write_int("maxPoolSize"),
         "corePoolSize": write_int("corePoolSize"),
         "keepAliveTime": write_int("keepAliveTime"),
         "queueType": write_string("queueType"),
-        "imageIOCacheThreshold": write_int("imageIOCacheThreshold")
+        "imageIOCacheThreshold": write_int("imageIOCacheThreshold"),
     }
 
 
 class GlobalSettings(ResourceInfo):
     resource_type = "global"
     save_method = "put"
 
@@ -149,31 +158,30 @@
 
     @property
     def catalog(self):
         return self._catalog
 
     @property
     def href(self):
-        return urljoin(
-            f"{self.catalog.service_url}/",
-            "settings"
-        )
+        return urljoin(f"{self.catalog.service_url}/", "settings")
 
     settings = xml_property("settings", Settings)
     jai = xml_property("jai", Jai)
     coverageAccess = xml_property("coverageAccess", CoverageAccess)
     updateSequence = xml_property("updateSequence", lambda x: int(x.text))
     featureTypeCacheSize = xml_property("featureTypeCacheSize", lambda x: int(x.text))
-    globalServices = xml_property("globalServices", lambda x: x.text.lower() == 'true')
-    xmlPostRequestLogBufferSize = xml_property("xmlPostRequestLogBufferSize", lambda x: int(x.text))
+    globalServices = xml_property("globalServices", lambda x: x.text.lower() == "true")
+    xmlPostRequestLogBufferSize = xml_property(
+        "xmlPostRequestLogBufferSize", lambda x: int(x.text)
+    )
 
     writers = {
-        'settings': write_subclass("settings"),
-        'jai': write_subclass("jai"),
-        'coverageAccess': write_subclass("coverageAccess"),
-        'featureTypeCacheSize': write_int("featureTypeCacheSize"),
-        'globalServices': write_bool("globalServices"),
-        'xmlPostRequestLogBufferSize': write_int("xmlPostRequestLogBufferSize")
+        "settings": write_subclass("settings"),
+        "jai": write_subclass("jai"),
+        "coverageAccess": write_subclass("coverageAccess"),
+        "featureTypeCacheSize": write_int("featureTypeCacheSize"),
+        "globalServices": write_bool("globalServices"),
+        "xmlPostRequestLogBufferSize": write_int("xmlPostRequestLogBufferSize"),
     }
 
     def __repr__(self):
         return f"settings @ {self.href}"
```

## geoserver/store.py

```diff
@@ -7,16 +7,28 @@
 # This source code is licensed under the MIT license found in the
 # LICENSE.txt file in the root directory of this source tree.
 #
 #########################################################################
 
 from six import string_types
 import geoserver.workspace as ws
-from geoserver.resource import featuretype_from_index, coverage_from_index, wmslayer_from_index
-from geoserver.support import ResourceInfo, xml_property, key_value_pairs, write_bool, write_dict, write_string, build_url
+from geoserver.resource import (
+    featuretype_from_index,
+    coverage_from_index,
+    wmslayer_from_index,
+)
+from geoserver.support import (
+    ResourceInfo,
+    xml_property,
+    key_value_pairs,
+    write_bool,
+    write_dict,
+    write_string,
+    build_url,
+)
 
 try:
     from past.builtins import basestring
 except ImportError:
     pass
 
 
@@ -34,15 +46,14 @@
     name = node.find("name")
     # user = node.find("user")
     # password = node.find("password")
     return WmsStore(catalog, workspace, name.text, None, None)
 
 
 class DataStore(ResourceInfo):
-
     resource_type = "dataStore"
     save_method = "PUT"
 
     def __init__(self, catalog, workspace, name):
         super(DataStore, self).__init__()
 
         assert isinstance(workspace, ws.Workspace)
@@ -51,46 +62,41 @@
         self.workspace = workspace
         self.name = name
 
     @property
     def href(self):
         url = build_url(
             self.catalog.service_url,
-            [
-                "workspaces",
-                self.workspace.name,
-                "datastores",
-                f"{self.name}.xml"
-            ]
+            ["workspaces", self.workspace.name, "datastores", f"{self.name}.xml"],
         )
         return url
 
     enabled = xml_property("enabled", lambda x: x.text == "true")
     name = xml_property("name")
     type = xml_property("type")
     connection_parameters = xml_property("connectionParameters", key_value_pairs)
 
     writers = dict(
-        enabled = write_bool("enabled"),
-        name = write_string("name"),
-        type = write_string("type"),
-        connectionParameters = write_dict("connectionParameters")
+        enabled=write_bool("enabled"),
+        name=write_string("name"),
+        type=write_string("type"),
+        connectionParameters=write_dict("connectionParameters"),
     )
 
     @property
     def resource_url(self):
         url = build_url(
             self.catalog.service_url,
             [
                 "workspaces",
                 self.workspace.name,
                 "datastores",
                 self.name,
-                "featuretypes.xml"
-            ]
+                "featuretypes.xml",
+            ],
         )
         return url
 
     def get_resources(self, name=None, available=False):
         res_url = self.resource_url
         if available:
             res_url += "?list=available"
@@ -108,81 +114,71 @@
         if available:
             return [str(node.text) for node in xml.findall("featureTypeName")]
         else:
             return [ft_from_node(node) for node in xml.findall("featureType")]
 
 
 class UnsavedDataStore(DataStore):
-
     save_method = "POST"
 
     def __init__(self, catalog, name, workspace):
         super(UnsavedDataStore, self).__init__(catalog, workspace, name)
-        self.dirty.update(dict(
-            name=name, enabled=True, type=None,
-            connectionParameters=dict()))
+        self.dirty.update(
+            dict(name=name, enabled=True, type=None, connectionParameters=dict())
+        )
 
     @property
     def href(self):
-        path = [
-            "workspaces",
-            self.workspace.name,
-            "datastores"
-        ]
+        path = ["workspaces", self.workspace.name, "datastores"]
         query = dict(name=self.name)
         return build_url(self.catalog.service_url, path, query)
 
 
 class CoverageStore(ResourceInfo):
-    resource_type = 'coverageStore'
+    resource_type = "coverageStore"
     save_method = "PUT"
 
     def __init__(self, catalog, workspace, name):
         super(CoverageStore, self).__init__()
 
         self.catalog = catalog
         self.workspace = workspace
         self.name = name
 
     @property
     def href(self):
         url = build_url(
             self.catalog.service_url,
-            [
-                "workspaces",
-                self.workspace.name,
-                "coveragestores",
-                f"{self.name}.xml"
-            ]
+            ["workspaces", self.workspace.name, "coveragestores", f"{self.name}.xml"],
         )
         return url
 
     enabled = xml_property("enabled", lambda x: x.text == "true")
     name = xml_property("name")
     url = xml_property("url")
     type = xml_property("type")
 
     writers = dict(
-        enabled = write_bool("enabled"),
-        name = write_string("name"),
-        url = write_string("url"),
-        type = write_string("type"),
-        workspace = write_string("workspace")
+        enabled=write_bool("enabled"),
+        name=write_string("name"),
+        url=write_string("url"),
+        type=write_string("type"),
+        workspace=write_string("workspace"),
     )
 
     def get_resources(self, name=None):
         res_url = build_url(
             self.catalog.service_url,
             [
                 "workspaces",
                 self.workspace.name,
                 "coveragestores",
                 self.name,
-                "coverages.xml"
-            ]
+                "coverages.xml",
+            ],
         )
 
         xml = self.catalog.get_xml(res_url)
 
         def cov_from_node(node):
             return coverage_from_index(self.catalog, self.workspace, self, node)
 
@@ -197,72 +193,70 @@
 
 class UnsavedCoverageStore(CoverageStore):
     save_method = "POST"
 
     def __init__(self, catalog, name, workspace):
         super(UnsavedCoverageStore, self).__init__(catalog, workspace, name)
         self.dirty.update(
-            name = name,
-            enabled = True,
-            type = 'GeoTIFF',
-            url = "file:data/",
-            workspace = workspace
+            name=name,
+            enabled=True,
+            type="GeoTIFF",
+            url="file:data/",
+            workspace=workspace,
         )
 
     @property
     def href(self):
         url = build_url(
             self.catalog.service_url,
-            [
-                "workspaces",
-                self.workspace,
-                "coveragestores"
-            ],
-            dict(name=self.name)
+            ["workspaces", self.workspace, "coveragestores"],
+            dict(name=self.name),
         )
         return url
 
 
 class WmsStore(ResourceInfo):
     resource_type = "wmsStore"
     save_method = "PUT"
 
     def __init__(self, catalog, workspace, name, user, password):
         super(WmsStore, self).__init__()
         self.catalog = catalog
         self.workspace = workspace
         self.name = name
         self.metadata = {}
-        self.metadata['user'] = user
-        self.metadata['password'] = password
+        self.metadata["user"] = user
+        self.metadata["password"] = password
 
     @property
     def href(self):
         return f"{self.catalog.service_url}/workspaces/{self.workspace.name}/wmsstores/{self.name}.xml"
 
     enabled = xml_property("enabled", lambda x: x.text == "true")
     name = xml_property("name")
     nativeName = xml_property("nativeName")
     capabilitiesURL = xml_property("capabilitiesURL")
     type = xml_property("type")
     metadata = xml_property("metadata", key_value_pairs)
 
-    writers = dict(enabled = write_bool("enabled"),
-                   name = write_string("name"),
-                   capabilitiesURL = write_string("capabilitiesURL"),
-                   type = write_string("type"),
-                   metadata = write_dict("metadata"))
+    writers = dict(
+        enabled=write_bool("enabled"),
+        name=write_string("name"),
+        capabilitiesURL=write_string("capabilitiesURL"),
+        type=write_string("type"),
+        metadata=write_dict("metadata"),
+    )
 
     def get_resources(self, name=None, available=False):
         res_url = f"{self.catalog.service_url}/workspaces/{self.workspace.name}/wmsstores/{self.name}/wmslayers.xml"
         layer_name_attr = "wmsLayer"
 
         if available:
             res_url += "?list=available"
-            layer_name_attr += 'Name'
+            layer_name_attr += "Name"
 
         xml = self.catalog.get_xml(res_url)
 
         def wl_from_node(node):
             return wmslayer_from_index(self.catalog, self.workspace, self, node)
 
         # if name passed, return only one layer, otherwise return all layers in store:
@@ -281,15 +275,22 @@
 class UnsavedWmsStore(WmsStore):
     save_method = "POST"
 
     def __init__(self, catalog, name, workspace, user, password):
         super(UnsavedWmsStore, self).__init__(catalog, workspace, name, user, password)
         metadata = {}
         if user is not None and password is not None:
-            metadata['user'] = user
-            metadata['password'] = password
-        self.dirty.update(dict(
-            name=name, enabled=True, capabilitiesURL="", type="WMS", metadata=metadata))
+            metadata["user"] = user
+            metadata["password"] = password
+        self.dirty.update(
+            dict(
+                name=name,
+                enabled=True,
+                capabilitiesURL="",
+                type="WMS",
+                metadata=metadata,
+            )
+        )
 
     @property
     def href(self):
         return f"{self.catalog.service_url}/workspaces/{self.workspace.name}/wmsstores?name={self.name}"
```

## geoserver/style.py

```diff
@@ -21,15 +21,14 @@
 class Style(ResourceInfo):
     supported_formats = ["sld10", "sld11", "zip10", "css10"]
     content_types = {
         "sld10": "application/vnd.ogc.sld+xml",
         "sld11": "application/vnd.ogc.se+xml",
         "zip10": "application/zip",
         "css10": "application/vnd.geoserver.geocss+css",
-
     }
 
     def __init__(self, catalog, name, workspace=None, style_format="sld10"):
         super(Style, self).__init__()
         assert isinstance(name, string_types)
         assert style_format in Style.supported_formats
 
@@ -39,56 +38,63 @@
         self.style_format = style_format
         self._sld_dom = None
 
     @property
     def fqn(self):
         if not self.workspace:
             return self.name
-        return f'{self.workspace}:{self.name}'
+        return f"{self.workspace}:{self.name}"
 
     @property
     def href(self):
-        return self._build_href('.xml')
+        return self._build_href(".xml")
 
     @property
     def body_href(self):
-        return self._build_href('.sld')
+        return self._build_href(".sld")
 
     @property
     def create_href(self):
-        return self._build_href('.xml', True)
+        return self._build_href(".xml", True)
 
     @property
     def content_type(self):
         return Style.content_types[self.style_format]
 
     def _build_href(self, extension, create=False):
         path_parts = ["styles"]
         query = {}
         if not create:
             path_parts.append(self.name + extension)
         else:
-            query['name'] = self.name
+            query["name"] = self.name
         if self.workspace is not None and self.workspace:
-            path_parts = ["workspaces", getattr(self.workspace, 'name', self.workspace)] + path_parts
+            path_parts = [
+                "workspaces",
+                getattr(self.workspace, "name", self.workspace),
+            ] + path_parts
         return build_url(self.catalog.service_url, path_parts, query)
 
     filename = xml_property("filename")
 
     def _get_sld_dom(self):
         if self._sld_dom is None:
             self._sld_dom = self.catalog.get_xml(self.body_href)
         return self._sld_dom
 
     @property
     def sld_title(self):
         named_layer = self._get_sld_dom().find("{http://www.opengis.net/sld}NamedLayer")
-        user_style = self._get_sld_dom().find("{http://www.opengis.net/sld}NamedLayer/{http://www.opengis.net/sld}UserStyle")
+        user_style = self._get_sld_dom().find(
+            "{http://www.opengis.net/sld}NamedLayer/{http://www.opengis.net/sld}UserStyle"
+        )
         if not user_style:
-            user_style = self._get_sld_dom().find("{http://www.opengis.net/sld}UserLayer/{http://www.opengis.net/sld}UserStyle")
+            user_style = self._get_sld_dom().find(
+                "{http://www.opengis.net/sld}UserLayer/{http://www.opengis.net/sld}UserStyle"
+            )
 
         title_node = None
         if named_layer:
             try:
                 # it is not mandatory
                 title_node = named_layer.find("{http://www.opengis.net/sld}Title")
             except AttributeError:
@@ -101,17 +107,21 @@
                 pass
 
         return str(title_node.text) if title_node is not None else None
 
     @property
     def sld_name(self):
         named_layer = self._get_sld_dom().find("{http://www.opengis.net/sld}NamedLayer")
-        user_style = self._get_sld_dom().find("{http://www.opengis.net/sld}NamedLayer/{http://www.opengis.net/sld}UserStyle")
+        user_style = self._get_sld_dom().find(
+            "{http://www.opengis.net/sld}NamedLayer/{http://www.opengis.net/sld}UserStyle"
+        )
         if not user_style:
-            user_style = self._get_sld_dom().find("{http://www.opengis.net/sld}UserLayer/{http://www.opengis.net/sld}UserStyle")
+            user_style = self._get_sld_dom().find(
+                "{http://www.opengis.net/sld}UserLayer/{http://www.opengis.net/sld}UserStyle"
+            )
 
         name_node = None
         if named_layer:
             try:
                 # it is not mandatory
                 name_node = named_layer.find("{http://www.opengis.net/sld}Name")
             except AttributeError:
@@ -127,26 +137,22 @@
     @property
     def sld_body(self):
         resp = self.catalog.http_request(self.body_href)
         return resp.content
 
     @property
     def body(self):
-        href_ext = ''
+        href_ext = ""
         _headers = {}
         if self.style_format and Style.content_types.get(self.style_format):
-            _headers = {
-                'Accept': Style.content_types[self.style_format]
-            }
+            _headers = {"Accept": Style.content_types[self.style_format]}
         else:
             # [:-2] remove version tag from type. GeoServer does not accept it
-            href_ext = f'.{self.style_format[:-2]}'
-        resp = self.catalog.http_request(
-            self._build_href(href_ext),
-            headers = _headers
-        )
+            href_ext = f".{self.style_format[:-2]}"
+        resp = self.catalog.http_request(self._build_href(href_ext), headers=_headers)
         return resp.content
 
     def update_body(self, body):
         headers = {"Content-Type": self.content_type}
         self.catalog.http_request(
-            self.body_href, data=body, method='put', headers=headers)
+            self.body_href, data=body, method="put", headers=headers
+        )
```

## geoserver/support.py

```diff
@@ -52,25 +52,25 @@
     parameters.
     """
 
     def clean_segment(segment):
         """
         Cleans the segment and encodes to UTF-8 if the segment is unicode.
         """
-        segment = segment.strip('/')
+        segment = segment.strip("/")
         if isinstance(segment, string_types):
             segment = segment
         return segment
 
     seg = (quote(clean_segment(s)) for s in seg)
     if query is None or len(query) == 0:
-        query_string = ''
+        query_string = ""
     else:
         query_string = f"?{urlencode(query)}"
-    path = '/'.join(seg) + query_string
+    path = "/".join(seg) + query_string
     adjusted_base = f"{base.rstrip('/')}/"
     return urljoin(str(adjusted_base), str(path))
 
 
 def xml_property(path, converter=lambda x: x.text, default=None):
     def getter(self):
         if hasattr(self, f"_{path}"):
@@ -106,15 +106,15 @@
         minx = node.find("minx")
         maxx = node.find("maxx")
         miny = node.find("miny")
         maxy = node.find("maxy")
         crs = node.find("crs")
         crs = crs.text if crs is not None else None
 
-        if (None not in [minx, maxx, miny, maxy]):
+        if None not in [minx, maxx, miny, maxy]:
             return (minx.text, maxx.text, miny.text, maxy.text, crs)
         else:
             return None
     else:
         return None
 
 
@@ -126,27 +126,30 @@
 def attribute_list(node):
     if node is not None:
         return [n.text for n in node.findall("attribute/name")]
 
 
 def key_value_pairs(node):
     if node is not None:
-        return dict((entry.attrib['key'], entry.text) for entry in node.findall("entry"))
+        return dict(
+            (entry.attrib["key"], entry.text) for entry in node.findall("entry")
+        )
 
 
 def read_string(node):
     return node.text
 
 
 def write_string(name):
     def write(builder, value):
         builder.start(name, dict())
         if value is not None and value:
             builder.data(value)
         builder.end(name)
+
     return write
 
 
 def read_bool(node):
     text = node.text
     if text:
         return text == "true"
@@ -155,14 +158,15 @@
 
 
 def write_bool(name):
     def write(builder, b):
         builder.start(name, dict())
         builder.data("true" if b and b != "false" else "false")
         builder.end(name)
+
     return write
 
 
 def read_int(node):
     text = node.text
     try:
         res = int(text)
@@ -172,14 +176,15 @@
 
 
 def write_int(name):
     def write(builder, b):
         builder.start(name, dict())
         builder.data(str(b))
         builder.end(name)
+
     return write
 
 
 def read_float(node):
     text = node.text
     try:
         res = float(text)
@@ -189,72 +194,76 @@
 
 
 def write_float(name):
     def write(builder, b):
         builder.start(name, dict())
         builder.data(str(b))
         builder.end(name)
+
     return write
 
 
 def write_bbox(name):
     def write(builder, b):
         builder.start(name, dict())
         bbox_xml(builder, b)
         builder.end(name)
+
     return write
 
 
 def write_string_list(name):
     def write(builder, words):
         builder.start(name, dict())
         if words:
             words = [w for w in words if len(w) > 0]
             for w in words:
                 builder.start("string", dict())
                 builder.data(w)
                 builder.end("string")
         builder.end(name)
+
     return write
 
 
 def write_dict(name):
     def write(builder, pairs):
         builder.start(name, dict())
         for k, v in pairs.items():
-            if k == 'port':
+            if k == "port":
                 v = str(v)
             builder.start("entry", dict(key=k))
             v = v if isinstance(v, string_types) else str(v)
             builder.data(v)
             builder.end("entry")
         builder.end(name)
+
     return write
 
 
 def write_metadata(name):
     def write(builder, metadata):
         builder.start(name, dict())
         for k, v in metadata.items():
             builder.start("entry", dict(key=k))
-            if k in ['time', 'elevation'] or k.startswith('custom_dimension'):
+            if k in ["time", "elevation"] or k.startswith("custom_dimension"):
                 dimension_info(builder, v)
-            elif k == 'DynamicDefaultValues':
+            elif k == "DynamicDefaultValues":
                 dynamic_default_values_info(builder, v)
-            elif k == 'JDBC_VIRTUAL_TABLE':
+            elif k == "JDBC_VIRTUAL_TABLE":
                 jdbc_virtual_table(builder, v)
             else:
                 builder.data(v)
             builder.end("entry")
         builder.end(name)
+
     return write
 
 
 class StaticResourceInfo(object):
-
     def __init__(self):
         self.write_all = True
         self.dom = None
         self.dirty = dict()
 
     def dirty_all(self):
         for key in self.writers.keys():
@@ -264,21 +273,23 @@
             else:
                 self.dirty[key] = attr
 
     def serialize(self, builder):
         # GeoServer will disable the resource if we omit the <enabled> tag,
         # so force it into the dirty dict before writing
         if hasattr(self, "enabled"):
-            self.dirty['enabled'] = self.enabled
+            self.dirty["enabled"] = self.enabled
 
         if hasattr(self, "advertised"):
-            self.dirty['advertised'] = self.advertised
+            self.dirty["advertised"] = self.advertised
 
         for k, writer in self.writers.items():
-            if hasattr(self, k) and issubclass(type(getattr(self, k)), StaticResourceInfo):
+            if hasattr(self, k) and issubclass(
+                type(getattr(self, k)), StaticResourceInfo
+            ):
                 attr = getattr(self, k)
                 if attr.dirty:
                     attr.serialize_all(builder)
             elif k in self.dirty:
                 val = self.dirty[k]
                 writer(builder, val)
             elif self.write_all:
@@ -297,22 +308,23 @@
         builder = TreeBuilder()
         self.serialize_all(builder)
         msg = tostring(builder.close())
         return msg
 
 
 class ResourceInfo(StaticResourceInfo):
-
     def __init__(self):
         self.write_all = False
         self.dom = None
         self.dirty = dict()
 
     def _clear_subclasses(self):
-        sbcs = [k for k, v in vars(self).items() if issubclass(type(v), StaticResourceInfo)]
+        sbcs = [
+            k for k, v in vars(self).items() if issubclass(type(v), StaticResourceInfo)
+        ]
         for sbc in sbcs:
             delattr(self, sbc)
 
     def fetch(self):
         self.dom = self.catalog.get_xml(self.href)
 
     def clear(self):
@@ -330,41 +342,44 @@
     the main data.  In such archives, GeoServer assumes that all of the relevant
     files will have the same base name and appropriate extensions, and live in
     the root of the ZIP archive.  This method produces a zip file that matches
     these expectations, based on a basename, and a dict of extensions to paths or
     file-like objects. The client code is responsible for deleting the zip
     archive when it's done."""
     fd, path = mkstemp()
-    zip_file = ZipFile(path, 'w', allowZip64=True)
+    zip_file = ZipFile(path, "w", allowZip64=True)
     for ext, stream in data.items():
         fname = f"{name}.{ext}"
-        if (isinstance(stream, string_types)):
+        if isinstance(stream, string_types):
             zip_file.write(stream, fname)
         else:
             zip_file.writestr(fname, stream.read())
     zip_file.close()
     os.close(fd)
     return path
 
 
 def atom_link(node):
-    if 'href' in node.attrib:
-        return node.attrib['href']
+    if "href" in node.attrib:
+        return node.attrib["href"]
     else:
         link = node.find("{http://www.w3.org/2005/Atom}link")
-        return link.get('href')
+        return link.get("href")
 
 
 def atom_link_xml(builder, href):
-    builder.start("atom:link", {
-        'rel': 'alternate',
-        'href': href,
-        'type': 'application/xml',
-        'xmlns:atom': 'http://www.w3.org/2005/Atom'
-    })
+    builder.start(
+        "atom:link",
+        {
+            "rel": "alternate",
+            "href": href,
+            "type": "application/xml",
+            "xmlns:atom": "http://www.w3.org/2005/Atom",
+        },
+    )
     builder.end("atom:link")
 
 
 def bbox_xml(builder, box):
     minx, maxx, miny, maxy, crs = box
     builder.start("minx", dict())
     builder.data(str(minx))
@@ -387,17 +402,19 @@
 def dimension_info(builder, metadata):
     if isinstance(metadata, DimensionInfo):
         builder.start("dimensionInfo", dict())
         builder.start("enabled", dict())
         builder.data("true" if metadata.enabled else "false")
         builder.end("enabled")
         if metadata.presentation is not None:
-            accepted = ['LIST', 'DISCRETE_INTERVAL', 'CONTINUOUS_INTERVAL']
+            accepted = ["LIST", "DISCRETE_INTERVAL", "CONTINUOUS_INTERVAL"]
             if metadata.presentation not in accepted:
-                raise ValueError(f"metadata.presentation must be one of the following {accepted}")
+                raise ValueError(
+                    f"metadata.presentation must be one of the following {accepted}"
+                )
             else:
                 builder.start("presentation", dict())
                 builder.data(metadata.presentation)
                 builder.end("presentation")
         if metadata.attribute is not None:
             builder.start("attribute", dict())
             builder.data(metadata.attribute)
@@ -433,27 +450,38 @@
             builder.data(metadata.nearestMatchEnabled)
             builder.end("nearestMatchEnabled")
 
         builder.end("dimensionInfo")
 
 
 class DimensionInfo(object):
-
     _lookup = (
-        ('seconds', 1),
-        ('minutes', 60),
-        ('hours', 3600),
-        ('days', 86400),
+        ("seconds", 1),
+        ("minutes", 60),
+        ("hours", 3600),
+        ("days", 86400),
         # this is the number geoserver computes for 1 month
-        ('months', 2628000000),
-        ('years', 31536000000)
+        ("months", 2628000000),
+        ("years", 31536000000),
     )
 
-    def __init__(self, name, enabled, presentation, resolution, units, unitSymbol,
-                 strategy=None, attribute=None, end_attribute=None, reference_value=None, nearestMatchEnabled=None):
+    def __init__(
+        self,
+        name,
+        enabled,
+        presentation,
+        resolution,
+        units,
+        unitSymbol,
+        strategy=None,
+        attribute=None,
+        end_attribute=None,
+        reference_value=None,
+        nearestMatchEnabled=None,
+    ):
         self.name = name
         self.enabled = enabled
         self.attribute = attribute
         self.end_attribute = end_attribute
         self.presentation = presentation
         self.resolution = resolution
         self.units = units
@@ -462,61 +490,62 @@
         self.referenceValue = reference_value
         self.nearestMatchEnabled = nearestMatchEnabled
 
     def _multipier(self, name):
         name = name.lower()
         found = [i[1] for i in self._lookup if i[0] == name]
         if not found:
-            raise ValueError(f'invalid multipler: {name}')
+            raise ValueError(f"invalid multipler: {name}")
         return found[0] if found else None
 
     def resolution_millis(self):
-        '''if set, get the value of resolution in milliseconds'''
+        """if set, get the value of resolution in milliseconds"""
         if self.resolution is None or not isinstance(self.resolution, string_types):
             return self.resolution
-        val, mult = self.resolution.split(' ')
+        val, mult = self.resolution.split(" ")
         return int(float(val) * self._multipier(mult) * 1000)
 
     def resolution_str(self):
         '''if set, get the value of resolution as "<n> <period>s", for example: "8 seconds"'''
         if self.resolution is None or isinstance(self.resolution, string_types):
             return self.resolution
-        seconds = self.resolution / 1000.
+        seconds = self.resolution / 1000.0
         biggest = self._lookup[0]
         for entry in self._lookup:
             if seconds < entry[1]:
                 break
             biggest = entry
         val = seconds / biggest[1]
         if val == int(val):
             val = int(val)
-        return f'{val} {biggest[0]}'
+        return f"{val} {biggest[0]}"
 
 
 def md_dimension_info(name, node):
     """Extract metadata Dimension Info from an xml node"""
+
     def _get_value(child_name):
-        return getattr(node.find(child_name), 'text', None)
+        return getattr(node.find(child_name), "text", None)
 
-    resolution = _get_value('resolution')
+    resolution = _get_value("resolution")
     defaultValue = node.find("defaultValue")
     strategy = defaultValue.find("strategy") if defaultValue is not None else None
     strategy = strategy.text if strategy is not None else None
     return DimensionInfo(
         name,
-        _get_value('enabled') == 'true',
-        _get_value('presentation'),
+        _get_value("enabled") == "true",
+        _get_value("presentation"),
         int(resolution) if resolution else None,
-        _get_value('units'),
-        _get_value('unitSymbol'),
+        _get_value("units"),
+        _get_value("unitSymbol"),
         strategy,
-        _get_value('attribute'),
-        _get_value('endAttribute'),
-        _get_value('referenceValue'),
-        _get_value('nearestMatchEnabled')
+        _get_value("attribute"),
+        _get_value("endAttribute"),
+        _get_value("referenceValue"),
+        _get_value("nearestMatchEnabled"),
     )
 
 
 def dynamic_default_values_info(builder, metadata):
     if isinstance(metadata, DynamicDefaultValues):
         builder.start("DynamicDefaultValues", dict())
 
@@ -561,17 +590,25 @@
         configurations = []
         for n in node.findall("configuration"):
             dimension = n.find("dimension")
             dimension = dimension.text if dimension is not None else None
             policy = n.find("policy")
             policy = policy.text if policy is not None else None
             defaultValueExpression = n.find("defaultValueExpression")
-            defaultValueExpression = defaultValueExpression.text if defaultValueExpression is not None else None
-
-            configurations.append(DynamicDefaultValuesConfiguration(dimension, policy, defaultValueExpression))
+            defaultValueExpression = (
+                defaultValueExpression.text
+                if defaultValueExpression is not None
+                else None
+            )
+
+            configurations.append(
+                DynamicDefaultValuesConfiguration(
+                    dimension, policy, defaultValueExpression
+                )
+            )
 
     return DynamicDefaultValues(name, configurations)
 
 
 class JDBCVirtualTableGeometry(object):
     def __init__(self, _name, _type, _srid):
         self.name = _name
@@ -583,15 +620,17 @@
     def __init__(self, _name, _defaultValue, _regexpValidator):
         self.name = _name
         self.defaultValue = _defaultValue
         self.regexpValidator = _regexpValidator
 
 
 class JDBCVirtualTable(object):
-    def __init__(self, _name, _sql, _escapeSql, _geometry, _keyColumn=None, _parameters=None):
+    def __init__(
+        self, _name, _sql, _escapeSql, _geometry, _keyColumn=None, _parameters=None
+    ):
         self.name = _name
         self.sql = _sql
         self.escapeSql = _escapeSql
         self.geometry = _geometry
         self.keyColumn = _keyColumn
         self.parameters = _parameters
 
@@ -661,41 +700,47 @@
     name = node.find("name")
     sql = node.find("sql")
     escapeSql = node.find("escapeSql")
     escapeSql = escapeSql.text if escapeSql is not None else None
     keyColumn = node.find("keyColumn")
     keyColumn = keyColumn.text if keyColumn is not None else None
     n_g = node.find("geometry")
-    geometry = JDBCVirtualTableGeometry(n_g.find("name"), n_g.find("type"), n_g.find("srid"))
+    geometry = JDBCVirtualTableGeometry(
+        n_g.find("name"), n_g.find("type"), n_g.find("srid")
+    )
     parameters = []
     for n_p in node.findall("parameter"):
         p_name = n_p.find("name")
         p_defaultValue = n_p.find("defaultValue")
         p_defaultValue = p_defaultValue.text if p_defaultValue is not None else None
         p_regexpValidator = n_p.find("regexpValidator")
-        p_regexpValidator = p_regexpValidator.text if p_regexpValidator is not None else None
-        parameters.append(JDBCVirtualTableParam(p_name, p_defaultValue, p_regexpValidator))
+        p_regexpValidator = (
+            p_regexpValidator.text if p_regexpValidator is not None else None
+        )
+        parameters.append(
+            JDBCVirtualTableParam(p_name, p_defaultValue, p_regexpValidator)
+        )
 
     return JDBCVirtualTable(name, sql, escapeSql, geometry, keyColumn, parameters)
 
 
 def md_entry(node):
     """Extract metadata entries from an xml node"""
     key = None
     value = None
-    if 'key' in node.attrib:
-        key = node.attrib['key']
+    if "key" in node.attrib:
+        key = node.attrib["key"]
     else:
         key = None
 
-    if key in ['time', 'elevation'] or key.startswith('custom_dimension'):
+    if key in ["time", "elevation"] or key.startswith("custom_dimension"):
         value = md_dimension_info(key, node.find("dimensionInfo"))
-    elif key == 'DynamicDefaultValues':
+    elif key == "DynamicDefaultValues":
         value = md_dynamic_default_values_info(key, node.find("DynamicDefaultValues"))
-    elif key == 'JDBC_VIRTUAL_TABLE':
+    elif key == "JDBC_VIRTUAL_TABLE":
         value = md_jdbc_virtual_table(key, node.find("virtualTable"))
     else:
         value = node.text
 
     if None in [key, value]:
         return None
     else:
@@ -733,22 +778,22 @@
             value = _decode_dict(value)
         rv[key] = value
     return rv
 
 
 def workspace_from_url(url):
     parts = urlparse(url)
-    split_path = parts.path.split('/')
-    if 'workspaces' in split_path:
-        return split_path[split_path.index('workspaces') + 1]
+    split_path = parts.path.split("/")
+    if "workspaces" in split_path:
+        return split_path[split_path.index("workspaces") + 1]
     else:
         return None
 
 
 def resource_from_url(url, workspace):
     parts = urlparse(url)
-    split_path = parts.path.split('/')
+    split_path = parts.path.split("/")
     if workspace in split_path:
         resource_type = split_path[split_path.index(workspace) + 1]
         return split_path[split_path.index(resource_type) + 1]
     else:
         return None
```

## geoserver/util.py

```diff
@@ -5,9 +5,10 @@
 # All rights reserved.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE.txt file in the root directory of this source tree.
 #
 #########################################################################
 
+
 def shapefile_and_friends(path):
-    return {ext: f"{path}.{ext}" for ext in ['shx', 'shp', 'dbf', 'prj']}
+    return {ext: f"{path}.{ext}" for ext in ["shx", "shp", "dbf", "prj"]}
```

## geoserver/workspace.py

```diff
@@ -35,40 +35,32 @@
 
     @property
     def name(self):
         return self._name
 
     @property
     def href(self):
-        return urljoin(
-            f"{self.catalog.service_url}/",
-            f"workspaces/{self.name}.xml"
-        )
+        return urljoin(f"{self.catalog.service_url}/", f"workspaces/{self.name}.xml")
 
     @property
     def coveragestore_url(self):
         return urljoin(
-            f"{self.catalog.service_url}/",
-            f"workspaces/{self.name}/coveragestores.xml"
+            f"{self.catalog.service_url}/", f"workspaces/{self.name}/coveragestores.xml"
         )
 
     @property
     def datastore_url(self):
         return urljoin(
-            f"{self.catalog.service_url}/",
-            f"workspaces/{self.name}/datastores.xml"
+            f"{self.catalog.service_url}/", f"workspaces/{self.name}/datastores.xml"
         )
 
     @property
     def wmsstore_url(self):
         return urljoin(
-            f"{self.catalog.service_url}/",
-            f"workspaces/{self.name}/wmsstores.xml"
+            f"{self.catalog.service_url}/", f"workspaces/{self.name}/wmsstores.xml"
         )
 
-    enabled = xml_property("enabled", lambda x: x.lower() == 'true')
-    writers = {
-        'enabled': write_bool("enabled")
-    }
+    enabled = xml_property("enabled", lambda x: x.lower() == "true")
+    writers = {"enabled": write_bool("enabled")}
 
     def __repr__(self):
         return f"{self.name} @ {self.href}"
```

## Comparing `geoserver_restconfig-2.0.8.dist-info/LICENSE.txt` & `geoserver_restconfig-2.0.9.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `geoserver_restconfig-2.0.8.dist-info/METADATA` & `geoserver_restconfig-2.0.9.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: geoserver-restconfig
-Version: 2.0.8
+Version: 2.0.9
 Summary: GeoServer REST Configuration
 Home-page: https://github.com/GeoNode/geoserver-restconfig
 Author: David Winslow, Sebastian Benthall, Alessio Fabiani
 Author-email: alessio.fabiani@gmail.com
 License: MIT
 Keywords: GeoServer REST Configuration
 Classifier: Development Status :: 5 - Production/Stable
```


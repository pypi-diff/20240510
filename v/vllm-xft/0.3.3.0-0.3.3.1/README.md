# Comparing `tmp/vllm_xft-0.3.3.0-py3-none-any.whl.zip` & `tmp/vllm_xft-0.3.3.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,159 +1,159 @@
-Zip file size: 318761 bytes, number of entries: 157
+Zip file size: 318993 bytes, number of entries: 157
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 02:36 tests/core/__init__.py
--rw-rw-r--  2.0 unx    13573 b- defN 24-Mar-18 02:36 tests/core/test_block_manager.py
--rw-rw-r--  2.0 unx     6456 b- defN 24-Mar-18 02:36 tests/core/test_scheduler.py
--rw-rw-r--  2.0 unx      880 b- defN 24-Mar-18 02:36 tests/core/utils.py
+-rw-rw-r--  2.0 unx    13573 b- defN 24-May-10 02:00 tests/core/test_block_manager.py
+-rw-rw-r--  2.0 unx     6456 b- defN 24-May-10 02:00 tests/core/test_scheduler.py
+-rw-rw-r--  2.0 unx      880 b- defN 24-May-10 02:00 tests/core/utils.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 02:36 tests/lora/__init__.py
--rw-rw-r--  2.0 unx     4654 b- defN 24-Mar-18 02:36 tests/lora/conftest.py
+-rw-rw-r--  2.0 unx     4654 b- defN 24-May-10 02:00 tests/lora/conftest.py
 -rw-rw-r--  2.0 unx     1549 b- defN 24-Mar-18 02:36 tests/lora/test_gemma.py
--rw-rw-r--  2.0 unx     6391 b- defN 24-Mar-18 02:36 tests/lora/test_layer_variation.py
--rw-rw-r--  2.0 unx    26918 b- defN 24-Mar-18 02:36 tests/lora/test_layers.py
--rw-rw-r--  2.0 unx    10193 b- defN 24-Mar-18 02:36 tests/lora/test_llama.py
+-rw-rw-r--  2.0 unx     6391 b- defN 24-May-10 02:00 tests/lora/test_layer_variation.py
+-rw-rw-r--  2.0 unx    26918 b- defN 24-May-10 02:00 tests/lora/test_layers.py
+-rw-rw-r--  2.0 unx    10193 b- defN 24-May-10 02:00 tests/lora/test_llama.py
 -rw-rw-r--  2.0 unx     8094 b- defN 24-Mar-18 02:36 tests/lora/test_lora.py
--rw-rw-r--  2.0 unx    19701 b- defN 24-Mar-18 02:36 tests/lora/test_lora_manager.py
+-rw-rw-r--  2.0 unx    19701 b- defN 24-May-10 02:00 tests/lora/test_lora_manager.py
 -rw-rw-r--  2.0 unx     4656 b- defN 24-Mar-18 02:36 tests/lora/test_mixtral.py
--rw-rw-r--  2.0 unx     5976 b- defN 24-Mar-18 02:36 tests/lora/test_punica.py
--rw-rw-r--  2.0 unx     2809 b- defN 24-Mar-21 02:26 tests/lora/test_tokenizer.py
--rw-rw-r--  2.0 unx     4327 b- defN 24-Mar-18 02:36 tests/lora/test_utils.py
--rw-rw-r--  2.0 unx     2185 b- defN 24-Mar-18 02:36 tests/lora/test_worker.py
+-rw-rw-r--  2.0 unx     5976 b- defN 24-May-10 02:00 tests/lora/test_punica.py
+-rw-rw-r--  2.0 unx     2809 b- defN 24-May-10 02:00 tests/lora/test_tokenizer.py
+-rw-rw-r--  2.0 unx     4327 b- defN 24-May-10 02:00 tests/lora/test_utils.py
+-rw-rw-r--  2.0 unx     2185 b- defN 24-May-10 02:00 tests/lora/test_worker.py
 -rw-rw-r--  2.0 unx     2846 b- defN 24-Mar-18 02:36 tests/lora/utils.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 02:36 tests/spec_decode/__init__.py
--rw-rw-r--  2.0 unx     3047 b- defN 24-Mar-18 02:36 tests/spec_decode/test_batch_expansion.py
--rw-rw-r--  2.0 unx     6093 b- defN 24-Mar-18 02:36 tests/spec_decode/test_metrics.py
--rw-rw-r--  2.0 unx    13962 b- defN 24-Mar-18 02:36 tests/spec_decode/test_multi_step_worker.py
--rw-rw-r--  2.0 unx    24611 b- defN 24-Mar-18 02:36 tests/spec_decode/test_spec_decode_worker.py
--rw-rw-r--  2.0 unx     3112 b- defN 24-Mar-18 02:36 tests/spec_decode/test_utils.py
--rw-rw-r--  2.0 unx     8368 b- defN 24-Mar-18 02:36 tests/spec_decode/utils.py
+-rw-rw-r--  2.0 unx     3047 b- defN 24-May-10 02:00 tests/spec_decode/test_batch_expansion.py
+-rw-rw-r--  2.0 unx     6093 b- defN 24-May-10 02:00 tests/spec_decode/test_metrics.py
+-rw-rw-r--  2.0 unx    13962 b- defN 24-May-10 02:00 tests/spec_decode/test_multi_step_worker.py
+-rw-rw-r--  2.0 unx    24611 b- defN 24-May-10 02:00 tests/spec_decode/test_spec_decode_worker.py
+-rw-rw-r--  2.0 unx     3112 b- defN 24-May-10 02:00 tests/spec_decode/test_utils.py
+-rw-rw-r--  2.0 unx     8368 b- defN 24-May-10 02:00 tests/spec_decode/utils.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 02:36 tests/worker/__init__.py
--rw-rw-r--  2.0 unx     2098 b- defN 24-Mar-18 02:36 tests/worker/test_model_runner.py
--rw-rw-r--  2.0 unx      611 b- defN 24-Mar-29 05:02 vllm/__init__.py
+-rw-rw-r--  2.0 unx     2098 b- defN 24-May-10 02:00 tests/worker/test_model_runner.py
+-rw-rw-r--  2.0 unx      611 b- defN 24-May-10 05:56 vllm/__init__.py
 -rw-rw-r--  2.0 unx     2374 b- defN 24-Mar-18 05:42 vllm/block.py
--rw-rw-r--  2.0 unx    17378 b- defN 24-Mar-21 02:26 vllm/config.py
--rw-rw-r--  2.0 unx     1962 b- defN 24-Mar-18 05:42 vllm/logger.py
--rw-rw-r--  2.0 unx     5411 b- defN 24-Mar-21 02:26 vllm/outputs.py
+-rw-rw-r--  2.0 unx    17378 b- defN 24-May-10 02:00 vllm/config.py
+-rw-rw-r--  2.0 unx     1962 b- defN 24-May-10 02:00 vllm/logger.py
+-rw-rw-r--  2.0 unx     5411 b- defN 24-May-10 02:00 vllm/outputs.py
 -rw-rw-r--  2.0 unx       65 b- defN 24-Mar-18 01:59 vllm/py.typed
--rw-rw-r--  2.0 unx    13175 b- defN 24-Mar-21 02:26 vllm/sampling_params.py
--rw-rw-r--  2.0 unx    19536 b- defN 24-Mar-21 02:26 vllm/sequence.py
--rw-rw-r--  2.0 unx     1199 b- defN 24-Mar-18 02:36 vllm/test_utils.py
--rw-rw-r--  2.0 unx    10325 b- defN 24-Mar-21 02:26 vllm/utils.py
+-rw-rw-r--  2.0 unx    13175 b- defN 24-May-10 02:00 vllm/sampling_params.py
+-rw-rw-r--  2.0 unx    19536 b- defN 24-May-10 02:00 vllm/sequence.py
+-rw-rw-r--  2.0 unx     1199 b- defN 24-May-10 02:00 vllm/test_utils.py
+-rw-rw-r--  2.0 unx    10325 b- defN 24-May-10 02:00 vllm/utils.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 05:42 vllm/core/__init__.py
--rw-rw-r--  2.0 unx    20253 b- defN 24-Mar-18 05:42 vllm/core/block_manager.py
--rw-rw-r--  2.0 unx     5426 b- defN 24-Mar-18 05:42 vllm/core/evictor.py
--rw-rw-r--  2.0 unx      973 b- defN 24-Mar-18 05:42 vllm/core/policy.py
--rw-rw-r--  2.0 unx    21672 b- defN 24-Mar-21 02:26 vllm/core/scheduler.py
+-rw-rw-r--  2.0 unx    20253 b- defN 24-May-10 02:00 vllm/core/block_manager.py
+-rw-rw-r--  2.0 unx     5426 b- defN 24-May-10 02:00 vllm/core/evictor.py
+-rw-rw-r--  2.0 unx      973 b- defN 24-May-10 02:00 vllm/core/policy.py
+-rw-rw-r--  2.0 unx    21672 b- defN 24-May-10 02:00 vllm/core/scheduler.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 05:42 vllm/engine/__init__.py
--rw-rw-r--  2.0 unx    16962 b- defN 24-Mar-21 02:26 vllm/engine/arg_utils.py
--rw-rw-r--  2.0 unx    24902 b- defN 24-Mar-21 02:26 vllm/engine/async_llm_engine.py
--rw-rw-r--  2.0 unx    35602 b- defN 24-Mar-21 02:26 vllm/engine/llm_engine.py
--rw-rw-r--  2.0 unx     9480 b- defN 24-Mar-18 05:42 vllm/engine/metrics.py
--rw-rw-r--  2.0 unx     5005 b- defN 24-Mar-21 02:26 vllm/engine/ray_utils.py
+-rw-rw-r--  2.0 unx    16962 b- defN 24-May-10 02:00 vllm/engine/arg_utils.py
+-rw-rw-r--  2.0 unx    24902 b- defN 24-May-10 02:00 vllm/engine/async_llm_engine.py
+-rw-rw-r--  2.0 unx    36241 b- defN 24-May-10 05:56 vllm/engine/llm_engine.py
+-rw-rw-r--  2.0 unx     9480 b- defN 24-May-10 02:00 vllm/engine/metrics.py
+-rw-rw-r--  2.0 unx     5005 b- defN 24-May-10 02:00 vllm/engine/ray_utils.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 05:42 vllm/entrypoints/__init__.py
--rw-rw-r--  2.0 unx     3560 b- defN 24-Mar-21 02:26 vllm/entrypoints/api_server.py
--rw-rw-r--  2.0 unx     9649 b- defN 24-Mar-21 02:26 vllm/entrypoints/llm.py
+-rw-rw-r--  2.0 unx     3560 b- defN 24-May-10 02:00 vllm/entrypoints/api_server.py
+-rw-rw-r--  2.0 unx     9649 b- defN 24-May-10 02:00 vllm/entrypoints/llm.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 05:42 vllm/entrypoints/openai/__init__.py
--rw-rw-r--  2.0 unx     9768 b- defN 24-Mar-21 02:26 vllm/entrypoints/openai/api_server.py
--rw-rw-r--  2.0 unx    11648 b- defN 24-Mar-21 02:26 vllm/entrypoints/openai/protocol.py
--rw-rw-r--  2.0 unx    14685 b- defN 24-Mar-21 02:26 vllm/entrypoints/openai/serving_chat.py
--rw-rw-r--  2.0 unx    15802 b- defN 24-Mar-21 02:26 vllm/entrypoints/openai/serving_completion.py
--rw-rw-r--  2.0 unx     6918 b- defN 24-Mar-21 02:26 vllm/entrypoints/openai/serving_engine.py
+-rw-rw-r--  2.0 unx     9768 b- defN 24-May-10 02:00 vllm/entrypoints/openai/api_server.py
+-rw-rw-r--  2.0 unx    11648 b- defN 24-May-10 02:00 vllm/entrypoints/openai/protocol.py
+-rw-rw-r--  2.0 unx    14777 b- defN 24-May-10 05:56 vllm/entrypoints/openai/serving_chat.py
+-rw-rw-r--  2.0 unx    15891 b- defN 24-May-10 05:56 vllm/entrypoints/openai/serving_completion.py
+-rw-rw-r--  2.0 unx     6918 b- defN 24-May-10 02:00 vllm/entrypoints/openai/serving_engine.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 05:42 vllm/executor/__init__.py
--rw-rw-r--  2.0 unx     5579 b- defN 24-Mar-21 02:26 vllm/executor/cpu_executor.py
--rw-rw-r--  2.0 unx     2385 b- defN 24-Mar-21 02:26 vllm/executor/executor_base.py
--rw-rw-r--  2.0 unx     6143 b- defN 24-Mar-18 02:36 vllm/executor/gpu_executor.py
--rw-rw-r--  2.0 unx    17242 b- defN 24-Mar-18 02:36 vllm/executor/ray_gpu_executor.py
--rw-rw-r--  2.0 unx      722 b- defN 24-Mar-18 02:36 vllm/executor/utils.py
+-rw-rw-r--  2.0 unx     5579 b- defN 24-May-10 02:00 vllm/executor/cpu_executor.py
+-rw-rw-r--  2.0 unx     2385 b- defN 24-May-10 02:00 vllm/executor/executor_base.py
+-rw-rw-r--  2.0 unx     6143 b- defN 24-May-10 02:00 vllm/executor/gpu_executor.py
+-rw-rw-r--  2.0 unx    17242 b- defN 24-May-10 02:00 vllm/executor/ray_gpu_executor.py
+-rw-rw-r--  2.0 unx      722 b- defN 24-May-10 02:00 vllm/executor/utils.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 02:36 vllm/lora/__init__.py
--rw-rw-r--  2.0 unx    35232 b- defN 24-Mar-18 02:36 vllm/lora/layers.py
--rw-rw-r--  2.0 unx     4849 b- defN 24-Mar-18 02:36 vllm/lora/lora.py
--rw-rw-r--  2.0 unx    25763 b- defN 24-Mar-18 02:36 vllm/lora/models.py
--rw-rw-r--  2.0 unx     5299 b- defN 24-Mar-18 02:36 vllm/lora/punica.py
+-rw-rw-r--  2.0 unx    35232 b- defN 24-May-10 02:00 vllm/lora/layers.py
+-rw-rw-r--  2.0 unx     4849 b- defN 24-May-10 02:00 vllm/lora/lora.py
+-rw-rw-r--  2.0 unx    25763 b- defN 24-May-10 02:00 vllm/lora/models.py
+-rw-rw-r--  2.0 unx     5299 b- defN 24-May-10 02:00 vllm/lora/punica.py
 -rw-rw-r--  2.0 unx      910 b- defN 24-Mar-18 02:36 vllm/lora/request.py
--rw-rw-r--  2.0 unx     1310 b- defN 24-Mar-18 02:36 vllm/lora/utils.py
--rw-rw-r--  2.0 unx     8743 b- defN 24-Mar-18 02:36 vllm/lora/worker_manager.py
--rw-rw-r--  2.0 unx      211 b- defN 24-Mar-21 02:26 vllm/model_executor/__init__.py
--rw-rw-r--  2.0 unx     3614 b- defN 24-Mar-21 02:26 vllm/model_executor/guided_decoding.py
--rw-rw-r--  2.0 unx     4669 b- defN 24-Mar-21 02:26 vllm/model_executor/guided_logits_processors.py
--rw-rw-r--  2.0 unx     1929 b- defN 24-Mar-21 02:26 vllm/model_executor/input_metadata.py
--rw-rw-r--  2.0 unx     2353 b- defN 24-Mar-21 02:26 vllm/model_executor/model_loader.py
--rw-rw-r--  2.0 unx     2257 b- defN 24-Mar-18 02:36 vllm/model_executor/neuron_model_loader.py
--rw-rw-r--  2.0 unx     9902 b- defN 24-Mar-18 05:42 vllm/model_executor/sampling_metadata.py
--rw-rw-r--  2.0 unx      755 b- defN 24-Mar-21 02:26 vllm/model_executor/utils.py
--rw-rw-r--  2.0 unx    11400 b- defN 24-Mar-21 02:26 vllm/model_executor/weight_utils.py
+-rw-rw-r--  2.0 unx     1310 b- defN 24-May-10 02:00 vllm/lora/utils.py
+-rw-rw-r--  2.0 unx     8743 b- defN 24-May-10 02:00 vllm/lora/worker_manager.py
+-rw-rw-r--  2.0 unx      211 b- defN 24-May-10 02:00 vllm/model_executor/__init__.py
+-rw-rw-r--  2.0 unx     3614 b- defN 24-May-10 02:00 vllm/model_executor/guided_decoding.py
+-rw-rw-r--  2.0 unx     4669 b- defN 24-May-10 02:00 vllm/model_executor/guided_logits_processors.py
+-rw-rw-r--  2.0 unx     1929 b- defN 24-May-10 02:00 vllm/model_executor/input_metadata.py
+-rw-rw-r--  2.0 unx     2353 b- defN 24-May-10 02:00 vllm/model_executor/model_loader.py
+-rw-rw-r--  2.0 unx     2257 b- defN 24-May-10 02:00 vllm/model_executor/neuron_model_loader.py
+-rw-rw-r--  2.0 unx     9902 b- defN 24-May-10 02:00 vllm/model_executor/sampling_metadata.py
+-rw-rw-r--  2.0 unx      755 b- defN 24-May-10 02:00 vllm/model_executor/utils.py
+-rw-rw-r--  2.0 unx    11400 b- defN 24-May-10 02:00 vllm/model_executor/weight_utils.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-14 03:19 vllm/model_executor/layers/__init__.py
--rw-rw-r--  2.0 unx     6004 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/activation.py
--rw-rw-r--  2.0 unx     1823 b- defN 24-Mar-18 01:59 vllm/model_executor/layers/layernorm.py
--rw-rw-r--  2.0 unx    25089 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/linear.py
--rw-rw-r--  2.0 unx    16136 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/rejection_sampler.py
--rw-rw-r--  2.0 unx    15339 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/rotary_embedding.py
--rw-rw-r--  2.0 unx    25317 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/sampler.py
--rw-rw-r--  2.0 unx     6060 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/vocab_parallel_embedding.py
--rw-rw-r--  2.0 unx      101 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/attention/__init__.py
--rw-rw-r--  2.0 unx     2861 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/attention/attention.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/attention/backends/__init__.py
--rw-rw-r--  2.0 unx     4739 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/attention/backends/flash_attn.py
--rw-rw-r--  2.0 unx    10337 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/attention/backends/xformers.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/attention/ops/__init__.py
--rw-rw-r--  2.0 unx     4481 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/attention/ops/paged_attn.py
--rw-rw-r--  2.0 unx    26013 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/attention/ops/prefix_prefill.py
--rw-rw-r--  2.0 unx      101 b- defN 24-Mar-21 02:26 vllm/model_executor/layers/fused_moe/__init__.py
--rw-rw-r--  2.0 unx    16598 b- defN 24-Mar-21 02:26 vllm/model_executor/layers/fused_moe/fused_moe.py
--rw-rw-r--  2.0 unx     2278 b- defN 24-Mar-21 02:26 vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json
--rw-rw-r--  2.0 unx     2794 b- defN 24-Mar-21 02:26 vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json
--rw-rw-r--  2.0 unx      885 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/quantization/__init__.py
--rw-rw-r--  2.0 unx     5742 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/quantization/awq.py
--rw-rw-r--  2.0 unx     2057 b- defN 24-Mar-18 01:59 vllm/model_executor/layers/quantization/base_config.py
--rw-rw-r--  2.0 unx     7462 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/quantization/gptq.py
--rw-rw-r--  2.0 unx     7181 b- defN 24-Mar-21 02:26 vllm/model_executor/layers/quantization/marlin.py
--rw-rw-r--  2.0 unx     4233 b- defN 24-Mar-18 02:36 vllm/model_executor/layers/quantization/squeezellm.py
--rw-rw-r--  2.0 unx     4295 b- defN 24-Mar-18 02:36 vllm/model_executor/models/__init__.py
--rw-rw-r--  2.0 unx    15080 b- defN 24-Mar-18 02:36 vllm/model_executor/models/baichuan.py
--rw-rw-r--  2.0 unx    12008 b- defN 24-Mar-18 02:36 vllm/model_executor/models/bloom.py
--rw-rw-r--  2.0 unx    12976 b- defN 24-Mar-18 02:36 vllm/model_executor/models/chatglm.py
--rw-rw-r--  2.0 unx     5552 b- defN 24-Mar-18 02:36 vllm/model_executor/models/decilm.py
--rw-rw-r--  2.0 unx    17689 b- defN 24-Mar-18 02:36 vllm/model_executor/models/deepseek.py
--rw-rw-r--  2.0 unx    17791 b- defN 24-Mar-18 02:36 vllm/model_executor/models/falcon.py
--rw-rw-r--  2.0 unx    12781 b- defN 24-Mar-18 02:36 vllm/model_executor/models/gemma.py
--rw-rw-r--  2.0 unx    10018 b- defN 24-Mar-18 02:36 vllm/model_executor/models/gpt2.py
--rw-rw-r--  2.0 unx     9983 b- defN 24-Mar-18 02:36 vllm/model_executor/models/gpt_bigcode.py
--rw-rw-r--  2.0 unx    10298 b- defN 24-Mar-18 02:36 vllm/model_executor/models/gpt_j.py
--rw-rw-r--  2.0 unx    11018 b- defN 24-Mar-18 02:36 vllm/model_executor/models/gpt_neox.py
--rw-rw-r--  2.0 unx    12467 b- defN 24-Mar-18 02:36 vllm/model_executor/models/internlm2.py
--rw-rw-r--  2.0 unx    14881 b- defN 24-Mar-18 02:36 vllm/model_executor/models/llama.py
--rw-rw-r--  2.0 unx    17792 b- defN 24-Mar-18 02:36 vllm/model_executor/models/mixtral.py
--rw-rw-r--  2.0 unx    16203 b- defN 24-Mar-18 02:36 vllm/model_executor/models/mixtral_quant.py
--rw-rw-r--  2.0 unx    10762 b- defN 24-Mar-18 02:36 vllm/model_executor/models/mpt.py
--rw-rw-r--  2.0 unx    13181 b- defN 24-Mar-18 02:36 vllm/model_executor/models/olmo.py
--rw-rw-r--  2.0 unx    13426 b- defN 24-Mar-18 02:36 vllm/model_executor/models/opt.py
--rw-rw-r--  2.0 unx    12087 b- defN 24-Mar-18 02:36 vllm/model_executor/models/orion.py
--rw-rw-r--  2.0 unx    11591 b- defN 24-Mar-18 02:36 vllm/model_executor/models/phi.py
--rw-rw-r--  2.0 unx    10325 b- defN 24-Mar-18 02:36 vllm/model_executor/models/qwen.py
--rw-rw-r--  2.0 unx    13535 b- defN 24-Mar-21 02:26 vllm/model_executor/models/qwen2.py
--rw-rw-r--  2.0 unx    12491 b- defN 24-Mar-18 02:36 vllm/model_executor/models/stablelm.py
--rw-rw-r--  2.0 unx    12233 b- defN 24-Mar-18 02:36 vllm/model_executor/models/starcoder2.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Mar-14 03:19 vllm/model_executor/parallel_utils/__init__.py
--rw-rw-r--  2.0 unx     8095 b- defN 24-Mar-21 02:26 vllm/model_executor/parallel_utils/communication_op.py
--rw-rw-r--  2.0 unx     3985 b- defN 24-Mar-18 02:36 vllm/model_executor/parallel_utils/cupy_utils.py
--rw-rw-r--  2.0 unx     7967 b- defN 24-Mar-18 02:36 vllm/model_executor/parallel_utils/custom_all_reduce.py
--rw-rw-r--  2.0 unx     9741 b- defN 24-Mar-18 02:36 vllm/model_executor/parallel_utils/parallel_state.py
--rw-rw-r--  2.0 unx     1601 b- defN 24-Mar-18 01:59 vllm/model_executor/parallel_utils/utils.py
+-rw-rw-r--  2.0 unx     6004 b- defN 24-May-10 02:00 vllm/model_executor/layers/activation.py
+-rw-rw-r--  2.0 unx     1823 b- defN 24-May-10 02:00 vllm/model_executor/layers/layernorm.py
+-rw-rw-r--  2.0 unx    25089 b- defN 24-May-10 02:00 vllm/model_executor/layers/linear.py
+-rw-rw-r--  2.0 unx    16136 b- defN 24-May-10 02:00 vllm/model_executor/layers/rejection_sampler.py
+-rw-rw-r--  2.0 unx    15339 b- defN 24-May-10 02:00 vllm/model_executor/layers/rotary_embedding.py
+-rw-rw-r--  2.0 unx    25317 b- defN 24-May-10 02:00 vllm/model_executor/layers/sampler.py
+-rw-rw-r--  2.0 unx     6060 b- defN 24-May-10 02:00 vllm/model_executor/layers/vocab_parallel_embedding.py
+-rw-rw-r--  2.0 unx      101 b- defN 24-May-10 02:00 vllm/model_executor/layers/attention/__init__.py
+-rw-rw-r--  2.0 unx     2861 b- defN 24-May-10 02:00 vllm/model_executor/layers/attention/attention.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-May-10 02:00 vllm/model_executor/layers/attention/backends/__init__.py
+-rw-rw-r--  2.0 unx     4739 b- defN 24-May-10 02:00 vllm/model_executor/layers/attention/backends/flash_attn.py
+-rw-rw-r--  2.0 unx    10337 b- defN 24-May-10 02:00 vllm/model_executor/layers/attention/backends/xformers.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-May-10 02:00 vllm/model_executor/layers/attention/ops/__init__.py
+-rw-rw-r--  2.0 unx     4481 b- defN 24-May-10 02:00 vllm/model_executor/layers/attention/ops/paged_attn.py
+-rw-rw-r--  2.0 unx    26013 b- defN 24-May-10 02:00 vllm/model_executor/layers/attention/ops/prefix_prefill.py
+-rw-rw-r--  2.0 unx      101 b- defN 24-May-10 02:00 vllm/model_executor/layers/fused_moe/__init__.py
+-rw-rw-r--  2.0 unx    16598 b- defN 24-May-10 02:00 vllm/model_executor/layers/fused_moe/fused_moe.py
+-rw-rw-r--  2.0 unx     2278 b- defN 24-May-10 02:00 vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json
+-rw-rw-r--  2.0 unx     2794 b- defN 24-May-10 02:00 vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json
+-rw-rw-r--  2.0 unx      885 b- defN 24-May-10 02:00 vllm/model_executor/layers/quantization/__init__.py
+-rw-rw-r--  2.0 unx     5742 b- defN 24-May-10 02:00 vllm/model_executor/layers/quantization/awq.py
+-rw-rw-r--  2.0 unx     2057 b- defN 24-May-10 02:00 vllm/model_executor/layers/quantization/base_config.py
+-rw-rw-r--  2.0 unx     7462 b- defN 24-May-10 02:00 vllm/model_executor/layers/quantization/gptq.py
+-rw-rw-r--  2.0 unx     7181 b- defN 24-May-10 02:00 vllm/model_executor/layers/quantization/marlin.py
+-rw-rw-r--  2.0 unx     4233 b- defN 24-May-10 02:00 vllm/model_executor/layers/quantization/squeezellm.py
+-rw-rw-r--  2.0 unx     4295 b- defN 24-May-10 02:00 vllm/model_executor/models/__init__.py
+-rw-rw-r--  2.0 unx    15080 b- defN 24-May-10 02:00 vllm/model_executor/models/baichuan.py
+-rw-rw-r--  2.0 unx    12008 b- defN 24-May-10 02:00 vllm/model_executor/models/bloom.py
+-rw-rw-r--  2.0 unx    12976 b- defN 24-May-10 02:00 vllm/model_executor/models/chatglm.py
+-rw-rw-r--  2.0 unx     5552 b- defN 24-May-10 02:00 vllm/model_executor/models/decilm.py
+-rw-rw-r--  2.0 unx    17689 b- defN 24-May-10 02:00 vllm/model_executor/models/deepseek.py
+-rw-rw-r--  2.0 unx    17791 b- defN 24-May-10 02:00 vllm/model_executor/models/falcon.py
+-rw-rw-r--  2.0 unx    12781 b- defN 24-May-10 02:00 vllm/model_executor/models/gemma.py
+-rw-rw-r--  2.0 unx    10018 b- defN 24-May-10 02:00 vllm/model_executor/models/gpt2.py
+-rw-rw-r--  2.0 unx     9983 b- defN 24-May-10 02:00 vllm/model_executor/models/gpt_bigcode.py
+-rw-rw-r--  2.0 unx    10298 b- defN 24-May-10 02:00 vllm/model_executor/models/gpt_j.py
+-rw-rw-r--  2.0 unx    11018 b- defN 24-May-10 02:00 vllm/model_executor/models/gpt_neox.py
+-rw-rw-r--  2.0 unx    12467 b- defN 24-May-10 02:00 vllm/model_executor/models/internlm2.py
+-rw-rw-r--  2.0 unx    14881 b- defN 24-May-10 02:00 vllm/model_executor/models/llama.py
+-rw-rw-r--  2.0 unx    17792 b- defN 24-May-10 02:00 vllm/model_executor/models/mixtral.py
+-rw-rw-r--  2.0 unx    16203 b- defN 24-May-10 02:00 vllm/model_executor/models/mixtral_quant.py
+-rw-rw-r--  2.0 unx    10762 b- defN 24-May-10 02:00 vllm/model_executor/models/mpt.py
+-rw-rw-r--  2.0 unx    13181 b- defN 24-May-10 02:00 vllm/model_executor/models/olmo.py
+-rw-rw-r--  2.0 unx    13426 b- defN 24-May-10 02:00 vllm/model_executor/models/opt.py
+-rw-rw-r--  2.0 unx    12087 b- defN 24-May-10 02:00 vllm/model_executor/models/orion.py
+-rw-rw-r--  2.0 unx    11591 b- defN 24-May-10 02:00 vllm/model_executor/models/phi.py
+-rw-rw-r--  2.0 unx    10325 b- defN 24-May-10 02:00 vllm/model_executor/models/qwen.py
+-rw-rw-r--  2.0 unx    13535 b- defN 24-May-10 02:00 vllm/model_executor/models/qwen2.py
+-rw-rw-r--  2.0 unx    12491 b- defN 24-May-10 02:00 vllm/model_executor/models/stablelm.py
+-rw-rw-r--  2.0 unx    12233 b- defN 24-May-10 02:00 vllm/model_executor/models/starcoder2.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-May-10 02:00 vllm/model_executor/parallel_utils/__init__.py
+-rw-rw-r--  2.0 unx     8095 b- defN 24-May-10 02:00 vllm/model_executor/parallel_utils/communication_op.py
+-rw-rw-r--  2.0 unx     3985 b- defN 24-May-10 02:00 vllm/model_executor/parallel_utils/cupy_utils.py
+-rw-rw-r--  2.0 unx     7967 b- defN 24-May-10 02:00 vllm/model_executor/parallel_utils/custom_all_reduce.py
+-rw-rw-r--  2.0 unx     9741 b- defN 24-May-10 02:00 vllm/model_executor/parallel_utils/parallel_state.py
+-rw-rw-r--  2.0 unx     1601 b- defN 24-May-10 02:00 vllm/model_executor/parallel_utils/utils.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 05:42 vllm/transformers_utils/__init__.py
--rw-rw-r--  2.0 unx     2080 b- defN 24-Mar-18 05:42 vllm/transformers_utils/config.py
--rw-rw-r--  2.0 unx     8485 b- defN 24-Mar-21 02:26 vllm/transformers_utils/tokenizer.py
--rw-rw-r--  2.0 unx      559 b- defN 24-Mar-18 05:42 vllm/transformers_utils/configs/__init__.py
+-rw-rw-r--  2.0 unx     2080 b- defN 24-May-10 02:00 vllm/transformers_utils/config.py
+-rw-rw-r--  2.0 unx     8485 b- defN 24-May-10 02:00 vllm/transformers_utils/tokenizer.py
+-rw-rw-r--  2.0 unx      559 b- defN 24-May-10 02:00 vllm/transformers_utils/configs/__init__.py
 -rw-rw-r--  2.0 unx     2747 b- defN 24-Mar-18 05:42 vllm/transformers_utils/configs/chatglm.py
 -rw-rw-r--  2.0 unx     2878 b- defN 24-Mar-18 05:42 vllm/transformers_utils/configs/falcon.py
--rw-rw-r--  2.0 unx     7561 b- defN 24-Mar-18 05:42 vllm/transformers_utils/configs/mpt.py
--rw-rw-r--  2.0 unx     1815 b- defN 24-Mar-18 05:42 vllm/transformers_utils/configs/starcoder2.py
+-rw-rw-r--  2.0 unx     7561 b- defN 24-May-10 02:00 vllm/transformers_utils/configs/mpt.py
+-rw-rw-r--  2.0 unx     1815 b- defN 24-May-10 02:00 vllm/transformers_utils/configs/starcoder2.py
 -rw-rw-r--  2.0 unx      114 b- defN 24-Mar-18 05:42 vllm/transformers_utils/tokenizers/__init__.py
--rw-rw-r--  2.0 unx     9347 b- defN 24-Mar-18 05:42 vllm/transformers_utils/tokenizers/baichuan.py
+-rw-rw-r--  2.0 unx     9347 b- defN 24-May-10 02:00 vllm/transformers_utils/tokenizers/baichuan.py
 -rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 05:42 vllm/worker/__init__.py
--rw-rw-r--  2.0 unx     6549 b- defN 24-Mar-18 02:36 vllm/worker/cache_engine.py
--rw-rw-r--  2.0 unx     7738 b- defN 24-Mar-21 02:26 vllm/worker/model_runner.py
--rw-rw-r--  2.0 unx     7566 b- defN 24-Mar-18 02:36 vllm/worker/neuron_worker.py
--rw-rw-r--  2.0 unx     5568 b- defN 24-Mar-21 02:26 vllm/worker/worker.py
--rw-rw-r--  2.0 unx    11357 b- defN 24-Mar-29 05:02 vllm_xft-0.3.3.0.dist-info/LICENSE
--rw-rw-r--  2.0 unx     8228 b- defN 24-Mar-29 05:02 vllm_xft-0.3.3.0.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 24-Mar-29 05:02 vllm_xft-0.3.3.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx       11 b- defN 24-Mar-29 05:02 vllm_xft-0.3.3.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    14297 b- defN 24-Mar-29 05:02 vllm_xft-0.3.3.0.dist-info/RECORD
-157 files, 1250582 bytes uncompressed, 295983 bytes compressed:  76.3%
+-rw-rw-r--  2.0 unx     6549 b- defN 24-May-10 02:00 vllm/worker/cache_engine.py
+-rw-rw-r--  2.0 unx     7738 b- defN 24-May-10 02:00 vllm/worker/model_runner.py
+-rw-rw-r--  2.0 unx     7566 b- defN 24-May-10 02:00 vllm/worker/neuron_worker.py
+-rw-rw-r--  2.0 unx     5568 b- defN 24-May-10 02:00 vllm/worker/worker.py
+-rw-rw-r--  2.0 unx    11357 b- defN 24-May-10 05:56 vllm_xft-0.3.3.1.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     8232 b- defN 24-May-10 05:56 vllm_xft-0.3.3.1.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 24-May-10 05:56 vllm_xft-0.3.3.1.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       11 b- defN 24-May-10 05:56 vllm_xft-0.3.3.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    14297 b- defN 24-May-10 05:56 vllm_xft-0.3.3.1.dist-info/RECORD
+157 files, 1251406 bytes uncompressed, 296215 bytes compressed:  76.3%
```

## zipnote {}

```diff
@@ -450,23 +450,23 @@
 
 Filename: vllm/worker/neuron_worker.py
 Comment: 
 
 Filename: vllm/worker/worker.py
 Comment: 
 
-Filename: vllm_xft-0.3.3.0.dist-info/LICENSE
+Filename: vllm_xft-0.3.3.1.dist-info/LICENSE
 Comment: 
 
-Filename: vllm_xft-0.3.3.0.dist-info/METADATA
+Filename: vllm_xft-0.3.3.1.dist-info/METADATA
 Comment: 
 
-Filename: vllm_xft-0.3.3.0.dist-info/WHEEL
+Filename: vllm_xft-0.3.3.1.dist-info/WHEEL
 Comment: 
 
-Filename: vllm_xft-0.3.3.0.dist-info/top_level.txt
+Filename: vllm_xft-0.3.3.1.dist-info/top_level.txt
 Comment: 
 
-Filename: vllm_xft-0.3.3.0.dist-info/RECORD
+Filename: vllm_xft-0.3.3.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## vllm/__init__.py

```diff
@@ -3,15 +3,15 @@
 from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
 from vllm.engine.async_llm_engine import AsyncLLMEngine
 from vllm.engine.llm_engine import LLMEngine
 from vllm.entrypoints.llm import LLM
 from vllm.outputs import CompletionOutput, RequestOutput
 from vllm.sampling_params import SamplingParams
 
-__version__ = "0.3.3.0"
+__version__ = "0.3.3.1"
 
 __all__ = [
     "LLM",
     "SamplingParams",
     "RequestOutput",
     "CompletionOutput",
     "LLMEngine",
```

## vllm/engine/llm_engine.py

```diff
@@ -96,14 +96,32 @@
         self.device_config = device_config
         self.log_stats = log_stats
         self._verify_args()
 
         self._init_tokenizer()
         self.seq_counter = Counter()
 
+        self.default_stop_ids = []
+        tokenizer = self.get_tokenizer()
+        stop_words_list = [
+            "<|end_of_text|>",
+            "<|eot_id|>",
+            "<|im_end|>",
+            "<|endoftext|>",
+        ]
+
+        special_tokens_dict = {'additional_special_tokens': []}
+        for stop_word in stop_words_list:
+            sopt_word_token_id = tokenizer.encode(stop_word)
+            if len(sopt_word_token_id) == 1:
+                self.default_stop_ids.append(sopt_word_token_id)
+                special_tokens_dict["additional_special_tokens"].append(stop_word)
+        tokenizer.add_special_tokens(special_tokens_dict)
+
+
         self.model_executor = executor_class(model_config, cache_config,
                                              parallel_config, scheduler_config,
                                              device_config, lora_config)
 
         # Create the scheduler.
         # NOTE: the cache_config here have been updated with the numbers of
         # GPU and CPU blocks, which are profiled in the distributed executor.
@@ -124,15 +142,15 @@
         engine_configs = engine_args.create_engine_configs()
         parallel_config = engine_configs[2]
 
         # Initialize the cluster and specify the executor class.
         assert parallel_config.world_size == 1, ("parallel_config.world_size should be 1.")
         from vllm.executor.cpu_executor import CPUExecutor
         executor_class = CPUExecutor
-        
+
         # Create the LLM engine.
         engine = cls(*engine_configs,
                      executor_class=executor_class,
                      log_stats=not engine_args.disable_log_stats)
         return engine
 
     def __reduce__(self):
```

## vllm/entrypoints/openai/serving_chat.py

```diff
@@ -69,14 +69,16 @@
             # if guided_decode_logits_processor:
             #     if sampling_params.logits_processors is None:
             #         sampling_params.logits_processors = []
             #     sampling_params.logits_processors.append(
             #         guided_decode_logits_processor)
         except ValueError as e:
             return self.create_error_response(str(e))
+        
+        sampling_params.stop_token_ids.extend(self.engine.engine.default_stop_ids)
 
         result_generator = self.engine.generate(prompt, sampling_params,
                                                 request_id, token_ids,
                                                 lora_request)
         # Streaming response
         if request.stream:
             return self.chat_completion_stream_generator(
```

## vllm/entrypoints/openai/serving_completion.py

```diff
@@ -118,14 +118,17 @@
         request_id = f"cmpl-{random_uuid()}"
         created_time = int(time.monotonic())
 
         # Schedule the request and get the result generator.
         generators = []
         try:
             sampling_params = request.to_sampling_params()
+
+            sampling_params.stop_token_ids.extend(self.engine.engine.default_stop_ids)
+
             lora_request = self._maybe_get_lora(request)
             # guided_decode_logit_processor = (
             #     await get_guided_decoding_logits_processor(
             #         request, await self.engine.get_tokenizer()))
             # if guided_decode_logit_processor is not None:
             #     if sampling_params.logits_processors is None:
             #         sampling_params.logits_processors = []
```

## Comparing `vllm_xft-0.3.3.0.dist-info/LICENSE` & `vllm_xft-0.3.3.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `vllm_xft-0.3.3.0.dist-info/METADATA` & `vllm_xft-0.3.3.1.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: vllm-xft
-Version: 0.3.3.0
+Version: 0.3.3.1
 Summary: A high-throughput and memory-efficient inference and serving engine for LLMs
 Home-page: https://github.com/vllm-project/vllm
 Author: vLLM Team
 License: Apache 2.0
 Project-URL: Homepage, https://github.com/vllm-project/vllm
 Project-URL: Documentation, https://vllm.readthedocs.io/en/latest/
 Classifier: Programming Language :: Python :: 3.8
@@ -12,18 +12,18 @@
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Requires-Python: >=3.8
 Description-Content-Type: text/markdown
 License-File: LICENSE
-Requires-Dist: transformers >=4.38.0
+Requires-Dist: transformers (>=4.38.0)
 Requires-Dist: fastapi
 Requires-Dist: uvicorn[standard]
-Requires-Dist: prometheus-client >=0.18.0
+Requires-Dist: prometheus-client (>=0.18.0)
 Requires-Dist: xfastertransformer
 
 This is a fork of vLLM to support xfastertransformer backend.  
 `python3 setup.py bdist_wheel --verbose` to build wheel package.  
 ***Distributed is not support yet.(WIP)***  
 **Continuous batching is not supported, so the scheduling strategy has also been modified. Only after the previous batch of requests has been processed will new requests be handled.**
 ### example
```

### html2text {}

```diff
@@ -1,20 +1,20 @@
-Metadata-Version: 2.1 Name: vllm-xft Version: 0.3.3.0 Summary: A high-
+Metadata-Version: 2.1 Name: vllm-xft Version: 0.3.3.1 Summary: A high-
 throughput and memory-efficient inference and serving engine for LLMs Home-
 page: https://github.com/vllm-project/vllm Author: vLLM Team License: Apache
 2.0 Project-URL: Homepage, https://github.com/vllm-project/vllm Project-URL:
 Documentation, https://vllm.readthedocs.io/en/latest/ Classifier: Programming
 Language :: Python :: 3.8 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10 Classifier: Programming
 Language :: Python :: 3.11 Classifier: License :: OSI Approved :: Apache
 Software License Classifier: Topic :: Scientific/Engineering :: Artificial
 Intelligence Requires-Python: >=3.8 Description-Content-Type: text/markdown
-License-File: LICENSE Requires-Dist: transformers >=4.38.0 Requires-Dist:
+License-File: LICENSE Requires-Dist: transformers (>=4.38.0) Requires-Dist:
 fastapi Requires-Dist: uvicorn[standard] Requires-Dist: prometheus-client
->=0.18.0 Requires-Dist: xfastertransformer This is a fork of vLLM to support
+(>=0.18.0) Requires-Dist: xfastertransformer This is a fork of vLLM to support
 xfastertransformer backend. `python3 setup.py bdist_wheel --verbose` to build
 wheel package. ***Distributed is not support yet.(WIP)*** **Continuous batching
 is not supported, so the scheduling strategy has also been modified. Only after
 the previous batch of requests has been processed will new requests be
 handled.** ### example run `examples/offline_xfastertransformer.py` model to
 config xft model directory and tokenizer to config huggingface model directory.
 ### openai.api ``` python -m vllm.entrypoints.openai.api_server \ --model /
```

## Comparing `vllm_xft-0.3.3.0.dist-info/RECORD` & `vllm_xft-0.3.3.1.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 tests/spec_decode/test_metrics.py,sha256=4DIyRsebXIQzQqPDPk2YUHfnGvliKy413viNlD_r308,6093
 tests/spec_decode/test_multi_step_worker.py,sha256=IyKrhrCLtUL2NKMWYlLJ0lNYI1nXwO8Qdi7aELmx0-I,13962
 tests/spec_decode/test_spec_decode_worker.py,sha256=C73uq9bXKZ594zfwAIO2wlKfV2ycNqCNnKle8Qn5D9A,24611
 tests/spec_decode/test_utils.py,sha256=i6n9qdQkEL7qcyCtQlUWfBLFRE83nDvIIxvl6eYzoIo,3112
 tests/spec_decode/utils.py,sha256=ecG1DKq8lgt-69s3XAWaTuYjYFkq670B032HGy2pK60,8368
 tests/worker/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 tests/worker/test_model_runner.py,sha256=gJGle85G3O1lJx3khnzlojW_vPhhlkAgMALCp3tOK6M,2098
-vllm/__init__.py,sha256=7kqWMn6Qm3u-kavA5attS6OHitHSmEY8hBLrwEXn_0o,611
+vllm/__init__.py,sha256=UDrcSgc2F_R9zJ_Ob0yQzCwswhDcX0nrjI2oRD-gJ0w,611
 vllm/block.py,sha256=5E1AqlE1QW44EWv_mE8RJTUkQb65VrFwtMBzak71JvM,2374
 vllm/config.py,sha256=puR__IBJgkQHFr9lMb9rO2YavKs234ZNiCLmaSaviiQ,17378
 vllm/logger.py,sha256=E4REDUV8_rQ7VsH4a8BDV2Hz5AmdsYG9_msA-LyYRcI,1962
 vllm/outputs.py,sha256=7N-y7xvr28HPdNpWxwzvS-0rT-ZLLMZzRoLfg6uzBEE,5411
 vllm/py.typed,sha256=F5LUrt0voM87SNuuOky2X9veCVDqJUgRg_VohYqDigY,65
 vllm/sampling_params.py,sha256=nTwg7VZx9PW26gwk0iJyhCQYyL-ZrYkHcAcfq7YBHcY,13175
 vllm/sequence.py,sha256=ckBN6U1FUHhnX4bwt8_TGA26bHttv2OUFkXQZ_OtZas,19536
@@ -39,25 +39,25 @@
 vllm/core/block_manager.py,sha256=Om0gm8htjydvukF6OuqRRE2IOJMLWIYcKPvdw_ZSVQI,20253
 vllm/core/evictor.py,sha256=2yt6-uqeg76asGU41h7n6R3_KZBjY1GR242s0CNO93w,5426
 vllm/core/policy.py,sha256=bR88Qt4k1tDzadvO1jNXmCkKCeslMdsyVkdTKoCKlpg,973
 vllm/core/scheduler.py,sha256=NX-OmzzgOOMIr7dc4qC2x4Lg1gH1KPXSZNbsDsfhdQQ,21672
 vllm/engine/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 vllm/engine/arg_utils.py,sha256=Ehy0Sm08NTWt-gzLl2NXLqINsZlU8SBTzsPEsKpfdo4,16962
 vllm/engine/async_llm_engine.py,sha256=B3W06l-3UoNoN_p6sI-ojRakUixOWSgQT3UkwqDFjRs,24902
-vllm/engine/llm_engine.py,sha256=_InhWzjCSXyjDxNykNsLRGrQrxhchRFgOSYJUa27734,35602
+vllm/engine/llm_engine.py,sha256=lyDpodyvsW5w4k4tT-vaEPk023jL50UpZClVnA60hbQ,36241
 vllm/engine/metrics.py,sha256=0aNBKL7-saFpMB_QNz4DRGue7duhR3eSnhe6hHgDqpk,9480
 vllm/engine/ray_utils.py,sha256=BtpT8QAhBU4PVhPk_FkshmZYK-vgi7NNxVRbyuPp44c,5005
 vllm/entrypoints/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 vllm/entrypoints/api_server.py,sha256=aI3e2NGO0mvJI9mh6Vp2dyBD-Mji3hENE69SFh-XTAo,3560
 vllm/entrypoints/llm.py,sha256=b4lH0IWW9BR-BAHrpeAn3wZIoZLHKkBAz41ZqLnvr8Y,9649
 vllm/entrypoints/openai/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 vllm/entrypoints/openai/api_server.py,sha256=63XKOrHgexGNkk-fj0bk1BHp57DF6FDoug_XDeosOy0,9768
 vllm/entrypoints/openai/protocol.py,sha256=wT2ie8q91braNQefT8rirskMG8YzrL12P2-Vx73iEdc,11648
-vllm/entrypoints/openai/serving_chat.py,sha256=8yDDWQsHtx5kGoPZ0E8VVBi16VxQlnaZWvpJNqGxaz4,14685
-vllm/entrypoints/openai/serving_completion.py,sha256=VTcZKoZCrWdlKyJzmrJXRidPxLR6sI-SDLi_b7oRuUA,15802
+vllm/entrypoints/openai/serving_chat.py,sha256=mEx-N2eR-x0_r9EN8yaORqN_P5FRPaC-itcawSSJGbE,14777
+vllm/entrypoints/openai/serving_completion.py,sha256=M8uGXzi2B_snRZE19NtsTl3yL8xydhE99RC__dpRFV8,15891
 vllm/entrypoints/openai/serving_engine.py,sha256=C6vtNb5I-ffVHTGHAcmor59CnltYSqWHY7a8_0WQFqU,6918
 vllm/executor/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 vllm/executor/cpu_executor.py,sha256=euQpi22GfZgxnep5_xN3w47QrXGmjpP1xyK0vlC937U,5579
 vllm/executor/executor_base.py,sha256=2AXB3K4iStEhhn5VSoiM68fe93nDSHoGi68GCv-VoH4,2385
 vllm/executor/gpu_executor.py,sha256=X5sjNWV5SKe_fG71_5ToQRRDeaQfM2pKdL4CvYZgBwc,6143
 vllm/executor/ray_gpu_executor.py,sha256=SXcUpGDVFP6ie3SCQvC5hbRdNXFsdpmRvTFleSBmJkM,17242
 vllm/executor/utils.py,sha256=F814pp7u97B3wrNUVBIjEGdBVkrQCcw8XgMMuXU3wAg,722
@@ -146,12 +146,12 @@
 vllm/transformers_utils/tokenizers/__init__.py,sha256=yNjHrv9o-X4OEvO3-ydyjzWWmqUuuJmYcVmkSmtnYLI,114
 vllm/transformers_utils/tokenizers/baichuan.py,sha256=U9oGvLB4ZETx7xUn3v_QOdzo5kfcjB_ls3kRGdv1a8I,9347
 vllm/worker/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 vllm/worker/cache_engine.py,sha256=4ni0hVUvFlWltXGXliuiy3hc31K3DLKmLohrHn7BOFg,6549
 vllm/worker/model_runner.py,sha256=MlLXt5CZjEKA0vcAjjYwMy6ITILkhGmQcV33zyWro5g,7738
 vllm/worker/neuron_worker.py,sha256=CMWGVFJwrs07k4XOYgoAdyHxqh1J-0t4MBdah0N7M-Q,7566
 vllm/worker/worker.py,sha256=jR4w-V4GXBXybZj4FTDPGLxTB9eI91BzUT_wwxZ96Vg,5568
-vllm_xft-0.3.3.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-vllm_xft-0.3.3.0.dist-info/METADATA,sha256=TfprDMYHbd8LunCv_goDmNBvOO4ZG6rm7tW8ButVlEE,8228
-vllm_xft-0.3.3.0.dist-info/WHEEL,sha256=yQN5g4mg4AybRjkgi-9yy4iQEFibGQmlz78Pik5Or-A,92
-vllm_xft-0.3.3.0.dist-info/top_level.txt,sha256=S3-kPzpWG_pE-4Lma2HBbTFJU64RKQ7LrD78aYpdxU4,11
-vllm_xft-0.3.3.0.dist-info/RECORD,,
+vllm_xft-0.3.3.1.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+vllm_xft-0.3.3.1.dist-info/METADATA,sha256=vVTMEbDFggbW4HvAA8unoaWKv6iY0-QU8NK-oyDrWNs,8232
+vllm_xft-0.3.3.1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+vllm_xft-0.3.3.1.dist-info/top_level.txt,sha256=S3-kPzpWG_pE-4Lma2HBbTFJU64RKQ7LrD78aYpdxU4,11
+vllm_xft-0.3.3.1.dist-info/RECORD,,
```


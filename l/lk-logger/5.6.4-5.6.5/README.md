# Comparing `tmp/lk_logger-5.6.4-py3-none-any.whl.zip` & `tmp/lk_logger-5.6.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,31 +1,31 @@
-Zip file size: 42049 bytes, number of entries: 29
--rw-r--r--  2.0 unx      600 b- defN 80-Jan-01 00:00 lk_logger/__init__.py
--rw-r--r--  2.0 unx      591 b- defN 80-Jan-01 00:00 lk_logger/_print.py
--rw-r--r--  2.0 unx       33 b- defN 80-Jan-01 00:00 lk_logger/cache/__init__.py
--rw-r--r--  2.0 unx     6775 b- defN 80-Jan-01 00:00 lk_logger/cache/cache.py
--rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 lk_logger/cache/frame.py
--rw-r--r--  2.0 unx     1817 b- defN 80-Jan-01 00:00 lk_logger/cache/legacy.py
--rw-r--r--  2.0 unx      730 b- defN 80-Jan-01 00:00 lk_logger/cache/util.py
--rw-r--r--  2.0 unx     5586 b- defN 80-Jan-01 00:00 lk_logger/config.py
--rw-r--r--  2.0 unx     1563 b- defN 80-Jan-01 00:00 lk_logger/console.py
--rw-r--r--  2.0 unx     4817 b- defN 80-Jan-01 00:00 lk_logger/control.py
--rw-r--r--  2.0 unx     7652 b- defN 80-Jan-01 00:00 lk_logger/frame_info.py
--rw-r--r--  2.0 unx    13703 b- defN 80-Jan-01 00:00 lk_logger/logger.py
--rw-r--r--  2.0 unx    10376 b- defN 80-Jan-01 00:00 lk_logger/markup.py
--rw-r--r--  2.0 unx    11169 b- defN 80-Jan-01 00:00 lk_logger/message_builder.py
--rw-r--r--  2.0 unx    11291 b- defN 80-Jan-01 00:00 lk_logger/message_formatter.py
--rw-r--r--  2.0 unx     4034 b- defN 80-Jan-01 00:00 lk_logger/path_helper.py
--rw-r--r--  2.0 unx     2559 b- defN 80-Jan-01 00:00 lk_logger/pipeline.py
--rw-r--r--  2.0 unx       71 b- defN 80-Jan-01 00:00 lk_logger/scanner/__init__.py
--rw-r--r--  2.0 unx     6247 b- defN 80-Jan-01 00:00 lk_logger/scanner/analyser.py
--rw-r--r--  2.0 unx     1128 b- defN 80-Jan-01 00:00 lk_logger/scanner/const.py
--rw-r--r--  2.0 unx     1780 b- defN 80-Jan-01 00:00 lk_logger/scanner/exceptions.py
--rw-r--r--  2.0 unx     9594 b- defN 80-Jan-01 00:00 lk_logger/scanner/scanner.py
--rw-r--r--  2.0 unx     3238 b- defN 80-Jan-01 00:00 lk_logger/scanner/symbols.py
--rw-r--r--  2.0 unx    19638 b- defN 80-Jan-01 00:00 lk_logger/scanner/text_scanner.py
--rw-r--r--  2.0 unx      491 b- defN 80-Jan-01 00:00 lk_logger/scanner/typehint.py
--rw-r--r--  2.0 unx      860 b- defN 80-Jan-01 00:00 lk_logger/shunt.py
--rw-r--r--  2.0 unx     4950 b- defN 80-Jan-01 00:00 lk_logger-5.6.4.dist-info/METADATA
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 lk_logger-5.6.4.dist-info/WHEEL
-?rw-r--r--  2.0 unx     2324 b- defN 16-Jan-01 00:00 lk_logger-5.6.4.dist-info/RECORD
-29 files, 133705 bytes uncompressed, 38355 bytes compressed:  71.3%
+Zip file size: 42228 bytes, number of entries: 29
+-rw-r--r--  2.0 fat      600 b- defN 80-Jan-01 00:00 lk_logger/__init__.py
+-rw-r--r--  2.0 fat      616 b- defN 80-Jan-01 00:00 lk_logger/_print.py
+-rw-r--r--  2.0 fat       34 b- defN 80-Jan-01 00:00 lk_logger/cache/__init__.py
+-rw-r--r--  2.0 fat     6970 b- defN 80-Jan-01 00:00 lk_logger/cache/cache.py
+-rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 lk_logger/cache/frame.py
+-rw-r--r--  2.0 fat     1875 b- defN 80-Jan-01 00:00 lk_logger/cache/legacy.py
+-rw-r--r--  2.0 fat      762 b- defN 80-Jan-01 00:00 lk_logger/cache/util.py
+-rw-r--r--  2.0 fat     5732 b- defN 80-Jan-01 00:00 lk_logger/config.py
+-rw-r--r--  2.0 fat     1604 b- defN 80-Jan-01 00:00 lk_logger/console.py
+-rw-r--r--  2.0 fat     4984 b- defN 80-Jan-01 00:00 lk_logger/control.py
+-rw-r--r--  2.0 fat     7860 b- defN 80-Jan-01 00:00 lk_logger/frame_info.py
+-rw-r--r--  2.0 fat    13703 b- defN 80-Jan-01 00:00 lk_logger/logger.py
+-rw-r--r--  2.0 fat    10376 b- defN 80-Jan-01 00:00 lk_logger/markup.py
+-rw-r--r--  2.0 fat    11468 b- defN 80-Jan-01 00:00 lk_logger/message_builder.py
+-rw-r--r--  2.0 fat    11291 b- defN 80-Jan-01 00:00 lk_logger/message_formatter.py
+-rw-r--r--  2.0 fat     4034 b- defN 80-Jan-01 00:00 lk_logger/path_helper.py
+-rw-r--r--  2.0 fat     2656 b- defN 80-Jan-01 00:00 lk_logger/pipeline.py
+-rw-r--r--  2.0 fat       73 b- defN 80-Jan-01 00:00 lk_logger/scanner/__init__.py
+-rw-r--r--  2.0 fat     6407 b- defN 80-Jan-01 00:00 lk_logger/scanner/analyser.py
+-rw-r--r--  2.0 fat     1164 b- defN 80-Jan-01 00:00 lk_logger/scanner/const.py
+-rw-r--r--  2.0 fat     1780 b- defN 80-Jan-01 00:00 lk_logger/scanner/exceptions.py
+-rw-r--r--  2.0 fat     9861 b- defN 80-Jan-01 00:00 lk_logger/scanner/scanner.py
+-rw-r--r--  2.0 fat     3345 b- defN 80-Jan-01 00:00 lk_logger/scanner/symbols.py
+-rw-r--r--  2.0 fat    19638 b- defN 80-Jan-01 00:00 lk_logger/scanner/text_scanner.py
+-rw-r--r--  2.0 fat      517 b- defN 80-Jan-01 00:00 lk_logger/scanner/typehint.py
+-rw-r--r--  2.0 fat      896 b- defN 80-Jan-01 00:00 lk_logger/shunt.py
+-rw-r--r--  2.0 fat     4950 b- defN 80-Jan-01 00:00 lk_logger-5.6.5.dist-info/METADATA
+-rw-r--r--  2.0 fat       88 b- defN 80-Jan-01 00:00 lk_logger-5.6.5.dist-info/WHEEL
+?rw-r--r--  2.0 fat     2324 b- defN 16-Jan-01 00:00 lk_logger-5.6.5.dist-info/RECORD
+29 files, 135608 bytes uncompressed, 38534 bytes compressed:  71.6%
```

## zipnote {}

```diff
@@ -72,17 +72,17 @@
 
 Filename: lk_logger/scanner/typehint.py
 Comment: 
 
 Filename: lk_logger/shunt.py
 Comment: 
 
-Filename: lk_logger-5.6.4.dist-info/METADATA
+Filename: lk_logger-5.6.5.dist-info/METADATA
 Comment: 
 
-Filename: lk_logger-5.6.4.dist-info/WHEEL
+Filename: lk_logger-5.6.5.dist-info/WHEEL
 Comment: 
 
-Filename: lk_logger-5.6.4.dist-info/RECORD
+Filename: lk_logger-5.6.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## lk_logger/__init__.py

```diff
@@ -17,8 +17,8 @@
 def __init() -> None:
     import traceback
     pipeline.add(traceback, bprint)
     setup(quiet=True)
 
 
 __init()
-__version__ = '5.6.4'
+__version__ = '5.6.5'
```

## lk_logger/_print.py

 * *Ordering differences only*

```diff
@@ -1,25 +1,25 @@
-import builtins
-from inspect import currentframe
-from os import name as os_name
-
-bprint = builtins.print
-std_print = builtins.print
-non_print = lambda *_, **__: None
-
-
-def debug(*args, condition=True) -> None:
-    frame = currentframe().f_back
-    filepath = _normpath(frame.f_globals["__file__"])
-    lineno = frame.f_lineno
-    source = '{}:{}'.format(filepath, lineno)
-    if condition:
-        bprint(source, '[LKDEBUG]', *args)
-
-
-_is_win = os_name == 'nt'
-
-
-def _normpath(path: str) -> str:
-    if _is_win:
-        return path.replace('\\', '/').rstrip('/')
-    return path.rstrip('/')
+import builtins
+from inspect import currentframe
+from os import name as os_name
+
+bprint = builtins.print
+std_print = builtins.print
+non_print = lambda *_, **__: None
+
+
+def debug(*args, condition=True) -> None:
+    frame = currentframe().f_back
+    filepath = _normpath(frame.f_globals["__file__"])
+    lineno = frame.f_lineno
+    source = '{}:{}'.format(filepath, lineno)
+    if condition:
+        bprint(source, '[LKDEBUG]', *args)
+
+
+_is_win = os_name == 'nt'
+
+
+def _normpath(path: str) -> str:
+    if _is_win:
+        return path.replace('\\', '/').rstrip('/')
+    return path.rstrip('/')
```

## lk_logger/cache/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-from .legacy import LoggingCache
+from .legacy import LoggingCache
```

## lk_logger/cache/cache.py

 * *Ordering differences only*

```diff
@@ -1,195 +1,195 @@
-import atexit
-import os
-import typing as t
-from time import time
-
-from .util import get_content_hash
-from .util import pickle_dump
-from .util import pickle_load
-from ..frame_info import FrameInfo
-from ..markup import MarkMeaning
-from ..markup import MarkupAnalyser
-
-_CACHE_DIR = os.path.abspath(f'{__file__}/../__cachemap__')
-_markup_analyser = MarkupAnalyser()
-_is_markup = _markup_analyser.is_valid_markup
-
-
-class T:
-    _Enum = t.Any
-    _FilePath = str
-    _LineNumber = int
-    _Time = int
-    
-    Args = t.Tuple[t.Any, ...]
-    FrameInfo = FrameInfo
-    MarksMeaning = MarkMeaning
-    MarkupPos = int  # -1, 0, 1
-    VarNames = t.Tuple[str, ...]
-    
-    # TODO: `global_settings` may be removed.
-    # noinspection PyTypedDict
-    Cache = t.TypedDict('Cache', {
-        'working_root'   : str,
-        'updated_time'   : _Time,
-        'global_settings': t.TypedDict('GlobalSettings', {
-            'show_source'  : bool,
-            'show_funcname': bool,
-            'show_varnames': bool,
-        }),
-        'optimizations'  : t.TypedDict('Optimizations', {
-            'source_width'  : t.Dict[int, int],
-            'funcname_width': t.Dict[int, int],
-        }),
-        'file_map'       : t.Dict[_FilePath, _Time],
-        'source_map'     : t.Dict[
-            _FilePath, t.Dict[
-                _LineNumber, t.TypedDict('MapInfo', {
-                    'markup_pos'   : int,
-                    'marks_meaning': t.Dict[str, _Enum],
-                    'varnames'     : VarNames,
-                })
-            ]
-        ]
-    })
-    # noinspection PyTypedDict
-    Info = t.TypedDict('Info', {
-        'markup_pos'         : int,
-        'marks_meaning'      : t.Dict[str, _Enum],
-        'varnames'           : VarNames,
-        # 'proper_prefix_width': t.Optional[t.Tuple[int, int]],
-        'proper_prefix_width': t.Tuple[t.Optional[int], t.Optional[int]],
-    })
-
-
-class Cache:
-    _cache: T.Cache
-    _path: str
-    
-    def __init__(self):
-        root = os.path.abspath(os.getcwd()).replace('\\', '/')
-        root_id = get_content_hash(root)
-        self._path = f'{_CACHE_DIR}/{root_id}.pkl'
-        if os.path.exists(self._path):
-            self._cache = pickle_load(self._path)
-            # update (reset) file_map and source_map
-            for f, t in self._cache['file_map'].items():
-                if not os.path.exists(f):
-                    self._cache['file_map'].pop(f)
-                    self._cache['source_map'].pop(f)
-                    continue
-                if os.path.getmtime(f) != t:
-                    self._cache['file_map'][f] = os.path.getmtime(f)
-                    self._cache['source_map'][f] = {}
-                    # self._cache['source_map'][f].clear()
-        else:
-            self._cache = {
-                'working_root'   : root,
-                'updated_time'   : int(time()),
-                'global_settings': {
-                    'show_source'  : True,
-                    'show_funcname': True,
-                    'show_varnames': False,
-                },
-                'optimizations'  : {
-                    'source_width'  : {},
-                    'funcname_width': {},
-                },
-                'file_map'       : {},
-                'source_map'     : {},
-            }
-        atexit.register(self._auto_save)
-    
-    @property
-    def path(self) -> str:
-        return self._path
-    
-    def get(self, frame_info: T.FrameInfo, aux: T.Args = None) -> T.Info:
-        out: t.Optional[T.Info] = None
-        fp = frame_info.filepath
-        ln = frame_info.lineno
-        d0 = self._cache['optimizations']
-        if d1 := self._cache['source_map'].get(fp):
-            if d2 := d1.get(ln):
-                # noinspection PyTypeChecker
-                out = {
-                    'markup_pos'         : d2['markup_pos'],
-                    'marks_meaning'      : d2['marks_meaning'],
-                    'varnames'           : d2['varnames'],
-                    'proper_prefix_width': (
-                        (x := d0['source_width'].get(ln)),
-                        (x and d0['funcname_width'].get(ln))
-                    )
-                }
-        else:
-            assert fp not in self._cache['file_map']
-            self._cache['file_map'][fp] = os.path.getmtime(fp)
-            self._cache['source_map'][fp] = {}
-        if out is None:
-            # assert aux is not None
-            pos, meaning, varnames = self._analyze_arguments(frame_info, aux)
-            # noinspection PyTypeChecker
-            self._cache['source_map'][fp][ln] = {
-                'markup_pos'   : pos,
-                'marks_meaning': meaning,
-                'varnames'     : varnames,
-            }
-            # noinspection PyTypeChecker
-            out = {
-                'markup_pos'         : pos,
-                'marks_meaning'      : meaning,
-                'varnames'           : varnames,
-                'proper_prefix_width': (None, None),
-            }
-        return out
-    
-    def update_settings(self, **kwargs) -> None:
-        if (x := 'show_varnames') in kwargs:
-            # show_varnames has special scheme: once it *changed*, whether to
-            # True or False, the cache must always be True.
-            if kwargs[x] != self._cache['global_settings'][x]:
-                kwargs[x] = True
-        self._cache['global_settings'].update(kwargs)
-    
-    def _auto_save(self) -> None:
-        def optimize_width_columns() -> None:
-            pass  # TODO
-        
-        optimize_width_columns()
-        pickle_dump(self._cache, self._path)
-    
-    @staticmethod
-    def _analyze_arguments(frame_info: T.FrameInfo, args: T.Args) \
-            -> t.Tuple[T.MarkupPos, T.MarksMeaning, T.VarNames]:
-        """
-        markup_pos: which position of `markup` in `args`.
-            0 not exists, 1 first place, -1 last place.
-        """
-        if (
-                len(args) > 0 and
-                isinstance(args[0], str) and
-                args[0].startswith(':') and
-                _is_markup(args[0])
-        ):
-            markup_pos = 1
-            marks = _markup_analyser.extract(args[0])
-        elif (
-                len(args) > 1 and
-                isinstance(args[-1], str) and
-                args[-1].startswith(':') and
-                _is_markup(args[-1])
-        ):
-            markup_pos = -1
-            marks = _markup_analyser.extract(args[-1])
-        else:
-            markup_pos = 0
-            marks = {}
-        
-        get_varnames = frame_info.collect_varnames  # backup method pointer
-        if marks['p']: frame_info = frame_info.get_parent(marks['p'])
-        marks_meaning = _markup_analyser.analyze(marks, frame_info=frame_info)
-        
-        return markup_pos, marks_meaning, get_varnames()
-
-
-cache = Cache()
+import atexit
+import os
+import typing as t
+from time import time
+
+from .util import get_content_hash
+from .util import pickle_dump
+from .util import pickle_load
+from ..frame_info import FrameInfo
+from ..markup import MarkMeaning
+from ..markup import MarkupAnalyser
+
+_CACHE_DIR = os.path.abspath(f'{__file__}/../__cachemap__')
+_markup_analyser = MarkupAnalyser()
+_is_markup = _markup_analyser.is_valid_markup
+
+
+class T:
+    _Enum = t.Any
+    _FilePath = str
+    _LineNumber = int
+    _Time = int
+    
+    Args = t.Tuple[t.Any, ...]
+    FrameInfo = FrameInfo
+    MarksMeaning = MarkMeaning
+    MarkupPos = int  # -1, 0, 1
+    VarNames = t.Tuple[str, ...]
+    
+    # TODO: `global_settings` may be removed.
+    # noinspection PyTypedDict
+    Cache = t.TypedDict('Cache', {
+        'working_root'   : str,
+        'updated_time'   : _Time,
+        'global_settings': t.TypedDict('GlobalSettings', {
+            'show_source'  : bool,
+            'show_funcname': bool,
+            'show_varnames': bool,
+        }),
+        'optimizations'  : t.TypedDict('Optimizations', {
+            'source_width'  : t.Dict[int, int],
+            'funcname_width': t.Dict[int, int],
+        }),
+        'file_map'       : t.Dict[_FilePath, _Time],
+        'source_map'     : t.Dict[
+            _FilePath, t.Dict[
+                _LineNumber, t.TypedDict('MapInfo', {
+                    'markup_pos'   : int,
+                    'marks_meaning': t.Dict[str, _Enum],
+                    'varnames'     : VarNames,
+                })
+            ]
+        ]
+    })
+    # noinspection PyTypedDict
+    Info = t.TypedDict('Info', {
+        'markup_pos'         : int,
+        'marks_meaning'      : t.Dict[str, _Enum],
+        'varnames'           : VarNames,
+        # 'proper_prefix_width': t.Optional[t.Tuple[int, int]],
+        'proper_prefix_width': t.Tuple[t.Optional[int], t.Optional[int]],
+    })
+
+
+class Cache:
+    _cache: T.Cache
+    _path: str
+    
+    def __init__(self):
+        root = os.path.abspath(os.getcwd()).replace('\\', '/')
+        root_id = get_content_hash(root)
+        self._path = f'{_CACHE_DIR}/{root_id}.pkl'
+        if os.path.exists(self._path):
+            self._cache = pickle_load(self._path)
+            # update (reset) file_map and source_map
+            for f, t in self._cache['file_map'].items():
+                if not os.path.exists(f):
+                    self._cache['file_map'].pop(f)
+                    self._cache['source_map'].pop(f)
+                    continue
+                if os.path.getmtime(f) != t:
+                    self._cache['file_map'][f] = os.path.getmtime(f)
+                    self._cache['source_map'][f] = {}
+                    # self._cache['source_map'][f].clear()
+        else:
+            self._cache = {
+                'working_root'   : root,
+                'updated_time'   : int(time()),
+                'global_settings': {
+                    'show_source'  : True,
+                    'show_funcname': True,
+                    'show_varnames': False,
+                },
+                'optimizations'  : {
+                    'source_width'  : {},
+                    'funcname_width': {},
+                },
+                'file_map'       : {},
+                'source_map'     : {},
+            }
+        atexit.register(self._auto_save)
+    
+    @property
+    def path(self) -> str:
+        return self._path
+    
+    def get(self, frame_info: T.FrameInfo, aux: T.Args = None) -> T.Info:
+        out: t.Optional[T.Info] = None
+        fp = frame_info.filepath
+        ln = frame_info.lineno
+        d0 = self._cache['optimizations']
+        if d1 := self._cache['source_map'].get(fp):
+            if d2 := d1.get(ln):
+                # noinspection PyTypeChecker
+                out = {
+                    'markup_pos'         : d2['markup_pos'],
+                    'marks_meaning'      : d2['marks_meaning'],
+                    'varnames'           : d2['varnames'],
+                    'proper_prefix_width': (
+                        (x := d0['source_width'].get(ln)),
+                        (x and d0['funcname_width'].get(ln))
+                    )
+                }
+        else:
+            assert fp not in self._cache['file_map']
+            self._cache['file_map'][fp] = os.path.getmtime(fp)
+            self._cache['source_map'][fp] = {}
+        if out is None:
+            # assert aux is not None
+            pos, meaning, varnames = self._analyze_arguments(frame_info, aux)
+            # noinspection PyTypeChecker
+            self._cache['source_map'][fp][ln] = {
+                'markup_pos'   : pos,
+                'marks_meaning': meaning,
+                'varnames'     : varnames,
+            }
+            # noinspection PyTypeChecker
+            out = {
+                'markup_pos'         : pos,
+                'marks_meaning'      : meaning,
+                'varnames'           : varnames,
+                'proper_prefix_width': (None, None),
+            }
+        return out
+    
+    def update_settings(self, **kwargs) -> None:
+        if (x := 'show_varnames') in kwargs:
+            # show_varnames has special scheme: once it *changed*, whether to
+            # True or False, the cache must always be True.
+            if kwargs[x] != self._cache['global_settings'][x]:
+                kwargs[x] = True
+        self._cache['global_settings'].update(kwargs)
+    
+    def _auto_save(self) -> None:
+        def optimize_width_columns() -> None:
+            pass  # TODO
+        
+        optimize_width_columns()
+        pickle_dump(self._cache, self._path)
+    
+    @staticmethod
+    def _analyze_arguments(frame_info: T.FrameInfo, args: T.Args) \
+            -> t.Tuple[T.MarkupPos, T.MarksMeaning, T.VarNames]:
+        """
+        markup_pos: which position of `markup` in `args`.
+            0 not exists, 1 first place, -1 last place.
+        """
+        if (
+                len(args) > 0 and
+                isinstance(args[0], str) and
+                args[0].startswith(':') and
+                _is_markup(args[0])
+        ):
+            markup_pos = 1
+            marks = _markup_analyser.extract(args[0])
+        elif (
+                len(args) > 1 and
+                isinstance(args[-1], str) and
+                args[-1].startswith(':') and
+                _is_markup(args[-1])
+        ):
+            markup_pos = -1
+            marks = _markup_analyser.extract(args[-1])
+        else:
+            markup_pos = 0
+            marks = {}
+        
+        get_varnames = frame_info.collect_varnames  # backup method pointer
+        if marks['p']: frame_info = frame_info.get_parent(marks['p'])
+        marks_meaning = _markup_analyser.analyze(marks, frame_info=frame_info)
+        
+        return markup_pos, marks_meaning, get_varnames()
+
+
+cache = Cache()
```

## lk_logger/cache/legacy.py

 * *Ordering differences only*

```diff
@@ -1,58 +1,58 @@
-import typing as t
-
-from ..markup import T as T0
-from ..message_builder import T as T1
-
-
-class T:  # Typehint
-    FrameId = str
-    Info = T1.Info
-    MarkupPos = int
-    Markup = str
-    
-    # noinspection PyTypedDict
-    Cache = t.Dict[FrameId, t.TypedDict('CacheValue', {
-        'markup_pos'   : MarkupPos,
-        'marks_meaning': T0.MarksMeaning,
-        'info'         : t.Dict[Markup, T1.Info],
-    })]
-
-
-class LoggingCache:
-    _cache: T.Cache
-    
-    def __init__(self) -> None:
-        from collections import defaultdict
-        # noinspection PyTypeChecker
-        self._cache = defaultdict(lambda: {
-            'markup_pos'   : None,
-            'marks_meaning': {},
-            'info'         : {},
-        })
-    
-    def clear_cache(self) -> None:
-        self._cache.clear()
-    
-    # -------------------------------------------------------------------------
-    
-    def get_markup_pos(self, frame_id: T.FrameId) -> t.Optional[T.MarkupPos]:
-        return self._cache[frame_id].get('markup_pos', None)
-    
-    def is_cached(self, frame_id: T.FrameId, markup: T.Markup) -> bool:
-        return (
-                frame_id in self._cache and
-                markup in self._cache[frame_id]['info']
-        )
-    
-    def get_cache(self, frame_id: T.FrameId, markup: T.Markup) -> T.Info:
-        # suggest checking `self.is_cached` before calling this method.
-        return self._cache[frame_id]['info'][markup]
-    
-    # -------------------------------------------------------------------------
-    
-    def record_markup_pos(self, frame_id: T.FrameId, pos: T.MarkupPos) -> None:
-        self._cache[frame_id]['markup_pos'] = pos
-    
-    def store_info(self, frame_id: T.FrameId, markup: T.Markup,
-                   info: T.Info) -> None:
-        self._cache[frame_id]['info'][markup] = info
+import typing as t
+
+from ..markup import T as T0
+from ..message_builder import T as T1
+
+
+class T:  # Typehint
+    FrameId = str
+    Info = T1.Info
+    MarkupPos = int
+    Markup = str
+    
+    # noinspection PyTypedDict
+    Cache = t.Dict[FrameId, t.TypedDict('CacheValue', {
+        'markup_pos'   : MarkupPos,
+        'marks_meaning': T0.MarksMeaning,
+        'info'         : t.Dict[Markup, T1.Info],
+    })]
+
+
+class LoggingCache:
+    _cache: T.Cache
+    
+    def __init__(self) -> None:
+        from collections import defaultdict
+        # noinspection PyTypeChecker
+        self._cache = defaultdict(lambda: {
+            'markup_pos'   : None,
+            'marks_meaning': {},
+            'info'         : {},
+        })
+    
+    def clear_cache(self) -> None:
+        self._cache.clear()
+    
+    # -------------------------------------------------------------------------
+    
+    def get_markup_pos(self, frame_id: T.FrameId) -> t.Optional[T.MarkupPos]:
+        return self._cache[frame_id].get('markup_pos', None)
+    
+    def is_cached(self, frame_id: T.FrameId, markup: T.Markup) -> bool:
+        return (
+                frame_id in self._cache and
+                markup in self._cache[frame_id]['info']
+        )
+    
+    def get_cache(self, frame_id: T.FrameId, markup: T.Markup) -> T.Info:
+        # suggest checking `self.is_cached` before calling this method.
+        return self._cache[frame_id]['info'][markup]
+    
+    # -------------------------------------------------------------------------
+    
+    def record_markup_pos(self, frame_id: T.FrameId, pos: T.MarkupPos) -> None:
+        self._cache[frame_id]['markup_pos'] = pos
+    
+    def store_info(self, frame_id: T.FrameId, markup: T.Markup,
+                   info: T.Info) -> None:
+        self._cache[frame_id]['info'][markup] = info
```

## lk_logger/cache/util.py

 * *Ordering differences only*

```diff
@@ -1,32 +1,32 @@
-import hashlib
-import os
-import pickle
-
-
-def get_content_hash(content: str) -> str:
-    return hashlib.md5(content.encode()).hexdigest()
-
-
-def get_file_hash(path: str) -> str:
-    """
-    if file is too big, read the first 8192 bytes.
-    https://blog.csdn.net/qq_26373925/article/details/115409308
-    """
-    file = open(path, 'rb')
-    md5 = hashlib.md5()
-    if os.path.getsize(path) > 3 * 1024 * 1024:
-        md5.update(file.read(8192))
-    else:
-        md5.update(file.read())
-    file.close()
-    return md5.hexdigest()
-
-
-def pickle_load(file: str) -> dict:
-    with open(file, 'rb') as f:
-        return pickle.load(f)
-
-
-def pickle_dump(obj: dict, file: str):
-    with open(file, 'wb') as f:
-        pickle.dump(obj, f)
+import hashlib
+import os
+import pickle
+
+
+def get_content_hash(content: str) -> str:
+    return hashlib.md5(content.encode()).hexdigest()
+
+
+def get_file_hash(path: str) -> str:
+    """
+    if file is too big, read the first 8192 bytes.
+    https://blog.csdn.net/qq_26373925/article/details/115409308
+    """
+    file = open(path, 'rb')
+    md5 = hashlib.md5()
+    if os.path.getsize(path) > 3 * 1024 * 1024:
+        md5.update(file.read(8192))
+    else:
+        md5.update(file.read())
+    file.close()
+    return md5.hexdigest()
+
+
+def pickle_load(file: str) -> dict:
+    with open(file, 'rb') as f:
+        return pickle.load(f)
+
+
+def pickle_dump(obj: dict, file: str):
+    with open(file, 'wb') as f:
+        pickle.dump(obj, f)
```

## lk_logger/config.py

 * *Ordering differences only*

```diff
@@ -1,146 +1,146 @@
-import sys
-import typing as t
-from sys import excepthook as _default_excepthook
-
-
-class LoggingConfig:
-    """
-    options:
-        show_source: bool[true]
-            add source info (filepath and line number) prefix to log messages.
-            example:
-                lk.log('hello world')
-                # enabled : './main.py:10  >>  hello world'
-                # disabled: 'hello world'
-        show_varnames: bool[false]
-            show both var names and values. (magic reflection)
-            example:
-                a, b = 1, 2
-                lk.log(a, b, a + b)
-                # enabled : 'main.py:11  >>  a = 1; b = 2; a + b = 3'
-                # disabled: 'main.py:11  >>  1, 2, 3'
-        show_external_lib: bool[true]
-            if `param source` came from an external library, whether to print.
-            for example, if a third-party library 'xxx' also used `lk.log`,
-            its source path (relative to current working dir) may be very long,
-            if you don't want to see any prints except your own project, you'd
-            set this to False.
-
-        # the following options are only available if `show_external_lib` is
-        # true.
-        path_style_for_external_lib: literal
-            literal:
-                'pretty_relpath': default
-                    trunscate the source path of external lib to be shorter.
-                    example:
-                        before:
-                            '../../../../site-packages/lk_logger/sourcemap.py'
-                            # there may be a lot of '../'.
-                        after:
-                            '[lk_logger]/sourcemap.py'
-                'relpath':
-                    a relative path to current working dir. (<- `os.getcwd()`)
-                    note there may be a lot of '../../../...' if external lib
-                    is far beyond the current working dir.
-                'lib_name_only':
-                    show only the library name (surrounded by brackets).
-                    example: '[lk_logger]'
-            ps: if you don't want to show anything, you should turn to set
-            `show_external_lib` to False.
-    """
-    async_: bool
-    clear_unfinished_stream: bool
-    console_width: t.Optional[int]
-    path_style_for_external_lib: str
-    rich_traceback: bool
-    separator: str
-    show_external_lib: bool
-    show_funcname: bool
-    show_source: bool
-    show_varnames: bool
-    sourcemap_alignment: t.Literal['left', 'right']
-    v2_meaning: t.Literal['info', 'success']  # TODO: not used.
-    
-    _preset_conf = {
-        'async_'                     : True,
-        'clear_unfinished_stream'    : False,
-        'console_width'              : None,
-        'path_style_for_external_lib': 'pretty_relpath',
-        'rich_traceback'             : True,
-        'separator'                  : ';   ',
-        'show_external_lib'          : True,
-        'show_funcname'              : True,
-        'show_source'                : True,
-        'show_varnames'              : False,
-        'sourcemap_alignment'        : 'left',
-        'v2_meaning'                 : 'info',
-    }
-    
-    def __init__(self, **kwargs) -> None:
-        for k, v in self._merge_dict(self._preset_conf, kwargs).items():
-            self._apply(k, v)
-    
-    def update(self, **kwargs) -> None:
-        for k, v in kwargs.items():
-            if k in self._preset_conf and v != getattr(self, k, None):
-                self._apply(k, v)
-    
-    def reset(self) -> None:
-        for k, v in self._preset_conf.items():
-            if v != getattr(self, k, None):
-                self._apply(k, v)
-    
-    def _apply(self, key: str, val: t.Union[bool, int, str]) -> None:
-        setattr(self, key, val)
-        if key == 'console_width':
-            if val and isinstance(val, int):
-                from .console import console
-                console.width = val
-        elif key == 'rich_traceback':
-            import sys
-            from functools import partial
-            if val:
-                # https://rich.readthedocs.io/en/stable/traceback.html
-                from rich.traceback import install
-                from .console import console
-                install(console=console, show_locals=False)
-                modified = sys.excepthook
-                sys.excepthook = partial(
-                    self._wrap_system_excepthook,
-                    callback=modified
-                )
-            else:
-                sys.excepthook = self._wrap_system_excepthook
-    
-    @staticmethod
-    def _wrap_system_excepthook(
-            type_, value, traceback, callback=_default_excepthook
-    ) -> None:
-        print(':r', '[red dim]drain out message queue[/]')
-        from .logger import lk
-        lk._stop_running()  # noqa
-        if type_ is KeyboardInterrupt:
-            print(':r', '[red dim]KeyboardInterrupt[/]')
-            sys.exit(0)
-        else:
-            callback(type_, value, traceback)
-    
-    # -------------------------------------------------------------------------
-    
-    def to_dict(self) -> t.Dict[str, t.Any]:
-        return {
-            k: getattr(self, k)
-            for k in self._preset_conf
-        }
-    
-    @staticmethod
-    def _merge_dict(base: dict, update: dict) -> dict:
-        return {k: update.get(k, default_v) for k, default_v in base.items()}
-    
-    @staticmethod
-    def _diff_dict(base: dict, update: dict) -> dict:
-        out = {}
-        for k, v0 in base.items():
-            if k in update and v0 != (v1 := update[k]):
-                out[k] = v1
-        return out
+import sys
+import typing as t
+from sys import excepthook as _default_excepthook
+
+
+class LoggingConfig:
+    """
+    options:
+        show_source: bool[true]
+            add source info (filepath and line number) prefix to log messages.
+            example:
+                lk.log('hello world')
+                # enabled : './main.py:10  >>  hello world'
+                # disabled: 'hello world'
+        show_varnames: bool[false]
+            show both var names and values. (magic reflection)
+            example:
+                a, b = 1, 2
+                lk.log(a, b, a + b)
+                # enabled : 'main.py:11  >>  a = 1; b = 2; a + b = 3'
+                # disabled: 'main.py:11  >>  1, 2, 3'
+        show_external_lib: bool[true]
+            if `param source` came from an external library, whether to print.
+            for example, if a third-party library 'xxx' also used `lk.log`,
+            its source path (relative to current working dir) may be very long,
+            if you don't want to see any prints except your own project, you'd
+            set this to False.
+
+        # the following options are only available if `show_external_lib` is
+        # true.
+        path_style_for_external_lib: literal
+            literal:
+                'pretty_relpath': default
+                    trunscate the source path of external lib to be shorter.
+                    example:
+                        before:
+                            '../../../../site-packages/lk_logger/sourcemap.py'
+                            # there may be a lot of '../'.
+                        after:
+                            '[lk_logger]/sourcemap.py'
+                'relpath':
+                    a relative path to current working dir. (<- `os.getcwd()`)
+                    note there may be a lot of '../../../...' if external lib
+                    is far beyond the current working dir.
+                'lib_name_only':
+                    show only the library name (surrounded by brackets).
+                    example: '[lk_logger]'
+            ps: if you don't want to show anything, you should turn to set
+            `show_external_lib` to False.
+    """
+    async_: bool
+    clear_unfinished_stream: bool
+    console_width: t.Optional[int]
+    path_style_for_external_lib: str
+    rich_traceback: bool
+    separator: str
+    show_external_lib: bool
+    show_funcname: bool
+    show_source: bool
+    show_varnames: bool
+    sourcemap_alignment: t.Literal['left', 'right']
+    v2_meaning: t.Literal['info', 'success']  # TODO: not used.
+    
+    _preset_conf = {
+        'async_'                     : True,
+        'clear_unfinished_stream'    : False,
+        'console_width'              : None,
+        'path_style_for_external_lib': 'pretty_relpath',
+        'rich_traceback'             : True,
+        'separator'                  : ';   ',
+        'show_external_lib'          : True,
+        'show_funcname'              : True,
+        'show_source'                : True,
+        'show_varnames'              : False,
+        'sourcemap_alignment'        : 'left',
+        'v2_meaning'                 : 'info',
+    }
+    
+    def __init__(self, **kwargs) -> None:
+        for k, v in self._merge_dict(self._preset_conf, kwargs).items():
+            self._apply(k, v)
+    
+    def update(self, **kwargs) -> None:
+        for k, v in kwargs.items():
+            if k in self._preset_conf and v != getattr(self, k, None):
+                self._apply(k, v)
+    
+    def reset(self) -> None:
+        for k, v in self._preset_conf.items():
+            if v != getattr(self, k, None):
+                self._apply(k, v)
+    
+    def _apply(self, key: str, val: t.Union[bool, int, str]) -> None:
+        setattr(self, key, val)
+        if key == 'console_width':
+            if val and isinstance(val, int):
+                from .console import console
+                console.width = val
+        elif key == 'rich_traceback':
+            import sys
+            from functools import partial
+            if val:
+                # https://rich.readthedocs.io/en/stable/traceback.html
+                from rich.traceback import install
+                from .console import console
+                install(console=console, show_locals=False)
+                modified = sys.excepthook
+                sys.excepthook = partial(
+                    self._wrap_system_excepthook,
+                    callback=modified
+                )
+            else:
+                sys.excepthook = self._wrap_system_excepthook
+    
+    @staticmethod
+    def _wrap_system_excepthook(
+            type_, value, traceback, callback=_default_excepthook
+    ) -> None:
+        print(':r', '[red dim]drain out message queue[/]')
+        from .logger import lk
+        lk._stop_running()  # noqa
+        if type_ is KeyboardInterrupt:
+            print(':r', '[red dim]KeyboardInterrupt[/]')
+            sys.exit(0)
+        else:
+            callback(type_, value, traceback)
+    
+    # -------------------------------------------------------------------------
+    
+    def to_dict(self) -> t.Dict[str, t.Any]:
+        return {
+            k: getattr(self, k)
+            for k in self._preset_conf
+        }
+    
+    @staticmethod
+    def _merge_dict(base: dict, update: dict) -> dict:
+        return {k: update.get(k, default_v) for k, default_v in base.items()}
+    
+    @staticmethod
+    def _diff_dict(base: dict, update: dict) -> dict:
+        out = {}
+        for k, v0 in base.items():
+            if k in update and v0 != (v1 := update[k]):
+                out[k] = v1
+        return out
```

## lk_logger/console.py

 * *Ordering differences only*

```diff
@@ -1,41 +1,41 @@
-from functools import partial
-from typing import Any
-
-from rich.console import Console as BaseConsole
-
-__all__ = ['con_print', 'con_error', 'console']
-
-
-class Console(BaseConsole):
-    
-    def __init__(self):
-        super().__init__()
-        if self._color_system is None:
-            try:
-                # in rich version >= 12.5, the color system is changed to be a
-                # contant integer.
-                from rich.console import ColorSystem
-                self._color_system = ColorSystem.STANDARD
-            except:
-                # the older version is using a string.
-                self._color_system = 'standard'
-        
-        # TODO (width):
-        #   if width longer than default, use single line style; otherwise
-        #   split sourcemap and message into different lines.
-        pass
-    
-    def print(self, *objects: Any, sep=" ", end="\n", style=None, justify=None,
-              overflow=None, no_wrap=None, emoji=None, markup=None,
-              highlight=None, width=None, height=None, crop=True,
-              soft_wrap=False, new_line_start=False, **_) -> None:
-        super().print(*objects, sep=sep, end=end, style=style, justify=justify,
-                      overflow=overflow, no_wrap=no_wrap, emoji=emoji,
-                      markup=markup, highlight=highlight, width=width,
-                      height=height, crop=crop, soft_wrap=soft_wrap,
-                      new_line_start=new_line_start)
-
-
-console = Console()
-con_print = partial(console.print, soft_wrap=True)
-con_error = console.print_exception
+from functools import partial
+from typing import Any
+
+from rich.console import Console as BaseConsole
+
+__all__ = ['con_print', 'con_error', 'console']
+
+
+class Console(BaseConsole):
+    
+    def __init__(self):
+        super().__init__()
+        if self._color_system is None:
+            try:
+                # in rich version >= 12.5, the color system is changed to be a
+                # contant integer.
+                from rich.console import ColorSystem
+                self._color_system = ColorSystem.STANDARD
+            except:
+                # the older version is using a string.
+                self._color_system = 'standard'
+        
+        # TODO (width):
+        #   if width longer than default, use single line style; otherwise
+        #   split sourcemap and message into different lines.
+        pass
+    
+    def print(self, *objects: Any, sep=" ", end="\n", style=None, justify=None,
+              overflow=None, no_wrap=None, emoji=None, markup=None,
+              highlight=None, width=None, height=None, crop=True,
+              soft_wrap=False, new_line_start=False, **_) -> None:
+        super().print(*objects, sep=sep, end=end, style=style, justify=justify,
+                      overflow=overflow, no_wrap=no_wrap, emoji=emoji,
+                      markup=markup, highlight=highlight, width=width,
+                      height=height, crop=crop, soft_wrap=soft_wrap,
+                      new_line_start=new_line_start)
+
+
+console = Console()
+con_print = partial(console.print, soft_wrap=True)
+con_error = console.print_exception
```

## lk_logger/control.py

 * *Ordering differences only*

```diff
@@ -1,167 +1,167 @@
-import builtins
-import typing as t
-
-from ._print import bprint
-from ._print import debug  # noqa
-from .logger import lk
-
-STATUS = 'unloaded'  # literal['enabled', 'disabled', 'unloaded']
-_HAS_WELCOME_MESSAGE_SHOWN = False
-
-
-def setup(*, quiet=False, clear_preset=False, **kwargs) -> None:
-    """
-    args:
-        quiet:
-            True: show a welcome message in caller side.
-            False: do not show.
-
-            note: the welcome message is shown only once, if caller calls this
-                function multi times, only the first time when passes
-                `quiet=True` will show this message.
-            tip: if you are developing an intermediate/supporting library, it
-                is recommended to set `quiet=True`.
-        clear_preset:
-        kwargs: see `./logger.py > LoggingConfig`.
-    """
-    global _HAS_WELCOME_MESSAGE_SHOWN, STATUS
-    
-    if _is_ipython_mode():
-        import IPython  # noqa
-        from .pipeline import pipeline
-        pipeline.add(IPython, bprint, scope=True)
-    
-    lk.configure(clear_preset, **kwargs)
-    setattr(builtins, 'print', lk.log)
-    
-    if not quiet and not _HAS_WELCOME_MESSAGE_SHOWN:
-        _HAS_WELCOME_MESSAGE_SHOWN = True
-        
-        from .markup import _Counter
-        random_color = _Counter._get_random_bright_color  # noqa
-        color_pair = (random_color(), random_color())
-        slogan = _blend_text('♥ lk-logger is ready', color_pair)
-
-        # from random import choice
-        # color_pairs_group = (
-        #     ('#0a87ee', '#9294f0'),  # calm blue -> light blue
-        #     ('#2d34f1', '#9294f0'),  # ocean blue -> light blue
-        #     ('#ed3b3b', '#d08bf3'),  # rose red -> violet
-        #     ('#f38cfd', '#d08bf3'),  # light magenta -> violet
-        #     ('#f47fa4', '#f49364'),  # cold sandy -> camel tan
-        # )
-        # color_pair = choice(color_pairs_group)
-        # slogan = _blend_text('♥ lk-logger is ready', color_pair)
-        
-        # debug(slogan)
-        print(slogan, ':rsp')
-    
-    STATUS = 'enabled'
-
-
-def update(clear_preset=False, **kwargs) -> None:
-    lk.configure(clear_preset, **kwargs)
-
-
-def unload() -> None:
-    setattr(builtins, 'print', bprint)
-    global STATUS
-    STATUS = 'unloaded'
-
-
-def enable() -> None:
-    setattr(builtins, 'print', lk.log)
-    global STATUS
-    STATUS = 'enabled'
-
-
-def disable() -> None:
-    setattr(builtins, 'print', lambda *_, **__: None)
-    global STATUS
-    STATUS = 'disabled'
-
-
-# -----------------------------------------------------------------------------
-# other
-
-def start_ipython(
-        user_ns: t.Dict[str, t.Any] = None
-) -> None:
-    if _is_ipython_mode():
-        return
-    try:
-        import IPython  # noqa
-    except (ImportError, ModuleNotFoundError) as e:
-        print('ipython is not installed!', ':pv4')
-        raise e
-    else:
-        import sys
-        from IPython.core.getipython import get_ipython  # noqa
-        from IPython.terminal.ipapp import TerminalIPythonApp  # noqa
-        from rich.traceback import install
-        from .console import console
-        from .pipeline import pipeline
-    
-    pipeline.add(IPython, bprint, scope=True)
-    
-    backups = {
-        'lklogger_config': lk.config.copy(),
-        'sys.argv'       : sys.argv.copy(),
-    }
-    
-    setup(quiet=True, clear_preset=True,
-          show_source=False, show_funcname=False, show_varnames=False)
-    sys.argv = ['']  # avoid ipython to parse `sys.argv`.
-    
-    app = TerminalIPythonApp.instance(
-        user_ns={'print': lk.log, **(user_ns or {})}
-    )
-    app.initialize()
-    
-    # setup except hook for ipython
-    setattr(builtins, 'get_ipython', get_ipython)
-    install(console=console)
-    
-    app.start()
-    
-    # afterwards
-    lk.configure(**backups['lklogger_config'])
-    sys.argv = backups['sys.argv']
-    del backups
-
-
-# -----------------------------------------------------------------------------
-# neutral functions
-
-# DELETE
-def _blend_text(message: str, color_pair: t.Tuple[str, str]) -> str:
-    """ blend text from one color to another.
-    
-    source: [lib:rich_cli/__main__.py : blend_text()]
-    """
-    from rich.color import Color
-    from rich.text import Text
-    
-    color1, color2 = (Color.parse(x).triplet for x in color_pair)
-    r1, g1, b1 = color1
-    r2, g2, b2 = color2
-    dr = r2 - r1
-    dg = g2 - g1
-    db = b2 - b1
-    
-    text = Text(message)
-    size = len(text)
-    
-    for index in range(size):
-        blend = index / size
-        color = '#{}{}{}'.format(
-            f'{int(r1 + dr * blend):02X}',
-            f'{int(g1 + dg * blend):02X}',
-            f'{int(b1 + db * blend):02X}'
-        )
-        text.stylize(color, index, index + 1)
-    return text.markup
-
-
-def _is_ipython_mode() -> bool:
-    return getattr(builtins, '__IPYTHON__', False)
+import builtins
+import typing as t
+
+from ._print import bprint
+from ._print import debug  # noqa
+from .logger import lk
+
+STATUS = 'unloaded'  # literal['enabled', 'disabled', 'unloaded']
+_HAS_WELCOME_MESSAGE_SHOWN = False
+
+
+def setup(*, quiet=False, clear_preset=False, **kwargs) -> None:
+    """
+    args:
+        quiet:
+            True: show a welcome message in caller side.
+            False: do not show.
+
+            note: the welcome message is shown only once, if caller calls this
+                function multi times, only the first time when passes
+                `quiet=True` will show this message.
+            tip: if you are developing an intermediate/supporting library, it
+                is recommended to set `quiet=True`.
+        clear_preset:
+        kwargs: see `./logger.py > LoggingConfig`.
+    """
+    global _HAS_WELCOME_MESSAGE_SHOWN, STATUS
+    
+    if _is_ipython_mode():
+        import IPython  # noqa
+        from .pipeline import pipeline
+        pipeline.add(IPython, bprint, scope=True)
+    
+    lk.configure(clear_preset, **kwargs)
+    setattr(builtins, 'print', lk.log)
+    
+    if not quiet and not _HAS_WELCOME_MESSAGE_SHOWN:
+        _HAS_WELCOME_MESSAGE_SHOWN = True
+        
+        from .markup import _Counter
+        random_color = _Counter._get_random_bright_color  # noqa
+        color_pair = (random_color(), random_color())
+        slogan = _blend_text('♥ lk-logger is ready', color_pair)
+
+        # from random import choice
+        # color_pairs_group = (
+        #     ('#0a87ee', '#9294f0'),  # calm blue -> light blue
+        #     ('#2d34f1', '#9294f0'),  # ocean blue -> light blue
+        #     ('#ed3b3b', '#d08bf3'),  # rose red -> violet
+        #     ('#f38cfd', '#d08bf3'),  # light magenta -> violet
+        #     ('#f47fa4', '#f49364'),  # cold sandy -> camel tan
+        # )
+        # color_pair = choice(color_pairs_group)
+        # slogan = _blend_text('♥ lk-logger is ready', color_pair)
+        
+        # debug(slogan)
+        print(slogan, ':rsp')
+    
+    STATUS = 'enabled'
+
+
+def update(clear_preset=False, **kwargs) -> None:
+    lk.configure(clear_preset, **kwargs)
+
+
+def unload() -> None:
+    setattr(builtins, 'print', bprint)
+    global STATUS
+    STATUS = 'unloaded'
+
+
+def enable() -> None:
+    setattr(builtins, 'print', lk.log)
+    global STATUS
+    STATUS = 'enabled'
+
+
+def disable() -> None:
+    setattr(builtins, 'print', lambda *_, **__: None)
+    global STATUS
+    STATUS = 'disabled'
+
+
+# -----------------------------------------------------------------------------
+# other
+
+def start_ipython(
+        user_ns: t.Dict[str, t.Any] = None
+) -> None:
+    if _is_ipython_mode():
+        return
+    try:
+        import IPython  # noqa
+    except (ImportError, ModuleNotFoundError) as e:
+        print('ipython is not installed!', ':pv4')
+        raise e
+    else:
+        import sys
+        from IPython.core.getipython import get_ipython  # noqa
+        from IPython.terminal.ipapp import TerminalIPythonApp  # noqa
+        from rich.traceback import install
+        from .console import console
+        from .pipeline import pipeline
+    
+    pipeline.add(IPython, bprint, scope=True)
+    
+    backups = {
+        'lklogger_config': lk.config.copy(),
+        'sys.argv'       : sys.argv.copy(),
+    }
+    
+    setup(quiet=True, clear_preset=True,
+          show_source=False, show_funcname=False, show_varnames=False)
+    sys.argv = ['']  # avoid ipython to parse `sys.argv`.
+    
+    app = TerminalIPythonApp.instance(
+        user_ns={'print': lk.log, **(user_ns or {})}
+    )
+    app.initialize()
+    
+    # setup except hook for ipython
+    setattr(builtins, 'get_ipython', get_ipython)
+    install(console=console)
+    
+    app.start()
+    
+    # afterwards
+    lk.configure(**backups['lklogger_config'])
+    sys.argv = backups['sys.argv']
+    del backups
+
+
+# -----------------------------------------------------------------------------
+# neutral functions
+
+# DELETE
+def _blend_text(message: str, color_pair: t.Tuple[str, str]) -> str:
+    """ blend text from one color to another.
+    
+    source: [lib:rich_cli/__main__.py : blend_text()]
+    """
+    from rich.color import Color
+    from rich.text import Text
+    
+    color1, color2 = (Color.parse(x).triplet for x in color_pair)
+    r1, g1, b1 = color1
+    r2, g2, b2 = color2
+    dr = r2 - r1
+    dg = g2 - g1
+    db = b2 - b1
+    
+    text = Text(message)
+    size = len(text)
+    
+    for index in range(size):
+        blend = index / size
+        color = '#{}{}{}'.format(
+            f'{int(r1 + dr * blend):02X}',
+            f'{int(g1 + dg * blend):02X}',
+            f'{int(b1 + db * blend):02X}'
+        )
+        text.stylize(color, index, index + 1)
+    return text.markup
+
+
+def _is_ipython_mode() -> bool:
+    return getattr(builtins, '__IPYTHON__', False)
```

## lk_logger/frame_info.py

 * *Ordering differences only*

```diff
@@ -1,208 +1,208 @@
-import inspect
-import re
-import typing as t
-from os.path import abspath
-from os.path import exists
-from textwrap import dedent
-from types import FrameType
-
-from .scanner import get_all_blocks
-from .scanner import get_variables
-from .scanner.const import SUBSCRIPTABLE
-from .scanner.const import VARIABLE_NAME
-from .scanner.exceptions import ScanningError
-from .scanner.exceptions import UnresolvedCase
-
-
-class T:
-    VarNames = t.Tuple[str, ...]
-    SourceMap = t.Dict[str, t.Dict[int, VarNames]]
-
-
-class SourceMap:
-    _sourcemap: T.SourceMap
-    
-    def __init__(self):
-        self._sourcemap = {}
-    
-    def get_varnames(self, filepath: str, lineno: int) -> T.VarNames:
-        if filepath not in self._sourcemap:
-            self._indexing_filemap(filepath)
-        return self._sourcemap[filepath].get(lineno, ())
-    
-    def _indexing_filemap(self, filepath: str) -> None:
-        if filepath.startswith('<') or filepath.endswith('>') \
-                or not exists(filepath):
-            # see `FrameInfo > property filepath > docstring notice`
-            self._sourcemap.setdefault(filepath, {})
-            return
-        
-        def get_blocks(lines: t.Iterator[str]) -> t.Dict[int, T.VarNames]:
-            out = {}
-            for match in get_all_blocks(*lines):
-                text = match.fulltext.strip()
-                if not text:
-                    continue
-                if not text.startswith('print'):  # FIXME: this is not stable
-                    continue
-                try:
-                    varnames = _analyse_block(text)
-                    lineno = match.cursor.lineno + 1
-                    out[lineno] = tuple(varnames)
-                except ScanningError:
-                    raise ScanningError(
-                        match.cursor.lineno + 1, text,
-                        0, '<unknown>',
-                        f'<filepath: {filepath}>'
-                    )
-            return out
-        
-        def _analyse_block(text: str) -> t.List[str]:
-            varnames = []
-            try:
-                for element, type_ in get_variables(text):
-                    if type_ == VARIABLE_NAME:
-                        varnames.append(element)
-                    elif type_ == SUBSCRIPTABLE:
-                        varnames.append(_analyse_subscriptables(
-                            element, shorten_sub_substrings=True
-                        ))
-                    else:
-                        varnames.append('')
-            except UnresolvedCase:
-                varnames.clear()
-            finally:
-                return varnames
-        
-        _quotes_pattern_1 = re.compile(r'\'\'\'[\w\W]*\'\'\'|"""[\w\W]*"""')
-        _quotes_pattern_2 = re.compile(r'\'[^\']*\'|"[^"]*"')
-        
-        def _analyse_subscriptables(
-                text: str,
-                shorten_sub_substrings: bool = True,
-                threshold: int = 20
-        ) -> str:
-            """
-            shorten_sub_strings:
-                example:
-                    case 1: when captured a "varname" like "xxx('hello world')":
-                        if shorten_sub_strings is True:
-                            varname updated: "xxx('...')"
-                        if shorten_sub_strings is False:
-                            varname updated: "xxx('hello world')"
-                    case 2: when captured a "varname" like "xxx('''hello world\n
-                            hello world\nhello world\nhello world\nhello...''')"
-                            (which is a very long sentense):
-                        if shorten_sub_strings is True:
-                            varname updated: "xxx('...')"
-                        if shorten_sub_strings is False:
-                            varname updated: "xxx('''hello world\nhello world\n
-                                hello world\nhello world\nhello world\n...)"
-                note: the character threshold length to trigger shortening a
-                    string is adjustable, the default threshold is 10 chars and
-                    must with no line break in it.
-            """
-            if not shorten_sub_substrings:
-                return text
-            
-            backslash_mask = []
-            for i in re.findall(r'\\.', text):
-                backslash_mask.append(i)
-            if backslash_mask:
-                text = re.sub(r'\\.', '__BACKSLASK_MASK__', text)
-            
-            for i in set(_quotes_pattern_1.findall(text)):
-                if '\n' in i or len(i) > threshold:
-                    text = text.replace(i, '"""..."""')
-            
-            for i in set(_quotes_pattern_2.findall(text)):
-                if '\n' in i or len(i) > threshold:
-                    text = text.replace(i, '"..."')
-            
-            # restore backslashes
-            if backslash_mask:
-                for i in backslash_mask:
-                    text = text.replace('__BACKSLASK_MASK__', i, 1)
-                del backslash_mask
-            
-            text = re.sub(r'\s+', ' ', text)
-            #   note: this ^measure takes a side effect that it may replace
-            #   sequential whitespaces to one whitespace inside quote strings.
-            
-            return text
-        
-        with open(filepath, 'r', encoding='utf-8') as f:
-            self._sourcemap.setdefault(
-                filepath, get_blocks((x.rstrip('\n') for x in f.readlines()))
-            )
-
-
-sourcemap = SourceMap()
-
-
-class FrameInfo:
-    
-    def __init__(self, frame: FrameType):
-        self._frame = frame
-    
-    def __str__(self) -> str:
-        return self.info
-    
-    @property
-    def info(self) -> str:
-        return dedent(f'''
-            <FrameInfo object>
-                filepath: {self.filepath}
-                lineno: {self.lineno}
-                funcname: {self.funcname}
-        ''').rstrip()
-    
-    @property
-    def id(self) -> str:
-        return f'{self.filepath}:{self.lineno}'
-    
-    @property
-    def filepath(self) -> str:
-        """
-        notice:
-            - the returned value may be '<string>', '<unknown>' etc.
-            - (2023-05-22):
-                we do not use `__file__` anymore, because it may cause markup
-                analyser broken when the `__file__` is not real (for example
-                when caller passes `globals()` to `exec` function).
-                see also `examples/start_ipython.py : line 11`.
-            - in python 3.8, `co_filename` may be a relative path, so we need
-                to convert it to absolute.
-            - (2023-06-30):
-                the path may be unexisted, for example a kernel file using
-                `background_zmq_ipython` library.
-        """
-        # from ._print import debug
-        # debug(self._frame.f_code.co_filename,
-        #       self._frame.f_globals.get('__file__'))
-        return abspath(self._frame.f_code.co_filename).replace('\\', '/')
-    
-    @property
-    def lineno(self) -> int:
-        return self._frame.f_lineno
-    
-    @property
-    def indentation(self) -> int:
-        # https://stackoverflow.com/a/39172552
-        if x := inspect.getframeinfo(self._frame).code_context:
-            ctx = x[0]
-            return len(ctx) - len(ctx.lstrip())
-        return 0
-    
-    @property
-    def funcname(self) -> str:
-        return self._frame.f_code.co_name
-    
-    def collect_varnames(self) -> T.VarNames:
-        return sourcemap.get_varnames(self.filepath, self.lineno)
-    
-    def get_parent(self, traceback_level: int = 1) -> 'FrameInfo':
-        frame = self._frame
-        for _ in range(traceback_level):
-            frame = frame.f_back
-        return FrameInfo(frame)
+import inspect
+import re
+import typing as t
+from os.path import abspath
+from os.path import exists
+from textwrap import dedent
+from types import FrameType
+
+from .scanner import get_all_blocks
+from .scanner import get_variables
+from .scanner.const import SUBSCRIPTABLE
+from .scanner.const import VARIABLE_NAME
+from .scanner.exceptions import ScanningError
+from .scanner.exceptions import UnresolvedCase
+
+
+class T:
+    VarNames = t.Tuple[str, ...]
+    SourceMap = t.Dict[str, t.Dict[int, VarNames]]
+
+
+class SourceMap:
+    _sourcemap: T.SourceMap
+    
+    def __init__(self):
+        self._sourcemap = {}
+    
+    def get_varnames(self, filepath: str, lineno: int) -> T.VarNames:
+        if filepath not in self._sourcemap:
+            self._indexing_filemap(filepath)
+        return self._sourcemap[filepath].get(lineno, ())
+    
+    def _indexing_filemap(self, filepath: str) -> None:
+        if filepath.startswith('<') or filepath.endswith('>') \
+                or not exists(filepath):
+            # see `FrameInfo > property filepath > docstring notice`
+            self._sourcemap.setdefault(filepath, {})
+            return
+        
+        def get_blocks(lines: t.Iterator[str]) -> t.Dict[int, T.VarNames]:
+            out = {}
+            for match in get_all_blocks(*lines):
+                text = match.fulltext.strip()
+                if not text:
+                    continue
+                if not text.startswith('print'):  # FIXME: this is not stable
+                    continue
+                try:
+                    varnames = _analyse_block(text)
+                    lineno = match.cursor.lineno + 1
+                    out[lineno] = tuple(varnames)
+                except ScanningError:
+                    raise ScanningError(
+                        match.cursor.lineno + 1, text,
+                        0, '<unknown>',
+                        f'<filepath: {filepath}>'
+                    )
+            return out
+        
+        def _analyse_block(text: str) -> t.List[str]:
+            varnames = []
+            try:
+                for element, type_ in get_variables(text):
+                    if type_ == VARIABLE_NAME:
+                        varnames.append(element)
+                    elif type_ == SUBSCRIPTABLE:
+                        varnames.append(_analyse_subscriptables(
+                            element, shorten_sub_substrings=True
+                        ))
+                    else:
+                        varnames.append('')
+            except UnresolvedCase:
+                varnames.clear()
+            finally:
+                return varnames
+        
+        _quotes_pattern_1 = re.compile(r'\'\'\'[\w\W]*\'\'\'|"""[\w\W]*"""')
+        _quotes_pattern_2 = re.compile(r'\'[^\']*\'|"[^"]*"')
+        
+        def _analyse_subscriptables(
+                text: str,
+                shorten_sub_substrings: bool = True,
+                threshold: int = 20
+        ) -> str:
+            """
+            shorten_sub_strings:
+                example:
+                    case 1: when captured a "varname" like "xxx('hello world')":
+                        if shorten_sub_strings is True:
+                            varname updated: "xxx('...')"
+                        if shorten_sub_strings is False:
+                            varname updated: "xxx('hello world')"
+                    case 2: when captured a "varname" like "xxx('''hello world\n
+                            hello world\nhello world\nhello world\nhello...''')"
+                            (which is a very long sentense):
+                        if shorten_sub_strings is True:
+                            varname updated: "xxx('...')"
+                        if shorten_sub_strings is False:
+                            varname updated: "xxx('''hello world\nhello world\n
+                                hello world\nhello world\nhello world\n...)"
+                note: the character threshold length to trigger shortening a
+                    string is adjustable, the default threshold is 10 chars and
+                    must with no line break in it.
+            """
+            if not shorten_sub_substrings:
+                return text
+            
+            backslash_mask = []
+            for i in re.findall(r'\\.', text):
+                backslash_mask.append(i)
+            if backslash_mask:
+                text = re.sub(r'\\.', '__BACKSLASK_MASK__', text)
+            
+            for i in set(_quotes_pattern_1.findall(text)):
+                if '\n' in i or len(i) > threshold:
+                    text = text.replace(i, '"""..."""')
+            
+            for i in set(_quotes_pattern_2.findall(text)):
+                if '\n' in i or len(i) > threshold:
+                    text = text.replace(i, '"..."')
+            
+            # restore backslashes
+            if backslash_mask:
+                for i in backslash_mask:
+                    text = text.replace('__BACKSLASK_MASK__', i, 1)
+                del backslash_mask
+            
+            text = re.sub(r'\s+', ' ', text)
+            #   note: this ^measure takes a side effect that it may replace
+            #   sequential whitespaces to one whitespace inside quote strings.
+            
+            return text
+        
+        with open(filepath, 'r', encoding='utf-8') as f:
+            self._sourcemap.setdefault(
+                filepath, get_blocks((x.rstrip('\n') for x in f.readlines()))
+            )
+
+
+sourcemap = SourceMap()
+
+
+class FrameInfo:
+    
+    def __init__(self, frame: FrameType):
+        self._frame = frame
+    
+    def __str__(self) -> str:
+        return self.info
+    
+    @property
+    def info(self) -> str:
+        return dedent(f'''
+            <FrameInfo object>
+                filepath: {self.filepath}
+                lineno: {self.lineno}
+                funcname: {self.funcname}
+        ''').rstrip()
+    
+    @property
+    def id(self) -> str:
+        return f'{self.filepath}:{self.lineno}'
+    
+    @property
+    def filepath(self) -> str:
+        """
+        notice:
+            - the returned value may be '<string>', '<unknown>' etc.
+            - (2023-05-22):
+                we do not use `__file__` anymore, because it may cause markup
+                analyser broken when the `__file__` is not real (for example
+                when caller passes `globals()` to `exec` function).
+                see also `examples/start_ipython.py : line 11`.
+            - in python 3.8, `co_filename` may be a relative path, so we need
+                to convert it to absolute.
+            - (2023-06-30):
+                the path may be unexisted, for example a kernel file using
+                `background_zmq_ipython` library.
+        """
+        # from ._print import debug
+        # debug(self._frame.f_code.co_filename,
+        #       self._frame.f_globals.get('__file__'))
+        return abspath(self._frame.f_code.co_filename).replace('\\', '/')
+    
+    @property
+    def lineno(self) -> int:
+        return self._frame.f_lineno
+    
+    @property
+    def indentation(self) -> int:
+        # https://stackoverflow.com/a/39172552
+        if x := inspect.getframeinfo(self._frame).code_context:
+            ctx = x[0]
+            return len(ctx) - len(ctx.lstrip())
+        return 0
+    
+    @property
+    def funcname(self) -> str:
+        return self._frame.f_code.co_name
+    
+    def collect_varnames(self) -> T.VarNames:
+        return sourcemap.get_varnames(self.filepath, self.lineno)
+    
+    def get_parent(self, traceback_level: int = 1) -> 'FrameInfo':
+        frame = self._frame
+        for _ in range(traceback_level):
+            frame = frame.f_back
+        return FrameInfo(frame)
```

## lk_logger/message_builder.py

```diff
@@ -1,308 +1,308 @@
-import typing as t
-
-from rich.console import Group
-from rich.padding import Padding  # DELETE
-from rich.text import Text
-from rich.traceback import Traceback
-
-from ._print import debug  # noqa
-from .console import console
-from .markup import MarkMeaning
-from .markup import T as T0
-from .message_formatter import formatter
-
-
-class MessageStruct:
-    head: t.Optional[Text]
-    body: Text
-    _reverse: bool
-    
-    def __init__(self, head: t.Optional[Text], body: Text, reverse=False):
-        self.head = head if (head and len(head)) else None
-        self.body = body
-        self._reverse = reverse
-    
-    @property
-    def text(self) -> t.Union[Text, Group, Padding]:
-        if self.head:
-            if not self._reverse:
-                return Text.assemble(self.head, self.body)
-            else:
-                con_width = console.width - 2
-                # debug(con_width)
-                if con_width <= len(self.head):  # fallback
-                    if '\n' not in self.body:
-                        self.body.pad_left(2)
-                        return self.body
-                    else:
-                        lines = self.body.split()
-                        for x in lines:
-                            x.pad_left(2)
-                        return Group(*lines)
-                
-                if '\n' not in self.body:  # body is single line
-                    self.body.pad_left(2)
-                    if (x := con_width - len(self.head) - len(self.body)) > 0:
-                        self.body.append(' ' * x)
-                        out = Text.assemble(self.body, self.head)
-                    else:
-                        part_1 = Text.assemble(
-                            self.body[: con_width - len(self.head)], self.head
-                        )
-                        part_2 = Text.assemble(
-                            '  ',
-                            Text('└─', 'dim'),
-                            self.body[con_width - len(self.head) :],
-                        )
-                        out = Group(part_1, part_2)
-                else:  # body is multi-line
-                    lines = self.body.split('\n')
-                    for x in lines:
-                        x.pad_left(2)
-                    if (x := con_width - len(self.head) - len(lines[0])) > 0:
-                        part_1 = Text.assemble(lines[0], ' ' * x, self.head)
-                        part_2 = lines[1:]
-                        out = Group(part_1, *part_2)
-                    else:
-                        part_1 = Text.assemble(
-                            lines[0][: con_width - len(self.head)], self.head
-                        )
-                        part_2 = Text.assemble(
-                            '  ',
-                            Text('└─', 'dim'),
-                            lines[0][con_width - len(self.head) :],
-                        )
-                        part_3 = lines[1:]
-                        out = Group(part_1, part_2, *part_3)
-                # return Padding(out, (0, 0, 0, 2))
-                return out
-        else:
-            return self.body
-
-
-class T:
-    Args = t.Tuple[t.Any, ...]
-    Markup = T0.Markup
-    MarksMeaning = T0.MarksMeaning
-    MessageStruct = MessageStruct
-    RichText = Text
-    
-    Info = t.TypedDict(
-        'Info',
-        {
-            'file_path': str,
-            'function_name': str,
-            'is_external_lib': bool,
-            'line_number': str,
-            'variable_names': t.Tuple[str, ...],
-        },
-    )
-
-
-class MessageBuilder:
-    _separator_a: Text  # l2r sep
-    _separator_b: Text  # var sep
-    _separator_c: Text  # r2l sep
-    
-    def __init__(self, **kwargs) -> None:
-        self.update_config(**kwargs)
-    
-    def update_config(self, **config) -> None:
-        # https://fsymbols.com/signs/arrow/
-        self._separator_a = Text(' ⪢  ', 'bright_black')
-        #   alternatives: ➤ ⪢ >> ⮕ -> ~> | │
-        #   note: if we use single char, make sure there are two whitespaces
-        #       before it.
-        b = config.get('separator', ';   ')
-        self._separator_b = Text(b, 'bright_black')
-        self._separator_c = Text('  ⪡ ', 'bright_black')
-    
-    # -------------------------------------------------------------------------
-    
-    def compose(
-        self,
-        args: T.Args,
-        marks_meaning: T.MarksMeaning,
-        info: T.Info,
-        show_source: bool = True,
-        show_funcname: bool = True,
-        show_varnames: bool = False,
-        sourcemap_alignment: t.Literal['left', 'right'] = 'left',
-    ) -> T.MessageStruct:
-        show_source = (
-            show_source  # fmt:skip
-            and MarkMeaning.AGRESSIVE_PRUNE not in marks_meaning
-        )
-        show_funcname = (
-            show_funcname  # fmt:skip
-            and MarkMeaning.AGRESSIVE_PRUNE not in marks_meaning
-        )
-        show_varnames = (
-            show_varnames
-            and MarkMeaning.MODERATE_PRUNE not in marks_meaning
-            and MarkMeaning.AGRESSIVE_PRUNE not in marks_meaning
-        )
-        has_any_prune_scheme = (
-            MarkMeaning.MODERATE_PRUNE in marks_meaning
-            or MarkMeaning.AGRESSIVE_PRUNE in marks_meaning
-        )
-        
-        head = Text()
-        body = Text()
-        
-        # 1. source
-        if show_source:
-            head_part_1 = formatter.fmt_source(
-                info['file_path'],
-                info['line_number'],
-                is_external_lib=info['is_external_lib'],
-                fmt_width=True,
-            )
-            # head.append_text(
-            #     formatter.fmt_source(
-            #         info['file_path'],
-            #         info['line_number'],
-            #         is_external_lib=info['is_external_lib'],
-            #         fmt_width=True,
-            #     )
-            # )
-            # head.append_text(self._separator_a)
-        else:
-            head_part_1 = None
-        
-        # 2. funcname
-        if show_funcname:
-            assert info['function_name']
-            head_part_2 = formatter.fmt_funcname(
-                info['function_name'],
-                fmt_width=True,
-            )
-            # head.append_text(
-            #     formatter.fmt_funcname(
-            #         info['function_name'],
-            #         fmt_width=True,
-            #     )
-            # )
-            # head.append_text(self._separator_a)
-        else:
-            head_part_2 = None
-        
-        if head_part_1 or head_part_2:
-            if sourcemap_alignment == 'left':
-                head = Text.assemble(
-                    *(head_part_1 and (head_part_1, self._separator_a) or ()),
-                    *(head_part_2 and (head_part_2, self._separator_a) or ()),
-                )
-            else:
-                head = Text.assemble(
-                    *(head_part_2 and (self._separator_c, head_part_2) or ()),
-                    *(head_part_1 and (self._separator_c, head_part_1) or ()),
-                )
-        
-        # if not self._show_source and not self._show_funcname:
-        #     head = None
-        # if len(head) == 0:
-        #     head = None
-        
-        # ---------------------------------------------------------------------
-        
-        # 3. verbosity
-        if MarkMeaning.VERBOSITY in marks_meaning:
-            if not has_any_prune_scheme:
-                if x := formatter.fmt_level(
-                    marks_meaning[MarkMeaning.VERBOSITY],
-                ):
-                    body.append_text(x)
-                    body.append(' ')
-        
-        # 4. index
-        if MarkMeaning.RESET_INDEX in marks_meaning:
-            if not has_any_prune_scheme:
-                body.append_text(formatter.fmt_index(0))
-                body.append(' ')
-                if not args:
-                    args = ('[grey50]reset index[/]',)
-        elif MarkMeaning.SIMPLE_COUNTER in marks_meaning:
-            body.append_text(
-                formatter.fmt_index(marks_meaning[MarkMeaning.SIMPLE_COUNTER])
-            )
-            body.append(' ')
-        elif MarkMeaning.SCOPED_COUNTER in marks_meaning:
-            body.append_text(
-                formatter.fmt_scoped_index(
-                    *marks_meaning[MarkMeaning.SCOPED_COUNTER]
-                )
-            )
-            body.append(' ')
-        
-        # 5. timestamp
-        if timestamp := MarkMeaning.RESET_TIMER in marks_meaning:
-            if args:
-                args = (
-                    formatter.fmt_time(timestamp, color_s='green dim'),
-                    *args,
-                )
-            else:
-                args = (
-                    '[grey50]reset timer: [/] {}'.format(
-                        formatter.fmt_time(timestamp, color_s='green dim')
-                    ),
-                )
-        elif MarkMeaning.STOP_TIMER in marks_meaning:
-            start, end = marks_meaning[MarkMeaning.STOP_TIMER]
-            args = (formatter.fmt_time(start, end), *args)
-        elif MarkMeaning.TEMP_TIMER in marks_meaning:
-            if not has_any_prune_scheme:
-                start, end = marks_meaning[MarkMeaning.TEMP_TIMER]
-                args = ('[i]{}[/]'.format(formatter.fmt_time(start, end)), *args)
-        
-        # # 6. divider
-        # if MarkMeaning.DIVIDER_LINE in marks_meaning:
-        #     pattern = marks_meaning[MarkMeaning.DIVIDER_LINE]
-        #     message_elements.append(
-        #         formatter.fmt_divider(pattern)
-        #     )
-        #     message_elements.append(' ')
-        
-        # 7. arguments
-        # body.append_text(
-        #     formatter.fmt_message(
-        #         arguments=args,
-        #         varnames=info['variable_names'] if self._show_varnames else (),
-        #         rich=MarkMeaning.RICH_FORMAT in marks_meaning,
-        #         expand=MarkMeaning.EXPAND_MULTIPLE_LINES in marks_meaning,
-        #         separator=self._separator_b,
-        #         overall_style=marks_meaning.get(MarkMeaning.VERBOSITY, None),
-        #     )
-        # )
-        temp = formatter.fmt_message(
-            arguments=args,
-            varnames=info['variable_names'] if show_varnames else (),
-            rich=MarkMeaning.RICH_FORMAT in marks_meaning,
-            expand_level=marks_meaning.get(MarkMeaning.EXPAND_OBJECT, 0),
-            separator=self._separator_b,
-            overall_style=marks_meaning.get(MarkMeaning.VERBOSITY, None),
-        )
-        
-        # PERF: this is compromised design.
-        # 8. divider
-        if MarkMeaning.DIVIDER_LINE in marks_meaning:
-            pattern = marks_meaning[MarkMeaning.DIVIDER_LINE]
-            divider = formatter.fmt_divider(pattern, context=(head, body, temp))
-            body.append_text(divider)
-            body.append(' ')
-            body.append_text(temp)
-        else:
-            body.append_text(temp)
-        del temp
-        
-        return MessageStruct(
-            head, body, reverse=(sourcemap_alignment == 'right')
-        )
-    
-    @staticmethod
-    def compose_exception(e: BaseException, show_locals: bool) -> Traceback:
-        return formatter.fmt_exception(e, show_locals)
-
-
-builder = MessageBuilder()
+import typing as t
+
+from rich.console import Group
+from rich.padding import Padding  # DELETE
+from rich.text import Text
+from rich.traceback import Traceback
+
+from ._print import debug  # noqa
+from .console import console
+from .markup import MarkMeaning
+from .markup import T as T0
+from .message_formatter import formatter
+
+
+class MessageStruct:
+    head: t.Optional[Text]
+    body: Text
+    _reverse: bool
+    
+    def __init__(self, head: t.Optional[Text], body: Text, reverse=False):
+        self.head = head if (head and len(head)) else None
+        self.body = body
+        self._reverse = reverse
+    
+    @property
+    def text(self) -> t.Union[Text, Group, Padding]:
+        if self.head:
+            if not self._reverse:
+                return Text.assemble(self.head, self.body)
+            else:
+                con_width = console.width - 2
+                # debug(con_width)
+                if con_width <= len(self.head):  # fallback
+                    if '\n' not in self.body:
+                        self.body.pad_left(2)
+                        return self.body
+                    else:
+                        lines = self.body.split()
+                        for x in lines:
+                            x.pad_left(2)
+                        return Group(*lines)
+                
+                if '\n' not in self.body:  # body is single line
+                    self.body.pad_left(2)
+                    if (x := con_width - len(self.head) - len(self.body)) > 0:
+                        self.body.append(' ' * x)
+                        out = Text.assemble(self.body, self.head)
+                    else:
+                        part_1 = Text.assemble(
+                            self.body[: con_width - len(self.head)], self.head
+                        )
+                        part_2 = Text.assemble(
+                            '  ',
+                            Text('└─', 'dim'),
+                            self.body[con_width - len(self.head) :],
+                        )
+                        out = Group(part_1, part_2)
+                else:  # body is multi-line
+                    lines = self.body.split('\n')
+                    for x in lines:
+                        x.pad_left(2)
+                    if (x := con_width - len(self.head) - len(lines[0])) > 0:
+                        part_1 = Text.assemble(lines[0], ' ' * x, self.head)
+                        part_2 = lines[1:]
+                        out = Group(part_1, *part_2)
+                    else:
+                        part_1 = Text.assemble(
+                            lines[0][: con_width - len(self.head)], self.head
+                        )
+                        part_2 = Text.assemble(
+                            '  ',
+                            Text('└─', 'dim'),
+                            lines[0][con_width - len(self.head) :],
+                        )
+                        part_3 = lines[1:]
+                        out = Group(part_1, part_2, *part_3)
+                # return Padding(out, (0, 0, 0, 2))
+                return out
+        else:
+            return self.body
+
+
+class T:
+    Args = t.Tuple[t.Any, ...]
+    Markup = T0.Markup
+    MarksMeaning = T0.MarksMeaning
+    MessageStruct = MessageStruct
+    RichText = Text
+    
+    Info = t.TypedDict(
+        'Info',
+        {
+            'file_path': str,
+            'function_name': str,
+            'is_external_lib': bool,
+            'line_number': str,
+            'variable_names': t.Tuple[str, ...],
+        },
+    )
+
+
+class MessageBuilder:
+    _separator_a: Text  # l2r sep
+    _separator_b: Text  # var sep
+    _separator_c: Text  # r2l sep
+    
+    def __init__(self, **kwargs) -> None:
+        self.update_config(**kwargs)
+    
+    def update_config(self, **config) -> None:
+        # https://fsymbols.com/signs/arrow/
+        self._separator_a = Text(' >  ', 'bright_black')
+        #   alternatives: ➤ ⪢ > >> -> ~> | │
+        #   note: if we use single char, make sure there are two whitespaces \
+        #   after it.
+        b = config.get('separator', ';   ')
+        self._separator_b = Text(b, 'bright_black')
+        self._separator_c = Text('  < ', 'bright_black')
+    
+    # -------------------------------------------------------------------------
+    
+    def compose(
+        self,
+        args: T.Args,
+        marks_meaning: T.MarksMeaning,
+        info: T.Info,
+        show_source: bool = True,
+        show_funcname: bool = True,
+        show_varnames: bool = False,
+        sourcemap_alignment: t.Literal['left', 'right'] = 'left',
+    ) -> T.MessageStruct:
+        show_source = (
+            show_source  # fmt:skip
+            and MarkMeaning.AGRESSIVE_PRUNE not in marks_meaning
+        )
+        show_funcname = (
+            show_funcname  # fmt:skip
+            and MarkMeaning.AGRESSIVE_PRUNE not in marks_meaning
+        )
+        show_varnames = (
+            show_varnames
+            and MarkMeaning.MODERATE_PRUNE not in marks_meaning
+            and MarkMeaning.AGRESSIVE_PRUNE not in marks_meaning
+        )
+        has_any_prune_scheme = (
+            MarkMeaning.MODERATE_PRUNE in marks_meaning
+            or MarkMeaning.AGRESSIVE_PRUNE in marks_meaning
+        )
+        
+        head = Text()
+        body = Text()
+        
+        # 1. source
+        if show_source:
+            head_part_1 = formatter.fmt_source(
+                info['file_path'],
+                info['line_number'],
+                is_external_lib=info['is_external_lib'],
+                fmt_width=True,
+            )
+            # head.append_text(
+            #     formatter.fmt_source(
+            #         info['file_path'],
+            #         info['line_number'],
+            #         is_external_lib=info['is_external_lib'],
+            #         fmt_width=True,
+            #     )
+            # )
+            # head.append_text(self._separator_a)
+        else:
+            head_part_1 = None
+        
+        # 2. funcname
+        if show_funcname:
+            assert info['function_name']
+            head_part_2 = formatter.fmt_funcname(
+                info['function_name'],
+                fmt_width=True,
+            )
+            # head.append_text(
+            #     formatter.fmt_funcname(
+            #         info['function_name'],
+            #         fmt_width=True,
+            #     )
+            # )
+            # head.append_text(self._separator_a)
+        else:
+            head_part_2 = None
+        
+        if head_part_1 or head_part_2:
+            if sourcemap_alignment == 'left':
+                head = Text.assemble(
+                    *(head_part_1 and (head_part_1, self._separator_a) or ()),
+                    *(head_part_2 and (head_part_2, self._separator_a) or ()),
+                )
+            else:
+                head = Text.assemble(
+                    *(head_part_2 and (self._separator_c, head_part_2) or ()),
+                    *(head_part_1 and (self._separator_c, head_part_1) or ()),
+                )
+        
+        # if not self._show_source and not self._show_funcname:
+        #     head = None
+        # if len(head) == 0:
+        #     head = None
+        
+        # ---------------------------------------------------------------------
+        
+        # 3. verbosity
+        if MarkMeaning.VERBOSITY in marks_meaning:
+            if not has_any_prune_scheme:
+                if x := formatter.fmt_level(
+                    marks_meaning[MarkMeaning.VERBOSITY],
+                ):
+                    body.append_text(x)
+                    body.append(' ')
+        
+        # 4. index
+        if MarkMeaning.RESET_INDEX in marks_meaning:
+            if not has_any_prune_scheme:
+                body.append_text(formatter.fmt_index(0))
+                body.append(' ')
+                if not args:
+                    args = ('[grey50]reset index[/]',)
+        elif MarkMeaning.SIMPLE_COUNTER in marks_meaning:
+            body.append_text(
+                formatter.fmt_index(marks_meaning[MarkMeaning.SIMPLE_COUNTER])
+            )
+            body.append(' ')
+        elif MarkMeaning.SCOPED_COUNTER in marks_meaning:
+            body.append_text(
+                formatter.fmt_scoped_index(
+                    *marks_meaning[MarkMeaning.SCOPED_COUNTER]
+                )
+            )
+            body.append(' ')
+        
+        # 5. timestamp
+        if timestamp := MarkMeaning.RESET_TIMER in marks_meaning:
+            if args:
+                args = (
+                    formatter.fmt_time(timestamp, color_s='green dim'),
+                    *args,
+                )
+            else:
+                args = (
+                    '[grey50]reset timer: [/] {}'.format(
+                        formatter.fmt_time(timestamp, color_s='green dim')
+                    ),
+                )
+        elif MarkMeaning.STOP_TIMER in marks_meaning:
+            start, end = marks_meaning[MarkMeaning.STOP_TIMER]
+            args = (formatter.fmt_time(start, end), *args)
+        elif MarkMeaning.TEMP_TIMER in marks_meaning:
+            if not has_any_prune_scheme:
+                start, end = marks_meaning[MarkMeaning.TEMP_TIMER]
+                args = ('[i]{}[/]'.format(formatter.fmt_time(start, end)), *args)
+        
+        # # 6. divider
+        # if MarkMeaning.DIVIDER_LINE in marks_meaning:
+        #     pattern = marks_meaning[MarkMeaning.DIVIDER_LINE]
+        #     message_elements.append(
+        #         formatter.fmt_divider(pattern)
+        #     )
+        #     message_elements.append(' ')
+        
+        # 7. arguments
+        # body.append_text(
+        #     formatter.fmt_message(
+        #         arguments=args,
+        #         varnames=info['variable_names'] if self._show_varnames else (),
+        #         rich=MarkMeaning.RICH_FORMAT in marks_meaning,
+        #         expand=MarkMeaning.EXPAND_MULTIPLE_LINES in marks_meaning,
+        #         separator=self._separator_b,
+        #         overall_style=marks_meaning.get(MarkMeaning.VERBOSITY, None),
+        #     )
+        # )
+        temp = formatter.fmt_message(
+            arguments=args,
+            varnames=info['variable_names'] if show_varnames else (),
+            rich=MarkMeaning.RICH_FORMAT in marks_meaning,
+            expand_level=marks_meaning.get(MarkMeaning.EXPAND_OBJECT, 0),
+            separator=self._separator_b,
+            overall_style=marks_meaning.get(MarkMeaning.VERBOSITY, None),
+        )
+        
+        # PERF: this is compromised design.
+        # 8. divider
+        if MarkMeaning.DIVIDER_LINE in marks_meaning:
+            pattern = marks_meaning[MarkMeaning.DIVIDER_LINE]
+            divider = formatter.fmt_divider(pattern, context=(head, body, temp))
+            body.append_text(divider)
+            body.append(' ')
+            body.append_text(temp)
+        else:
+            body.append_text(temp)
+        del temp
+        
+        return MessageStruct(
+            head, body, reverse=(sourcemap_alignment == 'right')
+        )
+    
+    @staticmethod
+    def compose_exception(e: BaseException, show_locals: bool) -> Traceback:
+        return formatter.fmt_exception(e, show_locals)
+
+
+builder = MessageBuilder()
```

## lk_logger/pipeline.py

 * *Ordering differences only*

```diff
@@ -1,97 +1,97 @@
-from __future__ import annotations
-
-import typing as t
-from os import name as _os_name
-from os.path import abspath
-from os.path import dirname
-
-from ._print import bprint
-from ._print import debug  # noqa
-
-
-class T:
-    PrintFunc = t.Optional[t.Callable]
-    Cache = t.Dict[str, PrintFunc]
-    PipeLines = t.NamedTuple('PipeLines2', (
-        ('abspath', t.Dict[str, PrintFunc]),
-        ('libname', t.Dict[str, PrintFunc]),  # TODO: not used
-    ))
-    ''' e.g.
-        ('abspath': {'/Users/.../python/3.10/lib/python3.10/traceback.py':
-                     <function ...>, ...},
-         'libpath': {'[tornado]': <function bprint at 0x000001D1C1D1B8B0>, ...})
-    '''
-
-
-class Pipeline:
-    _cache: T.Cache
-    _lines: T.PipeLines
-    
-    def __init__(self):
-        self._cache = {}
-        self._lines = T.PipeLines({}, {})
-    
-    def dump_list(self) -> t.List[str]:
-        return list(self._lines.abspath.keys())
-    
-    def add(self,
-            x: t.Union[str, object],
-            prt: t.Optional[t.Callable] = bprint,
-            scope=False) -> None:
-        if isinstance(x, str):
-            if x.startswith('['):
-                path = x
-            else:
-                path = _normpath(x)
-        else:
-            # x is a package or a module
-            # debug(x, x.__file__)
-            path = _normpath(x.__file__)
-            if scope:
-                path = dirname(path)
-        # debug('add path to pipeline', path)
-        if prt is None:
-            prt = _mute_print
-        if path.startswith('['):
-            self._lines.libname[path] = prt
-        else:
-            self._lines.abspath[path] = prt
-        self._cache[path] = prt
-    
-    def get(self, path: str) -> T.PrintFunc:
-        """
-        get proper print function for the given path.
-        """
-        # the path is an absolute path.
-        path = _normpath(path)
-        # debug(path)
-        if path in self._cache:
-            # debug('path in cache', path, self._cache[path])
-            return self._cache[path]
-        for root, prt in self._lines.abspath.items():
-            if path.startswith(root):
-                self._cache[path] = prt
-                # debug('use custom print', path)
-                return prt
-        self._cache[path] = None
-        return None
-
-
-class _MutePrint:
-    def __call__(self, *_, **__):
-        pass
-
-
-_mute_print = _MutePrint()
-
-_is_win = _os_name == 'nt'
-
-
-def _normpath(path: str) -> str:
-    path = abspath(path)
-    if _is_win:
-        path = path.replace('\\', '/')
-    return path
-
-
-pipeline = Pipeline()
+from __future__ import annotations
+
+import typing as t
+from os import name as _os_name
+from os.path import abspath
+from os.path import dirname
+
+from ._print import bprint
+from ._print import debug  # noqa
+
+
+class T:
+    PrintFunc = t.Optional[t.Callable]
+    Cache = t.Dict[str, PrintFunc]
+    PipeLines = t.NamedTuple('PipeLines2', (
+        ('abspath', t.Dict[str, PrintFunc]),
+        ('libname', t.Dict[str, PrintFunc]),  # TODO: not used
+    ))
+    ''' e.g.
+        ('abspath': {'/Users/.../python/3.10/lib/python3.10/traceback.py':
+                     <function ...>, ...},
+         'libpath': {'[tornado]': <function bprint at 0x000001D1C1D1B8B0>, ...})
+    '''
+
+
+class Pipeline:
+    _cache: T.Cache
+    _lines: T.PipeLines
+    
+    def __init__(self):
+        self._cache = {}
+        self._lines = T.PipeLines({}, {})
+    
+    def dump_list(self) -> t.List[str]:
+        return list(self._lines.abspath.keys())
+    
+    def add(self,
+            x: t.Union[str, object],
+            prt: t.Optional[t.Callable] = bprint,
+            scope=False) -> None:
+        if isinstance(x, str):
+            if x.startswith('['):
+                path = x
+            else:
+                path = _normpath(x)
+        else:
+            # x is a package or a module
+            # debug(x, x.__file__)
+            path = _normpath(x.__file__)
+            if scope:
+                path = dirname(path)
+        # debug('add path to pipeline', path)
+        if prt is None:
+            prt = _mute_print
+        if path.startswith('['):
+            self._lines.libname[path] = prt
+        else:
+            self._lines.abspath[path] = prt
+        self._cache[path] = prt
+    
+    def get(self, path: str) -> T.PrintFunc:
+        """
+        get proper print function for the given path.
+        """
+        # the path is an absolute path.
+        path = _normpath(path)
+        # debug(path)
+        if path in self._cache:
+            # debug('path in cache', path, self._cache[path])
+            return self._cache[path]
+        for root, prt in self._lines.abspath.items():
+            if path.startswith(root):
+                self._cache[path] = prt
+                # debug('use custom print', path)
+                return prt
+        self._cache[path] = None
+        return None
+
+
+class _MutePrint:
+    def __call__(self, *_, **__):
+        pass
+
+
+_mute_print = _MutePrint()
+
+_is_win = _os_name == 'nt'
+
+
+def _normpath(path: str) -> str:
+    path = abspath(path)
+    if _is_win:
+        path = path.replace('\\', '/')
+    return path
+
+
+pipeline = Pipeline()
```

## lk_logger/scanner/__init__.py

 * *Ordering differences only*

```diff
@@ -1,2 +1,2 @@
-from .scanner import get_all_blocks
-from .scanner import get_variables
+from .scanner import get_all_blocks
+from .scanner import get_variables
```

## lk_logger/scanner/analyser.py

 * *Ordering differences only*

```diff
@@ -1,160 +1,160 @@
-from contextlib import contextmanager
-
-from .const import *
-from .symbols import Symbols
-
-
-class Analyser:
-    
-    def __init__(self, end='\n'):
-        self.end = end
-        self.last_char = None
-        self.last_last_char = None
-        self.safe_period = 0
-        self.symbols = Symbols()
-    
-    def reset(self):
-        self.symbols.clear()
-    
-    @contextmanager
-    def trace_index(self, index):
-        """
-        This is an optional feature. When we use:
-            with my_analyser.trace_index(index):
-                my_analyser.analyse(some_char)
-        The `self.symbols.nested_struct` property will be available to use.
-        """
-        with self.symbols.trace_index(index):
-            yield self
-    
-    def analyse(self, char):
-        last_last_char, last_char = self.last_last_char, self.last_char
-        symbols = self.symbols
-        ret_code = INIT
-        
-        if symbols:
-            _, target_char, token = symbols.last_symbol
-            
-            if token == TOKEN_A00:
-                if char == target_char:
-                    symbols.consume()
-                elif char in PAIRED_SYMBOLS:
-                    symbols.append(*PAIRED_SYMBOLS[char])
-                else:
-                    pass
-            elif token == TOKEN_B00:
-                if char == '\\':
-                    symbols.append(*PAIRED_SYMBOLS[char])
-                elif last_last_char is not None:
-                    if last_char is not None:
-                        # cases:
-                        #   xxx'
-                        #   xxx''
-                        #   xxx'xxx
-                        if char == target_char:
-                            if last_last_char == last_char == char:
-                                # case: xxx'' + ' = xxx'''
-                                symbols.update(target_char, TOKEN_B21)
-                            elif last_char == char:
-                                # case: xxx' + ' = xxx''
-                                pass
-                            else:
-                                # case: xxx'xxx + ' = xxx'xxx'
-                                symbols.update(target_char, TOKEN_B10)
-                                symbols.consume()
-                        else:
-                            if last_last_char == last_char == target_char:
-                                # case: xxx'' + x = xxx''x
-                                symbols.update(target_char, TOKEN_B10)
-                                symbols.consume(-1)  # MARK: 20210901190803
-                                #   notice: here we are consuming LAST_CHAR's
-                                #   case, not current char's case. this is the
-                                #   ONLY position that current char doesn't get
-                                #   consumed, we need to recall `main_analyse`
-                                #   to consume it forcely.
-                                return self.analyse(char)
-                    else:
-                        ret_code = UNREACHABLE_CASE
-                else:
-                    if last_char is not None:
-                        # case: '
-                        assert last_char == target_char
-                        if char == target_char:
-                            # case: ' + ' = ''
-                            pass
-                        else:
-                            # case: ' + x = 'x
-                            symbols.update(target_char, TOKEN_B10)
-                    else:
-                        ret_code = UNREACHABLE_CASE
-            elif token == TOKEN_B10:
-                if char == target_char:
-                    symbols.consume()
-                elif char == '\\':
-                    symbols.append(*PAIRED_SYMBOLS[char])
-                else:
-                    pass
-            elif token == TOKEN_B20:
-                # the TOKEN_B2 is a virtual node and has no instances in
-                # this method. we could only see its sub node instances
-                # (TOKEN_B21, TOKEN_B22).
-                ret_code = UNREACHABLE_CASE
-            elif token == TOKEN_B21:
-                self.safe_period += 1
-                if self.safe_period == 1:
-                    if char == '\\':
-                        self.safe_period = 0
-                        symbols.update(target_char, TOKEN_B22)
-                        symbols.append(*PAIRED_SYMBOLS[char])
-                    else:
-                        pass
-                elif self.safe_period == 2:
-                    self.safe_period = 0
-                    symbols.update(target_char, TOKEN_B22)
-                    if char == '\\':
-                        symbols.append(*PAIRED_SYMBOLS[char])
-                    else:
-                        pass
-                else:
-                    ret_code = UNREACHABLE_CASE
-            elif token == TOKEN_B22:
-                # cases:
-                #   xxx'''x'
-                #   xxx'''xx
-                #   xxx''''x
-                #   xxx'''''
-                # assert last_last_char is not None
-                # assert last_char is not None
-                if last_last_char == last_char == char == target_char:
-                    # case: xxx''''' + ' = xxx''''''
-                    symbols.consume()
-                elif char == '\\':
-                    symbols.append(*PAIRED_SYMBOLS[char])
-                else:
-                    pass
-            elif token == TOKEN_C00:
-                symbols.consume()
-            elif token == TOKEN_D00:
-                symbols.consume()
-                ret_code = BREAK_OUT
-            else:
-                ret_code = UNREACHABLE_CASE
-        else:
-            if char in PAIRED_SYMBOLS:
-                if char == '#':
-                    ret_code = BREAK_OUT
-                else:
-                    symbols.append(*PAIRED_SYMBOLS[char])
-            elif char == self.end:
-                ret_code = SUBMITTABLE
-        
-        self.last_last_char, self.last_char = self.last_char, char
-        
-        if ret_code == INIT:
-            if self.symbols:
-                ret_code = CONTINUE
-            elif char == self.end:
-                ret_code = SUBMITTABLE
-            else:
-                ret_code = CONTINUE
-        return ret_code
+from contextlib import contextmanager
+
+from .const import *
+from .symbols import Symbols
+
+
+class Analyser:
+    
+    def __init__(self, end='\n'):
+        self.end = end
+        self.last_char = None
+        self.last_last_char = None
+        self.safe_period = 0
+        self.symbols = Symbols()
+    
+    def reset(self):
+        self.symbols.clear()
+    
+    @contextmanager
+    def trace_index(self, index):
+        """
+        This is an optional feature. When we use:
+            with my_analyser.trace_index(index):
+                my_analyser.analyse(some_char)
+        The `self.symbols.nested_struct` property will be available to use.
+        """
+        with self.symbols.trace_index(index):
+            yield self
+    
+    def analyse(self, char):
+        last_last_char, last_char = self.last_last_char, self.last_char
+        symbols = self.symbols
+        ret_code = INIT
+        
+        if symbols:
+            _, target_char, token = symbols.last_symbol
+            
+            if token == TOKEN_A00:
+                if char == target_char:
+                    symbols.consume()
+                elif char in PAIRED_SYMBOLS:
+                    symbols.append(*PAIRED_SYMBOLS[char])
+                else:
+                    pass
+            elif token == TOKEN_B00:
+                if char == '\\':
+                    symbols.append(*PAIRED_SYMBOLS[char])
+                elif last_last_char is not None:
+                    if last_char is not None:
+                        # cases:
+                        #   xxx'
+                        #   xxx''
+                        #   xxx'xxx
+                        if char == target_char:
+                            if last_last_char == last_char == char:
+                                # case: xxx'' + ' = xxx'''
+                                symbols.update(target_char, TOKEN_B21)
+                            elif last_char == char:
+                                # case: xxx' + ' = xxx''
+                                pass
+                            else:
+                                # case: xxx'xxx + ' = xxx'xxx'
+                                symbols.update(target_char, TOKEN_B10)
+                                symbols.consume()
+                        else:
+                            if last_last_char == last_char == target_char:
+                                # case: xxx'' + x = xxx''x
+                                symbols.update(target_char, TOKEN_B10)
+                                symbols.consume(-1)  # MARK: 20210901190803
+                                #   notice: here we are consuming LAST_CHAR's
+                                #   case, not current char's case. this is the
+                                #   ONLY position that current char doesn't get
+                                #   consumed, we need to recall `main_analyse`
+                                #   to consume it forcely.
+                                return self.analyse(char)
+                    else:
+                        ret_code = UNREACHABLE_CASE
+                else:
+                    if last_char is not None:
+                        # case: '
+                        assert last_char == target_char
+                        if char == target_char:
+                            # case: ' + ' = ''
+                            pass
+                        else:
+                            # case: ' + x = 'x
+                            symbols.update(target_char, TOKEN_B10)
+                    else:
+                        ret_code = UNREACHABLE_CASE
+            elif token == TOKEN_B10:
+                if char == target_char:
+                    symbols.consume()
+                elif char == '\\':
+                    symbols.append(*PAIRED_SYMBOLS[char])
+                else:
+                    pass
+            elif token == TOKEN_B20:
+                # the TOKEN_B2 is a virtual node and has no instances in
+                # this method. we could only see its sub node instances
+                # (TOKEN_B21, TOKEN_B22).
+                ret_code = UNREACHABLE_CASE
+            elif token == TOKEN_B21:
+                self.safe_period += 1
+                if self.safe_period == 1:
+                    if char == '\\':
+                        self.safe_period = 0
+                        symbols.update(target_char, TOKEN_B22)
+                        symbols.append(*PAIRED_SYMBOLS[char])
+                    else:
+                        pass
+                elif self.safe_period == 2:
+                    self.safe_period = 0
+                    symbols.update(target_char, TOKEN_B22)
+                    if char == '\\':
+                        symbols.append(*PAIRED_SYMBOLS[char])
+                    else:
+                        pass
+                else:
+                    ret_code = UNREACHABLE_CASE
+            elif token == TOKEN_B22:
+                # cases:
+                #   xxx'''x'
+                #   xxx'''xx
+                #   xxx''''x
+                #   xxx'''''
+                # assert last_last_char is not None
+                # assert last_char is not None
+                if last_last_char == last_char == char == target_char:
+                    # case: xxx''''' + ' = xxx''''''
+                    symbols.consume()
+                elif char == '\\':
+                    symbols.append(*PAIRED_SYMBOLS[char])
+                else:
+                    pass
+            elif token == TOKEN_C00:
+                symbols.consume()
+            elif token == TOKEN_D00:
+                symbols.consume()
+                ret_code = BREAK_OUT
+            else:
+                ret_code = UNREACHABLE_CASE
+        else:
+            if char in PAIRED_SYMBOLS:
+                if char == '#':
+                    ret_code = BREAK_OUT
+                else:
+                    symbols.append(*PAIRED_SYMBOLS[char])
+            elif char == self.end:
+                ret_code = SUBMITTABLE
+        
+        self.last_last_char, self.last_char = self.last_char, char
+        
+        if ret_code == INIT:
+            if self.symbols:
+                ret_code = CONTINUE
+            elif char == self.end:
+                ret_code = SUBMITTABLE
+            else:
+                ret_code = CONTINUE
+        return ret_code
```

## lk_logger/scanner/const.py

 * *Ordering differences only*

```diff
@@ -1,36 +1,36 @@
-# TOKENS
-TOKEN_A00 = 0x000  # ( <==> )
-TOKEN_B00 = 0x001  # ' <==> ' | " <==> " | ''' <==> ''' | """ <==> """
-TOKEN_B10 = 0x011  # ' <==> ' | " <==> "
-TOKEN_B20 = 0x012  # ''' <==> ''' | """ <==> """
-TOKEN_B21 = 0x121  # '''?? | """?? (safe period)
-TOKEN_B22 = 0x122  # '''xx | """xx (ridden off safe period)
-TOKEN_C00 = 0x003  # \ <==> *
-TOKEN_D00 = 0x004  # # <==> ***
-
-# RETURN CODE
-INIT = 0
-SUBMITTABLE = 1
-CONTINUE = 2
-BREAK_OUT = 3
-UNREACHABLE_CASE = 4
-
-# scanner.py > func:get_variables
-VARIABLE_NAME = 0  # varname. e.g. 'a', 'b', 'c'
-SUBSCRIPTABLE = 1  # varname with '(' or '[' or '{'. e.g. 'requests.get(...)'
-QUOTED_STRING = 2  # qstring. e.g. '"hello world"'
-SIMPLE_NUMBER = 3  # simple int or float. e.g. 1, 2, 3, 1.0, 2.0, 3.0, and
-#   negative number. but not support 1E10, 1., 2., 3., (they are treated as
-#   VARIABLE_NAME)
-NESTED_STRUCT = 4  # starts with '(' or '[' or '{'
-
-# PAIRED SYMBOLS
-PAIRED_SYMBOLS = {
-    '(' : (')', TOKEN_A00),
-    '[' : (']', TOKEN_A00),
-    '{' : ('}', TOKEN_A00),
-    '"' : ('"', TOKEN_B00),
-    "'" : ("'", TOKEN_B00),
-    '\\': ('*', TOKEN_C00),
-    '#' : ('*', TOKEN_D00),
-}
+# TOKENS
+TOKEN_A00 = 0x000  # ( <==> )
+TOKEN_B00 = 0x001  # ' <==> ' | " <==> " | ''' <==> ''' | """ <==> """
+TOKEN_B10 = 0x011  # ' <==> ' | " <==> "
+TOKEN_B20 = 0x012  # ''' <==> ''' | """ <==> """
+TOKEN_B21 = 0x121  # '''?? | """?? (safe period)
+TOKEN_B22 = 0x122  # '''xx | """xx (ridden off safe period)
+TOKEN_C00 = 0x003  # \ <==> *
+TOKEN_D00 = 0x004  # # <==> ***
+
+# RETURN CODE
+INIT = 0
+SUBMITTABLE = 1
+CONTINUE = 2
+BREAK_OUT = 3
+UNREACHABLE_CASE = 4
+
+# scanner.py > func:get_variables
+VARIABLE_NAME = 0  # varname. e.g. 'a', 'b', 'c'
+SUBSCRIPTABLE = 1  # varname with '(' or '[' or '{'. e.g. 'requests.get(...)'
+QUOTED_STRING = 2  # qstring. e.g. '"hello world"'
+SIMPLE_NUMBER = 3  # simple int or float. e.g. 1, 2, 3, 1.0, 2.0, 3.0, and
+#   negative number. but not support 1E10, 1., 2., 3., (they are treated as
+#   VARIABLE_NAME)
+NESTED_STRUCT = 4  # starts with '(' or '[' or '{'
+
+# PAIRED SYMBOLS
+PAIRED_SYMBOLS = {
+    '(' : (')', TOKEN_A00),
+    '[' : (']', TOKEN_A00),
+    '{' : ('}', TOKEN_A00),
+    '"' : ('"', TOKEN_B00),
+    "'" : ("'", TOKEN_B00),
+    '\\': ('*', TOKEN_C00),
+    '#' : ('*', TOKEN_D00),
+}
```

## lk_logger/scanner/scanner.py

 * *Ordering differences only*

```diff
@@ -1,267 +1,267 @@
-"""
-README:
-    `docs/what-is-block.md`
-"""
-from collections import namedtuple
-from re import compile
-from string import whitespace
-
-from .analyser import Analyser
-from .const import *
-from .exceptions import *
-from .typehint import *
-from .._print import debug  # noqa
-
-
-def get_all_blocks(*lines: str, end_mark='\n'):
-    """ Get ALL COMPLETE text blocks.
-    
-    Scanning lines and try to merge the adjacent incomplete lines. If the
-    merged result is a complete block (type: `list[str]`), yield it to the
-    caller.
-    
-    Args:
-        lines:
-        end_mark:
-            warnings:
-                1. whatever end_mark's value is, it is alwayse be measured as
-                   one-character width.
-                2. `params:lines:each` mustn't end with end_mark, i.e.
-                    assert(all(not x.rstrip().endswith(end_mark)) for x in lines)
-    """
-    assert all(bool(not x.rstrip().endswith(end_mark)) for x in lines), (
-        f'Please make sure each of lines must not end with "{end_mark}". '
-        f'(You need to strip them before calling this function)'
-    )
-    assert len(end_mark) == 1
-    
-    analyser = Analyser(end=end_mark)
-    #   IMPROVEMENT: if `lines:each` contains '\n', which means we can't pass
-    #       '\n' to `params:end`, we can use `end=None` instead.
-    #       (see reactions at MARK@20210901173115.)
-    cursor = Cursor()
-    fulltext = end_mark.join(lines)
-    last_submit_idx = 0
-    
-    def _submit():
-        nonlocal last_submit_idx
-        yield Match(cursor.snapshot(last_submit_idx),
-                    fulltext[last_submit_idx:cursor.x],
-                    analyser.symbols.matches_nest)
-        analyser.reset()
-        last_submit_idx = cursor.x + 1
-    
-    for line in lines:
-        cursor.update_lineno()
-        
-        line_ = line + end_mark
-        for char in line_:  # MARK: 20210901173115
-            cursor.update_charno()
-            # _debug(cursor.i, line, cursor.j, char, analyser.symbols)
-            
-            with analyser.trace_index(cursor.x):
-                ret_code = analyser.analyse(char)
-            
-            if ret_code == SUBMITTABLE:
-                yield from _submit()
-                # break
-            elif ret_code == CONTINUE:
-                continue
-            elif ret_code == BREAK_OUT:
-                # `BREAK_OUT` is recognized as continuously sending `CONTINUE`
-                # command, until we meet an `end_mark` then break.
-                while char != end_mark:
-                    cursor.update_charno()
-                    char = line_[cursor.charno]
-                    # debug(cursor.charno, char)
-                yield from _submit()
-                break
-            elif ret_code == UNREACHABLE_CASE:
-                raise UnreachableCase(
-                    cursor.i, line, cursor.j, char, analyser.symbols
-                )
-            else:
-                raise UnexpectedReturnCode(ret_code)
-
-
-def get_variables(line: str):
-    """
-
-    Workflow:
-        1. single_line = 'A, (B, C)'
-        2. split by comma: ['A', '(B', 'C)']
-        3. analyse each element, try to merge every mergable parts (based on
-           pairable symbols): ['A', '(B, C)']
-        4. now we know there are two elements in single_line: `A` and `(B, C)`
-    """
-    caller_pattern = compile(r'^([.\w]+)[(\[{]')  # matching: 'requests.get('
-    kwargs_pattern = compile(r'^\w+ *=')  # matching: 'a=1'
-    lambda_pattern = compile(r'^lambda ')  # matching: 'lambda *_, **__: ...'
-    nested_pattern = compile(r'^[(\[{]')  # matching: '(...', '[...', '{...'
-    number_pattern = compile(r'^-?\d+(?:\.\d+)?$')  # matching: '123', '-123'
-    quotes_pattern = compile(r'^[bfru]*[\'"]')  # matching: '"hello', 'b"hello'
-    walrus_pattern = compile(r'^(\w+) *:=')  # mathcing: 'x := 12'
-    
-    for match0 in get_all_blocks(line):
-        start, end = match0.span()  # exterior brackets span
-        line = line[start + 1:end].rstrip(whitespace + ',')
-        #   `~.rstrip(...)`: for example:
-        #       line = 'a, b, c, \n' -> 'a, b, c'
-        
-        for match1 in get_all_blocks(line, end_mark=','):
-            element = match1.fulltext.strip()
-            # debug(f'{element = }')
-            
-            if not element:
-                # # continue
-                raise ScanningError(
-                    match1.cursor.lineno, line,
-                    match1.cursor.charno, (line + ',')[match1.cursor.tileno],
-                    None
-                )
-            
-            if quotes_pattern.match(element):
-                yield element, QUOTED_STRING
-            elif number_pattern.match(element):
-                yield element, SIMPLE_NUMBER
-            elif kwargs_pattern.match(element):
-                continue  # continue or break out
-            elif nested_pattern.match(element):
-                yield element, NESTED_STRUCT
-            elif lambda_pattern.match(element):
-                ''' TODO (memo)
-                
-                How it happened?
-                    For example:
-                        line = 'lambda *args, **kwargs: None'
-                        
-                    When scanner goes here:
-                        lambda *args, **kwargs: None
-                                    ^
-                    Because 'lambda *args' is a 'complete' part (no unresolved
-                    brackets, quotes, etc. left), it treats this comma symbol
-                    as an end mark, so scanner thinks it can be submitted and
-                    yields 'lambda *args' as an 'element' to the caller.
-                    
-                    The caller (`lk_logger.sourcemap`) receives 'lambda *args'
-                    and '**kwargs: None' one after another, so caller thinks
-                    there're two elements found. But when logger tries to
-                    demonstrate their number is equivalent (see `lk_logger
-                    .logger.format > code:'assert len(info.varnames) ==
-                    len(data)'`), an AssertionError is raised.
-                
-                How to resolve it (in the future)?
-                    Before handling this example line, replace the comma with a
-                    mask symbol. After handling is over, restore it.
-                '''
-                raise UnresolvedCase('''
-                    We didn't find an ideal way to handle lambda expression
-                    without breaking currently designed function.
-                    The caller should catch this exception and it has to
-                    abandon all its collected varnames which came from this
-                    function. Say just take it as nothing received from here.
-                ''')
-                # see `~/lk_logger/sourcemap.py > class:SourceMap > method:
-                # _indexing_filemap`
-            elif m := walrus_pattern.match(element):
-                yield m.group(1), VARIABLE_NAME
-            elif caller_pattern.match(element):
-                yield element, SUBSCRIPTABLE
-            else:
-                yield element, VARIABLE_NAME
-        
-        break
-
-
-def _debug(linex, line, charx, char, symbols=None):
-    # from lk_logger_3_6 import lk
-    # lk.logt('[D4011]', visualize_line(
-    #     linex, line, charx, char, symbols), h='parent')
-    print(visualize_line(linex, line, charx, char, symbols))
-
-
-class Match:
-    
-    def __init__(self, cursor: Union[TCursor, tuple],
-                 text: str, matches: TMatches2):
-        self.cursor = cursor
-        self.fulltext = text
-        self._matches = matches
-        self.spans = list(matches)
-    
-    def change_depth(self, depth: int):
-        def _recurse(collector, node: dict, current_depth):
-            if current_depth < depth:
-                for v in node.values():
-                    _recurse(collector, v, current_depth + 1)
-            elif current_depth == depth:
-                collector.extend(node.keys())
-            return collector
-        
-        self.spans = _recurse([], self._matches, 0)
-    
-    def span(self, idx=0) -> TSpan:
-        return self.spans[idx]
-    
-    def group(self, idx=0):
-        start, end = self.span(idx)
-        return self.fulltext[start:end + 1]
-    
-    def groups(self):
-        out = []
-        for i in range(len(self.spans)):
-            out.append(self.group(i))
-        return out
-
-
-class Cursor:
-    lineno = -1
-    charno = -1
-    tileno = -1
-    
-    _dict: dict  # dict[tileno, tuple[lineno, charno]]
-    
-    def __init__(self):
-        self._dict = {}
-        self._snap = namedtuple(
-            'CursorShot', ['lineno', 'charno', 'tileno', 'index']
-        )
-    
-    def indexing_fulltext(self, lines):
-        for line in lines:
-            self.update_lineno()
-            for _ in line + '\n':
-                self.update_charno()
-    
-    def update_lineno(self):
-        self.lineno += 1
-        self.charno = -1
-    
-    def update_charno(self):
-        self.charno += 1
-        self.tileno += 1
-        self._dict[self.tileno] = (self.lineno, self.charno)
-        self._dict[(self.lineno, self.charno)] = self.tileno
-    
-    @property
-    def i(self):
-        return self.lineno
-    
-    @property
-    def j(self):
-        return self.charno
-    
-    @property
-    def x(self):
-        return self.tileno
-    
-    def trans(self, no: Union[int, tuple]):
-        return self._dict[no]
-    
-    def snapshot(self, index=None):
-        if index is None:
-            index = self.tileno
-        (i, j), x = self.trans(index), index
-        return self._snap(
-            lineno=i, charno=j, tileno=x, index=index
-        )
+"""
+README:
+    `docs/what-is-block.md`
+"""
+from collections import namedtuple
+from re import compile
+from string import whitespace
+
+from .analyser import Analyser
+from .const import *
+from .exceptions import *
+from .typehint import *
+from .._print import debug  # noqa
+
+
+def get_all_blocks(*lines: str, end_mark='\n'):
+    """ Get ALL COMPLETE text blocks.
+    
+    Scanning lines and try to merge the adjacent incomplete lines. If the
+    merged result is a complete block (type: `list[str]`), yield it to the
+    caller.
+    
+    Args:
+        lines:
+        end_mark:
+            warnings:
+                1. whatever end_mark's value is, it is alwayse be measured as
+                   one-character width.
+                2. `params:lines:each` mustn't end with end_mark, i.e.
+                    assert(all(not x.rstrip().endswith(end_mark)) for x in lines)
+    """
+    assert all(bool(not x.rstrip().endswith(end_mark)) for x in lines), (
+        f'Please make sure each of lines must not end with "{end_mark}". '
+        f'(You need to strip them before calling this function)'
+    )
+    assert len(end_mark) == 1
+    
+    analyser = Analyser(end=end_mark)
+    #   IMPROVEMENT: if `lines:each` contains '\n', which means we can't pass
+    #       '\n' to `params:end`, we can use `end=None` instead.
+    #       (see reactions at MARK@20210901173115.)
+    cursor = Cursor()
+    fulltext = end_mark.join(lines)
+    last_submit_idx = 0
+    
+    def _submit():
+        nonlocal last_submit_idx
+        yield Match(cursor.snapshot(last_submit_idx),
+                    fulltext[last_submit_idx:cursor.x],
+                    analyser.symbols.matches_nest)
+        analyser.reset()
+        last_submit_idx = cursor.x + 1
+    
+    for line in lines:
+        cursor.update_lineno()
+        
+        line_ = line + end_mark
+        for char in line_:  # MARK: 20210901173115
+            cursor.update_charno()
+            # _debug(cursor.i, line, cursor.j, char, analyser.symbols)
+            
+            with analyser.trace_index(cursor.x):
+                ret_code = analyser.analyse(char)
+            
+            if ret_code == SUBMITTABLE:
+                yield from _submit()
+                # break
+            elif ret_code == CONTINUE:
+                continue
+            elif ret_code == BREAK_OUT:
+                # `BREAK_OUT` is recognized as continuously sending `CONTINUE`
+                # command, until we meet an `end_mark` then break.
+                while char != end_mark:
+                    cursor.update_charno()
+                    char = line_[cursor.charno]
+                    # debug(cursor.charno, char)
+                yield from _submit()
+                break
+            elif ret_code == UNREACHABLE_CASE:
+                raise UnreachableCase(
+                    cursor.i, line, cursor.j, char, analyser.symbols
+                )
+            else:
+                raise UnexpectedReturnCode(ret_code)
+
+
+def get_variables(line: str):
+    """
+
+    Workflow:
+        1. single_line = 'A, (B, C)'
+        2. split by comma: ['A', '(B', 'C)']
+        3. analyse each element, try to merge every mergable parts (based on
+           pairable symbols): ['A', '(B, C)']
+        4. now we know there are two elements in single_line: `A` and `(B, C)`
+    """
+    caller_pattern = compile(r'^([.\w]+)[(\[{]')  # matching: 'requests.get('
+    kwargs_pattern = compile(r'^\w+ *=')  # matching: 'a=1'
+    lambda_pattern = compile(r'^lambda ')  # matching: 'lambda *_, **__: ...'
+    nested_pattern = compile(r'^[(\[{]')  # matching: '(...', '[...', '{...'
+    number_pattern = compile(r'^-?\d+(?:\.\d+)?$')  # matching: '123', '-123'
+    quotes_pattern = compile(r'^[bfru]*[\'"]')  # matching: '"hello', 'b"hello'
+    walrus_pattern = compile(r'^(\w+) *:=')  # mathcing: 'x := 12'
+    
+    for match0 in get_all_blocks(line):
+        start, end = match0.span()  # exterior brackets span
+        line = line[start + 1:end].rstrip(whitespace + ',')
+        #   `~.rstrip(...)`: for example:
+        #       line = 'a, b, c, \n' -> 'a, b, c'
+        
+        for match1 in get_all_blocks(line, end_mark=','):
+            element = match1.fulltext.strip()
+            # debug(f'{element = }')
+            
+            if not element:
+                # # continue
+                raise ScanningError(
+                    match1.cursor.lineno, line,
+                    match1.cursor.charno, (line + ',')[match1.cursor.tileno],
+                    None
+                )
+            
+            if quotes_pattern.match(element):
+                yield element, QUOTED_STRING
+            elif number_pattern.match(element):
+                yield element, SIMPLE_NUMBER
+            elif kwargs_pattern.match(element):
+                continue  # continue or break out
+            elif nested_pattern.match(element):
+                yield element, NESTED_STRUCT
+            elif lambda_pattern.match(element):
+                ''' TODO (memo)
+                
+                How it happened?
+                    For example:
+                        line = 'lambda *args, **kwargs: None'
+                        
+                    When scanner goes here:
+                        lambda *args, **kwargs: None
+                                    ^
+                    Because 'lambda *args' is a 'complete' part (no unresolved
+                    brackets, quotes, etc. left), it treats this comma symbol
+                    as an end mark, so scanner thinks it can be submitted and
+                    yields 'lambda *args' as an 'element' to the caller.
+                    
+                    The caller (`lk_logger.sourcemap`) receives 'lambda *args'
+                    and '**kwargs: None' one after another, so caller thinks
+                    there're two elements found. But when logger tries to
+                    demonstrate their number is equivalent (see `lk_logger
+                    .logger.format > code:'assert len(info.varnames) ==
+                    len(data)'`), an AssertionError is raised.
+                
+                How to resolve it (in the future)?
+                    Before handling this example line, replace the comma with a
+                    mask symbol. After handling is over, restore it.
+                '''
+                raise UnresolvedCase('''
+                    We didn't find an ideal way to handle lambda expression
+                    without breaking currently designed function.
+                    The caller should catch this exception and it has to
+                    abandon all its collected varnames which came from this
+                    function. Say just take it as nothing received from here.
+                ''')
+                # see `~/lk_logger/sourcemap.py > class:SourceMap > method:
+                # _indexing_filemap`
+            elif m := walrus_pattern.match(element):
+                yield m.group(1), VARIABLE_NAME
+            elif caller_pattern.match(element):
+                yield element, SUBSCRIPTABLE
+            else:
+                yield element, VARIABLE_NAME
+        
+        break
+
+
+def _debug(linex, line, charx, char, symbols=None):
+    # from lk_logger_3_6 import lk
+    # lk.logt('[D4011]', visualize_line(
+    #     linex, line, charx, char, symbols), h='parent')
+    print(visualize_line(linex, line, charx, char, symbols))
+
+
+class Match:
+    
+    def __init__(self, cursor: Union[TCursor, tuple],
+                 text: str, matches: TMatches2):
+        self.cursor = cursor
+        self.fulltext = text
+        self._matches = matches
+        self.spans = list(matches)
+    
+    def change_depth(self, depth: int):
+        def _recurse(collector, node: dict, current_depth):
+            if current_depth < depth:
+                for v in node.values():
+                    _recurse(collector, v, current_depth + 1)
+            elif current_depth == depth:
+                collector.extend(node.keys())
+            return collector
+        
+        self.spans = _recurse([], self._matches, 0)
+    
+    def span(self, idx=0) -> TSpan:
+        return self.spans[idx]
+    
+    def group(self, idx=0):
+        start, end = self.span(idx)
+        return self.fulltext[start:end + 1]
+    
+    def groups(self):
+        out = []
+        for i in range(len(self.spans)):
+            out.append(self.group(i))
+        return out
+
+
+class Cursor:
+    lineno = -1
+    charno = -1
+    tileno = -1
+    
+    _dict: dict  # dict[tileno, tuple[lineno, charno]]
+    
+    def __init__(self):
+        self._dict = {}
+        self._snap = namedtuple(
+            'CursorShot', ['lineno', 'charno', 'tileno', 'index']
+        )
+    
+    def indexing_fulltext(self, lines):
+        for line in lines:
+            self.update_lineno()
+            for _ in line + '\n':
+                self.update_charno()
+    
+    def update_lineno(self):
+        self.lineno += 1
+        self.charno = -1
+    
+    def update_charno(self):
+        self.charno += 1
+        self.tileno += 1
+        self._dict[self.tileno] = (self.lineno, self.charno)
+        self._dict[(self.lineno, self.charno)] = self.tileno
+    
+    @property
+    def i(self):
+        return self.lineno
+    
+    @property
+    def j(self):
+        return self.charno
+    
+    @property
+    def x(self):
+        return self.tileno
+    
+    def trans(self, no: Union[int, tuple]):
+        return self._dict[no]
+    
+    def snapshot(self, index=None):
+        if index is None:
+            index = self.tileno
+        (i, j), x = self.trans(index), index
+        return self._snap(
+            lineno=i, charno=j, tileno=x, index=index
+        )
```

## lk_logger/scanner/symbols.py

 * *Ordering differences only*

```diff
@@ -1,107 +1,107 @@
-from contextlib import contextmanager
-
-from .typehint import *
-
-
-class Symbols:
-    
-    def __init__(self):
-        self._symbols = []  # type: TSymbols
-        self._matches = {}  # type: TMatches1
-        self._index = -1
-    
-    def __str__(self):
-        return str(self._symbols)
-    
-    def __bool__(self):
-        return bool(self._symbols)
-    
-    def __getitem__(self, item):
-        return self._symbols[item]
-    
-    @contextmanager
-    def trace_index(self, index):
-        self._index = index
-        yield self
-    
-    def consume(self, adjust_offset=0):
-        """
-        Args:
-            adjust_offset: if the caller is not consuming a target character,
-                pass it a negative number.
-                see `analyser.py > MARK@20210901190803`
-        """
-        pos_i, _, _ = self._symbols.pop()
-        pos_o = self._index + adjust_offset
-        self._matches[pos_i] = pos_o
-    
-    def update(self, char, token):
-        index, _, _ = self._symbols[-1]
-        self._symbols[-1] = (index, char, token)
-    
-    def append(self, char, token):
-        self._symbols.append((self._index, char, token))
-    
-    def clear(self):
-        self._symbols.clear()
-        self._matches.clear()
-        self._index = -1
-    
-    @property
-    def last_symbol(self):
-        return self._symbols[-1]
-    
-    @property
-    def matches_list(self) -> TSpans:
-        return [(k, v) for k, v in self._matches.items()]
-    
-    @property
-    def matches_nest(self) -> TMatches2:
-        if not self._matches:
-            return {}
-        
-        consumed = []
-        matches = self._matches
-        pos_list = sorted(matches.keys())
-        
-        # noinspection PyUnusedLocal
-        def loop(master, node, pos_s, pos_e, start, end):
-            for i in range(start, end):
-                if i in consumed:
-                    continue
-                pos_i = pos_list[i]
-                pos_o = matches[pos_i]
-                # lk.logt('[D1605]', pos_i, pos_o, 'field range', pos_s, pos_e)
-                
-                if pos_o < pos_e:
-                    # lk.logt('[D1427]', 'subset of node', pos_i, pos_o, node)
-                    loop(
-                        master=node, node=node.setdefault((pos_i, pos_o), {}),
-                        pos_s=pos_i, pos_e=pos_o,
-                        start=i + 1, end=find_nearest_index(pos_o, i + 1)
-                    )
-                else:
-                    # lk.logt('[D1453]', 'adjacent to node', pos_i, pos_o, master)
-                    loop(
-                        master=master, node=master.setdefault((pos_i, pos_o), {}),
-                        pos_s=pos_i, pos_e=pos_o,
-                        start=i + 1, end=find_nearest_index(pos_o, i + 1)
-                    )
-                consumed.append(i)
-        
-        def find_nearest_index(pos_e, start):
-            for i in range(start, len(pos_list)):
-                if pos_list[i] > pos_e:
-                    return i
-            else:
-                return len(pos_list)
-        
-        loop(
-            master=None, node=(out := {}),
-            pos_s=0, pos_e=max(matches.values()) + 1,
-            start=0, end=len(pos_list)
-        )
-        return out
-
-
-symbols = Symbols()
+from contextlib import contextmanager
+
+from .typehint import *
+
+
+class Symbols:
+    
+    def __init__(self):
+        self._symbols = []  # type: TSymbols
+        self._matches = {}  # type: TMatches1
+        self._index = -1
+    
+    def __str__(self):
+        return str(self._symbols)
+    
+    def __bool__(self):
+        return bool(self._symbols)
+    
+    def __getitem__(self, item):
+        return self._symbols[item]
+    
+    @contextmanager
+    def trace_index(self, index):
+        self._index = index
+        yield self
+    
+    def consume(self, adjust_offset=0):
+        """
+        Args:
+            adjust_offset: if the caller is not consuming a target character,
+                pass it a negative number.
+                see `analyser.py > MARK@20210901190803`
+        """
+        pos_i, _, _ = self._symbols.pop()
+        pos_o = self._index + adjust_offset
+        self._matches[pos_i] = pos_o
+    
+    def update(self, char, token):
+        index, _, _ = self._symbols[-1]
+        self._symbols[-1] = (index, char, token)
+    
+    def append(self, char, token):
+        self._symbols.append((self._index, char, token))
+    
+    def clear(self):
+        self._symbols.clear()
+        self._matches.clear()
+        self._index = -1
+    
+    @property
+    def last_symbol(self):
+        return self._symbols[-1]
+    
+    @property
+    def matches_list(self) -> TSpans:
+        return [(k, v) for k, v in self._matches.items()]
+    
+    @property
+    def matches_nest(self) -> TMatches2:
+        if not self._matches:
+            return {}
+        
+        consumed = []
+        matches = self._matches
+        pos_list = sorted(matches.keys())
+        
+        # noinspection PyUnusedLocal
+        def loop(master, node, pos_s, pos_e, start, end):
+            for i in range(start, end):
+                if i in consumed:
+                    continue
+                pos_i = pos_list[i]
+                pos_o = matches[pos_i]
+                # lk.logt('[D1605]', pos_i, pos_o, 'field range', pos_s, pos_e)
+                
+                if pos_o < pos_e:
+                    # lk.logt('[D1427]', 'subset of node', pos_i, pos_o, node)
+                    loop(
+                        master=node, node=node.setdefault((pos_i, pos_o), {}),
+                        pos_s=pos_i, pos_e=pos_o,
+                        start=i + 1, end=find_nearest_index(pos_o, i + 1)
+                    )
+                else:
+                    # lk.logt('[D1453]', 'adjacent to node', pos_i, pos_o, master)
+                    loop(
+                        master=master, node=master.setdefault((pos_i, pos_o), {}),
+                        pos_s=pos_i, pos_e=pos_o,
+                        start=i + 1, end=find_nearest_index(pos_o, i + 1)
+                    )
+                consumed.append(i)
+        
+        def find_nearest_index(pos_e, start):
+            for i in range(start, len(pos_list)):
+                if pos_list[i] > pos_e:
+                    return i
+            else:
+                return len(pos_list)
+        
+        loop(
+            master=None, node=(out := {}),
+            pos_s=0, pos_e=max(matches.values()) + 1,
+            start=0, end=len(pos_list)
+        )
+        return out
+
+
+symbols = Symbols()
```

## lk_logger/scanner/typehint.py

 * *Ordering differences only*

```diff
@@ -1,26 +1,26 @@
-from typing import *
-
-if __name__ == '__main__':
-    from lk_logger.scanner.scanner import Match as _Match
-    from lk_logger.scanner.scanner import Cursor as _Cursor
-else:
-    _Match = None
-    _Cursor = None
-
-TLine = str
-TChar = str
-
-TCursor = _Cursor
-TPos = int
-TStart = TPos
-TEnd = TPos
-
-TToken = int
-TSymbols = List[Tuple[TPos, TChar, TToken]]
-
-TMatch = _Match
-TSpan = Tuple[TStart, TEnd]
-TSpans = List[TSpan]
-
-TMatches1 = Dict[TStart, TEnd]
-TMatches2 = Dict[Tuple[TStart, TEnd], Dict]
+from typing import *
+
+if __name__ == '__main__':
+    from lk_logger.scanner.scanner import Match as _Match
+    from lk_logger.scanner.scanner import Cursor as _Cursor
+else:
+    _Match = None
+    _Cursor = None
+
+TLine = str
+TChar = str
+
+TCursor = _Cursor
+TPos = int
+TStart = TPos
+TEnd = TPos
+
+TToken = int
+TSymbols = List[Tuple[TPos, TChar, TToken]]
+
+TMatch = _Match
+TSpan = Tuple[TStart, TEnd]
+TSpans = List[TSpan]
+
+TMatches1 = Dict[TStart, TEnd]
+TMatches2 = Dict[Tuple[TStart, TEnd], Dict]
```

## lk_logger/shunt.py

 * *Ordering differences only*

```diff
@@ -1,36 +1,36 @@
-import typing as t
-
-
-class T:
-    Pipe = t.Callable[..., t.Any]
-    PipeId = str
-    Pipes = t.Dict[PipeId, Pipe]
-
-
-class Shunt:
-    _pipes: T.Pipes
-    
-    def __init__(self):
-        self._pipes = {}
-        self._id_gen = 0
-        
-    def __bool__(self):
-        return bool(self._pipes)
-        
-    def __call__(self, msg: t.Union[str, t.Any], **kwargs) -> None:
-        for p in self._pipes.values():
-            p(msg, **kwargs)
-    
-    def __iter__(self) -> t.Iterator[T.Pipe]:
-        yield from self._pipes.values()
-    
-    def add(self, pipe: T.Pipe, name: str = '') -> T.PipeId:
-        self._pipes[(id := name or self._random_id())] = pipe
-        return id
-    
-    def remove(self, id: T.PipeId) -> None:
-        self._pipes.pop(id)
-    
-    def _random_id(self) -> T.PipeId:
-        self._id_gen += 1
-        return f'pipe_{self._id_gen}'
+import typing as t
+
+
+class T:
+    Pipe = t.Callable[..., t.Any]
+    PipeId = str
+    Pipes = t.Dict[PipeId, Pipe]
+
+
+class Shunt:
+    _pipes: T.Pipes
+    
+    def __init__(self):
+        self._pipes = {}
+        self._id_gen = 0
+        
+    def __bool__(self):
+        return bool(self._pipes)
+        
+    def __call__(self, msg: t.Union[str, t.Any], **kwargs) -> None:
+        for p in self._pipes.values():
+            p(msg, **kwargs)
+    
+    def __iter__(self) -> t.Iterator[T.Pipe]:
+        yield from self._pipes.values()
+    
+    def add(self, pipe: T.Pipe, name: str = '') -> T.PipeId:
+        self._pipes[(id := name or self._random_id())] = pipe
+        return id
+    
+    def remove(self, id: T.PipeId) -> None:
+        self._pipes.pop(id)
+    
+    def _random_id(self) -> T.PipeId:
+        self._id_gen += 1
+        return f'pipe_{self._id_gen}'
```

## Comparing `lk_logger-5.6.4.dist-info/METADATA` & `lk_logger-5.6.5.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: lk-logger
-Version: 5.6.4
+Version: 5.6.5
 Summary: Python advanced print with varnames.
 Home-page: https://github.com/likianta/lk-logger
 License: MIT
 Author: Likianta
 Author-email: likianta@foxmail.com
 Requires-Python: >=3.8,<4.0
 Classifier: License :: OSI Approved :: MIT License
```

## Comparing `lk_logger-5.6.4.dist-info/RECORD` & `lk_logger-5.6.5.dist-info/RECORD`

 * *Files 23% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-lk_logger/__init__.py,sha256=u5p-4qis5VJqxjYLS1HBN55Num5lDBmzxzcXkCvqVTQ,600
-lk_logger/_print.py,sha256=Q0WdJ-TxOcQy1aKxEgaxaCrixq9GdXqQVF7YTw-jELo,591
-lk_logger/cache/__init__.py,sha256=tsCw3CkeO9mnKVyrRer8L92jnHTyIm1nBnTyEdghDVo,33
-lk_logger/cache/cache.py,sha256=JNzGc80jDqi6fm4TiLApeU6UDKlyTQ7G4Ow-LWhc6Tc,6775
+lk_logger/__init__.py,sha256=nIVmeLZa5uIDcoHQ4O2bbWTl5FxZBr8_D2-GUqn8NxI,600
+lk_logger/_print.py,sha256=vr_kODnH9vZU-r6MSLpgQxoRt2SxsVT-bzVP0nIxIsU,616
+lk_logger/cache/__init__.py,sha256=jkWi40WfmTt3Akv3YKjJHI6gxPqzXwpFmdF4bIJ-SUs,34
+lk_logger/cache/cache.py,sha256=b2zusDBHjbAVtoP8CdBedPvkujVjNosUNlsUiCPSJeY,6970
 lk_logger/cache/frame.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-lk_logger/cache/legacy.py,sha256=kg2Qiyo6kpaH5giA2n8H5yID4QMusKz2hZ6uw8sX0v4,1817
-lk_logger/cache/util.py,sha256=laADgua6FHf8BcN_4XgZvY0yr9hOsZ87yvDr6FbrdGA,730
-lk_logger/config.py,sha256=fYOLbtYh7LsT5Vdhejdv2PPXFPxA-tDo6b8T-hr4AD8,5586
-lk_logger/console.py,sha256=GSoFWXBybfNuF7S7b3_OJL70h52OSlTPnCbpay1pL60,1563
-lk_logger/control.py,sha256=hlIK3pUjIK1fiHczN6aoOonhsJoNdvaji2WghMirh54,4817
-lk_logger/frame_info.py,sha256=cWRorf2KUQevoBdwgwXxliTwf5m2zpK9r5XEIasX6xQ,7652
+lk_logger/cache/legacy.py,sha256=kuQrFzJGuTd_NQWrO5Vp6b-Da3X73w60Ae2LxVP3Xb8,1875
+lk_logger/cache/util.py,sha256=6qtnnIhdrKTqyP4Elxd1d3OnkTFROzxAGWYz3c4smDk,762
+lk_logger/config.py,sha256=dNjNYrh9fn1mC5xi48BxuRAPuEfvYjDj3JCupoXHEmo,5732
+lk_logger/console.py,sha256=O7t06PiIe5P3A1ZTYQV-KOg2-N0eWloqSpbd0s_fvhk,1604
+lk_logger/control.py,sha256=xGpGI2ZYIfANsJsd1vqXZne1YU7vUfGqZlu-FAujRxY,4984
+lk_logger/frame_info.py,sha256=wLnmzGfNXGXEqDikodPUe8JHMi9dHXtdT2CEkiGDp-M,7860
 lk_logger/logger.py,sha256=N2ncmmsqC7ovELajcpwjaaO29q4JA-HDEiCMmLyofyw,13703
 lk_logger/markup.py,sha256=WkIaQIRDwUyYZFY-Jn22qc-Ig7fJyx6V6jYawZcnnYQ,10376
-lk_logger/message_builder.py,sha256=1_F_-nJnFut_FV6hGON-59kioWoHxbEpoAcU8fvYyyM,11169
+lk_logger/message_builder.py,sha256=sVrOtJMQi9JmowCR-zWF2WJggRQ8xXTpoRvsppogQ3Q,11468
 lk_logger/message_formatter.py,sha256=iT869b9P6eReA5j4vI4yk9m6W4t9HUenxDOKrhsos2c,11291
 lk_logger/path_helper.py,sha256=LAZOe5XK_51I0YPA6rUuY0_DKtaMtHyz52xcHqRbxY0,4034
-lk_logger/pipeline.py,sha256=bo-Z9367i2TxxJOCS5_Rk_6CFccFyJYgp3-uw9q9LzQ,2559
-lk_logger/scanner/__init__.py,sha256=er6nQAKVaYpdk30878kEDo5vKTSa6CzR-CdxNJiaODo,71
-lk_logger/scanner/analyser.py,sha256=tbI48nDcBPthZoD8jlnpap7S6FIHs4u8pUMQpsmh6r4,6247
-lk_logger/scanner/const.py,sha256=pRfHUK2huF2oLkd-ZpGtGUKQ2T4K3EnlSI0pUGGnp6Q,1128
+lk_logger/pipeline.py,sha256=WmKrflsI6VXqFcUq60iaySHjhFcPw0UEml0jZmHe7lU,2656
+lk_logger/scanner/__init__.py,sha256=2b0jy5SdPwiVQSV9kL_3Vd4AkbKrRp7npAUWC3Hbyek,73
+lk_logger/scanner/analyser.py,sha256=y3HuYB2DJ4ixwww4c9o6Jq6mPc2eqz88w5Cf84_Pf6E,6407
+lk_logger/scanner/const.py,sha256=npj77J2VntzHArQOaIUIj9IeRQi9hH33_lo2XYLlg-s,1164
 lk_logger/scanner/exceptions.py,sha256=G1wpgEIzTLLrD6Q_m0qGD85v5KnlPm3CV1ZxgvGCVd8,1780
-lk_logger/scanner/scanner.py,sha256=7Ase1WyHD87cBr4k9zYehe9LgL91r0L1_XlgKHg1_Eg,9594
-lk_logger/scanner/symbols.py,sha256=ibW1-n7Xigo9LvowUSn6dIrx-UmiJyuxN321bSCilSg,3238
+lk_logger/scanner/scanner.py,sha256=F9lS4doo9MvCn9gRRaSR5cJ_hnVQUV2dvq0dbuxjQbg,9861
+lk_logger/scanner/symbols.py,sha256=4Od09HWEBXe6xsPfBfwV5pMsUJYPkLyoEEneV93HzjA,3345
 lk_logger/scanner/text_scanner.py,sha256=84ese30Bh-H1ZVxT0jcNhsTwM1nLDkZOrUO1LSdjV6k,19638
-lk_logger/scanner/typehint.py,sha256=Vr929B1w9UGiLVEMIJJIyE6gULjd_NxmNVpssyZW_JI,491
-lk_logger/shunt.py,sha256=-2uc2STfSIABrY-yAC7qIBh3uBgEx0iL1CGB_9rcwzg,860
-lk_logger-5.6.4.dist-info/METADATA,sha256=iE01ep7-HEM-l2HlzzgjGBQb_nydsGEIJ6Bvu0BYzuk,4950
-lk_logger-5.6.4.dist-info/WHEEL,sha256=FMvqSimYX_P7y0a7UY-_Mc83r5zkBZsCYPm7Lr0Bsq4,88
-lk_logger-5.6.4.dist-info/RECORD,,
+lk_logger/scanner/typehint.py,sha256=CdX-02JvaI8PkEHgTN279e081njEAfNOHaxPXCQkguc,517
+lk_logger/shunt.py,sha256=lqC61T3Txo2L-rDmlA1VdFp9aTEkoNSOCh8Y2l6-kRI,896
+lk_logger-5.6.5.dist-info/METADATA,sha256=swvTebTGlZy0VrjH9B3zS7H29oSXkSfg_thpVUmIGHA,4950
+lk_logger-5.6.5.dist-info/WHEEL,sha256=sP946D7jFCHeNz5Iq4fL4Lu-PrWrFsgfLXbbkciIZwg,88
+lk_logger-5.6.5.dist-info/RECORD,,
```


# Comparing `tmp/tf-models-no-deps-2.11.2.tar.gz` & `tmp/tf-models-no-deps-2.16.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "tf-models-no-deps-2.11.2.tar", last modified: Sun Dec 18 00:04:19 2022, max compression
+gzip compressed data, was "tf-models-no-deps-2.16.0.tar", last modified: Fri May 10 21:05:19 2024, max compression
```

## Comparing `tf-models-no-deps-2.11.2.tar` & `tf-models-no-deps-2.16.0.tar`

### file list

```diff
@@ -1,1108 +1,1345 @@
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.591015 tf-models-no-deps-2.11.2/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      337 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/AUTHORS
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11405 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/LICENSE
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      603 2022-12-18 00:04:19.591015 tf-models-no-deps-2.11.2/PKG-INFO
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3072 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/README.md
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.431001 tf-models-no-deps-2.11.2/official/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.431001 tf-models-no-deps-2.11.2/official/common/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/common/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1848 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/common/dataset_fn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8562 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/common/distribute_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4904 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/common/distribute_utils_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4199 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/common/flags.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      843 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/common/registry_imports.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1057 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/common/streamz_counters.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.435001 tf-models-no-deps-2.11.2/official/core/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1265 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8083 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/actions.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4515 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/actions_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12890 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/base_task.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15542 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/base_trainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13011 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/base_trainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14464 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/core/config_definitions.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1115 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/exp_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7025 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/export_base.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4426 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/export_base_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3174 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/file_writers.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1987 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/file_writers_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24113 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/input_reader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4300 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/registry.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2350 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/registry_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9184 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/savedmodel_checkpoint_manager.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3814 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/savedmodel_checkpoint_manager_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2513 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/task_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1802 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/test_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4623 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/tf_example_builder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5793 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/tf_example_builder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2049 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/tf_example_feature_key.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1649 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/tf_example_feature_key_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11104 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/core/train_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9932 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/train_lib_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19817 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/train_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7169 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/core/train_utils_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.435001 tf-models-no-deps-2.11.2/official/legacy/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.439002 tf-models-no-deps-2.11.2/official/legacy/albert/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/albert/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2012 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/albert/configs.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.439002 tf-models-no-deps-2.11.2/official/legacy/bert/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14931 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/bert_models.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3883 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/bert_models_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4832 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/common_flags.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4167 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/configs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5966 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/export_tfhub.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4688 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/export_tfhub_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11724 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/input_pipeline.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2875 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/model_saving_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    25317 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/model_training_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11705 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/model_training_utils_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18826 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/run_classifier.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8410 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/run_pretraining.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5366 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/run_squad.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18945 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/run_squad_helper.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5054 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/bert/serving.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.439002 tf-models-no-deps-2.11.2/official/legacy/detection/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.443002 tf-models-no-deps-2.11.2/official/legacy/detection/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4468 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/configs/base_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1692 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/configs/factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3328 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/configs/maskrcnn_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4271 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/configs/olnmask_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1776 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/configs/retinanet_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3204 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/configs/shapemask_config.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.443002 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    20689 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/anchor.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6563 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3653 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/input_reader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15731 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/maskrcnn_parser.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1061 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/mode_keys.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14218 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/olnmask_parser.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18283 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/retinanet_parser.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    22331 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/shapemask_parser.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6219 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/tf_example_decoder.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.443002 tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24838 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/coco_evaluator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15169 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/coco_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2169 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/factory.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.443002 tf-models-no-deps-2.11.2/official/legacy/detection/executor/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/executor/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6259 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/executor/detection_executor.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    30360 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/executor/distributed_executor.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9015 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/main.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.447002 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.447002 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7994 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5976 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/fpn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    49476 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/heads.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      974 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/identity.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11219 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/nn_blocks.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3853 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/nn_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13159 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/resnet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    17270 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/spinenet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4439 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/base_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4862 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/checkpoint_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1402 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3800 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/learning_rates.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    30203 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/losses.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13458 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/maskrcnn_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16774 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/olnmask_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1716 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/optimizers.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6661 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/retinanet_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12110 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/modeling/shapemask_model.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.447002 tf-models-no-deps-2.11.2/official/legacy/detection/ops/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/ops/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8125 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/ops/nms.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    21942 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/ops/postprocess_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    22986 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/ops/roi_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    25998 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/ops/spatial_transform_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    28304 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/ops/target_ops.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.447002 tf-models-no-deps-2.11.2/official/legacy/detection/utils/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/utils/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    26050 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/utils/box_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1465 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/utils/class_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1575 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/utils/dataloader_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14297 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/detection/utils/input_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6647 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/legacy/detection/utils/mask_utils.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.451003 tf-models-no-deps-2.11.2/official/legacy/image_classification/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    34315 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/augment.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4313 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/augment_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9355 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/callbacks.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16195 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/classifier_trainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7755 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/classifier_trainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6047 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/classifier_trainer_util_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.451003 tf-models-no-deps-2.11.2/official/legacy/image_classification/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8668 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/configs/base_configs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6110 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/configs/configs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19517 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/dataset_factory.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.451003 tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/common_modules.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2867 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/efficientnet_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16417 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/efficientnet_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2319 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/tfhub_export.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4272 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/learning_rate.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1941 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/learning_rate_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6114 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/mnist_main.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2581 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/mnist_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6890 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/optimizer_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4067 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/optimizer_factory_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13537 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/preprocessing.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.455003 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16294 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/common.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    21168 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/imagenet_preprocessing.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2070 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/resnet_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6916 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/resnet_ctl_imagenet_main.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10945 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/resnet_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8124 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/resnet_runnable.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2189 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/tfhub_export.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1322 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/test_utils.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.455003 tf-models-no-deps-2.11.2/official/legacy/image_classification/vgg/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/vgg/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1803 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/vgg/vgg_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7607 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/image_classification/vgg/vgg_model.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.459003 tf-models-no-deps-2.11.2/official/legacy/transformer/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7119 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/attention_layer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3679 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/beam_search_v1.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5141 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/compute_bleu.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2585 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/compute_bleu_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15291 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/data_download.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13237 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/data_pipeline.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3684 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/embedding_layer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2320 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/ffn_layer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7007 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/metrics.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10346 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/misc.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2936 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/model_params.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4427 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/model_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1891 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/model_utils_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2434 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/optimizer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    21751 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/transformer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6060 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_forward_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3566 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_layers_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18183 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_main.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6631 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_main_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3628 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6951 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/translate.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.459003 tf-models-no-deps-2.11.2/official/legacy/transformer/utils/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/utils/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16706 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/utils/metrics.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24517 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/utils/tokenizer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6658 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/transformer/utils/tokenizer_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.463004 tf-models-no-deps-2.11.2/official/legacy/xlnet/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5421 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/classifier_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5367 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/common_flags.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    30095 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/data_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3769 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/optimization.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15344 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/preprocess_classification_data.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    32400 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/preprocess_pretrain_data.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4046 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/preprocess_squad_data.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3693 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/preprocess_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6976 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/run_classifier.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5710 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/run_pretrain.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11597 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/run_squad.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    32226 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/squad_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11664 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/training_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5894 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/xlnet_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    47595 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/legacy/xlnet/xlnet_modeling.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.463004 tf-models-no-deps-2.11.2/official/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.467004 tf-models-no-deps-2.11.2/official/modeling/activations/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1044 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/activations/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1037 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/activations/gelu.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1212 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/modeling/activations/gelu_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1191 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/activations/mish.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1082 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/modeling/activations/mish_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      984 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/activations/relu.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1200 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/modeling/activations/relu_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1041 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/activations/sigmoid.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1364 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/modeling/activations/sigmoid_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2291 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/activations/swish.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1566 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/modeling/activations/swish_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6730 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/grad_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2786 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/grad_utils_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.467004 tf-models-no-deps-2.11.2/official/modeling/hyperparams/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      846 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/hyperparams/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11213 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/modeling/hyperparams/base_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11413 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/modeling/hyperparams/base_config_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1870 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/hyperparams/oneof.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1882 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/hyperparams/oneof_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16412 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/hyperparams/params_dict.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13657 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/hyperparams/params_dict_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.471005 tf-models-no-deps-2.11.2/official/modeling/multitask/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1936 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/base_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5846 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/base_trainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3653 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/base_trainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2683 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/configs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6068 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/evaluator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4633 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/evaluator_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4448 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/interleaving_trainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4295 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/interleaving_trainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5938 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/multitask.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4887 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/task_sampler.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3027 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/task_sampler_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4155 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/test_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10422 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/train_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4756 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/multitask/train_lib_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.471005 tf-models-no-deps-2.11.2/official/modeling/optimization/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1201 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      792 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/adafactor_optimizer.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.471005 tf-models-no-deps-2.11.2/official/modeling/optimization/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11122 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/configs/learning_rate_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4826 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/configs/optimization_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2009 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/configs/optimization_config_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11745 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/configs/optimizer_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9093 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/ema_optimizer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7338 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/lars_optimizer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5953 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/legacy_adamw.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19097 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/lr_schedule.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3951 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/lr_schedule_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10511 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/optimizer_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    17015 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/optimizer_factory_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      707 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/optimization/slide_optimizer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2159 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/performance.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.475005 tf-models-no-deps-2.11.2/official/modeling/privacy/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/privacy/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      960 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/privacy/configs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1359 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/privacy/configs_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1452 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/privacy/ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1684 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/privacy/ops_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9846 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/tf_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3694 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/modeling/tf_utils_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.475005 tf-models-no-deps-2.11.2/official/nlp/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.475005 tf-models-no-deps-2.11.2/official/nlp/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1508 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/configs/bert.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1381 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/configs/electra.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    25765 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/configs/encoders.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1963 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/configs/encoders_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      845 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/configs/experiment_configs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6571 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/configs/finetuning_experiments.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2968 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/configs/pretraining_experiments.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3791 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/configs/wmt_transformer_experiments.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7884 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/continuous_finetune_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3182 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/continuous_finetune_lib_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.479005 tf-models-no-deps-2.11.2/official/nlp/data/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    57071 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/classifier_data_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3352 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/classifier_data_lib_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16693 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/create_finetuning_data.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    23360 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/create_pretraining_data.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4857 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/create_pretraining_data_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24192 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/create_xlnet_pretraining_data.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10930 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/create_xlnet_pretraining_data_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1688 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/data_loader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1788 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/data_loader_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1325 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/data_loader_factory_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5713 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/dual_encoder_dataloader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5040 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/dual_encoder_dataloader_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24634 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/pretrain_dataloader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9141 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/pretrain_dataloader_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9814 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/pretrain_dynamic_dataloader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9620 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/pretrain_dynamic_dataloader_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4308 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/question_answering_dataloader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2830 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/question_answering_dataloader_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10337 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/sentence_prediction_dataloader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11662 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/sentence_prediction_dataloader_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6413 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/sentence_retrieval_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    36512 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/squad_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    34939 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/squad_lib_sp.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15489 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/tagging_data_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3737 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/tagging_data_lib_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3181 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/tagging_dataloader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3196 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/tagging_dataloader_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4513 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/train_sentencepiece.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11174 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/wmt_dataloader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4892 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/data/wmt_dataloader_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.483006 tf-models-no-deps-2.11.2/official/nlp/metrics/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/metrics/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6577 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/metrics/bleu.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2498 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/metrics/bleu_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.483006 tf-models-no-deps-2.11.2/official/nlp/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1062 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.491006 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4494 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3896 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3681 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    21026 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/bigbird_attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2196 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/bigbird_attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7233 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/block_diag_feedforward.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4302 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/block_diag_feedforward_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16198 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/cls_head.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8878 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/cls_head_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2892 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/factorized_embedding.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2579 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/factorized_embedding_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9681 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/gated_feedforward.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4761 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/gated_feedforward_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    20440 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/gaussian_process.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10091 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/gaussian_process_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    34144 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/kernel_attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9473 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/kernel_attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4798 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/masked_lm.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5853 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/masked_lm_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2990 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/masked_softmax.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4694 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/masked_softmax_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2250 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mat_mul_with_margin.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2136 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mat_mul_with_margin_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9741 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mixing.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3549 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mixing_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    23471 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mobile_bert_layers.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10880 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mobile_bert_layers_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    28804 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/moe.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10018 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/moe_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7312 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/multi_channel_attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1912 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/multi_channel_attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3891 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/on_device_embedding.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8880 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/on_device_embedding_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10279 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/pack_optimization.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2785 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/pack_optimization_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3331 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/per_dim_scale_attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1751 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/per_dim_scale_attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11347 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/position_embedding.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8538 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/position_embedding_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    20472 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/relative_attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6806 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/relative_attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    25658 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/reuse_attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14319 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/reuse_attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15687 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/reuse_transformer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    17478 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/reuse_transformer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12529 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/rezero_transformer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6028 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/rezero_transformer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4459 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/routing.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2216 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/routing_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2163 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/self_attention_mask.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10578 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/spectral_normalization.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3111 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/spectral_normalization_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6903 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/talking_heads_attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7289 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/talking_heads_attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    32516 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/text_layers.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24245 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/text_layers_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6703 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/tn_expand_condense.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6434 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/tn_expand_condense_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11022 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/tn_transformer_expand_condense.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9160 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/tn_transformer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19124 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18295 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_encoder_block.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    27772 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_encoder_block_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14931 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_scaffold.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    20221 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_scaffold_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3718 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    22180 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_xl.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9514 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_xl_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2723 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/layers/util.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.495007 tf-models-no-deps-2.11.2/official/nlp/modeling/losses/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      824 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/losses/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2859 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8619 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.495007 tf-models-no-deps-2.11.2/official/nlp/modeling/models/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1654 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5896 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_classifier.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5092 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_classifier_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11405 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_pretrainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10116 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_pretrainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4997 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_span_labeler.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5053 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_span_labeler_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5216 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_token_classifier.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5112 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_token_classifier_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6583 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/dual_encoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5377 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/dual_encoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12961 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/electra_pretrainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6804 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/electra_pretrainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    25716 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/seq2seq_transformer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5402 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/seq2seq_transformer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    57316 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/t5.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    27024 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/t5_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11779 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/xlnet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13044 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/models/xlnet_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.499007 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1771 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8877 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/albert_encoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7494 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/albert_encoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14506 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/bert_dense_encoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24904 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/bert_encoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    27197 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/bert_encoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4222 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7448 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/classification_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    17143 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/encoder_scaffold.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    29410 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/encoder_scaffold_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14701 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/fnet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4543 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/fnet_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    21731 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/funnel_transformer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14466 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/funnel_transformer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7533 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/mobile_bert_encoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7105 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/mobile_bert_encoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12800 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/packed_sequence_embedding.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5066 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/packed_sequence_embedding_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13195 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/span_labeling.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12330 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/span_labeling_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    25857 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/xlnet_base.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14869 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/networks/xlnet_base_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.503008 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1011 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    29237 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/beam_search.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3695 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/beam_search_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11269 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/decoding_module.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2613 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/decoding_module_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19240 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/sampling_module.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9596 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/segment_extractor.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5398 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/modeling/ops/segment_extractor_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3875 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/optimization.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.503008 tf-models-no-deps-2.11.2/official/nlp/serving/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/serving/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6192 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/serving/export_savedmodel.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6513 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/serving/export_savedmodel_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2312 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/serving/export_savedmodel_util.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18889 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/serving/serving_modules.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15068 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/serving/serving_modules_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.507008 tf-models-no-deps-2.11.2/official/nlp/tasks/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1178 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7634 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/dual_encoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4561 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/dual_encoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9637 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/electra_task.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2282 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/electra_task_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7703 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/masked_lm.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3922 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/masked_lm_determinism_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2160 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/masked_lm_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19817 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/question_answering.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9939 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/question_answering_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12506 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/sentence_prediction.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10430 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/sentence_prediction_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10088 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/tagging.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6407 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/tagging_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13381 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/translation.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6871 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/translation_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2575 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tasks/utils.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.507008 tf-models-no-deps-2.11.2/official/nlp/tools/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9443 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/export_tfhub.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    21376 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/export_tfhub_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    46347 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/export_tfhub_lib_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3724 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/squad_evaluate_v1_1.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8625 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/squad_evaluate_v2_0.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7865 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/tf1_bert_checkpoint_converter_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6676 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/tf2_albert_encoder_checkpoint_converter.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5826 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/tf2_bert_encoder_checkpoint_converter.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16591 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/tokenization.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5217 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/tools/tokenization_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3043 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/nlp/train.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.507008 tf-models-no-deps-2.11.2/official/projects/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.507008 tf-models-no-deps-2.11.2/official/projects/bigbird/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/bigbird/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9220 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/bigbird/encoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2340 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/bigbird/encoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3774 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/bigbird/experiment_configs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9027 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/bigbird/recompute_grad.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5942 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/bigbird/recomputing_dropout.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4921 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/bigbird/stateless_dropout.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.507008 tf-models-no-deps-2.11.2/official/projects/centernet/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.507008 tf-models-no-deps-2.11.2/official/projects/centernet/common/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/common/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      999 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/common/registry_imports.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.511008 tf-models-no-deps-2.11.2/official/projects/centernet/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1077 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/configs/backbones.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7292 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/configs/centernet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1601 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/configs/centernet_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.511008 tf-models-no-deps-2.11.2/official/projects/centernet/dataloaders/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/dataloaders/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12562 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/dataloaders/centernet_input.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.511008 tf-models-no-deps-2.11.2/official/projects/centernet/losses/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/losses/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4548 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/losses/centernet_losses.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3777 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/losses/centernet_losses_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.511008 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.511008 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/backbones/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/backbones/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10285 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/backbones/hourglass.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1602 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/backbones/hourglass_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2541 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/centernet_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2575 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/centernet_model_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.511008 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/heads/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/heads/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3833 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/heads/centernet_head.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2425 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/heads/centernet_head_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.511008 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12200 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/cn_nn_blocks.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5148 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/cn_nn_blocks_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13299 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/detection_generator.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/centernet/ops/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/ops/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6813 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/ops/box_list.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12856 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/ops/box_list_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7558 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/ops/loss_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3923 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/ops/nms_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19013 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/ops/preprocess_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16235 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/ops/target_assigner.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6817 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/ops/target_assigner_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/centernet/tasks/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/tasks/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16719 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/tasks/centernet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2522 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/train.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/centernet/utils/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/utils/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9665 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/config_classes.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4085 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/config_data.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6042 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/load_weights.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3752 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/read_checkpoints.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5327 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/centernet/utils/tf2_centernet_checkpoint_converter.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/common/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/common/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      775 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/common/registry_imports.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7948 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1218 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn_config_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.515009 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    21630 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/hourglass_network.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12060 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/instance_heads.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3172 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/instance_heads_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8566 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/maskrcnn_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5471 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/maskrcnn_model_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.519009 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5494 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/detection.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6352 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/detection_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3991 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/export_saved_model.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.519009 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/tasks/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/tasks/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8667 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/tasks/deep_mask_head_rcnn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2630 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/train.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.519009 tf-models-no-deps-2.11.2/official/projects/mobilebert/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/mobilebert/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    25064 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/mobilebert/distillation.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7257 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/mobilebert/distillation_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3689 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/mobilebert/export_tfhub.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7470 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/mobilebert/model_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5486 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/mobilebert/run_distillation.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10709 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/mobilebert/tf2_model_checkpoint_converter.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1036 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/mobilebert/utils.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.519009 tf-models-no-deps-2.11.2/official/projects/movinet/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.519009 tf-models-no-deps-2.11.2/official/projects/movinet/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4362 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/configs/movinet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1596 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/configs/movinet_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.523009 tf-models-no-deps-2.11.2/official/projects/movinet/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/modeling/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    29475 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    61303 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_layers.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14957 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_layers_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9800 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8838 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_model_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7863 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.523009 tf-models-no-deps-2.11.2/official/projects/movinet/tools/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/tools/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3809 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/tools/convert_3d_2plus1d.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1997 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/tools/convert_3d_2plus1d_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10999 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/tools/export_saved_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4451 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/tools/export_saved_model_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11994 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/tools/quantize_movinet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3320 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/train.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3119 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/movinet/train_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.523009 tf-models-no-deps-2.11.2/official/projects/nhnet/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3202 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/configs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3116 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/configs_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15312 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/decoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6024 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/decoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6091 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/evaluation.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9053 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/input_pipeline.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    23056 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/models.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11786 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/models_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2809 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/optimizer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3735 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/raw_data_process.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9238 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/raw_data_processor.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8900 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/trainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3289 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/trainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3294 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/nhnet/utils.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.523009 tf-models-no-deps-2.11.2/official/projects/panoptic/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/panoptic/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.523009 tf-models-no-deps-2.11.2/official/projects/panoptic/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/panoptic/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    25348 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/panoptic/configs/panoptic_deeplab.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10436 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/panoptic/configs/panoptic_maskrcnn.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.527010 tf-models-no-deps-2.11.2/official/projects/panoptic/tasks/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/panoptic/tasks/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14422 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/panoptic/tasks/panoptic_deeplab.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18024 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/panoptic/tasks/panoptic_maskrcnn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1191 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/panoptic/train.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.527010 tf-models-no-deps-2.11.2/official/projects/roformer/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/roformer/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2002 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/roformer/roformer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4449 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/roformer/roformer_attention.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4133 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/roformer/roformer_attention_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11374 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/roformer/roformer_encoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13507 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/roformer/roformer_encoder_block.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13069 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/roformer/roformer_encoder_block_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9791 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/roformer/roformer_encoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4797 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/roformer/roformer_experiments.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2566 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/roformer/train.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.527010 tf-models-no-deps-2.11.2/official/projects/teams/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/teams/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4010 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/teams/teams.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4424 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/teams/teams_experiments.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18608 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/teams/teams_pretrainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7737 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/teams/teams_pretrainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10170 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/teams/teams_task.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2184 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/teams/teams_task_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1028 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/teams/train.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.531010 tf-models-no-deps-2.11.2/official/projects/triviaqa/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16320 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/dataset.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2497 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/download_and_prepare.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1550 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/evaluate.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5293 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/evaluation.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    21718 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/inputs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4629 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/modeling.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7087 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/predict.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2735 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/prediction.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18797 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/preprocess.py
--rwxr-x---   0 hongkuny (405338) primarygroup (89939)    10818 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/sentencepiece_pb2.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14287 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/triviaqa/train.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.531010 tf-models-no-deps-2.11.2/official/projects/yolo/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.531010 tf-models-no-deps-2.11.2/official/projects/yolo/common/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/common/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1459 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/common/registry_imports.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.531010 tf-models-no-deps-2.11.2/official/projects/yolo/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1143 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/configs/backbones.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2568 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/configs/darknet_classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1640 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/configs/decoders.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    17602 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/yolo/configs/yolo.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.531010 tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3279 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/classification_input.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4810 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/tf_example_decoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14673 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/yolo_input.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.531010 tf-models-no-deps-2.11.2/official/projects/yolo/losses/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/losses/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    31724 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/losses/yolo_loss.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2998 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/losses/yolo_loss_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.535010 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.535010 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/backbones/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/backbones/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    22062 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/backbones/darknet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4682 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/backbones/darknet_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.535010 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/decoders/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/decoders/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    23635 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/decoders/yolo_decoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4804 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/decoders/yolo_decoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4208 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/factory.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.535010 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/heads/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/heads/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5234 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/heads/yolo_head.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2323 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/heads/yolo_head_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.535010 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12243 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/detection_generator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1913 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/detection_generator_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    60049 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/nn_blocks.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11653 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/nn_blocks_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3117 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/yolo/modeling/yolo_model.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.539011 tf-models-no-deps-2.11.2/official/projects/yolo/ops/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      610 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19309 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/anchor.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11193 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/box_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2005 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/box_ops_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11618 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/kmeans_anchors.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1445 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/kmeans_anchors_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    23482 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/loss_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1676 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/math_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16383 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/mosaic.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    36261 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/preprocessing_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5468 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/ops/preprocessing_ops_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.539011 tf-models-no-deps-2.11.2/official/projects/yolo/optimization/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1099 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/optimization/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.539011 tf-models-no-deps-2.11.2/official/projects/yolo/optimization/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/optimization/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1998 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/optimization/configs/optimization_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2283 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/optimization/configs/optimizer_config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3389 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/yolo/optimization/optimizer_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11225 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/optimization/sgd_torch.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.539011 tf-models-no-deps-2.11.2/official/projects/yolo/serving/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/serving/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9124 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/serving/export_module_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3960 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/serving/export_saved_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3008 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/serving/model_fn.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.539011 tf-models-no-deps-2.11.2/official/projects/yolo/tasks/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/tasks/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2693 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/tasks/image_classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1526 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/tasks/task_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16440 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/tasks/yolo.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      981 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yolo/train.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.539011 tf-models-no-deps-2.11.2/official/projects/yt8m/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.539011 tf-models-no-deps-2.11.2/official/projects/yt8m/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      692 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8380 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/configs/yt8m.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1561 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/configs/yt8m_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.543011 tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4632 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/nn_layers.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6892 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/yt8m_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2149 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/yt8m_model_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8408 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/yt8m_model_utils.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.543011 tf-models-no-deps-2.11.2/official/projects/yt8m/tasks/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      692 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/tasks/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12717 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/tasks/yt8m_task.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      987 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/train.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3218 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/projects/yt8m/train_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.543011 tf-models-no-deps-2.11.2/official/recommendation/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2877 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/constants.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4008 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/create_ncf_data.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    37218 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/data_pipeline.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10308 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/data_preprocessing.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12821 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/data_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9734 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/movielens.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12278 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ncf_common.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6964 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ncf_input_pipeline.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19840 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ncf_keras_main.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4134 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ncf_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16940 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/neumf_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1917 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/popen_helper.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.543011 tf-models-no-deps-2.11.2/official/recommendation/ranking/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3988 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/common.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.547011 tf-models-no-deps-2.11.2/official/recommendation/ranking/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10418 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/configs/config.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1464 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/configs/config_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.547011 tf-models-no-deps-2.11.2/official/recommendation/ranking/data/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/data/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7319 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/data/data_pipeline.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2335 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/data/data_pipeline_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7723 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/task.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2182 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/task_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6613 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/train.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4884 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/ranking/train_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3076 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/recommendation/stat_utils.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.547011 tf-models-no-deps-2.11.2/official/utils/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.547011 tf-models-no-deps-2.11.2/official/utils/docs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/docs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3850 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/docs/build_orbit_api_docs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6437 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/docs/build_tfm_api_docs.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.547011 tf-models-no-deps-2.11.2/official/utils/flags/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6395 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/_base.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4082 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/_benchmark.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1618 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/_conventions.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2826 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/_device.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1694 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/_distribution.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1541 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/_misc.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11566 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/_performance.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4427 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/core.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5302 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/flags/flags_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4607 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/hyperparams_flags.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.547011 tf-models-no-deps-2.11.2/official/utils/misc/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/misc/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7783 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/misc/keras_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3360 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/misc/model_helpers.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4549 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/misc/model_helpers_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.547011 tf-models-no-deps-2.11.2/official/utils/testing/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/testing/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2220 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/testing/integration.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3227 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/utils/testing/mock_task.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.551012 tf-models-no-deps-2.11.2/official/vision/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      744 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.551012 tf-models-no-deps-2.11.2/official/vision/configs/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1045 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4772 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/backbones.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3650 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/backbones_3d.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4342 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/common.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1948 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/decoders.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    23194 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/image_classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1857 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/image_classification_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    22401 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/configs/maskrcnn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1723 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/maskrcnn_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15597 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/configs/retinanet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1689 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/retinanet_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    28090 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/configs/semantic_segmentation.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1721 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/configs/semantic_segmentation_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14084 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/configs/video_classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1700 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/configs/video_classification_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.555012 tf-models-no-deps-2.11.2/official/vision/data/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/data/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    22397 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/data/create_coco_tf_record.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5039 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/data/fake_feature_generator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3503 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/data/image_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4061 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/data/image_utils_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6051 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/data/process_coco_few_shot_json_files.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    20503 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/data/tf_example_builder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    28468 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/data/tf_example_builder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6677 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/data/tf_example_feature_key.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6316 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/data/tfrecord_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2765 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/data/tfrecord_lib_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.559013 tf-models-no-deps-2.11.2/official/vision/dataloaders/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11612 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/classification_input.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1032 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/decoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7720 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/input_reader.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1623 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/input_reader_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15595 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/maskrcnn_input.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2315 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/parser.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13706 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/retinanet_input.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9695 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/segmentation_input.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7868 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tf_example_decoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11783 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tf_example_decoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2588 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tf_example_label_map_decoder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7746 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tf_example_label_map_decoder_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1242 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_classification_decoders.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2272 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_detection_decoders.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2568 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4010 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_factory_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2418 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_segmentation_decoders.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11675 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/tfexample_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3103 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2557 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/utils_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16753 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/video_input.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7541 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/dataloaders/video_input_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.559013 tf-models-no-deps-2.11.2/official/vision/evaluation/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13722 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/coco_evaluator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16492 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/coco_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1710 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/coco_utils_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2200 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/iou.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3949 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/iou_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12497 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/panoptic_quality.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7945 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/panoptic_quality_evaluator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3323 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/panoptic_quality_evaluator_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    11082 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/panoptic_quality_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7402 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/segmentation_metrics.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2990 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/segmentation_metrics_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6604 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/evaluation/wod_detection_evaluator.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.559013 tf-models-no-deps-2.11.2/official/vision/losses/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/losses/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3229 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/losses/focal_loss.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1569 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/losses/loss_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    13380 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/losses/maskrcnn_losses.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8097 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/losses/retinanet_losses.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9520 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/losses/segmentation_losses.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.563013 tf-models-no-deps-2.11.2/official/vision/modeling/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      869 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.567013 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1329 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12005 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/efficientnet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3752 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/efficientnet_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3494 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8383 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/factory_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24886 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/mobiledet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3794 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/mobiledet_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    41026 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/mobilenet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10596 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/mobilenet_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15932 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18573 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_3d.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3789 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_3d_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15644 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_deeplab.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5510 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_deeplab_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5503 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8840 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/revnet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3215 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/revnet_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    20970 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/spinenet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    20638 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/spinenet_mobile.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3948 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/spinenet_mobile_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4724 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/spinenet_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12383 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/vit.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2071 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/vit_specs.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2577 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/backbones/vit_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4607 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/classification_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7007 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/classification_model_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.567013 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      815 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8600 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/aspp.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3001 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/aspp_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4387 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5621 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/factory_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9720 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/fpn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4274 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/fpn_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14450 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/nasfpn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1887 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/decoders/nasfpn_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16849 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3530 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/factory_3d.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4960 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/factory_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.567013 tf-models-no-deps-2.11.2/official/vision/modeling/heads/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1014 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/heads/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    22117 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/heads/dense_prediction_heads.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4986 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/heads/dense_prediction_heads_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18550 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/heads/instance_heads.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4197 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/heads/instance_heads_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18940 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/heads/segmentation_heads.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3802 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/heads/segmentation_heads_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.571014 tf-models-no-deps-2.11.2/official/vision/modeling/layers/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2597 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3401 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/box_sampler.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8487 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/deeplab.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1935 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/deeplab_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    45278 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/detection_generator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10473 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/detection_generator_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7914 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/mask_sampler.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    62598 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_blocks.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10508 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_blocks_3d.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2028 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_blocks_3d_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12575 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_blocks_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    48133 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_layers.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12791 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_layers_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2533 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/roi_aligner.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1275 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/roi_aligner_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14408 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/roi_generator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8270 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/layers/roi_sampler.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    17419 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/maskrcnn_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14252 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/maskrcnn_model_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.571014 tf-models-no-deps-2.11.2/official/vision/modeling/models/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1020 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/models/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9190 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/retinanet_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10976 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/modeling/retinanet_model_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3353 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/segmentation_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2807 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/segmentation_model_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4703 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/video_classification_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3261 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/modeling/video_classification_model_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.575014 tf-models-no-deps-2.11.2/official/vision/ops/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18630 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/anchor.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7234 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/anchor_generator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5286 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/anchor_generator_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7623 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/anchor_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    89553 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/augment.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    18515 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/augment_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9057 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/box_matcher.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2428 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/box_matcher_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    31840 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/ops/box_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5841 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/iou_similarity.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1898 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/iou_similarity_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6830 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/mask_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1676 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/mask_ops_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8099 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/nms.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    37929 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/ops/preprocess_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    15378 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/preprocess_ops_3d.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7239 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/preprocess_ops_3d_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    10806 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/preprocess_ops_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16062 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/sampling_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    35833 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/spatial_transform_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3955 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/target_gather.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2551 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/ops/target_gather_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      760 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/registry_imports.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.579014 tf-models-no-deps-2.11.2/official/vision/serving/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      702 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8302 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/serving/detection.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5515 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/serving/detection_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7429 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_base.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2731 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_base_v2.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2870 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_base_v2_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3539 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_module_factory.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4595 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_module_factory_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4463 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_saved_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7272 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_saved_model_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2399 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_saved_model_lib_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3700 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_saved_model_lib_v2.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3737 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_tfhub.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4786 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_tflite.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6300 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_tflite_lib.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     7185 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_tflite_lib_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4607 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/export_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2858 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/image_classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4612 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/image_classification_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4013 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/semantic_segmentation.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5628 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/semantic_segmentation_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6874 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/video_classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4222 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/serving/video_classification_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.579014 tf-models-no-deps-2.11.2/official/vision/tasks/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      995 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/tasks/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14324 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/tasks/image_classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    19402 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/tasks/maskrcnn.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    16083 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/tasks/retinanet.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12716 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/official/vision/tasks/semantic_segmentation.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    14308 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/tasks/video_classification.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2598 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/train.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5725 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/train_spatial_partitioning.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.579014 tf-models-no-deps-2.11.2/official/vision/utils/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.583015 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      609 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     9011 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/argmax_matcher.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    12058 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/balanced_positive_negative_sampler.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4776 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/box_coder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6739 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/box_list.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    41961 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/box_list_ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3806 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/faster_rcnn_box_coder.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8751 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/matcher.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3074 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/minibatch_sampler.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3212 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/ops.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    20356 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/preprocessor.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4544 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/region_similarity_calculator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3608 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/shape_utils.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    24198 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/target_assigner.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    28970 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/official/vision/utils/object_detection/visualization_utils.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.583015 tf-models-no-deps-2.11.2/orbit/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1117 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.587015 tf-models-no-deps-2.11.2/orbit/actions/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3245 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/actions/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1978 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/actions/conditional_action.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1325 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/actions/conditional_action_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5024 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/actions/export_saved_model.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     6761 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/actions/export_saved_model_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8479 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/actions/new_best_metric.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4014 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/actions/new_best_metric_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    23184 2022-12-18 00:02:30.000000 tf-models-no-deps-2.11.2/orbit/controller.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    29864 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/controller_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.587015 tf-models-no-deps-2.11.2/orbit/examples/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      604 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/examples/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.587015 tf-models-no-deps-2.11.2/orbit/examples/single_task/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      604 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/examples/single_task/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3195 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/examples/single_task/single_task_evaluator.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2088 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/examples/single_task/single_task_evaluator_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5647 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/examples/single_task/single_task_trainer.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1961 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/examples/single_task/single_task_trainer_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3509 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/runner.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    17402 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/standard_runner.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5100 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/standard_runner_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.587015 tf-models-no-deps-2.11.2/orbit/utils/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1218 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     3913 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/common.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1032 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/common_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2136 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/epoch_helper.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     8016 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/loop_fns.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4277 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/summary_manager.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     2253 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/summary_manager_interface.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     5631 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/tpu_summaries.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     4513 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/orbit/utils/tpu_summaries_test.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)       38 2022-12-18 00:04:19.591015 tf-models-no-deps-2.11.2/setup.cfg
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.587015 tf-models-no-deps-2.11.2/tensorflow_models/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      909 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/tensorflow_models/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.587015 tf-models-no-deps-2.11.2/tensorflow_models/nlp/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      807 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/tensorflow_models/nlp/__init__.py
--rw-r-----   0 hongkuny (405338) primarygroup (89939)     1385 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/tensorflow_models/tensorflow_models_test.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.587015 tf-models-no-deps-2.11.2/tensorflow_models/vision/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      833 2022-12-17 23:59:54.000000 tf-models-no-deps-2.11.2/tensorflow_models/vision/__init__.py
-drwxr-x---   0 hongkuny (405338) primarygroup (89939)        0 2022-12-18 00:04:19.587015 tf-models-no-deps-2.11.2/tf_models_no_deps.egg-info/
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      603 2022-12-18 00:04:18.000000 tf-models-no-deps-2.11.2/tf_models_no_deps.egg-info/PKG-INFO
--rw-r-----   0 hongkuny (405338) primarygroup (89939)    44781 2022-12-18 00:04:18.000000 tf-models-no-deps-2.11.2/tf_models_no_deps.egg-info/SOURCES.txt
--rw-r-----   0 hongkuny (405338) primarygroup (89939)        1 2022-12-18 00:04:18.000000 tf-models-no-deps-2.11.2/tf_models_no_deps.egg-info/dependency_links.txt
--rw-r-----   0 hongkuny (405338) primarygroup (89939)      382 2022-12-18 00:04:18.000000 tf-models-no-deps-2.11.2/tf_models_no_deps.egg-info/requires.txt
--rw-r-----   0 hongkuny (405338) primarygroup (89939)       33 2022-12-18 00:04:18.000000 tf-models-no-deps-2.11.2/tf_models_no_deps.egg-info/top_level.txt
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.911001 tf-models-no-deps-2.16.0/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      337 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/AUTHORS
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11512 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/LICENSE
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      584 2024-05-10 21:05:19.911001 tf-models-no-deps-2.16.0/PKG-INFO
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4911 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/README.md
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.655002 tf-models-no-deps-2.16.0/official/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.659002 tf-models-no-deps-2.16.0/official/common/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/common/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1858 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/common/dataset_fn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8572 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/common/distribute_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4914 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/common/distribute_utils_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4286 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/common/flags.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      843 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/common/registry_imports.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1057 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/common/streamz_counters.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.663002 tf-models-no-deps-2.16.0/official/core/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1265 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8476 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/actions.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4525 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/actions_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12968 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/base_task.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18130 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/base_trainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13021 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/base_trainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15555 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/config_definitions.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1115 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/exp_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7035 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/export_base.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4436 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/export_base_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3184 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/file_writers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1997 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/file_writers_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    25827 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/input_reader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3949 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/registry.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2360 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/registry_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9859 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/savedmodel_checkpoint_manager.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4055 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/savedmodel_checkpoint_manager_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2513 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/task_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1887 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/test_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4633 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/tf_example_builder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5803 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/tf_example_builder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2095 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/tf_example_feature_key.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1649 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/tf_example_feature_key_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13921 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/core/train_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9942 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/train_lib_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    22116 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/train_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7903 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/core/train_utils_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.663002 tf-models-no-deps-2.16.0/official/legacy/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.663002 tf-models-no-deps-2.16.0/official/legacy/albert/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/albert/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2012 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/albert/configs.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.667002 tf-models-no-deps-2.16.0/official/legacy/bert/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14941 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/bert_models.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3893 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/bert_models_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4842 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/common_flags.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4177 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5976 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/export_tfhub.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4698 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/export_tfhub_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11734 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/input_pipeline.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2885 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/model_saving_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    25327 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/model_training_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11715 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/model_training_utils_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18836 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/run_classifier.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8420 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/run_pretraining.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5376 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/run_squad.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18955 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/run_squad_helper.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5064 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/bert/serving.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.667002 tf-models-no-deps-2.16.0/official/legacy/detection/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.671002 tf-models-no-deps-2.16.0/official/legacy/detection/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4468 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/configs/base_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1692 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/configs/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3328 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/configs/maskrcnn_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4271 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/configs/olnmask_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1776 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/configs/retinanet_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3204 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/configs/shapemask_config.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.671002 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20699 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/anchor.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6563 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3663 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/input_reader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15741 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/maskrcnn_parser.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1061 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/mode_keys.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14228 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/olnmask_parser.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18293 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/retinanet_parser.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    22341 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/shapemask_parser.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6229 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/tf_example_decoder.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.675002 tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    32823 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/coco_evaluator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15092 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/coco_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2169 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/factory.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.675002 tf-models-no-deps-2.16.0/official/legacy/detection/executor/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/executor/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6269 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/executor/detection_executor.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    30370 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/executor/distributed_executor.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9025 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/main.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.675002 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.679002 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7994 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5986 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/fpn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    48987 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/heads.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      974 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/identity.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11229 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/nn_blocks.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3863 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/nn_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13169 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/resnet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17337 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/spinenet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4449 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/base_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4872 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/checkpoint_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1402 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3810 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/learning_rates.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    30213 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/losses.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13468 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/maskrcnn_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16784 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/olnmask_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1726 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/optimizers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6671 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/retinanet_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12120 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/modeling/shapemask_model.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.679002 tf-models-no-deps-2.16.0/official/legacy/detection/ops/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/ops/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8151 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/ops/nms.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    21952 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/ops/postprocess_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    22996 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/ops/roi_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    26008 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/ops/spatial_transform_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    28314 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/ops/target_ops.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.683002 tf-models-no-deps-2.16.0/official/legacy/detection/utils/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/utils/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    26060 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/utils/box_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1465 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/utils/class_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1585 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/utils/dataloader_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14307 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/utils/input_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6647 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/detection/utils/mask_utils.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.683002 tf-models-no-deps-2.16.0/official/legacy/image_classification/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    37511 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/augment.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4323 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/augment_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9365 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/callbacks.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16205 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/classifier_trainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7765 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/classifier_trainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6057 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/classifier_trainer_util_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.687002 tf-models-no-deps-2.16.0/official/legacy/image_classification/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8797 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/configs/base_configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7571 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/configs/configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19560 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/dataset_factory.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.687002 tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4619 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/common_modules.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3169 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/efficientnet_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16427 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/efficientnet_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2329 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/tfhub_export.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4282 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/learning_rate.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1951 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/learning_rate_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6124 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/mnist_main.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2591 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/mnist_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12613 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/optimizer_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4098 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/optimizer_factory_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13547 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/preprocessing.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.687002 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16304 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/common.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    21178 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/imagenet_preprocessing.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2368 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/resnet_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6926 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/resnet_ctl_imagenet_main.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10955 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/resnet_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8134 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/resnet_runnable.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2199 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/tfhub_export.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1332 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/test_utils.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.687002 tf-models-no-deps-2.16.0/official/legacy/image_classification/vgg/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/vgg/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2115 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/vgg/vgg_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7617 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/image_classification/vgg/vgg_model.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.695002 tf-models-no-deps-2.16.0/official/legacy/transformer/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7129 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/attention_layer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3679 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/beam_search_v1.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5151 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/compute_bleu.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2595 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/compute_bleu_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15291 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/data_download.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13247 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/data_pipeline.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3694 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/embedding_layer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2330 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/ffn_layer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7017 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/metrics.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10356 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/misc.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2936 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/model_params.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4437 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/model_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1901 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/model_utils_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2444 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/optimizer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    21761 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/transformer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6070 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_forward_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3576 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_layers_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18193 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_main.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6641 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_main_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3638 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6961 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/translate.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.695002 tf-models-no-deps-2.16.0/official/legacy/transformer/utils/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/utils/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16706 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/utils/metrics.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24527 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/utils/tokenizer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6668 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/transformer/utils/tokenizer_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.699002 tf-models-no-deps-2.16.0/official/legacy/xlnet/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5421 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/classifier_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5367 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/common_flags.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    30105 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/data_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3779 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/optimization.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15354 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/preprocess_classification_data.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    32391 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/preprocess_pretrain_data.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4056 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/preprocess_squad_data.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3693 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/preprocess_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6986 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/run_classifier.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5720 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/run_pretrain.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11607 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/run_squad.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    32236 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/squad_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11674 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/training_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5904 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/xlnet_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    47605 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/legacy/xlnet/xlnet_modeling.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.699002 tf-models-no-deps-2.16.0/official/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.703002 tf-models-no-deps-2.16.0/official/modeling/activations/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1044 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1047 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/gelu.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1067 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/gelu_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1140 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/mish.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      937 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/mish_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      994 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/relu.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1051 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/relu_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1051 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/sigmoid.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1215 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/sigmoid_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2301 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/swish.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1421 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/activations/swish_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6740 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/grad_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2796 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/grad_utils_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.703002 tf-models-no-deps-2.16.0/official/modeling/hyperparams/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      846 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/hyperparams/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12519 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/hyperparams/base_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12636 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/hyperparams/base_config_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1870 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/hyperparams/oneof.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1991 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/hyperparams/oneof_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17810 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/hyperparams/params_dict.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14673 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/hyperparams/params_dict_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.707002 tf-models-no-deps-2.16.0/official/modeling/multitask/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1946 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/base_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5856 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/base_trainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3663 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/base_trainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3164 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6078 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/evaluator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4643 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/evaluator_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4458 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/interleaving_trainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4305 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/interleaving_trainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5948 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/multitask.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4897 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/task_sampler.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3037 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/task_sampler_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4315 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/test_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11616 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/train_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4766 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/multitask/train_lib_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.711002 tf-models-no-deps-2.16.0/official/modeling/optimization/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1201 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      792 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/adafactor_optimizer.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.711002 tf-models-no-deps-2.16.0/official/modeling/optimization/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11122 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/configs/learning_rate_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6082 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/configs/optimization_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2019 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/configs/optimization_config_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13127 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/configs/optimizer_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10518 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/ema_optimizer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10147 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/lamb.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5938 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/lamb_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7348 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/lars.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5963 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/legacy_adamw.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18517 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/lr_schedule.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3961 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/lr_schedule_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10539 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/optimizer_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17025 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/optimizer_factory_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      707 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/optimization/slide_optimizer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2169 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/performance.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.711002 tf-models-no-deps-2.16.0/official/modeling/privacy/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/privacy/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      960 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/privacy/configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1369 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/privacy/configs_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2054 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/privacy/ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1694 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/privacy/ops_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12156 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/tf_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3776 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/modeling/tf_utils_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.711002 tf-models-no-deps-2.16.0/official/nlp/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.715002 tf-models-no-deps-2.16.0/official/nlp/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1551 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/bert.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1467 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/electra.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    31048 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/encoders.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1973 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/encoders_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      845 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/experiment_configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6571 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/finetuning_experiments.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4775 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/pretraining_experiments.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3791 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/configs/wmt_transformer_experiments.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7894 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/continuous_finetune_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3192 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/continuous_finetune_lib_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.723002 tf-models-no-deps-2.16.0/official/nlp/data/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    57080 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/classifier_data_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3362 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/classifier_data_lib_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16705 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/create_finetuning_data.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24265 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/create_pretraining_data.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4817 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/create_pretraining_data_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24200 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/create_xlnet_pretraining_data.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10940 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/create_xlnet_pretraining_data_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1698 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/data_loader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1788 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/data_loader_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1335 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/data_loader_factory_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5819 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/dual_encoder_dataloader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5050 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/dual_encoder_dataloader_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24602 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/pretrain_dataloader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9151 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/pretrain_dataloader_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9824 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/pretrain_dynamic_dataloader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9630 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/pretrain_dynamic_dataloader_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9007 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/pretrain_text_dataloader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4474 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/question_answering_dataloader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2840 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/question_answering_dataloader_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10347 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/sentence_prediction_dataloader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11672 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/sentence_prediction_dataloader_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6413 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/sentence_retrieval_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    36524 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/squad_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    34951 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/squad_lib_sp.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15499 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/tagging_data_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3747 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/tagging_data_lib_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3347 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/tagging_dataloader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3206 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/tagging_dataloader_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4523 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/train_sentencepiece.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11184 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/wmt_dataloader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4901 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/data/wmt_dataloader_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.723002 tf-models-no-deps-2.16.0/official/nlp/metrics/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/metrics/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6587 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/metrics/bleu.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2508 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/metrics/bleu_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.723002 tf-models-no-deps-2.16.0/official/nlp/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1062 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.739002 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4780 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3906 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3536 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    21111 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/bigbird_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2206 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/bigbird_attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7243 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/block_diag_feedforward.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4181 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/block_diag_feedforward_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16208 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/cls_head.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8888 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/cls_head_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2902 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/factorized_embedding.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2589 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/factorized_embedding_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9691 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/gated_feedforward.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4494 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/gated_feedforward_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20450 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/gaussian_process.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10101 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/gaussian_process_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    34885 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/kernel_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9483 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/kernel_attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4924 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/masked_lm.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5947 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/masked_lm_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3000 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/masked_softmax.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4403 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/masked_softmax_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2260 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mat_mul_with_margin.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2032 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mat_mul_with_margin_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9743 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mixing.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3559 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mixing_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    23481 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mobile_bert_layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10890 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mobile_bert_layers_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    27440 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/moe.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9414 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/moe_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7322 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/multi_channel_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1922 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/multi_channel_attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4582 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/on_device_embedding.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8589 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/on_device_embedding_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10289 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/pack_optimization.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2795 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/pack_optimization_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3416 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/per_dim_scale_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1761 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/per_dim_scale_attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11347 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/position_embedding.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8019 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/position_embedding_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20557 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/relative_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6695 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/relative_attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    25668 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/reuse_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14329 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/reuse_attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15697 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/reuse_transformer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17201 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/reuse_transformer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12539 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/rezero_transformer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5761 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/rezero_transformer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4469 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/routing.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2226 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/routing_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2173 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/self_attention_mask.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10738 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/spectral_normalization.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3121 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/spectral_normalization_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6913 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/talking_heads_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7022 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/talking_heads_attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    32526 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/text_layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24255 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/text_layers_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6713 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/tn_expand_condense.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5900 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/tn_expand_condense_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11032 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/tn_transformer_expand_condense.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8893 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/tn_transformer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20087 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20237 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_encoder_block.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    28304 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_encoder_block_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15704 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_scaffold.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19920 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_scaffold_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5522 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    22190 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_xl.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9396 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_xl_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2733 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/layers/util.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.739002 tf-models-no-deps-2.16.0/official/nlp/modeling/losses/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      824 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/losses/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2869 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8474 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.743002 tf-models-no-deps-2.16.0/official/nlp/modeling/models/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1654 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5906 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_classifier.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4825 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_classifier_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11490 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_pretrainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9910 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_pretrainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5007 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_span_labeler.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4779 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_span_labeler_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5226 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_token_classifier.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4845 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_token_classifier_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6593 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/dual_encoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5130 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/dual_encoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13046 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/electra_pretrainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6513 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/electra_pretrainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    26901 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/seq2seq_transformer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6858 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/seq2seq_transformer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    58181 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/t5.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    29617 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/t5_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12014 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/xlnet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12618 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/models/xlnet_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.747002 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1839 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8887 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/albert_encoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7117 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/albert_encoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14239 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/bert_dense_encoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    26288 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/bert_encoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    29165 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/bert_encoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4232 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7071 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/classification_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17153 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/encoder_scaffold.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    29066 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/encoder_scaffold_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14586 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/fnet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4553 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/fnet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24127 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/funnel_transformer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17562 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/funnel_transformer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8621 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/mobile_bert_encoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7115 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/mobile_bert_encoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12810 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/packed_sequence_embedding.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5076 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/packed_sequence_embedding_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13205 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/span_labeling.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11984 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/span_labeling_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17460 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/sparse_mixer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5202 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/sparse_mixer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    25867 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/xlnet_base.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14788 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/networks/xlnet_base_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.751002 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1011 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    29830 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/beam_search.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5749 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/beam_search_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11279 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/decoding_module.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2623 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/decoding_module_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19250 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/sampling_module.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9603 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/segment_extractor.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5408 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/modeling/ops/segment_extractor_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3888 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/optimization.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.751002 tf-models-no-deps-2.16.0/official/nlp/serving/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/serving/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6225 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/serving/export_savedmodel.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6523 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/serving/export_savedmodel_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2593 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/serving/export_savedmodel_util.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18899 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/serving/serving_modules.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15078 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/serving/serving_modules_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.755002 tf-models-no-deps-2.16.0/official/nlp/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1178 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7787 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/dual_encoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4571 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/dual_encoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9860 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/electra_task.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2292 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/electra_task_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7987 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/masked_lm.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3932 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/masked_lm_determinism_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2170 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/masked_lm_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19979 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/question_answering.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10012 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/question_answering_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12648 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/sentence_prediction.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10440 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/sentence_prediction_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10230 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/tagging.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6417 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/tagging_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13566 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/translation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6881 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/translation_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2585 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tasks/utils.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.759002 tf-models-no-deps-2.16.0/official/nlp/tools/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9443 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/export_tfhub.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    21401 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/export_tfhub_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    46357 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/export_tfhub_lib_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3724 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/squad_evaluate_v1_1.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8625 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/squad_evaluate_v2_0.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7865 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/tf1_bert_checkpoint_converter_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6686 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/tf2_albert_encoder_checkpoint_converter.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5836 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/tf2_bert_encoder_checkpoint_converter.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16601 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/tokenization.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5227 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/tools/tokenization_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4224 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/nlp/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.759002 tf-models-no-deps-2.16.0/official/projects/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.759002 tf-models-no-deps-2.16.0/official/projects/bigbird/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/bigbird/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9359 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/bigbird/encoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2350 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/bigbird/encoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3774 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/bigbird/experiment_configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9037 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/bigbird/recompute_grad.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5952 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/bigbird/recomputing_dropout.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4931 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/bigbird/stateless_dropout.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.759002 tf-models-no-deps-2.16.0/official/projects/centernet/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.759002 tf-models-no-deps-2.16.0/official/projects/centernet/common/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/common/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      999 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/common/registry_imports.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.759002 tf-models-no-deps-2.16.0/official/projects/centernet/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1110 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/configs/backbones.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8005 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/configs/centernet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1611 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/configs/centernet_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.759002 tf-models-no-deps-2.16.0/official/projects/centernet/dataloaders/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/dataloaders/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12572 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/dataloaders/centernet_input.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.763002 tf-models-no-deps-2.16.0/official/projects/centernet/losses/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/losses/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4558 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/losses/centernet_losses.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3787 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/losses/centernet_losses_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.763002 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.763002 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/backbones/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/backbones/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10295 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/backbones/hourglass.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1612 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/backbones/hourglass_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2626 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/centernet_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2585 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/centernet_model_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.763002 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/heads/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/heads/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3843 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/heads/centernet_head.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2435 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/heads/centernet_head_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.763002 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12210 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/cn_nn_blocks.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5158 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/cn_nn_blocks_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14242 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/detection_generator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4628 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/detection_generator_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.767001 tf-models-no-deps-2.16.0/official/projects/centernet/ops/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/ops/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6823 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/ops/box_list.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12866 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/ops/box_list_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7568 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/ops/loss_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3933 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/ops/nms_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19023 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/ops/preprocess_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16245 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/ops/target_assigner.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6827 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/ops/target_assigner_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.767001 tf-models-no-deps-2.16.0/official/projects/centernet/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16794 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/tasks/centernet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2522 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.767001 tf-models-no-deps-2.16.0/official/projects/centernet/utils/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/utils/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.767001 tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9675 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/config_classes.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4085 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/config_data.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6042 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/load_weights.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3762 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/read_checkpoints.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5337 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/centernet/utils/tf2_centernet_checkpoint_converter.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.767001 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.771001 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/common/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/common/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      775 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/common/registry_imports.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.771001 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8024 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1228 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn_config_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.771001 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.771001 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    21715 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/hourglass_network.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11476 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/instance_heads.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3182 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/instance_heads_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9666 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/maskrcnn_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5741 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/maskrcnn_model_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.771001 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5504 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/detection.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6362 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/detection_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3991 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/export_saved_model.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.771001 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9436 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/tasks/deep_mask_head_rcnn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2630 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.775002 tf-models-no-deps-2.16.0/official/projects/maxvit/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.775002 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1116 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3466 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/backbones.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2197 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/image_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1584 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/image_classification_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5017 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/rcnn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1403 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/rcnn_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1483 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/retinanet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1688 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/retinanet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8657 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/semantic_segmentation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1583 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/configs/semantic_segmentation_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.775002 tf-models-no-deps-2.16.0/official/projects/maxvit/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/modeling/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8464 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/modeling/common_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    28938 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/modeling/layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    32309 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/modeling/maxvit.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4753 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/modeling/maxvit_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      934 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/registry_imports.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      958 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/train.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3015 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/maxvit/train_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.779002 tf-models-no-deps-2.16.0/official/projects/mobilebert/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/mobilebert/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    25430 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/mobilebert/distillation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7267 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/mobilebert/distillation_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3699 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/mobilebert/export_tfhub.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7470 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/mobilebert/model_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5486 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/mobilebert/run_distillation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10709 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/mobilebert/tf2_model_checkpoint_converter.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1036 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/mobilebert/utils.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.779002 tf-models-no-deps-2.16.0/official/projects/movinet/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.779002 tf-models-no-deps-2.16.0/official/projects/movinet/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4538 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/configs/movinet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1606 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/configs/movinet_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.783002 tf-models-no-deps-2.16.0/official/projects/movinet/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/modeling/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    29513 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    62649 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14967 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_layers_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9810 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8848 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_model_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7873 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.783002 tf-models-no-deps-2.16.0/official/projects/movinet/tools/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/tools/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3819 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/tools/convert_3d_2plus1d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2007 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/tools/convert_3d_2plus1d_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11704 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/tools/export_saved_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4461 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/tools/export_saved_model_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11994 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/tools/quantize_movinet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3320 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/train.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3129 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/movinet/train_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.787001 tf-models-no-deps-2.16.0/official/projects/nhnet/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3202 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3126 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/configs_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15322 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/decoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6034 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/decoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6101 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/evaluation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9063 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/input_pipeline.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    23139 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/models.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11796 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/models_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2819 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/optimizer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3735 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/raw_data_process.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9253 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/raw_data_processor.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8910 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/trainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3299 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/trainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3304 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/nhnet/utils.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.787001 tf-models-no-deps-2.16.0/official/projects/panoptic/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/panoptic/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.787001 tf-models-no-deps-2.16.0/official/projects/panoptic/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/panoptic/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    26059 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/panoptic/configs/panoptic_deeplab.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11613 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/panoptic/configs/panoptic_maskrcnn.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.787001 tf-models-no-deps-2.16.0/official/projects/panoptic/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/panoptic/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14723 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/panoptic/tasks/panoptic_deeplab.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20333 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/panoptic/tasks/panoptic_maskrcnn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1275 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/panoptic/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.787001 tf-models-no-deps-2.16.0/official/projects/qat/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.787001 tf-models-no-deps-2.16.0/official/projects/qat/nlp/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.791001 tf-models-no-deps-2.16.0/official/projects/qat/nlp/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      713 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1303 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/configs/finetuning_experiments.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.791001 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.791001 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/layers/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/layers/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19448 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/layers/mobile_bert_layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7455 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/layers/multi_head_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14715 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/layers/transformer_encoder_block.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9298 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/layers/transformer_encoder_block_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.791001 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/models/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/models/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5066 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/models/bert_span_labeler.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.791001 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/networks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/networks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4632 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/networks/span_labeling.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5173 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/pretrained_checkpoint_converter.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.791001 tf-models-no-deps-2.16.0/official/projects/qat/nlp/quantization/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/quantization/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14187 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/quantization/configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9381 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/quantization/configs_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1835 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/quantization/helper.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8475 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/quantization/schemes.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1820 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/quantization/wrappers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1039 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/registry_imports.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.795001 tf-models-no-deps-2.16.0/official/projects/qat/nlp/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3597 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/tasks/question_answering.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3858 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/tasks/question_answering_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2636 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/nlp/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.795001 tf-models-no-deps-2.16.0/official/projects/qat/vision/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.795001 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      899 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1786 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/common.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1986 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/image_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1949 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/image_classification_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1721 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/retinanet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1837 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/retinanet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2280 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/semantic_segmentation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2031 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/semantic_segmentation_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.795001 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      757 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11054 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9747 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/factory_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.799002 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/heads/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      743 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/heads/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15789 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/heads/dense_prediction_heads.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3990 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/heads/dense_prediction_heads_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.799002 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/layers/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      991 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/layers/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    30128 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/layers/nn_blocks.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3355 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/layers/nn_blocks_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    38737 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/layers/nn_layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4548 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/layers/nn_layers_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3087 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/segmentation_model.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.799002 tf-models-no-deps-2.16.0/official/projects/qat/vision/n_bit/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1018 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/n_bit/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13661 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/n_bit/configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7772 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/n_bit/configs_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    32597 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/n_bit/nn_blocks.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3663 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/n_bit/nn_blocks_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8369 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/n_bit/nn_layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9743 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/n_bit/schemes.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.803001 tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      643 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11694 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/configs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6807 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/configs_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9799 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/helper.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1938 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/helper_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5067 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/layer_transforms.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3089 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/schemes.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1002 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/registry_imports.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.803001 tf-models-no-deps-2.16.0/official/projects/qat/vision/serving/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/serving/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2405 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/serving/export_module.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5358 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/serving/export_saved_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      904 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/serving/export_tflite.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.803001 tf-models-no-deps-2.16.0/official/projects/qat/vision/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      835 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2316 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/tasks/image_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3160 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/tasks/image_classification_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1760 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/tasks/retinanet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3433 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/tasks/retinanet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1793 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/tasks/semantic_segmentation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      960 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/qat/vision/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.807001 tf-models-no-deps-2.16.0/official/projects/roformer/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2012 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/roformer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4648 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/roformer_attention.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4047 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/roformer_attention_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11384 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/roformer_encoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13517 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/roformer_encoder_block.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12919 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/roformer_encoder_block_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9524 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/roformer_encoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4797 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/roformer_experiments.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2566 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/roformer/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.807001 tf-models-no-deps-2.16.0/official/projects/teams/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/teams/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4106 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/teams/teams.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4424 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/teams/teams_experiments.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18693 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/teams/teams_pretrainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7446 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/teams/teams_pretrainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10299 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/teams/teams_task.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2194 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/teams/teams_task_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1028 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/teams/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.811001 tf-models-no-deps-2.16.0/official/projects/triviaqa/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16330 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/dataset.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2497 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/download_and_prepare.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1560 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/evaluate.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5293 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/evaluation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    21728 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/inputs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4639 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/modeling.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7097 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/predict.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2745 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/prediction.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18797 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/preprocess.py
+-rwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)    10818 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/sentencepiece_pb2.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14297 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/triviaqa/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.811001 tf-models-no-deps-2.16.0/official/projects/video_ssl/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.811001 tf-models-no-deps-2.16.0/official/projects/video_ssl/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      702 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5841 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/configs/video_ssl.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2326 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/configs/video_ssl_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.811001 tf-models-no-deps-2.16.0/official/projects/video_ssl/dataloaders/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/dataloaders/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12672 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/dataloaders/video_ssl_input.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3801 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/dataloaders/video_ssl_input_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.811001 tf-models-no-deps-2.16.0/official/projects/video_ssl/losses/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/losses/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5183 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/losses/losses.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.811001 tf-models-no-deps-2.16.0/official/projects/video_ssl/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/modeling/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6611 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/modeling/video_ssl_model.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.815001 tf-models-no-deps-2.16.0/official/projects/video_ssl/ops/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/ops/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14041 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/ops/video_ssl_preprocess_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1789 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/ops/video_ssl_preprocess_ops_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.815001 tf-models-no-deps-2.16.0/official/projects/video_ssl/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      755 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2531 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/tasks/linear_eval.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6758 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/tasks/pretrain.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2853 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/tasks/pretrain_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2967 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/video_ssl/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.815001 tf-models-no-deps-2.16.0/official/projects/volumetric_models/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.815001 tf-models-no-deps-2.16.0/official/projects/volumetric_models/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1304 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/configs/backbones.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1560 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/configs/decoders.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6315 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/configs/semantic_segmentation_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1652 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/configs/semantic_segmentation_3d_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.815001 tf-models-no-deps-2.16.0/official/projects/volumetric_models/dataloaders/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/dataloaders/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4241 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/dataloaders/segmentation_input_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2170 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/dataloaders/segmentation_input_3d_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.819002 tf-models-no-deps-2.16.0/official/projects/volumetric_models/evaluation/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/evaluation/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5362 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/evaluation/segmentation_metrics.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2378 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/evaluation/segmentation_metrics_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.819002 tf-models-no-deps-2.16.0/official/projects/volumetric_models/losses/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/losses/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5078 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/losses/segmentation_losses.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2108 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/losses/segmentation_losses_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.819002 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.819002 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/backbones/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      728 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/backbones/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7079 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/backbones/unet_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2540 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/backbones/unet_3d_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.819002 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/decoders/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      741 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/decoders/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3575 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/decoders/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3018 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/decoders/factory_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7774 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/decoders/unet_3d_decoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2832 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/decoders/unet_3d_decoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2630 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2004 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/factory_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.823001 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/heads/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/heads/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7511 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/heads/segmentation_heads_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2102 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/heads/segmentation_heads_3d_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19168 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/nn_blocks_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2986 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/nn_blocks_3d_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2866 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/segmentation_model_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1058 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/registry_imports.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.823001 tf-models-no-deps-2.16.0/official/projects/volumetric_models/serving/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/serving/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4426 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/serving/export_saved_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2099 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/serving/semantic_segmentation_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4175 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/serving/semantic_segmentation_3d_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.823001 tf-models-no-deps-2.16.0/official/projects/volumetric_models/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12907 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/tasks/semantic_segmentation_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4079 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/tasks/semantic_segmentation_3d_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1012 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/train.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3082 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/volumetric_models/train_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.823001 tf-models-no-deps-2.16.0/official/projects/waste_identification_ml/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/waste_identification_ml/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.823001 tf-models-no-deps-2.16.0/official/projects/waste_identification_ml/data_generation/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/waste_identification_ml/data_generation/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10239 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/waste_identification_ml/data_generation/utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5340 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/waste_identification_ml/data_generation/utils_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.823001 tf-models-no-deps-2.16.0/official/projects/yolo/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.823001 tf-models-no-deps-2.16.0/official/projects/yolo/common/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/common/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1747 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/common/registry_imports.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.827001 tf-models-no-deps-2.16.0/official/projects/yolo/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1365 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/configs/backbones.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/configs/darknet_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1855 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/configs/decoders.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18648 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/configs/yolo.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12932 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/configs/yolov7.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.827001 tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3800 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/classification_input.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4820 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/tf_example_decoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14616 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/yolo_input.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.827001 tf-models-no-deps-2.16.0/official/projects/yolo/losses/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/losses/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    31734 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/losses/yolo_loss.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3008 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/losses/yolo_loss_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    36629 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/losses/yolov7_loss.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4914 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/losses/yolov7_loss_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.831001 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.831001 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/backbones/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/backbones/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    22025 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/backbones/darknet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4768 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/backbones/darknet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12885 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/backbones/yolov7.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3059 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/backbones/yolov7_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.831001 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/decoders/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/decoders/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    23645 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/decoders/yolo_decoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4814 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/decoders/yolo_decoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15644 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/decoders/yolov7.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3570 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/decoders/yolov7_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6972 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3675 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/factory_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.831001 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/heads/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/heads/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5244 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/heads/yolo_head.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2333 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/heads/yolo_head_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5464 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/heads/yolov7_head.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2734 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/heads/yolov7_head_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.835001 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13284 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/detection_generator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2149 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/detection_generator_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    68770 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/nn_blocks.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14821 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/nn_blocks_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3220 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/yolo_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3215 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/modeling/yolov7_model.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.835001 tf-models-no-deps-2.16.0/official/projects/yolo/ops/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19319 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/anchor.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11203 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/box_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2015 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/box_ops_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      991 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/initializer_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11626 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/kmeans_anchors.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1455 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/kmeans_anchors_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    23492 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/loss_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1686 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/math_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18895 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/mosaic.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    36309 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/preprocessing_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5478 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/ops/preprocessing_ops_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.835001 tf-models-no-deps-2.16.0/official/projects/yolo/optimization/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1099 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/optimization/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.839001 tf-models-no-deps-2.16.0/official/projects/yolo/optimization/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/optimization/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2084 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/optimization/configs/optimization_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2283 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/optimization/configs/optimizer_config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3403 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/optimization/optimizer_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11235 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/optimization/sgd_torch.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.839001 tf-models-no-deps-2.16.0/official/projects/yolo/serving/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/serving/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9955 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/serving/export_module_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4584 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/serving/export_saved_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      902 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/serving/export_tflite.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3018 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/serving/model_fn.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.839001 tf-models-no-deps-2.16.0/official/projects/yolo/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2693 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/tasks/image_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1536 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/tasks/task_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16657 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/tasks/yolo.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17689 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/tasks/yolov7.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      981 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yolo/train.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.839001 tf-models-no-deps-2.16.0/official/projects/yt8m/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.839001 tf-models-no-deps-2.16.0/official/projects/yt8m/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      692 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10403 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/configs/yt8m.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1571 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/configs/yt8m_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.843001 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.843001 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/backbones/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      705 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/backbones/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6375 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/backbones/dbof.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1941 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/backbones/dbof_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.843001 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/heads/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      790 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/heads/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1969 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/heads/logistic.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5272 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/heads/moe.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6898 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/nn_layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2038 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/nn_layers_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5042 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/yt8m_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2719 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/yt8m_model_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4602 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/yt8m_model_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1969 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/yt8m_model_utils_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.843001 tf-models-no-deps-2.16.0/official/projects/yt8m/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      692 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14817 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/tasks/yt8m_task.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      987 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/train.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4853 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/projects/yt8m/train_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.847001 tf-models-no-deps-2.16.0/official/recommendation/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2877 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/constants.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4018 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/create_ncf_data.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    37216 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/data_pipeline.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10318 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/data_preprocessing.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12831 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/data_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9744 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/movielens.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12288 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ncf_common.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6974 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ncf_input_pipeline.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19850 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ncf_keras_main.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4144 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ncf_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16950 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/neumf_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1917 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/popen_helper.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.847001 tf-models-no-deps-2.16.0/official/recommendation/ranking/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3998 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/common.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.847001 tf-models-no-deps-2.16.0/official/recommendation/ranking/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11435 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/configs/config.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1474 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/configs/config_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.851001 tf-models-no-deps-2.16.0/official/recommendation/ranking/data/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/data/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7329 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/data/data_pipeline.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2345 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/data/data_pipeline_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8909 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/task.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2175 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/task_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6604 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/train.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4894 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/recommendation/ranking/train_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3076 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/recommendation/stat_utils.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.851001 tf-models-no-deps-2.16.0/official/utils/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.851001 tf-models-no-deps-2.16.0/official/utils/docs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/docs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3860 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/docs/build_orbit_api_docs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6447 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/docs/build_tfm_api_docs.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.851001 tf-models-no-deps-2.16.0/official/utils/flags/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6405 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/_base.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4082 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/_benchmark.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1618 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/_conventions.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2826 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/_device.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1704 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/_distribution.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1541 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/_misc.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11576 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/_performance.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4427 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/core.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5312 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/flags/flags_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4607 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/hyperparams_flags.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.855001 tf-models-no-deps-2.16.0/official/utils/misc/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/misc/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7793 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/misc/keras_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3370 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/misc/model_helpers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4559 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/misc/model_helpers_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.855001 tf-models-no-deps-2.16.0/official/utils/testing/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/testing/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2220 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/testing/integration.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3312 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/utils/testing/mock_task.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.855001 tf-models-no-deps-2.16.0/official/vision/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      744 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.859001 tf-models-no-deps-2.16.0/official/vision/configs/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1045 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5547 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/configs/backbones.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3614 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/backbones_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5354 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/configs/common.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2080 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/decoders.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24563 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/image_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1867 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/image_classification_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24236 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/maskrcnn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1733 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/maskrcnn_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17752 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/configs/retinanet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1699 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/retinanet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    30616 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/configs/semantic_segmentation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1867 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/semantic_segmentation_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14513 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/configs/video_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1879 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/configs/video_classification_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.859001 tf-models-no-deps-2.16.0/official/vision/data/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    22742 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/create_coco_tf_record.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5039 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/fake_feature_generator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3503 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/image_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4071 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/image_utils_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6061 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/process_coco_few_shot_json_files.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20494 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/tf_example_builder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    27986 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/tf_example_builder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6677 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/tf_example_feature_key.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6326 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/tfrecord_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5081 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/data/tfrecord_lib_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.867001 tf-models-no-deps-2.16.0/official/vision/dataloaders/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13039 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/classification_input.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1016 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/decoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10716 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/input_reader.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1623 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/input_reader_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16822 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/maskrcnn_input.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2315 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/parser.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17372 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/retinanet_input.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11838 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/segmentation_input.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8647 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tf_example_decoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12629 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tf_example_decoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2598 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tf_example_label_map_decoder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7756 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tf_example_label_map_decoder_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1311 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_classification_decoders.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2324 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_detection_decoders.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2568 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4020 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_factory_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2428 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_segmentation_decoders.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12698 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/tfexample_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3113 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2567 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/utils_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17267 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/video_input.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7551 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/dataloaders/video_input_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.871001 tf-models-no-deps-2.16.0/official/vision/evaluation/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15601 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/coco_evaluator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17880 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/coco_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3199 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/coco_utils_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    29114 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/instance_metrics.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10823 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/instance_metrics_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6364 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/iou.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5390 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/iou_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    27447 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/panoptic_quality.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7959 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/panoptic_quality_evaluator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3333 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/panoptic_quality_evaluator_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17714 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/panoptic_quality_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13780 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/segmentation_metrics.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4023 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/segmentation_metrics_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6615 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/evaluation/wod_detection_evaluator.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.871001 tf-models-no-deps-2.16.0/official/vision/losses/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/losses/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3239 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/losses/focal_loss.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1579 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/losses/loss_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17076 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/losses/maskrcnn_losses.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5348 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/losses/maskrcnn_losses_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8107 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/losses/retinanet_losses.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11424 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/losses/segmentation_losses.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3660 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/losses/segmentation_losses_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.875001 tf-models-no-deps-2.16.0/official/vision/modeling/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      869 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.879001 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1329 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12438 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/efficientnet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3762 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/efficientnet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3504 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8393 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/factory_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24896 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/mobiledet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3804 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/mobiledet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    40975 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/mobilenet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10606 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/mobilenet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16384 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18657 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3799 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_3d_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    15840 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_deeplab.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5520 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_deeplab_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5555 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8797 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/revnet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3225 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/revnet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    21154 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/spinenet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20784 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/spinenet_mobile.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3958 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/spinenet_mobile_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4734 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/spinenet_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14438 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/vit.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2412 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/vit_specs.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3463 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/backbones/vit_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4867 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/classification_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7017 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/classification_model_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.883001 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      815 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8610 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/aspp.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3011 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/aspp_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4397 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5631 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/factory_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9822 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/fpn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4284 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/fpn_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14440 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/nasfpn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1897 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/decoders/nasfpn_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17537 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3540 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/factory_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5296 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/factory_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.883001 tf-models-no-deps-2.16.0/official/vision/modeling/heads/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1088 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/heads/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    26846 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/heads/dense_prediction_heads.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8266 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/heads/dense_prediction_heads_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17829 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/heads/instance_heads.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4207 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/heads/instance_heads_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20184 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/heads/segmentation_heads.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3812 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/heads/segmentation_heads_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.887001 tf-models-no-deps-2.16.0/official/vision/modeling/layers/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2597 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3411 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/box_sampler.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8571 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/deeplab.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1904 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/deeplab_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    66301 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/detection_generator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17663 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/detection_generator_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16737 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/edgetpu.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10120 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/edgetpu_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7924 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/mask_sampler.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    72020 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_blocks.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10575 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_blocks_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2038 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_blocks_3d_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    33835 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_blocks_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    52982 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_layers.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    13319 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_layers_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2543 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/roi_aligner.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1285 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/roi_aligner_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14418 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/roi_generator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10006 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/layers/roi_sampler.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20774 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/maskrcnn_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14844 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/maskrcnn_model_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.887001 tf-models-no-deps-2.16.0/official/vision/modeling/models/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1020 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/models/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9705 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/modeling/retinanet_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    11164 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/retinanet_model_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3438 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/segmentation_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2817 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/segmentation_model_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4713 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/video_classification_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3271 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/modeling/video_classification_model_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.891001 tf-models-no-deps-2.16.0/official/vision/ops/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19627 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/anchor.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7274 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/anchor_generator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5296 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/anchor_generator_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7633 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/anchor_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)   103080 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/augment.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    19463 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/augment_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9067 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/box_matcher.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2438 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/box_matcher_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    34618 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/box_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5851 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/iou_similarity.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1908 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/iou_similarity_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10270 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/mask_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2835 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/mask_ops_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8125 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/nms.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    41238 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/preprocess_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16110 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/preprocess_ops_3d.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8364 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/preprocess_ops_3d_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14685 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/ops/preprocess_ops_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16072 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/sampling_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    38389 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/spatial_transform_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3965 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/target_gather.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2561 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/ops/target_gather_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      760 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/registry_imports.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.899001 tf-models-no-deps-2.16.0/official/vision/serving/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      702 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10693 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/serving/detection.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9165 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/detection_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7541 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_base.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2741 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_base_v2.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2880 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_base_v2_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3549 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_module_factory.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4605 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_module_factory_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5758 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_saved_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8116 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_saved_model_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2409 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_saved_model_lib_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3710 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_saved_model_lib_v2.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3500 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_tfhub.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2880 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_tfhub_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5115 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_tflite.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7272 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_tflite_lib.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4881 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/export_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2868 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/serving/image_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4622 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/serving/image_classification_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4023 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/serving/semantic_segmentation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5638 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/semantic_segmentation_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6884 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/video_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4232 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/serving/video_classification_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.899001 tf-models-no-deps-2.16.0/official/vision/tasks/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      995 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/tasks/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    16699 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/tasks/image_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    25569 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/tasks/maskrcnn.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    18210 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/tasks/retinanet.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14243 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/official/vision/tasks/semantic_segmentation.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    14318 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/tasks/video_classification.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4005 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/train.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5735 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/train_spatial_partitioning.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.899001 tf-models-no-deps-2.16.0/official/vision/utils/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.903001 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      609 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     9023 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/argmax_matcher.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    12068 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/balanced_positive_negative_sampler.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4786 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/box_coder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     6749 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/box_list.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    41971 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/box_list_ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3816 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/faster_rcnn_box_coder.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8761 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/matcher.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3084 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/minibatch_sampler.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     7076 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/ops.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    20366 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/preprocessor.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4554 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/region_similarity_calculator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3618 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/shape_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    24208 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/target_assigner.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    40267 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/object_detection/visualization_utils.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4394 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/ops_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2773 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/official/vision/utils/summary_manager.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.903001 tf-models-no-deps-2.16.0/orbit/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1117 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.907001 tf-models-no-deps-2.16.0/orbit/actions/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3327 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/actions/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1988 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/actions/conditional_action.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1335 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/actions/conditional_action_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5960 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/actions/export_saved_model.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    10753 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/actions/export_saved_model_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8489 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/actions/new_best_metric.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4024 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/actions/new_best_metric_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2329 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/actions/save_checkpoint_if_preempted.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    25368 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/controller.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    31802 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/controller_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.907001 tf-models-no-deps-2.16.0/orbit/examples/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      604 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/examples/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.907001 tf-models-no-deps-2.16.0/orbit/examples/single_task/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      604 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/examples/single_task/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3205 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/examples/single_task/single_task_evaluator.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2098 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/examples/single_task/single_task_evaluator_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5657 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/examples/single_task/single_task_trainer.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1971 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/examples/single_task/single_task_trainer_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3519 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/runner.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    17412 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/standard_runner.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5110 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/standard_runner_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.911001 tf-models-no-deps-2.16.0/orbit/utils/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1218 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     3923 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/common.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1042 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/common_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2146 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/epoch_helper.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     8026 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/loop_fns.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4287 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/summary_manager.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     2253 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/summary_manager_interface.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     5641 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/tpu_summaries.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     4523 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/orbit/utils/tpu_summaries_test.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)       38 2024-05-10 21:05:19.911001 tf-models-no-deps-2.16.0/setup.cfg
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.911001 tf-models-no-deps-2.16.0/tensorflow_models/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      909 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/tensorflow_models/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.911001 tf-models-no-deps-2.16.0/tensorflow_models/nlp/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      807 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/tensorflow_models/nlp/__init__.py
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)     1395 2024-05-10 19:45:42.000000 tf-models-no-deps-2.16.0/tensorflow_models/tensorflow_models_test.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.911001 tf-models-no-deps-2.16.0/tensorflow_models/vision/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      833 2024-05-10 19:45:10.000000 tf-models-no-deps-2.16.0/tensorflow_models/vision/__init__.py
+drwxr-x---   0 laxmareddyp (1114418) primarygroup (89939)        0 2024-05-10 21:05:19.911001 tf-models-no-deps-2.16.0/tf_models_no_deps.egg-info/
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      584 2024-05-10 21:05:19.000000 tf-models-no-deps-2.16.0/tf_models_no_deps.egg-info/PKG-INFO
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)    55415 2024-05-10 21:05:19.000000 tf-models-no-deps-2.16.0/tf_models_no_deps.egg-info/SOURCES.txt
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)        1 2024-05-10 21:05:19.000000 tf-models-no-deps-2.16.0/tf_models_no_deps.egg-info/dependency_links.txt
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)      389 2024-05-10 21:05:19.000000 tf-models-no-deps-2.16.0/tf_models_no_deps.egg-info/requires.txt
+-rw-r-----   0 laxmareddyp (1114418) primarygroup (89939)       33 2024-05-10 21:05:19.000000 tf-models-no-deps-2.16.0/tf_models_no_deps.egg-info/top_level.txt
```

### Comparing `tf-models-no-deps-2.11.2/LICENSE` & `tf-models-no-deps-2.16.0/LICENSE`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,17 @@
-Copyright 2016 The TensorFlow Authors.  All rights reserved.
+Copyright 2022 Google LLC. All rights reserved.
+
+All files in the following folders:
+/community
+/official
+/orbit
+/research
+/tensorflow_models
+
+Are licensed as follows:
 
                                  Apache License
                            Version 2.0, January 2004
                         http://www.apache.org/licenses/
 
    TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
```

### Comparing `tf-models-no-deps-2.11.2/PKG-INFO` & `tf-models-no-deps-2.16.0/PKG-INFO`

 * *Files 21% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 Metadata-Version: 2.1
 Name: tf-models-no-deps
-Version: 2.11.2
+Version: 2.16.0
 Summary: TensorFlow Official Models
 Home-page: https://github.com/tensorflow/models
 Author: Google Inc.
 Author-email: packages@tensorflow.org
 License: Apache 2.0
-Platform: UNKNOWN
 Requires-Python: >=3.7
 License-File: LICENSE
 License-File: AUTHORS
 
 The TensorFlow official models are a collection of
 models that use TensorFlow's high-level APIs.
 They are intended to be well-maintained, tested, and kept up to date with the
 latest TensorFlow API. They should also be reasonably optimized for fast
 performance while still being easy to read.
-
```

### Comparing `tf-models-no-deps-2.11.2/official/__init__.py` & `tf-models-no-deps-2.16.0/official/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/common/__init__.py` & `tf-models-no-deps-2.16.0/official/common/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/common/dataset_fn.py` & `tf-models-no-deps-2.16.0/official/common/dataset_fn.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -27,15 +27,15 @@
 # limitations under the License.
 # ==============================================================================
 """Utility library for picking an appropriate dataset function."""
 
 import functools
 from typing import Any, Callable, Type, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 PossibleDatasetType = Union[Type[tf.data.Dataset], Callable[[tf.Tensor], Any]]
 
 
 def pick_dataset_fn(file_type: str) -> PossibleDatasetType:
   if file_type == 'tfrecord':
     return tf.data.TFRecordDataset
```

### Comparing `tf-models-no-deps-2.11.2/official/common/distribute_utils.py` & `tf-models-no-deps-2.16.0/official/common/distribute_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Helper functions for running models in a distributed setting."""
 
 import json
 import os
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _collective_communication(all_reduce_alg):
   """Return a CollectiveCommunication based on all_reduce_alg.
 
   Args:
     all_reduce_alg: a string specifying which collective communication to pick,
```

### Comparing `tf-models-no-deps-2.11.2/official/common/distribute_utils_test.py` & `tf-models-no-deps-2.16.0/official/common/distribute_utils_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for distribution util functions."""
 
 import sys
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import distribute_utils
 
 TPU_TEST = 'test_tpu' in sys.argv[0]
 
 
 class DistributeUtilsTest(tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/common/flags.py` & `tf-models-no-deps-2.16.0/official/common/flags.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -105,7 +105,10 @@
       default=None,
       help='The Cloud TPU to use for training. This should be either the name '
       'used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 '
       'url.')
 
   flags.DEFINE_string(
       'tf_data_service', default=None, help='The tf.data service address')
+
+  flags.DEFINE_string(
+      'tpu_platform', default=None, help='TPU platform type.')
```

### Comparing `tf-models-no-deps-2.11.2/official/common/registry_imports.py` & `tf-models-no-deps-2.16.0/official/common/registry_imports.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/common/streamz_counters.py` & `tf-models-no-deps-2.16.0/official/common/streamz_counters.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/core/__init__.py` & `tf-models-no-deps-2.16.0/official/core/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/core/actions.py` & `tf-models-no-deps-2.16.0/official/core/actions.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import os
 from typing import List
 from absl import logging
 
 import gin
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_trainer
 from official.core import config_definitions
 from official.modeling import optimization
 
 
 class PruningAction:
@@ -35,24 +35,24 @@
 
   This action must be used when training a pruned model to avoid pruning error.
   """
 
   def __init__(
       self,
       export_dir: str,
-      model: tf.keras.Model,
-      optimizer: tf.keras.optimizers.Optimizer,
+      model: tf_keras.Model,
+      optimizer: tf_keras.optimizers.Optimizer,
   ):
     """Initializes the instance.
 
     Args:
       export_dir: `str` for the export directory of the pruning summaries.
-      model: `tf.keras.Model` model instance used for training. This will be
+      model: `tf_keras.Model` model instance used for training. This will be
         used to assign a pruning step to each prunable weight.
-      optimizer: `tf.keras.optimizers.Optimizer` optimizer instance used for
+      optimizer: `tf_keras.optimizers.Optimizer` optimizer instance used for
         training. This will be used to find the current training steps.
     """
     # TODO(b/221490190): Avoid local import when the bug is fixed.
     import tensorflow_model_optimization as tfmot  # pylint: disable=g-import-not-at-top
     self._optimizer = optimizer
     self.update_pruning_step = tfmot.sparsity.keras.UpdatePruningStep()
     self.update_pruning_step.set_model(model)
@@ -80,22 +80,22 @@
   saves the checkpoint under export_dir/ema_checkpoints. Checkpointing is
   expensive for large models, so doing this action in eval is more efficient
   than training.
   """
 
   def __init__(self,
                export_dir: str,
-               optimizer: tf.keras.optimizers.Optimizer,
+               optimizer: tf_keras.optimizers.Optimizer,
                checkpoint: tf.train.Checkpoint,
                max_to_keep: int = 1):
     """Initializes the instance.
 
     Args:
       export_dir: `str` for the export directory of the EMA average weights.
-      optimizer: `tf.keras.optimizers.Optimizer` optimizer instance used for
+      optimizer: `tf_keras.optimizers.Optimizer` optimizer instance used for
         training. This will be used to swap the model weights with the average
         weigths.
       checkpoint: `tf.train.Checkpoint` instance.
       max_to_keep: `int` for max checkpoints to keep in ema_checkpoints subdir.
     """
     if not isinstance(optimizer, optimization.ExponentialMovingAverage):
       raise ValueError('Optimizer has to be instance of'
@@ -217,8 +217,20 @@
         recovery_max_trials=params.trainer.recovery_max_trials,
     )
     recover_action = orbit.actions.ConditionalAction(
         condition=recovery_condition,
         action=RecoveryAction(checkpoint_manager),
     )
     train_actions.append(recover_action)
+
+  if (
+      params.trainer.preemption_on_demand_checkpoint
+      and trainer.strategy.cluster_resolver
+  ):
+    on_demand_checkpoint_action = orbit.actions.SaveCheckpointIfPreempted(
+        trainer.strategy.cluster_resolver,
+        checkpoint_manager,
+        trainer.global_step,
+        keep_running_after_save=True,
+    )
+    train_actions.append(on_demand_checkpoint_action)
   return train_actions
```

### Comparing `tf-models-no-deps-2.11.2/official/core/actions_test.py` & `tf-models-no-deps-2.16.0/official/core/actions_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,28 +15,28 @@
 """Tests for TFM actions."""
 
 import os
 
 from absl.testing import parameterized
 import numpy as np
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.core import actions
 from official.modeling import optimization
 
 
-class TestModel(tf.keras.Model):
+class TestModel(tf_keras.Model):
 
   def __init__(self):
     super().__init__()
     self.value = tf.Variable(0.0)
-    self.dense = tf.keras.layers.Dense(2)
+    self.dense = tf_keras.layers.Dense(2)
     _ = self.dense(tf.zeros((2, 2), tf.float32))
 
   def call(self, x, training=None):
     return self.value + x
 
 
 class ActionsTest(tf.test.TestCase, parameterized.TestCase):
@@ -47,15 +47,15 @@
               strategy_combinations.cloud_tpu_strategy,
               strategy_combinations.one_device_strategy,
           ],))
   def test_ema_checkpointing(self, distribution):
     with distribution.scope():
       directory = self.create_tempdir()
       model = TestModel()
-      optimizer = tf.keras.optimizers.SGD()
+      optimizer = tf_keras.optimizers.SGD()
       optimizer = optimization.ExponentialMovingAverage(
           optimizer, trainable_weights_only=False)
 
       # Creats average weights for the model variables. Average weights are
       # initialized to zero.
       optimizer.shadow_copy(model)
       checkpoint = tf.train.Checkpoint(model=model)
@@ -77,15 +77,15 @@
 
       # Checks model.value is 0 after swapping.
       self.assertEqual(model(0.), 0)
 
       # Raises an error for a normal optimizer.
       with self.assertRaisesRegex(ValueError,
                                   'Optimizer has to be instance of.*'):
-        _ = actions.EMACheckpointing(directory, tf.keras.optimizers.SGD(),
+        _ = actions.EMACheckpointing(directory, tf_keras.optimizers.SGD(),
                                      checkpoint)
 
   @combinations.generate(
       combinations.combine(
           distribution=[
               strategy_combinations.default_strategy,
               strategy_combinations.cloud_tpu_strategy,
@@ -117,15 +117,15 @@
               strategy_combinations.one_device_strategy_gpu,
               strategy_combinations.one_device_strategy,
           ],))
   def test_pruning(self, distribution):
     with distribution.scope():
       directory = self.get_temp_dir()
       model = TestModel()
-      optimizer = tf.keras.optimizers.SGD()
+      optimizer = tf_keras.optimizers.SGD()
       pruning = actions.PruningAction(directory, model, optimizer)
 
       pruning({})
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/core/base_task.py` & `tf-models-no-deps-2.16.0/official/core/base_task.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Defines the base task abstraction."""
 import abc
 import functools
 from typing import Optional
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions
 from official.modeling import optimization
 from official.modeling import performance
 from official.modeling.privacy import configs
 from official.modeling.privacy import ops
 
@@ -53,15 +53,17 @@
         ConfigDict, namedtuple, etc.
       logging_dir: a string pointing to where the model, summaries etc. will be
         saved. You can also write additional stuff in this directory.
       name: the task name.
     """
     super().__init__(name=name)
     self._task_config = params
-    self._logging_dir = logging_dir
+    self._logging_dir = (
+        logging_dir or ""
+    )  # Empty directory hints current working dir.
 
   @property
   def task_config(self):
     return self._task_config
 
   @property
   def logging_dir(self) -> str:
@@ -104,15 +106,15 @@
       optimizer = performance.configure_optimizer(
           optimizer,
           use_float16=runtime_config.mixed_precision_dtype == "float16",
           loss_scale=runtime_config.loss_scale)
 
     return optimizer
 
-  def initialize(self, model: tf.keras.Model):
+  def initialize(self, model: tf_keras.Model):
     """[Optional] A callback function used as CheckpointManager's init_fn.
 
     This function will be called when no checkpoint is found for the model.
     If there is a checkpoint, the checkpoint will be loaded and this function
     will not be called. You can use this callback function to load a pretrained
     checkpoint, saved under a directory other than the model_dir.
 
@@ -135,15 +137,15 @@
       checkpoint_items = dict(model=model)
     ckpt = tf.train.Checkpoint(**checkpoint_items)
     status = ckpt.read(ckpt_dir_or_file)
     status.expect_partial().assert_existing_objects_matched()
     logging.info("Finished loading pretrained checkpoint from %s",
                  ckpt_dir_or_file)
 
-  def build_model(self) -> tf.keras.Model:
+  def build_model(self) -> tf_keras.Model:
     """[Optional] Creates model architecture.
 
     Returns:
       A model instance.
     """  # pytype: disable=bad-return-type  # typed-keras
 
   @abc.abstractmethod
@@ -216,16 +218,16 @@
       model_outputs: a tensor or a nested structure of tensors. For example,
         output of the keras model built by self.build_model.
     """
     compiled_metrics.update_state(labels, model_outputs)
 
   def train_step(self,
                  inputs,
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
+                 model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer,
                  metrics=None):
     """Does forward and backward.
 
     With distribution strategies, this method runs on devices.
 
     Args:
       inputs: a dictionary of input tensors.
@@ -254,34 +256,34 @@
       # Scales loss as the default gradients allreduce performs sum inside the
       # optimizer.
       scaled_loss = loss / tf.distribute.get_strategy().num_replicas_in_sync
 
       # For mixed precision, when a LossScaleOptimizer is used, the loss is
       # scaled to avoid numeric underflow.
       if isinstance(optimizer,
-                    tf.keras.mixed_precision.LossScaleOptimizer):
+                    tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
 
     if isinstance(optimizer,
-                  tf.keras.mixed_precision.LossScaleOptimizer):
+                  tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
     optimizer.apply_gradients(list(zip(grads, tvars)))
     logs = {self.loss: loss}
     if metrics:
       self.process_metrics(metrics, labels, outputs)
     if model.compiled_metrics:
       self.process_compiled_metrics(model.compiled_metrics, labels, outputs)
       logs.update({m.name: m.result() for m in metrics or []})
       logs.update({m.name: m.result() for m in model.metrics})
     return logs
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics=None):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics=None):
     """Validation step.
 
     With distribution strategies, this method runs on devices.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
@@ -302,15 +304,15 @@
       self.process_metrics(metrics, labels, outputs)
     if model.compiled_metrics:
       self.process_compiled_metrics(model.compiled_metrics, labels, outputs)
       logs.update({m.name: m.result() for m in metrics or []})
       logs.update({m.name: m.result() for m in model.metrics})
     return logs
 
-  def inference_step(self, inputs, model: tf.keras.Model):
+  def inference_step(self, inputs, model: tf_keras.Model):
     """Performs the forward step.
 
     With distribution strategies, this method runs on devices.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
```

### Comparing `tf-models-no-deps-2.11.2/official/core/base_trainer.py` & `tf-models-no-deps-2.16.0/official/core/base_trainer.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,15 +19,15 @@
 interchangable and independent on model architectures and tasks.
 """
 import functools
 from typing import Union, Optional
 from absl import logging
 import gin
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions
 from official.modeling import optimization
 
 ExperimentConfig = config_definitions.ExperimentConfig
 TrainerConfig = config_definitions.TrainerConfig
@@ -43,26 +43,37 @@
         self._strategy, tf.distribute.experimental.ParameterServerStrategy)
     self._coordinator = None
     if self._is_async:
       self._coordinator = (
           tf.distribute.experimental.coordinator.ClusterCoordinator(
               self._strategy))
 
+  def coordinator_for_async(
+      self,
+  ) -> tf.distribute.experimental.coordinator.ClusterCoordinator:
+    if not self._coordinator:
+      raise ValueError(
+          "Coordinator uninitialized for async run. Call init_async() first."
+      )
+    return self._coordinator
+
   def join(self):
     """Join all async steps. Only useful in aysnc training."""
     if getattr(self, "_is_async", False):
-      self._coordinator.join()
+      self.coordinator_for_async().join()
 
   def create_train_loop_fn(self):
     """Creates a eval loop from the given step function and options."""
     train_loop_fn = super().create_train_loop_fn()
     if getattr(self, "_is_async", False):
 
       def _async_loop_fn(iterator, num_steps):
-        self._coordinator.schedule(train_loop_fn, args=(iterator, num_steps))
+        self.coordinator_for_async().schedule(
+            train_loop_fn, args=(iterator, num_steps)
+        )
 
       return _async_loop_fn
     else:
       return train_loop_fn
 
   def create_eval_loop_fn(self, has_state: bool):
     """Creates a training loop from the given step function and options."""
@@ -72,15 +83,17 @@
       if has_state:
         raise ValueError(
             "Stateful eval loop is not supported in async training.")
 
       def _async_loop_fn(iterator, num_steps, state=None, reduce_fn=None):
         assert state is None
         assert reduce_fn is None
-        self._coordinator.schedule(eval_loop_fn, args=(iterator, num_steps))
+        self.coordinator_for_async().schedule(
+            eval_loop_fn, args=(iterator, num_steps)
+        )
 
       return _async_loop_fn
     else:
       return eval_loop_fn
 
   def distribute_dataset(self, dataset_or_fn, *args, **kwargs):
     """A utility function to help create a `tf.distribute.DistributedDataset`.
@@ -98,15 +111,17 @@
     """
     if getattr(self, "_is_async", False):
       per_worker_dataset_fn = functools.partial(
           orbit.utils.make_distributed_dataset, self._strategy, dataset_or_fn,
           *args, **kwargs)
       per_worker_dataset_fn = tf.function(per_worker_dataset_fn)
 
-      return self._coordinator.create_per_worker_dataset(per_worker_dataset_fn)
+      return self.coordinator_for_async().create_per_worker_dataset(
+          per_worker_dataset_fn
+      )
     else:
       return orbit.utils.make_distributed_dataset(self._strategy, dataset_or_fn,
                                                   *args, **kwargs)
 
 
 def get_runtime_options(config: ExperimentConfig):
   """Get tf.distribute.RunOptions from config."""
@@ -123,29 +138,29 @@
   """Implements the common trainer shared for TensorFlow models."""
 
   # pylint: disable=super-init-not-called
   def __init__(
       self,
       config: ExperimentConfig,
       task: base_task.Task,
-      model: tf.keras.Model,
+      model: tf_keras.Model,
       optimizer: tf.optimizers.Optimizer,
       train: bool = True,
       evaluate: bool = True,
       train_dataset: Optional[Union[tf.data.Dataset,
                                     tf.distribute.DistributedDataset]] = None,
       validation_dataset: Optional[Union[
           tf.data.Dataset, tf.distribute.DistributedDataset]] = None,
       checkpoint_exporter=None):
     """Initialize common trainer for TensorFlow models.
 
     Args:
       config: An `ExperimentConfig` instance specifying experiment config.
       task: A base_task.Task instance.
-      model: The model instance, e.g. a tf.keras.Model instance.
+      model: The model instance, e.g. a tf_keras.Model instance.
       optimizer: tf.optimizers.Optimizer instance.
       train: bool, whether or not this trainer will be used for training.
         default to True.
       evaluate: bool, whether or not this trainer will be used for evaluation.
         default to True.
       train_dataset: a dataset object created for training. With tf.distribute,
         it needs to be a `DistributedDataset`.
@@ -188,16 +203,16 @@
       checkpoint_items = {}
     self._checkpoint = tf.train.Checkpoint(
         global_step=self.global_step,
         model=self.model,
         optimizer=self.optimizer,
         **checkpoint_items)
 
-    self._train_loss = tf.keras.metrics.Mean("training_loss", dtype=tf.float32)
-    self._validation_loss = tf.keras.metrics.Mean(
+    self._train_loss = tf_keras.metrics.Mean("training_loss", dtype=tf.float32)
+    self._validation_loss = tf_keras.metrics.Mean(
         "validation_loss", dtype=tf.float32)
     model_metrics = model.metrics if hasattr(model, "metrics") else []
 
     self.init_async()
 
     if train:
       self._train_metrics = self.task.build_metrics(
@@ -339,14 +354,36 @@
             self.optimizer.iterations)
       else:
         logs["learning_rate"] = self.optimizer.learning_rate(self.global_step)
     else:
       logs["learning_rate"] = self.optimizer.learning_rate
     return logs
 
+  def next_train_inputs(self, iterator):
+    """Fetches the next inputs for the model during train.
+
+    This method consumes the input iterator and returns the next inputs for the
+    model.
+
+    This method provides a way to control how to fetch the next model input, and
+    what data to send to the model.
+
+    Note: This function runs on the host side when accelerators are used.
+
+    Note: Depending on the training setup this may or may not run in eager mode.
+    In most cases it will be run in graph mode.
+
+    Args:
+      iterator: Dataset iterator to generate the next inputs from.
+
+    Returns:
+      The inputs to the model.
+    """
+    return next(iterator)
+
   def train_step(self, iterator):
     """See base class."""
 
     def step_fn(inputs):
       if self.config.runtime.enable_xla and (self.config.runtime.num_gpus > 0):
         task_train_step = tf.function(self.task.train_step, jit_compile=True)
       else:
@@ -355,39 +392,79 @@
           inputs,
           model=self.model,
           optimizer=self.optimizer,
           metrics=self.train_metrics)
       self._train_loss.update_state(logs[self.task.loss])
       self.global_step.assign_add(1)
 
-    self.strategy.run(
-        step_fn, args=(next(iterator),), options=self._runtime_options)
+    inputs = self.next_train_inputs(iterator)
+    self.strategy.run(step_fn, args=(inputs,), options=self._runtime_options)
 
   def eval_begin(self):
     """Sets up metrics."""
     for metric in self.validation_metrics + [self.validation_loss]:
       metric.reset_states()
     # Swaps weights to test on weights moving average.
     if self.optimizer and isinstance(self.optimizer,
                                      optimization.ExponentialMovingAverage):
       self.optimizer.swap_weights()
 
+  def next_eval_inputs(self, iterator):
+    """Fetches the next inputs for the model during eval.
+
+    This method consumes the input iterator and returns the next inputs for the
+    model and an additional logs dict. The output dict remains in the host (not
+    sent to GPUs/TPUs) and is merged with the model outputs which will be
+    processed later in `aggregate_logs`. This is useful for sending extra logs
+    downstream that are not compatible with the accelerators.
+
+    Note: This function runs on the host side when accelerators are used.
+
+    Note: Depending on the training setup this may or may not run in eager mode.
+    In most cases it will be run in graph mode.
+
+    Args:
+      iterator: Dataset iterator to generate the next inputs from.
+
+    Returns:
+      The inputs to the model, and an additional logs dictionnary. The logs
+      are not passed to the model, instead they are merged with model output
+      logs.
+    """
+    passthrough_logs = dict()
+    return next(iterator), passthrough_logs
+
   def eval_step(self, iterator):
     """See base class."""
 
     def step_fn(inputs):
       logs = self.task.validation_step(
           inputs, model=self.model, metrics=self.validation_metrics)
       if self.task.loss in logs:
         self._validation_loss.update_state(logs[self.task.loss])
       return logs
 
-    distributed_outputs = self.strategy.run(step_fn, args=(next(iterator),))
-    return tf.nest.map_structure(self.strategy.experimental_local_results,
-                                 distributed_outputs)
+    inputs, passthrough_logs = self.next_eval_inputs(iterator)
+    distributed_outputs = self.strategy.run(step_fn, args=(inputs,))
+    logs = tf.nest.map_structure(
+        self.strategy.experimental_local_results, distributed_outputs
+    )
+
+    if set(logs.keys()) & set(passthrough_logs.keys()):
+      logging.warning(
+          (
+              "Conflict between the pasthrough log keys and the returned model"
+              " log keys. Found %r keys in the passthrough logs and %r keys in"
+              " the model logs. Model log keys takes precedence."
+          ),
+          logs.keys(),
+          passthrough_logs.keys(),
+      )
+
+    return {**passthrough_logs, **logs}
 
   def eval_end(self, aggregated_logs=None):
     """Processes evaluation results."""
     self.join()
     logs = {}
     for metric in self.validation_metrics:
       logs[metric.name] = metric.result()
```

### Comparing `tf-models-no-deps-2.11.2/official/core/base_trainer_test.py` & `tf-models-no-deps-2.16.0/official/core/base_trainer_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,15 +18,15 @@
 import multiprocessing
 import os
 import sys
 
 from absl.testing import parameterized
 import orbit
 import portpicker
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.core import base_trainer as trainer_lib
 from official.core import config_definitions as cfg
 from official.core import train_lib
 from official.utils.testing import mock_task
@@ -308,24 +308,24 @@
                 'learning_rate': {
                     'type': 'constant'
                 },
             })))
     trainer = self.create_test_trainer(config)
     if mixed_precision_dtype == 'float16':
       self.assertIsInstance(trainer.optimizer,
-                            tf.keras.mixed_precision.LossScaleOptimizer)
+                            tf_keras.mixed_precision.LossScaleOptimizer)
       if loss_scale in (None, 'dynamic'):
         self.assertTrue(trainer.optimizer.dynamic)
       else:
         self.assertFalse(trainer.optimizer.dynamic)
         self.assertEqual(trainer.optimizer.initial_scale, loss_scale)
     else:
       self.assertIsInstance(
           trainer.optimizer,
-          (tf.keras.optimizers.SGD, tf.keras.optimizers.legacy.SGD))
+          (tf_keras.optimizers.SGD, tf_keras.optimizers.legacy.SGD))
 
     metrics = trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))
     self.assertIn('training_loss', metrics)
 
   def test_export_best_ckpt(self):
     config = cfg.ExperimentConfig(
         trainer=cfg.TrainerConfig(
@@ -345,15 +345,15 @@
     trainer.evaluate(tf.convert_to_tensor(1, dtype=tf.int32))
     self.assertTrue(
         tf.io.gfile.exists(os.path.join(model_dir, 'best_ckpt', 'info.json')))
 
   def test_model_with_compiled_loss(self):
     task = mock_task.MockTask()
     model = task.build_model()
-    model.compile(loss=tf.keras.losses.CategoricalCrossentropy())
+    model.compile(loss=tf_keras.losses.CategoricalCrossentropy())
     trainer = trainer_lib.Trainer(
         self._config,
         task,
         model=model,
         optimizer=task.create_optimizer(self._config.trainer.optimizer_config))
     logs = trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))
     self.assertIn('training_loss', logs)
```

### Comparing `tf-models-no-deps-2.11.2/official/core/config_definitions.py` & `tf-models-no-deps-2.16.0/official/core/config_definitions.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -51,14 +51,16 @@
       dataset after applying the decode_fn and parse_fn. It can be used to avoid
       re-reading from disk, re-decoding and re-parsing the example on the second
       epoch, but it requires significant memory overhead.
     cycle_length: The number of files that will be processed concurrently when
       interleaving files.
     block_length: The number of consecutive elements to produce from each input
       element before cycling to another input element when interleaving files.
+    ram_budget: RAM budget for tf.data service in GB. If None, tf.data will use
+      50% of the available host RAM.
     deterministic: A boolean controlling whether determinism should be enforced.
     sharding: Whether sharding is used in the input pipeline.
     enable_tf_data_service: A boolean indicating whether to enable tf.data
       service for the input pipeline.
     tf_data_service_address: The URI of a tf.data service to offload
       preprocessing onto during training. The URI should be in the format
       "protocol://address", e.g. "grpc://tf-data-service:5050". It can be
@@ -100,38 +102,42 @@
       automatically set if this field is needed. Users does not need to set it
       when creating experiment configs.
     seed: An optional seed to use for deterministic shuffling/preprocessing.
     prefetch_buffer_size: An int specifying the buffer size of prefetch
       datasets. If None, the buffer size is autotuned. Specifying this is useful
       in case autotuning uses up too much memory by making the buffer size too
       high.
+    autotune_algorithm: If specified, use this algorithm for AUTOTUNE. See:
+      https://www.tensorflow.org/api_docs/python/tf/data/experimental/AutotuneAlgorithm
   """
   input_path: Union[Sequence[str], str, base_config.Config] = ""
-  tfds_name: str = ""
+  tfds_name: Union[str, base_config.Config] = ""
   tfds_split: str = ""
   global_batch_size: int = 0
-  is_training: bool = None
+  is_training: Optional[bool] = None
   drop_remainder: bool = True
   shuffle_buffer_size: int = 100
   cache: bool = False
   cycle_length: Optional[int] = None
   block_length: int = 1
+  ram_budget: Optional[int] = None
   deterministic: Optional[bool] = None
   sharding: bool = True
   enable_tf_data_service: bool = False
   tf_data_service_address: Optional[str] = None
   tf_data_service_job_name: Optional[str] = None
   tfds_data_dir: str = ""
   tfds_as_supervised: bool = False
   tfds_skip_decoding_feature: str = ""
   enable_shared_tf_data_service_between_parallel_trainers: bool = False
   apply_tf_data_service_before_batching: bool = False
   trainer_id: Optional[str] = None
   seed: Optional[int] = None
   prefetch_buffer_size: Optional[int] = None
+  autotune_algorithm: Optional[str] = None
 
 
 @dataclasses.dataclass
 class RuntimeConfig(base_config.Config):
   """High-level configurations for Runtime.
 
   These include parameters that are not directly related to the experiment,
@@ -189,14 +195,15 @@
   # already handled in the user side.
   # If None, will respect XLA default.
   tpu_enable_xla_dynamic_padder: Optional[bool] = None
 
   # Global model parallelism configurations.
   num_cores_per_replica: int = 1
   default_shard_dim: int = -1
+  use_tpu_mp_strategy: bool = False
 
   def model_parallelism(self):
     return dict(
         num_cores_per_replica=self.num_cores_per_replica,
         default_shard_dim=self.default_shard_dim)
 
 
@@ -206,14 +213,15 @@
 
   Attributes:
     optimizer_config: optimizer config, it includes optimizer, learning rate,
       and warmup schedule configs.
     train_tf_while_loop: whether or not to use tf while loop.
     train_tf_function: whether or not to use tf_function for training loop.
     eval_tf_function: whether or not to use tf_function for eval.
+    eval_tf_while_loop: whether or not to use tf while loop for eval.
     allow_tpu_summary: Whether to allow summary happen inside the XLA program
       runs on TPU through automatic outside compilation.
     steps_per_loop: number of steps per loop to report training metrics. This
       can also be used to reduce host worker communication in a TPU setup.
     summary_interval: number of steps between each summary.
     checkpoint_interval: number of steps between checkpoints.
     max_to_keep: max checkpoints to keep.
@@ -233,16 +241,20 @@
     best_checkpoint_eval_metric: for exporting the best checkpoint, which
       evaluation metric the trainer should monitor. This can be any evaluation
       metric appears on tensorboard.
     best_checkpoint_metric_comp: for exporting the best checkpoint, how the
       trainer should compare the evaluation metrics. This can be either `higher`
       (higher the better) or `lower` (lower the better).
     validation_summary_subdir: A 'str', sub directory for saving eval summary.
+    preemption_on_demand_checkpoint: whether or not to save on-demand
+      checkpoints after a preemption.
   """
-  optimizer_config: OptimizationConfig = OptimizationConfig()
+  optimizer_config: OptimizationConfig = dataclasses.field(
+      default_factory=OptimizationConfig
+  )
   # Orbit settings.
   train_tf_while_loop: bool = True
   train_tf_function: bool = True
   eval_tf_function: bool = True
   eval_tf_while_loop: bool = False
   allow_tpu_summary: bool = False
   # Trainer intervals.
@@ -265,30 +277,36 @@
   loss_upper_bound: float = 1e6
   recovery_begin_steps: int = 0  # Enforcing the loss bound after these steps.
   # When max trials < 0, no recovery module; max trials = 0, we will check
   # the condition and fail the job if the condition happens; max trials > 0,
   # we will retore the model states.
   recovery_max_trials: int = 0
   validation_summary_subdir: str = "validation"
+  # Preemption on-demand checkpoint.
+  preemption_on_demand_checkpoint: bool = True  # copybara-replace
 
 
 @dataclasses.dataclass
 class TaskConfig(base_config.Config):
   """Config passed to task."""
   init_checkpoint: str = ""
   model: Optional[base_config.Config] = None
-  train_data: DataConfig = DataConfig()
-  validation_data: DataConfig = DataConfig()
+  train_data: DataConfig = dataclasses.field(default_factory=DataConfig)
+  validation_data: DataConfig = dataclasses.field(default_factory=DataConfig)
   name: Optional[str] = None
   # Configs for differential privacy
   # These configs are only effective if you use create_optimizer in
   # tensorflow_models/official/core/base_task.py
+  # DEPRECATED b/264611883
   differential_privacy_config: Optional[
       dp_configs.DifferentialPrivacyConfig] = None
+  # Whether to show image summary. Useful to visualize model predictions. Only
+  # work for vision tasks.
+  allow_image_summary: bool = False
 
 
 @dataclasses.dataclass
 class ExperimentConfig(base_config.Config):
   """Top-level configuration."""
-  task: TaskConfig = TaskConfig()
-  trainer: TrainerConfig = TrainerConfig()
-  runtime: RuntimeConfig = RuntimeConfig()
+  task: TaskConfig = dataclasses.field(default_factory=TaskConfig)
+  trainer: TrainerConfig = dataclasses.field(default_factory=TrainerConfig)
+  runtime: RuntimeConfig = dataclasses.field(default_factory=RuntimeConfig)
```

### Comparing `tf-models-no-deps-2.11.2/official/core/exp_factory.py` & `tf-models-no-deps-2.16.0/official/core/exp_factory.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/core/export_base.py` & `tf-models-no-deps-2.16.0/official/core/export_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,25 +16,25 @@
 
 import abc
 import functools
 import time
 from typing import Any, Callable, Dict, Mapping, List, Optional, Text, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 MAX_DIRECTORY_CREATION_ATTEMPTS = 10
 
 
 class ExportModule(tf.Module, metaclass=abc.ABCMeta):
   """Base Export Module."""
 
   def __init__(self,
                params,
-               model: Union[tf.Module, tf.keras.Model],
+               model: Union[tf.Module, tf_keras.Model],
                inference_step: Optional[Callable[..., Any]] = None,
                *,
                preprocessor: Optional[Callable[..., Any]] = None,
                postprocessor: Optional[Callable[..., Any]] = None):
     """Instantiates an ExportModel.
 
     Examples:
@@ -64,15 +64,15 @@
     super().__init__(name=None)
     self.model = model
     self.params = params
 
     if inference_step is not None:
       self.inference_step = functools.partial(inference_step, model=self.model)
     else:
-      if issubclass(type(model), tf.keras.Model):
+      if issubclass(type(model), tf_keras.Model):
         # Default to self.model.call instead of self.model.__call__ to avoid
         # keras tracing logic designed for training.
         # Since most of Model Garden's call doesn't not have training kwargs
         # or the default is False, we don't pass anything here.
         # Please pass custom inference step if your model has training=True as
         # default.
         self.inference_step = self.model.call
```

### Comparing `tf-models-no-deps-2.11.2/official/core/export_base_test.py` & `tf-models-no-deps-2.16.0/official/core/export_base_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.core.export_base."""
 import os
 from typing import Any, Dict, Mapping, Text
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import export_base
 
 
 class TestModule(export_base.ExportModule):
 
   @tf.function
@@ -37,15 +37,15 @@
     return {'foo': self.serve.get_concrete_function(input_signature)}
 
 
 class ExportBaseTest(tf.test.TestCase):
 
   def test_export_module(self):
     tmp_dir = self.get_temp_dir()
-    model = tf.keras.layers.Dense(2)
+    model = tf_keras.layers.Dense(2)
     inputs = tf.ones([2, 4], tf.float32)
     expected_output = model(inputs, training=False)
     module = TestModule(params=None, model=model)
     ckpt_path = tf.train.Checkpoint(model=model).save(
         os.path.join(tmp_dir, 'ckpt'))
     export_dir = export_base.export(
         module, ['foo'],
@@ -63,15 +63,15 @@
 
     imported = tf.saved_model.load(export_dir)
     output = imported.signatures['foo'](inputs)
     self.assertAllClose(output['outputs'].numpy(), expected_output.numpy())
 
   def test_custom_inference_step(self):
     tmp_dir = self.get_temp_dir()
-    model = tf.keras.layers.Dense(2)
+    model = tf_keras.layers.Dense(2)
     inputs = tf.ones([2, 4], tf.float32)
 
     def _inference_step(inputs, model):
       return tf.nn.softmax(model(inputs, training=False))
 
     module = TestModule(
         params=None, model=model, inference_step=_inference_step)
```

### Comparing `tf-models-no-deps-2.11.2/official/core/file_writers.py` & `tf-models-no-deps-2.16.0/official/core/file_writers.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """File writer functions for dataset preparation, infra validation, and unit tests."""
 
 import io
 from typing import Optional, Sequence, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def write_small_dataset(examples: Sequence[Union[tf.train.Example,
                                                  tf.train.SequenceExample]],
                         output_path: str,
                         file_type: str = 'tfrecord') -> None:
   """Writes `examples` to a file at `output_path` with type `file_type`.
```

### Comparing `tf-models-no-deps-2.11.2/official/core/file_writers_test.py` & `tf-models-no-deps-2.16.0/official/core/file_writers_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for file_writers."""
 
 import os
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import file_writers
 from official.core import tf_example_builder
 
 
 class FileWritersTest(tf.test.TestCase, parameterized.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/core/input_reader.py` & `tf-models-no-deps-2.16.0/official/core/input_reader.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,27 +1,28 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """A common dataset reader."""
+import dataclasses
 import random
 from typing import Any, Callable, Dict, List, Optional, Sequence, Text, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 from official.core import config_definitions as cfg
 
 
 def _get_random_integer():
   return random.randint(0, (1 << 31) - 1)
@@ -143,89 +144,101 @@
       block_length=block_length,
       num_parallel_calls=(cycle_length
                           if cycle_length else tf.data.experimental.AUTOTUNE),
       deterministic=deterministic)
   return dataset
 
 
-def _read_tfds(tfds_builder: tfds.core.DatasetBuilder,
+def _read_tfds(tfds_name: Text,
+               tfds_data_dir: Text,
                tfds_split: Text,
                tfds_skip_decoding_feature: Text,
                tfds_as_supervised: bool,
                input_context: Optional[tf.distribute.InputContext] = None,
                seed: Optional[Union[int, tf.Tensor]] = None,
                is_training: bool = False,
                cache: bool = False,
                cycle_length: Optional[int] = None,
                block_length: Optional[int] = None) -> tf.data.Dataset:
   """Reads a dataset from tfds."""
-  # No op if exist.
-  tfds_builder.download_and_prepare()
+  repeat_filenames = is_training and not cache
+  read_config = tfds.ReadConfig(
+      interleave_cycle_length=cycle_length,
+      interleave_block_length=block_length,
+      input_context=input_context,
+      shuffle_seed=seed,
+      repeat_filenames=repeat_filenames,
+      # Only assert cardinality when we have a finite dataset.
+      assert_cardinality=not repeat_filenames,
+      skip_prefetch=True)
+
   decoders = {}
   if tfds_skip_decoding_feature:
     for skip_feature in tfds_skip_decoding_feature.split(','):
       decoders[skip_feature.strip()] = tfds.decode.SkipDecoding()
-  if tfds_builder.info.splits:
-    num_shards = len(tfds_builder.info.splits[tfds_split].file_instructions)
-  else:
-    # The tfds mock path often does not provide splits.
-    num_shards = 1
-  if input_context and num_shards < input_context.num_input_pipelines:
-    # The number of files in the dataset split is smaller than the number of
-    # input pipelines. We read the entire dataset first and then shard in the
-    # host memory.
-    read_config = tfds.ReadConfig(
-        interleave_cycle_length=cycle_length,
-        interleave_block_length=block_length,
-        input_context=None,
-        shuffle_seed=seed)
-    dataset = tfds_builder.as_dataset(
-        split=tfds_split,
-        shuffle_files=is_training,
-        as_supervised=tfds_as_supervised,
-        decoders=decoders,
-        read_config=read_config)
-    dataset = dataset.shard(input_context.num_input_pipelines,
-                            input_context.input_pipeline_id)
-  else:
-    read_config = tfds.ReadConfig(
-        interleave_cycle_length=cycle_length,
-        interleave_block_length=block_length,
-        input_context=input_context,
-        shuffle_seed=seed)
-    dataset = tfds_builder.as_dataset(
-        split=tfds_split,
-        shuffle_files=is_training,
-        as_supervised=tfds_as_supervised,
-        decoders=decoders,
-        read_config=read_config)
 
-  if is_training and not cache:
-    dataset = dataset.repeat()
+  if tfds_name.startswith('mldataset.'):
+    dataset = tfds.load(name=tfds_name,
+                        split=tfds_split,
+                        as_supervised=tfds_as_supervised,
+                        decoders=decoders if decoders else None,
+                        read_config=read_config)
+  else:
+    builder = tfds.builder(tfds_name, data_dir=tfds_data_dir)
+    if builder.info.splits:
+      num_shards = len(builder.info.splits[tfds_split].file_instructions)
+    else:
+      # The tfds mock path often does not provide splits.
+      num_shards = 1
+    load_kwargs = dict(
+        name=tfds_name, download=True, split=tfds_split,
+        shuffle_files=is_training, as_supervised=tfds_as_supervised,
+        decoders=decoders if decoders else None)
+    if tfds_data_dir:
+      load_kwargs.update({'data_dir': tfds_data_dir})
+
+    if input_context and num_shards < input_context.num_input_pipelines:
+      # The number of files in the dataset split is smaller than the number of
+      # input pipelines. We read the entire dataset first and then shard in the
+      # host memory.
+      read_config = dataclasses.replace(read_config, input_context=None)
+      load_kwargs.update({'read_config': read_config})
+      dataset = tfds.load(**load_kwargs)
+      dataset = dataset.shard(input_context.num_input_pipelines,
+                              input_context.input_pipeline_id)
+    else:
+      load_kwargs.update({'read_config': read_config})
+      dataset = tfds.load(**load_kwargs)
   return dataset
 
 
 class InputReader:
   """Input reader that returns a tf.data.Dataset instance."""
 
   # A static random number which is the same across different InputReader
   # instances.
   static_randnum = _get_random_integer()
 
-  def __init__(self,
-               params: cfg.DataConfig,
-               dataset_fn=tf.data.TFRecordDataset,
-               decoder_fn: Optional[Callable[..., Any]] = None,
-               combine_fn: Optional[Callable[..., Any]] = None,
-               sample_fn: Optional[Callable[..., Any]] = None,
-               parser_fn: Optional[Callable[..., Any]] = None,
-               transform_and_batch_fn: Optional[Callable[
-                   [tf.data.Dataset, Optional[tf.distribute.InputContext]],
-                   tf.data.Dataset]] = None,
-               postprocess_fn: Optional[Callable[..., Any]] = None):
+  def __init__(
+      self,
+      params: cfg.DataConfig,
+      dataset_fn=tf.data.TFRecordDataset,
+      decoder_fn: Optional[Callable[..., Any]] = None,
+      combine_fn: Optional[Callable[..., Any]] = None,
+      sample_fn: Optional[Callable[..., Any]] = None,
+      parser_fn: Optional[Callable[..., Any]] = None,
+      filter_fn: Optional[Callable[..., tf.Tensor]] = None,
+      transform_and_batch_fn: Optional[
+          Callable[
+              [tf.data.Dataset, Optional[tf.distribute.InputContext]],
+              tf.data.Dataset,
+          ]
+      ] = None,
+      postprocess_fn: Optional[Callable[..., Any]] = None,
+  ):
     """Initializes an InputReader instance.
 
     Args:
       params: A config_definitions.DataConfig object.
       dataset_fn: A `tf.data.Dataset` that consumes the input files. For
         example, it can be `tf.data.TFRecordDataset`.
       decoder_fn: An optional `callable` that takes the serialized data string
@@ -235,43 +248,45 @@
         will be executed after the decoder_fn and before the sample_fn.
       sample_fn: An optional `callable` that takes a `tf.data.Dataset` object as
         input and outputs the transformed dataset. It performs sampling on the
         decoded raw tensors dict before the parser_fn.
       parser_fn: An optional `callable` that takes the decoded raw tensors dict
         and parse them into a dictionary of tensors that can be consumed by the
         model. It will be executed after decoder_fn.
+      filter_fn: An optional `callable` mapping a dataset element to a boolean.
+        It will be executed after parser_fn.
       transform_and_batch_fn: An optional `callable` that takes a
         `tf.data.Dataset` object and an optional `tf.distribute.InputContext` as
         input, and returns a `tf.data.Dataset` object. It will be executed after
         `parser_fn` to transform and batch the dataset; if None, after
         `parser_fn` is executed, the dataset will be batched into per-replica
         batch size.
       postprocess_fn: A optional `callable` that processes batched tensors. It
         will be executed after batching.
     """
     if params.input_path and params.tfds_name:
       raise ValueError('At most one of `input_path` and `tfds_name` can be '
                        'specified, but got %s and %s.' %
                        (params.input_path, params.tfds_name))
 
-    if isinstance(params.input_path,
-                  cfg.base_config.Config) and combine_fn is None:
+    if (isinstance(params.input_path, cfg.base_config.Config) or
+        isinstance(params.tfds_name, cfg.base_config.Config)
+        ) and combine_fn is None:
       raise ValueError(
-          'A `combine_fn` is required if the `input_path` is a dictionary.')
+          'A combine_fn is required if `input_path` or `tfds_name` is a dict.')
 
-    self._tfds_builder = None
+    self._tfds_name = params.tfds_name
+    self._tfds_data_dir = params.tfds_data_dir
     self._matched_files = None
     if not params.input_path:
       # Read dataset from TFDS.
       if not params.tfds_split:
         raise ValueError(
             '`tfds_name` is %s, but `tfds_split` is not specified.' %
             params.tfds_name)
-      self._tfds_builder = tfds.builder(
-          params.tfds_name, data_dir=params.tfds_data_dir)
     else:
       self._matched_files = self.get_files(params.input_path)
 
     self._global_batch_size = params.global_batch_size
     self._is_training = params.is_training
     self._drop_remainder = params.drop_remainder
     self._shuffle_buffer_size = params.shuffle_buffer_size
@@ -287,17 +302,20 @@
     self._dataset_fn = dataset_fn
     self._decoder_fn = decoder_fn
     self._combine_fn = combine_fn
     self._sample_fn = sample_fn
     self._parser_fn = parser_fn
     self._transform_and_batch_fn = transform_and_batch_fn
     self._postprocess_fn = postprocess_fn
+    self._filter_fn = filter_fn
     self._seed = params.seed
     self._prefetch_buffer_size = (
         params.prefetch_buffer_size or tf.data.experimental.AUTOTUNE)
+    self._autotune_algorithm = params.autotune_algorithm
+    self._ram_budget = params.ram_budget
 
     # When tf.data service is enabled, each data service worker should get
     # different random seeds. Thus, we set `seed` to None.
     # Sharding should also be disabled because tf data service handles how
     # each worker shard data with `processing_mode` in distribute method.
     if params.enable_tf_data_service:
       self._seed = None
@@ -333,23 +351,14 @@
         # the global batch size is different across trainers,
         # params.apply_tf_data_service_before_batching should be set to true
         # because tf.data service with different batch sizes will be considered
         # separate tf.data service instances.
         self._tf_data_service_job_name = (
             f'{params.tf_data_service_job_name}_{self.static_randnum}')
 
-  @property
-  def tfds_info(self) -> tfds.core.DatasetInfo:
-    """Returns TFDS dataset info, if available."""
-    if self._tfds_builder:
-      return self._tfds_builder.info
-    else:
-      raise ValueError('tfds_info is not available, because the dataset '
-                       'is not loaded from tfds.')
-
   def get_files(self, input_path):
     """Gets matched files. Can be overridden by subclasses."""
     if not input_path:
       return None
     # we want to combine / mix datasets
     if isinstance(input_path, cfg.base_config.Config):
       matched_files = {}
@@ -361,25 +370,29 @@
     return matched_files
 
   def _read_data_source(
       self,
       matched_files: Union[Dict[str, List[str]], List[str]],
       dataset_fn,
       input_context: Optional[tf.distribute.InputContext] = None,
-      tfds_builder: Optional[tfds.core.DatasetBuilder] = None):
+  ):
     """Reads the data source (files/tfds) to a dataset."""
 
     def _files_to_dataset(files: List[str]) -> tf.data.Dataset:
       if len(files) > 1:
         if input_context and (len(files) < input_context.num_input_pipelines):
           logging.warn(
-              'The number of files %d is less than the number of input pipelines '
-              '%d. We will send all input files to every worker. '
-              'Please consider sharding your data into more files.', len(files),
-              input_context.num_input_pipelines)
+              (
+                  'The number of files %d is less than the number of input '
+                  'pipelines %d. We will send all input files to every worker. '
+                  'Please consider sharding your data into more files.'
+              ),
+              len(files),
+              input_context.num_input_pipelines,
+          )
           return _read_files_then_shard(
               files,
               dataset_fn,
               input_context,
               sharding=self._sharding,
               repeat=self._is_training and not self._cache)
         else:
@@ -401,26 +414,43 @@
             input_context,
             sharding=self._sharding,
             repeat=self._is_training and not self._cache)
       else:
         raise ValueError('It is unexpected that `tfds_builder` is None and '
                          'there is also no `files`.')
 
-    if tfds_builder:
-      dataset = _read_tfds(
-          tfds_builder=self._tfds_builder,
-          tfds_split=self._tfds_split,
-          tfds_skip_decoding_feature=self._tfds_skip_decoding_feature,
-          tfds_as_supervised=self._tfds_as_supervised,
-          input_context=input_context,
-          seed=self._seed,
-          is_training=self._is_training,
-          cache=self._cache,
-          cycle_length=self._cycle_length,
-          block_length=self._block_length)
+    if self._tfds_name:
+      if isinstance(self._tfds_name, cfg.base_config.Config):
+        dataset = {}
+        for k, tfds_name in self._tfds_name.as_dict().items():
+          dataset[k] = _read_tfds(
+              tfds_name=tfds_name,
+              tfds_data_dir=self._tfds_data_dir,
+              tfds_split=self._tfds_split,
+              tfds_skip_decoding_feature=self._tfds_skip_decoding_feature,
+              tfds_as_supervised=self._tfds_as_supervised,
+              input_context=input_context,
+              seed=self._seed,
+              is_training=self._is_training,
+              cache=self._cache,
+              cycle_length=self._cycle_length,
+              block_length=self._block_length)
+      else:
+        dataset = _read_tfds(
+            tfds_name=self._tfds_name,
+            tfds_data_dir=self._tfds_data_dir,
+            tfds_split=self._tfds_split,
+            tfds_skip_decoding_feature=self._tfds_skip_decoding_feature,
+            tfds_as_supervised=self._tfds_as_supervised,
+            input_context=input_context,
+            seed=self._seed,
+            is_training=self._is_training,
+            cache=self._cache,
+            cycle_length=self._cycle_length,
+            block_length=self._block_length)
     elif isinstance(matched_files, (list, tuple)):
       dataset = _files_to_dataset(matched_files)
     elif isinstance(matched_files, dict):
       dataset = {}
       for k, fs in matched_files.items():
         dataset[k] = _files_to_dataset(fs)
     else:
@@ -448,14 +478,17 @@
     if tf.nest.is_nested(dataset):
       dataset = self._combine_fn(dataset)
 
     if self._sample_fn is not None:
       dataset = dataset.apply(self._sample_fn)
     dataset = _maybe_map_fn(dataset, self._parser_fn)
 
+    if self._filter_fn is not None:
+      dataset = dataset.filter(self._filter_fn)
+
     if self._cache:
       dataset = dataset.cache()
       if self._is_training:
         dataset = dataset.repeat()
         dataset = dataset.shuffle(self._shuffle_buffer_size, seed=self._seed)
 
     # Applies tf.data service before batching operations. This is useful when
@@ -535,20 +568,32 @@
 
   def read(self,
            input_context: Optional[tf.distribute.InputContext] = None,
            dataset: Optional[tf.data.Dataset] = None) -> tf.data.Dataset:
     """Generates a tf.data.Dataset object."""
     if dataset is None:
       dataset = self._read_data_source(self._matched_files, self._dataset_fn,
-                                       input_context, self._tfds_builder)
+                                       input_context)
     dataset = self._decode_and_parse_dataset(dataset, self._global_batch_size,
                                              input_context)
     dataset = _maybe_map_fn(dataset, self._postprocess_fn)
     if not (self._enable_shared_tf_data_service_between_parallel_trainers and
             self._apply_tf_data_service_before_batching):
       dataset = self._maybe_apply_data_service(dataset, input_context)
 
     if self._deterministic is not None:
       options = tf.data.Options()
       options.deterministic = self._deterministic
       dataset = dataset.with_options(options)
+    if self._autotune_algorithm:
+      options = tf.data.Options()
+      options.autotune.autotune_algorithm = (
+          tf.data.experimental.AutotuneAlgorithm[self._autotune_algorithm]
+      )
+      dataset = dataset.with_options(options)
+
+    if self._ram_budget:
+      options = tf.data.Options()
+      options.autotune.ram_budget = self._ram_budget * 1024 * 1024 * 1024
+      dataset = dataset.with_options(options)
+
     return dataset.prefetch(self._prefetch_buffer_size)
```

### Comparing `tf-models-no-deps-2.11.2/official/core/registry.py` & `tf-models-no-deps-2.16.0/official/core/registry.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,23 +1,22 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Registry utility."""
-from absl import logging
 
 
 def register(registered_collection, reg_key):
   """Register decorated function or class to collection.
 
   Register decorated function or class into registered_collection, in a
   hierarchical order. For example, when reg_key="my_model/my_exp/my_config_0"
@@ -51,24 +50,16 @@
               "a function or class.".format(entry_name, h_idx))
       leaf_reg_key = hierarchy[-1]
     else:
       collection = registered_collection
       leaf_reg_key = reg_key
 
     if leaf_reg_key in collection:
-      if "beta" in fn_or_cls.__module__:
-        # TODO(yeqing): Clean this temporary branch for beta.
-        logging.warn(
-            "Duplicate registeration of beta module "
-            "name %r new %r old %r", reg_key, collection[leaf_reg_key],
-            fn_or_cls.__module__)
-        return fn_or_cls
-      else:
-        raise KeyError("Function or class {} registered multiple times.".format(
-            leaf_reg_key))
+      raise KeyError("Function or class {} registered multiple times.".format(
+          leaf_reg_key))
 
     collection[leaf_reg_key] = fn_or_cls
     return fn_or_cls
   return decorator
 
 
 def lookup(registered_collection, reg_key):
```

### Comparing `tf-models-no-deps-2.11.2/official/core/registry_test.py` & `tf-models-no-deps-2.16.0/official/core/registry_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for registry."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import registry
 
 
 class RegistryTest(tf.test.TestCase):
 
   def test_register(self):
     collection = {}
```

### Comparing `tf-models-no-deps-2.11.2/official/core/savedmodel_checkpoint_manager.py` & `tf-models-no-deps-2.16.0/official/core/savedmodel_checkpoint_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import os
 import re
 import time
 from typing import Callable, List, Mapping, Optional, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 SAVED_MODULES_PATH_SUFFIX = 'saved_modules'
 
 
 def make_saved_modules_directory_name(checkpoint_name: str) -> str:
   return f'{checkpoint_name}_{SAVED_MODULES_PATH_SUFFIX}'
 
@@ -68,20 +68,27 @@
       return
     if not self._modules_to_export:  # No modules to export.
       logging.info('Skip saving SavedModel due to empty modules_to_export.')
       return checkpoint_path
 
     # Save the models for the checkpoint that just got written.
     saved_modules_directory = make_saved_modules_directory_name(checkpoint_path)
+    # Atomic export of SavedModel. Write into a temporary direcotory and then
+    # rename as the final direcotory after finishing the writing.
+    # This can avoid trying to read an unfinished savedmodel.
+    saved_modules_directory_tmp = saved_modules_directory + '_temp'
     for model_name, model in self._modules_to_export.items():
       signatures = getattr(model, 'saved_model_signatures', None)
-      tf.saved_model.save(
-          obj=model,
-          export_dir=os.path.join(saved_modules_directory, model_name),
-          signatures=signatures)
+      if signatures is not None:
+        tf.saved_model.save(
+            obj=model,
+            export_dir=os.path.join(saved_modules_directory_tmp, model_name),
+            signatures=signatures)
+    if tf.io.gfile.exists(saved_modules_directory_tmp):
+      tf.io.gfile.rename(saved_modules_directory_tmp, saved_modules_directory)
 
     saved_modules_directories_to_keep = [
         make_saved_modules_directory_name(ckpt) for ckpt in self.checkpoints
     ]
     existing_saved_modules_dirs = self.get_existing_savedmodels()
 
     self._savedmodels = []
@@ -100,15 +107,22 @@
     """Gets a list of all existing SavedModel paths in `directory`.
 
     Returns:
       A list of all existing SavedModel paths.
     """
     saved_modules_glob = make_saved_modules_directory_name(
         self._checkpoint_prefix + '-*')
-    return tf.io.gfile.glob(saved_modules_glob)
+    savedmodels = tf.io.gfile.glob(saved_modules_glob)
+    # Filter out temporary savedmodel.
+    savedmodels = [
+        savedmodel
+        for savedmodel in savedmodels
+        if savedmodel.endswith(SAVED_MODULES_PATH_SUFFIX)
+    ]
+    return savedmodels
 
   @property
   def latest_savedmodel(self) -> Union[str, None]:
     """The path of the most recent SavedModel in `directory`.
 
     Returns:
       The latest SavedModel path. If there are no SavedModels, returns `None`.
@@ -209,15 +223,15 @@
 
     Returns:
       A new savedmodel path, or None if the timeout was reached.
     """
     logging.info('Waiting for new savedmodel at %s', self._directory)
     stop_time = time.time() + timeout if timeout is not None else None
 
-    last_savedmodel_number = 0
+    last_savedmodel_number = -1
     if last_savedmodel:
       last_savedmodel_number = self.get_savedmodel_number_from_path(
           last_savedmodel)
 
     while True:
       if stop_time is not None and time.time() + seconds_to_sleep > stop_time:
         return None
```

### Comparing `tf-models-no-deps-2.11.2/official/core/savedmodel_checkpoint_manager_test.py` & `tf-models-no-deps-2.16.0/official/core/savedmodel_checkpoint_manager_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,47 +12,58 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import os
 import time
 from typing import Iterable
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import savedmodel_checkpoint_manager
 
 
 def _models_exist(checkpoint_path: str, models: Iterable[str]) -> bool:
   for model_name in models:
     if not tf.io.gfile.isdir(
         os.path.join(
             savedmodel_checkpoint_manager.make_saved_modules_directory_name(
                 checkpoint_path), model_name)):
       return False
   return True
 
 
+class _ModelForTest(tf_keras.Model):
+  def __init__(self, hidden_size: int = 8):
+    super().__init__()
+    self.dense = tf_keras.layers.Dense(hidden_size)
+
+  @tf.function(input_signature=[tf.TensorSpec([None, 16])])
+  def call(self, inputs):
+    return self.dense(inputs)
+
+  @property
+  def saved_model_signatures(self):
+    # Build SavedModel signatures.
+    return dict(serving_default=self.call)
+
+
 class CheckpointManagerTest(tf.test.TestCase):
 
   def _create_manager(self, max_to_keep: int = 1) -> tf.train.CheckpointManager:
     """Sets up SavedModelCheckpointManager object.
 
     Args:
       max_to_keep: max number of savedmodels to keep.
 
     Returns:
       created savedmodel manager.
     """
     models = {
-        'model_1':
-            tf.keras.Sequential(
-                layers=[tf.keras.layers.Dense(8, input_shape=(16,))]),
-        'model_2':
-            tf.keras.Sequential(
-                layers=[tf.keras.layers.Dense(16, input_shape=(32,))]),
+        'model_1': _ModelForTest(12),
+        'model_2': _ModelForTest(14),
     }
     checkpoint = tf.train.Checkpoint()
     manager = savedmodel_checkpoint_manager.SavedModelCheckpointManager(
         checkpoint=checkpoint,
         directory=self.get_temp_dir(),
         max_to_keep=max_to_keep,
         modules_to_export=models)
```

### Comparing `tf-models-no-deps-2.11.2/official/core/task_factory.py` & `tf-models-no-deps-2.16.0/official/core/task_factory.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/core/tf_example_builder.py` & `tf-models-no-deps-2.16.0/official/core/tf_example_builder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 # https://www.python.org/dev/peps/pep-0563/#enabling-the-future-behavior-in-python-3-7
 from __future__ import annotations
 
 from typing import Mapping, Sequence, Union
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 BytesValueType = Union[bytes, Sequence[bytes], str, Sequence[str]]
 
 _to_array = lambda v: [v] if not isinstance(v, (list, np.ndarray)) else v
 _to_bytes = lambda v: v.encode() if isinstance(v, str) else v
 _to_bytes_array = lambda v: list(map(_to_bytes, _to_array(v)))
```

### Comparing `tf-models-no-deps-2.11.2/official/core/tf_example_builder_test.py` & `tf-models-no-deps-2.16.0/official/core/tf_example_builder_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Tests for tf_example_builder.
 
 See `test_add_image_matrix_feature_with_fake_image` for the typical structure of
 a unit test.
 """
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import tf_example_builder
 
 
 class TfExampleBuilderTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_init_an_empty_example(self):
     example_builder = tf_example_builder.TfExampleBuilder()
```

### Comparing `tf-models-no-deps-2.11.2/official/core/tf_example_feature_key.py` & `tf-models-no-deps-2.16.0/official/core/tf_example_feature_key.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -52,11 +52,11 @@
     prefix/image/encoded
 
     Args:
       prefix: A prefix string that will be added before the feature key string
         with a trailing slash '/'.
     """
     if prefix:
-      for field in dataclasses.fields(self):
+      for field in dataclasses.fields(self):  # pytype: disable=wrong-arg-types  # re-none
         key_name = field.name
         key_value = getattr(self, key_name)
         setattr(self, key_name, f'{prefix}/{key_value}')
```

### Comparing `tf-models-no-deps-2.11.2/official/core/tf_example_feature_key_test.py` & `tf-models-no-deps-2.16.0/official/core/tf_example_feature_key_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/core/train_lib.py` & `tf-models-no-deps-2.16.0/official/core/train_lib.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,21 +11,22 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """TFM common training driver library."""
 # pytype: disable=attribute-error
 import os
-from typing import Any, Mapping, Optional, Tuple, List
+import tempfile
+from typing import Any, List, Mapping, Optional, Tuple
 
 # Import libraries
 
 from absl import logging
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import actions
 from official.core import base_task
 from official.core import base_trainer
 from official.core import config_definitions
 from official.core import train_utils
 
@@ -38,19 +39,21 @@
   The default experiment runner for model garden experiments. User can
   customize the experiment pipeline by subclassing this class and replacing
   components or functions.
 
   For example, an experiment runner with customized checkpoint manager:
 
   ```python
-  class MyExpRunnerWithExporter(AbstractExperimentRunner):
+  class MyExpRunnerWithExporter(OrbitExperimentRunner):
     def _maybe_build_checkpoint_manager(sefl):
+      # Replaces the default CheckpointManger with a customized one.
       return MyCheckpointManager(*args)
 
-  # In user code
+  # In user code, instead of the orginal
+  # `OrbitExperimentRunner(..).run(mode)`, now user can do:
   MyExpRunnerWithExporter(**needed_kwargs).run(mode)
   ```
 
   Similar override can be done to other components.
   """
 
   def __init__(
@@ -61,15 +64,18 @@
       params: config_definitions.ExperimentConfig,
       model_dir: str,
       run_post_eval: bool = False,
       save_summary: bool = True,
       train_actions: Optional[List[orbit.Action]] = None,
       eval_actions: Optional[List[orbit.Action]] = None,
       trainer: Optional[base_trainer.Trainer] = None,
-      controller_cls=orbit.Controller
+      controller_cls=orbit.Controller,
+      summary_manager: Optional[orbit.utils.SummaryManager] = None,
+      eval_summary_manager: Optional[orbit.utils.SummaryManager] = None,
+      enable_async_checkpointing: bool = False,
   ):
     """Constructor.
 
     Args:
       distribution_strategy: A distribution strategy.
       task: A Task instance.
       mode: A 'str', specifying the mode. Can be 'train', 'eval',
@@ -81,53 +87,67 @@
       save_summary: Whether to save train and validation summary.
       train_actions: Optional list of Orbit train actions.
       eval_actions: Optional list of Orbit eval actions.
       trainer: the base_trainer.Trainer instance. It should be created within
         the strategy.scope().
       controller_cls: The controller class to manage the train and eval process.
         Must be a orbit.Controller subclass.
+      summary_manager: Instance of the summary manager to override default
+        summary manager.
+      eval_summary_manager: Instance of the eval summary manager to override
+        default eval summary manager.
+      enable_async_checkpointing: Optional boolean indicating whether to enable
+        async checkpoint saving.
     """
     self.strategy = distribution_strategy or tf.distribute.get_strategy()
     self._params = params
     self._model_dir = model_dir
     self._mode = mode
     self._run_post_eval = run_post_eval
 
     self._trainer = trainer or self._build_trainer(
         task,
         train='train' in mode,
         evaluate=('eval' in mode) or run_post_eval)
     assert self.trainer is not None
     self._checkpoint_manager = self._maybe_build_checkpoint_manager()
+    self._summary_manager = summary_manager
+    self._eval_summary_manager = eval_summary_manager
     self._controller = self._build_controller(
         trainer=self.trainer if 'train' in mode else None,
         evaluator=self.trainer,
         save_summary=save_summary,
         train_actions=train_actions,
         eval_actions=eval_actions,
-        controller_cls=controller_cls)
+        controller_cls=controller_cls,
+        enable_async_checkpointing=enable_async_checkpointing)
 
   @property
   def params(self) -> config_definitions.ExperimentConfig:
+    """The whole experiment parameters object."""
     return self._params
 
   @property
   def model_dir(self) -> str:
+    """Path to the model folder, which stores checkpoints, params, log, etc."""
     return self._model_dir
 
   @property
   def trainer(self) -> base_trainer.Trainer:
+    """The underlying Orbit Trainer object."""
     return self._trainer
 
   @property
-  def checkpoint_manager(self) -> tf.train.CheckpointManager:
+  def checkpoint_manager(self) -> Optional[tf.train.CheckpointManager]:
+    """The CheckpointManager that stores the checkpoints in a train job."""
     return self._checkpoint_manager
 
   @property
   def controller(self) -> orbit.Controller:
+    """The Orbit controller object."""
     return self._controller
 
   def _build_trainer(self, task: base_task.Task, train: bool,
                      evaluate: bool) -> base_trainer.Trainer:
     """Create trainer."""
     with self.strategy.scope():
       trainer = train_utils.create_trainer(
@@ -144,70 +164,104 @@
   def _maybe_build_checkpoint_manager(
       self) -> Optional[tf.train.CheckpointManager]:
     """Maybe create a CheckpointManager."""
     assert self.trainer is not None
     if self.trainer.checkpoint:
       if self.model_dir is None:
         raise ValueError('model_dir must be specified, but got None')
+
+      if (not self.strategy) or self.strategy.extended.should_checkpoint:
+        ckpt_path = self.model_dir
+        max_to_keep = self.params.trainer.max_to_keep
+      else:
+        # In multi worker training we need every worker to save checkpoint,
+        # because variables can trigger synchronization on read and
+        # synchronization needs all workers to participate. To avoid workers
+        # overriding each other we save to a temporary directory on non-chief
+        # workers.
+        ckpt_path = tempfile.mkdtemp()
+        max_to_keep = 1
+
       checkpoint_manager = tf.train.CheckpointManager(
           self.trainer.checkpoint,
-          directory=self.model_dir,
-          max_to_keep=self.params.trainer.max_to_keep,
+          directory=ckpt_path,
+          max_to_keep=max_to_keep,
           step_counter=self.trainer.global_step,
           checkpoint_interval=self.params.trainer.checkpoint_interval,
           init_fn=self.trainer.initialize)
     else:
       checkpoint_manager = None
     return checkpoint_manager
 
-  def _build_controller(self,
-                        trainer,
-                        evaluator,
-                        save_summary: bool = True,
-                        train_actions: Optional[List[orbit.Action]] = None,
-                        eval_actions: Optional[List[orbit.Action]] = None,
-                        controller_cls=orbit.Controller) -> orbit.Controller:
+  def _build_controller(
+      self,
+      trainer,
+      evaluator,
+      save_summary: bool = True,
+      train_actions: Optional[List[orbit.Action]] = None,
+      eval_actions: Optional[List[orbit.Action]] = None,
+      controller_cls=orbit.Controller,
+      enable_async_checkpointing: bool = False,
+  ) -> orbit.Controller:
     """Builds a Orbit controler."""
     train_actions = [] if not train_actions else train_actions
     if trainer:
+      checkpoint_manager = self.checkpoint_manager
+      assert checkpoint_manager, 'Checkpoint manager required but undefined.'
       train_actions += actions.get_train_actions(
           self.params,
           trainer,
           self.model_dir,
-          checkpoint_manager=self.checkpoint_manager)
+          checkpoint_manager=checkpoint_manager,
+      )
 
     eval_actions = [] if not eval_actions else eval_actions
     if evaluator:
       eval_actions += actions.get_eval_actions(self.params, evaluator,
                                                self.model_dir)
 
+    if save_summary:
+      eval_summary_dir = os.path.join(
+          self.model_dir, self.params.trainer.validation_summary_subdir
+      )
+    else:
+      eval_summary_dir = None
+
     controller = controller_cls(
         strategy=self.strategy,
         trainer=trainer,
         evaluator=evaluator,
         global_step=self.trainer.global_step,
         steps_per_loop=self.params.trainer.steps_per_loop,
         checkpoint_manager=self.checkpoint_manager,
-        summary_dir=os.path.join(self.model_dir, 'train') if
-        (save_summary) else None,
-        eval_summary_dir=os.path.join(
-            self.model_dir, self.params.trainer.validation_summary_subdir) if
-        (save_summary) else None,
-        summary_interval=self.params.trainer.summary_interval if
-        (save_summary) else None,
+        enable_async_checkpointing=enable_async_checkpointing,
+        summary_dir=os.path.join(self.model_dir, 'train')
+        if (save_summary)
+        else None,
+        eval_summary_dir=eval_summary_dir,
+        summary_interval=self.params.trainer.summary_interval
+        if (save_summary)
+        else None,
         train_actions=train_actions,
-        eval_actions=eval_actions)
+        eval_actions=eval_actions,
+        summary_manager=self._summary_manager
+        if hasattr(self, '_summary_manager')
+        else None,
+        eval_summary_manager=self._eval_summary_manager
+        if hasattr(self, '_eval_summary_manager')
+        else None,
+    )
     return controller
 
-  def run(self) -> Tuple[tf.keras.Model, Mapping[str, Any]]:
+  def run(self) -> Tuple[tf_keras.Model, Mapping[str, Any]]:
     """Run experiments by mode.
 
     Returns:
       A 2-tuple of (model, eval_logs).
-        model: `tf.keras.Model` instance.
+        model: `tf_keras.Model` instance.
         eval_logs: returns eval metrics logs when run_post_eval is set to True,
           otherwise, returns {}.
     """
     mode = self._mode
     params = self.params
     logging.info('Starts to execute mode: %s', mode)
     with self.strategy.scope():
@@ -259,16 +313,19 @@
     params: config_definitions.ExperimentConfig,
     model_dir: str,
     run_post_eval: bool = False,
     save_summary: bool = True,
     train_actions: Optional[List[orbit.Action]] = None,
     eval_actions: Optional[List[orbit.Action]] = None,
     trainer: Optional[base_trainer.Trainer] = None,
-    controller_cls=orbit.Controller
-) -> Tuple[tf.keras.Model, Mapping[str, Any]]:
+    controller_cls=orbit.Controller,
+    summary_manager: Optional[orbit.utils.SummaryManager] = None,
+    eval_summary_manager: Optional[orbit.utils.SummaryManager] = None,
+    enable_async_checkpointing: bool = False,
+) -> Tuple[tf_keras.Model, Mapping[str, Any]]:
   """Runs train/eval configured by the experiment params.
 
   Args:
     distribution_strategy: A distribution distribution_strategy.
     task: A Task instance.
     mode: A 'str', specifying the mode. Can be 'train', 'eval', 'train_and_eval'
       or 'continuous_eval'.
@@ -279,18 +336,24 @@
     save_summary: Whether to save train and validation summary.
     train_actions: Optional list of Orbit train actions.
     eval_actions: Optional list of Orbit eval actions.
     trainer: the base_trainer.Trainer instance. It should be created within the
       strategy.scope().
     controller_cls: The controller class to manage the train and eval process.
       Must be a orbit.Controller subclass.
+    summary_manager: Instance of the summary manager to override default summary
+      manager.
+    eval_summary_manager: Instance of the eval summary manager to override
+      default eval summary manager.
+    enable_async_checkpointing: Optional boolean indicating whether to enable
+        async checkpoint saving.
 
   Returns:
     A 2-tuple of (model, eval_logs).
-      model: `tf.keras.Model` instance.
+      model: `tf_keras.Model` instance.
       eval_logs: returns eval metrics logs when run_post_eval is set to True,
         otherwise, returns {}.
   """
   runner = OrbitExperimentRunner(
       distribution_strategy=distribution_strategy,
       task=task,
       mode=mode,
@@ -298,9 +361,12 @@
       model_dir=model_dir,
       run_post_eval=run_post_eval,
       save_summary=save_summary,
       train_actions=train_actions,
       eval_actions=eval_actions,
       trainer=trainer,
       controller_cls=controller_cls,
+      summary_manager=summary_manager,
+      eval_summary_manager=eval_summary_manager,
+      enable_async_checkpointing=enable_async_checkpointing,
   )
   return runner.run()
```

### Comparing `tf-models-no-deps-2.11.2/official/core/train_lib_test.py` & `tf-models-no-deps-2.16.0/official/core/train_lib_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 import json
 import os
 
 from absl import flags
 from absl.testing import flagsaver
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.common import flags as tfm_flags
 # pylint: disable=unused-import
 from official.common import registry_imports
 # pylint: enable=unused-import
```

### Comparing `tf-models-no-deps-2.11.2/official/core/train_utils.py` & `tf-models-no-deps-2.16.0/official/core/train_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,36 +1,38 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Training utils."""
-import copy
+
 import dataclasses
 import inspect
 import json
 import os
 import pprint
 from typing import Any, Callable, Dict, List, Optional, Union
 
 from absl import logging
 import gin
+import numpy as np
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # pylint: disable=g-direct-tensorflow-import
+from tensorflow.python.framework import ops
 from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2_as_graph
 # pylint: enable=g-direct-tensorflow-import
 from official.core import base_task
 from official.core import base_trainer
 from official.core import config_definitions
 from official.core import exp_factory
 from official.modeling import hyperparams
@@ -81,14 +83,37 @@
     if isinstance(value, dict):
       d[key] = cast_leaf_nested_dict(value, cast_fn)
     else:
       d[key] = cast_fn(value)
   return d
 
 
+def _filter_leaf_nested_dict(
+    d: Dict[str, Any], predicate: Callable[[Any], bool]
+) -> Dict[str, Any]:
+  """Filters the leaves of a dictionary with arbitrary depth in place.
+
+  Args:
+    d: The dictionary to extract value from.
+    predicate: A function that will be called on every leave item. When the
+      function returns True the leave will be kept. Otherwise the leave will be
+      dropped.
+
+  Returns:
+    A new dictionray with filtered result.
+  """
+  result = {}
+  for key, value in d.items():
+    if isinstance(value, dict):
+      result[key] = _filter_leaf_nested_dict(value, predicate)
+    elif predicate(value):
+      result[key] = value
+  return result
+
+
 def maybe_create_best_ckpt_exporter(params: config_definitions.ExperimentConfig,
                                     data_dir: str) -> Any:
   """Maybe create a BestCheckpointExporter object, according to the config."""
   export_subdir = params.trainer.best_checkpoint_export_subdir
   metric_name = params.trainer.best_checkpoint_eval_metric
   metric_comp = params.trainer.best_checkpoint_metric_comp
   if data_dir and export_subdir and metric_name:
@@ -186,15 +211,19 @@
         logging.info('[BestCheckpointExporter] '
                      'the new number is better since it is lower.')
         return True
     return False
 
   def export_best_eval_metric(self, eval_logs, global_step):
     """Export evaluation results of the best checkpoint into a json file."""
-    eval_logs_ext = copy.copy(eval_logs)
+    # eval_log_ext may contains non-scalar tensors, such as image data when
+    # `allow_image_summary` is True. Here we only keep scalar tensors.
+    eval_logs_ext = _filter_leaf_nested_dict(
+        eval_logs, lambda x: tf.rank(x) <= 1
+    )
     eval_logs_ext['best_ckpt_global_step'] = global_step
     eval_logs_ext = cast_leaf_nested_dict(
         eval_logs_ext, lambda x: float(orbit.utils.get_value(x)))
     # Saving json file is very fast.
     with tf.io.gfile.GFile(self.best_ckpt_logs_path, 'w') as writer:
       writer.write(json.dumps(eval_logs_ext, indent=4) + '\n')
 
@@ -210,15 +239,15 @@
   def best_ckpt_path(self):
     """Returns the best ckpt path or None if there is no ckpt yet."""
     return tf.train.latest_checkpoint(self._export_dir)
 
 
 def create_optimizer(task: base_task.Task,
                      params: config_definitions.ExperimentConfig
-                     ) -> tf.keras.optimizers.Optimizer:
+                     ) -> tf_keras.optimizers.Optimizer:
   """A create optimizer util to be backward compatability with new args."""
   if 'dp_config' in inspect.signature(task.create_optimizer).parameters:
     dp_config = None
     if hasattr(params.task, 'differential_privacy_config'):
       dp_config = params.task.differential_privacy_config
     optimizer = task.create_optimizer(
         params.trainer.optimizer_config, params.runtime,
@@ -438,15 +467,15 @@
     tf.io.gfile.rmtree(file_to_remove)
 
   file_to_remove = os.path.join(model_dir, 'checkpoint')
   if tf.io.gfile.exists(file_to_remove):
     tf.io.gfile.remove(file_to_remove)
 
 
-def write_model_params(model: Union[tf.Module, tf.keras.Model],
+def write_model_params(model: Union[tf.Module, tf_keras.Model],
                        output_path: str) -> None:
   """Writes the model parameters and shapes to a file.
 
   Args:
     model: A model instance.
     output_path: Output file path.
   """
@@ -456,15 +485,15 @@
       shape = tf.shape(var)
       total_params += tf.math.reduce_prod(shape).numpy()
       f.write(f'{var.name} {shape.numpy().tolist()}\n')
     f.write(f'\nTotal params: {total_params}\n')
 
 
 def try_count_params(
-    model: Union[tf.Module, tf.keras.Model],
+    model: Union[tf.Module, tf_keras.Model],
     trainable_only: bool = False):
   """Count the number of parameters if model is possible.
 
   Args:
     model: Try to count the number of params in this model.
     trainable_only: Whether to calculate trainable params only. This flag is
       not used when the model has `count_params` attribute.
@@ -486,15 +515,15 @@
     variables = model.trainable_variables if trainable_only else model.variables
     for var in variables:
       shape = tf.shape(var)
       total_params += tf.math.reduce_prod(shape).numpy()
   return total_params
 
 
-def try_count_flops(model: Union[tf.Module, tf.keras.Model],
+def try_count_flops(model: Union[tf.Module, tf_keras.Model],
                     inputs_kwargs: Optional[Dict[str, Any]] = None,
                     output_path: Optional[str] = None):
   """Counts and returns model FLOPs.
 
   Args:
     model: A model instance.
     inputs_kwargs: An optional dictionary of argument pairs specifying inputs'
@@ -534,7 +563,48 @@
       logging.info(
           'Failed to count model FLOPs with error %s, because the build() '
           'methods in keras layers were not called. This is probably because '
           'the model was not feed any input, e.g., the max train step already '
           'reached before this run.', e)
       return None
   return None
+
+
+@ops.RegisterStatistics('Einsum', 'flops')
+def _einsum_flops(graph, node):
+  """Calculates the compute resources needed for Einsum."""
+  assert len(node.input) == 2
+  x_shape = tf.compat.v1.graph_util.tensor_shape_from_node_def_name(
+      graph, node.input[0])
+  y_shape = tf.compat.v1.graph_util.tensor_shape_from_node_def_name(
+      graph, node.input[1])
+  x_shape.assert_is_fully_defined()
+  y_shape.assert_is_fully_defined()
+  x_shape = x_shape.as_list()
+  y_shape = y_shape.as_list()
+  equation = str(node.attr['equation'])
+  equation = (
+      equation.replace('s:', '')
+      .replace('"', '')
+      .replace(' ', '')
+      .replace('\n', '')
+  )
+  x_str = equation.split(',')[0]
+  y_r_str = equation.split(',')[1]
+  y_str = y_r_str.split('->')[0]
+  r_str = y_r_str.split('->')[1]
+  shape_dic = {}
+  contracted = set()
+  for indice in x_str + y_str:
+    if indice in x_str:
+      indice_dim = x_shape[x_str.find(indice)]
+    elif indice in y_str:
+      indice_dim = y_shape[y_str.find(indice)]
+    else:
+      raise ValueError('indice {} not found in inputs'.format(indice))
+    shape_dic[indice] = indice_dim
+    if indice not in r_str:
+      contracted.add(indice)
+  madds = np.prod([shape_dic[indice] for indice in r_str]) * (
+      np.prod([shape_dic[indice] for indice in contracted]))
+  flops = 2 * madds
+  return ops.OpStats('flops', flops)
```

### Comparing `tf-models-no-deps-2.11.2/official/core/train_utils_test.py` & `tf-models-no-deps-2.16.0/official/core/train_utils_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for official.core.train_utils."""
 import json
 import os
 import pprint
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import exp_factory
 from official.core import test_utils
 from official.core import train_utils
 from official.modeling import hyperparams
 
 
@@ -189,10 +189,27 @@
     with tf.io.gfile.GFile(os.path.join(model_dir, 'info.json'),
                            'rb') as reader:
       metric = json.loads(reader.read())
       self.assertAllEqual(
           metric,
           {'test_metric': {'metric_1': 5.0}, 'best_ckpt_global_step': 100.0})
 
+  def test_export_best_eval_metric_skips_non_scalar_values(self):
+    model_dir = self.create_tempdir().full_path
+    metric_name = 'test_metric|metric_1'
+    exporter = train_utils.BestCheckpointExporter(model_dir, metric_name,
+                                                  'higher')
+    image = tf.zeros(shape=[16, 8, 1])
+    eval_logs = {'test_metric': {'metric_1': 5.0, 'image': image}}
+
+    exporter.export_best_eval_metric(eval_logs, 100)
+
+    with tf.io.gfile.GFile(os.path.join(model_dir, 'info.json'),
+                           'rb') as reader:
+      metric = json.loads(reader.read())
+      self.assertAllEqual(
+          metric,
+          {'test_metric': {'metric_1': 5.0}, 'best_ckpt_global_step': 100.0})
+
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/albert/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/albert/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/albert/configs.py` & `tf-models-no-deps-2.16.0/official/legacy/albert/configs.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/bert_models.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/bert_models.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,49 +11,49 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """BERT models that are compatible with TF 2.0."""
 
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_hub as hub
 from official.legacy.albert import configs as albert_configs
 from official.legacy.bert import configs
 from official.modeling import tf_utils
 from official.nlp.modeling import models
 from official.nlp.modeling import networks
 
 
-class BertPretrainLossAndMetricLayer(tf.keras.layers.Layer):
+class BertPretrainLossAndMetricLayer(tf_keras.layers.Layer):
   """Returns layer that computes custom loss and metrics for pretraining."""
 
   def __init__(self, vocab_size, **kwargs):
     super(BertPretrainLossAndMetricLayer, self).__init__(**kwargs)
     self._vocab_size = vocab_size
     self.config = {
         'vocab_size': vocab_size,
     }
 
   def _add_metrics(self, lm_output, lm_labels, lm_label_weights,
                    lm_example_loss, sentence_output, sentence_labels,
                    next_sentence_loss):
     """Adds metrics."""
-    masked_lm_accuracy = tf.keras.metrics.sparse_categorical_accuracy(
+    masked_lm_accuracy = tf_keras.metrics.sparse_categorical_accuracy(
         lm_labels, lm_output)
     numerator = tf.reduce_sum(masked_lm_accuracy * lm_label_weights)
     denominator = tf.reduce_sum(lm_label_weights) + 1e-5
     masked_lm_accuracy = numerator / denominator
     self.add_metric(
         masked_lm_accuracy, name='masked_lm_accuracy', aggregation='mean')
 
     self.add_metric(lm_example_loss, name='lm_example_loss', aggregation='mean')
 
     if sentence_labels is not None:
-      next_sentence_accuracy = tf.keras.metrics.sparse_categorical_accuracy(
+      next_sentence_accuracy = tf_keras.metrics.sparse_categorical_accuracy(
           sentence_labels, sentence_output)
       self.add_metric(
           next_sentence_accuracy,
           name='next_sentence_accuracy',
           aggregation='mean')
 
     if next_sentence_loss is not None:
@@ -66,24 +66,24 @@
            lm_label_ids,
            lm_label_weights,
            sentence_labels=None):
     """Implements call() for the layer."""
     lm_label_weights = tf.cast(lm_label_weights, tf.float32)
     lm_output_logits = tf.cast(lm_output_logits, tf.float32)
 
-    lm_prediction_losses = tf.keras.losses.sparse_categorical_crossentropy(
+    lm_prediction_losses = tf_keras.losses.sparse_categorical_crossentropy(
         lm_label_ids, lm_output_logits, from_logits=True)
     lm_numerator_loss = tf.reduce_sum(lm_prediction_losses * lm_label_weights)
     lm_denominator_loss = tf.reduce_sum(lm_label_weights)
     mask_label_loss = tf.math.divide_no_nan(lm_numerator_loss,
                                             lm_denominator_loss)
 
     if sentence_labels is not None:
       sentence_output_logits = tf.cast(sentence_output_logits, tf.float32)
-      sentence_loss = tf.keras.losses.sparse_categorical_crossentropy(
+      sentence_loss = tf_keras.losses.sparse_categorical_crossentropy(
           sentence_labels, sentence_output_logits, from_logits=True)
       sentence_loss = tf.reduce_mean(sentence_loss)
       loss = mask_label_loss + sentence_loss
     else:
       sentence_loss = None
       loss = mask_label_loss
 
@@ -119,33 +119,33 @@
   if transformer_encoder_cls is not None:
     # TODO(hongkuny): evaluate if it is better to put cfg definition in gin.
     embedding_cfg = dict(
         vocab_size=bert_config.vocab_size,
         type_vocab_size=bert_config.type_vocab_size,
         hidden_size=bert_config.hidden_size,
         max_seq_length=bert_config.max_position_embeddings,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=bert_config.initializer_range),
         dropout_rate=bert_config.hidden_dropout_prob,
     )
     hidden_cfg = dict(
         num_attention_heads=bert_config.num_attention_heads,
         intermediate_size=bert_config.intermediate_size,
         intermediate_activation=tf_utils.get_activation(bert_config.hidden_act),
         dropout_rate=bert_config.hidden_dropout_prob,
         attention_dropout_rate=bert_config.attention_probs_dropout_prob,
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=bert_config.initializer_range),
     )
     kwargs = dict(
         embedding_cfg=embedding_cfg,
         hidden_cfg=hidden_cfg,
         num_hidden_instances=bert_config.num_hidden_layers,
         pooled_output_dim=bert_config.hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=bert_config.initializer_range))
 
     # Relies on gin configuration to define the Transformer encoder arguments.
     return transformer_encoder_cls(**kwargs)
 
   kwargs = dict(
       vocab_size=bert_config.vocab_size,
@@ -155,15 +155,15 @@
       intermediate_size=bert_config.intermediate_size,
       activation=tf_utils.get_activation(bert_config.hidden_act),
       dropout_rate=bert_config.hidden_dropout_prob,
       attention_dropout_rate=bert_config.attention_probs_dropout_prob,
       max_sequence_length=bert_config.max_position_embeddings,
       type_vocab_size=bert_config.type_vocab_size,
       embedding_width=bert_config.embedding_size,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=bert_config.initializer_range))
   if isinstance(bert_config, albert_configs.AlbertConfig):
     return networks.AlbertEncoder(**kwargs)
   else:
     assert isinstance(bert_config, configs.BertConfig)
     kwargs['output_range'] = output_range
     return networks.BertEncoder(**kwargs)
@@ -188,40 +188,40 @@
         object.
 
   Returns:
       A Tuple of (1) Pretraining model, (2) core BERT submodel from which to
       save weights after pretraining, and (3) optional core `BertPretrainer`
       object if argument `return_core_pretrainer_model` is True.
   """
-  input_word_ids = tf.keras.layers.Input(
+  input_word_ids = tf_keras.layers.Input(
       shape=(seq_length,), name='input_word_ids', dtype=tf.int32)
-  input_mask = tf.keras.layers.Input(
+  input_mask = tf_keras.layers.Input(
       shape=(seq_length,), name='input_mask', dtype=tf.int32)
-  input_type_ids = tf.keras.layers.Input(
+  input_type_ids = tf_keras.layers.Input(
       shape=(seq_length,), name='input_type_ids', dtype=tf.int32)
-  masked_lm_positions = tf.keras.layers.Input(
+  masked_lm_positions = tf_keras.layers.Input(
       shape=(max_predictions_per_seq,),
       name='masked_lm_positions',
       dtype=tf.int32)
-  masked_lm_ids = tf.keras.layers.Input(
+  masked_lm_ids = tf_keras.layers.Input(
       shape=(max_predictions_per_seq,), name='masked_lm_ids', dtype=tf.int32)
-  masked_lm_weights = tf.keras.layers.Input(
+  masked_lm_weights = tf_keras.layers.Input(
       shape=(max_predictions_per_seq,),
       name='masked_lm_weights',
       dtype=tf.int32)
 
   if use_next_sentence_label:
-    next_sentence_labels = tf.keras.layers.Input(
+    next_sentence_labels = tf_keras.layers.Input(
         shape=(1,), name='next_sentence_labels', dtype=tf.int32)
   else:
     next_sentence_labels = None
 
   transformer_encoder = get_transformer_encoder(bert_config, seq_length)
   if initializer is None:
-    initializer = tf.keras.initializers.TruncatedNormal(
+    initializer = tf_keras.initializers.TruncatedNormal(
         stddev=bert_config.initializer_range)
   pretrainer_model = models.BertPretrainer(
       network=transformer_encoder,
       embedding_table=transformer_encoder.get_embedding_table(),
       num_classes=2,  # The next sentence prediction label has two classes.
       activation=tf_utils.get_activation(bert_config.hidden_act),
       num_token_predictions=max_predictions_per_seq,
@@ -243,15 +243,15 @@
       'masked_lm_positions': masked_lm_positions,
       'masked_lm_ids': masked_lm_ids,
       'masked_lm_weights': masked_lm_weights,
   }
   if use_next_sentence_label:
     inputs['next_sentence_labels'] = next_sentence_labels
 
-  keras_model = tf.keras.Model(inputs=inputs, outputs=output_loss)
+  keras_model = tf_keras.Model(inputs=inputs, outputs=output_loss)
   if return_core_pretrainer_model:
     return keras_model, transformer_encoder, pretrainer_model
   else:
     return keras_model, transformer_encoder
 
 
 def squad_model(bert_config,
@@ -270,31 +270,31 @@
     hub_module_trainable: True to finetune layers in the hub module.
 
   Returns:
     A tuple of (1) keras model that outputs start logits and end logits and
     (2) the core BERT transformer encoder.
   """
   if initializer is None:
-    initializer = tf.keras.initializers.TruncatedNormal(
+    initializer = tf_keras.initializers.TruncatedNormal(
         stddev=bert_config.initializer_range)
   if not hub_module_url:
     bert_encoder = get_transformer_encoder(bert_config, max_seq_length)
     return models.BertSpanLabeler(
         network=bert_encoder, initializer=initializer), bert_encoder
 
-  input_word_ids = tf.keras.layers.Input(
+  input_word_ids = tf_keras.layers.Input(
       shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')
-  input_mask = tf.keras.layers.Input(
+  input_mask = tf_keras.layers.Input(
       shape=(max_seq_length,), dtype=tf.int32, name='input_mask')
-  input_type_ids = tf.keras.layers.Input(
+  input_type_ids = tf_keras.layers.Input(
       shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')
   core_model = hub.KerasLayer(hub_module_url, trainable=hub_module_trainable)
   pooled_output, sequence_output = core_model(
       [input_word_ids, input_mask, input_type_ids])
-  bert_encoder = tf.keras.Model(
+  bert_encoder = tf_keras.Model(
       inputs={
           'input_word_ids': input_word_ids,
           'input_mask': input_mask,
           'input_type_ids': input_type_ids,
       },
       outputs=[sequence_output, pooled_output],
       name='core_model')
@@ -326,40 +326,40 @@
   Returns:
     Combined prediction model (words, mask, type) -> (one-hot labels)
     BERT sub-model (words, mask, type) -> (bert_outputs)
   """
   if final_layer_initializer is not None:
     initializer = final_layer_initializer
   else:
-    initializer = tf.keras.initializers.TruncatedNormal(
+    initializer = tf_keras.initializers.TruncatedNormal(
         stddev=bert_config.initializer_range)
 
   if not hub_module_url:
     bert_encoder = get_transformer_encoder(
         bert_config, max_seq_length, output_range=1)
     return models.BertClassifier(
         bert_encoder,
         num_classes=num_labels,
         dropout_rate=bert_config.hidden_dropout_prob,
         initializer=initializer), bert_encoder
 
-  input_word_ids = tf.keras.layers.Input(
+  input_word_ids = tf_keras.layers.Input(
       shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')
-  input_mask = tf.keras.layers.Input(
+  input_mask = tf_keras.layers.Input(
       shape=(max_seq_length,), dtype=tf.int32, name='input_mask')
-  input_type_ids = tf.keras.layers.Input(
+  input_type_ids = tf_keras.layers.Input(
       shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')
   bert_model = hub.KerasLayer(hub_module_url, trainable=hub_module_trainable)
   pooled_output, _ = bert_model([input_word_ids, input_mask, input_type_ids])
-  output = tf.keras.layers.Dropout(rate=bert_config.hidden_dropout_prob)(
+  output = tf_keras.layers.Dropout(rate=bert_config.hidden_dropout_prob)(
       pooled_output)
 
-  output = tf.keras.layers.Dense(
+  output = tf_keras.layers.Dense(
       num_labels, kernel_initializer=initializer, name='output')(
           output)
-  return tf.keras.Model(
+  return tf_keras.Model(
       inputs={
           'input_word_ids': input_word_ids,
           'input_mask': input_mask,
           'input_type_ids': input_type_ids
       },
       outputs=output), bert_model
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/bert_models_test.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/bert_models_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.bert import bert_models
 from official.legacy.bert import configs as bert_configs
 from official.nlp.modeling import networks
 
 
 class BertModelsTest(tf.test.TestCase):
@@ -39,15 +39,15 @@
   def test_pretrain_model(self):
     model, encoder = bert_models.pretrain_model(
         self._bert_test_config,
         seq_length=5,
         max_predictions_per_seq=2,
         initializer=None,
         use_next_sentence_label=True)
-    self.assertIsInstance(model, tf.keras.Model)
+    self.assertIsInstance(model, tf_keras.Model)
     self.assertIsInstance(encoder, networks.BertEncoder)
 
     # model has one scalar output: loss value.
     self.assertEqual(model.output.shape.as_list(), [
         None,
     ])
 
@@ -60,16 +60,16 @@
   def test_squad_model(self):
     model, core_model = bert_models.squad_model(
         self._bert_test_config,
         max_seq_length=5,
         initializer=None,
         hub_module_url=None,
         hub_module_trainable=None)
-    self.assertIsInstance(model, tf.keras.Model)
-    self.assertIsInstance(core_model, tf.keras.Model)
+    self.assertIsInstance(model, tf_keras.Model)
+    self.assertIsInstance(core_model, tf_keras.Model)
 
     # Expect two output from model: start positions and end positions
     self.assertIsInstance(model.output, list)
     self.assertLen(model.output, 2)
 
     # Expect two output from core_model: sequence and classification output.
     self.assertIsInstance(core_model.output, list)
@@ -83,16 +83,16 @@
     model, core_model = bert_models.classifier_model(
         self._bert_test_config,
         num_labels=3,
         max_seq_length=5,
         final_layer_initializer=None,
         hub_module_url=None,
         hub_module_trainable=None)
-    self.assertIsInstance(model, tf.keras.Model)
-    self.assertIsInstance(core_model, tf.keras.Model)
+    self.assertIsInstance(model, tf_keras.Model)
+    self.assertIsInstance(core_model, tf_keras.Model)
 
     # model has one classification output with num_labels=3.
     self.assertEqual(model.output.shape.as_list(), [None, 3])
 
     # Expect two output from core_model: sequence and classification output.
     self.assertIsInstance(core_model.output, list)
     self.assertLen(core_model.output, 2)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/common_flags.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/common_flags.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Defining common flags used across all BERT models/applications."""
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.utils import hyperparams_flags
 from official.utils.flags import core as flags_core
 
 
 def define_common_bert_flags():
   """Define common flags for BERT tasks."""
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/configs.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/configs.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """The main BERT model and related functions."""
 
 import copy
 import json
 
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class BertConfig(object):
   """Configuration for `BertModel`."""
 
   def __init__(self,
                vocab_size,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/export_tfhub.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/export_tfhub.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,15 +20,15 @@
 
 from typing import Text
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.bert import bert_models
 from official.legacy.bert import configs
 
 FLAGS = flags.FLAGS
 
 flags.DEFINE_string("bert_config_file", None,
                     "Bert configuration file to define core bert layers.")
@@ -41,47 +41,47 @@
     "do_lower_case", None, "Whether to lowercase. If None, "
     "do_lower_case will be enabled if 'uncased' appears in the "
     "name of --vocab_file")
 flags.DEFINE_enum("model_type", "encoder", ["encoder", "squad"],
                   "What kind of BERT model to export.")
 
 
-def create_bert_model(bert_config: configs.BertConfig) -> tf.keras.Model:
+def create_bert_model(bert_config: configs.BertConfig) -> tf_keras.Model:
   """Creates a BERT keras core model from BERT configuration.
 
   Args:
     bert_config: A `BertConfig` to create the core model.
 
   Returns:
     A keras model.
   """
   # Adds input layers just as placeholders.
-  input_word_ids = tf.keras.layers.Input(
+  input_word_ids = tf_keras.layers.Input(
       shape=(None,), dtype=tf.int32, name="input_word_ids")
-  input_mask = tf.keras.layers.Input(
+  input_mask = tf_keras.layers.Input(
       shape=(None,), dtype=tf.int32, name="input_mask")
-  input_type_ids = tf.keras.layers.Input(
+  input_type_ids = tf_keras.layers.Input(
       shape=(None,), dtype=tf.int32, name="input_type_ids")
   transformer_encoder = bert_models.get_transformer_encoder(
       bert_config, sequence_length=None)
   sequence_output, pooled_output = transformer_encoder(
       [input_word_ids, input_mask, input_type_ids])
   # To keep consistent with legacy hub modules, the outputs are
   # "pooled_output" and "sequence_output".
-  return tf.keras.Model(
+  return tf_keras.Model(
       inputs=[input_word_ids, input_mask, input_type_ids],
       outputs=[pooled_output, sequence_output]), transformer_encoder
 
 
 def export_bert_tfhub(bert_config: configs.BertConfig,
                       model_checkpoint_path: Text,
                       hub_destination: Text,
                       vocab_file: Text,
                       do_lower_case: bool = None):
-  """Restores a tf.keras.Model and saves for TF-Hub."""
+  """Restores a tf_keras.Model and saves for TF-Hub."""
   # If do_lower_case is not explicit, default to checking whether "uncased" is
   # in the vocab file name
   if do_lower_case is None:
     do_lower_case = "uncased" in vocab_file
     logging.info("Using do_lower_case=%s based on name of vocab_file=%s",
                  do_lower_case, vocab_file)
   core_model, encoder = create_bert_model(bert_config)
@@ -95,15 +95,15 @@
 
 
 def export_bert_squad_tfhub(bert_config: configs.BertConfig,
                             model_checkpoint_path: Text,
                             hub_destination: Text,
                             vocab_file: Text,
                             do_lower_case: bool = None):
-  """Restores a tf.keras.Model for BERT with SQuAD and saves for TF-Hub."""
+  """Restores a tf_keras.Model for BERT with SQuAD and saves for TF-Hub."""
   # If do_lower_case is not explicit, default to checking whether "uncased" is
   # in the vocab file name
   if do_lower_case is None:
     do_lower_case = "uncased" in vocab_file
     logging.info("Using do_lower_case=%s based on name of vocab_file=%s",
                  do_lower_case, vocab_file)
   span_labeling, _ = bert_models.squad_model(bert_config, max_seq_length=None)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/export_tfhub_test.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/export_tfhub_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests official.nlp.bert.export_tfhub."""
 
 import os
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_hub as hub
 
 from official.legacy.bert import configs
 from official.legacy.bert import export_tfhub
 
 
 class ExportTfhubTest(tf.test.TestCase, parameterized.TestCase):
@@ -90,17 +90,17 @@
           [hub_layer(inputs, training=training)[0] for _ in range(num_runs)])
       return np.mean(np.std(outputs, axis=0))
 
     self.assertLess(_dropout_mean_stddev(training=False), 1e-6)
     self.assertGreater(_dropout_mean_stddev(training=True), 1e-3)
 
     # Test propagation of seq_length in shape inference.
-    input_word_ids = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
-    input_mask = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
-    input_type_ids = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_word_ids = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_mask = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_type_ids = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
     pooled_output, sequence_output = hub_layer(
         [input_word_ids, input_mask, input_type_ids])
     self.assertEqual(pooled_output.shape.as_list(), [None, hidden_size])
     self.assertEqual(sequence_output.shape.as_list(),
                      [None, seq_length, hidden_size])
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/input_pipeline.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/input_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """BERT model input pipelines."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def decode_record(record, name_to_features):
   """Decodes a record to a TensorFlow example."""
   example = tf.io.parse_single_example(record, name_to_features)
 
   # tf.Example only supports tf.int64, but the TPU only supports tf.int32.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/model_saving_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/model_saving_utils.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,19 +13,19 @@
 # limitations under the License.
 
 """Utilities to save models."""
 
 import os
 import typing
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def export_bert_model(model_export_path: typing.Text,
-                      model: tf.keras.Model,
+                      model: tf_keras.Model,
                       checkpoint_dir: typing.Optional[typing.Text] = None,
                       restore_model_using_load_weights: bool = False) -> None:
   """Export BERT model for serving which does not include the optimizer.
 
   Args:
       model_export_path: Path to which exported model will be saved.
       model: Keras model object to export.
@@ -41,16 +41,16 @@
         how model checkpoint was saved.
 
   Raises:
     ValueError when either model_export_path or model is not specified.
   """
   if not model_export_path:
     raise ValueError('model_export_path must be specified.')
-  if not isinstance(model, tf.keras.Model):
-    raise ValueError('model must be a tf.keras.Model object.')
+  if not isinstance(model, tf_keras.Model):
+    raise ValueError('model must be a tf_keras.Model object.')
 
   if checkpoint_dir:
     if restore_model_using_load_weights:
       model_weight_path = os.path.join(checkpoint_dir, 'checkpoint')
       assert tf.io.gfile.exists(model_weight_path)
       model.load_weights(model_weight_path)
     else:
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/model_training_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/model_training_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """A light weight utilities to train NLP models."""
 
 import json
 import os
 import tempfile
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow.python.util import deprecation
 from official.common import distribute_utils
 from official.modeling import grad_utils
 
 _SUMMARY_TXT = 'training_summary.txt'
 _MIN_SUMMARY_STEPS = 10
 
@@ -257,41 +257,41 @@
         '`eval_step` is required when `eval_input_fn ` is not none.')
   if metric_fn and not callable(metric_fn):
     raise ValueError(
         'if `metric_fn` is specified, metric_fn must be a callable.')
 
   total_training_steps = steps_per_epoch * epochs
   train_iterator = _get_input_iterator(train_input_fn, strategy)
-  eval_loss_metric = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)
+  eval_loss_metric = tf_keras.metrics.Mean('training_loss', dtype=tf.float32)
 
   with distribute_utils.get_strategy_scope(strategy):
     # To correctly place the model weights on accelerators,
     # model and optimizer should be created in scope.
     model, sub_model = model_fn()
     if not hasattr(model, 'optimizer'):
       raise ValueError('User should set optimizer attribute to model '
                        'inside `model_fn`.')
     if sub_model_export_name and sub_model is None:
       raise ValueError('sub_model_export_name is specified as %s, but '
                        'sub_model is None.' % sub_model_export_name)
 
-    callback_list = tf.keras.callbacks.CallbackList(
+    callback_list = tf_keras.callbacks.CallbackList(
         callbacks=custom_callbacks, model=model)
 
     optimizer = model.optimizer
 
     if init_checkpoint:
       logging.info(
           'Checkpoint file %s found and restoring from '
           'initial checkpoint for core model.', init_checkpoint)
       checkpoint = tf.train.Checkpoint(model=sub_model, encoder=sub_model)
       checkpoint.read(init_checkpoint).assert_existing_objects_matched()
       logging.info('Loading from checkpoint file completed')
 
-    train_loss_metric = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)
+    train_loss_metric = tf_keras.metrics.Mean('training_loss', dtype=tf.float32)
     eval_metrics = metric_fn() if metric_fn else []
     if not isinstance(eval_metrics, list):
       eval_metrics = [eval_metrics]
     # If evaluation is required, make a copy of metric as it will be used by
     # both train and evaluation.
     train_metrics = [
         metric.__class__.from_config(metric.get_config())
@@ -336,15 +336,15 @@
       if explicit_allreduce:
         grad_utils.minimize_using_explicit_allreduce(tape, optimizer, loss,
                                                      training_vars,
                                                      pre_allreduce_callbacks,
                                                      post_allreduce_callbacks,
                                                      allreduce_bytes_per_pack)
       else:
-        if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+        if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
           with tape:
             scaled_loss = optimizer.get_scaled_loss(loss)
           scaled_grads = tape.gradient(scaled_loss, training_vars)
           grads = optimizer.get_unscaled_gradients(scaled_grads)
         else:
           grads = tape.gradient(loss, training_vars)
         optimizer.apply_gradients(zip(grads, training_vars))
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/model_training_utils_test.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/model_training_utils_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import os
 
 from absl import logging
 from absl.testing import flagsaver
 from absl.testing import parameterized
 from absl.testing.absltest import mock
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.legacy.bert import common_flags
 from official.legacy.bert import model_training_utils
 
 
@@ -90,33 +90,33 @@
   return _dataset_fn
 
 
 def create_model_fn(input_shape, num_classes, use_float16=False):
 
   def _model_fn():
     """A one-layer softmax model suitable for testing."""
-    input_layer = tf.keras.layers.Input(shape=input_shape)
-    x = tf.keras.layers.Dense(num_classes, activation='relu')(input_layer)
-    output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')(x)
-    sub_model = tf.keras.models.Model(input_layer, x, name='sub_model')
-    model = tf.keras.models.Model(input_layer, output_layer, name='model')
+    input_layer = tf_keras.layers.Input(shape=input_shape)
+    x = tf_keras.layers.Dense(num_classes, activation='relu')(input_layer)
+    output_layer = tf_keras.layers.Dense(num_classes, activation='softmax')(x)
+    sub_model = tf_keras.models.Model(input_layer, x, name='sub_model')
+    model = tf_keras.models.Model(input_layer, output_layer, name='model')
     model.add_metric(
         tf.reduce_mean(input_layer), name='mean_input', aggregation='mean')
-    model.optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)
+    model.optimizer = tf_keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)
     if use_float16:
-      model.optimizer = tf.keras.mixed_precision.LossScaleOptimizer(
+      model.optimizer = tf_keras.mixed_precision.LossScaleOptimizer(
           model.optimizer)
     return model, sub_model
 
   return _model_fn
 
 
 def metric_fn():
   """Gets a tf.keras metric object."""
-  return tf.keras.metrics.CategoricalAccuracy(name='accuracy', dtype=tf.float32)
+  return tf_keras.metrics.CategoricalAccuracy(name='accuracy', dtype=tf.float32)
 
 
 def summaries_with_matching_keyword(keyword, summary_dir):
   """Yields summary protos matching given keyword from event file."""
   event_paths = tf.io.gfile.glob(os.path.join(summary_dir, 'events*'))
   for event in tf.compat.v1.train.summary_iterator(event_paths[-1]):
     if event.summary is not None:
@@ -127,15 +127,15 @@
 
 
 def check_eventfile_for_keyword(keyword, summary_dir):
   """Checks event files for the keyword."""
   return any(summaries_with_matching_keyword(keyword, summary_dir))
 
 
-class RecordingCallback(tf.keras.callbacks.Callback):
+class RecordingCallback(tf_keras.callbacks.Callback):
 
   def __init__(self):
     self.batch_begin = []  # (batch, logs)
     self.batch_end = []  # (batch, logs)
     self.epoch_begin = []  # (epoch, logs)
     self.epoch_end = []  # (epoch, logs)
 
@@ -161,15 +161,15 @@
   @flagsaver.flagsaver
   def run_training(self, strategy, model_dir, steps_per_loop, run_eagerly):
     input_fn = create_fake_data_input_fn(
         batch_size=8, features_shape=[128], num_classes=3)
     model_training_utils.run_customized_training_loop(
         strategy=strategy,
         model_fn=self._model_fn,
-        loss_fn=tf.keras.losses.categorical_crossentropy,
+        loss_fn=tf_keras.losses.categorical_crossentropy,
         model_dir=model_dir,
         steps_per_epoch=20,
         steps_per_loop=steps_per_loop,
         epochs=2,
         train_input_fn=input_fn,
         eval_input_fn=input_fn,
         eval_steps=10,
@@ -191,15 +191,15 @@
     else:
       self.run_training(
           distribution, model_dir, steps_per_loop=1, run_eagerly=True)
 
   @combinations.generate(eager_gpu_strategy_combinations())
   def test_train_eager_mixed_precision(self, distribution):
     model_dir = self.create_tempdir().full_path
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     self._model_fn = create_model_fn(
         input_shape=[128], num_classes=3, use_float16=True)
     self.run_training(
         distribution, model_dir, steps_per_loop=1, run_eagerly=True)
 
   @combinations.generate(eager_strategy_combinations())
   def test_train_check_artifacts(self, distribution):
@@ -251,15 +251,15 @@
     callback = RecordingCallback()
     callbacks = [callback]
     input_fn = create_fake_data_input_fn(
         batch_size=8, features_shape=[128], num_classes=3)
     model_training_utils.run_customized_training_loop(
         strategy=distribution,
         model_fn=self._model_fn,
-        loss_fn=tf.keras.losses.categorical_crossentropy,
+        loss_fn=tf_keras.losses.categorical_crossentropy,
         model_dir=model_dir,
         steps_per_epoch=20,
         num_eval_per_epoch=4,
         steps_per_loop=10,
         epochs=2,
         train_input_fn=input_fn,
         eval_input_fn=input_fn,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/run_classifier.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/run_classifier.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,15 +20,15 @@
 import os
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.common import distribute_utils
 from official.legacy.bert import bert_models
 from official.legacy.bert import common_flags
 from official.legacy.bert import configs as bert_configs
 from official.legacy.bert import input_pipeline
 from official.legacy.bert import model_saving_utils
 from official.modeling import performance
@@ -149,33 +149,33 @@
                                               warmup_steps, FLAGS.end_lr,
                                               FLAGS.optimizer_type)
     classifier_model.optimizer = performance.configure_optimizer(
         optimizer,
         use_float16=common_flags.use_float16())
     return classifier_model, core_model
 
-  # tf.keras.losses objects accept optional sample_weight arguments (eg. coming
+  # tf_keras.losses objects accept optional sample_weight arguments (eg. coming
   # from the dataset) to compute weighted loss, as used for the regression
   # tasks. The classification tasks, using the custom get_loss_fn don't accept
   # sample weights though.
-  loss_fn = (tf.keras.losses.MeanSquaredError() if is_regression
+  loss_fn = (tf_keras.losses.MeanSquaredError() if is_regression
              else get_loss_fn(num_classes))
 
   # Defines evaluation metrics function, which will create metrics in the
   # correct device and strategy scope.
   if custom_metrics:
     metric_fn = custom_metrics
   elif is_regression:
     metric_fn = functools.partial(
-        tf.keras.metrics.MeanSquaredError,
+        tf_keras.metrics.MeanSquaredError,
         'mean_squared_error',
         dtype=tf.float32)
   else:
     metric_fn = functools.partial(
-        tf.keras.metrics.SparseCategoricalAccuracy,
+        tf_keras.metrics.SparseCategoricalAccuracy,
         'accuracy',
         dtype=tf.float32)
 
   # Start training using Keras compile/fit API.
   logging.info('Training using TF 2.x Keras compile/fit API with '
                'distribution strategy.')
   return run_keras_compile_fit(
@@ -226,15 +226,15 @@
     bert_model.compile(
         optimizer=optimizer,
         loss=loss_fn,
         metrics=[fn() for fn in metric_fn],
         steps_per_execution=steps_per_loop)
 
     summary_dir = os.path.join(model_dir, 'summaries')
-    summary_callback = tf.keras.callbacks.TensorBoard(summary_dir)
+    summary_callback = tf_keras.callbacks.TensorBoard(summary_dir)
     checkpoint = tf.train.Checkpoint(model=bert_model, optimizer=optimizer)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
         directory=model_dir,
         max_to_keep=None,
         step_counter=optimizer.iterations,
         checkpoint_interval=0)
@@ -343,15 +343,15 @@
   """
   if not model_export_path:
     raise ValueError('Export path is not specified: %s' % model_export_path)
   if not model_dir:
     raise ValueError('Export path is not specified: %s' % model_dir)
 
   # Export uses float32 for now, even if training uses mixed precision.
-  tf.keras.mixed_precision.set_global_policy('float32')
+  tf_keras.mixed_precision.set_global_policy('float32')
   classifier_model = bert_models.classifier_model(
       bert_config,
       input_meta_data.get('num_labels', 1),
       hub_module_url=FLAGS.hub_module_url,
       hub_module_trainable=False)[0]
 
   model_saving_utils.export_bert_model(
@@ -418,15 +418,15 @@
   return trained_model
 
 
 def custom_main(custom_callbacks=None, custom_metrics=None):
   """Run classification or regression.
 
   Args:
-    custom_callbacks: list of tf.keras.Callbacks passed to training loop.
+    custom_callbacks: list of tf_keras.Callbacks passed to training loop.
     custom_metrics: list of metrics passed to the training loop.
   """
   gin.parse_config_files_and_bindings(FLAGS.gin_file, FLAGS.gin_param)
 
   with tf.io.gfile.GFile(FLAGS.input_meta_data_path, 'rb') as reader:
     input_meta_data = json.loads(reader.read().decode('utf-8'))
   label_type = LABEL_TYPES_MAP[input_meta_data.get('label_type', 'int')]
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/run_pretraining.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/run_pretraining.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Run masked LM/next sentence pre-training for BERT in TF 2.x."""
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.common import distribute_utils
 from official.legacy.bert import bert_models
 from official.legacy.bert import common_flags
 from official.legacy.bert import configs
 from official.legacy.bert import input_pipeline
 from official.legacy.bert import model_training_utils
 from official.modeling import performance
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/run_squad.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/run_squad.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,15 +19,15 @@
 import time
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.common import distribute_utils
 from official.legacy.bert import configs as bert_configs
 from official.legacy.bert import run_squad_helper
 from official.nlp.data import squad_lib as squad_lib_wp
 from official.nlp.tools import tokenization
 from official.utils.misc import keras_utils
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/run_squad_helper.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/run_squad_helper.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import collections
 import json
 import os
 
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.bert import bert_models
 from official.legacy.bert import common_flags
 from official.legacy.bert import input_pipeline
 from official.legacy.bert import model_saving_utils
 from official.legacy.bert import model_training_utils
 from official.modeling import performance
 from official.nlp import optimization
@@ -93,17 +93,17 @@
 
 
 FLAGS = flags.FLAGS
 
 
 def squad_loss_fn(start_positions, end_positions, start_logits, end_logits):
   """Returns sparse categorical crossentropy for start/end logits."""
-  start_loss = tf.keras.losses.sparse_categorical_crossentropy(
+  start_loss = tf_keras.losses.sparse_categorical_crossentropy(
       start_positions, start_logits, from_logits=True)
-  end_loss = tf.keras.losses.sparse_categorical_crossentropy(
+  end_loss = tf_keras.losses.sparse_categorical_crossentropy(
       end_positions, end_logits, from_logits=True)
 
   total_loss = (tf.reduce_mean(start_loss) + tf.reduce_mean(end_loss)) / 2
   return total_loss
 
 
 def get_loss_fn():
@@ -156,15 +156,15 @@
 
 
 def get_squad_model_to_predict(strategy, bert_config, checkpoint_path,
                                input_meta_data):
   """Gets a squad model to make predictions."""
   with strategy.scope():
     # Prediction always uses float32, even if training uses mixed precision.
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
     squad_model, _ = bert_models.squad_model(
         bert_config,
         input_meta_data['max_seq_length'],
         hub_module_url=FLAGS.hub_module_url)
 
   if checkpoint_path is None:
     checkpoint_path = tf.train.latest_checkpoint(FLAGS.model_dir)
@@ -460,12 +460,12 @@
 
   Raises:
     Export path is not specified, got an empty string or None.
   """
   if not model_export_path:
     raise ValueError('Export path is not specified: %s' % model_export_path)
   # Export uses float32 for now, even if training uses mixed precision.
-  tf.keras.mixed_precision.set_global_policy('float32')
+  tf_keras.mixed_precision.set_global_policy('float32')
   squad_model, _ = bert_models.squad_model(bert_config,
                                            input_meta_data['max_seq_length'])
   model_saving_utils.export_bert_model(
       model_export_path, model=squad_model, checkpoint_dir=FLAGS.model_dir)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/bert/serving.py` & `tf-models-no-deps-2.16.0/official/legacy/bert/serving.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Examples of SavedModel export for tf-serving."""
 
 from absl import app
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.bert import bert_models
 from official.legacy.bert import configs
 
 flags.DEFINE_integer(
     "sequence_length", None, "Sequence length to parse the tf.Example. If "
     "sequence_length > 0, add a signature for serialized "
@@ -32,15 +32,15 @@
                     "File path to TF model checkpoint.")
 flags.DEFINE_string("export_path", None,
                     "Destination folder to export the serving SavedModel.")
 
 FLAGS = flags.FLAGS
 
 
-class BertServing(tf.keras.Model):
+class BertServing(tf_keras.Model):
   """Bert transformer encoder model for serving."""
 
   def __init__(self, bert_config, name_to_features=None, name="serving_model"):
     super(BertServing, self).__init__(name=name)
     self.encoder = bert_models.get_transformer_encoder(
         bert_config, sequence_length=None)
     self.name_to_features = name_to_features
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/configs/base_config.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/configs/base_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/configs/factory.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/configs/factory.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/configs/maskrcnn_config.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/configs/maskrcnn_config.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/configs/olnmask_config.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/configs/olnmask_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/configs/retinanet_config.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/configs/retinanet_config.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/configs/shapemask_config.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/configs/shapemask_config.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/anchor.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/anchor.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import collections
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.detection.utils import box_utils
 from official.vision.ops import iou_similarity
 from official.vision.utils.object_detection import argmax_matcher
 from official.vision.utils.object_detection import balanced_positive_negative_sampler
 from official.vision.utils.object_detection import box_list
 from official.vision.utils.object_detection import faster_rcnn_box_coder
 from official.vision.utils.object_detection import target_assigner
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/factory.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/factory.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/input_reader.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/input_reader.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Data loader and input processing."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 from typing import Optional, Text
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.detection.dataloader import factory
 from official.legacy.detection.dataloader import mode_keys as ModeKeys
 from official.modeling.hyperparams import params_dict
 
 
 class InputFn(object):
   """Input function that creates dataset from files."""
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/maskrcnn_parser.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/maskrcnn_parser.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Data parser and processing for Mask R-CNN."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import anchor
 from official.legacy.detection.dataloader import mode_keys as ModeKeys
 from official.legacy.detection.dataloader import tf_example_decoder
 from official.legacy.detection.utils import box_utils
 from official.legacy.detection.utils import dataloader_utils
 from official.legacy.detection.utils import input_utils
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/mode_keys.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/mode_keys.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/olnmask_parser.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/olnmask_parser.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Data parser and processing for Mask R-CNN."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import anchor
 from official.legacy.detection.dataloader.maskrcnn_parser import Parser as MaskrcnnParser
 from official.legacy.detection.utils import box_utils
 from official.legacy.detection.utils import class_utils
 from official.legacy.detection.utils import input_utils
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/retinanet_parser.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/retinanet_parser.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 Parse image and ground truths in a dataset to training targets and package them
 into (image, labels) tuple for RetinaNet.
 
 T.-Y. Lin, P. Goyal, R. Girshick, K. He,  and P. Dollar
 Focal Loss for Dense Object Detection. arXiv:1708.02002
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import anchor
 from official.legacy.detection.dataloader import mode_keys as ModeKeys
 from official.legacy.detection.dataloader import tf_example_decoder
 from official.legacy.detection.utils import box_utils
 from official.legacy.detection.utils import input_utils
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/shapemask_parser.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/shapemask_parser.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 Parse image and ground truths in a dataset to training targets and package them
 into (image, labels) tuple for ShapeMask.
 
 Weicheng Kuo, Anelia Angelova, Jitendra Malik, Tsung-Yi Lin
 ShapeMask: Learning to Segment Novel Objects by Refining Shape Priors.
 arXiv:1904.03239.
 """
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import anchor
 from official.legacy.detection.dataloader import mode_keys as ModeKeys
 from official.legacy.detection.dataloader import tf_example_decoder
 from official.legacy.detection.utils import box_utils
 from official.legacy.detection.utils import class_utils
 from official.legacy.detection.utils import dataloader_utils
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/dataloader/tf_example_decoder.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/dataloader/tf_example_decoder.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 
 """Tensorflow Example proto decoder for object detection.
 
 A decoder to decode string tensors containing serialized tensorflow.Example
 protos for object detection.
 """
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class TfExampleDecoder(object):
   """Tensorflow Example proto decoder."""
 
   def __init__(self, include_mask=False):
     self._include_mask = include_mask
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/coco_evaluator.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/coco_evaluator.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -34,24 +34,254 @@
 import copy
 import tempfile
 
 from absl import logging
 import numpy as np
 from pycocotools import cocoeval
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.evaluation import coco_utils
 from official.legacy.detection.utils import class_utils
 
 
+class OlnCOCOevalWrapper(cocoeval.COCOeval):
+  """COCOeval wrapper class.
+
+  Rewritten based on cocoapi: (pycocotools/cocoeval.py)
+
+  This class wraps COCOEVAL API object, which provides the following additional
+  functionalities:
+    1. summarze 'all', 'seen', and 'novel' split output print-out, e.g., AR at
+       different K proposals, AR and AP resutls for 'seen' and 'novel' class
+       splits.
+  """
+
+  def __init__(self, coco_gt, coco_dt, iou_type='box'):
+    super(OlnCOCOevalWrapper, self).__init__(
+        cocoGt=coco_gt, cocoDt=coco_dt, iouType=iou_type)
+
+  def summarize(self):
+    """Compute and display summary metrics for evaluation results.
+
+    Delta to the standard cocoapi function:
+      More Averate Recall metrics are produced with different top-K proposals.
+    Note this functin can *only* be applied on the default parameter
+    setting.
+    Raises:
+      Exception: Please run accumulate() first.
+    """
+
+    def _summarize(ap=1, iou_thr=None, area_rng='all', max_dets=100):
+      p = self.params
+      i_str = (' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = '
+               '{:0.3f}')
+      title_str = 'Average Precision' if ap == 1 else 'Average Recall'
+      type_str = '(AP)' if ap == 1 else '(AR)'
+      iou_str = '{:0.2f}:{:0.2f}'.format(
+          p.iouThrs[0],
+          p.iouThrs[-1]) if iou_thr is None else '{:0.2f}'.format(iou_thr)
+
+      aind = [i for i, a_rng in enumerate(p.areaRngLbl) if a_rng == area_rng]
+      mind = [i for i, m_det in enumerate(p.maxDets) if m_det == max_dets]
+      if ap == 1:
+        # dimension of precision: [TxRxKxAxM]
+        s = self.eval['precision']
+        # IoU
+        if iou_thr is not None:
+          t = np.where(iou_thr == p.iouThrs)[0]
+          s = s[t]
+        s = s[:, :, :, aind, mind]
+      else:
+        # dimension of recall: [TxKxAxM]
+        s = self.eval['recall']
+        if iou_thr is not None:
+          t = np.where(iou_thr == p.iouThrs)[0]
+          s = s[t]
+        s = s[:, :, aind, mind]
+
+      if not (s[s > -1]).any():
+        mean_s = -1
+      else:
+        mean_s = np.mean(s[s > -1])
+        print(
+            i_str.format(title_str, type_str, iou_str, area_rng, max_dets,
+                         mean_s))
+      return mean_s
+
+    def _summarize_dets():
+      stats = np.zeros((14,))
+      stats[0] = _summarize(1)
+      stats[1] = _summarize(
+          1,
+          iou_thr=.5,
+      )
+      stats[2] = _summarize(
+          1,
+          iou_thr=.75,
+      )
+      stats[3] = _summarize(
+          1,
+          area_rng='small',
+      )
+      stats[4] = _summarize(
+          1,
+          area_rng='medium',
+      )
+      stats[5] = _summarize(
+          1,
+          area_rng='large',
+      )
+
+      stats[6] = _summarize(0, max_dets=self.params.maxDets[0])  # 10
+      stats[7] = _summarize(0, max_dets=self.params.maxDets[1])  # 20
+      stats[8] = _summarize(0, max_dets=self.params.maxDets[2])  # 50
+      stats[9] = _summarize(0, max_dets=self.params.maxDets[3])  # 100
+      stats[10] = _summarize(0, max_dets=self.params.maxDets[4])  # 200
+
+      stats[11] = _summarize(0, area_rng='small', max_dets=10)
+      stats[12] = _summarize(0, area_rng='medium', max_dets=10)
+      stats[13] = _summarize(0, area_rng='large', max_dets=10)
+      return stats
+
+    if not self.eval:
+      raise Exception('Please run accumulate() first')
+    summarize = _summarize_dets
+    self.stats = summarize()
+
+
+class OlnCOCOevalXclassWrapper(OlnCOCOevalWrapper):
+  """COCOeval wrapper class.
+
+  Rewritten based on cocoapi: (pycocotools/cocoeval.py)
+  Delta to the standard cocoapi:
+    Detections that hit the 'seen' class objects are ignored in top-K proposals.
+
+  This class wraps COCOEVAL API object, which provides the following additional
+  functionalities:
+    1. Include ignore-class split (e.g., 'voc' or 'nonvoc').
+    2. Do not count (or ignore) box proposals hitting ignore-class when
+       evaluating Average Recall at top-K proposals.
+  """
+
+  def __init__(self, coco_gt, coco_dt, iou_type='box'):
+    super(OlnCOCOevalXclassWrapper, self).__init__(
+        coco_gt=coco_gt, coco_dt=coco_dt, iou_type=iou_type)
+
+  def evaluateImg(self, img_id, cat_id, a_rng, max_det):
+    p = self.params
+    if p.useCats:
+      gt = self._gts[img_id, cat_id]
+      dt = self._dts[img_id, cat_id]
+    else:
+      gt, dt = [], []
+      for c_id in p.catIds:
+        gt.extend(self._gts[img_id, c_id])
+        dt.extend(self._dts[img_id, c_id])
+
+    if not gt and not dt:
+      return None
+
+    for g in gt:
+      if g['ignore'] or (g['area'] < a_rng[0] or g['area'] > a_rng[1]):
+        g['_ignore'] = 1
+      else:
+        g['_ignore'] = 0
+      # Class manipulation: ignore the 'ignored_split'.
+      if 'ignored_split' in g and g['ignored_split'] == 1:
+        g['_ignore'] = 1
+
+    # sort dt highest score first, sort gt ignore last
+    gtind = np.argsort([g['_ignore'] for g in gt], kind='mergesort')
+    gt = [gt[i] for i in gtind]
+    dtind = np.argsort([-d['score'] for d in dt], kind='mergesort')
+    dt = [dt[i] for i in dtind[0:max_det]]
+    iscrowd = [int(o['iscrowd']) for o in gt]
+    # load computed ious
+    # ious = self.ious[img_id, cat_id][:, gtind] if len(
+    #     self.ious[img_id, cat_id]) > 0 else self.ious[img_id, cat_id]
+    if self.ious[img_id, cat_id].any():
+      ious = self.ious[img_id, cat_id][:, gtind]
+    else:
+      ious = self.ious[img_id, cat_id]
+
+    tt = len(p.iouThrs)
+    gg = len(gt)
+    dd = len(dt)
+    gtm = np.zeros((tt, gg))
+    dtm = np.zeros((tt, dd))
+    gt_ig = np.array([g['_ignore'] for g in gt])
+    dt_ig = np.zeros((tt, dd))
+    # indicator of whether the gt object class is of ignored_split or not.
+    gt_ig_split = np.array([g['ignored_split'] for g in gt])
+    dt_ig_split = np.zeros((dd))
+
+    if ious.any():
+      for tind, t in enumerate(p.iouThrs):
+        for dind, d in enumerate(dt):
+          # information about best match so far (m=-1 -> unmatched)
+          iou = min([t, 1 - 1e-10])
+          m = -1
+          for gind, g in enumerate(gt):
+            # if this gt already matched, and not a crowd, continue
+            if gtm[tind, gind] > 0 and not iscrowd[gind]:
+              continue
+            # if dt matched to reg gt, and on ignore gt, stop
+            if m > -1 and gt_ig[m] == 0 and gt_ig[gind] == 1:
+              break
+            # continue to next gt unless better match made
+            if ious[dind, gind] < iou:
+              continue
+            # if match successful and best so far, store appropriately
+            iou = ious[dind, gind]
+            m = gind
+          # if match made store id of match for both dt and gt
+          if m == -1:
+            continue
+          dt_ig[tind, dind] = gt_ig[m]
+          dtm[tind, dind] = gt[m]['id']
+          gtm[tind, m] = d['id']
+
+          # Activate to ignore the seen-class detections.
+          if tind == 0:  # Register just only once: tind > 0 is also fine.
+            dt_ig_split[dind] = gt_ig_split[m]
+
+    # set unmatched detections outside of area range to ignore
+    a = np.array([d['area'] < a_rng[0] or d['area'] > a_rng[1] for d in dt
+                 ]).reshape((1, len(dt)))
+    dt_ig = np.logical_or(dt_ig, np.logical_and(dtm == 0, np.repeat(a, tt, 0)))
+
+    # Activate to ignore the seen-class detections.
+    # Take only eval_split (eg, nonvoc) and ignore seen_split (eg, voc).
+    if dt_ig_split.sum() > 0:
+      dtm = dtm[:, dt_ig_split == 0]
+      dt_ig = dt_ig[:, dt_ig_split == 0]
+      len_dt = min(max_det, len(dt))
+      dt = [dt[i] for i in range(len_dt) if dt_ig_split[i] == 0]
+
+    # store results for given image and category
+    return {
+        'image_id': img_id,
+        'category_id': cat_id,
+        'aRng': a_rng,
+        'maxDet': max_det,
+        'dtIds': [d['id'] for d in dt],
+        'gtIds': [g['id'] for g in gt],
+        'dtMatches': dtm,
+        'gtMatches': gtm,
+        'dtScores': [d['score'] for d in dt],
+        'gtIgnore': gt_ig,
+        'dtIgnore': dt_ig,
+    }
+
+
 class MetricWrapper(object):
   """Metric Wrapper of the COCO evaluator."""
   # This is only a wrapper for COCO metric and works on for numpy array. So it
-  # doesn't inherit from tf.keras.layers.Layer or tf.keras.metrics.Metric.
+  # doesn't inherit from tf_keras.layers.Layer or tf_keras.metrics.Metric.
 
   def __init__(self, evaluator):
     self._evaluator = evaluator
 
   def update_state(self, y_true, y_pred):
     """Update internal states."""
     labels = tf.nest.map_structure(lambda x: x.numpy(), y_true)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/coco_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/coco_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -23,15 +23,15 @@
 
 from absl import logging
 import numpy as np
 from PIL import Image
 from pycocotools import coco
 from pycocotools import mask as mask_api
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import tf_example_decoder
 from official.legacy.detection.utils import box_utils
 from official.legacy.detection.utils import mask_utils
 
 
 class COCOWrapper(coco.COCO):
@@ -234,17 +234,15 @@
           ann['area'] = float(groundtruths['areas'][i][j, k])
         else:
           ann['area'] = float(
               (boxes[j, k, 3] - boxes[j, k, 1]) *
               (boxes[j, k, 2] - boxes[j, k, 0]))
         if 'masks' in groundtruths:
           mask = Image.open(six.BytesIO(groundtruths['masks'][i][j, k]))
-          width, height = mask.size
-          np_mask = (
-              np.array(mask.getdata()).reshape(height, width).astype(np.uint8))
+          np_mask = np.array(mask, dtype=np.uint8)
           np_mask[np_mask > 0] = 255
           encoded_mask = mask_api.encode(np.asfortranarray(np_mask))
           ann['segmentation'] = encoded_mask
           if 'areas' not in groundtruths:
             ann['area'] = mask_api.area(encoded_mask)
         gt_annotations.append(ann)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/evaluation/factory.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/evaluation/factory.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/executor/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/executor/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/executor/detection_executor.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/executor/detection_executor.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.detection.executor import distributed_executor as executor
 from official.vision.utils.object_detection import visualization_utils
 
 
 class DetectionDistributedExecutor(executor.DistributedExecutor):
   """Detection specific customer training loop executor.
 
@@ -59,19 +59,19 @@
     trainable_variables = model.trainable_variables
     if self._trainable_variables_filter:
       trainable_variables = self._trainable_variables_filter(
           trainable_variables)
     logging.info('Filter trainable variables from %d to %d',
                  len(model.trainable_variables), len(trainable_variables))
     update_state_fn = lambda labels, outputs: None
-    if isinstance(metric, tf.keras.metrics.Metric):
+    if isinstance(metric, tf_keras.metrics.Metric):
       update_state_fn = metric.update_state
     else:
       logging.error('Detection: train metric is not an instance of '
-                    'tf.keras.metrics.Metric.')
+                    'tf_keras.metrics.Metric.')
 
     def _replicated_step(inputs):
       """Replicated training step."""
       inputs, labels = inputs
 
       with tf.GradientTape() as tape:
         outputs = model(inputs, training=True)
@@ -147,13 +147,13 @@
         labels, outputs = test_step(test_iterator, self.eval_steps)
         if metric:
           metric.update_state(labels, outputs)
       except (StopIteration, tf.errors.OutOfRangeError):
         break
 
     metric_result = metric.result()
-    if isinstance(metric, tf.keras.metrics.Metric):
+    if isinstance(metric, tf_keras.metrics.Metric):
       metric_result = tf.nest.map_structure(lambda x: x.numpy().astype(float),
                                             metric_result)
     logging.info('Step: [%d] Validation metric = %s', current_training_step,
                  metric_result)
     return metric_result
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/executor/distributed_executor.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/executor/distributed_executor.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,15 +21,15 @@
 import os
 from typing import Optional, Dict, List, Text, Callable, Union, Iterator, Any
 
 from absl import flags
 from absl import logging
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # pylint: disable=unused-import,g-import-not-at-top,redefined-outer-name,reimported
 from official.common import distribute_utils
 from official.modeling.hyperparams import params_dict
 from official.utils import hyperparams_flags
 from official.utils.misc import keras_utils
 
@@ -59,20 +59,20 @@
 
 
 def metrics_as_dict(metric):
   """Puts input metric(s) into a list.
 
   Args:
     metric: metric(s) to be put into the list. `metric` could be an object, a
-      list, or a dict of tf.keras.metrics.Metric or has the `required_method`.
+      list, or a dict of tf_keras.metrics.Metric or has the `required_method`.
 
   Returns:
     A dictionary of valid metrics.
   """
-  if isinstance(metric, tf.keras.metrics.Metric):
+  if isinstance(metric, tf_keras.metrics.Metric):
     metrics = {metric.name: metric}
   elif isinstance(metric, list):
     metrics = {m.name: m for m in metric}
   elif isinstance(metric, dict):
     metrics = metric
   elif not metric:
     return {}
@@ -137,15 +137,15 @@
   def __init__(self, strategy, params, model_fn, loss_fn, is_multi_host=False):
     """Constructor.
 
     Args:
       strategy: an instance of tf.distribute.Strategy.
       params: Model configuration needed to run distribution strategy.
       model_fn: Keras model function. Signature:
-        (params: ParamsDict) -> tf.keras.models.Model.
+        (params: ParamsDict) -> tf_keras.models.Model.
       loss_fn: loss function. Signature:
         (y_true: Tensor, y_pred: Tensor) -> Tensor
       is_multi_host: Set to True when using multi hosts for training, like multi
         worker GPU or TPU pod (slice). Otherwise, False.
     """
 
     self._params = params
@@ -219,16 +219,16 @@
                               metric=None):
     """Creates a single training step.
 
     Args:
       strategy: an instance of tf.distribute.Strategy.
       model: (Tensor, bool) -> Tensor. model function.
       loss_fn: (y_true: Tensor, y_pred: Tensor) -> Tensor.
-      optimizer: tf.keras.optimizers.Optimizer.
-      metric: tf.keras.metrics.Metric subclass.
+      optimizer: tf_keras.optimizers.Optimizer.
+      metric: tf_keras.metrics.Metric subclass.
 
     Returns:
       The training step callable.
     """
     metrics = metrics_as_dict(metric)
 
     def _replicated_step(inputs):
@@ -257,16 +257,16 @@
                          metric=None):
     """Creates a distributed training step.
 
     Args:
       strategy: an instance of tf.distribute.Strategy.
       model: (Tensor, bool) -> Tensor. model function.
       loss_fn: (y_true: Tensor, y_pred: Tensor) -> Tensor.
-      optimizer: tf.keras.optimizers.Optimizer.
-      metric: tf.keras.metrics.Metric subclass.
+      optimizer: tf_keras.optimizers.Optimizer.
+      metric: tf_keras.metrics.Metric subclass.
 
     Returns:
       The training step callable.
     """
     replicated_step = self._create_replicated_step(strategy, model, loss_fn,
                                                    optimizer, metric)
 
@@ -328,16 +328,16 @@
                                        tf.data.Dataset]] = None,
       model_dir: Optional[Text] = None,
       total_steps: int = 1,
       iterations_per_loop: int = 1,
       train_metric_fn: Optional[Callable[[], Any]] = None,
       eval_metric_fn: Optional[Callable[[], Any]] = None,
       summary_writer_fn: Callable[[Text, Text], SummaryWriter] = SummaryWriter,
-      init_checkpoint: Optional[Callable[[tf.keras.Model], Any]] = None,
-      custom_callbacks: Optional[List[tf.keras.callbacks.Callback]] = None,
+      init_checkpoint: Optional[Callable[[tf_keras.Model], Any]] = None,
+      custom_callbacks: Optional[List[tf_keras.callbacks.Callback]] = None,
       continuous_eval: bool = False,
       save_config: bool = True):
     """Runs distributed training.
 
     Args:
       train_input_fn: (params: dict) -> tf.data.Dataset training data input
         function.
@@ -408,15 +408,15 @@
     strategy = self._strategy
     # To reduce unnecessary send/receive input pipeline operation, we place
     # input pipeline ops in worker task.
     train_iterator = self._get_input_iterator(train_input_fn, strategy)
     train_loss = None
     train_metric_result = None
     eval_metric_result = None
-    tf.keras.backend.set_learning_phase(1)
+    tf_keras.backend.set_learning_phase(1)
     with strategy.scope():
       # To correctly place the model weights on accelerators,
       # model and optimizer should be created in scope.
       model = self.model_fn(params.as_dict())
       if not hasattr(model, 'optimizer'):
         raise ValueError('User should set optimizer attribute to model '
                          'inside `model_fn`.')
@@ -658,16 +658,16 @@
     Returns:
       Eval metrics dictionary of the last checkpoint.
     """
     if not callable(eval_metric_fn):
       raise ValueError('if `eval_metric_fn` is specified, '
                        'eval_metric_fn must be a callable.')
 
-    old_phase = tf.keras.backend.learning_phase()
-    tf.keras.backend.set_learning_phase(0)
+    old_phase = tf_keras.backend.learning_phase()
+    tf_keras.backend.set_learning_phase(0)
     params = self._params
     strategy = self._strategy
     # To reduce unnecessary send/receive input pipeline operation, we place
     # input pipeline ops in worker task.
     with strategy.scope():
 
       # To correctly place the model weights on accelerators,
@@ -701,15 +701,15 @@
       eval_metric_result = self._run_evaluation(test_step, current_step,
                                                 eval_metric, eval_iterator)
       logging.info('Step: %s evalation metric = %s.', current_step,
                    eval_metric_result)
       summary_writer(metrics=eval_metric_result, step=current_step)
       reset_states(eval_metric)
 
-    tf.keras.backend.set_learning_phase(old_phase)
+    tf_keras.backend.set_learning_phase(old_phase)
     return eval_metric_result, current_step
 
   def predict(self):
     return NotImplementedError('Unimplmented function.')
 
 
 class ExecutorBuilder(object):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/main.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/main.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import functools
 import pprint
 
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import distribute_utils
 from official.legacy.detection.configs import factory as config_factory
 from official.legacy.detection.dataloader import input_reader
 from official.legacy.detection.dataloader import mode_keys as ModeKeys
 from official.legacy.detection.executor import distributed_executor as executor
 from official.legacy.detection.executor.detection_executor import DetectionDistributedExecutor
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/factory.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/factory.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/fpn.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/fpn.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,15 +22,15 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.modeling.architecture import nn_ops
 from official.legacy.detection.ops import spatial_transform_ops
 
 
 class Fpn(object):
   """Feature pyramid networks."""
@@ -58,17 +58,17 @@
         followed by an optional activation layer.
     """
     self._min_level = min_level
     self._max_level = max_level
     self._fpn_feat_dims = fpn_feat_dims
     if use_separable_conv:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.SeparableConv2D, depth_multiplier=1)
+          tf_keras.layers.SeparableConv2D, depth_multiplier=1)
     else:
-      self._conv2d_op = tf.keras.layers.Conv2D
+      self._conv2d_op = tf_keras.layers.Conv2D
     if activation == 'relu':
       self._activation_op = tf.nn.relu
     elif activation == 'swish':
       self._activation_op = tf.nn.swish
     else:
       raise ValueError('Unsupported activation `{}`.'.format(activation))
     self._use_batch_norm = use_batch_norm
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/heads.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/heads.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,21 +17,21 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import functools
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.modeling.architecture import nn_ops
 from official.legacy.detection.ops import spatial_transform_ops
 
 
-class RpnHead(tf.keras.layers.Layer):
+class RpnHead(tf_keras.layers.Layer):
   """Region Proposal Network head."""
 
   def __init__(
       self,
       min_level,
       max_level,
       anchors_per_location,
@@ -70,21 +70,21 @@
       self._activation_op = tf.nn.swish
     else:
       raise ValueError('Unsupported activation `{}`.'.format(activation))
     self._use_batch_norm = use_batch_norm
 
     if use_separable_conv:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.SeparableConv2D,
+          tf_keras.layers.SeparableConv2D,
           depth_multiplier=1,
           bias_initializer=tf.zeros_initializer())
     else:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.Conv2D,
-          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
+          tf_keras.layers.Conv2D,
+          kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
           bias_initializer=tf.zeros_initializer())
 
     self._rpn_conv = self._conv2d_op(
         num_filters,
         kernel_size=(3, 3),
         strides=(1, 1),
         activation=(None if self._use_batch_norm else self._activation_op),
@@ -134,15 +134,15 @@
         scores_output, box_output = self._shared_rpn_heads(
             features[level], self._anchors_per_location, level, is_training)
         scores_outputs[level] = scores_output
         box_outputs[level] = box_output
       return scores_outputs, box_outputs
 
 
-class OlnRpnHead(tf.keras.layers.Layer):
+class OlnRpnHead(tf_keras.layers.Layer):
   """Region Proposal Network for Object Localization Network (OLN)."""
 
   def __init__(
       self,
       min_level,
       max_level,
       anchors_per_location,
@@ -179,21 +179,21 @@
       self._activation_op = tf.nn.swish
     else:
       raise ValueError('Unsupported activation `{}`.'.format(activation))
     self._use_batch_norm = use_batch_norm
 
     if use_separable_conv:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.SeparableConv2D,
+          tf_keras.layers.SeparableConv2D,
           depth_multiplier=1,
           bias_initializer=tf.zeros_initializer())
     else:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.Conv2D,
-          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
+          tf_keras.layers.Conv2D,
+          kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
           bias_initializer=tf.zeros_initializer())
 
     self._rpn_conv = self._conv2d_op(
         num_filters,
         kernel_size=(3, 3),
         strides=(1, 1),
         activation=(None if self._use_batch_norm else self._activation_op),
@@ -258,15 +258,15 @@
             features[level], self._anchors_per_location, level, is_training)
         scores_outputs[level] = scores_output
         box_outputs[level] = box_output
         center_outputs[level] = center_output
       return scores_outputs, box_outputs, center_outputs
 
 
-class FastrcnnHead(tf.keras.layers.Layer):
+class FastrcnnHead(tf_keras.layers.Layer):
   """Fast R-CNN box head."""
 
   def __init__(
       self,
       num_classes,
       num_convs=0,
       num_filters=256,
@@ -299,21 +299,21 @@
 
     self._num_classes = num_classes
 
     self._num_convs = num_convs
     self._num_filters = num_filters
     if use_separable_conv:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.SeparableConv2D,
+          tf_keras.layers.SeparableConv2D,
           depth_multiplier=1,
           bias_initializer=tf.zeros_initializer())
     else:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.Conv2D,
-          kernel_initializer=tf.keras.initializers.VarianceScaling(
+          tf_keras.layers.Conv2D,
+          kernel_initializer=tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           bias_initializer=tf.zeros_initializer())
 
     self._num_fcs = num_fcs
     self._fc_dims = fc_dims
     if activation == 'relu':
       self._activation_op = tf.nn.relu
@@ -340,30 +340,30 @@
       if self._use_batch_norm:
         self._conv_bn_ops.append(self._norm_activation())
 
     self._fc_ops = []
     self._fc_bn_ops = []
     for i in range(self._num_fcs):
       self._fc_ops.append(
-          tf.keras.layers.Dense(
+          tf_keras.layers.Dense(
               units=self._fc_dims,
               activation=(None
                           if self._use_batch_norm else self._activation_op),
               name='fc{}'.format(i)))
       if self._use_batch_norm:
         self._fc_bn_ops.append(self._norm_activation(fused=False))
 
-    self._class_predict = tf.keras.layers.Dense(
+    self._class_predict = tf_keras.layers.Dense(
         self._num_classes,
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
         bias_initializer=tf.zeros_initializer(),
         name='class-predict')
-    self._box_predict = tf.keras.layers.Dense(
+    self._box_predict = tf_keras.layers.Dense(
         self._num_classes * 4,
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.001),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.001),
         bias_initializer=tf.zeros_initializer(),
         name='box-predict')
 
   def call(self, roi_features, is_training=None):
     """Box and class branches for the Mask-RCNN model.
 
     Args:
@@ -399,15 +399,15 @@
           net = self._fc_bn_ops[i](net, is_training=is_training)
 
       class_outputs = self._class_predict(net)
       box_outputs = self._box_predict(net)
       return class_outputs, box_outputs
 
 
-class OlnBoxScoreHead(tf.keras.layers.Layer):
+class OlnBoxScoreHead(tf_keras.layers.Layer):
   """Box head of Object Localization Network (OLN)."""
 
   def __init__(
       self,
       num_classes,
       num_convs=0,
       num_filters=256,
@@ -438,21 +438,21 @@
     """
     self._num_classes = num_classes
 
     self._num_convs = num_convs
     self._num_filters = num_filters
     if use_separable_conv:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.SeparableConv2D,
+          tf_keras.layers.SeparableConv2D,
           depth_multiplier=1,
           bias_initializer=tf.zeros_initializer())
     else:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.Conv2D,
-          kernel_initializer=tf.keras.initializers.VarianceScaling(
+          tf_keras.layers.Conv2D,
+          kernel_initializer=tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           bias_initializer=tf.zeros_initializer())
 
     self._num_fcs = num_fcs
     self._fc_dims = fc_dims
     if activation == 'relu':
       self._activation_op = tf.nn.relu
@@ -479,35 +479,35 @@
       if self._use_batch_norm:
         self._conv_bn_ops.append(self._norm_activation())
 
     self._fc_ops = []
     self._fc_bn_ops = []
     for i in range(self._num_fcs):
       self._fc_ops.append(
-          tf.keras.layers.Dense(
+          tf_keras.layers.Dense(
               units=self._fc_dims,
               activation=(None
                           if self._use_batch_norm else self._activation_op),
               name='fc{}'.format(i)))
       if self._use_batch_norm:
         self._fc_bn_ops.append(self._norm_activation(fused=False))
 
-    self._class_predict = tf.keras.layers.Dense(
+    self._class_predict = tf_keras.layers.Dense(
         self._num_classes,
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
         bias_initializer=tf.zeros_initializer(),
         name='class-predict')
-    self._box_predict = tf.keras.layers.Dense(
+    self._box_predict = tf_keras.layers.Dense(
         self._num_classes * 4,
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.001),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.001),
         bias_initializer=tf.zeros_initializer(),
         name='box-predict')
-    self._score_predict = tf.keras.layers.Dense(
+    self._score_predict = tf_keras.layers.Dense(
         1,
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
         bias_initializer=tf.zeros_initializer(),
         name='score-predict')
 
   def __call__(self, roi_features, is_training=None):
     """Box and class branches for the Mask-RCNN model.
 
     Args:
@@ -543,15 +543,15 @@
 
       class_outputs = self._class_predict(net)
       box_outputs = self._box_predict(net)
       score_outputs = self._score_predict(net)
       return class_outputs, box_outputs, score_outputs
 
 
-class MaskrcnnHead(tf.keras.layers.Layer):
+class MaskrcnnHead(tf_keras.layers.Layer):
   """Mask R-CNN head."""
 
   def __init__(
       self,
       num_classes,
       mask_target_size,
       num_convs=4,
@@ -580,21 +580,21 @@
     self._num_classes = num_classes
     self._mask_target_size = mask_target_size
 
     self._num_convs = num_convs
     self._num_filters = num_filters
     if use_separable_conv:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.SeparableConv2D,
+          tf_keras.layers.SeparableConv2D,
           depth_multiplier=1,
           bias_initializer=tf.zeros_initializer())
     else:
       self._conv2d_op = functools.partial(
-          tf.keras.layers.Conv2D,
-          kernel_initializer=tf.keras.initializers.VarianceScaling(
+          tf_keras.layers.Conv2D,
+          kernel_initializer=tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           bias_initializer=tf.zeros_initializer())
     if activation == 'relu':
       self._activation_op = tf.nn.relu
     elif activation == 'swish':
       self._activation_op = tf.nn.swish
     else:
@@ -609,21 +609,21 @@
               kernel_size=(3, 3),
               strides=(1, 1),
               padding='same',
               dilation_rate=(1, 1),
               activation=(None
                           if self._use_batch_norm else self._activation_op),
               name='mask-conv-l%d' % i))
-    self._mask_conv_transpose = tf.keras.layers.Conv2DTranspose(
+    self._mask_conv_transpose = tf_keras.layers.Conv2DTranspose(
         self._num_filters,
         kernel_size=(2, 2),
         strides=(2, 2),
         padding='valid',
         activation=(None if self._use_batch_norm else self._activation_op),
-        kernel_initializer=tf.keras.initializers.VarianceScaling(
+        kernel_initializer=tf_keras.initializers.VarianceScaling(
             scale=2, mode='fan_out', distribution='untruncated_normal'),
         bias_initializer=tf.zeros_initializer(),
         name='conv5-mask')
 
     with tf.name_scope('mask_head'):
       self._mask_conv2d_op = self._conv2d_op(
           self._num_classes,
@@ -669,26 +669,20 @@
       mask_outputs = self._mask_conv2d_op(net)
       mask_outputs = tf.reshape(mask_outputs, [
           -1, num_rois, self._mask_target_size, self._mask_target_size,
           self._num_classes
       ])
 
       with tf.name_scope('masks_post_processing'):
-        # TODO(pengchong): Figure out the way not to use the static inferred
-        # batch size.
-        batch_size, num_masks = class_indices.get_shape().as_list()
-        mask_outputs = tf.transpose(a=mask_outputs, perm=[0, 1, 4, 2, 3])
-        # Constructs indices for gather.
-        batch_indices = tf.tile(
-            tf.expand_dims(tf.range(batch_size), axis=1), [1, num_masks])
-        mask_indices = tf.tile(
-            tf.expand_dims(tf.range(num_masks), axis=0), [batch_size, 1])
-        gather_indices = tf.stack(
-            [batch_indices, mask_indices, class_indices], axis=2)
-        mask_outputs = tf.gather_nd(mask_outputs, gather_indices)
+        mask_outputs = tf.gather(
+            mask_outputs,
+            tf.cast(class_indices, tf.int32),
+            axis=-1,
+            batch_dims=2,
+        )
       return mask_outputs
 
 
 class RetinanetHead(object):
   """RetinaNet head."""
 
   def __init__(
@@ -737,92 +731,92 @@
 
   def _box_net_batch_norm_name(self, i, level):
     return 'box-%d-%d' % (i, level)
 
   def _build_class_net_layers(self, norm_activation):
     """Build re-usable layers for class prediction network."""
     if self._use_separable_conv:
-      self._class_predict = tf.keras.layers.SeparableConv2D(
+      self._class_predict = tf_keras.layers.SeparableConv2D(
           self._num_classes * self._anchors_per_location,
           kernel_size=(3, 3),
           bias_initializer=tf.constant_initializer(-np.log((1 - 0.01) / 0.01)),
           padding='same',
           name='class-predict')
     else:
-      self._class_predict = tf.keras.layers.Conv2D(
+      self._class_predict = tf_keras.layers.Conv2D(
           self._num_classes * self._anchors_per_location,
           kernel_size=(3, 3),
           bias_initializer=tf.constant_initializer(-np.log((1 - 0.01) / 0.01)),
-          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=1e-5),
+          kernel_initializer=tf_keras.initializers.RandomNormal(stddev=1e-5),
           padding='same',
           name='class-predict')
     self._class_conv = []
     self._class_norm_activation = {}
     for i in range(self._num_convs):
       if self._use_separable_conv:
         self._class_conv.append(
-            tf.keras.layers.SeparableConv2D(
+            tf_keras.layers.SeparableConv2D(
                 self._num_filters,
                 kernel_size=(3, 3),
                 bias_initializer=tf.zeros_initializer(),
                 activation=None,
                 padding='same',
                 name='class-' + str(i)))
       else:
         self._class_conv.append(
-            tf.keras.layers.Conv2D(
+            tf_keras.layers.Conv2D(
                 self._num_filters,
                 kernel_size=(3, 3),
                 bias_initializer=tf.zeros_initializer(),
-                kernel_initializer=tf.keras.initializers.RandomNormal(
+                kernel_initializer=tf_keras.initializers.RandomNormal(
                     stddev=0.01),
                 activation=None,
                 padding='same',
                 name='class-' + str(i)))
       for level in range(self._min_level, self._max_level + 1):
         name = self._class_net_batch_norm_name(i, level)
         self._class_norm_activation[name] = norm_activation(name=name)
 
   def _build_box_net_layers(self, norm_activation):
     """Build re-usable layers for box prediction network."""
     if self._use_separable_conv:
-      self._box_predict = tf.keras.layers.SeparableConv2D(
+      self._box_predict = tf_keras.layers.SeparableConv2D(
           4 * self._anchors_per_location,
           kernel_size=(3, 3),
           bias_initializer=tf.zeros_initializer(),
           padding='same',
           name='box-predict')
     else:
-      self._box_predict = tf.keras.layers.Conv2D(
+      self._box_predict = tf_keras.layers.Conv2D(
           4 * self._anchors_per_location,
           kernel_size=(3, 3),
           bias_initializer=tf.zeros_initializer(),
-          kernel_initializer=tf.keras.initializers.RandomNormal(stddev=1e-5),
+          kernel_initializer=tf_keras.initializers.RandomNormal(stddev=1e-5),
           padding='same',
           name='box-predict')
     self._box_conv = []
     self._box_norm_activation = {}
     for i in range(self._num_convs):
       if self._use_separable_conv:
         self._box_conv.append(
-            tf.keras.layers.SeparableConv2D(
+            tf_keras.layers.SeparableConv2D(
                 self._num_filters,
                 kernel_size=(3, 3),
                 activation=None,
                 bias_initializer=tf.zeros_initializer(),
                 padding='same',
                 name='box-' + str(i)))
       else:
         self._box_conv.append(
-            tf.keras.layers.Conv2D(
+            tf_keras.layers.Conv2D(
                 self._num_filters,
                 kernel_size=(3, 3),
                 activation=None,
                 bias_initializer=tf.zeros_initializer(),
-                kernel_initializer=tf.keras.initializers.RandomNormal(
+                kernel_initializer=tf_keras.initializers.RandomNormal(
                     stddev=0.01),
                 padding='same',
                 name='box-' + str(i)))
       for level in range(self._min_level, self._max_level + 1):
         name = self._box_net_batch_norm_name(i, level)
         self._box_norm_activation[name] = norm_activation(name=name)
 
@@ -888,15 +882,15 @@
     """
     self._mask_num_classes = num_classes if use_category_for_mask else 1
     self._num_downsample_channels = num_downsample_channels
     self._mask_crop_size = mask_crop_size
     self._shape_prior_path = shape_prior_path
     self._use_category_for_mask = use_category_for_mask
 
-    self._shape_prior_fc = tf.keras.layers.Dense(
+    self._shape_prior_fc = tf_keras.layers.Dense(
         self._num_downsample_channels, name='shape-prior-fc')
 
   def __call__(self, fpn_features, boxes, outer_boxes, classes, is_training):
     """Generate the detection priors from the box detections and FPN features.
 
     This corresponds to the Fig. 4 of the ShapeMask paper at
     https://arxiv.org/pdf/1904.03239.pdf
@@ -988,15 +982,15 @@
     """
 
     batch_size, num_instances, _, _, _ = features.get_shape().as_list()
     features *= tf.expand_dims(uniform_priors, axis=-1)
     # Reduce spatial dimension of features. The features have shape
     # [batch_size, num_instances, num_channels].
     features = tf.reduce_mean(features, axis=(2, 3))
-    logits = tf.keras.layers.Dense(
+    logits = tf_keras.layers.Dense(
         self._mask_num_classes * self._num_clusters,
         kernel_initializer=tf.random_normal_initializer(stddev=0.01),
         name='classify-shape-prior-fc')(features)
     logits = tf.reshape(
         logits,
         [batch_size, num_instances, self._mask_num_classes, self._num_clusters])
     if self._use_category_for_mask:
@@ -1034,40 +1028,40 @@
     self._mask_num_classes = num_classes if use_category_for_mask else 1
     self._use_category_for_mask = use_category_for_mask
     self._num_downsample_channels = num_downsample_channels
     self._mask_crop_size = mask_crop_size
     self._num_convs = num_convs
     self._norm_activation = norm_activation
 
-    self._coarse_mask_fc = tf.keras.layers.Dense(
+    self._coarse_mask_fc = tf_keras.layers.Dense(
         self._num_downsample_channels, name='coarse-mask-fc')
 
     self._class_conv = []
     self._class_norm_activation = []
 
     for i in range(self._num_convs):
       self._class_conv.append(
-          tf.keras.layers.Conv2D(
+          tf_keras.layers.Conv2D(
               self._num_downsample_channels,
               kernel_size=(3, 3),
               bias_initializer=tf.zeros_initializer(),
-              kernel_initializer=tf.keras.initializers.RandomNormal(
+              kernel_initializer=tf_keras.initializers.RandomNormal(
                   stddev=0.01),
               padding='same',
               name='coarse-mask-class-%d' % i))
 
       self._class_norm_activation.append(
           norm_activation(name='coarse-mask-class-%d-bn' % i))
 
-    self._class_predict = tf.keras.layers.Conv2D(
+    self._class_predict = tf_keras.layers.Conv2D(
         self._mask_num_classes,
         kernel_size=(1, 1),
         # Focal loss bias initialization to have foreground 0.01 probability.
         bias_initializer=tf.constant_initializer(-np.log((1 - 0.01) / 0.01)),
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
         padding='same',
         name='coarse-mask-class-predict')
 
   def __call__(self, features, detection_priors, classes, is_training):
     """Generate instance masks from FPN features and detection priors.
 
     This corresponds to the Fig. 5-6 of the ShapeMask paper at
@@ -1160,45 +1154,45 @@
     self._use_category_for_mask = use_category_for_mask
     self._mask_num_classes = num_classes if use_category_for_mask else 1
     self._num_downsample_channels = num_downsample_channels
     self._mask_crop_size = mask_crop_size
     self._num_convs = num_convs
     self.up_sample_factor = upsample_factor
 
-    self._fine_mask_fc = tf.keras.layers.Dense(
+    self._fine_mask_fc = tf_keras.layers.Dense(
         self._num_downsample_channels, name='fine-mask-fc')
 
-    self._upsample_conv = tf.keras.layers.Conv2DTranspose(
+    self._upsample_conv = tf_keras.layers.Conv2DTranspose(
         self._num_downsample_channels,
         (self.up_sample_factor, self.up_sample_factor),
         (self.up_sample_factor, self.up_sample_factor),
         name='fine-mask-conv2d-tran')
 
     self._fine_class_conv = []
     self._fine_class_bn = []
     for i in range(self._num_convs):
       self._fine_class_conv.append(
-          tf.keras.layers.Conv2D(
+          tf_keras.layers.Conv2D(
               self._num_downsample_channels,
               kernel_size=(3, 3),
               bias_initializer=tf.zeros_initializer(),
-              kernel_initializer=tf.keras.initializers.RandomNormal(
+              kernel_initializer=tf_keras.initializers.RandomNormal(
                   stddev=0.01),
               activation=None,
               padding='same',
               name='fine-mask-class-%d' % i))
       self._fine_class_bn.append(
           norm_activation(name='fine-mask-class-%d-bn' % i))
 
-    self._class_predict_conv = tf.keras.layers.Conv2D(
+    self._class_predict_conv = tf_keras.layers.Conv2D(
         self._mask_num_classes,
         kernel_size=(1, 1),
         # Focal loss bias initialization to have foreground 0.01 probability.
         bias_initializer=tf.constant_initializer(-np.log((1 - 0.01) / 0.01)),
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
         padding='same',
         name='fine-mask-class-predict')
 
   def __call__(self, features, mask_logits, classes, is_training):
     """Generate instance masks from FPN features and detection priors.
 
     This corresponds to the Fig. 5-6 of the ShapeMask paper at
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/identity.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/identity.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/nn_blocks.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/nn_blocks.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,20 +14,20 @@
 
 """Contains common building blocks for neural networks."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
-class ResidualBlock(tf.keras.layers.Layer):
+class ResidualBlock(tf_keras.layers.Layer):
   """A residual block."""
 
   def __init__(self,
                filters,
                strides,
                use_projection=False,
                kernel_initializer='VarianceScaling',
@@ -46,17 +46,17 @@
       strides: `int` block stride. If greater than 1, this block will ultimately
         downsample the input.
       use_projection: `bool` for whether this block should use a projection
         shortcut (versus the default identity shortcut). This is usually `True`
         for the first block of a block group, which may change the number of
         filters and the resolution.
       kernel_initializer: kernel_initializer for convolutional layers.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
+      kernel_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
         Default to None.
-      bias_regularizer: tf.keras.regularizers.Regularizer object for Conv2d.
+      bias_regularizer: tf_keras.regularizers.Regularizer object for Conv2d.
         Default to None.
       activation: `str` name of the activation function.
       use_sync_bn: if True, use synchronized batch normalization.
       norm_momentum: `float` normalization omentum for the moving average.
       norm_epsilon: `float` small float added to variance to avoid dividing by
         zero.
       **kwargs: keyword arguments to be passed.
@@ -71,53 +71,53 @@
     self._kernel_initializer = kernel_initializer
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
 
     if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
+      self._norm = tf_keras.layers.experimental.SyncBatchNormalization
     else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+      self._norm = tf_keras.layers.BatchNormalization
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation_fn = tf_utils.get_activation(activation)
 
   def build(self, input_shape):
     if self._use_projection:
-      self._shortcut = tf.keras.layers.Conv2D(
+      self._shortcut = tf_keras.layers.Conv2D(
           filters=self._filters,
           kernel_size=1,
           strides=self._strides,
           use_bias=False,
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)
       self._norm0 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
           epsilon=self._norm_epsilon)
 
-    self._conv1 = tf.keras.layers.Conv2D(
+    self._conv1 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=3,
         strides=self._strides,
         padding='same',
         use_bias=False,
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
         epsilon=self._norm_epsilon)
 
-    self._conv2 = tf.keras.layers.Conv2D(
+    self._conv2 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=3,
         strides=1,
         padding='same',
         use_bias=False,
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
@@ -158,15 +158,15 @@
 
     x = self._conv2(x)
     x = self._norm2(x)
 
     return self._activation_fn(x + shortcut)
 
 
-class BottleneckBlock(tf.keras.layers.Layer):
+class BottleneckBlock(tf_keras.layers.Layer):
   """A standard bottleneck block."""
 
   def __init__(self,
                filters,
                strides,
                use_projection=False,
                kernel_initializer='VarianceScaling',
@@ -185,17 +185,17 @@
       strides: `int` block stride. If greater than 1, this block will ultimately
         downsample the input.
       use_projection: `bool` for whether this block should use a projection
         shortcut (versus the default identity shortcut). This is usually `True`
         for the first block of a block group, which may change the number of
         filters and the resolution.
       kernel_initializer: kernel_initializer for convolutional layers.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
+      kernel_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
         Default to None.
-      bias_regularizer: tf.keras.regularizers.Regularizer object for Conv2d.
+      bias_regularizer: tf_keras.regularizers.Regularizer object for Conv2d.
         Default to None.
       activation: `str` name of the activation function.
       use_sync_bn: if True, use synchronized batch normalization.
       norm_momentum: `float` normalization omentum for the moving average.
       norm_epsilon: `float` small float added to variance to avoid dividing by
         zero.
       **kwargs: keyword arguments to be passed.
@@ -209,66 +209,66 @@
     self._activation = activation
     self._kernel_initializer = kernel_initializer
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
+      self._norm = tf_keras.layers.experimental.SyncBatchNormalization
     else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+      self._norm = tf_keras.layers.BatchNormalization
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation_fn = tf_utils.get_activation(activation)
 
   def build(self, input_shape):
     if self._use_projection:
-      self._shortcut = tf.keras.layers.Conv2D(
+      self._shortcut = tf_keras.layers.Conv2D(
           filters=self._filters * 4,
           kernel_size=1,
           strides=self._strides,
           use_bias=False,
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)
       self._norm0 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
           epsilon=self._norm_epsilon)
 
-    self._conv1 = tf.keras.layers.Conv2D(
+    self._conv1 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=1,
         strides=1,
         use_bias=False,
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
         epsilon=self._norm_epsilon)
 
-    self._conv2 = tf.keras.layers.Conv2D(
+    self._conv2 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=3,
         strides=self._strides,
         padding='same',
         use_bias=False,
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm2 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
         epsilon=self._norm_epsilon)
 
-    self._conv3 = tf.keras.layers.Conv2D(
+    self._conv3 = tf_keras.layers.Conv2D(
         filters=self._filters * 4,
         kernel_size=1,
         strides=1,
         use_bias=False,
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/nn_ops.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/nn_ops.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,18 +16,18 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-class NormActivation(tf.keras.layers.Layer):
+class NormActivation(tf_keras.layers.Layer):
   """Combined Normalization and Activation layers."""
 
   def __init__(self,
                momentum=0.997,
                epsilon=1e-4,
                trainable=True,
                init_zero=False,
@@ -50,18 +50,18 @@
       activation: 'string', the type of the activation layer. Currently support
         `relu` and `swish`.
       fused: `bool` fused option in batch normalziation.
       name: `str` name for the operation.
     """
     super(NormActivation, self).__init__(trainable=trainable)
     if init_zero:
-      gamma_initializer = tf.keras.initializers.Zeros()
+      gamma_initializer = tf_keras.initializers.Zeros()
     else:
-      gamma_initializer = tf.keras.initializers.Ones()
-    self._normalization_op = tf.keras.layers.BatchNormalization(
+      gamma_initializer = tf_keras.initializers.Ones()
+    self._normalization_op = tf_keras.layers.BatchNormalization(
         momentum=momentum,
         epsilon=epsilon,
         center=True,
         scale=True,
         trainable=trainable,
         fused=fused,
         gamma_initializer=gamma_initializer,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/resnet.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/resnet.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,15 +19,15 @@
     Deep Residual Learning for Image Recognition. arXiv:1512.03385
 """
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.detection.modeling.architecture import nn_ops
 
 
 # TODO(b/140112644): Refactor the code with Keras style, i.e. build and call.
 class Resnet(object):
   """Class to build ResNet family model."""
 
@@ -155,15 +155,15 @@
 
     Returns:
       A `Tensor` of shape `[batch, filters, height_out, width_out]`.
     """
     if strides > 1:
       inputs = self.fixed_padding(inputs, kernel_size)
 
-    return tf.keras.layers.Conv2D(
+    return tf_keras.layers.Conv2D(
         filters=filters,
         kernel_size=kernel_size,
         strides=strides,
         padding=('SAME' if strides == 1 else 'VALID'),
         use_bias=False,
         kernel_initializer=tf.initializers.VarianceScaling(),
         data_format=self._data_format)(
@@ -305,15 +305,15 @@
     def model(inputs, is_training=None):
       """Creation of the model graph."""
       inputs = self.conv2d_fixed_padding(
           inputs=inputs, filters=64, kernel_size=7, strides=2)
       inputs = tf.identity(inputs, 'initial_conv')
       inputs = self._norm_activation()(inputs, is_training=is_training)
 
-      inputs = tf.keras.layers.MaxPool2D(
+      inputs = tf_keras.layers.MaxPool2D(
           pool_size=3, strides=2, padding='SAME',
           data_format=self._data_format)(
               inputs)
       inputs = tf.identity(inputs, 'initial_max_pool')
 
       c2 = self.block_group(
           inputs=inputs,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/architecture/spinenet.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/architecture/spinenet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,19 +18,19 @@
 X. Du, T-Y. Lin, P. Jin, G. Ghiasi, M. Tan, Y. Cui, Q. V. Le, X. Song
 SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization
 https://arxiv.org/abs/1912.05027
 """
 import math
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.detection.modeling.architecture import nn_blocks
 from official.modeling import tf_utils
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 FILTER_SIZE_MAP = {
     1: 32,
     2: 64,
     3: 128,
     4: 256,
     5: 256,
@@ -107,22 +107,22 @@
   """Builds the list of BlockSpec objects for SpineNet."""
   if not block_specs:
     block_specs = SPINENET_BLOCK_SPECS
   logging.info('Building SpineNet block specs: %s', block_specs)
   return [BlockSpec(*b) for b in block_specs]
 
 
-class SpineNet(tf.keras.Model):
+class SpineNet(tf_keras.Model):
   """Class to build SpineNet models."""
 
   def __init__(self,
-               input_specs=tf.keras.layers.InputSpec(shape=[None, 640, 640, 3]),
+               input_specs=tf_keras.layers.InputSpec(shape=[None, 640, 640, 3]),
                min_level=3,
                max_level=7,
-               block_specs=build_block_specs(),
+               block_specs=None,
                endpoints_num_filters=256,
                resample_alpha=0.5,
                block_repeats=1,
                filter_size_scale=1.0,
                kernel_initializer='VarianceScaling',
                kernel_regularizer=None,
                bias_regularizer=None,
@@ -130,15 +130,17 @@
                use_sync_bn=False,
                norm_momentum=0.99,
                norm_epsilon=0.001,
                **kwargs):
     """SpineNet model."""
     self._min_level = min_level
     self._max_level = max_level
-    self._block_specs = block_specs
+    self._block_specs = (
+        build_block_specs() if block_specs is None else block_specs
+    )
     self._endpoints_num_filters = endpoints_num_filters
     self._resample_alpha = resample_alpha
     self._block_repeats = block_repeats
     self._filter_size_scale = filter_size_scale
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
@@ -155,21 +157,21 @@
     self._num_init_blocks = 2
 
     if use_sync_bn:
       self._norm = layers.experimental.SyncBatchNormalization
     else:
       self._norm = layers.BatchNormalization
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
 
     # Build SpineNet.
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
 
     net = self._build_stem(inputs=inputs)
     net = self._build_scale_permuted_network(
         net=net, input_width=input_specs.shape[1])
     net = self._build_endpoints(net=net)
 
     super(SpineNet, self).__init__(inputs=inputs, outputs=net)
@@ -447,33 +449,33 @@
 
 
 class SpineNetBuilder(object):
   """SpineNet builder."""
 
   def __init__(self,
                model_id,
-               input_specs=tf.keras.layers.InputSpec(shape=[None, 640, 640, 3]),
+               input_specs=tf_keras.layers.InputSpec(shape=[None, 640, 640, 3]),
                min_level=3,
                max_level=7,
-               block_specs=build_block_specs(),
+               block_specs=None,
                kernel_initializer='VarianceScaling',
                kernel_regularizer=None,
                bias_regularizer=None,
                activation='relu',
                use_sync_bn=False,
                norm_momentum=0.99,
                norm_epsilon=0.001):
     if model_id not in SCALING_MAP:
       raise ValueError(
           'SpineNet {} is not a valid architecture.'.format(model_id))
     scaling_params = SCALING_MAP[model_id]
     self._input_specs = input_specs
     self._min_level = min_level
     self._max_level = max_level
-    self._block_specs = block_specs
+    self._block_specs = block_specs or build_block_specs()
     self._endpoints_num_filters = scaling_params['endpoints_num_filters']
     self._resample_alpha = scaling_params['resample_alpha']
     self._block_repeats = scaling_params['block_repeats']
     self._filter_size_scale = scaling_params['filter_size_scale']
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/base_model.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/base_model.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import abc
 import re
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.detection.modeling import checkpoint_utils
 from official.legacy.detection.modeling import learning_rates
 from official.legacy.detection.modeling import optimizers
 
 
 def _make_filter_trainable_variables_fn(frozen_variable_prefix):
   """Creates a function for filtering trainable varialbes."""
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/checkpoint_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/checkpoint_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,29 +22,29 @@
 from __future__ import division
 from __future__ import print_function
 
 import re
 
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _build_assignment_map(keras_model,
                           prefix='',
                           skip_variables_regex=None,
                           var_to_shape_map=None):
   """Builds the variable assignment map.
 
   Compute an assignment mapping for loading older checkpoints into a Keras
   model. Variable names are remapped from the original TPUEstimator model to
   the new Keras name.
 
   Args:
-    keras_model: tf.keras.Model object to provide variables to assign.
+    keras_model: tf_keras.Model object to provide variables to assign.
     prefix: prefix in the variable name to be remove for alignment with names in
       the checkpoint.
     skip_variables_regex: regular expression to math the names of variables that
       do not need to be assign.
     var_to_shape_map: variable name to shape mapping from the checkpoint.
 
   Returns:
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/factory.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/factory.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/learning_rates.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/learning_rates.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,20 +15,20 @@
 """Learning rate schedule."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling.hyperparams import params_dict
 
 
 class StepLearningRateWithLinearWarmup(
-    tf.keras.optimizers.schedules.LearningRateSchedule):
+    tf_keras.optimizers.schedules.LearningRateSchedule):
   """Class to generate learning rate tensor."""
 
   def __init__(self, total_steps, params):
     """Creates the step learning rate tensor with linear warmup."""
     super(StepLearningRateWithLinearWarmup, self).__init__()
     self._total_steps = total_steps
     assert isinstance(params, (dict, params_dict.ParamsDict))
@@ -53,15 +53,15 @@
     return learning_rate
 
   def get_config(self):
     return {'_params': self._params.as_dict()}
 
 
 class CosineLearningRateWithLinearWarmup(
-    tf.keras.optimizers.schedules.LearningRateSchedule):
+    tf_keras.optimizers.schedules.LearningRateSchedule):
   """Class to generate learning rate tensor."""
 
   def __init__(self, total_steps, params):
     """Creates the cosine learning rate tensor with linear warmup."""
     super(CosineLearningRateWithLinearWarmup, self).__init__()
     self._total_steps = total_steps
     assert isinstance(params, (dict, params_dict.ParamsDict))
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/losses.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/losses.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Losses used for detection models."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def focal_loss(logits, targets, alpha, gamma, normalizer):
   """Compute the focal loss between `logits` and the golden `target` values.
 
   Focal loss = -(1-pt)^gamma * log(pt)
   where pt is the probability of being classified to the true class.
@@ -86,16 +86,16 @@
 
 
 class RpnScoreLoss(object):
   """Region Proposal Network score loss function."""
 
   def __init__(self, params):
     self._rpn_batch_size_per_im = params.rpn_batch_size_per_im
-    self._binary_crossentropy = tf.keras.losses.BinaryCrossentropy(
-        reduction=tf.keras.losses.Reduction.SUM, from_logits=True)
+    self._binary_crossentropy = tf_keras.losses.BinaryCrossentropy(
+        reduction=tf_keras.losses.Reduction.SUM, from_logits=True)
 
   def __call__(self, score_outputs, labels):
     """Computes total RPN detection loss.
 
     Computes total RPN detection loss including box and score from all levels.
 
     Args:
@@ -149,16 +149,16 @@
   """Region Proposal Network box regression loss function."""
 
   def __init__(self, params):
     logging.info('RpnBoxLoss huber_loss_delta %s', params.huber_loss_delta)
     # The delta is typically around the mean value of regression target.
     # for instances, the regression targets of 512x512 input with 6 anchors on
     # P2-P6 pyramid is about [0.1, 0.1, 0.2, 0.2].
-    self._huber_loss = tf.keras.losses.Huber(
-        delta=params.huber_loss_delta, reduction=tf.keras.losses.Reduction.SUM)
+    self._huber_loss = tf_keras.losses.Huber(
+        delta=params.huber_loss_delta, reduction=tf_keras.losses.Reduction.SUM)
 
   def __call__(self, box_outputs, labels):
     """Computes total RPN detection loss.
 
     Computes total RPN detection loss including box and score from all levels.
 
     Args:
@@ -195,16 +195,16 @@
       return box_loss
 
 
 class OlnRpnCenterLoss(object):
   """Object Localization Network RPN centerness regression loss function."""
 
   def __init__(self):
-    self._l1_loss = tf.keras.losses.MeanAbsoluteError(
-        reduction=tf.keras.losses.Reduction.SUM)
+    self._l1_loss = tf_keras.losses.MeanAbsoluteError(
+        reduction=tf_keras.losses.Reduction.SUM)
 
   def __call__(self, center_outputs, labels):
     """Computes total RPN centerness regression loss.
 
     Computes total RPN centerness score regression loss from all levels.
 
     Args:
@@ -338,16 +338,16 @@
       return iou_loss
 
 
 class FastrcnnClassLoss(object):
   """Fast R-CNN classification loss function."""
 
   def __init__(self):
-    self._categorical_crossentropy = tf.keras.losses.CategoricalCrossentropy(
-        reduction=tf.keras.losses.Reduction.SUM, from_logits=True)
+    self._categorical_crossentropy = tf_keras.losses.CategoricalCrossentropy(
+        reduction=tf_keras.losses.Reduction.SUM, from_logits=True)
 
   def __call__(self, class_outputs, class_targets):
     """Computes the class loss (Fast-RCNN branch) of Mask-RCNN.
 
     This function implements the classification loss of the Fast-RCNN.
 
     The classification loss is softmax on all RoIs.
@@ -384,16 +384,16 @@
   """Fast R-CNN box regression loss function."""
 
   def __init__(self, params):
     logging.info('FastrcnnBoxLoss huber_loss_delta %s', params.huber_loss_delta)
     # The delta is typically around the mean value of regression target.
     # for instances, the regression targets of 512x512 input with 6 anchors on
     # P2-P6 pyramid is about [0.1, 0.1, 0.2, 0.2].
-    self._huber_loss = tf.keras.losses.Huber(
-        delta=params.huber_loss_delta, reduction=tf.keras.losses.Reduction.SUM)
+    self._huber_loss = tf_keras.losses.Huber(
+        delta=params.huber_loss_delta, reduction=tf_keras.losses.Reduction.SUM)
 
   def __call__(self, box_outputs, class_targets, box_targets):
     """Computes the box loss (Fast-RCNN branch) of Mask-RCNN.
 
     This function implements the box regression loss of the Fast-RCNN. As the
     `box_outputs` produces `num_classes` boxes for each RoI, the reference model
     expands `box_targets` to match the shape of `box_outputs` and selects only
@@ -461,16 +461,16 @@
 
 
 class OlnBoxScoreLoss(object):
   """Object Localization Network Box-Iou scoring function."""
 
   def __init__(self, params):
     self._ignore_threshold = params.ignore_threshold
-    self._l1_loss = tf.keras.losses.MeanAbsoluteError(
-        reduction=tf.keras.losses.Reduction.SUM)
+    self._l1_loss = tf_keras.losses.MeanAbsoluteError(
+        reduction=tf_keras.losses.Reduction.SUM)
 
   def __call__(self, score_outputs, score_targets):
     """Computes the class loss (Fast-RCNN branch) of Mask-RCNN.
 
     This function implements the classification loss of the Fast-RCNN.
 
     The classification loss is softmax on all RoIs.
@@ -501,16 +501,16 @@
       return score_loss
 
 
 class MaskrcnnLoss(object):
   """Mask R-CNN instance segmentation mask loss function."""
 
   def __init__(self):
-    self._binary_crossentropy = tf.keras.losses.BinaryCrossentropy(
-        reduction=tf.keras.losses.Reduction.SUM, from_logits=True)
+    self._binary_crossentropy = tf_keras.losses.BinaryCrossentropy(
+        reduction=tf_keras.losses.Reduction.SUM, from_logits=True)
 
   def __call__(self, mask_outputs, mask_targets, select_class_targets):
     """Computes the mask loss of Mask-RCNN.
 
     This function implements the mask loss of Mask-RCNN. As the `mask_outputs`
     produces `num_classes` masks for each RoI, the reference model expands
     `mask_targets` to match the shape of `mask_outputs` and selects only the
@@ -612,16 +612,16 @@
     return tf.reduce_sum(input_tensor=ignore_loss * loss)
 
 
 class RetinanetBoxLoss(object):
   """RetinaNet box loss."""
 
   def __init__(self, params):
-    self._huber_loss = tf.keras.losses.Huber(
-        delta=params.huber_loss_delta, reduction=tf.keras.losses.Reduction.SUM)
+    self._huber_loss = tf_keras.losses.Huber(
+        delta=params.huber_loss_delta, reduction=tf_keras.losses.Reduction.SUM)
 
   def __call__(self, box_outputs, labels, num_positives):
     """Computes box detection loss.
 
     Computes total detection loss including box and class loss from all levels.
 
     Args:
@@ -691,16 +691,16 @@
     return loss
 
 
 class ShapemaskLoss(object):
   """ShapeMask mask loss function wrapper."""
 
   def __init__(self):
-    self._binary_crossentropy = tf.keras.losses.BinaryCrossentropy(
-        reduction=tf.keras.losses.Reduction.SUM, from_logits=True)
+    self._binary_crossentropy = tf_keras.losses.BinaryCrossentropy(
+        reduction=tf_keras.losses.Reduction.SUM, from_logits=True)
 
   def __call__(self, logits, labels, valid_mask):
     """ShapeMask mask cross entropy loss function wrapper.
 
     Args:
       logits: A Tensor of shape [batch_size * num_instances, height, width,
         num_classes]. The logits are not necessarily between 0 and 1.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/maskrcnn_model.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/maskrcnn_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Model defination for the Mask R-CNN Model."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import anchor
 from official.legacy.detection.dataloader import mode_keys
 from official.legacy.detection.evaluation import factory as eval_factory
 from official.legacy.detection.modeling import base_model
 from official.legacy.detection.modeling import losses
 from official.legacy.detection.modeling.architecture import factory
@@ -235,72 +235,72 @@
     input_shape = (
         params.maskrcnn_parser.output_size +
         [params.maskrcnn_parser.num_channels])
     if is_training:
       batch_size = params.train.batch_size
       input_layer = {
           'image':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=input_shape,
                   batch_size=batch_size,
                   name='image',
                   dtype=tf.bfloat16 if self._use_bfloat16 else tf.float32),
           'image_info':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[4, 2],
                   batch_size=batch_size,
                   name='image_info',
               ),
           'gt_boxes':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[params.maskrcnn_parser.max_num_instances, 4],
                   batch_size=batch_size,
                   name='gt_boxes'),
           'gt_classes':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[params.maskrcnn_parser.max_num_instances],
                   batch_size=batch_size,
                   name='gt_classes',
                   dtype=tf.int64),
       }
       if self._include_mask:
-        input_layer['gt_masks'] = tf.keras.layers.Input(
+        input_layer['gt_masks'] = tf_keras.layers.Input(
             shape=[
                 params.maskrcnn_parser.max_num_instances,
                 params.maskrcnn_parser.mask_crop_size,
                 params.maskrcnn_parser.mask_crop_size
             ],
             batch_size=batch_size,
             name='gt_masks')
     else:
       batch_size = params.eval.batch_size
       input_layer = {
           'image':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=input_shape,
                   batch_size=batch_size,
                   name='image',
                   dtype=tf.bfloat16 if self._use_bfloat16 else tf.float32),
           'image_info':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[4, 2],
                   batch_size=batch_size,
                   name='image_info',
               ),
       }
     return input_layer
 
   def build_model(self, params, mode):
     if self._keras_model is None:
       input_layers = self.build_input_layers(self._params, mode)
       outputs = self.model_outputs(input_layers, mode)
 
-      model = tf.keras.models.Model(
+      model = tf_keras.models.Model(
           inputs=input_layers, outputs=outputs, name='maskrcnn')
-      assert model is not None, 'Fail to build tf.keras.Model.'
+      assert model is not None, 'Fail to build tf_keras.Model.'
       model.optimizer = self.build_optimizer()
       self._keras_model = model
 
     return self._keras_model
 
   def post_processing(self, labels, outputs):
     required_output_fields = ['class_outputs', 'box_outputs']
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/olnmask_model.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/olnmask_model.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Model defination for the Object Localization Network (OLN) Model."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import anchor
 from official.legacy.detection.dataloader import mode_keys
 from official.legacy.detection.modeling import losses
 from official.legacy.detection.modeling.architecture import factory
 from official.legacy.detection.modeling.maskrcnn_model import MaskrcnnModel
 from official.legacy.detection.ops import postprocess_ops
@@ -364,69 +364,69 @@
     input_shape = (
         params.olnmask_parser.output_size +
         [params.olnmask_parser.num_channels])
     if is_training:
       batch_size = params.train.batch_size
       input_layer = {
           'image':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=input_shape,
                   batch_size=batch_size,
                   name='image',
                   dtype=tf.bfloat16 if self._use_bfloat16 else tf.float32),
           'image_info':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[4, 2],
                   batch_size=batch_size,
                   name='image_info',
               ),
           'gt_boxes':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[params.olnmask_parser.max_num_instances, 4],
                   batch_size=batch_size,
                   name='gt_boxes'),
           'gt_classes':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[params.olnmask_parser.max_num_instances],
                   batch_size=batch_size,
                   name='gt_classes',
                   dtype=tf.int64),
       }
       if self._include_mask:
-        input_layer['gt_masks'] = tf.keras.layers.Input(
+        input_layer['gt_masks'] = tf_keras.layers.Input(
             shape=[
                 params.olnmask_parser.max_num_instances,
                 params.olnmask_parser.mask_crop_size,
                 params.olnmask_parser.mask_crop_size
             ],
             batch_size=batch_size,
             name='gt_masks')
     else:
       batch_size = params.eval.batch_size
       input_layer = {
           'image':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=input_shape,
                   batch_size=batch_size,
                   name='image',
                   dtype=tf.bfloat16 if self._use_bfloat16 else tf.float32),
           'image_info':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[4, 2],
                   batch_size=batch_size,
                   name='image_info',
               ),
       }
     return input_layer
 
   def build_model(self, params, mode):
     if self._keras_model is None:
       input_layers = self.build_input_layers(self._params, mode)
       outputs = self.model_outputs(input_layers, mode)
 
-      model = tf.keras.models.Model(
+      model = tf_keras.models.Model(
           inputs=input_layers, outputs=outputs, name='olnmask')
-      assert model is not None, 'Fail to build tf.keras.Model.'
+      assert model is not None, 'Fail to build tf_keras.Model.'
       model.optimizer = self.build_optimizer()
       self._keras_model = model
 
     return self._keras_model
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/optimizers.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/optimizers.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,34 +16,34 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class OptimizerFactory(object):
   """Class to generate optimizer function."""
 
   def __init__(self, params):
     """Creates optimized based on the specified flags."""
     if params.type == 'momentum':
       self._optimizer = functools.partial(
-          tf.keras.optimizers.SGD,
+          tf_keras.optimizers.SGD,
           momentum=params.momentum,
           nesterov=params.nesterov)
     elif params.type == 'adam':
-      self._optimizer = tf.keras.optimizers.Adam
+      self._optimizer = tf_keras.optimizers.Adam
     elif params.type == 'adadelta':
-      self._optimizer = tf.keras.optimizers.Adadelta
+      self._optimizer = tf_keras.optimizers.Adadelta
     elif params.type == 'adagrad':
-      self._optimizer = tf.keras.optimizers.Adagrad
+      self._optimizer = tf_keras.optimizers.Adagrad
     elif params.type == 'rmsprop':
       self._optimizer = functools.partial(
-          tf.keras.optimizers.RMSprop, momentum=params.momentum)
+          tf_keras.optimizers.RMSprop, momentum=params.momentum)
     else:
       raise ValueError('Unsupported optimizer type `{}`.'.format(params.type))
 
   def __call__(self, learning_rate):
     return self._optimizer(learning_rate=learning_rate)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/retinanet_model.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/retinanet_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Model defination for the RetinaNet Model."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import mode_keys
 from official.legacy.detection.evaluation import factory as eval_factory
 from official.legacy.detection.modeling import base_model
 from official.legacy.detection.modeling import losses
 from official.legacy.detection.modeling.architecture import factory
 from official.legacy.detection.ops import postprocess_ops
@@ -53,15 +53,15 @@
     self._generate_detections_fn = postprocess_ops.MultilevelDetectionGenerator(
         params.architecture.min_level, params.architecture.max_level,
         params.postprocess)
 
     self._transpose_input = params.train.transpose_input
     assert not self._transpose_input, 'Transpose input is not supported.'
     # Input layer.
-    self._input_layer = tf.keras.layers.Input(
+    self._input_layer = tf_keras.layers.Input(
         shape=(None, None, params.retinanet_parser.num_channels),
         name='',
         dtype=tf.bfloat16 if self._use_bfloat16 else tf.float32)
 
   def build_outputs(self, inputs, mode):
     # If the input image is transposed (from NHWC to HWCN), we need to revert it
     # back to the original shape before it's used in the computation.
@@ -114,17 +114,17 @@
 
     return _total_loss_fn
 
   def build_model(self, params, mode=None):
     if self._keras_model is None:
       outputs = self.model_outputs(self._input_layer, mode)
 
-      model = tf.keras.models.Model(
+      model = tf_keras.models.Model(
           inputs=self._input_layer, outputs=outputs, name='retinanet')
-      assert model is not None, 'Fail to build tf.keras.Model.'
+      assert model is not None, 'Fail to build tf_keras.Model.'
       model.optimizer = self.build_optimizer()
       self._keras_model = model
 
     return self._keras_model
 
   def post_processing(self, labels, outputs):
     # TODO(yeqing): Moves the output related part into build_outputs.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/modeling/shapemask_model.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/modeling/shapemask_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Model definition for the ShapeMask Model."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.dataloader import anchor
 from official.legacy.detection.dataloader import mode_keys
 from official.legacy.detection.evaluation import factory as eval_factory
 from official.legacy.detection.modeling import base_model
 from official.legacy.detection.modeling import losses
 from official.legacy.detection.modeling.architecture import factory
@@ -99,15 +99,15 @@
         tf.reshape(valid_boxes, [-1, 4]),
         image_size,
         scale=self._params.shapemask_parser.outer_box_scale)
     valid_outer_boxes = tf.reshape(valid_outer_boxes, tf.shape(valid_boxes))
 
     # Wrapping if else code paths into a layer to make the checkpoint loadable
     # in prediction mode.
-    class SampledBoxesLayer(tf.keras.layers.Layer):
+    class SampledBoxesLayer(tf_keras.layers.Layer):
       """ShapeMask model function."""
 
       def call(self, inputs, val_boxes, val_classes, val_outer_boxes, training):
         if training:
           boxes = inputs['mask_boxes']
           outer_boxes = inputs['mask_outer_boxes']
           classes = inputs['mask_classes']
@@ -206,64 +206,64 @@
     input_shape = (
         params.shapemask_parser.output_size +
         [params.shapemask_parser.num_channels])
     if is_training:
       batch_size = params.train.batch_size
       input_layer = {
           'image':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=input_shape,
                   batch_size=batch_size,
                   name='image',
                   dtype=tf.bfloat16 if self._use_bfloat16 else tf.float32),
           'image_info':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[4, 2], batch_size=batch_size, name='image_info'),
           'mask_classes':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[params.shapemask_parser.num_sampled_masks],
                   batch_size=batch_size,
                   name='mask_classes',
                   dtype=tf.int64),
           'mask_outer_boxes':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[params.shapemask_parser.num_sampled_masks, 4],
                   batch_size=batch_size,
                   name='mask_outer_boxes',
                   dtype=tf.float32),
           'mask_boxes':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[params.shapemask_parser.num_sampled_masks, 4],
                   batch_size=batch_size,
                   name='mask_boxes',
                   dtype=tf.float32),
       }
     else:
       batch_size = params.eval.batch_size
       input_layer = {
           'image':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=input_shape,
                   batch_size=batch_size,
                   name='image',
                   dtype=tf.bfloat16 if self._use_bfloat16 else tf.float32),
           'image_info':
-              tf.keras.layers.Input(
+              tf_keras.layers.Input(
                   shape=[4, 2], batch_size=batch_size, name='image_info'),
       }
     return input_layer
 
   def build_model(self, params, mode):
     if self._keras_model is None:
       input_layers = self.build_input_layers(self._params, mode)
       outputs = self.model_outputs(input_layers, mode)
 
-      model = tf.keras.models.Model(
+      model = tf_keras.models.Model(
           inputs=input_layers, outputs=outputs, name='shapemask')
-      assert model is not None, 'Fail to build tf.keras.Model.'
+      assert model is not None, 'Fail to build tf_keras.Model.'
       model.optimizer = self.build_optimizer()
       self._keras_model = model
 
     return self._keras_model
 
   def post_processing(self, labels, outputs):
     required_output_fields = [
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/ops/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/ops/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/ops/nms.py` & `tf-models-no-deps-2.16.0/official/vision/ops/nms.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,21 +10,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tensorflow implementation of non max suppression."""
 
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
+# Import libraries
+import tensorflow as tf, tf_keras
 
-import tensorflow as tf
+from official.vision.ops import box_ops
 
-from official.legacy.detection.utils import box_utils
 
 NMS_TILE_SIZE = 512
 
 
 def _self_suppression(iou, _, iou_sum):
   batch_size = tf.shape(iou)[0]
   can_suppress_others = tf.cast(
@@ -39,15 +37,15 @@
   ]
 
 
 def _cross_suppression(boxes, box_slice, iou_threshold, inner_idx):
   batch_size = tf.shape(boxes)[0]
   new_slice = tf.slice(boxes, [0, inner_idx * NMS_TILE_SIZE, 0],
                        [batch_size, NMS_TILE_SIZE, 4])
-  iou = box_utils.bbox_overlap(new_slice, box_slice)
+  iou = box_ops.bbox_overlap(new_slice, box_slice)
   ret_slice = tf.expand_dims(
       tf.cast(tf.reduce_all(iou < iou_threshold, [1]), box_slice.dtype),
       2) * box_slice
   return boxes, ret_slice, iou_threshold, inner_idx + 1
 
 
 def _suppression_loop_body(boxes, iou_threshold, output_size, idx):
@@ -63,27 +61,28 @@
 
   Returns:
     boxes: updated boxes.
     iou_threshold: pass down iou_threshold to the next iteration.
     output_size: the updated output_size.
     idx: the updated induction variable.
   """
-  num_tiles = tf.shape(boxes)[1] // NMS_TILE_SIZE
-  batch_size = tf.shape(boxes)[0]
+  boxes_shape = tf.shape(boxes)
+  num_tiles = boxes_shape[1] // NMS_TILE_SIZE
+  batch_size = boxes_shape[0]
 
   # Iterates over tiles that can possibly suppress the current tile.
   box_slice = tf.slice(boxes, [0, idx * NMS_TILE_SIZE, 0],
                        [batch_size, NMS_TILE_SIZE, 4])
   _, box_slice, _, _ = tf.while_loop(
       lambda _boxes, _box_slice, _threshold, inner_idx: inner_idx < idx,
       _cross_suppression, [boxes, box_slice, iou_threshold,
                            tf.constant(0)])
 
   # Iterates over the current tile to compute self-suppression.
-  iou = box_utils.bbox_overlap(box_slice, box_slice)
+  iou = box_ops.bbox_overlap(box_slice, box_slice)
   mask = tf.expand_dims(
       tf.reshape(tf.range(NMS_TILE_SIZE), [1, -1]) > tf.reshape(
           tf.range(NMS_TILE_SIZE), [-1, 1]), 0)
   iou *= tf.cast(tf.logical_and(mask, iou >= iou_threshold), iou.dtype)
   suppressed_iou, _, _ = tf.while_loop(
       lambda _iou, loop_condition, _iou_sum: loop_condition, _self_suppression,
       [iou, tf.constant(True),
@@ -93,23 +92,25 @@
 
   # Uses box_slice to update the input boxes.
   mask = tf.reshape(
       tf.cast(tf.equal(tf.range(num_tiles), idx), boxes.dtype), [1, -1, 1, 1])
   boxes = tf.tile(tf.expand_dims(
       box_slice, [1]), [1, num_tiles, 1, 1]) * mask + tf.reshape(
           boxes, [batch_size, num_tiles, NMS_TILE_SIZE, 4]) * (1 - mask)
-  boxes = tf.reshape(boxes, [batch_size, -1, 4])
+  boxes = tf.reshape(boxes, boxes_shape)
 
   # Updates output_size.
   output_size += tf.reduce_sum(
       tf.cast(tf.reduce_any(box_slice > 0, [2]), tf.int32), [1])
   return boxes, iou_threshold, output_size, idx + 1
 
 
-def sorted_non_max_suppression_padded(scores, boxes, max_output_size,
+def sorted_non_max_suppression_padded(scores,
+                                      boxes,
+                                      max_output_size,
                                       iou_threshold):
   """A wrapper that handles non-maximum suppression.
 
   Assumption:
     * The boxes are sorted by scores unless the box is a dot (all coordinates
       are zero).
     * Boxes with higher scores can be used to suppress boxes with lower scores.
@@ -170,26 +171,27 @@
 
   def _loop_cond(unused_boxes, unused_threshold, output_size, idx):
     return tf.logical_and(
         tf.reduce_min(output_size) < max_output_size,
         idx < num_boxes // NMS_TILE_SIZE)
 
   selected_boxes, _, output_size, _ = tf.while_loop(
-      _loop_cond, _suppression_loop_body,
-      [boxes, iou_threshold,
-       tf.zeros([batch_size], tf.int32),
-       tf.constant(0)])
+      _loop_cond, _suppression_loop_body, [
+          boxes, iou_threshold,
+          tf.zeros([batch_size], tf.int32),
+          tf.constant(0)
+      ])
   idx = num_boxes - tf.cast(
       tf.nn.top_k(
           tf.cast(tf.reduce_any(selected_boxes > 0, [2]), tf.int32) *
           tf.expand_dims(tf.range(num_boxes, 0, -1), 0), max_output_size)[0],
       tf.int32)
   idx = tf.minimum(idx, num_boxes - 1)
-  idx = tf.reshape(idx + tf.reshape(tf.range(batch_size) * num_boxes, [-1, 1]),
-                   [-1])
+  idx = tf.reshape(
+      idx + tf.reshape(tf.range(batch_size) * num_boxes, [-1, 1]), [-1])
   boxes = tf.reshape(
       tf.gather(tf.reshape(boxes, [-1, 4]), idx),
       [batch_size, max_output_size, 4])
   boxes = boxes * tf.cast(
       tf.reshape(tf.range(max_output_size), [1, -1, 1]) < tf.reshape(
           output_size, [-1, 1, 1]), boxes.dtype)
   scores = tf.reshape(
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/ops/postprocess_ops.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/ops/postprocess_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.ops import nms
 from official.legacy.detection.utils import box_utils
 
 
 def generate_detections_factory(params):
   """Factory to select function to generate detection."""
@@ -287,15 +287,15 @@
      )
     # De-normalizes box cooridinates.
     nmsed_boxes *= normalizer
   nmsed_classes = tf.cast(nmsed_classes, tf.int32)
   return nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections
 
 
-class MultilevelDetectionGenerator(tf.keras.layers.Layer):
+class MultilevelDetectionGenerator(tf_keras.layers.Layer):
   """Generates detected boxes with scores and classes for one-stage detector."""
 
   def __init__(self, min_level, max_level, params):
     self._min_level = min_level
     self._max_level = max_level
     self._generate_detections = generate_detections_factory(params)
     super(MultilevelDetectionGenerator, self).__init__(autocast=False)
@@ -334,15 +334,15 @@
         self._generate_detections(tf.expand_dims(boxes, axis=2), scores))
 
     # Adds 1 to offset the background class which has index 0.
     nmsed_classes += 1
     return nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections
 
 
-class GenericDetectionGenerator(tf.keras.layers.Layer):
+class GenericDetectionGenerator(tf_keras.layers.Layer):
   """Generates the final detected boxes with scores and classes."""
 
   def __init__(self, params):
     super(GenericDetectionGenerator, self).__init__(autocast=False)
     self._generate_detections = generate_detections_factory(params)
 
   def call(self, box_outputs, class_outputs, anchor_boxes, image_shape):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/ops/roi_ops.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/ops/roi_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """ROI-related ops."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.ops import nms
 from official.legacy.detection.utils import box_utils
 
 
 def multilevel_propose_rois(rpn_boxes,
                             rpn_scores,
@@ -166,15 +166,15 @@
 
       selected_rois, selected_roi_scores = box_utils.top_k_boxes(
           all_rois, all_roi_scores, k=overall_top_k)
 
     return selected_rois, selected_roi_scores
 
 
-class ROIGenerator(tf.keras.layers.Layer):
+class ROIGenerator(tf_keras.layers.Layer):
   """Proposes RoIs for the second stage processing."""
 
   def __init__(self, params):
     self._rpn_pre_nms_top_k = params.rpn_pre_nms_top_k
     self._rpn_post_nms_top_k = params.rpn_post_nms_top_k
     self._rpn_nms_threshold = params.rpn_nms_threshold
     self._rpn_score_threshold = params.rpn_score_threshold
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/ops/spatial_transform_ops.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/ops/spatial_transform_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Functions to performa spatial transformation for Tensor."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 _EPSILON = 1e-8
 
 
 def nearest_upsampling(data, scale):
   """Nearest neighbor upsampling implementation.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/ops/target_ops.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/ops/target_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Target and sampling related ops."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.ops import spatial_transform_ops
 from official.legacy.detection.utils import box_utils
 from official.vision.utils.object_detection import balanced_positive_negative_sampler
 
 
 def box_matching(boxes, gt_boxes, gt_classes):
@@ -288,15 +288,15 @@
         foreground_rois,
         mask_target_size,
         sample_offset=0.5)
 
     return foreground_rois, foreground_classes, cropped_foreground_masks
 
 
-class ROISampler(tf.keras.layers.Layer):
+class ROISampler(tf_keras.layers.Layer):
   """Samples RoIs and creates training targets."""
 
   def __init__(self, params):
     self._num_samples_per_image = params.num_samples_per_image
     self._fg_fraction = params.fg_fraction
     self._fg_iou_thresh = params.fg_iou_thresh
     self._bg_iou_thresh_hi = params.bg_iou_thresh_hi
@@ -513,15 +513,15 @@
       sampled_gt_classes = tf.gather_nd(matched_gt_classes, gather_nd_indices)
       sampled_gt_indices = tf.gather_nd(matched_gt_indices, gather_nd_indices)
 
       return (sampled_rois, sampled_roi_scores, sampled_gt_boxes,
               sampled_gt_classes, sampled_gt_indices)
 
 
-class MaskSampler(tf.keras.layers.Layer):
+class MaskSampler(tf_keras.layers.Layer):
   """Samples and creates mask training targets."""
 
   def __init__(self, mask_target_size, num_mask_samples_per_image):
     self._mask_target_size = mask_target_size
     self._num_mask_samples_per_image = num_mask_samples_per_image
     super(MaskSampler, self).__init__(autocast=False)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/utils/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/utils/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/utils/box_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/utils/box_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Utility functions for bounding box processing."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 EPSILON = 1e-8
 BBOX_XFORM_CLIP = np.log(1000. / 16.)
 
 
 def visualize_images_with_bounding_boxes(images, box_outputs, step,
                                          summary_writer):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/utils/class_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/utils/class_utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/utils/dataloader_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/utils/dataloader_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Utility functions for dataloader."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.utils import input_utils
 
 
 def process_source_id(source_id):
   """Processes source_id to the right format."""
   if source_id.dtype == tf.string:
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/utils/input_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/utils/input_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Utility functions for input processing."""
 
 import math
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.detection.utils import box_utils
 from official.vision.utils.object_detection import preprocessor
 
 
 def pad_to_fixed_size(input_tensor, size, constant_values=0):
   """Pads data to a fixed length at the first dimension.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/detection/utils/mask_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/utils/mask_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,16 +15,16 @@
 """Utility functions for segmentations."""
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import math
 
-import numpy as np
 import cv2
+import numpy as np
 
 
 def paste_instance_masks(masks, detected_boxes, image_height, image_width):
   """Paste instance masks to generate the image segmentation results.
 
   Args:
     masks: a numpy array of shape [N, mask_height, mask_width] representing the
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/augment.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/augment.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,16 +21,15 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import math
 from typing import Any, Dict, List, Optional, Text, Tuple
 
-from keras.layers.preprocessing import image_preprocessing as image_ops
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 # This signifies the max integer that the controller RNN could predict for the
 # augmentation scheme.
 _MAX_LEVEL = 10.
 
 
@@ -159,38 +158,119 @@
           y_offset[:, None],
           tf.zeros((num_angles, 2), tf.dtypes.float32),
       ],
       axis=1,
   )
 
 
+def apply_transform_to_images(
+    images,
+    transforms,
+    fill_mode='reflect',
+    fill_value=0.0,
+    interpolation='bilinear',
+    output_shape=None,
+    name=None,
+):
+  """Applies the given transform(s) to the image(s).
+
+  Args:
+    images: A tensor of shape `(num_images, num_rows, num_columns,
+      num_channels)` (NHWC). The rank must be statically known (the shape is
+      not `TensorShape(None)`).
+    transforms: Projective transform matrix/matrices. A vector of length 8 or
+      tensor of size N x 8. If one row of transforms is [a0, a1, a2, b0, b1,
+      b2, c0, c1], then it maps the *output* point `(x, y)` to a transformed
+      *input* point `(x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) /
+      k)`, where `k = c0 x + c1 y + 1`. The transforms are *inverted* compared
+      to the transform mapping input points to output points. Note that
+      gradients are not backpropagated into transformation parameters.
+    fill_mode: Points outside the boundaries of the input are filled according
+      to the given mode (one of `{"constant", "reflect", "wrap", "nearest"}`).
+    fill_value: a float represents the value to be filled outside the
+      boundaries when `fill_mode="constant"`.
+    interpolation: Interpolation mode. Supported values: `"nearest"`,
+      `"bilinear"`.
+    output_shape: Output dimension after the transform, `[height, width]`. If
+      `None`, output is the same size as input image.
+    name: The name of the op.  Fill mode behavior for each valid value is as
+      follows
+      - `"reflect"`: `(d c b a | a b c d | d c b a)` The input is extended by
+      reflecting about the edge of the last pixel.
+      - `"constant"`: `(k k k k | a b c d | k k k k)` The input is extended by
+      filling all values beyond the edge with the same constant value k = 0.
+      - `"wrap"`: `(a b c d | a b c d | a b c d)` The input is extended by
+      wrapping around to the opposite edge.
+      - `"nearest"`: `(a a a a | a b c d | d d d d)` The input is extended by
+      the nearest pixel.  Input shape: 4D tensor with shape:
+      `(samples, height, width, channels)`, in `"channels_last"` format.
+      Output shape: 4D tensor with shape: `(samples, height, width, channels)`,
+      in `"channels_last"` format.
+
+  Returns:
+    Image(s) with the same type and shape as `images`, with the given
+    transform(s) applied. Transformed coordinates outside of the input image
+    will be filled with zeros.
+  """
+  with tf.name_scope(name or 'transform'):
+    if output_shape is None:
+      output_shape = tf.shape(images)[1:3]
+      if not tf.executing_eagerly():
+        output_shape_value = tf.get_static_value(output_shape)
+        if output_shape_value is not None:
+          output_shape = output_shape_value
+
+    output_shape = tf.convert_to_tensor(
+        output_shape, tf.int32, name='output_shape'
+    )
+
+    if not output_shape.get_shape().is_compatible_with([2]):
+      raise ValueError(
+          'output_shape must be a 1-D Tensor of 2 elements: '
+          'new_height, new_width, instead got '
+          f'output_shape={output_shape}'
+      )
+
+    fill_value = tf.convert_to_tensor(fill_value, tf.float32, name='fill_value')
+
+    return tf.raw_ops.ImageProjectiveTransformV3(
+        images=images,
+        output_shape=output_shape,
+        fill_value=fill_value,
+        transforms=transforms,
+        fill_mode=fill_mode.upper(),
+        interpolation=interpolation.upper(),
+    )
+
+
 def transform(image: tf.Tensor, transforms) -> tf.Tensor:
   """Prepares input data for `image_ops.transform`."""
   original_ndims = tf.rank(image)
   transforms = tf.convert_to_tensor(transforms, dtype=tf.float32)
   if transforms.shape.rank == 1:
     transforms = transforms[None]
   image = to_4d(image)
-  image = image_ops.transform(
-      images=image, transforms=transforms, interpolation='nearest')
+  image = apply_transform_to_images(
+      images=image, transforms=transforms, interpolation='nearest'
+  )
   return from_4d(image, original_ndims)
 
 
 def translate(image: tf.Tensor, translations) -> tf.Tensor:
   """Translates image(s) by provided vectors.
 
   Args:
     image: An image Tensor of type uint8.
     translations: A vector or matrix representing [dx dy].
 
   Returns:
     The translated version of the image.
 
   """
-  transforms = _convert_translation_to_transform(translations)
+  transforms = _convert_translation_to_transform(translations)  # pytype: disable=wrong-arg-types  # always-use-return-annotations
   return transform(image, transforms=transforms)
 
 
 def rotate(image: tf.Tensor, degrees: float) -> tf.Tensor:
   """Rotates the image by degrees either clockwise or counterclockwise.
 
   Args:
@@ -835,18 +915,14 @@
     (operation, probability, magnitude). Each element in policy is a
     sub-policy that will be applied sequentially on the image.
 
     Returns:
       the policy.
     """
 
-    # TODO(dankondratyuk): tensorflow_addons defines custom ops, which
-    # for some reason are not included when building/linking
-    # This results in the error, "Op type not registered
-    # 'Addons>ImageProjectiveTransformV2' in binary" when running on borg TPUs
     policy = [
         [('Equalize', 0.8, 1), ('ShearY', 0.8, 4)],
         [('Color', 0.4, 9), ('Equalize', 0.6, 3)],
         [('Color', 0.4, 1), ('Rotate', 0.6, 8)],
         [('Solarize', 0.8, 3), ('Equalize', 0.4, 7)],
         [('Solarize', 0.4, 2), ('Solarize', 0.6, 2)],
         [('Color', 0.2, 0), ('Equalize', 0.8, 8)],
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/augment_test.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/augment_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 from absl.testing import parameterized
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.image_classification import augment
 
 
 def get_dtype_test_cases():
   return [
       ('uint8', tf.uint8),
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/callbacks.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/callbacks.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 from __future__ import division
 from __future__ import print_function
 
 import os
 from typing import Any, List, MutableMapping, Optional, Text
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import optimization
 from official.utils.misc import keras_utils
 
 
 def get_callbacks(
     model_checkpoint: bool = True,
@@ -34,27 +34,27 @@
     track_lr: bool = True,
     write_model_weights: bool = True,
     apply_moving_average: bool = False,
     initial_step: int = 0,
     batch_size: int = 0,
     log_steps: int = 0,
     model_dir: Optional[str] = None,
-    backup_and_restore: bool = False) -> List[tf.keras.callbacks.Callback]:
+    backup_and_restore: bool = False) -> List[tf_keras.callbacks.Callback]:
   """Get all callbacks."""
   model_dir = model_dir or ''
   callbacks = []
   if model_checkpoint:
     ckpt_full_path = os.path.join(model_dir, 'model.ckpt-{epoch:04d}')
     callbacks.append(
-        tf.keras.callbacks.ModelCheckpoint(
+        tf_keras.callbacks.ModelCheckpoint(
             ckpt_full_path, save_weights_only=True, verbose=1))
   if backup_and_restore:
     backup_dir = os.path.join(model_dir, 'tmp')
     callbacks.append(
-        tf.keras.callbacks.experimental.BackupAndRestore(backup_dir))
+        tf_keras.callbacks.experimental.BackupAndRestore(backup_dir))
   if include_tensorboard:
     callbacks.append(
         CustomTensorBoard(
             log_dir=model_dir,
             track_lr=track_lr,
             initial_step=initial_step,
             write_images=write_model_weights,
@@ -78,22 +78,22 @@
             verbose=1))
     callbacks.append(MovingAverageCallback())
   return callbacks
 
 
 def get_scalar_from_tensor(t: tf.Tensor) -> int:
   """Utility function to convert a Tensor to a scalar."""
-  t = tf.keras.backend.get_value(t)
+  t = tf_keras.backend.get_value(t)
   if callable(t):
     return t()
   else:
     return t
 
 
-class CustomTensorBoard(tf.keras.callbacks.TensorBoard):
+class CustomTensorBoard(tf_keras.callbacks.TensorBoard):
   """A customized TensorBoard callback that tracks additional datapoints.
 
   Metrics tracked:
   - Global learning rate
 
   Attributes:
     log_dir: the path of the directory where to save the log files to be parsed
@@ -153,27 +153,27 @@
     return logs
 
   def _calculate_lr(self) -> int:
     """Calculates the learning rate given the current step."""
     return get_scalar_from_tensor(
         self._get_base_optimizer()._decayed_lr(var_dtype=tf.float32))  # pylint:disable=protected-access
 
-  def _get_base_optimizer(self) -> tf.keras.optimizers.Optimizer:
+  def _get_base_optimizer(self) -> tf_keras.optimizers.Optimizer:
     """Get the base optimizer used by the current model."""
 
     optimizer = self.model.optimizer
 
     # The optimizer might be wrapped by another class, so unwrap it
     while hasattr(optimizer, '_optimizer'):
       optimizer = optimizer._optimizer  # pylint:disable=protected-access
 
     return optimizer
 
 
-class MovingAverageCallback(tf.keras.callbacks.Callback):
+class MovingAverageCallback(tf_keras.callbacks.Callback):
   """A Callback to be used with a `ExponentialMovingAverage` optimizer.
 
   Applies moving average weights to the model during validation time to test
   and predict on the averaged weights rather than the current model weights.
   Once training is complete, the model weights will be overwritten with the
   averaged weights (by default).
 
@@ -183,15 +183,15 @@
     **kwargs: Any additional callback arguments.
   """
 
   def __init__(self, overwrite_weights_on_train_end: bool = False, **kwargs):
     super(MovingAverageCallback, self).__init__(**kwargs)
     self.overwrite_weights_on_train_end = overwrite_weights_on_train_end
 
-  def set_model(self, model: tf.keras.Model):
+  def set_model(self, model: tf_keras.Model):
     super(MovingAverageCallback, self).set_model(model)
     assert isinstance(self.model.optimizer,
                       optimization.ExponentialMovingAverage)
     self.model.optimizer.shadow_copy(self.model)
 
   def on_test_begin(self, logs: Optional[MutableMapping[Text, Any]] = None):
     self.model.optimizer.swap_weights()
@@ -200,23 +200,23 @@
     self.model.optimizer.swap_weights()
 
   def on_train_end(self, logs: Optional[MutableMapping[Text, Any]] = None):
     if self.overwrite_weights_on_train_end:
       self.model.optimizer.assign_average_vars(self.model.variables)
 
 
-class AverageModelCheckpoint(tf.keras.callbacks.ModelCheckpoint):
+class AverageModelCheckpoint(tf_keras.callbacks.ModelCheckpoint):
   """Saves and, optionally, assigns the averaged weights.
 
   Taken from tfa.callbacks.AverageModelCheckpoint.
 
   Attributes:
     update_weights: If True, assign the moving average weights to the model, and
       save them. If False, keep the old non-averaged weights, but the saved
-      model uses the average weights. See `tf.keras.callbacks.ModelCheckpoint`
+      model uses the average weights. See `tf_keras.callbacks.ModelCheckpoint`
       for the other args.
   """
 
   def __init__(self,
                update_weights: bool,
                filepath: str,
                monitor: str = 'val_loss',
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/classifier_trainer.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/classifier_trainer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import os
 import pprint
 from typing import Any, Mapping, Optional, Text, Tuple
 
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.common import distribute_utils
 from official.legacy.image_classification import callbacks as custom_callbacks
 from official.legacy.image_classification import dataset_factory
 from official.legacy.image_classification import optimizer_factory
 from official.legacy.image_classification.configs import base_configs
 from official.legacy.image_classification.configs import configs
 from official.legacy.image_classification.efficientnet import efficientnet_model
@@ -34,15 +34,15 @@
 from official.legacy.image_classification.vgg import vgg_model
 from official.modeling import hyperparams
 from official.modeling import performance
 from official.utils import hyperparams_flags
 from official.utils.misc import keras_utils
 
 
-def get_models() -> Mapping[str, tf.keras.Model]:
+def get_models() -> Mapping[str, tf_keras.Model]:
   """Returns the mapping from model type name to Keras model."""
   return {
       'efficientnet': efficientnet_model.EfficientNet.from_name,
       'resnet': resnet_model.resnet50,
       'vgg': vgg_model.vgg16,
   }
 
@@ -60,34 +60,34 @@
 
 def _get_metrics(one_hot: bool) -> Mapping[Text, Any]:
   """Get a dict of available metrics to track."""
   if one_hot:
     return {
         # (name, metric_fn)
         'acc':
-            tf.keras.metrics.CategoricalAccuracy(name='accuracy'),
+            tf_keras.metrics.CategoricalAccuracy(name='accuracy'),
         'accuracy':
-            tf.keras.metrics.CategoricalAccuracy(name='accuracy'),
+            tf_keras.metrics.CategoricalAccuracy(name='accuracy'),
         'top_1':
-            tf.keras.metrics.CategoricalAccuracy(name='accuracy'),
+            tf_keras.metrics.CategoricalAccuracy(name='accuracy'),
         'top_5':
-            tf.keras.metrics.TopKCategoricalAccuracy(
+            tf_keras.metrics.TopKCategoricalAccuracy(
                 k=5, name='top_5_accuracy'),
     }
   else:
     return {
         # (name, metric_fn)
         'acc':
-            tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
+            tf_keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
         'accuracy':
-            tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
+            tf_keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
         'top_1':
-            tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
+            tf_keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
         'top_5':
-            tf.keras.metrics.SparseTopKCategoricalAccuracy(
+            tf_keras.metrics.SparseTopKCategoricalAccuracy(
                 k=5, name='top_5_accuracy'),
     }
 
 
 def get_image_size_from_model(
     params: base_configs.ExperimentConfig) -> Optional[int]:
   """If the given model has a preferred image size, return it."""
@@ -188,15 +188,15 @@
   params.validate()
   params.lock()
 
   logging.info('Final model parameters: %s', pp.pformat(params.as_dict()))
   return params
 
 
-def resume_from_checkpoint(model: tf.keras.Model, model_dir: str,
+def resume_from_checkpoint(model: tf_keras.Model, model_dir: str,
                            train_steps: int) -> int:
   """Resumes from the latest checkpoint, if possible.
 
   Loads the model weights and optimizer settings from a checkpoint.
   This function should be used in case of preemption recovery.
 
   Args:
@@ -229,15 +229,15 @@
   """Initializes backend related initializations."""
   keras_utils.set_session_config(enable_xla=params.runtime.enable_xla)
   performance.set_mixed_precision_policy(dataset_builder.dtype)
   if tf.config.list_physical_devices('GPU'):
     data_format = 'channels_first'
   else:
     data_format = 'channels_last'
-  tf.keras.backend.set_image_data_format(data_format)
+  tf_keras.backend.set_image_data_format(data_format)
   if params.runtime.run_eagerly:
     # Enable eager execution to allow step-by-step debugging
     tf.config.experimental_run_functions_eagerly(True)
   if tf.config.list_physical_devices('GPU'):
     if params.runtime.gpu_thread_mode:
       keras_utils.set_gpu_thread_mode_and_count(
           per_gpu_thread_count=params.runtime.per_gpu_thread_count,
@@ -344,18 +344,18 @@
         loss_scale=get_loss_scale(params))
 
     metrics_map = _get_metrics(one_hot)
     metrics = [metrics_map[metric] for metric in params.train.metrics]
     steps_per_loop = train_steps if params.train.set_epoch_loop else 1
 
     if one_hot:
-      loss_obj = tf.keras.losses.CategoricalCrossentropy(
+      loss_obj = tf_keras.losses.CategoricalCrossentropy(
           label_smoothing=params.model.loss.label_smoothing)
     else:
-      loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()
+      loss_obj = tf_keras.losses.SparseCategoricalCrossentropy()
     model.compile(
         optimizer=optimizer,
         loss=loss_obj,
         metrics=metrics,
         steps_per_execution=steps_per_loop)
 
     initial_epoch = 0
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/classifier_trainer_test.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/classifier_trainer_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,15 +21,15 @@
 import sys
 
 from typing import Any, Callable, Iterable, Mapping, MutableMapping, Optional, Tuple
 
 from absl import flags
 from absl.testing import flagsaver
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.legacy.image_classification import classifier_trainer
 from official.utils.flags import core as flags_core
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/classifier_trainer_util_test.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/classifier_trainer_util_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,28 +18,28 @@
 from __future__ import division
 from __future__ import print_function
 
 import copy
 import os
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.image_classification import classifier_trainer
 from official.legacy.image_classification import dataset_factory
 from official.legacy.image_classification import test_utils
 from official.legacy.image_classification.configs import base_configs
 
 
-def get_trivial_model(num_classes: int) -> tf.keras.Model:
+def get_trivial_model(num_classes: int) -> tf_keras.Model:
   """Creates and compiles trivial model for ImageNet dataset."""
   model = test_utils.trivial_model(num_classes=num_classes)
   lr = 0.01
-  optimizer = tf.keras.optimizers.SGD(learning_rate=lr)
-  loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()
+  optimizer = tf_keras.optimizers.SGD(learning_rate=lr)
+  loss_obj = tf_keras.losses.SparseCategoricalCrossentropy()
   model.compile(optimizer=optimizer, loss=loss_obj, run_eagerly=True)
   return model
 
 
 def get_trivial_data() -> tf.data.Dataset:
   """Gets trivial data in the ImageNet size."""
 
@@ -116,26 +116,26 @@
     fake_ds_builder.dtype = dtype
     fake_ds_builder.config = EmptyClass()
     classifier_trainer.initialize(config, fake_ds_builder)
 
   def test_resume_from_checkpoint(self):
     """Tests functionality for resuming from checkpoint."""
     # Set the keras policy
-    tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')
+    tf_keras.mixed_precision.set_global_policy('mixed_bfloat16')
 
     # Get the model, datasets, and compile it.
     model = get_trivial_model(10)
 
     # Create the checkpoint
     model_dir = self.create_tempdir().full_path
     train_epochs = 1
     train_steps = 10
     ds = get_trivial_data()
     callbacks = [
-        tf.keras.callbacks.ModelCheckpoint(
+        tf_keras.callbacks.ModelCheckpoint(
             os.path.join(model_dir, 'model.ckpt-{epoch:04d}'),
             save_weights_only=True)
     ]
     model.fit(
         ds,
         callbacks=callbacks,
         epochs=train_epochs,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/configs/base_configs.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/configs/base_configs.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -108,18 +108,24 @@
       equal the number of training steps in `model.compile`. This reduces the
       number of callbacks run per epoch which significantly improves end-to-end
       TPU training time.
   """
   resume_checkpoint: bool = None
   epochs: int = None
   steps: int = None
-  callbacks: CallbacksConfig = CallbacksConfig()
+  callbacks: CallbacksConfig = dataclasses.field(
+      default_factory=CallbacksConfig
+  )
   metrics: MetricsConfig = None
-  tensorboard: TensorBoardConfig = TensorBoardConfig()
-  time_history: TimeHistoryConfig = TimeHistoryConfig()
+  tensorboard: TensorBoardConfig = dataclasses.field(
+      default_factory=TensorBoardConfig
+  )
+  time_history: TimeHistoryConfig = dataclasses.field(
+      default_factory=TimeHistoryConfig
+  )
   set_epoch_loop: bool = False
 
 
 @dataclasses.dataclass
 class EvalConfig(hyperparams.Config):
   """Configuration for evaluation.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/configs/configs.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/configs/configs.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -31,91 +31,146 @@
     export: An `ExportConfig` instance
     runtime: A `RuntimeConfig` instance.
     dataset: A `DatasetConfig` instance.
     train: A `TrainConfig` instance.
     evaluation: An `EvalConfig` instance.
     model: A `ModelConfig` instance.
   """
-  export: base_configs.ExportConfig = base_configs.ExportConfig()
-  runtime: base_configs.RuntimeConfig = base_configs.RuntimeConfig()
-  train_dataset: dataset_factory.DatasetConfig = dataset_factory.ImageNetConfig(
-      split='train')
-  validation_dataset: dataset_factory.DatasetConfig = dataset_factory.ImageNetConfig(
-      split='validation')
-  train: base_configs.TrainConfig = base_configs.TrainConfig(
-      resume_checkpoint=True,
-      epochs=500,
-      steps=None,
-      callbacks=base_configs.CallbacksConfig(
-          enable_checkpoint_and_export=True, enable_tensorboard=True),
-      metrics=['accuracy', 'top_5'],
-      time_history=base_configs.TimeHistoryConfig(log_steps=100),
-      tensorboard=base_configs.TensorBoardConfig(
-          track_lr=True, write_model_weights=False),
-      set_epoch_loop=False)
-  evaluation: base_configs.EvalConfig = base_configs.EvalConfig(
-      epochs_between_evals=1, steps=None)
-  model: base_configs.ModelConfig = efficientnet_config.EfficientNetModelConfig(
+  export: base_configs.ExportConfig = dataclasses.field(
+      default_factory=base_configs.ExportConfig
+  )
+  runtime: base_configs.RuntimeConfig = dataclasses.field(
+      default_factory=base_configs.RuntimeConfig
+  )
+  train_dataset: dataset_factory.DatasetConfig = dataclasses.field(
+      default_factory=lambda: dataset_factory.ImageNetConfig(split='train')
+  )
+  validation_dataset: dataset_factory.DatasetConfig = dataclasses.field(
+      default_factory=lambda: dataset_factory.ImageNetConfig(split='validation')
+  )
+  train: base_configs.TrainConfig = dataclasses.field(
+      default_factory=lambda: base_configs.TrainConfig(  # pylint: disable=g-long-lambda
+          resume_checkpoint=True,
+          epochs=500,
+          steps=None,
+          callbacks=base_configs.CallbacksConfig(
+              enable_checkpoint_and_export=True, enable_tensorboard=True
+          ),
+          metrics=['accuracy', 'top_5'],
+          time_history=base_configs.TimeHistoryConfig(log_steps=100),
+          tensorboard=base_configs.TensorBoardConfig(
+              track_lr=True, write_model_weights=False
+          ),
+          set_epoch_loop=False,
+      )
+  )
+  evaluation: base_configs.EvalConfig = dataclasses.field(
+      default_factory=lambda: base_configs.EvalConfig(  # pylint: disable=g-long-lambda
+          epochs_between_evals=1, steps=None
+      )
+  )
+  model: base_configs.ModelConfig = dataclasses.field(
+      default_factory=efficientnet_config.EfficientNetModelConfig
   )
 
 
 @dataclasses.dataclass
 class ResNetImagenetConfig(base_configs.ExperimentConfig):
   """Base configuration to train resnet-50 on ImageNet."""
-  export: base_configs.ExportConfig = base_configs.ExportConfig()
-  runtime: base_configs.RuntimeConfig = base_configs.RuntimeConfig()
-  train_dataset: dataset_factory.DatasetConfig = \
-      dataset_factory.ImageNetConfig(split='train',
-                                     one_hot=False,
-                                     mean_subtract=True,
-                                     standardize=True)
-  validation_dataset: dataset_factory.DatasetConfig = \
-      dataset_factory.ImageNetConfig(split='validation',
-                                     one_hot=False,
-                                     mean_subtract=True,
-                                     standardize=True)
-  train: base_configs.TrainConfig = base_configs.TrainConfig(
-      resume_checkpoint=True,
-      epochs=90,
-      steps=None,
-      callbacks=base_configs.CallbacksConfig(
-          enable_checkpoint_and_export=True, enable_tensorboard=True),
-      metrics=['accuracy', 'top_5'],
-      time_history=base_configs.TimeHistoryConfig(log_steps=100),
-      tensorboard=base_configs.TensorBoardConfig(
-          track_lr=True, write_model_weights=False),
-      set_epoch_loop=False)
-  evaluation: base_configs.EvalConfig = base_configs.EvalConfig(
-      epochs_between_evals=1, steps=None)
-  model: base_configs.ModelConfig = resnet_config.ResNetModelConfig()
+  export: base_configs.ExportConfig = dataclasses.field(
+      default_factory=base_configs.ExportConfig
+  )
+  runtime: base_configs.RuntimeConfig = dataclasses.field(
+      default_factory=base_configs.RuntimeConfig
+  )
+  train_dataset: dataset_factory.DatasetConfig = dataclasses.field(
+      default_factory=lambda: dataset_factory.ImageNetConfig(  # pylint: disable=g-long-lambda
+          split='train', one_hot=False, mean_subtract=True, standardize=True
+      )
+  )
+  validation_dataset: dataset_factory.DatasetConfig = dataclasses.field(
+      default_factory=lambda: dataset_factory.ImageNetConfig(  # pylint: disable=g-long-lambda
+          split='validation',
+          one_hot=False,
+          mean_subtract=True,
+          standardize=True,
+      )
+  )
+  train: base_configs.TrainConfig = dataclasses.field(
+      default_factory=lambda: base_configs.TrainConfig(  # pylint: disable=g-long-lambda
+          resume_checkpoint=True,
+          epochs=90,
+          steps=None,
+          callbacks=base_configs.CallbacksConfig(
+              enable_checkpoint_and_export=True, enable_tensorboard=True
+          ),
+          metrics=['accuracy', 'top_5'],
+          time_history=base_configs.TimeHistoryConfig(log_steps=100),
+          tensorboard=base_configs.TensorBoardConfig(
+              track_lr=True, write_model_weights=False
+          ),
+          set_epoch_loop=False,
+      )
+  )
+  evaluation: base_configs.EvalConfig = dataclasses.field(
+      default_factory=lambda: base_configs.EvalConfig(  # pylint: disable=g-long-lambda
+          epochs_between_evals=1, steps=None
+      )
+  )
+  model: base_configs.ModelConfig = dataclasses.field(
+      default_factory=resnet_config.ResNetModelConfig
+  )
 
 
 @dataclasses.dataclass
 class VGGImagenetConfig(base_configs.ExperimentConfig):
   """Base configuration to train vgg-16 on ImageNet."""
-  export: base_configs.ExportConfig = base_configs.ExportConfig()
-  runtime: base_configs.RuntimeConfig = base_configs.RuntimeConfig()
-  train_dataset: dataset_factory.DatasetConfig = dataset_factory.ImageNetConfig(
-      split='train', one_hot=False, mean_subtract=True, standardize=True)
-  validation_dataset: dataset_factory.DatasetConfig = dataset_factory.ImageNetConfig(
-      split='validation', one_hot=False, mean_subtract=True, standardize=True)
-  train: base_configs.TrainConfig = base_configs.TrainConfig(
-      resume_checkpoint=True,
-      epochs=90,
-      steps=None,
-      callbacks=base_configs.CallbacksConfig(
-          enable_checkpoint_and_export=True, enable_tensorboard=True),
-      metrics=['accuracy', 'top_5'],
-      time_history=base_configs.TimeHistoryConfig(log_steps=100),
-      tensorboard=base_configs.TensorBoardConfig(
-          track_lr=True, write_model_weights=False),
-      set_epoch_loop=False)
-  evaluation: base_configs.EvalConfig = base_configs.EvalConfig(
-      epochs_between_evals=1, steps=None)
-  model: base_configs.ModelConfig = vgg_config.VGGModelConfig()
+  export: base_configs.ExportConfig = dataclasses.field(
+      default_factory=base_configs.ExportConfig
+  )
+  runtime: base_configs.RuntimeConfig = dataclasses.field(
+      default_factory=base_configs.RuntimeConfig
+  )
+  train_dataset: dataset_factory.DatasetConfig = dataclasses.field(
+      default_factory=lambda: dataset_factory.ImageNetConfig(  # pylint: disable=g-long-lambda
+          split='train', one_hot=False, mean_subtract=True, standardize=True
+      )
+  )
+  validation_dataset: dataset_factory.DatasetConfig = dataclasses.field(
+      default_factory=lambda: dataset_factory.ImageNetConfig(  # pylint: disable=g-long-lambda
+          split='validation',
+          one_hot=False,
+          mean_subtract=True,
+          standardize=True,
+      )
+  )
+  train: base_configs.TrainConfig = dataclasses.field(
+      default_factory=lambda: base_configs.TrainConfig(  # pylint: disable=g-long-lambda
+          resume_checkpoint=True,
+          epochs=90,
+          steps=None,
+          callbacks=base_configs.CallbacksConfig(
+              enable_checkpoint_and_export=True, enable_tensorboard=True
+          ),
+          metrics=['accuracy', 'top_5'],
+          time_history=base_configs.TimeHistoryConfig(log_steps=100),
+          tensorboard=base_configs.TensorBoardConfig(
+              track_lr=True, write_model_weights=False
+          ),
+          set_epoch_loop=False,
+      )
+  )
+  evaluation: base_configs.EvalConfig = dataclasses.field(
+      default_factory=lambda: base_configs.EvalConfig(  # pylint: disable=g-long-lambda
+          epochs_between_evals=1, steps=None
+      )
+  )
+  model: base_configs.ModelConfig = dataclasses.field(
+      default_factory=vgg_config.VGGModelConfig
+  )
 
 
 def get_config(model: str, dataset: str) -> base_configs.ExperimentConfig:
   """Given model and dataset names, return the ExperimentConfig."""
   dataset_model_config_map = {
       'imagenet': {
           'efficientnet': EfficientNetImageNetConfig(),
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/dataset_factory.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/dataset_factory.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 from __future__ import division
 from __future__ import print_function
 import dataclasses
 import os
 from typing import Any, List, Mapping, Optional, Tuple, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 from official.legacy.image_classification import augment
 from official.legacy.image_classification import preprocessing
 from official.modeling.hyperparams import base_config
 
 AUGMENTERS = {
     'autoaugment': augment.AutoAugment,
@@ -112,15 +112,15 @@
   num_channels: Union[int, str] = 'infer'
   num_examples: Union[int, str] = 'infer'
   batch_size: int = 128
   use_per_replica_batch_size: bool = True
   num_devices: int = 1
   dtype: str = 'float32'
   one_hot: bool = True
-  augmenter: AugmentConfig = AugmentConfig()
+  augmenter: AugmentConfig = dataclasses.field(default_factory=AugmentConfig)
   download: bool = False
   shuffle_buffer_size: int = 10000
   file_shuffle_buffer_size: int = 1024
   skip_decoding: bool = True
   cache: bool = False
   tf_data_service: Optional[str] = None
   mean_subtract: bool = False
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/common_modules.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/common_modules.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,21 +14,21 @@
 
 """Common modeling utilities."""
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 from typing import Optional, Text
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow.compat.v1 as tf1
 from tensorflow.python.tpu import tpu_function
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class TpuBatchNormalization(tf.keras.layers.BatchNormalization):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class TpuBatchNormalization(tf_keras.layers.BatchNormalization):
   """Cross replica batch normalization."""
 
   def __init__(self, fused: Optional[bool] = False, **kwargs):
     if fused in (True, None):
       raise ValueError('TpuBatchNormalization does not support fused=True.')
     super(TpuBatchNormalization, self).__init__(fused=fused, **kwargs)
 
@@ -67,50 +67,50 @@
           shard_mean_of_square, num_shards_per_group)
       group_variance = group_mean_of_square - tf.math.square(group_mean)
       return (group_mean, group_variance)
     else:
       return (shard_mean, shard_variance)
 
 
-def get_batch_norm(batch_norm_type: Text) -> tf.keras.layers.BatchNormalization:
+def get_batch_norm(batch_norm_type: Text) -> tf_keras.layers.BatchNormalization:
   """A helper to create a batch normalization getter.
 
   Args:
     batch_norm_type: The type of batch normalization layer implementation. `tpu`
       will use `TpuBatchNormalization`.
 
   Returns:
-    An instance of `tf.keras.layers.BatchNormalization`.
+    An instance of `tf_keras.layers.BatchNormalization`.
   """
   if batch_norm_type == 'tpu':
     return TpuBatchNormalization
 
-  return tf.keras.layers.BatchNormalization  # pytype: disable=bad-return-type  # typed-keras
+  return tf_keras.layers.BatchNormalization  # pytype: disable=bad-return-type  # typed-keras
 
 
 def count_params(model, trainable_only=True):
   """Returns the count of all model parameters, or just trainable ones."""
   if not trainable_only:
     return model.count_params()
   else:
     return int(
         np.sum([
-            tf.keras.backend.count_params(p) for p in model.trainable_weights
+            tf_keras.backend.count_params(p) for p in model.trainable_weights
         ]))
 
 
-def load_weights(model: tf.keras.Model,
+def load_weights(model: tf_keras.Model,
                  model_weights_path: Text,
                  weights_format: Text = 'saved_model'):
   """Load model weights from the given file path.
 
   Args:
     model: the model to load weights into
     model_weights_path: the path of the model weights
     weights_format: the model weights format. One of 'saved_model', 'h5', or
       'checkpoint'.
   """
   if weights_format == 'saved_model':
-    loaded_model = tf.keras.models.load_model(model_weights_path)
+    loaded_model = tf_keras.models.load_model(model_weights_path)
     model.set_weights(loaded_model.get_weights())
   else:
     model.load_weights(model_weights_path)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/efficientnet_config.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/efficientnet_config.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -51,23 +51,32 @@
               'batch_norm': 'default',
               'rescale_input': True,
               'num_classes': 1000,
               'activation': 'swish',
               'dtype': 'float32',
           }
       })
-  loss: base_configs.LossConfig = base_configs.LossConfig(
-      name='categorical_crossentropy', label_smoothing=0.1)
-  optimizer: base_configs.OptimizerConfig = base_configs.OptimizerConfig(
-      name='rmsprop',
-      decay=0.9,
-      epsilon=0.001,
-      momentum=0.9,
-      moving_average_decay=None)
-  learning_rate: base_configs.LearningRateConfig = base_configs.LearningRateConfig(  # pylint: disable=line-too-long
-      name='exponential',
-      initial_lr=0.008,
-      decay_epochs=2.4,
-      decay_rate=0.97,
-      warmup_epochs=5,
-      scale_by_batch_size=1. / 128.,
-      staircase=True)
+  loss: base_configs.LossConfig = dataclasses.field(
+      default_factory=lambda: base_configs.LossConfig(  # pylint: disable=g-long-lambda
+          name='categorical_crossentropy', label_smoothing=0.1
+      )
+  )
+  optimizer: base_configs.OptimizerConfig = dataclasses.field(
+      default_factory=lambda: base_configs.OptimizerConfig(  # pylint: disable=g-long-lambda
+          name='rmsprop',
+          decay=0.9,
+          epsilon=0.001,
+          momentum=0.9,
+          moving_average_decay=None,
+      )
+  )
+  learning_rate: base_configs.LearningRateConfig = dataclasses.field(
+      default_factory=lambda: base_configs.LearningRateConfig(  # pylint: disable=g-long-lambda
+          name='exponential',
+          initial_lr=0.008,
+          decay_epochs=2.4,
+          decay_rate=0.97,
+          warmup_epochs=5,
+          scale_by_batch_size=1.0 / 128.0,
+          staircase=True,
+      )
+  )
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/efficientnet_model.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/efficientnet_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -23,15 +23,15 @@
 from __future__ import division
 from __future__ import print_function
 import dataclasses
 import math
 from typing import Any, Dict, Optional, Text, Tuple
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.image_classification import preprocessing
 from official.legacy.image_classification.efficientnet import common_modules
 from official.modeling import tf_utils
 from official.modeling.hyperparams import base_config
 
 
 @dataclasses.dataclass
@@ -159,35 +159,35 @@
                  activation: Optional[Any] = None,
                  depthwise: bool = False,
                  name: Optional[Text] = None):
   """A conv2d followed by batch norm and an activation."""
   batch_norm = common_modules.get_batch_norm(config.batch_norm)
   bn_momentum = config.bn_momentum
   bn_epsilon = config.bn_epsilon
-  data_format = tf.keras.backend.image_data_format()
+  data_format = tf_keras.backend.image_data_format()
   weight_decay = config.weight_decay
 
   name = name or ''
 
   # Collect args based on what kind of conv2d block is desired
   init_kwargs = {
       'kernel_size': kernel_size,
       'strides': strides,
       'use_bias': use_bias,
       'padding': 'same',
       'name': name + '_conv2d',
-      'kernel_regularizer': tf.keras.regularizers.l2(weight_decay),
-      'bias_regularizer': tf.keras.regularizers.l2(weight_decay),
+      'kernel_regularizer': tf_keras.regularizers.l2(weight_decay),
+      'bias_regularizer': tf_keras.regularizers.l2(weight_decay),
   }
 
   if depthwise:
-    conv2d = tf.keras.layers.DepthwiseConv2D
+    conv2d = tf_keras.layers.DepthwiseConv2D
     init_kwargs.update({'depthwise_initializer': CONV_KERNEL_INITIALIZER})
   else:
-    conv2d = tf.keras.layers.Conv2D
+    conv2d = tf_keras.layers.Conv2D
     init_kwargs.update({
         'filters': conv_filters,
         'kernel_initializer': CONV_KERNEL_INITIALIZER
     })
 
   x = conv2d(**init_kwargs)(inputs)
 
@@ -197,15 +197,15 @@
         axis=bn_axis,
         momentum=bn_momentum,
         epsilon=bn_epsilon,
         name=name + '_bn')(
             x)
 
   if activation is not None:
-    x = tf.keras.layers.Activation(activation, name=name + '_activation')(x)
+    x = tf_keras.layers.Activation(activation, name=name + '_activation')(x)
   return x
 
 
 def mb_conv_block(inputs: tf.Tensor,
                   block: BlockConfig,
                   config: ModelConfig,
                   prefix: Optional[Text] = None):
@@ -219,15 +219,15 @@
 
   Returns:
     the output of the block
   """
   use_se = config.use_se
   activation = tf_utils.get_activation(config.activation)
   drop_connect_rate = config.drop_connect_rate
-  data_format = tf.keras.backend.image_data_format()
+  data_format = tf_keras.backend.image_data_format()
   use_depthwise = block.conv_type != 'no_depthwise'
   prefix = prefix or ''
 
   filters = block.input_filters * block.expand_ratio
 
   x = inputs
 
@@ -272,16 +272,16 @@
     num_reduced_filters = max(1, int(block.input_filters * block.se_ratio))
 
     if data_format == 'channels_first':
       se_shape = (filters, 1, 1)
     else:
       se_shape = (1, 1, filters)
 
-    se = tf.keras.layers.GlobalAveragePooling2D(name=prefix + 'se_squeeze')(x)
-    se = tf.keras.layers.Reshape(se_shape, name=prefix + 'se_reshape')(se)
+    se = tf_keras.layers.GlobalAveragePooling2D(name=prefix + 'se_squeeze')(x)
+    se = tf_keras.layers.Reshape(se_shape, name=prefix + 'se_reshape')(se)
 
     se = conv2d_block(
         se,
         num_reduced_filters,
         config,
         use_bias=True,
         use_batch_norm=False,
@@ -291,46 +291,46 @@
         se,
         filters,
         config,
         use_bias=True,
         use_batch_norm=False,
         activation='sigmoid',
         name=prefix + 'se_expand')
-    x = tf.keras.layers.multiply([x, se], name=prefix + 'se_excite')
+    x = tf_keras.layers.multiply([x, se], name=prefix + 'se_excite')
 
   # Output phase
   x = conv2d_block(
       x, block.output_filters, config, activation=None, name=prefix + 'project')
 
   # Add identity so that quantization-aware training can insert quantization
   # ops correctly.
-  x = tf.keras.layers.Activation(
+  x = tf_keras.layers.Activation(
       tf_utils.get_activation('identity'), name=prefix + 'id')(
           x)
 
   if (block.id_skip and all(s == 1 for s in block.strides) and
       block.input_filters == block.output_filters):
     if drop_connect_rate and drop_connect_rate > 0:
       # Apply dropconnect
       # The only difference between dropout and dropconnect in TF is scaling by
       # drop_connect_rate during training. See:
       # https://github.com/keras-team/keras/pull/9898#issuecomment-380577612
-      x = tf.keras.layers.Dropout(
+      x = tf_keras.layers.Dropout(
           drop_connect_rate, noise_shape=(None, 1, 1, 1), name=prefix + 'drop')(
               x)
 
-    x = tf.keras.layers.add([x, inputs], name=prefix + 'add')
+    x = tf_keras.layers.add([x, inputs], name=prefix + 'add')
 
   return x
 
 
-def efficientnet(image_input: tf.keras.layers.Input, config: ModelConfig):  # pytype: disable=invalid-annotation  # typed-keras
+def efficientnet(image_input: tf_keras.layers.Input, config: ModelConfig):  # pytype: disable=invalid-annotation  # typed-keras
   """Creates an EfficientNet graph given the model parameters.
 
-  This function is wrapped by the `EfficientNet` class to make a tf.keras.Model.
+  This function is wrapped by the `EfficientNet` class to make a tf_keras.Model.
 
   Args:
     image_input: the input batch of images
     config: the model config
 
   Returns:
     the output of efficientnet
@@ -341,22 +341,22 @@
   top_base_filters = config.top_base_filters
   activation = tf_utils.get_activation(config.activation)
   dropout_rate = config.dropout_rate
   drop_connect_rate = config.drop_connect_rate
   num_classes = config.num_classes
   input_channels = config.input_channels
   rescale_input = config.rescale_input
-  data_format = tf.keras.backend.image_data_format()
+  data_format = tf_keras.backend.image_data_format()
   dtype = config.dtype
   weight_decay = config.weight_decay
 
   x = image_input
   if data_format == 'channels_first':
     # Happens on GPU/TPU if available.
-    x = tf.keras.layers.Permute((3, 1, 2))(x)
+    x = tf_keras.layers.Permute((3, 1, 2))(x)
   if rescale_input:
     x = preprocessing.normalize_images(
         x, num_channels=input_channels, dtype=dtype, data_format=data_format)
 
   # Build stem
   x = conv2d_block(
       x,
@@ -401,30 +401,30 @@
       x,
       round_filters(top_base_filters, config),
       config,
       activation=activation,
       name='top')
 
   # Build classifier
-  x = tf.keras.layers.GlobalAveragePooling2D(name='top_pool')(x)
+  x = tf_keras.layers.GlobalAveragePooling2D(name='top_pool')(x)
   if dropout_rate and dropout_rate > 0:
-    x = tf.keras.layers.Dropout(dropout_rate, name='top_dropout')(x)
-  x = tf.keras.layers.Dense(
+    x = tf_keras.layers.Dropout(dropout_rate, name='top_dropout')(x)
+  x = tf_keras.layers.Dense(
       num_classes,
       kernel_initializer=DENSE_KERNEL_INITIALIZER,
-      kernel_regularizer=tf.keras.regularizers.l2(weight_decay),
-      bias_regularizer=tf.keras.regularizers.l2(weight_decay),
+      kernel_regularizer=tf_keras.regularizers.l2(weight_decay),
+      bias_regularizer=tf_keras.regularizers.l2(weight_decay),
       name='logits')(
           x)
-  x = tf.keras.layers.Activation('softmax', name='probs')(x)
+  x = tf_keras.layers.Activation('softmax', name='probs')(x)
 
   return x
 
 
-class EfficientNet(tf.keras.Model):
+class EfficientNet(tf_keras.Model):
   """Wrapper class for an EfficientNet Keras model.
 
   Contains helper methods to build, manage, and save metadata about the model.
   """
 
   def __init__(self,
                config: Optional[ModelConfig] = None,
@@ -439,15 +439,15 @@
     config = config or ModelConfig()
 
     self.config = config.replace(**overrides)
 
     input_channels = self.config.input_channels
     model_name = self.config.model_name
     input_shape = (None, None, input_channels)  # Should handle any size image
-    image_input = tf.keras.layers.Input(shape=input_shape)
+    image_input = tf_keras.layers.Input(shape=input_shape)
 
     output = efficientnet(image_input, self.config)
 
     # Cast to float32 in case we have a different model dtype
     output = tf.cast(output, tf.float32)
 
     logging.info('Building model %s with params %s', model_name, self.config)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/efficientnet/tfhub_export.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/efficientnet/tfhub_export.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,43 +19,43 @@
 from __future__ import print_function
 
 import os
 
 from absl import app
 from absl import flags
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.image_classification.efficientnet import efficientnet_model
 
 FLAGS = flags.FLAGS
 
 flags.DEFINE_string("model_name", None, "EfficientNet model name.")
 flags.DEFINE_string("model_path", None, "File path to TF model checkpoint.")
 flags.DEFINE_string("export_path", None,
                     "TF-Hub SavedModel destination path to export.")
 
 
 def export_tfhub(model_path, hub_destination, model_name):
-  """Restores a tf.keras.Model and saves for TF-Hub."""
+  """Restores a tf_keras.Model and saves for TF-Hub."""
   model_configs = dict(efficientnet_model.MODEL_CONFIGS)
   config = model_configs[model_name]
 
-  image_input = tf.keras.layers.Input(
+  image_input = tf_keras.layers.Input(
       shape=(None, None, 3), name="image_input", dtype=tf.float32)
   x = image_input * 255.0
   outputs = efficientnet_model.efficientnet(x, config)
-  hub_model = tf.keras.Model(image_input, outputs)
+  hub_model = tf_keras.Model(image_input, outputs)
   ckpt = tf.train.Checkpoint(model=hub_model)
   ckpt.restore(model_path).assert_existing_objects_matched()
   hub_model.save(
       os.path.join(hub_destination, "classification"), include_optimizer=False)
 
   feature_vector_output = hub_model.get_layer(name="top_pool").get_output_at(0)
-  hub_model2 = tf.keras.Model(image_input, feature_vector_output)
+  hub_model2 = tf_keras.Model(image_input, feature_vector_output)
   hub_model2.save(
       os.path.join(hub_destination, "feature-vector"), include_optimizer=False)
 
 
 def main(argv):
   if len(argv) > 1:
     raise app.UsageError("Too many command-line arguments.")
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/learning_rate.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/learning_rate.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,24 +16,24 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 from typing import Any, Mapping, Optional
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 BASE_LEARNING_RATE = 0.1
 
 
-class WarmupDecaySchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
+class WarmupDecaySchedule(tf_keras.optimizers.schedules.LearningRateSchedule):
   """A wrapper for LearningRateSchedule that includes warmup steps."""
 
   def __init__(self,
-               lr_schedule: tf.keras.optimizers.schedules.LearningRateSchedule,
+               lr_schedule: tf_keras.optimizers.schedules.LearningRateSchedule,
                warmup_steps: int,
                warmup_lr: Optional[float] = None):
     """Add warmup decay to a learning rate schedule.
 
     Args:
       lr_schedule: base learning rate scheduler
       warmup_steps: number of warmup steps
@@ -69,15 +69,15 @@
     config.update({
         "warmup_steps": self._warmup_steps,
         "warmup_lr": self._warmup_lr,
     })
     return config
 
 
-class CosineDecayWithWarmup(tf.keras.optimizers.schedules.LearningRateSchedule):
+class CosineDecayWithWarmup(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Class to generate learning rate tensor."""
 
   def __init__(self, batch_size: int, total_steps: int, warmup_steps: int):
     """Creates the cosine learning rate tensor with linear warmup.
 
     Args:
       batch_size: The training batch size used in the experiment.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/learning_rate_test.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/learning_rate_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,29 +14,29 @@
 
 """Tests for learning_rate."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.image_classification import learning_rate
 
 
 class LearningRateTests(tf.test.TestCase):
 
   def test_warmup_decay(self):
     """Basic computational test for warmup decay."""
     initial_lr = 0.01
     decay_steps = 100
     decay_rate = 0.01
     warmup_steps = 10
 
-    base_lr = tf.keras.optimizers.schedules.ExponentialDecay(
+    base_lr = tf_keras.optimizers.schedules.ExponentialDecay(
         initial_learning_rate=initial_lr,
         decay_steps=decay_steps,
         decay_rate=decay_rate)
     lr = learning_rate.WarmupDecaySchedule(
         lr_schedule=base_lr, warmup_steps=warmup_steps)
 
     for step in range(warmup_steps - 1):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/mnist_main.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/mnist_main.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,50 +19,50 @@
 
 import os
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 from official.common import distribute_utils
 from official.legacy.image_classification.resnet import common
 from official.utils.flags import core as flags_core
 from official.utils.misc import model_helpers
 
 FLAGS = flags.FLAGS
 
 
 def build_model():
   """Constructs the ML model used to predict handwritten digits."""
 
-  image = tf.keras.layers.Input(shape=(28, 28, 1))
+  image = tf_keras.layers.Input(shape=(28, 28, 1))
 
-  y = tf.keras.layers.Conv2D(filters=32,
+  y = tf_keras.layers.Conv2D(filters=32,
                              kernel_size=5,
                              padding='same',
                              activation='relu')(image)
-  y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
+  y = tf_keras.layers.MaxPooling2D(pool_size=(2, 2),
                                    strides=(2, 2),
                                    padding='same')(y)
-  y = tf.keras.layers.Conv2D(filters=32,
+  y = tf_keras.layers.Conv2D(filters=32,
                              kernel_size=5,
                              padding='same',
                              activation='relu')(y)
-  y = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),
+  y = tf_keras.layers.MaxPooling2D(pool_size=(2, 2),
                                    strides=(2, 2),
                                    padding='same')(y)
-  y = tf.keras.layers.Flatten()(y)
-  y = tf.keras.layers.Dense(1024, activation='relu')(y)
-  y = tf.keras.layers.Dropout(0.4)(y)
+  y = tf_keras.layers.Flatten()(y)
+  y = tf_keras.layers.Dense(1024, activation='relu')(y)
+  y = tf_keras.layers.Dropout(0.4)(y)
 
-  probs = tf.keras.layers.Dense(10, activation='softmax')(y)
+  probs = tf_keras.layers.Dense(10, activation='softmax')(y)
 
-  model = tf.keras.models.Model(image, probs, name='mnist')
+  model = tf_keras.models.Model(image, probs, name='mnist')
 
   return model
 
 
 @tfds.decode.make_decoder(output_dtype=tf.float32)
 def decode_image(example, feature):
   """Convert image to float32 and normalize from [0, 255] to [0.0, 1.0]."""
@@ -100,33 +100,33 @@
       decoders={'image': decode_image()},  # pylint: disable=no-value-for-parameter
       as_supervised=True)
   train_input_dataset = mnist_train.cache().repeat().shuffle(
       buffer_size=50000).batch(flags_obj.batch_size)
   eval_input_dataset = mnist_test.cache().repeat().batch(flags_obj.batch_size)
 
   with strategy_scope:
-    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
+    lr_schedule = tf_keras.optimizers.schedules.ExponentialDecay(
         0.05, decay_steps=100000, decay_rate=0.96)
-    optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule)
+    optimizer = tf_keras.optimizers.SGD(learning_rate=lr_schedule)
 
     model = build_model()
     model.compile(
         optimizer=optimizer,
         loss='sparse_categorical_crossentropy',
         metrics=['sparse_categorical_accuracy'])
 
   num_train_examples = mnist.info.splits['train'].num_examples
   train_steps = num_train_examples // flags_obj.batch_size
   train_epochs = flags_obj.train_epochs
 
   ckpt_full_path = os.path.join(flags_obj.model_dir, 'model.ckpt-{epoch:04d}')
   callbacks = [
-      tf.keras.callbacks.ModelCheckpoint(
+      tf_keras.callbacks.ModelCheckpoint(
           ckpt_full_path, save_weights_only=True),
-      tf.keras.callbacks.TensorBoard(log_dir=flags_obj.model_dir),
+      tf_keras.callbacks.TensorBoard(log_dir=flags_obj.model_dir),
   ]
 
   num_eval_examples = mnist.info.splits['test'].num_examples
   num_eval_steps = num_eval_examples // flags_obj.batch_size
 
   history = model.fit(
       train_input_dataset,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/mnist_test.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/mnist_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import functools
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.legacy.image_classification import mnist_main
 from official.utils.testing import integration
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/optimizer_factory_test.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/optimizer_factory_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,25 +16,25 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 from absl.testing import parameterized
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.image_classification import optimizer_factory
 from official.legacy.image_classification.configs import base_configs
 
 
 class OptimizerFactoryTest(tf.test.TestCase, parameterized.TestCase):
 
-  def build_toy_model(self) -> tf.keras.Model:
+  def build_toy_model(self) -> tf_keras.Model:
     """Creates a toy `tf.Keras.Model`."""
-    model = tf.keras.Sequential()
-    model.add(tf.keras.layers.Dense(1, input_shape=(1,)))
+    model = tf_keras.Sequential()
+    model.add(tf_keras.layers.Dense(1, input_shape=(1,)))
     return model
 
   @parameterized.named_parameters(
       ('sgd', 'sgd', 0., False), ('momentum', 'momentum', 0., False),
       ('rmsprop', 'rmsprop', 0., False), ('adam', 'adam', 0., False),
       ('adamw', 'adamw', 0., False),
       ('momentum_lookahead', 'momentum', 0., True),
@@ -53,15 +53,17 @@
         'lookahead': lookahead,
     }
     optimizer = optimizer_factory.build_optimizer(
         optimizer_name=optimizer_name,
         base_learning_rate=params['learning_rate'],
         params=params,
         model=model)
-    self.assertTrue(issubclass(type(optimizer), tf.keras.optimizers.Optimizer))
+    self.assertTrue(
+        issubclass(type(optimizer), tf_keras.optimizers.legacy.Optimizer)
+    )
 
   def test_unknown_optimizer(self):
     with self.assertRaises(ValueError):
       optimizer_factory.build_optimizer(
           optimizer_name='this_optimizer_does_not_exist',
           base_learning_rate=None,
           params=None)
@@ -80,15 +82,15 @@
     batch_size = 1
     train_steps = 1
 
     lr = optimizer_factory.build_learning_rate(
         params=params, batch_size=batch_size, train_steps=train_steps)
     self.assertTrue(
         issubclass(
-            type(lr), tf.keras.optimizers.schedules.LearningRateSchedule))
+            type(lr), tf_keras.optimizers.schedules.LearningRateSchedule))
 
   @parameterized.named_parameters(('exponential', 'exponential'),
                                   ('cosine_with_warmup', 'cosine_with_warmup'))
   def test_learning_rate_with_decay_and_warmup(self, lr_decay_type):
     """Basic smoke test for syntax."""
     params = base_configs.LearningRateConfig(
         name=lr_decay_type,
@@ -107,12 +109,12 @@
     lr = optimizer_factory.build_learning_rate(
         params=params,
         batch_size=batch_size,
         train_epochs=train_epochs,
         train_steps=train_steps)
     self.assertTrue(
         issubclass(
-            type(lr), tf.keras.optimizers.schedules.LearningRateSchedule))
+            type(lr), tf_keras.optimizers.schedules.LearningRateSchedule))
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/preprocessing.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/preprocessing.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Preprocessing functions for images."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 from typing import List, Optional, Text, Tuple
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.image_classification import augment
 
 
 # Calculated from the ImageNet training set
 MEAN_RGB = (0.485 * 255, 0.456 * 255, 0.406 * 255)
 STDDEV_RGB = (0.229 * 255, 0.224 * 255, 0.225 * 255)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/common.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/common.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,30 +16,30 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import os
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 import tensorflow_model_optimization as tfmot
 from official.utils.flags import core as flags_core
 from official.utils.misc import keras_utils
 
 FLAGS = flags.FLAGS
 BASE_LEARNING_RATE = 0.1  # This matches Jing's version.
 TRAIN_TOP_1 = 'training_accuracy_top_1'
 LR_SCHEDULE = [  # (multiplier, epoch to start) tuples
     (1.0, 5), (0.1, 30), (0.01, 60), (0.001, 80)
 ]
 
 
 class PiecewiseConstantDecayWithWarmup(
-    tf.keras.optimizers.schedules.LearningRateSchedule):
+    tf_keras.optimizers.schedules.LearningRateSchedule):
   """Piecewise constant decay with warmup schedule."""
 
   def __init__(self,
                batch_size,
                epoch_size,
                warmup_epochs,
                boundaries,
@@ -106,32 +106,32 @@
     }
 
 
 def get_optimizer(learning_rate=0.1, use_legacy_optimizer=True):
   """Returns optimizer to use."""
   # The learning_rate is overwritten at the beginning of each step by callback.
   if use_legacy_optimizer:
-    return tf.keras.optimizers.legacy.SGD(
+    return tf_keras.optimizers.legacy.SGD(
         learning_rate=learning_rate, momentum=0.9)
   else:
-    return tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)
+    return tf_keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)
 
 
 def get_callbacks(pruning_method=None,
                   enable_checkpoint_and_export=False,
                   model_dir=None):
   """Returns common callbacks."""
   time_callback = keras_utils.TimeHistory(
       FLAGS.batch_size,
       FLAGS.log_steps,
       logdir=FLAGS.model_dir if FLAGS.enable_tensorboard else None)
   callbacks = [time_callback]
 
   if FLAGS.enable_tensorboard:
-    tensorboard_callback = tf.keras.callbacks.TensorBoard(
+    tensorboard_callback = tf_keras.callbacks.TensorBoard(
         log_dir=FLAGS.model_dir, profile_batch=FLAGS.profile_steps)
     callbacks.append(tensorboard_callback)
 
   is_pruning_enabled = pruning_method is not None
   if is_pruning_enabled:
     callbacks.append(tfmot.sparsity.keras.UpdatePruningStep())
     if model_dir is not None:
@@ -139,15 +139,15 @@
           tfmot.sparsity.keras.PruningSummaries(
               log_dir=model_dir, profile_batch=0))
 
   if enable_checkpoint_and_export:
     if model_dir is not None:
       ckpt_full_path = os.path.join(model_dir, 'model.ckpt-{epoch:04d}')
       callbacks.append(
-          tf.keras.callbacks.ModelCheckpoint(
+          tf_keras.callbacks.ModelCheckpoint(
               ckpt_full_path, save_weights_only=True))
   return callbacks
 
 
 def build_stats(history, eval_output, callbacks):
   """Normalizes and returns dictionary of stats.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/imagenet_preprocessing.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/imagenet_preprocessing.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -34,15 +34,15 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import os
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 DEFAULT_IMAGE_SIZE = 224
 NUM_CHANNELS = 3
 NUM_CLASSES = 1001
 
 NUM_IMAGES = {
     'train': 1281167,
@@ -253,30 +253,30 @@
 
 def get_parse_record_fn(use_keras_image_data_format=False):
   """Get a function for parsing the records, accounting for image format.
 
   This is useful by handling different types of Keras models. For instance,
   the current resnet_model.resnet50 input format is always channel-last,
   whereas the keras_applications mobilenet input format depends on
-  tf.keras.backend.image_data_format(). We should set
+  tf_keras.backend.image_data_format(). We should set
   use_keras_image_data_format=False for the former and True for the latter.
 
   Args:
     use_keras_image_data_format: A boolean denoting whether data format is keras
       backend image data format. If False, the image format is channel-last. If
-      True, the image format matches tf.keras.backend.image_data_format().
+      True, the image format matches tf_keras.backend.image_data_format().
 
   Returns:
     Function to use for parsing the records.
   """
 
   def parse_record_fn(raw_record, is_training, dtype):
     image, label = parse_record(raw_record, is_training, dtype)
     if use_keras_image_data_format:
-      if tf.keras.backend.image_data_format() == 'channels_first':
+      if tf_keras.backend.image_data_format() == 'channels_first':
         image = tf.transpose(image, perm=[2, 0, 1])
     return image, label
 
   return parse_record_fn
 
 
 def input_fn(is_training,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/resnet_config.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/vgg/vgg_config.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,55 +1,55 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Configuration definitions for ResNet losses, learning rates, and optimizers."""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
+"""Configuration definitions for VGG losses, learning rates, and optimizers."""
 
 import dataclasses
 from official.legacy.image_classification.configs import base_configs
 from official.modeling.hyperparams import base_config
 
 
 @dataclasses.dataclass
-class ResNetModelConfig(base_configs.ModelConfig):
-  """Configuration for the ResNet model."""
-  name: str = 'ResNet'
+class VGGModelConfig(base_configs.ModelConfig):
+  """Configuration for the VGG model."""
+  name: str = 'VGG'
   num_classes: int = 1000
-  model_params: base_config.Config = dataclasses.field(
-      # pylint: disable=g-long-lambda
-      default_factory=lambda: {
-          'num_classes': 1000,
-          'batch_size': None,
-          'use_l2_regularizer': True,
-          'rescale_inputs': False,
-      })
-  # pylint: enable=g-long-lambda
-  loss: base_configs.LossConfig = base_configs.LossConfig(
-      name='sparse_categorical_crossentropy')
-  optimizer: base_configs.OptimizerConfig = base_configs.OptimizerConfig(
-      name='momentum',
-      decay=0.9,
-      epsilon=0.001,
-      momentum=0.9,
-      moving_average_decay=None)
-  learning_rate: base_configs.LearningRateConfig = (
-      base_configs.LearningRateConfig(
+  model_params: base_config.Config = dataclasses.field(default_factory=lambda: {   # pylint:disable=g-long-lambda
+      'num_classes': 1000,
+      'batch_size': None,
+      'use_l2_regularizer': True
+  })
+  loss: base_configs.LossConfig = dataclasses.field(
+      default_factory=lambda: base_configs.LossConfig(  # pylint: disable=g-long-lambda
+          name='sparse_categorical_crossentropy'
+      )
+  )
+  optimizer: base_configs.OptimizerConfig = dataclasses.field(
+      default_factory=lambda: base_configs.OptimizerConfig(  # pylint: disable=g-long-lambda
+          name='momentum',
+          epsilon=0.001,
+          momentum=0.9,
+          moving_average_decay=None,
+      )
+  )
+  learning_rate: base_configs.LearningRateConfig = dataclasses.field(
+      default_factory=lambda: base_configs.LearningRateConfig(  # pylint: disable=g-long-lambda
           name='stepwise',
-          initial_lr=0.1,
+          initial_lr=0.01,
           examples_per_epoch=1281167,
-          boundaries=[30, 60, 80],
-          warmup_epochs=5,
-          scale_by_batch_size=1. / 256.,
-          multipliers=[0.1 / 256, 0.01 / 256, 0.001 / 256, 0.0001 / 256]))
+          boundaries=[30, 60],
+          warmup_epochs=0,
+          scale_by_batch_size=1.0 / 256.0,
+          multipliers=[0.01 / 256, 0.001 / 256, 0.0001 / 256],
+      )
+  )
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/resnet_ctl_imagenet_main.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/resnet_ctl_imagenet_main.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,15 +18,15 @@
 import os
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.common import distribute_utils
 from official.legacy.image_classification.resnet import common
 from official.legacy.image_classification.resnet import imagenet_preprocessing
 from official.legacy.image_classification.resnet import resnet_runnable
 from official.modeling import performance
 from official.utils.flags import core as flags_core
 from official.utils.misc import keras_utils
@@ -109,15 +109,15 @@
           datasets_num_private_threads=flags_obj.datasets_num_private_threads)
     common.set_cudnn_batchnorm_mode()
 
   data_format = flags_obj.data_format
   if data_format is None:
     data_format = ('channels_first' if tf.config.list_physical_devices('GPU')
                    else 'channels_last')
-  tf.keras.backend.set_image_data_format(data_format)
+  tf_keras.backend.set_image_data_format(data_format)
 
   strategy = distribute_utils.get_distribution_strategy(
       distribution_strategy=flags_obj.distribution_strategy,
       num_gpus=flags_obj.num_gpus,
       all_reduce_alg=flags_obj.all_reduce_alg,
       num_packs=flags_obj.num_packs,
       tpu_address=flags_obj.tpu)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/resnet_model.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/resnet_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,35 +10,35 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """ResNet50 model for Keras.
 
-Adapted from tf.keras.applications.resnet50.ResNet50().
+Adapted from tf_keras.applications.resnet50.ResNet50().
 This is ResNet model version 1.5.
 
 Related papers/blogs:
 - https://arxiv.org/abs/1512.03385
 - https://arxiv.org/pdf/1603.05027v2.pdf
 - http://torch.ch/blog/2016/02/04/resnets.html
 
 """
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.image_classification.resnet import imagenet_preprocessing
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 
 def _gen_l2_regularizer(use_l2_regularizer=True, l2_weight_decay=1e-4):
-  return tf.keras.regularizers.L2(
+  return tf_keras.regularizers.L2(
       l2_weight_decay) if use_l2_regularizer else None
 
 
 def identity_block(input_tensor,
                    kernel_size,
                    filters,
                    stage,
@@ -58,15 +58,15 @@
     batch_norm_decay: Moment of batch norm layers.
     batch_norm_epsilon: Epsilon of batch borm layers.
 
   Returns:
     Output tensor for the block.
   """
   filters1, filters2, filters3 = filters
-  if tf.keras.backend.image_data_format() == 'channels_last':
+  if tf_keras.backend.image_data_format() == 'channels_last':
     bn_axis = 3
   else:
     bn_axis = 1
   conv_name_base = 'res' + str(stage) + block + '_branch'
   bn_name_base = 'bn' + str(stage) + block + '_branch'
 
   x = layers.Conv2D(
@@ -146,15 +146,15 @@
     batch_norm_decay: Moment of batch norm layers.
     batch_norm_epsilon: Epsilon of batch borm layers.
 
   Returns:
     Output tensor for the block.
   """
   filters1, filters2, filters3 = filters
-  if tf.keras.backend.image_data_format() == 'channels_last':
+  if tf_keras.backend.image_data_format() == 'channels_last':
     bn_axis = 3
   else:
     bn_axis = 1
   conv_name_base = 'res' + str(stage) + block + '_branch'
   bn_name_base = 'bn' + str(stage) + block + '_branch'
 
   x = layers.Conv2D(
@@ -245,24 +245,24 @@
   """
   input_shape = (224, 224, 3)
   img_input = layers.Input(shape=input_shape, batch_size=batch_size)
   if rescale_inputs:
     # Hub image modules expect inputs in the range [0, 1]. This rescales these
     # inputs to the range expected by the trained model.
     x = layers.Lambda(
-        lambda x: x * 255.0 - tf.keras.backend.constant(    # pylint: disable=g-long-lambda
+        lambda x: x * 255.0 - tf_keras.backend.constant(    # pylint: disable=g-long-lambda
             imagenet_preprocessing.CHANNEL_MEANS,
             shape=[1, 1, 3],
             dtype=x.dtype),
         name='rescale')(
             img_input)
   else:
     x = img_input
 
-  if tf.keras.backend.image_data_format() == 'channels_first':
+  if tf_keras.backend.image_data_format() == 'channels_first':
     x = layers.Permute((3, 1, 2))(x)
     bn_axis = 1
   else:  # channels_last
     bn_axis = 3
 
   block_config = dict(
       use_l2_regularizer=use_l2_regularizer,
@@ -318,8 +318,8 @@
           x)
 
   # A softmax that is followed by the model loss must be done cannot be done
   # in float16 due to numeric issues. So we pass dtype=float32.
   x = layers.Activation('softmax', dtype='float32')(x)
 
   # Create model.
-  return tf.keras.Model(img_input, x, name='resnet50')
+  return tf_keras.Model(img_input, x, name='resnet50')
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/resnet_runnable.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/resnet_runnable.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Runs a ResNet model on the ImageNet dataset using custom training loops."""
 
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.image_classification.resnet import common
 from official.legacy.image_classification.resnet import imagenet_preprocessing
 from official.legacy.image_classification.resnet import resnet_model
 from official.modeling import grad_utils
 from official.modeling import performance
 from official.utils.flags import core as flags_core
 
@@ -72,19 +72,19 @@
     # Make sure iterations variable is created inside scope.
     self.global_step = self.optimizer.iterations
     self.optimizer = performance.configure_optimizer(
         self.optimizer,
         use_float16=self.dtype == tf.float16,
         loss_scale=flags_core.get_loss_scale(flags_obj, default_for_fp16=128))
 
-    self.train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)
-    self.train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
+    self.train_loss = tf_keras.metrics.Mean('train_loss', dtype=tf.float32)
+    self.train_accuracy = tf_keras.metrics.SparseCategoricalAccuracy(
         'train_accuracy', dtype=tf.float32)
-    self.test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)
-    self.test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
+    self.test_loss = tf_keras.metrics.Mean('test_loss', dtype=tf.float32)
+    self.test_accuracy = tf_keras.metrics.SparseCategoricalAccuracy(
         'test_accuracy', dtype=tf.float32)
 
     self.checkpoint = tf.train.Checkpoint(
         model=self.model, optimizer=self.optimizer)
 
     # Handling epochs.
     self.epoch_steps = epoch_steps
@@ -136,15 +136,15 @@
 
     def step_fn(inputs):
       """Function to run on the device."""
       images, labels = inputs
       with tf.GradientTape() as tape:
         logits = self.model(images, training=True)
 
-        prediction_loss = tf.keras.losses.sparse_categorical_crossentropy(
+        prediction_loss = tf_keras.losses.sparse_categorical_crossentropy(
             labels, logits)
         loss = tf.reduce_sum(prediction_loss) * (1.0 /
                                                  self.flags_obj.batch_size)
         num_replicas = self.strategy.num_replicas_in_sync
         l2_weight_decay = 1e-4
         if self.flags_obj.single_l2_loss_op:
           l2_loss = l2_weight_decay * 2 * tf.add_n([
@@ -183,15 +183,15 @@
   def eval_step(self, iterator):
     """See base class."""
 
     def step_fn(inputs):
       """Function to run on the device."""
       images, labels = inputs
       logits = self.model(images, training=False)
-      loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits)
+      loss = tf_keras.losses.sparse_categorical_crossentropy(labels, logits)
       loss = tf.reduce_sum(loss) * (1.0 / self.flags_obj.batch_size)
       self.test_loss.update_state(loss)
       self.test_accuracy.update_state(labels, logits)
 
     self.strategy.run(step_fn, args=(next(iterator),))
 
   def eval_end(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/resnet/tfhub_export.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/resnet/tfhub_export.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,39 +20,39 @@
 
 import os
 
 # Import libraries
 from absl import app
 from absl import flags
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.image_classification.resnet import imagenet_preprocessing
 from official.legacy.image_classification.resnet import resnet_model
 
 FLAGS = flags.FLAGS
 
 flags.DEFINE_string("model_path", None,
                     "File path to TF model checkpoint or H5 file.")
 flags.DEFINE_string("export_path", None,
                     "TF-Hub SavedModel destination path to export.")
 
 
 def export_tfhub(model_path, hub_destination):
-  """Restores a tf.keras.Model and saves for TF-Hub."""
+  """Restores a tf_keras.Model and saves for TF-Hub."""
   model = resnet_model.resnet50(
       num_classes=imagenet_preprocessing.NUM_CLASSES, rescale_inputs=True)
   model.load_weights(model_path)
   model.save(
       os.path.join(hub_destination, "classification"), include_optimizer=False)
 
   # Extracts a sub-model to use pooling feature vector as model output.
   image_input = model.get_layer(index=0).get_output_at(0)
   feature_vector_output = model.get_layer(name="reduce_mean").get_output_at(0)
-  hub_model = tf.keras.Model(image_input, feature_vector_output)
+  hub_model = tf_keras.Model(image_input, feature_vector_output)
 
   # Exports a SavedModel.
   hub_model.save(
       os.path.join(hub_destination, "feature-vector"), include_optimizer=False)
 
 
 def main(argv):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/test_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/test_utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,24 +14,24 @@
 
 """Test utilities for image classification tasks."""
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def trivial_model(num_classes):
   """Trivial model for ImageNet dataset."""
 
   input_shape = (224, 224, 3)
-  img_input = tf.keras.layers.Input(shape=input_shape)
+  img_input = tf_keras.layers.Input(shape=input_shape)
 
-  x = tf.keras.layers.Lambda(
-      lambda x: tf.keras.backend.reshape(x, [-1, 224 * 224 * 3]),
+  x = tf_keras.layers.Lambda(
+      lambda x: tf_keras.backend.reshape(x, [-1, 224 * 224 * 3]),
       name='reshape')(img_input)
-  x = tf.keras.layers.Dense(1, name='fc1')(x)
-  x = tf.keras.layers.Dense(num_classes, name='fc1000')(x)
-  x = tf.keras.layers.Activation('softmax', dtype='float32')(x)
+  x = tf_keras.layers.Dense(1, name='fc1')(x)
+  x = tf_keras.layers.Dense(num_classes, name='fc1000')(x)
+  x = tf_keras.layers.Activation('softmax', dtype='float32')(x)
 
-  return tf.keras.models.Model(img_input, x, name='trivial')
+  return tf_keras.models.Model(img_input, x, name='trivial')
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/vgg/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/vgg/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/vgg/vgg_config.py` & `tf-models-no-deps-2.16.0/official/nlp/configs/electra.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,44 +1,40 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Configuration definitions for VGG losses, learning rates, and optimizers."""
+"""ELECTRA model configurations and instantiation methods."""
+from typing import List
 
 import dataclasses
-from official.legacy.image_classification.configs import base_configs
+
 from official.modeling.hyperparams import base_config
+from official.nlp.configs import bert
+from official.nlp.configs import encoders
 
 
 @dataclasses.dataclass
-class VGGModelConfig(base_configs.ModelConfig):
-  """Configuration for the VGG model."""
-  name: str = 'VGG'
-  num_classes: int = 1000
-  model_params: base_config.Config = dataclasses.field(default_factory=lambda: {   # pylint:disable=g-long-lambda
-      'num_classes': 1000,
-      'batch_size': None,
-      'use_l2_regularizer': True
-  })
-  loss: base_configs.LossConfig = base_configs.LossConfig(
-      name='sparse_categorical_crossentropy')
-  optimizer: base_configs.OptimizerConfig = base_configs.OptimizerConfig(
-      name='momentum', epsilon=0.001, momentum=0.9, moving_average_decay=None)
-  learning_rate: base_configs.LearningRateConfig = (
-      base_configs.LearningRateConfig(
-          name='stepwise',
-          initial_lr=0.01,
-          examples_per_epoch=1281167,
-          boundaries=[30, 60],
-          warmup_epochs=0,
-          scale_by_batch_size=1. / 256.,
-          multipliers=[0.01 / 256, 0.001 / 256, 0.0001 / 256]))
+class ElectraPretrainerConfig(base_config.Config):
+  """ELECTRA pretrainer configuration."""
+  num_masked_tokens: int = 76
+  sequence_length: int = 512
+  num_classes: int = 2
+  discriminator_loss_weight: float = 50.0
+  tie_embeddings: bool = True
+  disallow_correct: bool = False
+  generator_encoder: encoders.EncoderConfig = dataclasses.field(
+      default_factory=encoders.EncoderConfig
+  )
+  discriminator_encoder: encoders.EncoderConfig = dataclasses.field(
+      default_factory=encoders.EncoderConfig
+  )
+  cls_heads: List[bert.ClsHeadConfig] = dataclasses.field(default_factory=list)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/image_classification/vgg/vgg_model.py` & `tf-models-no-deps-2.16.0/official/legacy/image_classification/vgg/vgg_model.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,27 +10,27 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """VGG16 model for Keras.
 
-Adapted from tf.keras.applications.vgg16.VGG16().
+Adapted from tf_keras.applications.vgg16.VGG16().
 
 Related papers/blogs:
 - https://arxiv.org/abs/1409.1556
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 
 def _gen_l2_regularizer(use_l2_regularizer=True, l2_weight_decay=1e-4):
-  return tf.keras.regularizers.L2(
+  return tf_keras.regularizers.L2(
       l2_weight_decay) if use_l2_regularizer else None
 
 
 def vgg16(num_classes,
           batch_size=None,
           use_l2_regularizer=True,
           batch_norm_decay=0.9,
@@ -49,15 +49,15 @@
 
   """
   input_shape = (224, 224, 3)
   img_input = layers.Input(shape=input_shape, batch_size=batch_size)
 
   x = img_input
 
-  if tf.keras.backend.image_data_format() == 'channels_first':
+  if tf_keras.backend.image_data_format() == 'channels_first':
     x = layers.Permute((3, 1, 2))(x)
     bn_axis = 1
   else:  # channels_last
     bn_axis = 3
   # Block 1
   x = layers.Conv2D(
       64, (3, 3),
@@ -262,8 +262,8 @@
       kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),
       name='fc1000')(
           x)
 
   x = layers.Activation('softmax', dtype='float32')(x)
 
   # Create model.
-  return tf.keras.Model(img_input, x, name='vgg16')
+  return tf_keras.Model(img_input, x, name='vgg16')
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/attention_layer.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/attention_layer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,20 +11,20 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Implementation of multiheaded attention and self-attention layers."""
 import math
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
-class Attention(tf.keras.layers.Layer):
+class Attention(tf_keras.layers.Layer):
   """Multi-headed attention layer."""
 
   def __init__(self, hidden_size, num_heads, attention_dropout):
     """Initialize Attention.
 
     Args:
       hidden_size: int, output dim of hidden layer.
@@ -44,39 +44,39 @@
   def build(self, input_shape):
     """Builds the layer."""
     # Layers for linearly projecting the queries, keys, and values.
     size_per_head = self.hidden_size // self.num_heads
 
     def _glorot_initializer(fan_in, fan_out):
       limit = math.sqrt(6.0 / (fan_in + fan_out))
-      return tf.keras.initializers.RandomUniform(minval=-limit, maxval=limit)
+      return tf_keras.initializers.RandomUniform(minval=-limit, maxval=limit)
 
     attention_initializer = _glorot_initializer(input_shape.as_list()[-1],
                                                 self.hidden_size)
-    self.query_dense_layer = tf.keras.layers.EinsumDense(
+    self.query_dense_layer = tf_keras.layers.EinsumDense(
         "BTE,ENH->BTNH",
         output_shape=(None, self.num_heads, size_per_head),
         kernel_initializer=tf_utils.clone_initializer(attention_initializer),
         bias_axes=None,
         name="query")
-    self.key_dense_layer = tf.keras.layers.EinsumDense(
+    self.key_dense_layer = tf_keras.layers.EinsumDense(
         "BTE,ENH->BTNH",
         output_shape=(None, self.num_heads, size_per_head),
         kernel_initializer=tf_utils.clone_initializer(attention_initializer),
         bias_axes=None,
         name="key")
-    self.value_dense_layer = tf.keras.layers.EinsumDense(
+    self.value_dense_layer = tf_keras.layers.EinsumDense(
         "BTE,ENH->BTNH",
         output_shape=(None, self.num_heads, size_per_head),
         kernel_initializer=tf_utils.clone_initializer(attention_initializer),
         bias_axes=None,
         name="value")
 
     output_initializer = _glorot_initializer(self.hidden_size, self.hidden_size)
-    self.output_dense_layer = tf.keras.layers.EinsumDense(
+    self.output_dense_layer = tf_keras.layers.EinsumDense(
         "BTNH,NHE->BTE",
         output_shape=(None, self.hidden_size),
         kernel_initializer=output_initializer,
         bias_axes=None,
         name="output_transform")
     super(Attention, self).build(input_shape)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/beam_search_v1.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/beam_search_v1.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/compute_bleu.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/compute_bleu.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -23,15 +23,15 @@
 import unicodedata
 
 from absl import app
 from absl import flags
 from absl import logging
 import six
 from six.moves import range
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer.utils import metrics
 from official.legacy.transformer.utils import tokenizer
 from official.utils.flags import core as flags_core
 
 
 class UnicodeRegex(object):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/compute_bleu_test.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/compute_bleu_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Test functions in compute_blue.py."""
 
 import tempfile
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import compute_bleu
 
 
 class ComputeBleuTest(tf.test.TestCase):
 
   def _create_temp_file(self, text):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/data_download.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/data_download.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/data_pipeline.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/data_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -46,15 +46,15 @@
    `parallel_interleave`, the `sloppy` argument is used to generate randomness
    in the order of the examples.
 """
 
 import os
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.utils.misc import model_helpers
 
 # Buffer size for reading records from a TFRecord file. Each training file is
 # 7.2 MB, so 8 MB allows an entire file to be kept in memory.
 _READ_RECORD_BUFFER = 8 * 1000 * 1000
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/embedding_layer.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/embedding_layer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,18 +10,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Implementation of embedding layer with shared weights."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-class EmbeddingSharedWeights(tf.keras.layers.Layer):
+class EmbeddingSharedWeights(tf_keras.layers.Layer):
   """Calculates input embeddings and pre-softmax linear with shared weights."""
 
   def __init__(self, vocab_size, hidden_size):
     """Specify characteristic parameters of embedding layer.
 
     Args:
       vocab_size: Number of tokens in the embedding. (Typically ~32,000)
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/ffn_layer.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/ffn_layer.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,18 +10,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Implementation of fully connected network."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-class FeedForwardNetwork(tf.keras.layers.Layer):
+class FeedForwardNetwork(tf_keras.layers.Layer):
   """Fully connected feedforward network."""
 
   def __init__(self, hidden_size, filter_size, relu_dropout):
     """Initialize FeedForwardNetwork.
 
     Args:
       hidden_size: int, output dim of hidden layer.
@@ -30,20 +30,20 @@
     """
     super(FeedForwardNetwork, self).__init__()
     self.hidden_size = hidden_size
     self.filter_size = filter_size
     self.relu_dropout = relu_dropout
 
   def build(self, input_shape):
-    self.filter_dense_layer = tf.keras.layers.Dense(
+    self.filter_dense_layer = tf_keras.layers.Dense(
         self.filter_size,
         use_bias=True,
         activation=tf.nn.relu,
         name="filter_layer")
-    self.output_dense_layer = tf.keras.layers.Dense(
+    self.output_dense_layer = tf_keras.layers.Dense(
         self.hidden_size, use_bias=True, name="output_layer")
     super(FeedForwardNetwork, self).build(input_shape)
 
   def get_config(self):
     return {
         "hidden_size": self.hidden_size,
         "filter_size": self.filter_size,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/metrics.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/metrics.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,15 +21,15 @@
      https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/bleu_hook.py
  - ROUGE score. Source:
      https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/rouge.py
 """
 
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _pad_tensors_to_same_length(x, y):
   """Pad x and y so that the results have the same length (second dimension)."""
   with tf.name_scope("pad_to_same_length"):
     x_length = tf.shape(x)[1]
     y_length = tf.shape(y)[1]
@@ -127,32 +127,32 @@
 
 def padded_neg_log_perplexity(logits, labels, vocab_size):
   """Average log-perplexity excluding padding 0s. No smoothing."""
   num, den = padded_cross_entropy_loss(logits, labels, 0, vocab_size)
   return -num, den
 
 
-class MetricLayer(tf.keras.layers.Layer):
+class MetricLayer(tf_keras.layers.Layer):
   """Custom a layer of metrics for Transformer model."""
 
   def __init__(self, vocab_size):
     super(MetricLayer, self).__init__()
     self.vocab_size = vocab_size
     self.metric_mean_fns = []
 
   def build(self, input_shape):
     """"Builds metric layer."""
     neg_log_perplexity = functools.partial(
         padded_neg_log_perplexity, vocab_size=self.vocab_size)
     self.metric_mean_fns = [
-        (tf.keras.metrics.Mean("accuracy"), padded_accuracy),
-        (tf.keras.metrics.Mean("accuracy_top5"), padded_accuracy_top5),
-        (tf.keras.metrics.Mean("accuracy_per_sequence"),
+        (tf_keras.metrics.Mean("accuracy"), padded_accuracy),
+        (tf_keras.metrics.Mean("accuracy_top5"), padded_accuracy_top5),
+        (tf_keras.metrics.Mean("accuracy_per_sequence"),
          padded_sequence_accuracy),
-        (tf.keras.metrics.Mean("neg_log_perplexity"), neg_log_perplexity),
+        (tf_keras.metrics.Mean("neg_log_perplexity"), neg_log_perplexity),
     ]
     super(MetricLayer, self).build(input_shape)
 
   def get_config(self):
     return {"vocab_size": self.vocab_size}
 
   def call(self, inputs):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/misc.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/misc.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Misc for Transformer."""
 
 # pylint: disable=g-bad-import-order
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import model_params
 from official.utils.flags import core as flags_core
 from official.utils.misc import keras_utils
 
 FLAGS = flags.FLAGS
 
@@ -246,15 +246,15 @@
     time_callback = keras_utils.TimeHistory(
         FLAGS.batch_size,
         FLAGS.log_steps,
         logdir=FLAGS.model_dir if FLAGS.enable_tensorboard else None)
     callbacks.append(time_callback)
 
   if FLAGS.enable_tensorboard:
-    tensorboard_callback = tf.keras.callbacks.TensorBoard(
+    tensorboard_callback = tf_keras.callbacks.TensorBoard(
         log_dir=FLAGS.model_dir)
     callbacks.append(tensorboard_callback)
 
   return callbacks
 
 
 def update_stats(history, stats, callbacks):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/model_params.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/model_params.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/model_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/model_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Transformer model helper methods."""
 
 import math
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # Very low numbers to represent -infinity. We do not actually use -Inf, since we
 # want to be able to multiply these values by zero to get zero. (-Inf * 0 = NaN)
 _NEG_INF_FP32 = -1e9
 _NEG_INF_FP16 = np.finfo(np.float16).min
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/model_utils_test.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/model_utils_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Test Transformer model helper methods."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import model_utils
 
 NEG_INF = -1e9
 
 
 class ModelUtilsTest(tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/optimizer.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/optimizer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,18 +10,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Optimizer from addons and learning rate scheduler."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-class LearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
+class LearningRateSchedule(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Learning rate schedule."""
 
   def __init__(self, initial_learning_rate, hidden_size, warmup_steps):
     """Initialize configuration of the learning rate schedule.
 
     Args:
       initial_learning_rate: A float, the initial learning rate.
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/transformer.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/transformer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Defines the Transformer model in TF 2.0.
 
 Model paper: https://arxiv.org/pdf/1706.03762.pdf
 Transformer model code source: https://github.com/tensorflow/tensor2tensor
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import attention_layer
 from official.legacy.transformer import embedding_layer
 from official.legacy.transformer import ffn_layer
 from official.legacy.transformer import metrics
 from official.legacy.transformer import model_utils
 from official.legacy.transformer.utils.tokenizer import EOS_ID
@@ -34,40 +34,40 @@
 # pylint: disable=not-callable
 
 
 def create_model(params, is_train):
   """Creates transformer model."""
   with tf.name_scope("model"):
     if is_train:
-      inputs = tf.keras.layers.Input((None,), dtype="int64", name="inputs")
-      targets = tf.keras.layers.Input((None,), dtype="int64", name="targets")
+      inputs = tf_keras.layers.Input((None,), dtype="int64", name="inputs")
+      targets = tf_keras.layers.Input((None,), dtype="int64", name="targets")
       internal_model = Transformer(params, name="transformer_v2")
       logits = internal_model([inputs, targets], training=is_train)
       vocab_size = params["vocab_size"]
       label_smoothing = params["label_smoothing"]
       if params["enable_metrics_in_training"]:
         logits = metrics.MetricLayer(vocab_size)([logits, targets])
-      logits = tf.keras.layers.Lambda(
+      logits = tf_keras.layers.Lambda(
           lambda x: x, name="logits", dtype=tf.float32)(
               logits)
-      model = tf.keras.Model([inputs, targets], logits)
+      model = tf_keras.Model([inputs, targets], logits)
       loss = metrics.transformer_loss(logits, targets, label_smoothing,
                                       vocab_size)
       model.add_loss(loss)
       return model
 
     else:
-      inputs = tf.keras.layers.Input((None,), dtype="int64", name="inputs")
+      inputs = tf_keras.layers.Input((None,), dtype="int64", name="inputs")
       internal_model = Transformer(params, name="transformer_v2")
       ret = internal_model([inputs], training=is_train)
       outputs, scores = ret["outputs"], ret["scores"]
-      return tf.keras.Model(inputs, [outputs, scores])
+      return tf_keras.Model(inputs, [outputs, scores])
 
 
-class Transformer(tf.keras.Model):
+class Transformer(tf_keras.Model):
   """Transformer model with Keras.
 
   Implemented as described in: https://arxiv.org/pdf/1706.03762.pdf
 
   The Transformer model consists of an encoder and decoder. The input is an int
   sequence (or a batch of sequences). The encoder produces a continuous
   representation, and the decoder uses the encoder output to generate
@@ -335,26 +335,26 @@
     # Get the top sequence for each batch element
     top_decoded_ids = decoded_ids[:, 0, 1:]
     top_scores = scores[:, 0]
 
     return {"outputs": top_decoded_ids, "scores": top_scores}
 
 
-class PrePostProcessingWrapper(tf.keras.layers.Layer):
+class PrePostProcessingWrapper(tf_keras.layers.Layer):
   """Wrapper class that applies layer pre-processing and post-processing."""
 
   def __init__(self, layer, params):
     super(PrePostProcessingWrapper, self).__init__()
     self.layer = layer
     self.params = params
     self.postprocess_dropout = params["layer_postprocess_dropout"]
 
   def build(self, input_shape):
     # Create normalization layer
-    self.layer_norm = tf.keras.layers.LayerNormalization(
+    self.layer_norm = tf_keras.layers.LayerNormalization(
         epsilon=1e-6, dtype="float32")
     super(PrePostProcessingWrapper, self).build(input_shape)
 
   def get_config(self):
     return {
         "params": self.params,
     }
@@ -371,15 +371,15 @@
 
     # Postprocessing: apply dropout and residual connection
     if training:
       y = tf.nn.dropout(y, rate=self.postprocess_dropout)
     return x + y
 
 
-class EncoderStack(tf.keras.layers.Layer):
+class EncoderStack(tf_keras.layers.Layer):
   """Transformer encoder stack.
 
   The encoder stack is made up of N identical layers. Each layer is composed
   of the sublayers:
     1. Self-attention layer
     2. Feedforward network (which is 2 fully-connected layers)
   """
@@ -402,15 +402,15 @@
 
       self.layers.append([
           PrePostProcessingWrapper(self_attention_layer, params),
           PrePostProcessingWrapper(feed_forward_network, params)
       ])
 
     # Create final layer normalization layer.
-    self.output_normalization = tf.keras.layers.LayerNormalization(
+    self.output_normalization = tf_keras.layers.LayerNormalization(
         epsilon=1e-6, dtype="float32")
     super(EncoderStack, self).build(input_shape)
 
   def get_config(self):
     return {
         "params": self.params,
     }
@@ -442,15 +442,15 @@
         with tf.name_scope("ffn"):
           encoder_inputs = feed_forward_network(
               encoder_inputs, training=training)
 
     return self.output_normalization(encoder_inputs)
 
 
-class DecoderStack(tf.keras.layers.Layer):
+class DecoderStack(tf_keras.layers.Layer):
   """Transformer decoder stack.
 
   Like the encoder stack, the decoder stack is made up of N identical layers.
   Each layer is composed of the sublayers:
     1. Self-attention layer
     2. Multi-headed attention layer combining encoder outputs with results from
        the previous self-attention layer.
@@ -476,15 +476,15 @@
           params["hidden_size"], params["filter_size"], params["relu_dropout"])
 
       self.layers.append([
           PrePostProcessingWrapper(self_attention_layer, params),
           PrePostProcessingWrapper(enc_dec_attention_layer, params),
           PrePostProcessingWrapper(feed_forward_network, params)
       ])
-    self.output_normalization = tf.keras.layers.LayerNormalization(
+    self.output_normalization = tf_keras.layers.LayerNormalization(
         epsilon=1e-6, dtype="float32")
     super(DecoderStack, self).build(input_shape)
 
   def get_config(self):
     return {
         "params": self.params,
     }
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_forward_test.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_forward_test.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,30 +11,30 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Forward pass test for Transformer model refactoring."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import metrics
 from official.legacy.transformer import model_params
 from official.legacy.transformer import transformer
 from official.nlp.modeling import models
 
 
 def _count_params(layer, trainable_only=True):
   """Returns the count of all model parameters, or just trainable ones."""
   if not trainable_only:
     return layer.count_params()
   else:
     return int(
         np.sum([
-            tf.keras.backend.count_params(p) for p in layer.trainable_weights
+            tf_keras.backend.count_params(p) for p in layer.trainable_weights
         ]))
 
 
 def _create_model(params, is_train):
   """Creates transformer model."""
 
   encdec_kwargs = dict(
@@ -62,41 +62,41 @@
       beam_size=params["beam_size"],
       alpha=params["alpha"],
       encoder_layer=encoder_layer,
       decoder_layer=decoder_layer,
       name="transformer_v2")
 
   if is_train:
-    inputs = tf.keras.layers.Input((None,), dtype="int64", name="inputs")
-    targets = tf.keras.layers.Input((None,), dtype="int64", name="targets")
+    inputs = tf_keras.layers.Input((None,), dtype="int64", name="inputs")
+    targets = tf_keras.layers.Input((None,), dtype="int64", name="targets")
     internal_model = models.Seq2SeqTransformer(**model_kwargs)
     logits = internal_model(
         dict(inputs=inputs, targets=targets), training=is_train)
     vocab_size = params["vocab_size"]
     label_smoothing = params["label_smoothing"]
     if params["enable_metrics_in_training"]:
       logits = metrics.MetricLayer(vocab_size)([logits, targets])
-    logits = tf.keras.layers.Lambda(
+    logits = tf_keras.layers.Lambda(
         lambda x: x, name="logits", dtype=tf.float32)(
             logits)
-    model = tf.keras.Model([inputs, targets], logits)
+    model = tf_keras.Model([inputs, targets], logits)
     loss = metrics.transformer_loss(logits, targets, label_smoothing,
                                     vocab_size)
     model.add_loss(loss)
     return model
 
   batch_size = params["decode_batch_size"] if params["padded_decode"] else None
-  inputs = tf.keras.layers.Input((None,),
+  inputs = tf_keras.layers.Input((None,),
                                  batch_size=batch_size,
                                  dtype="int64",
                                  name="inputs")
   internal_model = models.Seq2SeqTransformer(**model_kwargs)
   ret = internal_model(dict(inputs=inputs), training=is_train)
   outputs, scores = ret["outputs"], ret["scores"]
-  return tf.keras.Model(inputs, [outputs, scores])
+  return tf_keras.Model(inputs, [outputs, scores])
 
 
 class TransformerForwardTest(tf.test.TestCase):
 
   def setUp(self):
     super(TransformerForwardTest, self).setUp()
     self.params = params = model_params.TINY_PARAMS
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_layers_test.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_layers_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for layers in Transformer."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import attention_layer
 from official.legacy.transformer import embedding_layer
 from official.legacy.transformer import ffn_layer
 from official.legacy.transformer import metrics
 
 
@@ -105,18 +105,18 @@
         1,
         length,
         hidden_size,
     ))
 
   def test_metric_layer(self):
     vocab_size = 50
-    logits = tf.keras.layers.Input((None, vocab_size),
+    logits = tf_keras.layers.Input((None, vocab_size),
                                    dtype="float32",
                                    name="logits")
-    targets = tf.keras.layers.Input((None,), dtype="int64", name="targets")
+    targets = tf_keras.layers.Input((None,), dtype="int64", name="targets")
     output_logits = metrics.MetricLayer(vocab_size)([logits, targets])
     self.assertEqual(output_logits.shape.as_list(), [
         None,
         None,
         vocab_size,
     ])
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_main.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_main.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,15 +22,15 @@
 import tempfile
 
 # Import libraries
 
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import distribute_utils
 from official.legacy.transformer import compute_bleu
 from official.legacy.transformer import data_pipeline
 from official.legacy.transformer import metrics
 from official.legacy.transformer import misc
 from official.legacy.transformer import optimizer
@@ -204,15 +204,15 @@
       latest_checkpoint = tf.train.latest_checkpoint(flags_obj.model_dir)
       if latest_checkpoint:
         checkpoint.restore(latest_checkpoint)
         logging.info("Loaded checkpoint %s", latest_checkpoint)
         current_step = opt.iterations.numpy()
 
       if params["use_ctl"]:
-        train_loss_metric = tf.keras.metrics.Mean(
+        train_loss_metric = tf_keras.metrics.Mean(
             "training_loss", dtype=tf.float32)
         if params["enable_tensorboard"]:
           summary_writer = tf.summary.create_file_writer(
               os.path.join(flags_obj.model_dir, "summary"))
         else:
           summary_writer = tf.summary.create_noop_writer()
         train_metrics = [train_loss_metric]
@@ -407,15 +407,15 @@
 
   def _create_callbacks(self, cur_log_dir, params):
     """Creates a list of callbacks."""
     callbacks = misc.get_callbacks()
     if params["enable_checkpointing"]:
       ckpt_full_path = os.path.join(cur_log_dir, "cp-{epoch:04d}.ckpt")
       callbacks.append(
-          tf.keras.callbacks.ModelCheckpoint(
+          tf_keras.callbacks.ModelCheckpoint(
               ckpt_full_path, save_weights_only=params["save_weights_only"]))
     return callbacks
 
   def _load_weights_if_possible(self, model, init_weight_path=None):
     """Loads model weights when it is provided."""
     if init_weight_path:
       logging.info("Load weights: {}".format(init_weight_path))
@@ -430,15 +430,15 @@
 
   def _create_optimizer(self):
     """Creates optimizer."""
     params = self.params
     lr_schedule = optimizer.LearningRateSchedule(
         params["learning_rate"], params["hidden_size"],
         params["learning_rate_warmup_steps"])
-    opt = tf.keras.optimizers.Adam(
+    opt = tf_keras.optimizers.Adam(
         lr_schedule,
         params["optimizer_adam_beta1"],
         params["optimizer_adam_beta2"],
         epsilon=params["optimizer_adam_epsilon"])
 
     opt = performance.configure_optimizer(
         opt,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_main_test.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_main_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import os
 import re
 import sys
 import unittest
 
 from absl import flags
 from absl.testing import flagsaver
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow.python.eager import context  # pylint: disable=ungrouped-imports
 from official.legacy.transformer import misc
 from official.legacy.transformer import transformer_main
 
 FLAGS = flags.FLAGS
 FIXED_TIMESTAMP = 'my_time_stamp'
 WEIGHT_PATTERN = re.compile(r'weights-epoch-.+\.hdf5')
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/transformer_test.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/transformer_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Test Transformer model."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import model_params
 from official.legacy.transformer import transformer
 
 
 class TransformerV2Test(tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/translate.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/translate.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Translate text or files using trained transformer model."""
 
 # Import libraries
 from absl import logging
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer.utils import tokenizer
 
 _EXTRA_DECODE_LENGTH = 100
 _BEAM_SIZE = 4
 _ALPHA = 0.6
 
@@ -106,15 +106,15 @@
           for j in range(batch_size)
           if j + i * batch_size < total_samples
       ]
       lines = [_encode_and_add_eos(l, subtokenizer) for l in lines]
       if distribution_strategy:
         for j in range(batch_size - len(lines)):
           lines.append([tokenizer.EOS_ID])
-      batch = tf.keras.preprocessing.sequence.pad_sequences(
+      batch = tf_keras.preprocessing.sequence.pad_sequences(
           lines,
           maxlen=params["decode_max_length"],
           dtype="int32",
           padding="post")
       logging.info("Decoding batch %d out of %d.", i, num_decode_batches)
       yield batch
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/utils/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/utils/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/utils/metrics.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/utils/metrics.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/utils/tokenizer.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/utils/tokenizer.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -24,15 +24,15 @@
 import unicodedata
 
 from absl import logging
 
 import numpy as np
 import six
 from six.moves import xrange  # pylint: disable=redefined-builtin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # pylint: disable=g-complex-comprehension
 PAD = "<pad>"
 PAD_ID = 0
 EOS = "<EOS>"
 EOS_ID = 1
 RESERVED_TOKENS = [PAD, EOS]
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/transformer/utils/tokenizer_test.py` & `tf-models-no-deps-2.16.0/official/legacy/transformer/utils/tokenizer_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Test Subtokenizer and string helper methods."""
 
 import collections
 import tempfile
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer.utils import tokenizer
 
 
 class SubtokenizerTest(tf.test.TestCase):
 
   def _init_subtokenizer(self, vocab_list):
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/__init__.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/classifier_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/classifier_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/common_flags.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/common_flags.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/data_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/data_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import collections
 import json
 import os
 
 from absl import logging
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 special_symbols = {
     "<unk>": 0,
     "<s>": 1,
     "</s>": 2,
     "<cls>": 3,
     "<sep>": 4,
@@ -525,15 +525,15 @@
       example["target_mask"] = tf.reshape(target_mask, [num_predict])
     else:
       example["target"] = tf.reshape(target, [seq_len])
       example["target_mask"] = tf.reshape(target_mask, [seq_len])
 
     for key in list(example.keys()):
       val = example[key]
-      if tf.keras.backend.is_sparse(val):
+      if tf_keras.backend.is_sparse(val):
         val = tf.sparse.to_dense(val)
       if val.dtype == tf.int64:
         val = tf.cast(val, tf.int32)
 
       example[key] = val
 
     for k, v in example.items():
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/optimization.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/optimization.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,19 +11,19 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Functions and classes related to optimization (weight updates)."""
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.nlp import optimization
 
 
-class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):
+class WarmUp(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Applys a warmup schedule on a given learning rate decay schedule."""
 
   def __init__(self,
                initial_learning_rate,
                decay_schedule_fn,
                warmup_steps,
                power=1.0,
@@ -65,15 +65,15 @@
                      num_train_steps,
                      num_warmup_steps,
                      min_lr_ratio=0.0,
                      adam_epsilon=1e-8,
                      weight_decay_rate=0.0):
   """Creates an optimizer with learning rate schedule."""
   # Implements linear decay of the learning rate.
-  learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(
+  learning_rate_fn = tf_keras.optimizers.schedules.PolynomialDecay(
       initial_learning_rate=init_lr,
       decay_steps=num_train_steps - num_warmup_steps,
       end_learning_rate=init_lr * min_lr_ratio)
   if num_warmup_steps:
     learning_rate_fn = WarmUp(
         initial_learning_rate=init_lr,
         decay_schedule_fn=learning_rate_fn,
@@ -88,11 +88,11 @@
         beta_1=0.9,
         beta_2=0.999,
         epsilon=adam_epsilon,
         exclude_from_weight_decay=["LayerNorm", "layer_norm", "bias"],
         include_in_weight_decay=["r_s_bias", "r_r_bias", "r_w_bias"])
   else:
     logging.info("Using Adam with adam_epsilon=%.9f", (adam_epsilon))
-    optimizer = tf.keras.optimizers.legacy.Adam(
+    optimizer = tf_keras.optimizers.legacy.Adam(
         learning_rate=learning_rate_fn, epsilon=adam_epsilon)
 
   return optimizer, learning_rate_fn
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/preprocess_classification_data.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/preprocess_classification_data.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,15 +19,15 @@
 import os
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 import sentencepiece as spm
 from official.legacy.xlnet import classifier_utils
 from official.legacy.xlnet import preprocess_utils
 
 
 flags.DEFINE_bool(
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/preprocess_pretrain_data.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/preprocess_pretrain_data.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -125,15 +125,15 @@
       sent_id = not sent_id
 
     logging.info("Finish with line %d", line_cnt)
     if line_cnt == 0:
       continue
 
     input_data = np.array(input_data, dtype=np.int64)
-    sent_ids = np.array(sent_ids, dtype=np.bool)
+    sent_ids = np.array(sent_ids, dtype=bool)
 
     total_line_cnt += line_cnt
     input_shards.append((input_data, sent_ids))
 
   logging.info("[Task %d] Total number line: %d", idx, total_line_cnt)
 
   tfrecord_dir = os.path.join(FLAGS.save_dir, "tfrecords")
@@ -344,15 +344,15 @@
   else:
     return False
 
 
 def _sample_mask(sp, seg, reverse=False, max_gram=5, goal_num_predict=None):
   """Samples `goal_num_predict` tokens for partial prediction."""
   seg_len = len(seg)
-  mask = np.array([False] * seg_len, dtype=np.bool)
+  mask = np.array([False] * seg_len, dtype=bool)
 
   num_predict = 0
 
   ngrams = np.arange(1, max_gram + 1, dtype=np.int64)
   pvals = 1. / np.arange(1, max_gram + 1)
   pvals /= pvals.sum(keepdims=True)
 
@@ -407,15 +407,15 @@
 
 
 def _sample_mask_ngram(sp, seg, reverse=False, max_gram=5,
                        goal_num_predict=None):
   """Sample `goal_num_predict` tokens for partial prediction."""
 
   seg_len = len(seg)
-  mask = np.array([False] * seg_len, dtype=np.bool)
+  mask = np.array([False] * seg_len, dtype=bool)
 
   num_predict = 0
 
   ngrams = np.arange(1, max_gram + 1, dtype=np.int64)
   pvals = 1. / np.arange(1, max_gram + 1)
   pvals /= pvals.sum(keepdims=True)
 
@@ -610,15 +610,15 @@
 ################
 # get_input_fn #
 ################
 def _convert_example(example, use_bfloat16):
   """Cast int64 into int32 and float32 to bfloat16 if use_bfloat16."""
   for key in list(example.keys()):
     val = example[key]
-    if tf.keras.backend.is_sparse(val):
+    if tf_keras.backend.is_sparse(val):
       val = tf.sparse.to_dense(val)
     if val.dtype == tf.int64:
       val = tf.cast(val, tf.int32)
     if use_bfloat16 and val.dtype == tf.float32:
       val = tf.cast(val, tf.bfloat16)
 
     example[key] = val
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/preprocess_squad_data.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/preprocess_squad_data.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,15 +18,15 @@
 import os
 import random
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 import sentencepiece as spm
 from official.legacy.xlnet import squad_utils
 
 flags.DEFINE_integer(
     "num_proc", default=1, help="Number of preprocessing processes.")
 flags.DEFINE_integer("proc_id", default=0, help="Process id for preprocessing.")
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/preprocess_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/preprocess_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/run_classifier.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/run_classifier.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import functools
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 # pylint: disable=unused-import
 from official.common import distribute_utils
 from official.legacy.xlnet import common_flags
 from official.legacy.xlnet import data_utils
 from official.legacy.xlnet import optimization
 from official.legacy.xlnet import training_utils
 from official.legacy.xlnet import xlnet_config
@@ -119,15 +119,15 @@
     with eval_summary_writer.as_default():
       tf.summary.scalar("eval_acc", float(correct) / float(total), step=step)
       eval_summary_writer.flush()
   return accuracy
 
 
 def get_metric_fn():
-  train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy(
+  train_acc_metric = tf_keras.metrics.SparseCategoricalAccuracy(
       "acc", dtype=tf.float32)
   return train_acc_metric
 
 
 def main(unused_argv):
   del unused_argv
   strategy = distribute_utils.get_distribution_strategy(
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/run_pretrain.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/run_pretrain.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import functools
 import os
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 # pylint: disable=unused-import
 from official.common import distribute_utils
 from official.legacy.xlnet import common_flags
 from official.legacy.xlnet import data_utils
 from official.legacy.xlnet import optimization
 from official.legacy.xlnet import training_utils
 from official.legacy.xlnet import xlnet_config
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/run_squad.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/run_squad.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,15 +20,15 @@
 import pickle
 
 # Import libraries
 from absl import app
 from absl import flags
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 # pylint: disable=unused-import
 import sentencepiece as spm
 from official.common import distribute_utils
 from official.legacy.xlnet import common_flags
 from official.legacy.xlnet import data_utils
 from official.legacy.xlnet import optimization
 from official.legacy.xlnet import squad_utils
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/squad_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/squad_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -26,15 +26,15 @@
 import pickle
 import re
 import string
 
 from absl import logging
 import numpy as np
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.xlnet import data_utils
 from official.legacy.xlnet import preprocess_utils
 
 SPIECE_UNDERLINE = u"▁"
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/training_utils.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/training_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """XLNet training utils."""
 
 import os
 import re
 from typing import Any, Callable, Dict, Optional, Text
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.bert import model_training_utils
 from official.legacy.xlnet import data_utils
 
 # pytype: disable=attribute-error
 # pylint: disable=g-bare-generic,unused-import
 
@@ -47,19 +47,19 @@
 def train(
     strategy: tf.distribute.Strategy,
     model_fn: Callable,
     input_meta_data: Dict,
     train_input_fn: Callable,
     total_training_steps: int,
     steps_per_loop: int,
-    optimizer: tf.keras.optimizers.Optimizer,
-    learning_rate_fn: tf.keras.optimizers.schedules.LearningRateSchedule,
-    eval_fn: Optional[Callable[[tf.keras.Model, int, tf.summary.SummaryWriter],
+    optimizer: tf_keras.optimizers.Optimizer,
+    learning_rate_fn: tf_keras.optimizers.schedules.LearningRateSchedule,
+    eval_fn: Optional[Callable[[tf_keras.Model, int, tf.summary.SummaryWriter],
                                Any]] = None,
-    metric_fn: Optional[Callable[[], tf.keras.metrics.Metric]] = None,
+    metric_fn: Optional[Callable[[], tf_keras.metrics.Metric]] = None,
     init_checkpoint: Optional[Text] = None,
     init_from_transformerxl: Optional[bool] = False,
     model_dir: Optional[Text] = None,
     save_steps: Optional[int] = None,
     run_eagerly: Optional[bool] = False):
   """Runs customized training.
 
@@ -136,15 +136,15 @@
       checkpoint.restore(init_checkpoint)
 
     model.optimizer = optimizer
 
     if not hasattr(model, "optimizer"):
       raise ValueError("User should set optimizer attribute to model.")
 
-    train_loss_metric = tf.keras.metrics.Mean("training_loss", dtype=tf.float32)
+    train_loss_metric = tf_keras.metrics.Mean("training_loss", dtype=tf.float32)
     train_metric = None
     if metric_fn:
       train_metric = metric_fn()
 
     def _replicated_step(inputs, mem=None):
       """Replicated training step."""
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/xlnet_config.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/xlnet_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Utility functions used in XLNet model."""
 
 import json
 import os
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def create_run_config(is_training, is_finetune, flags):
   """Helper function for creating RunConfig."""
   kwargs = dict(
       is_training=is_training,
       use_tpu=flags.use_tpu,
```

### Comparing `tf-models-no-deps-2.11.2/official/legacy/xlnet/xlnet_modeling.py` & `tf-models-no-deps-2.16.0/official/legacy/xlnet/xlnet_modeling.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,30 +13,30 @@
 # limitations under the License.
 
 """Keras layers of XLNet model in TF 2.0."""
 
 import copy
 import warnings
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.xlnet import data_utils
 from official.nlp.modeling import networks
 
 
 def gelu(x):
-  return tf.keras.activations.gelu(x, approximate=True)
+  return tf_keras.activations.gelu(x, approximate=True)
 
 
 def _get_initializer(flags):
   """Get variable initializer."""
   if flags.init_method == "uniform":
-    initializer = tf.keras.initializers.RandomUniform(
+    initializer = tf_keras.initializers.RandomUniform(
         minval=-flags.init_range, maxval=flags.init_range)
   elif flags.init_method == "normal":
-    initializer = tf.keras.initializers.RandomNormal(stddev=flags.init_std)
+    initializer = tf_keras.initializers.RandomNormal(stddev=flags.init_std)
   else:
     raise ValueError("Initializer {} not supported".format(flags.init_method))
   return initializer
 
 
 def rel_shift(x, klen=-1):
   """Performs relative shift to form the relative attention score."""
@@ -74,24 +74,24 @@
       curr_out = curr_out[:reuse_len]
 
     if prev_mem is None:
       new_mem = curr_out[-mem_len:]
     else:
       new_mem = tf.concat([prev_mem, curr_out], 0)[-mem_len:]
 
-  return tf.keras.backend.stop_gradient(new_mem)
+  return tf_keras.backend.stop_gradient(new_mem)
 
 
 def is_special_none_tensor(tensor):
   """Checks if a tensor is a special None Tensor."""
   return tensor.shape.ndims == 0 and tensor.dtype == tf.int32
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class RelativePositionEncoding(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class RelativePositionEncoding(tf_keras.layers.Layer):
   """Creates a relative positional encoding.
 
   This layer creates a relative positional encoding as described in
   "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
   (https://arxiv.org/abs/1901.02860).
 
   Rather than an absolute position embedding as in Transformer, this
@@ -128,26 +128,26 @@
     pos_emb = pos_emb[:, None, :]
 
     if batch_size is not None:
       pos_emb = tf.tile(pos_emb, [1, batch_size, 1])
     return pos_emb
 
 
-class RelativeAttention(tf.keras.layers.Layer):
+class RelativeAttention(tf_keras.layers.Layer):
   """Core calculations for relative attention."""
 
   def __init__(self, dropout_att, scale):
     super(RelativeAttention, self).__init__()
     self.scale = scale
     self.dropout_att = dropout_att
 
   def build(self, unused_input_shapes):
     """Implements build() for the layer."""
 
-    self.attention_probs_dropout = tf.keras.layers.Dropout(
+    self.attention_probs_dropout = tf_keras.layers.Dropout(
         rate=self.dropout_att)
 
     super(RelativeAttention, self).build(unused_input_shapes)
 
   def call(self, q_head, k_head_h, v_head_h, k_head_r, seg_embed, seg_mat,
            r_w_bias, r_r_bias, r_s_bias, attn_mask):
     """Implements call() for the layer."""
@@ -181,15 +181,15 @@
 
     # attention output
     attn_vec = tf.einsum("ijbn,jbnd->ibnd", attn_prob, v_head_h)
 
     return attn_vec
 
 
-class PositionwiseFF(tf.keras.layers.Layer):
+class PositionwiseFF(tf_keras.layers.Layer):
   """Positionwise feed-forward layer."""
 
   def __init__(self, d_model, d_inner, dropout, kernel_initializer,
                activation_type, **kwargs):
     super(PositionwiseFF, self).__init__(**kwargs)
     self.d_model = d_model
     self.d_inner = d_inner
@@ -203,42 +203,42 @@
       activation = tf.nn.relu
     elif self.activation_type == "gelu":
       activation = gelu
     else:
       raise (ValueError("Unsupported activation type {}".format(
           self.activation_type)))
     self.inner_projection_layer = (
-        tf.keras.layers.Dense(
+        tf_keras.layers.Dense(
             units=self.d_inner,
             activation=activation,
             kernel_initializer=self.kernel_initializer,
             name="layer_1"))
     self.output_projection_layer = (
-        tf.keras.layers.Dense(
+        tf_keras.layers.Dense(
             units=self.d_model,
             kernel_initializer=self.kernel_initializer,
             name="layer_2"))
-    self.output_dropout = tf.keras.layers.Dropout(
+    self.output_dropout = tf_keras.layers.Dropout(
         rate=self.dropout, name="drop_2")
     self.output_layer_norm = (
-        tf.keras.layers.LayerNormalization(
+        tf_keras.layers.LayerNormalization(
             name="LayerNorm", axis=-1, epsilon=1e-12))
     super(PositionwiseFF, self).build(unused_input_shapes)
 
   def call(self, inp):
     """Implements call() for the layer."""
 
     output = self.inner_projection_layer(inp)
     output = self.output_projection_layer(output)
     output = self.output_dropout(output)
     output = self.output_layer_norm(output + inp)
     return output
 
 
-class EmbeddingLookup(tf.keras.layers.Layer):
+class EmbeddingLookup(tf_keras.layers.Layer):
   """Looks up words embeddings for id tensor."""
 
   def __init__(self, n_token, d_embed, initializer, **kwargs):
     super(EmbeddingLookup, self).__init__(**kwargs)
     self.n_token = n_token
     self.d_embed = d_embed
     self.initializer = initializer
@@ -253,15 +253,15 @@
 
     super(EmbeddingLookup, self).build(unused_input_shapes)
 
   def call(self, inputs):
     return tf.nn.embedding_lookup(self.lookup_table, inputs)
 
 
-class RelativeMultiheadAttention(tf.keras.layers.Layer):
+class RelativeMultiheadAttention(tf_keras.layers.Layer):
   """Multi-head attention with relative embedding."""
 
   def __init__(self, d_model, n_head, d_head, dropout, dropout_att,
                kernel_initializer, **kwargs):
     super(RelativeMultiheadAttention, self).__init__(**kwargs)
     self.d_model = d_model
     self.n_head = n_head
@@ -270,15 +270,15 @@
     self.dropout_att = dropout_att
     self.initializer = kernel_initializer
 
   def build(self, unused_input_shapes):
     """Implements build() for the layer."""
     self.scale = 1.0 / (self.d_head**0.5)
 
-    self.output_layer_norm = tf.keras.layers.LayerNormalization(
+    self.output_layer_norm = tf_keras.layers.LayerNormalization(
         name="LayerNorm", axis=-1, epsilon=1e-12)
 
     self.kh_projection_layer = self.add_weight(
         "k/kernel",
         shape=[self.d_model, self.n_head, self.d_head],
         initializer=self.initializer)
     self.vh_projection_layer = self.add_weight(
@@ -298,15 +298,15 @@
         dropout_att=self.dropout_att, scale=self.scale)
 
     self.proj_o = self.add_weight(
         "o/kernel",
         shape=[self.d_model, self.n_head, self.d_head],
         initializer=self.initializer)
 
-    self.attention_dropout = tf.keras.layers.Dropout(rate=self.dropout)
+    self.attention_dropout = tf_keras.layers.Dropout(rate=self.dropout)
 
     super(RelativeMultiheadAttention, self).build(unused_input_shapes)
 
   def call(self, h, g, r, r_w_bias, r_r_bias, seg_mat, r_s_bias, seg_embed,
            attn_mask_h, attn_mask_g, mems, target_mapping):
     """Implements call() for the layer."""
 
@@ -356,15 +356,15 @@
       output_g = tf.einsum("ibnd,hnd->ibh", attn_vec_g, self.proj_o)
       output_g = self.attention_dropout(output_g)
       output_g = self.output_layer_norm(output_g + g)
 
     return (output_h, output_g)
 
 
-class TransformerXLModel(tf.keras.layers.Layer):
+class TransformerXLModel(tf_keras.layers.Layer):
   """Defines a Transformer-XL computation graph with additional support for XLNet."""
 
   def __init__(self,
                n_token,
                n_layer,
                d_model,
                n_head,
@@ -448,16 +448,16 @@
     self.embedding_lookup = EmbeddingLookup(
         n_token=self.n_token,
         d_embed=self.d_model,
         initializer=self.initializer,
         dtype=self.tf_float,
         name="word_embedding")
 
-    self.h_dropout = tf.keras.layers.Dropout(rate=self.dropout)
-    self.g_dropout = tf.keras.layers.Dropout(rate=self.dropout)
+    self.h_dropout = tf_keras.layers.Dropout(rate=self.dropout)
+    self.g_dropout = tf_keras.layers.Dropout(rate=self.dropout)
 
     if self.untie_r:
       self.r_w_bias = (
           self.add_weight(
               "r_w_bias",
               shape=[self.n_layer, self.n_head, self.d_head],
               dtype=self.tf_float,
@@ -497,15 +497,15 @@
         "seg_embed", [self.n_layer, 2, self.n_head, self.d_head],
         dtype=self.tf_float,
         initializer=self.initializer)
 
     self.mask_emb = self.add_weight(
         "mask_emb/mask_emb", shape=[1, 1, self.d_model], dtype=self.tf_float)
 
-    self.emb_dropout = tf.keras.layers.Dropout(rate=self.dropout)
+    self.emb_dropout = tf_keras.layers.Dropout(rate=self.dropout)
     self.fwd_position_embedding = RelativePositionEncoding(self.d_model)
     self.bwd_position_embedding = RelativePositionEncoding(self.d_model)
 
     self.rel_multihead_layers = []
     self.h_positionwise_ffn_layers = []
     for i in range(self.n_layer):
       self.rel_multihead_layers.append(
@@ -522,15 +522,15 @@
               d_model=self.d_model,
               d_inner=self.d_inner,
               dropout=self.dropout,
               kernel_initializer=self.initializer,
               activation_type=self.ff_activation,
               name="layer_%d/ff" % (i)))
 
-    self.output_dropout = tf.keras.layers.Dropout(rate=self.dropout)
+    self.output_dropout = tf_keras.layers.Dropout(rate=self.dropout)
 
     super(TransformerXLModel, self).build(unused_input_shapes)
 
   def __call__(self,
                inp_k,
                seg_id=None,
                input_mask=None,
@@ -737,15 +737,15 @@
       output = output_g
     else:
       output = output_h
 
     return output, new_mems, None
 
 
-class PretrainingXLNetModel(tf.keras.Model):
+class PretrainingXLNetModel(tf_keras.Model):
   """XLNet keras model combined with pretraining LM loss layer.
 
   See the original paper: https://arxiv.org/pdf/1906.08237.pdf
 
   """
 
   def __init__(self, use_proj, xlnet_config, run_config, use_legacy_mask=True,
@@ -822,15 +822,15 @@
         target=target,
         lookup_table=self.xlnet_model.get_embedding_lookup_table(),
         target_mask=tgt_mask)
     self.add_loss(lm_loss)
     return self.new_mems, model_output
 
 
-class ClassificationXLNetModel(tf.keras.Model):
+class ClassificationXLNetModel(tf_keras.Model):
   """XLNet keras model combined with classification loss layer.
 
   See the original paper: https://arxiv.org/pdf/1906.08237.pdf
 
   """
 
   def __init__(self, xlnet_config, run_config, n_class, summary_type,
@@ -897,19 +897,19 @@
     mems = features.get("mems", None)
 
     attention_output, new_mems = (
         self.xlnet_model(input_ids, segment_ids, input_mask, mems))
 
     summary = self.summarization_layer(attention_output)
     per_example_loss, logits = self.cl_loss_layer(hidden=summary, labels=label)
-    self.add_loss(tf.keras.backend.mean(per_example_loss))
+    self.add_loss(tf_keras.backend.mean(per_example_loss))
     return new_mems, logits
 
 
-class LMLossLayer(tf.keras.layers.Layer):
+class LMLossLayer(tf_keras.layers.Layer):
   """Layer computing cross entropy loss for language modeling."""
 
   def __init__(self,
                vocab_size,
                hidden_size,
                initializer,
                tie_weight=False,
@@ -941,20 +941,20 @@
     self.bi_data = bi_data
     self.use_one_hot = use_one_hot
     self.use_proj = use_proj
 
   def build(self, unused_input_shapes):
     """Implements build() for the layer."""
     if self.use_proj:
-      self.proj_layer = tf.keras.layers.Dense(
+      self.proj_layer = tf_keras.layers.Dense(
           units=self.hidden_size,
           kernel_initializer=self.initializer,
           activation=gelu,
           name="lm_projection/dense")
-      self.proj_layer_norm = tf.keras.layers.LayerNormalization(
+      self.proj_layer_norm = tf_keras.layers.LayerNormalization(
           axis=-1, epsilon=1e-12, name="lm_projection/LayerNorm")
     if not self.tie_weight:
       self.softmax_w = self.add_weight(
           "weight",
           shape=[self.vocab_size, self.hidden_size],
           initializer=self.initializer)
 
@@ -980,15 +980,15 @@
           labels=target, logits=logits)
 
     total_loss = tf.reduce_sum(loss * target_mask) / tf.reduce_sum(target_mask)
 
     return total_loss, logits
 
 
-class Summarization(tf.keras.layers.Layer):
+class Summarization(tf_keras.layers.Layer):
   """The layer to pool the output from XLNet model into a vector."""
 
   def __init__(self,
                hidden_size,
                num_attention_heads,
                head_size,
                dropout_rate,
@@ -1020,20 +1020,20 @@
     self.attention_dropout_rate = attention_dropout_rate
     self.use_proj = use_proj
     self.summary_type = summary_type
 
   def build(self, unused_input_shapes):
     """Implements build() for the layer."""
     if self.use_proj:
-      self.proj_layer = tf.keras.layers.Dense(
+      self.proj_layer = tf_keras.layers.Dense(
           units=self.hidden_size,
           kernel_initializer=self.initializer,
           activation=tf.nn.tanh,
           name="summary")
-    self.dropout_layer = tf.keras.layers.Dropout(rate=self.dropout_rate)
+    self.dropout_layer = tf_keras.layers.Dropout(rate=self.dropout_rate)
 
     super(Summarization, self).build(unused_input_shapes)
 
   def call(self, inputs):
     """Implements call() for the layer."""
     if self.summary_type == "last":
       summary = inputs[:, -1, :]
@@ -1043,15 +1043,15 @@
       raise ValueError("Invalid summary type provided: %s" % self.summary_type)
     if self.use_proj:
       summary = self.proj_layer(summary)
     summary = self.dropout_layer(summary)
     return summary
 
 
-class ClassificationLossLayer(tf.keras.layers.Layer):
+class ClassificationLossLayer(tf_keras.layers.Layer):
   """Layer computing cross entropy loss for classification task."""
 
   def __init__(self, n_class, initializer, **kwargs):
     """Constructs Summarization layer.
 
     Args:
       n_class: Number of tokens in vocabulary.
@@ -1061,30 +1061,30 @@
     super(ClassificationLossLayer, self).__init__(**kwargs)
 
     self.n_class = n_class
     self.initializer = initializer
 
   def build(self, unused_input_shapes):
     """Implements build() for the layer."""
-    self.proj_layer = tf.keras.layers.Dense(
+    self.proj_layer = tf_keras.layers.Dense(
         units=self.n_class, kernel_initializer=self.initializer, name="logit")
 
     super(ClassificationLossLayer, self).build(unused_input_shapes)
 
   def call(self, hidden, labels):
     """Implements call() for the layer."""
 
     logits = self.proj_layer(hidden)
     one_hot_target = tf.one_hot(labels, self.n_class, dtype=hidden.dtype)  # pytype: disable=attribute-error
     loss = -tf.reduce_sum(tf.nn.log_softmax(logits) * one_hot_target, -1)
 
     return loss, logits
 
 
-class QAXLNetModel(tf.keras.Model):
+class QAXLNetModel(tf_keras.Model):
   """XLNet keras model combined with question answering loss layer.
 
   See the original paper: https://arxiv.org/pdf/1906.08237.pdf
 
   """
 
   def __init__(self, xlnet_config, run_config, start_n_top, end_n_top,
@@ -1157,15 +1157,15 @@
       return new_mems, logits
     else:
       results = self.qa_loss_layer(
           hidden=attention_output, p_mask=p_mask, cls_index=cls_index)
       return results
 
 
-class QALossLayer(tf.keras.layers.Layer):
+class QALossLayer(tf_keras.layers.Layer):
   """Layer computing position and regression loss for question answering task."""
 
   def __init__(self, hidden_size, start_n_top, end_n_top, initializer,
                dropout_rate, **kwargs):
     """Constructs Summarization layer.
 
     Args:
@@ -1181,36 +1181,36 @@
     self.start_n_top = start_n_top
     self.end_n_top = end_n_top
     self.initializer = initializer
     self.dropout_rate = dropout_rate
 
   def build(self, unused_input_shapes):
     """Implements build() for the layer."""
-    self.start_logits_proj_layer = tf.keras.layers.Dense(
+    self.start_logits_proj_layer = tf_keras.layers.Dense(
         units=1, kernel_initializer=self.initializer, name="start_logits/dense")
-    self.end_logits_proj_layer0 = tf.keras.layers.Dense(
+    self.end_logits_proj_layer0 = tf_keras.layers.Dense(
         units=self.hidden_size,
         kernel_initializer=self.initializer,
         activation=tf.nn.tanh,
         name="end_logits/dense_0")
-    self.end_logits_proj_layer1 = tf.keras.layers.Dense(
+    self.end_logits_proj_layer1 = tf_keras.layers.Dense(
         units=1, kernel_initializer=self.initializer, name="end_logits/dense_1")
-    self.end_logits_layer_norm = tf.keras.layers.LayerNormalization(
+    self.end_logits_layer_norm = tf_keras.layers.LayerNormalization(
         axis=-1, epsilon=1e-12, name="end_logits/LayerNorm")
-    self.answer_class_proj_layer0 = tf.keras.layers.Dense(
+    self.answer_class_proj_layer0 = tf_keras.layers.Dense(
         units=self.hidden_size,
         kernel_initializer=self.initializer,
         activation=tf.nn.tanh,
         name="answer_class/dense_0")
-    self.answer_class_proj_layer1 = tf.keras.layers.Dense(
+    self.answer_class_proj_layer1 = tf_keras.layers.Dense(
         units=1,
         kernel_initializer=self.initializer,
         use_bias=False,
         name="answer_class/dense_1")
-    self.ans_feature_dropout = tf.keras.layers.Dropout(rate=self.dropout_rate)
+    self.ans_feature_dropout = tf_keras.layers.Dropout(rate=self.dropout_rate)
     super(QALossLayer, self).build(unused_input_shapes)
 
   def __call__(self, hidden, p_mask, cls_index, **kwargs):
     return super(QALossLayer, self).__call__(
         (hidden, p_mask, cls_index, kwargs))
 
   def call(self, inputs, training=False):
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/__init__.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/gelu.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/gelu.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,23 +10,23 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Gaussian error linear unit."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 def gelu(x):
   """Gaussian Error Linear Unit.
 
   This is a smoother version of the RELU.
   Original paper: https://arxiv.org/abs/1606.08415
   Args:
     x: float Tensor to perform activation.
 
   Returns:
     `x` with the GELU activation applied.
   """
-  return tf.keras.activations.gelu(x, approximate=True)
+  return tf_keras.activations.gelu(x, approximate=True)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/gelu_test.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/gelu_test.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,22 +10,20 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for the Gaussian error linear unit."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import activations
 
 
-@keras_parameterized.run_all_keras_modes
-class GeluTest(keras_parameterized.TestCase):
+class GeluTest(tf.test.TestCase):
 
   def test_gelu(self):
     expected_data = [[0.14967535, 0., -0.10032465],
                      [-0.15880796, -0.04540223, 2.9963627]]
     gelu_data = activations.gelu([[.25, 0, -.25], [-1, -2, 3]])
     self.assertAllClose(expected_data, gelu_data)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/mish.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/relu.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,38 +1,31 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Self Regularized Non-Monotonic Activation Function."""
+"""Customized Relu activation."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow_addons.utils import types
 
-
-@tf.keras.utils.register_keras_serializable(package='Text')
-def mish(x: types.TensorLike) -> tf.Tensor:
-  """Mish activation function.
-
-     Mish: A Self Regularized Non-Monotonic Activation Function
-     https://arxiv.org/pdf/1908.08681.pdf
-
-     Mish(x) = x * tanh(ln(1+e^x))
+@tf_keras.utils.register_keras_serializable(package='Text')
+def relu6(features):
+  """Computes the Relu6 activation function.
 
   Args:
-    x: A `Tensor` representing preactivation values.
+    features: A `Tensor` representing preactivation values.
 
   Returns:
     The activation value.
   """
-  x = tf.convert_to_tensor(x)
-  return x * tf.tanh(tf.nn.softplus(x))
+  features = tf.convert_to_tensor(features)
+  return tf.nn.relu6(features)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/mish_test.py` & `tf-models-no-deps-2.16.0/official/projects/maxvit/registry_imports.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,32 +1,21 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Tests for the customized Mish activation."""
+"""All necessary imports for registration."""
 
-import tensorflow as tf
-
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
-from official.modeling import activations
-
-
-@keras_parameterized.run_all_keras_modes
-class MishTest(keras_parameterized.TestCase):
-
-  def test_mish(self):
-    x = tf.constant([1.0, 0.0])
-    self.assertAllClose([0.86509839, 0.0], activations.mish(x))
-
-
-if __name__ == '__main__':
-  tf.test.main()
+# pylint: disable=unused-import
+# pylint: disable=g-bad-import-order
+from official.vision import registry_imports
+from official.projects.maxvit import configs  # pylint: disable=unused-import
+from official.projects.maxvit.modeling import maxvit  # pylint: disable=unused-import
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/relu.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/mish_test.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,31 +1,30 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Customized Relu activation."""
+"""Tests for the customized Mish activation."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
+from official.modeling import activations
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-def relu6(features):
-  """Computes the Relu6 activation function.
 
-  Args:
-    features: A `Tensor` representing preactivation values.
+class MishTest(tf.test.TestCase):
 
-  Returns:
-    The activation value.
-  """
-  features = tf.convert_to_tensor(features)
-  return tf.nn.relu6(features)
+  def test_mish(self):
+    x = tf.constant([1.0, 0.0])
+    self.assertAllClose([0.86509839, 0.0], activations.mish(x))
+
+
+if __name__ == '__main__':
+  tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/relu_test.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/sigmoid_test.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,35 +1,37 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Tests for the customized Relu activation."""
+"""Tests for the customized Sigmoid activation."""
 
-import tensorflow as tf
+import numpy as np
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import \
-  keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import activations
 
 
-@keras_parameterized.run_all_keras_modes
-class CustomizedReluTest(keras_parameterized.TestCase):
+class CustomizedSigmoidTest(tf.test.TestCase):
 
-  def test_relu6(self):
+  def _hard_sigmoid_nn(self, x):
+    x = np.float32(x)
+    return tf.nn.relu6(x + 3.) * 0.16667
+
+  def test_hard_sigmoid(self):
     features = [[.25, 0, -.25], [-1, -2, 3]]
-    customized_relu6_data = activations.relu6(features)
-    relu6_data = tf.nn.relu6(features)
-    self.assertAllClose(customized_relu6_data, relu6_data)
+    customized_hard_sigmoid_data = activations.hard_sigmoid(features)
+    sigmoid_data = self._hard_sigmoid_nn(features)
+    self.assertAllClose(customized_hard_sigmoid_data, sigmoid_data)
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/sigmoid.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/sigmoid.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,18 +10,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Customized Sigmoid activation."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 def hard_sigmoid(features):
   """Computes the hard sigmoid activation function.
 
   Args:
     features: A `Tensor` representing preactivation values.
 
   Returns:
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/sigmoid_test.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/relu_test.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,40 +1,32 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Tests for the customized Sigmoid activation."""
+"""Tests for the customized Relu activation."""
 
-import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import \
-  keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import activations
 
 
-@keras_parameterized.run_all_keras_modes
-class CustomizedSigmoidTest(keras_parameterized.TestCase):
+class CustomizedReluTest(tf.test.TestCase):
 
-  def _hard_sigmoid_nn(self, x):
-    x = np.float32(x)
-    return tf.nn.relu6(x + 3.) * 0.16667
-
-  def test_hard_sigmoid(self):
+  def test_relu6(self):
     features = [[.25, 0, -.25], [-1, -2, 3]]
-    customized_hard_sigmoid_data = activations.hard_sigmoid(features)
-    sigmoid_data = self._hard_sigmoid_nn(features)
-    self.assertAllClose(customized_hard_sigmoid_data, sigmoid_data)
+    customized_relu6_data = activations.relu6(features)
+    relu6_data = tf.nn.relu6(features)
+    self.assertAllClose(customized_relu6_data, relu6_data)
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/swish.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/swish.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,18 +10,18 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Customized Swish activation."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 def simple_swish(features):
   """Computes the Swish activation function.
 
   The tf.nn.swish operation uses a custom gradient to reduce memory usage.
   Since saving custom gradients in SavedModel is currently not supported, and
   one would not be able to use an exported TF-Hub module for fine-tuning, we
   provide this wrapper that can allow to select whether to use the native
@@ -34,15 +34,15 @@
   Returns:
     The activation value.
   """
   features = tf.convert_to_tensor(features)
   return features * tf.nn.sigmoid(features)
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 def hard_swish(features):
   """Computes a hard version of the swish function.
 
   This operation can be used to reduce computational cost and improve
   quantization for edge devices.
 
   Args:
@@ -52,15 +52,15 @@
     The activation value.
   """
   features = tf.convert_to_tensor(features)
   fdtype = features.dtype
   return features * tf.nn.relu6(features + tf.cast(3., fdtype)) * (1. / 6.)
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 def identity(features):
   """Computes the identity function.
 
   Useful for helping in quantization.
 
   Args:
     features: A `Tensor` representing preactivation values.
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/activations/swish_test.py` & `tf-models-no-deps-2.16.0/official/modeling/activations/swish_test.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,22 +10,20 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for the customized Swish activation."""
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import activations
 
 
-@keras_parameterized.run_all_keras_modes
-class CustomizedSwishTest(keras_parameterized.TestCase):
+class CustomizedSwishTest(tf.test.TestCase):
 
   def _hard_swish_np(self, x):
     x = np.float32(x)
     return x * np.clip(x + 3, 0, 6) / 6
 
   def test_simple_swish(self):
     features = [[.25, 0, -.25], [-1, -2, 3]]
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/grad_utils.py` & `tf-models-no-deps-2.16.0/official/modeling/grad_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Some gradient util functions to help users writing custom training loop."""
 
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _filter_grads(grads_and_vars):
   """Filter out iterable with grad equal to None."""
   grads_and_vars = tuple(grads_and_vars)
   if not grads_and_vars:
     return grads_and_vars
@@ -94,15 +94,15 @@
   allreduce in optimizer.apply_gradients(). If training using FP16 mixed
   precision, explicit allreduce will aggregate gradients in FP16 format.
   For TPU and GPU training using FP32, explicit allreduce will aggregate
   gradients in FP32 format.
 
   Args:
       tape: An instance of `tf.GradientTape`.
-      optimizer: An instance of `tf.keras.optimizers.Optimizer`.
+      optimizer: An instance of `tf_keras.optimizers.Optimizer`.
       loss: the loss tensor.
       trainable_variables: A list of model Variables.
       pre_allreduce_callbacks: A list of callback functions that takes gradients
         and model variables pairs as input, manipulate them, and returns a new
         gradients and model variables pairs. The callback functions will be
         invoked in the list order and before gradients are allreduced. With
         mixed precision training, the pre_allreduce_allbacks will be applied on
@@ -113,15 +113,15 @@
         functions will be invoked in the list order and right before gradients
         are applied to variables for updates. Default is no callbacks.
       allreduce_bytes_per_pack: A non-negative integer. Breaks collective
         operations into packs of certain size. If it's zero, all gradients are
         in one pack.
   """
   if isinstance(optimizer,
-                tf.keras.mixed_precision.LossScaleOptimizer):
+                tf_keras.mixed_precision.LossScaleOptimizer):
     # FP16 GPU code path
     with tape:
       scaled_loss = optimizer.get_scaled_loss(loss)
     scaled_grads = tape.gradient(scaled_loss, trainable_variables)
     grads_and_vars = zip(scaled_grads, trainable_variables)
     if pre_allreduce_callbacks:
       grads_and_vars = _run_callbacks(pre_allreduce_callbacks, grads_and_vars)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/grad_utils_test.py` & `tf-models-no-deps-2.16.0/official/modeling/grad_utils_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,56 +10,56 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for grad_utils."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling import grad_utils
 from official.modeling import performance
 
 
 class GradUtilsTest(tf.test.TestCase):
 
   def test_minimize(self):
 
-    optimizer = tf.keras.optimizers.SGD(0.1)
+    optimizer = tf_keras.optimizers.SGD(0.1)
     with tf.GradientTape() as tape:
-      model = tf.keras.layers.Dense(2)
+      model = tf_keras.layers.Dense(2)
       outputs = model(tf.zeros((2, 2), tf.float32))
       loss = tf.reduce_mean(outputs)
 
     grad_utils.minimize_using_explicit_allreduce(tape, optimizer, loss,
                                                  model.trainable_variables)
 
   def test_minimize_fp16(self):
 
     optimizer = performance.configure_optimizer(
-        tf.keras.optimizers.SGD(0.1), use_float16=True)
+        tf_keras.optimizers.SGD(0.1), use_float16=True)
     performance.set_mixed_precision_policy(tf.float16)
     with tf.GradientTape() as tape:
-      model = tf.keras.layers.Dense(2)
+      model = tf_keras.layers.Dense(2)
       outputs = model(tf.zeros((2, 2), tf.float16))
       loss = tf.reduce_mean(outputs)
 
     grad_utils.minimize_using_explicit_allreduce(tape, optimizer, loss,
                                                  model.trainable_variables)
 
     # Test other fp16 settings.
     def _clip_by_global_norm(grads_and_vars):
       grads, tvars = list(zip(*grads_and_vars))
       (grads, _) = tf.clip_by_global_norm(grads, clip_norm=1.0)
       return zip(grads, tvars)
     with tf.GradientTape() as tape:
-      model = tf.keras.layers.Dense(2)
+      model = tf_keras.layers.Dense(2)
       outputs = model(tf.zeros((2, 2), tf.float16))
       loss = tf.reduce_mean(outputs)
     optimizer = performance.configure_optimizer(
-        tf.keras.optimizers.SGD(0.1), use_float16=True, loss_scale=128)
+        tf_keras.optimizers.SGD(0.1), use_float16=True, loss_scale=128)
     grad_utils.minimize_using_explicit_allreduce(
         tape,
         optimizer,
         loss,
         model.trainable_variables,
         pre_allreduce_callbacks=[_clip_by_global_norm],
         post_allreduce_callbacks=[_clip_by_global_norm])
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/hyperparams/__init__.py` & `tf-models-no-deps-2.16.0/official/modeling/hyperparams/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/hyperparams/base_config.py` & `tf-models-no-deps-2.16.0/official/modeling/hyperparams/base_config.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,34 +1,37 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Base configurations to standardize experiments."""
+
 import copy
 import dataclasses
 import functools
 import inspect
-from typing import Any, List, Mapping, Optional, Type
+import typing
+from typing import Any, List, Mapping, Optional, Type, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import yaml
 
 from official.modeling.hyperparams import params_dict
 
+
 _BOUND = set()
 
 
 def bind(config_cls):
   """Bind a class to config cls."""
   if not inspect.isclass(config_cls):
     raise ValueError('The bind decorator is supposed to apply on the class '
@@ -50,14 +53,19 @@
       raise ValueError(f'The `BUILDER` type is not supported: {builder}')
     _BOUND.add(config_cls)
     return builder
 
   return decorator
 
 
+def _is_optional(field):
+  return typing.get_origin(field) is Union and type(None) in typing.get_args(
+      field)
+
+
 @dataclasses.dataclass
 class Config(params_dict.ParamsDict):
   """The base configuration class that supports YAML/JSON based overrides.
 
   Because of YAML/JSON serialization limitations, some semantics of dataclass
   are not supported:
   * It recursively enforces a allowlist of basic types and container types, so
@@ -84,14 +92,28 @@
         restrictions=restrictions)
 
   @property
   def BUILDER(self):
     return self._BUILDER
 
   @classmethod
+  def _get_annotations(cls):
+    """Returns valid annotations.
+
+    Note: this is similar to dataclasses.__annotations__ except it also includes
+      annotations from its parent classes.
+    """
+    all_annotations = typing.get_type_hints(cls)
+    # Removes Config class annotation from the value, e.g., default_params,
+    # restrictions, etc.
+    for k in Config.__annotations__:
+      del all_annotations[k]
+    return all_annotations
+
+  @classmethod
   def _isvalidsequence(cls, v):
     """Check if the input values are valid sequences.
 
     Args:
       v: Input sequence.
 
     Returns:
@@ -144,42 +166,61 @@
       return v.as_dict()
     elif isinstance(v, dict):
       raise TypeError('dict value not supported in converting.')
     else:
       raise TypeError('Unknown type: {!r}'.format(type(v)))
 
   @classmethod
-  def _get_subconfig_type(cls, k) -> Type[params_dict.ParamsDict]:
+  def _get_subconfig_type(
+      cls, k, subconfig_type=None
+  ) -> Type[params_dict.ParamsDict]:
     """Get element type by the field name.
 
     Args:
       k: the key/name of the field.
+      subconfig_type: default subconfig_type. If None, it is set to
+        Config.
 
     Returns:
       Config as default. If a type annotation is found for `k`,
       1) returns the type of the annotation if it is subtype of ParamsDict;
       2) returns the element type if the annotation of `k` is List[SubType]
          or Tuple[SubType].
     """
-    subconfig_type = Config
-    if k in cls.__annotations__:
+    if not subconfig_type:
+      subconfig_type = Config
+
+    annotations = cls._get_annotations()
+    if k in annotations:
       # Directly Config subtype.
-      type_annotation = cls.__annotations__[k]  # pytype: disable=invalid-annotation
-      if (isinstance(type_annotation, type) and
-          issubclass(type_annotation, Config)):
-        subconfig_type = cls.__annotations__[k]  # pytype: disable=invalid-annotation
-      else:
-        # Check if the field is a sequence of subtypes.
-        field_type = getattr(type_annotation, '__origin__', type(None))
-        if (isinstance(field_type, type) and
-            issubclass(field_type, cls.SEQUENCE_TYPES)):
-          element_type = getattr(type_annotation, '__args__', [type(None)])[0]
-          subconfig_type = (
-              element_type if issubclass(element_type, params_dict.ParamsDict)
-              else subconfig_type)
+      type_annotation = annotations[k]
+      i = 0
+      # Loop for striping the Optional annotation.
+      traverse_in = True
+      while traverse_in:
+        i += 1
+        if (isinstance(type_annotation, type) and
+            issubclass(type_annotation, Config)):
+          subconfig_type = type_annotation
+          break
+        else:
+          # Check if the field is a sequence of subtypes.
+          field_type = typing.get_origin(type_annotation)
+          if (isinstance(field_type, type) and
+              issubclass(field_type, cls.SEQUENCE_TYPES)):
+            element_type = typing.get_args(type_annotation)[0]
+            subconfig_type = (
+                element_type if issubclass(element_type, params_dict.ParamsDict)
+                else subconfig_type)
+            break
+          elif _is_optional(type_annotation):
+            # Strip the `Optional` annotation and process the subtype.
+            type_annotation = typing.get_args(type_annotation)[0]
+            continue
+        traverse_in = False
     return subconfig_type
 
   def _set(self, k, v):
     """Overrides same method in ParamsDict.
 
     Also called by ParamsDict methods.
 
@@ -296,11 +337,14 @@
   def from_json(cls, file_path: str):
     """Wrapper for `from_yaml`."""
     return cls.from_yaml(file_path)
 
   @classmethod
   def from_args(cls, *args, **kwargs):
     """Builds a config from the given list of arguments."""
+    # Note we intend to keep `__annotations__` instead of `_get_annotations`.
+    # Assuming a parent class of (a, b) with the sub-class of (c, d), the
+    # sub-class will take (c, d) for args, rather than starting from (a, b).
     attributes = list(cls.__annotations__.keys())
     default_params = {a: p for a, p in zip(attributes, args)}
     default_params.update(kwargs)
     return cls(default_params=default_params)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/hyperparams/base_config_test.py` & `tf-models-no-deps-2.16.0/official/modeling/hyperparams/base_config_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,41 +1,43 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import pprint
-from typing import List, Tuple
+import dataclasses
+from typing import List, Optional, Tuple
 
 from absl.testing import parameterized
-import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
+
 from official.modeling.hyperparams import base_config
 
 
 @dataclasses.dataclass
 class DumpConfig1(base_config.Config):
   a: int = 1
   b: str = 'text'
 
 
 @dataclasses.dataclass
 class DumpConfig2(base_config.Config):
   c: int = 2
   d: str = 'text'
-  e: DumpConfig1 = DumpConfig1()
+  e: DumpConfig1 = dataclasses.field(default_factory=DumpConfig1)
+  optional_e: Optional[DumpConfig1] = None
 
 
 @dataclasses.dataclass
 class DumpConfig3(DumpConfig2):
   f: int = 2
   g: str = 'text'
   h: List[DumpConfig1] = dataclasses.field(
@@ -50,14 +52,19 @@
 
 @dataclasses.dataclass
 class DummyConfig5(base_config.Config):
   y: Tuple[DumpConfig2, ...] = (DumpConfig2(), DumpConfig4())
   z: Tuple[str] = ('a',)
 
 
+@dataclasses.dataclass
+class DumpConfig6(base_config.Config):
+  test_config1: Optional[DumpConfig1] = None
+
+
 class BaseConfigTest(parameterized.TestCase, tf.test.TestCase):
 
   def assertHasSameTypes(self, c, d, msg=''):
     """Checks if a Config has the same structure as a given dict.
 
     Args:
       c: the Config object to be check.
@@ -338,14 +345,42 @@
                     6: 7,
                 }),
                 8: 9,
             }
         ]),
         "['s', 1, 1.0, True, None, {}, [], (), {8: 9, (2,): (3, [4], {6: 7})}]")
 
+  def test_with_superclass_override(self):
+    config = DumpConfig2()
+    config.override({'optional_e': {'a': 2}})
+    self.assertEqual(
+        config.optional_e.as_dict(),
+        {
+            'a': 2,
+            'b': 'text',
+        },
+    )
+
+    # Previously, the following will fail. See b/274696969 for context.
+    config = DumpConfig3()
+    config.override({'optional_e': {'a': 2}})
+    self.assertEqual(
+        config.optional_e.as_dict(),
+        {
+            'a': 2,
+            'b': 'text',
+        },
+    )
+
+  def test_get_annotations_without_base_config_leak(self):
+    with self.assertRaisesRegex(
+        KeyError, "The key 'restrictions' does not exist"
+    ):
+      DumpConfig3().override({'restrictions': None})
+
   def test_with_restrictions(self):
     restrictions = ['e.a<c']
     config = DumpConfig2(restrictions=restrictions)
     config.validate()
 
   def test_nested_tuple(self):
     config = DummyConfig5()
@@ -376,10 +411,17 @@
     config.override({
         'y': [],
         'z': (),
     }, is_strict=True)
     self.assertEmpty(config.y)
     self.assertEmpty(config.z)
 
+  def test_correctly_display_optional_field(self):
+    c = DumpConfig6()
+    c.override({'test_config1': {'b': 'abc'}})
+    self.assertEqual(f'{c}',
+                     "DumpConfig6(test_config1=DumpConfig1(a=1, b='abc'))")
+    self.assertIsInstance(c.test_config1, DumpConfig1)
+
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/hyperparams/oneof.py` & `tf-models-no-deps-2.16.0/official/modeling/hyperparams/oneof.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/hyperparams/oneof_test.py` & `tf-models-no-deps-2.16.0/official/modeling/hyperparams/oneof_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,50 +1,50 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling.hyperparams import base_config
 from official.modeling.hyperparams import oneof
 
 
 @dataclasses.dataclass
 class ResNet(base_config.Config):
   model_depth: int = 50
 
 
 @dataclasses.dataclass
 class Backbone(oneof.OneOfConfig):
   type: str = 'resnet'
-  resnet: ResNet = ResNet()
+  resnet: ResNet = dataclasses.field(default_factory=ResNet)
   not_resnet: int = 2
 
 
 @dataclasses.dataclass
 class OutputLayer(oneof.OneOfConfig):
   type: str = 'single'
   single: int = 1
   multi_head: int = 2
 
 
 @dataclasses.dataclass
 class Network(base_config.Config):
-  backbone: Backbone = Backbone()
-  output_layer: OutputLayer = OutputLayer()
+  backbone: Backbone = dataclasses.field(default_factory=Backbone)
+  output_layer: OutputLayer = dataclasses.field(default_factory=OutputLayer)
 
 
 class OneOfTest(tf.test.TestCase):
 
   def test_to_dict(self):
     network_params = {
         'backbone': {
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/hyperparams/params_dict.py` & `tf-models-no-deps-2.16.0/official/modeling/hyperparams/params_dict.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,24 +15,24 @@
 """A parameter dictionary class which supports the nest structure."""
 
 import collections
 import copy
 import re
 
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import yaml
 
 # regex pattern that matches on key-value pairs in a comma-separated
 # key-value pair string. It splits each k-v pair on the = sign, and
 # matches on values that are within single quotes, double quotes, single
 # values (e.g. floats, ints, etc.), and a lists within brackets.
 _PARAM_RE = re.compile(
     r"""
-  (?P<name>[a-zA-Z][\w\.]*)    # variable name: "var" or "x"
+  (?P<name>[a-zA-Z][\w\.]*)(?P<bracketed_index>\[?[0-9]*\]?)  # variable name: "var" or "x" followed by optional index: "[0]" or "[23]"
   \s*=\s*
   ((?P<val>\'(.*?)\'           # single quote
   |
   \"(.*?)\"                    # double quote
   |
   [^,\[]*                      # single value
   |
@@ -44,15 +44,15 @@
 # Yaml LOADER with an implicit resolver to parse float decimal and exponential
 # format. The regular experission parse the following cases:
 # 1- Decimal number with an optional exponential term.
 # 2- Integer number with an exponential term.
 # 3- Decimal number with an optional exponential term.
 # 4- Decimal number.
 
-_LOADER = yaml.SafeLoader
+_LOADER = yaml.FullLoader
 _LOADER.add_implicit_resolver(
     'tag:yaml.org,2002:float',
     re.compile(r'''
     ^(?:[-+]?(?:[0-9][0-9_]*)\\.[0-9_]*(?:[eE][-+]?[0-9]+)?
     |
     [-+]?(?:[0-9][0-9_]*)(?:[eE][-+]?[0-9]+)
     |
@@ -219,15 +219,15 @@
           params_dict[k] = copy.deepcopy(v)
     return params_dict
 
   def validate(self):
     """Validate the parameters consistency based on the restrictions.
 
     This method validates the internal consistency using the pre-defined list of
-    restrictions. A restriction is defined as a string which specfiies a binary
+    restrictions. A restriction is defined as a string which specifies a binary
     operation. The supported binary operations are {'==', '!=', '<', '<=', '>',
     '>='}. Note that the meaning of these operators are consistent with the
     underlying Python immplementation. Users should make sure the define
     restrictions on their type make sense.
 
     For example, for a ParamsDict like the following
     ```
@@ -293,42 +293,42 @@
       elif '!=' in restriction:
         tokens = restriction.split('!=')
         _, left_v, _, right_v = _get_kvs(tokens, params_dict)
         if left_v == right_v:
           raise KeyError(
               'Found inconsistency between key `{}` and key `{}`.'.format(
                   tokens[0], tokens[1]))
-      elif '<' in restriction:
-        tokens = restriction.split('<')
-        _, left_v, _, right_v = _get_kvs(tokens, params_dict)
-        if left_v >= right_v:
-          raise KeyError(
-              'Found inconsistency between key `{}` and key `{}`.'.format(
-                  tokens[0], tokens[1]))
       elif '<=' in restriction:
         tokens = restriction.split('<=')
         _, left_v, _, right_v = _get_kvs(tokens, params_dict)
         if left_v > right_v:
           raise KeyError(
               'Found inconsistency between key `{}` and key `{}`.'.format(
                   tokens[0], tokens[1]))
-      elif '>' in restriction:
-        tokens = restriction.split('>')
+      elif '<' in restriction:
+        tokens = restriction.split('<')
         _, left_v, _, right_v = _get_kvs(tokens, params_dict)
-        if left_v <= right_v:
+        if left_v >= right_v:
           raise KeyError(
               'Found inconsistency between key `{}` and key `{}`.'.format(
                   tokens[0], tokens[1]))
       elif '>=' in restriction:
         tokens = restriction.split('>=')
         _, left_v, _, right_v = _get_kvs(tokens, params_dict)
         if left_v < right_v:
           raise KeyError(
               'Found inconsistency between key `{}` and key `{}`.'.format(
                   tokens[0], tokens[1]))
+      elif '>' in restriction:
+        tokens = restriction.split('>')
+        _, left_v, _, right_v = _get_kvs(tokens, params_dict)
+        if left_v <= right_v:
+          raise KeyError(
+              'Found inconsistency between key `{}` and key `{}`.'.format(
+                  tokens[0], tokens[1]))
       else:
         raise ValueError('Unsupported relation in restriction.')
 
 
 def read_yaml_to_params_dict(file_path: str):
   """Reads a YAML file to a ParamsDict."""
   with tf.io.gfile.GFile(file_path, 'r') as f:
@@ -381,45 +381,78 @@
   Raises:
     ValueError: If csv_str is not in a comma separated string or
       if the string is formatted incorrectly.
   """
   if not csv_str:
     return ''
 
+  array_param_map = collections.defaultdict(str)
+  max_index_map = collections.defaultdict(str)
   formatted_entries = []
   nested_map = collections.defaultdict(list)
   pos = 0
   while pos < len(csv_str):
     m = _PARAM_RE.match(csv_str, pos)
     if not m:
       raise ValueError('Malformed hyperparameter value while parsing '
                        'CSV string: %s' % csv_str[pos:])
     pos = m.end()
     # Parse the values.
     m_dict = m.groupdict()
     name = m_dict['name']
     v = m_dict['val']
+    bracketed_index = m_dict['bracketed_index']
+    # If we reach the name of the array.
+    if bracketed_index and '.' not in name:
+      # Extract the array's index by removing '[' and ']'
+      index = int(bracketed_index[1:-1])
+      if '.' in v:
+        numeric_val = float(v)
+      else:
+        numeric_val = int(v)
+      # Add the value to the array.
+      if name not in array_param_map:
+        max_index_map[name] = index
+        array_param_map[name] = [None] * (index + 1)
+        array_param_map[name][index] = numeric_val
+      elif index < max_index_map[name]:
+        array_param_map[name][index] = numeric_val
+      else:
+        array_param_map[name] += [None] * (index - max_index_map[name])
+        array_param_map[name][index] = numeric_val
+        max_index_map[name] = index
+      continue
 
     # If a GCS path (e.g. gs://...) is provided, wrap this in quotes
     # as yaml.load would otherwise throw an exception
     if re.match(r'(?=[^\"\'])(?=[gs://])', v):
       v = '\'{}\''.format(v)
 
     name_nested = name.split('.')
     if len(name_nested) > 1:
       grouping = name_nested[0]
-      value = '.'.join(name_nested[1:]) + '=' + v
+      if bracketed_index:
+        value = '.'.join(name_nested[1:]) + bracketed_index + '=' + v
+      else:
+        value = '.'.join(name_nested[1:]) + '=' + v
       nested_map[grouping].append(value)
     else:
       formatted_entries.append('%s : %s' % (name, v))
 
   for grouping, value in nested_map.items():
     value = ','.join(value)
     value = nested_csv_str_to_json_str(value)
     formatted_entries.append('%s : %s' % (grouping, value))
+
+  # Add array parameters and check that the array is fully initialized.
+  for name in array_param_map:
+    if any(v is None for v in array_param_map[name]):
+      raise ValueError('Did not pass all values of array: %s' % name)
+    formatted_entries.append('%s : %s' % (name, array_param_map[name]))
+
   return '{' + ', '.join(formatted_entries) + '}'
 
 
 def override_params_dict(params, dict_or_string_or_yaml_file, is_strict):
   """Override a given ParamsDict using a dict, JSON/YAML/CSV string or YAML file.
 
   The logic of the function is outlined below:
@@ -454,11 +487,11 @@
     except ValueError:
       pass
     params_dict = yaml.load(dict_or_string_or_yaml_file, Loader=_LOADER)
     if isinstance(params_dict, dict):
       params.override(params_dict, is_strict)
     else:
       with tf.io.gfile.GFile(dict_or_string_or_yaml_file) as f:
-        params.override(yaml.load(f, Loader=yaml.FullLoader), is_strict)
+        params.override(yaml.load(f, Loader=_LOADER), is_strict)
   else:
     raise ValueError('Unknown input type to parse.')
   return params
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/hyperparams/params_dict_test.py` & `tf-models-no-deps-2.16.0/official/modeling/hyperparams/params_dict_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for params_dict.py."""
 
 import os
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import yaml
 
 from official.modeling.hyperparams import params_dict
 
 
 class ParamsDictTest(tf.test.TestCase):
 
@@ -163,24 +163,25 @@
         'b': {
             'a': 10
         },
         'c': {
             'a': 10
         }
     }, ['b == c'])
+    params.validate()
 
     # Raise error due to inconsistency
     with self.assertRaises(KeyError):
       params = params_dict.ParamsDict({'a': 1, 'c': {'a': 10}}, ['a == c.a'])
       params.validate()
 
     # Valid rule.
     params = params_dict.ParamsDict({'a': 1, 'c': {'a': 1}}, ['a == c.a'])
 
-    # Overridding violates the existing rule, raise error upon validate.
+    # Overriding violates the existing rule, raise error upon validate.
     params.override({'a': 11})
     with self.assertRaises(KeyError):
       params.validate()
 
     # Valid restrictions with constant.
     params = params_dict.ParamsDict({
         'a': None,
@@ -194,14 +195,18 @@
           'a': 4,
           'c': {
               'a': 1
           }
       }, ['a == None', 'c.a == 1'])
       params.validate()
 
+    # Valid restrictions with inequality.
+    params = params_dict.ParamsDict({'a': 1}, ['a >= 1'])
+    params.validate()
+
 
 class ParamsDictIOTest(tf.test.TestCase):
 
   def write_temp_file(self, filename, text):
     temp_file = os.path.join(self.get_temp_dir(), filename)
     with tf.io.gfile.GFile(temp_file, 'w') as writer:
       writer.write(text)
@@ -216,15 +221,15 @@
             'c2': 20
         }
     })
     output_yaml_file = os.path.join(self.get_temp_dir(), 'params.yaml')
     params_dict.save_params_dict_to_yaml(params, output_yaml_file)
 
     with tf.io.gfile.GFile(output_yaml_file, 'r') as f:
-      params_d = yaml.load(f)
+      params_d = yaml.load(f, Loader=yaml.Loader)
       self.assertEqual(params.a, params_d['a'])
       self.assertEqual(params.b, params_d['b'])
       self.assertEqual(params.c.c1, params_d['c']['c1'])
       self.assertEqual(params.c.c2, params_d['c']['c2'])
 
   def test_read_yaml_to_params_dict(self):
     input_yaml_file = self.write_temp_file(
@@ -360,47 +365,64 @@
     converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
     self.assertEqual(converted_csv_str, json_str)
 
   def test_basic_csv_str_load(self):
     csv_str = 'a=1,b=2,c=3'
     expected_output = {'a': 1, 'b': 2, 'c': 3}
     converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
-    converted_dict = yaml.load(converted_csv_str)
+    converted_dict = yaml.load(converted_csv_str, Loader=yaml.Loader)
     self.assertDictEqual(converted_dict, expected_output)
 
   def test_basic_nested_csv_str_to_json_str(self):
     csv_str = 'a=1,b.b1=2'
     json_str = '{a : 1, b : {b1 : 2}}'
     converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
     self.assertEqual(converted_csv_str, json_str)
 
   def test_basic_nested_csv_str_load(self):
     csv_str = 'a=1,b.b1=2,c.c1=3'
     expected_output = {'a': 1, 'b': {'b1': 2}, 'c': {'c1': 3}}
     converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
-    converted_dict = yaml.load(converted_csv_str)
+    converted_dict = yaml.load(converted_csv_str, Loader=yaml.Loader)
     self.assertDictEqual(converted_dict, expected_output)
 
   def test_complex_nested_csv_str_to_json_str(self):
     csv_str = 'a.aa.aaa.aaaaa.a=1'
     json_str = '{a : {aa : {aaa : {aaaaa : {a : 1}}}}}'
     converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
     self.assertEqual(converted_csv_str, json_str)
 
   def test_complex_nested_csv_str_load(self):
     csv_str = 'a.aa.aaa.aaaaa.a=1,a.a=2'
     expected_output = {'a': {'aa': {'aaa': {'aaaaa': {'a': 1}}}, 'a': 2}}
     converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
-    converted_dict = yaml.load(converted_csv_str)
+    converted_dict = yaml.load(converted_csv_str, Loader=yaml.Loader)
     self.assertDictEqual(converted_dict, expected_output)
 
+  def test_int_array_param_nested_csv_str_to_json_str(self):
+    csv_str = 'a.b[2]=3,a.b[0]=1,a.b[1]=2'
+    json_str = '{a : {b : [1, 2, 3]}}'
+    converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
+    self.assertEqual(converted_csv_str, json_str)
+
+  def test_float_array_param_nested_csv_str_to_json_str(self):
+    csv_str = 'a.b[1]=3.45,a.b[2]=1.32,a.b[0]=2.232'
+    json_str = '{a : {b : [2.232, 3.45, 1.32]}}'
+    converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
+    self.assertEqual(converted_csv_str, json_str)
+
+  def test_incomplete_array_param_nested_csv_str_to_json_str(self):
+    csv_str = 'a.b[0]=1,a.b[2]=2'
+    self.assertRaises(ValueError, params_dict.nested_csv_str_to_json_str,
+                      csv_str)
+
   def test_csv_str_load_supported_datatypes(self):
     csv_str = 'a=1,b=2.,c=[1,2,3],d=\'hello, there\',e=\"Hi.\"'
     converted_csv_str = params_dict.nested_csv_str_to_json_str(csv_str)
-    converted_dict = yaml.load(converted_csv_str)
+    converted_dict = yaml.load(converted_csv_str, Loader=yaml.Loader)
     self.assertEqual(converted_dict['a'], 1)
     self.assertEqual(converted_dict['b'], 2.)
     self.assertEqual(converted_dict['c'], [1, 2, 3])
     self.assertEqual(converted_dict['d'], 'hello, there')
     self.assertEqual(converted_dict['e'], 'Hi.')
 
   def test_csv_str_load_unsupported_datatypes(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/__init__.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/base_model.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/base_model.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,44 +11,44 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Abstraction of multi-task model."""
 from typing import Text, Dict
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class MultiTaskBaseModel(tf.Module):
   """Base class that holds multi-task model computation."""
 
   def __init__(self, **kwargs):
     super().__init__(**kwargs)
     self._sub_tasks = self._instantiate_sub_tasks()
 
-  def _instantiate_sub_tasks(self) -> Dict[Text, tf.keras.Model]:
+  def _instantiate_sub_tasks(self) -> Dict[Text, tf_keras.Model]:
     """Abstract function that sets up the computation for each sub-task.
 
     Returns:
-      A map from task name (as string) to a tf.keras.Model object that
+      A map from task name (as string) to a tf_keras.Model object that
         represents the sub-task in the multi-task pool.
     """
     raise NotImplementedError(
         "_instantiate_sub_task_models() is not implemented.")
 
   @property
   def sub_tasks(self):
-    """Fetch a map of task name (string) to task model (tf.keras.Model)."""
+    """Fetch a map of task name (string) to task model (tf_keras.Model)."""
     return self._sub_tasks
 
   def initialize(self):
     """Optional function that loads a pre-train checkpoint."""
     return
 
   def build(self):
     """Builds the networks for tasks to make sure variables are created."""
     # Try to build all sub tasks.
     for task_model in self._sub_tasks.values():
       # Assumes all the tf.Module models are built because we don't have any
       # way to check them.
-      if isinstance(task_model, tf.keras.Model) and not task_model.built:
+      if isinstance(task_model, tf_keras.Model) and not task_model.built:
         _ = task_model(task_model.inputs)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/base_trainer.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/base_trainer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,28 +16,28 @@
 
 The trainer derives from the Orbit `StandardTrainer` class.
 """
 from typing import Union
 
 import gin
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import optimization
 from official.modeling.multitask import base_model
 from official.modeling.multitask import multitask
 
 
 @gin.configurable
 class MultiTaskBaseTrainer(orbit.StandardTrainer):
   """Multitask base trainer."""
 
   def __init__(self,
                multi_task: multitask.MultiTask,
-               multi_task_model: Union[tf.keras.Model,
+               multi_task_model: Union[tf_keras.Model,
                                        base_model.MultiTaskBaseModel],
                optimizer: tf.optimizers.Optimizer,
                trainer_options=None,
                train_datasets=None):
     self._strategy = tf.distribute.get_strategy()
     self._multi_task = multi_task
     self._multi_task_model = multi_task_model
@@ -109,17 +109,17 @@
   @property
   def training_losses(self):
     """Access training loss metric objects for all tasks."""
     if self._training_losses is None:
       # Builds the per-task metrics and losses.
       # This the total summed training loss of tasks in the joint training.
       self._training_losses = dict(
-          total_loss=tf.keras.metrics.Mean("training_loss", dtype=tf.float32))
+          total_loss=tf_keras.metrics.Mean("training_loss", dtype=tf.float32))
       for name in self.multi_task.tasks:
-        self._training_losses[name] = tf.keras.metrics.Mean(
+        self._training_losses[name] = tf_keras.metrics.Mean(
             "training_loss", dtype=tf.float32)
     return self._training_losses
 
   @property
   def training_metrics(self):
     """Access training metric metric objects for all tasks."""
     if self._training_metrics is None:
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/base_trainer_test.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/base_trainer_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for multitask.base_trainer."""
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.modeling.multitask import base_trainer
 from official.modeling.multitask import configs
 from official.modeling.multitask import multitask
 from official.modeling.multitask import test_utils
@@ -43,15 +43,15 @@
       tasks = [
           test_utils.MockFooTask(params=test_utils.FooConfig(), name="foo"),
           test_utils.MockBarTask(params=test_utils.BarConfig(), name="bar")
       ]
       task_weights = {"foo": 1.0, "bar": 1.0}
       test_multitask = multitask.MultiTask(
           tasks=tasks, task_weights=task_weights)
-      test_optimizer = tf.keras.optimizers.SGD(0.1)
+      test_optimizer = tf_keras.optimizers.SGD(0.1)
       model = test_utils.MockMultiTaskModel()
       test_trainer = base_trainer.MultiTaskBaseTrainer(
           multi_task=test_multitask,
           multi_task_model=model,
           optimizer=test_optimizer)
       results = test_trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))
       self.assertContainsSubset(["training_loss", "bar_acc"],
@@ -66,15 +66,15 @@
             task_config=test_utils.FooConfig(),
             task_weight=0.5),
                        configs.TaskRoutine(
                            task_name="bar",
                            task_config=test_utils.BarConfig(),
                            task_weight=0.5)))
     test_multitask = multitask.MultiTask.from_config(config)
-    test_optimizer = tf.keras.optimizers.SGD(0.1)
+    test_optimizer = tf_keras.optimizers.SGD(0.1)
     model = test_utils.MockMultiTaskModel()
     test_trainer = base_trainer.MultiTaskBaseTrainer(
         multi_task=test_multitask,
         multi_task_model=model,
         optimizer=test_optimizer)
     results = test_trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))
     self.assertContainsSubset(["training_loss", "bar_acc"],
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/configs.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/configs.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,25 +1,24 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Configuration definitions for multi-task training."""
-from typing import Optional, Tuple
-
 import dataclasses
+from typing import Optional, Tuple
 
 from official.core import config_definitions as cfg
 from official.modeling import hyperparams
 from official.modeling.privacy import configs as dp_configs
 
 
 @dataclasses.dataclass
@@ -32,14 +31,18 @@
 
 
 @dataclasses.dataclass
 class MultiTaskConfig(hyperparams.Config):
   init_checkpoint: str = ""
   model: hyperparams.Config = None
   task_routines: Tuple[TaskRoutine, ...] = ()
+  # Configs for differential privacy
+  # These configs are only effective if you use create_optimizer in
+  # tensorflow_models/official/core/base_task.py
+  # DEPRECATED b/264611883
   differential_privacy_config: Optional[
       dp_configs.DifferentialPrivacyConfig] = None
 
 
 @dataclasses.dataclass
 class ProportionalSampleConfig(hyperparams.Config):
   alpha: float = 1.0
@@ -50,31 +53,43 @@
   steps_per_epoch: int = 5
   total_steps: int = 20
 
 
 @dataclasses.dataclass
 class TaskSamplingConfig(hyperparams.OneOfConfig):
   type: str = ""
-  uniform: hyperparams.Config = hyperparams.Config()
-  proportional: ProportionalSampleConfig = ProportionalSampleConfig()
-  annealing: AnnealingSampleConfig = AnnealingSampleConfig()
+  uniform: hyperparams.Config = dataclasses.field(
+      default_factory=hyperparams.Config
+  )
+  proportional: ProportionalSampleConfig = dataclasses.field(
+      default_factory=ProportionalSampleConfig
+  )
+  annealing: AnnealingSampleConfig = dataclasses.field(
+      default_factory=AnnealingSampleConfig
+  )
 
 
 @dataclasses.dataclass
 class MultiTaskTrainerConfig(cfg.TrainerConfig):
   trainer_type: str = "interleaving"
-  task_sampler: TaskSamplingConfig = TaskSamplingConfig(type="proportional")
+  task_sampler: TaskSamplingConfig = dataclasses.field(
+      default_factory=lambda: TaskSamplingConfig(type="proportional")
+  )
 
 
 @dataclasses.dataclass
 class MultiTaskExperimentConfig(hyperparams.Config):
   """An experiment config for multi-task training and multi-task evaluation."""
-  task: MultiTaskConfig = MultiTaskConfig()
-  trainer: MultiTaskTrainerConfig = MultiTaskTrainerConfig()
-  runtime: cfg.RuntimeConfig = cfg.RuntimeConfig()
+  task: MultiTaskConfig = dataclasses.field(default_factory=MultiTaskConfig)
+  trainer: MultiTaskTrainerConfig = dataclasses.field(
+      default_factory=MultiTaskTrainerConfig
+  )
+  runtime: cfg.RuntimeConfig = dataclasses.field(
+      default_factory=cfg.RuntimeConfig
+  )
 
 
 @dataclasses.dataclass
 class MultiEvalExperimentConfig(cfg.ExperimentConfig):
   """An experiment config for single-task training and multi-task evaluation.
 
   Attributes:
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/evaluator.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/evaluator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,37 +15,37 @@
 """Multitask Evaluator implementation.
 
 The evaluator implements the Orbit `AbstractEvaluator` interface.
 """
 from typing import Dict, List, Optional, Union
 import gin
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import train_utils
 from official.modeling.multitask import base_model
 
 
 @gin.configurable
 class MultiTaskEvaluator(orbit.AbstractEvaluator):
   """Implements the common trainer shared for TensorFlow models."""
 
   def __init__(
       self,
       eval_tasks: List[base_task.Task],
-      model: Union[tf.keras.Model, base_model.MultiTaskBaseModel],
+      model: Union[tf_keras.Model, base_model.MultiTaskBaseModel],
       global_step: Optional[tf.Variable] = None,
       eval_steps: Optional[Dict[str, int]] = None,
       checkpoint_exporter: Optional[train_utils.BestCheckpointExporter] = None):
     """Initialize common trainer for TensorFlow models.
 
     Args:
       eval_tasks: A list of tasks to evaluate.
-      model: tf.keras.Model instance.
+      model: tf_keras.Model instance.
       global_step: the global step variable.
       eval_steps: a dictionary of steps to run eval keyed by task names.
       checkpoint_exporter: an object that has the `maybe_export_checkpoint`
         interface.
     """
     # Gets the current distribution strategy. If not inside any strategy scope,
     # it gets a single-replica no-op strategy.
@@ -120,15 +120,15 @@
   @property
   def validation_losses(self):
     """Accesses the validation loss metric object."""
     if self._validation_losses is None:
       # Builds the per-task metrics and losses.
       self._validation_losses = {}
       for task in self.tasks:
-        self._validation_losses[task.name] = tf.keras.metrics.Mean(
+        self._validation_losses[task.name] = tf_keras.metrics.Mean(
             "validation_loss", dtype=tf.float32)
     return self._validation_losses
 
   @property
   def validation_metrics(self):
     """Accesses all validation metric metric objects."""
     if self._validation_metrics is None:
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/evaluator_test.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/evaluator_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for multitask.evaluator."""
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.modeling.multitask import evaluator
 
@@ -31,19 +31,19 @@
           strategy_combinations.cloud_tpu_strategy,
           strategy_combinations.one_device_strategy_gpu,
       ],
       mode="eager",
   )
 
 
-class MockModel(tf.keras.Model):
+class MockModel(tf_keras.Model):
 
   def __init__(self, *args, **kwargs):
     super().__init__(*args, **kwargs)
-    self.dense = tf.keras.layers.Dense(1)
+    self.dense = tf_keras.layers.Dense(1)
 
   def call(self, inputs):
     print(inputs, type(inputs))
     if "y" in inputs:
       self.add_loss(tf.zeros((1,), dtype=tf.float32))
     else:
       self.add_loss(tf.ones((1,), dtype=tf.float32))
@@ -51,15 +51,15 @@
 
 
 class MockTask(base_task.Task):
   """Mock task object for testing."""
 
   def build_metrics(self, training: bool = True):
     del training
-    return [tf.keras.metrics.Accuracy(name="acc")]
+    return [tf_keras.metrics.Accuracy(name="acc")]
 
   def build_inputs(self, params):
 
     def generate_data(_):
       x = tf.zeros(shape=(2,), dtype=tf.float32)
       label = tf.zeros([1], dtype=tf.int32)
       if self.name == "bar":
@@ -69,15 +69,15 @@
 
     dataset = tf.data.Dataset.range(1)
     dataset = dataset.repeat()
     dataset = dataset.map(
         generate_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)
     return dataset.prefetch(buffer_size=1).batch(2, drop_remainder=True)
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics=None):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics=None):
     logs = super().validation_step(inputs, model, metrics)
     logs["counter"] = tf.ones((1,), dtype=tf.float32)
     return logs
 
   def aggregate_logs(self, state, step_outputs):
     if state is None:
       state = {}
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/interleaving_trainer.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/interleaving_trainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,32 +12,32 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Multitask trainer that interleaves each task's train step."""
 from typing import Union
 import gin
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling.multitask import base_model
 from official.modeling.multitask import base_trainer
 from official.modeling.multitask import multitask
 from official.modeling.multitask import task_sampler as sampler
 
 
 @gin.configurable
 class MultiTaskInterleavingTrainer(base_trainer.MultiTaskBaseTrainer):
   """MultiTask trainer that interleaves task update."""
 
   def __init__(self,
                multi_task: multitask.MultiTask,
-               multi_task_model: Union[tf.keras.Model,
+               multi_task_model: Union[tf_keras.Model,
                                        base_model.MultiTaskBaseModel],
                optimizer: Union[tf.optimizers.Optimizer,
-                                tf.keras.optimizers.experimental.Optimizer,
-                                tf.keras.optimizers.legacy.Optimizer],
+                                tf_keras.optimizers.experimental.Optimizer,
+                                tf_keras.optimizers.legacy.Optimizer],
                task_sampler: sampler.TaskSampler,
                trainer_options=None):
     super().__init__(
         multi_task=multi_task,
         multi_task_model=multi_task_model,
         optimizer=optimizer,
         trainer_options=trainer_options)
@@ -70,15 +70,15 @@
     self._task_step_counters = {
         name: orbit.utils.create_global_step() for name in self.multi_task.tasks
     }
 
     # If the new Keras optimizer is used, we require all model variables are
     # created before the training and let the optimizer to create the slot
     # variable all together.
-    if isinstance(optimizer, tf.keras.optimizers.experimental.Optimizer):
+    if isinstance(optimizer, tf_keras.optimizers.experimental.Optimizer):
       multi_task_model.build()
       optimizer.build(multi_task_model.trainable_variables)
 
   def task_step_counter(self, name):
     return self._task_step_counters[name]
 
   def train_step(self, iterator_map):
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/interleaving_trainer_test.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/interleaving_trainer_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for multitask.interleaving_trainer."""
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.modeling.multitask import configs
 from official.modeling.multitask import interleaving_trainer
 from official.modeling.multitask import multitask
 from official.modeling.multitask import task_sampler
@@ -42,15 +42,15 @@
   def test_multitask_interleaving_trainer(self, distribution):
     with distribution.scope():
       tasks = [
           test_utils.MockFooTask(params=test_utils.FooConfig(), name="foo"),
           test_utils.MockBarTask(params=test_utils.BarConfig(), name="bar")
       ]
       test_multitask = multitask.MultiTask(tasks=tasks)
-      test_optimizer = tf.keras.optimizers.SGD(0.1)
+      test_optimizer = tf_keras.optimizers.SGD(0.1)
       model = test_utils.MockMultiTaskModel()
       sampler = task_sampler.UniformTaskSampler(
           task_weights=test_multitask.task_weights)
       test_trainer = interleaving_trainer.MultiTaskInterleavingTrainer(
           multi_task=test_multitask,
           multi_task_model=model,
           optimizer=test_optimizer,
@@ -71,15 +71,15 @@
             task_weight=3.0),
                        configs.TaskRoutine(
                            task_name="bar",
                            task_config=test_utils.BarConfig(),
                            task_weight=1.0)))
     with distribution.scope():
       test_multitask = multitask.MultiTask.from_config(config)
-    test_optimizer = tf.keras.optimizers.SGD(0.1)
+    test_optimizer = tf_keras.optimizers.SGD(0.1)
     model = test_utils.MockMultiTaskModel()
     num_step = 1000
     sampler = task_sampler.AnnealingTaskSampler(
         task_weights=test_multitask.task_weights,
         steps_per_epoch=num_step/5,
         total_steps=num_step)
     test_trainer = interleaving_trainer.MultiTaskInterleavingTrainer(
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/multitask.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/multitask.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Experimental MultiTask base class for multi-task training/evaluation."""
 import abc
 from typing import Dict, List, Optional, Text, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import base_task
 from official.core import config_definitions
 from official.core import task_factory
 from official.modeling import optimization
 from official.modeling.multitask import base_model
 from official.modeling.multitask import configs
 from official.modeling.privacy import configs as dp_configs
@@ -99,15 +99,15 @@
                        dp_config: Optional[DifferentialPrivacyConfig] = None):
     return base_task.Task.create_optimizer(
         optimizer_config=optimizer_config, runtime_config=runtime_config,
         dp_config=dp_config)
 
   def joint_train_step(self, task_inputs,
                        multi_task_model: base_model.MultiTaskBaseModel,
-                       optimizer: tf.keras.optimizers.Optimizer, task_metrics,
+                       optimizer: tf_keras.optimizers.Optimizer, task_metrics,
                        **kwargs):
     """The joint train step.
 
     Args:
       task_inputs: a dictionary of task names and per-task features.
       multi_task_model: a MultiTaskBaseModel instance.
       optimizer: a tf.optimizers.Optimizer.
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/task_sampler.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/task_sampler.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Utils to sample tasks for interleaved optimization."""
 import abc
 from typing import Union, Dict, Text
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling.multitask import configs
 
 
 class TaskSampler(tf.Module, metaclass=abc.ABCMeta):
   """An abstract class defining task sampling API for interleaving trainer."""
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/task_sampler_test.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/task_sampler_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for multitask.task_sampler."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling.multitask import configs
 from official.modeling.multitask import task_sampler as sampler
 
 
 class TaskSamplerTest(tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/test_utils.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/test_utils.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,61 +10,61 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Testing utils for mock models and tasks."""
 from typing import Dict, Text
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling.multitask import base_model
 
 
-class MockFooModel(tf.keras.Model):
+class MockFooModel(tf_keras.Model):
   """A mock model can consume 'foo' and 'bar' inputs."""
 
   def __init__(self, shared_layer, *args, **kwargs):
     super().__init__(*args, **kwargs)
     self._share_layer = shared_layer
-    self._foo_specific_layer = tf.keras.layers.Dense(1)
-    self.inputs = {"foo": tf.keras.Input(shape=(2,), dtype=tf.float32),
-                   "bar": tf.keras.Input(shape=(2,), dtype=tf.float32)}
+    self._foo_specific_layer = tf_keras.layers.Dense(1)
+    self.inputs = {"foo": tf_keras.Input(shape=(2,), dtype=tf.float32),
+                   "bar": tf_keras.Input(shape=(2,), dtype=tf.float32)}
 
-  def call(self, inputs):
+  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     self.add_loss(tf.zeros((1,), dtype=tf.float32))
     if "foo" in inputs:
       input_tensor = inputs["foo"]
     else:
       input_tensor = inputs["bar"]
     return self._foo_specific_layer(self._share_layer(input_tensor))
 
 
-class MockBarModel(tf.keras.Model):
+class MockBarModel(tf_keras.Model):
   """A mock model can only consume 'bar' inputs."""
 
   def __init__(self, shared_layer, *args, **kwargs):
     super().__init__(*args, **kwargs)
     self._share_layer = shared_layer
-    self._bar_specific_layer = tf.keras.layers.Dense(1)
-    self.inputs = {"bar": tf.keras.Input(shape=(2,), dtype=tf.float32)}
+    self._bar_specific_layer = tf_keras.layers.Dense(1)
+    self.inputs = {"bar": tf_keras.Input(shape=(2,), dtype=tf.float32)}
 
-  def call(self, inputs):
+  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     self.add_loss(tf.zeros((2,), dtype=tf.float32))
     return self._bar_specific_layer(self._share_layer(inputs["bar"]))
 
 
 class MockMultiTaskModel(base_model.MultiTaskBaseModel):
 
   def __init__(self, *args, **kwargs):
-    self._shared_dense = tf.keras.layers.Dense(1)
+    self._shared_dense = tf_keras.layers.Dense(1)
     super().__init__(*args, **kwargs)
 
-  def _instantiate_sub_tasks(self) -> Dict[Text, tf.keras.Model]:
+  def _instantiate_sub_tasks(self) -> Dict[Text, tf_keras.Model]:
     return {
         "foo": MockFooModel(self._shared_dense),
         "bar": MockBarModel(self._shared_dense)
     }
 
 
 def mock_data(feature_name):
@@ -92,38 +92,38 @@
 
 @task_factory.register_task_cls(FooConfig)
 class MockFooTask(base_task.Task):
   """Mock foo task object for testing."""
 
   def build_metrics(self, training: bool = True):
     del training
-    return [tf.keras.metrics.Accuracy(name="foo_acc")]
+    return [tf_keras.metrics.Accuracy(name="foo_acc")]
 
   def build_inputs(self, params):
     return mock_data("foo")
 
-  def build_model(self) -> tf.keras.Model:
-    return MockFooModel(shared_layer=tf.keras.layers.Dense(1))
+  def build_model(self) -> tf_keras.Model:
+    return MockFooModel(shared_layer=tf_keras.layers.Dense(1))
 
   def build_losses(self, labels, model_outputs, aux_losses=None) -> tf.Tensor:
-    loss = tf.keras.losses.mean_squared_error(labels, model_outputs)
+    loss = tf_keras.losses.mean_squared_error(labels, model_outputs)
     if aux_losses:
       loss += tf.add_n(aux_losses)
     return tf.reduce_mean(loss)
 
 
 @task_factory.register_task_cls(BarConfig)
 class MockBarTask(base_task.Task):
   """Mock bar task object for testing."""
 
   def build_metrics(self, training: bool = True):
     del training
-    return [tf.keras.metrics.Accuracy(name="bar_acc")]
+    return [tf_keras.metrics.Accuracy(name="bar_acc")]
 
   def build_inputs(self, params):
     return mock_data("bar")
 
   def build_losses(self, labels, model_outputs, aux_losses=None) -> tf.Tensor:
-    loss = tf.keras.losses.mean_squared_error(labels, model_outputs)
+    loss = tf_keras.losses.mean_squared_error(labels, model_outputs)
     if aux_losses:
       loss += tf.add_n(aux_losses)
     return tf.reduce_mean(loss)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/train_lib.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/train_lib.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Multitask training driver library."""
 # pytype: disable=attribute-error
 import os
 from typing import Any, List, Mapping, Optional, Tuple, Union
 from absl import logging
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import base_task
 from official.core import base_trainer as core_lib
 from official.core import train_utils
 from official.modeling.multitask import base_model
 from official.modeling.multitask import base_trainer
 from official.modeling.multitask import configs
 from official.modeling.multitask import evaluator as evaluator_lib
@@ -42,14 +42,15 @@
     task: multitask.MultiTask,
     model: base_model.MultiTaskBaseModel,
     mode: str,
     params: configs.MultiTaskExperimentConfig,
     model_dir: str,
     run_post_eval: bool = False,
     trainer: base_trainer.MultiTaskBaseTrainer = None,
+    eval_summary_manager: Optional[orbit.utils.SummaryManagerInterface] = None,
     best_ckpt_exporter_creator: Optional[Any] = train_utils
     .maybe_create_best_ckpt_exporter
 ) -> Union[base_model.MultiTaskBaseModel, Tuple[base_model.MultiTaskBaseModel,
                                                 Mapping[Any, Any]]]:
   """Runs train/eval configured by the experiment params.
 
   Args:
@@ -60,14 +61,18 @@
       or 'continuous_eval'.
     params: ExperimentConfig instance.
     model_dir: A 'str', a path to store model checkpoints and summaries.
     run_post_eval: Whether to run post eval once after training, metrics logs
       are returned.
     trainer: (optional) A multi-task trainer to use. If none is provided, a
       default one will be created based on `params`.
+    eval_summary_manager: Instance of the eval summary manager. If set, the
+      `eval_summary_dir` will be ignored. Otherwise the eval summary manager
+      will be created internally for TensorBoard summaries by default from the
+      `eval_summary_dir`.
     best_ckpt_exporter_creator: A functor for creating best checkpoint exporter.
 
   Returns:
       model: `base_model.MultiTaskBaseModel` instance.
   """
 
   is_training = 'train' in mode
@@ -113,14 +118,15 @@
       trainer=trainer,
       evaluator=evaluator,
       global_step=global_step,
       steps_per_loop=params.trainer.steps_per_loop,
       checkpoint_manager=checkpoint_manager,
       summary_dir=os.path.join(model_dir, 'train'),
       eval_summary_dir=os.path.join(model_dir, 'validation'),
+      eval_summary_manager=eval_summary_manager,
       summary_interval=params.trainer.summary_interval)
 
   logging.info('Starts to execute mode: %s', mode)
   with distribution_strategy.scope():
     if mode == 'train':
       controller.train(steps=params.trainer.train_steps)
     elif mode == 'train_and_eval':
@@ -158,14 +164,15 @@
     eval_tasks: List[base_task.Task],
     mode: str,
     params: configs.MultiEvalExperimentConfig,
     model_dir: str,
     run_post_eval: bool = False,
     save_summary: bool = True,
     trainer: Optional[core_lib.Trainer] = None,
+    eval_summary_manager: Optional[orbit.utils.SummaryManagerInterface] = None,
     best_ckpt_exporter_creator: Optional[Any] = train_utils
     .maybe_create_best_ckpt_exporter,
 ) -> Tuple[Any, Any]:
   """Runs train/eval configured by the experiment params.
 
   Args:
     distribution_strategy: A distribution distribution_strategy.
@@ -177,18 +184,22 @@
     model_dir: A 'str', a path to store model checkpoints and summaries.
     run_post_eval: Whether to run post eval once after training, metrics logs
       are returned.
     save_summary: Whether to save train and validation summary.
     trainer: the core_lib.Trainer instance. It should be created within the
       strategy.scope(). If not provided, an instance will be created by default
       if `mode` contains 'train'.
+    eval_summary_manager: Instance of the eval summary manager. If set, the
+      `eval_summary_dir` will be ignored. Otherwise the eval summary manager
+      will be created internally for TensorBoard summaries by default from the
+      `eval_summary_dir`.
     best_ckpt_exporter_creator: A functor for creating best checkpoint exporter.
 
   Returns:
-      model: `tf.keras.Model` instance.
+      model: `tf_keras.Model` instance.
   """
 
   is_training = 'train' in mode
   is_eval = 'eval' in mode
   with distribution_strategy.scope():
     if is_training:
       trainer = trainer or core_lib.Trainer(
@@ -196,15 +207,28 @@
           task=train_task,
           model=train_task.build_model(),
           optimizer=train_utils.create_optimizer(train_task, params),
           train=True,
           evaluate=False)
     else:
       trainer = None
-    model = trainer.model if trainer else train_task.build_model()
+
+    # Build the model or fetch the pre-cached one (which could be either
+    # multi-task model or single task model).
+    model = None
+    if trainer is None:
+      if isinstance(train_task, multitask.MultiTask):
+        model = train_task.build_multitask_model()
+      else:
+        model = train_task.build_model()
+    else:
+      if isinstance(trainer, base_trainer.MultiTaskBaseTrainer):
+        model = trainer.multi_task_model
+      else:
+        model = trainer.model
 
     if is_eval:
       eval_steps = dict([(task_routine.task_config.name,
                           task_routine.eval_steps)
                          for task_routine in params.eval_tasks])
       evaluator = evaluator_lib.MultiTaskEvaluator(
           eval_tasks=eval_tasks,
@@ -236,14 +260,15 @@
       evaluator=evaluator,
       global_step=global_step,
       steps_per_loop=params.trainer.steps_per_loop,
       checkpoint_manager=checkpoint_manager,
       summary_dir=os.path.join(model_dir, 'train') if save_summary else None,
       eval_summary_dir=os.path.join(model_dir, 'validation') if
       (save_summary) else None,
+      eval_summary_manager=eval_summary_manager,
       summary_interval=params.trainer.summary_interval if
       (save_summary) else None)
 
   logging.info('Starts to execute mode: %s', mode)
   with distribution_strategy.scope():
     if mode == 'train':
       controller.train(steps=params.trainer.train_steps)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/multitask/train_lib_test.py` & `tf-models-no-deps-2.16.0/official/modeling/multitask/train_lib_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for multitask.train_lib."""
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.core import task_factory
 from official.modeling.hyperparams import params_dict
 from official.modeling.multitask import configs
 from official.modeling.multitask import multitask
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/__init__.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/adafactor_optimizer.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/adafactor_optimizer.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/configs/learning_rate_config.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/configs/learning_rate_config.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -115,15 +115,15 @@
 
 
 @dataclasses.dataclass
 class CosineLrConfig(base_config.Config):
   """Configuration for Cosine learning rate decay.
 
   This class is a containers for the cosine learning rate decay configs,
-  tf.keras.experimental.CosineDecay.
+  tf_keras.experimental.CosineDecay.
 
   Attributes:
     name: The name of the learning rate schedule. Defaults to CosineDecay.
     initial_learning_rate: A float. The initial learning rate. Defaults to None.
     decay_steps: A positive integer that is used for decay computation. Defaults
       to None.
     alpha: A float.  Minimum learning rate value as a fraction of
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/configs/optimization_config_test.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/configs/optimization_config_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for optimization_config.py."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling.optimization.configs import learning_rate_config as lr_cfg
 from official.modeling.optimization.configs import optimization_config
 from official.modeling.optimization.configs import optimizer_config as opt_cfg
 
 
 class OptimizerConfigTest(tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/configs/optimizer_config.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/configs/optimizer_config.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -36,15 +36,15 @@
   global_clipnorm: Optional[float] = None
 
 
 @dataclasses.dataclass
 class SGDConfig(BaseOptimizerConfig):
   """Configuration for SGD optimizer.
 
-  The attributes for this class matches the arguments of tf.keras.optimizer.SGD.
+  The attributes for this class matches the arguments of tf_keras.optimizer.SGD.
 
   Attributes:
     name: name of the optimizer.
     decay: decay rate for SGD optimizer.
     nesterov: nesterov for SGD optimizer.
     momentum: momentum for SGD optimizer.
   """
@@ -57,15 +57,15 @@
 # TODO(b/216129465): Merge this config with SGDConfig after the experimental
 # optimizer graduates.
 @dataclasses.dataclass
 class SGDExperimentalConfig(BaseOptimizerConfig):
   """Configuration for SGD optimizer.
 
   The attributes for this class matches the arguments of
-  `tf.keras.optimizer.experimental.SGD`.
+  `tf_keras.optimizer.experimental.SGD`.
 
   Attributes:
     name: name of the optimizer.
     nesterov: nesterov for SGD optimizer.
     momentum: momentum for SGD optimizer.
     jit_compile: if True, jit compile will be used.
   """
@@ -76,15 +76,15 @@
 
 
 @dataclasses.dataclass
 class RMSPropConfig(BaseOptimizerConfig):
   """Configuration for RMSProp optimizer.
 
   The attributes for this class matches the arguments of
-  tf.keras.optimizers.RMSprop.
+  tf_keras.optimizers.RMSprop.
 
   Attributes:
     name: name of the optimizer.
     rho: discounting factor for RMSprop optimizer.
     momentum: momentum for RMSprop optimizer.
     epsilon: epsilon value for RMSprop optimizer, help with numerical stability.
     centered: Whether to normalize gradients or not.
@@ -97,15 +97,15 @@
 
 
 @dataclasses.dataclass
 class AdagradConfig(BaseOptimizerConfig):
   """Configuration for Adagrad optimizer.
 
   The attributes of this class match the arguments of
-  tf.keras.optimizer.Adagrad.
+  tf_keras.optimizer.Adagrad.
 
   Attributes:
     name: name of the optimizer.
     initial_accumulator_value: A floating point value. Starting value for the
       accumulators, must be non-negative.
     epsilon: A small floating point value to avoid zero denominator.
   """
@@ -115,15 +115,15 @@
 
 
 @dataclasses.dataclass
 class AdamConfig(BaseOptimizerConfig):
   """Configuration for Adam optimizer.
 
   The attributes for this class matches the arguments of
-  tf.keras.optimizer.Adam.
+  tf_keras.optimizer.Adam.
 
   Attributes:
     name: name of the optimizer.
     beta_1: decay rate for 1st order moments.
     beta_2: decay rate for 2st order moments.
     epsilon: epsilon value used for numerical stability in Adam optimizer.
     amsgrad: boolean. Whether to apply AMSGrad variant of this algorithm from
@@ -137,15 +137,15 @@
 
 
 @dataclasses.dataclass
 class AdamExperimentalConfig(BaseOptimizerConfig):
   """Configuration for experimental Adam optimizer.
 
   The attributes for this class matches the arguments of
-  `tf.keras.optimizer.experimental.Adam`.
+  `tf_keras.optimizer.experimental.Adam`.
 
   Attributes:
     name: name of the optimizer.
     beta_1: decay rate for 1st order moments.
     beta_2: decay rate for 2st order moments.
     epsilon: epsilon value used for numerical stability in Adam optimizer.
     amsgrad: boolean. Whether to apply AMSGrad variant of this algorithm from
@@ -216,16 +216,15 @@
   jit_compile: bool = False
 
 
 @dataclasses.dataclass
 class LAMBConfig(BaseOptimizerConfig):
   """Configuration for LAMB optimizer.
 
-  The attributes for this class matches the arguments of
-  tensorflow_addons.optimizers.LAMB.
+  The attributes for this class matches the arguments of LAMB optimizer.
 
   Attributes:
     name: name of the optimizer.
     beta_1: decay rate for 1st order moments.
     beta_2: decay rate for 2st order moments.
     epsilon: epsilon value used for numerical stability in LAMB optimizer.
     weight_decay_rate: float. Weight decay rate. Default to 0.
@@ -335,7 +334,41 @@
   step_offset: int = 0
   clipping_threshold: float = 1.0
   min_dim_size_to_factor: int = 128
   epsilon1: float = 1e-30
   epsilon2: float = 1e-3
   weight_decay: Optional[float] = None
   include_in_weight_decay: Optional[str] = None
+
+
+@dataclasses.dataclass
+class AdafactorKerasConfig(BaseOptimizerConfig):
+  """Configuration for AdafactorKeras optimizer.
+
+  The attributes for this class matches the arguments of the Adafactor
+  implementation provided by keras.
+
+  Attributes:
+          learning_rate: Initial value for the learning rate: either a floating
+            point value, or a
+            `tf_keras.optimizers.schedules.LearningRateSchedule` instance.
+            Defaults to 0.001.
+        beta_2_decay: float, defaults to -0.8. The decay rate of `beta_2`.
+        epsilon_1: float, defaults to 1e-30. A small offset to keep denominator
+          away from 0.
+        epsilon_2: float, defaults to 1e-3. A small offset to avoid learning
+          rate becoming too small by time.
+        clip_threshold: float, defaults to 1.0. Clipping threshold. This is a
+          part of Adafactor algorithm, independent from `clipnorm`, `clipvalue`
+          and `global_clipnorm`.
+        relative_step: bool, defaults to True. If `learning_rate` is a constant
+          and `relative_step=True`, learning rate will be adjusted based on
+          current iterations. This is a default learning rate decay in
+          Adafactor.
+  """
+  name: str = "Adafactor"
+  learning_rate: float = 0.001
+  beta_2_decay: float = -0.8
+  epsilon_1: float = 1e-30
+  epsilon_2: float = 1e-3
+  clip_threshold: float = 1.0
+  relative_step: bool = True
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/ema_optimizer.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/ema_optimizer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,58 +10,85 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Exponential moving average optimizer."""
 
-from typing import List, Optional, Text
+from typing import List, Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # pylint: disable=protected-access
 
 
-class ExponentialMovingAverage(tf.keras.optimizers.legacy.Optimizer):
+def maybe_merge_call(fn, strategy, *args, **kwargs):
+  """Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.
+
+  The caller of this utility function requests to invoke `fn` via `merge_call`
+  at `tf.distribute.Strategy`'s best efforts. It is `tf.distribute`'s internal
+  whether the request is honored, depending on the `Strategy`. See
+  `tf.distribute.ReplicaContext.merge_call()` for more information.
+
+  This is adapted from tensorflow/python/distribute/merge_call_interim.py.
+
+  Args:
+    fn: the function to be invoked.
+    strategy: the `tf.distribute.Strategy` to call `fn` with.
+    *args: the positional arguments to be passed in to `fn`.
+    **kwargs: the keyword arguments to be passed in to `fn`.
+
+  Returns:
+    The return value of the `fn` call.
+  """
+  if strategy.extended._use_merge_call():
+    return tf.distribute.get_replica_context().merge_call(
+        fn, args=args, kwargs=kwargs
+    )
+  else:
+    return fn(strategy, *args, **kwargs)
+
+
+class ExponentialMovingAverage(tf_keras.optimizers.legacy.Optimizer):
   """Optimizer that computes an exponential moving average of the variables.
 
   Empirically it has been found that using the moving average of the trained
   parameters of a deep network is better than using its trained parameters
   directly. This optimizer allows you to compute this moving average and swap
   the variables at save time so that any code outside of the training loop
   will use by default the average values instead of the original ones.
 
   Example of usage for training:
   ```python
-  opt = tf.keras.optimizers.SGD(learning_rate)
+  opt = tf_keras.optimizers.SGD(learning_rate)
   opt = ExponentialMovingAverage(opt)
 
   opt.shadow_copy(model)
   ```
 
   At test time, swap the shadow variables to evaluate on the averaged weights:
   ```python
   opt.swap_weights()
   # Test eval the model here
   opt.swap_weights()
   ```
   """
 
   def __init__(self,
-               optimizer: tf.keras.optimizers.Optimizer,
+               optimizer: tf_keras.optimizers.Optimizer,
                trainable_weights_only: bool = True,
                average_decay: float = 0.99,
                start_step: int = 0,
                dynamic_decay: bool = True,
-               name: Text = 'ExponentialMovingAverage',
+               name: str = 'ExponentialMovingAverage',
                **kwargs):
     """Construct a new ExponentialMovingAverage optimizer.
 
     Args:
-      optimizer: `tf.keras.optimizers.Optimizer` that will be
+      optimizer: `tf_keras.optimizers.Optimizer` that will be
         used to compute and apply gradients.
       trainable_weights_only: 'bool', if True, only model trainable weights will
         be updated. Otherwise, all model weights will be updated. This mainly
         affects batch normalization parameters.
       average_decay: float. Decay to use to maintain the moving averages
         of trained variables.
       start_step: int. What step to start the moving average.
@@ -76,19 +103,19 @@
     """
     super().__init__(name, **kwargs)
     self._average_decay = average_decay
     self._trainable_weights_only = trainable_weights_only
     self._start_step = tf.constant(start_step, tf.float32)
     self._dynamic_decay = dynamic_decay
     self._optimizer = optimizer
-    self._track_trackable(self._optimizer, 'base_optimizer')
+    self._track_trackable(self._optimizer, 'ema_base_optimizer')
     self._average_weights = None
     self._model_weights = None
 
-  def shadow_copy(self, model: tf.keras.Model):
+  def shadow_copy(self, model: tf_keras.Model):
     """Creates shadow variables for the given model weights."""
 
     if self._trainable_weights_only:
       self._model_weights = model.trainable_variables
     else:
       self._model_weights = model.variables
     for var in self._model_weights:
@@ -102,80 +129,94 @@
   def has_shadow_copy(self):
     """Whether this optimizer has created shadow variables."""
     return self._model_weights is not None and self._average_weights is not None
 
   def _create_slots(self, var_list):
     self._optimizer._create_slots(var_list=var_list)  # pylint: disable=protected-access
 
-  def apply_gradients(self, grads_and_vars, name: Optional[Text] = None):
+  def apply_gradients(self, grads_and_vars, name: Optional[str] = None):
     result = self._optimizer.apply_gradients(grads_and_vars, name)
-    self.update_average(self.iterations)
+    maybe_merge_call(self.update_average, tf.distribute.get_strategy())
     return result
 
   @tf.function
-  def update_average(self, step: tf.Tensor):
-    step = tf.cast(step, tf.float32)
+  def update_average(self, strategy):
+    # Compute current decay value.
+    step = tf.cast(self.iterations, tf.float32)
     if step < self._start_step:
       decay = tf.constant(0., tf.float32)
     elif self._dynamic_decay:
       decay = step - self._start_step
       decay = tf.minimum(self._average_decay, (1. + decay) / (10. + decay))
     else:
       decay = self._average_decay
 
-    def _apply_moving(v_moving, v_normal):
-      diff = v_moving - v_normal
-      v_moving.assign_sub(tf.cast(1. - decay, v_moving.dtype) * diff)
-      return v_moving
-
-    def _update(strategy, v_moving_and_v_normal):
-      for v_moving, v_normal in v_moving_and_v_normal:
-        strategy.extended.update(v_moving, _apply_moving, args=(v_normal,))
-
-    ctx = tf.distribute.get_replica_context()
-    return ctx.merge_call(_update, args=(zip(self._average_weights,
-                                             self._model_weights),))
+    def _apply_moving(average, normal):
+      diff = average - normal
+      average.assign_sub(tf.cast(1.0 - decay, average.dtype) * diff)
+      return average
+
+    # Update moving average with the latest value.
+    for average, normal in zip(self._average_weights, self._model_weights):
+      strategy.extended.update(
+          average, _apply_moving, args=(normal,), group=False
+      )
 
   def swap_weights(self):
     """Swap the average and moving weights.
 
     This is a convenience method to allow one to evaluate the averaged weights
     at test time. Loads the weights stored in `self._average` into the model,
     keeping a copy of the original model weights. Swapping twice will return
     the original weights.
     """
     if tf.distribute.in_cross_replica_context():
       strategy = tf.distribute.get_strategy()
       strategy.run(self._swap_weights, args=())
     else:
-      raise ValueError('Swapping weights must occur under a '
-                       'tf.distribute.Strategy')
+      raise ValueError(
+          'Swapping weights must occur under a tf.distribute.Strategy.'
+      )
 
   @tf.function
   def _swap_weights(self):
     def fn_0(a, b):
       a.assign_add(b)
       return a
     def fn_1(b, a):
       b.assign(a - b)
       return b
     def fn_2(a, b):
       a.assign_sub(b)
       return a
 
-    def swap(strategy, a_and_b):
+    def _swap(strategy, a_and_b):
       """Swap `a` and `b` and mirror to all devices."""
       for a, b in a_and_b:
         strategy.extended.update(a, fn_0, args=(b,))  # a = a + b
         strategy.extended.update(b, fn_1, args=(a,))  # b = a - b
         strategy.extended.update(a, fn_2, args=(b,))  # a = a - b
 
-    ctx = tf.distribute.get_replica_context()
-    return ctx.merge_call(
-        swap, args=(zip(self._average_weights, self._model_weights),))
+    # Use merge_call if requested by strategy and always for TPUStrategy as
+    # the use of merge_call is not recommended and deprecated for other
+    # strategies such as mirrored strategy (MS) and multi-worker mirrored
+    # strategy (MWMS) if nccl/collective_ops are used, which can operate in
+    # pure replica context.
+    strategy = tf.distribute.get_strategy()
+    if isinstance(strategy, tf.distribute.TPUStrategy):
+      maybe_merge_call(
+          _swap,
+          strategy,
+          zip(self._average_weights, self._model_weights),
+      )
+    else:
+      _swap(
+          strategy,
+          zip(self._average_weights, self._model_weights),
+      )
 
   def assign_average_vars(self, var_list: List[tf.Variable]):
     """Assign variables in var_list with their respective averages.
 
     Args:
       var_list: List of model variables to be assigned to their average.
     Returns:
@@ -234,22 +275,22 @@
 
   def _resource_apply_sparse_duplicate_indices(self, grad, var, indices):
     return self._optimizer._resource_apply_sparse_duplicate_indices(
         grad, var, indices)
 
   def get_config(self):
     config = {
-        'optimizer': tf.keras.optimizers.serialize(self._optimizer),
+        'optimizer': tf_keras.optimizers.serialize(self._optimizer),
         'average_decay': self._average_decay,
         'start_step': self._start_step,
         'dynamic_decay': self._dynamic_decay,
     }
     base_config = super(ExponentialMovingAverage, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
-    optimizer = tf.keras.optimizers.deserialize(
+    optimizer = tf_keras.optimizers.deserialize(
         config.pop('optimizer'),
         custom_objects=custom_objects,
     )
     return cls(optimizer, **config)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/lars_optimizer.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/lars.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,21 +12,21 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Layer-wise adaptive rate scaling optimizer."""
 import re
 from typing import Text, List, Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 # pylint: disable=protected-access
 
 
-class LARS(tf.keras.optimizers.legacy.Optimizer):
+class LARS(tf_keras.optimizers.legacy.Optimizer):
   """Layer-wise Adaptive Rate Scaling for large batch training.
 
   Introduced by "Large Batch Training of Convolutional Networks" by Y. You,
   I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)
   """
 
   def __init__(self,
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/legacy_adamw.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/legacy_adamw.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,18 +13,18 @@
 # limitations under the License.
 
 """Adam optimizer with weight decay that exactly matches the original BERT."""
 
 import re
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-class AdamWeightDecay(tf.keras.optimizers.legacy.Adam):
+class AdamWeightDecay(tf_keras.optimizers.legacy.Adam):
   """Adam enables L2 weight decay and clip_by_global_norm on gradients.
 
   [Warning!]: Keras optimizer supports gradient clipping and has an AdamW
   implementation. Please consider evaluating the choice in Keras package.
 
   Just adding the square of the weights to the loss function is *not* the
   correct way of using L2 regularization/weight decay with Adam, since that will
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/lr_schedule.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/lr_schedule.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,43 +13,44 @@
 # limitations under the License.
 
 """Learning rate schedule classes."""
 
 import math
 from typing import Mapping, Any, Union, Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _make_offset_wrapper(new_class_name: str, base_lr_class):
   """Generates a offset wrapper of learning rate schedule.
 
   It will returns a subclass of the `base_lr_class`, the subclass takes an
   `offset` argument in the constructor. When the new class instance is called,
   the behavior is:
     new_class_object(step) = base_lr_class_object(step - offset)
 
   Example:
     CosineDecayWithOffset = _make_offset_wrapper(
-                     'CosineDecayWithOffset', tf.keras.experimental.CosineDecay)
+                     'CosineDecayWithOffset', 
+                     tf_keras.optimizers.schedules.CosineDecay)
     # Use the lr:
     lr = CosineDecayWithOffset(offset=100, initial_learning_rate=0.1,
                                decay_steps=1000)
-    lr(101) # equals to tf.keras.experimental.CosineDecay(...)(101-100)
+    lr(101) # equals to keras.optimizers.schedules.CosineDecay(...)(101-100)
 
   Args:
     new_class_name: the name of the new class.
     base_lr_class: the base learning rate schedule class. Should be subclass of
-      tf.keras.optimizers.schedules.LearningRateSchedule
+      tf_keras.optimizers.schedules.LearningRateSchedule
 
   Returns:
     A new class (subclass of the base_lr_class) that can take an offset.
   """
   assert issubclass(base_lr_class,
-                    tf.keras.optimizers.schedules.LearningRateSchedule), (
+                    tf_keras.optimizers.schedules.LearningRateSchedule), (
                         "base_lr_class should be subclass of keras "
                         f"LearningRateSchedule, got {base_lr_class}")
 
   # pylint: disable=protected-access,pointless-statement
   def offset_learning_rate_init(self, offset=0, **kwargs):
     """Construct learning rate schedule object.
 
@@ -75,30 +76,32 @@
           "__init__": offset_learning_rate_init,
           "__call__": offset_learning_rate_call
       })
 
 
 PiecewiseConstantDecayWithOffset = _make_offset_wrapper(
     "PiecewiseConstantDecayWithOffset",
-    tf.keras.optimizers.schedules.PiecewiseConstantDecay)
+    tf_keras.optimizers.schedules.PiecewiseConstantDecay)
 PolynomialDecayWithOffset = _make_offset_wrapper(
-    "PolynomialDecayWithOffset", tf.keras.optimizers.schedules.PolynomialDecay)
+    "PolynomialDecayWithOffset", tf_keras.optimizers.schedules.PolynomialDecay)
 ExponentialDecayWithOffset = _make_offset_wrapper(
     "ExponentialDecayWithOffset",
-    tf.keras.optimizers.schedules.ExponentialDecay)
-CosineDecayWithOffset = _make_offset_wrapper("CosineDecayWithOffset",
-                                             tf.keras.experimental.CosineDecay)
+    tf_keras.optimizers.schedules.ExponentialDecay)
+CosineDecayWithOffset = _make_offset_wrapper(
+    "CosineDecayWithOffset",
+    tf_keras.optimizers.schedules.CosineDecay,
+)
 
 
-class LinearWarmup(tf.keras.optimizers.schedules.LearningRateSchedule):
+class LinearWarmup(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Linear warmup schedule."""
 
   def __init__(self,
                after_warmup_lr_sched: Union[
-                   tf.keras.optimizers.schedules.LearningRateSchedule, float],
+                   tf_keras.optimizers.schedules.LearningRateSchedule, float],
                warmup_steps: int,
                warmup_learning_rate: float,
                name: Optional[str] = None):
     """Add linear warmup schedule to a learning rate schedule.
 
     warmup_lr is the initial learning rate, the final learning rate of the
     init_warmup period is the initial learning rate of lr_schedule in use.
@@ -106,78 +109,78 @@
     formula:
       learning_rate = warmup_lr + step / warmup_steps
                     * (final_warmup_lr - warmup_lr).
     Using warmup overrides the learning rate schedule by the number of warmup
     steps.
 
     Args:
-      after_warmup_lr_sched: tf.keras.optimizers.schedules .LearningRateSchedule
+      after_warmup_lr_sched: tf_keras.optimizers.schedules .LearningRateSchedule
         or a constant.
       warmup_steps: Number of the warmup steps.
       warmup_learning_rate: Initial learning rate for the warmup.
       name: Optional, name of warmup schedule.
     """
     super().__init__()
     self._name = name
     self._after_warmup_lr_sched = after_warmup_lr_sched
     self._warmup_steps = warmup_steps
     self._init_warmup_lr = warmup_learning_rate
     if isinstance(after_warmup_lr_sched,
-                  tf.keras.optimizers.schedules.LearningRateSchedule):
+                  tf_keras.optimizers.schedules.LearningRateSchedule):
       self._final_warmup_lr = after_warmup_lr_sched(warmup_steps)
     else:
       self._final_warmup_lr = tf.cast(after_warmup_lr_sched, dtype=tf.float32)
 
   def __call__(self, step: int):
 
     global_step = tf.cast(step, dtype=tf.float32)
 
     linear_warmup_lr = (
         self._init_warmup_lr + global_step / self._warmup_steps *
         (self._final_warmup_lr - self._init_warmup_lr))
 
     if isinstance(self._after_warmup_lr_sched,
-                  tf.keras.optimizers.schedules.LearningRateSchedule):
+                  tf_keras.optimizers.schedules.LearningRateSchedule):
       after_warmup_lr = self._after_warmup_lr_sched(step)
     else:
       after_warmup_lr = tf.cast(self._after_warmup_lr_sched, dtype=tf.float32)
 
     lr = tf.cond(global_step < self._warmup_steps,
                  lambda: linear_warmup_lr,
                  lambda: after_warmup_lr)
     return lr
 
   def get_config(self) -> Mapping[str, Any]:
     if isinstance(self._after_warmup_lr_sched,
-                  tf.keras.optimizers.schedules.LearningRateSchedule):
+                  tf_keras.optimizers.schedules.LearningRateSchedule):
       config = {
           "after_warmup_lr_sched": self._after_warmup_lr_sched.get_config()}  # pytype: disable=attribute-error
     else:
       config = {"after_warmup_lr_sched": self._after_warmup_lr_sched}  # pytype: disable=attribute-error
 
     config.update({
         "warmup_steps": self._warmup_steps,
         "warmup_learning_rate": self._init_warmup_lr,
         "name": self._name
     })
     return config
 
 
-class PolynomialWarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):
+class PolynomialWarmUp(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Applies polynomial warmup schedule on a given learning rate decay schedule."""
 
   def __init__(self,
                after_warmup_lr_sched: Union[
-                   tf.keras.optimizers.schedules.LearningRateSchedule, float],
+                   tf_keras.optimizers.schedules.LearningRateSchedule, float],
                warmup_steps: int,
                power: float = 1.0,
                name: str = "PolynomialWarmup"):
     super().__init__()
     if isinstance(after_warmup_lr_sched,
-                  tf.keras.optimizers.schedules.LearningRateSchedule):
+                  tf_keras.optimizers.schedules.LearningRateSchedule):
       self._initial_learning_rate = after_warmup_lr_sched(warmup_steps)
     else:
       self._initial_learning_rate = tf.cast(
           after_warmup_lr_sched, dtype=tf.float32)
 
     self._warmup_steps = warmup_steps
     self._power = power
@@ -199,42 +202,42 @@
         warmup_percent_done = step_non_zero / warmup_steps_float
 
       warmup_learning_rate = (
           self._initial_learning_rate *
           tf.math.pow(warmup_percent_done, self._power))
 
       if isinstance(self._after_warmup_lr_sched,
-                    tf.keras.optimizers.schedules.LearningRateSchedule):
+                    tf_keras.optimizers.schedules.LearningRateSchedule):
         after_warmup_lr = self._after_warmup_lr_sched(step)
       else:
         after_warmup_lr = tf.cast(self._after_warmup_lr_sched, dtype=tf.float32)
 
       return tf.cond(
           global_step_float < warmup_steps_float,
           lambda: warmup_learning_rate,
           lambda: after_warmup_lr,
           name=name)
 
   def get_config(self) -> Mapping[str, Any]:
     if isinstance(self._after_warmup_lr_sched,
-                  tf.keras.optimizers.schedules.LearningRateSchedule):
+                  tf_keras.optimizers.schedules.LearningRateSchedule):
       config = {
           "after_warmup_lr_sched": self._after_warmup_lr_sched.get_config()}  # pytype: disable=attribute-error
     else:
       config = {"after_warmup_lr_sched": self._after_warmup_lr_sched}  # pytype: disable=attribute-error
 
     config.update({
         "warmup_steps": self._warmup_steps,
         "power": self._power,
         "name": self._name
     })
     return config
 
 
-class DirectPowerDecay(tf.keras.optimizers.schedules.LearningRateSchedule):
+class DirectPowerDecay(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Learning rate schedule follows lr * (step)^power."""
 
   def __init__(self,
                initial_learning_rate: float,
                power: float = 1.0,
                name: str = "DirectPowerDecay"):
     """Initialize configuration of the learning rate schedule.
@@ -263,15 +266,15 @@
     return {
         "initial_learning_rate": self._initial_learning_rate,
         "power": self._power,
         "name": self._name,
     }
 
 
-class PowerAndLinearDecay(tf.keras.optimizers.schedules.LearningRateSchedule):
+class PowerAndLinearDecay(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Learning rate schedule with multiplied by linear decay at the end.
 
   The schedule has the following behavoir.
   Let offset_step = step - offset.
   1) offset_step < 0, the actual learning rate equals initial_learning_rate.
   2) offset_step <= total_decay_steps * (1 - linear_decay_fraction), the
   actual learning rate equals lr * offset_step^power.
@@ -330,15 +333,15 @@
         "power": self._power,
         "linear_decay_fraction": self._linear_decay_fraction,
         "offset": self._offset,
         "name": self._name,
     }
 
 
-class PowerDecayWithOffset(tf.keras.optimizers.schedules.LearningRateSchedule):
+class PowerDecayWithOffset(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Power learning rate decay with offset.
 
   Learning rate equals to `pre_offset_learning_rate` if `step` < `offset`.
   Otherwise, learning rate equals to lr * (step - offset)^power.
   """
 
   def __init__(self,
@@ -383,15 +386,15 @@
         "offset": self._offset,
         "pre_offset_learning_rate": self._pre_offset_lr,
         "name": self._name,
     }
 
 
 class StepCosineDecayWithOffset(
-    tf.keras.optimizers.schedules.LearningRateSchedule):
+    tf_keras.optimizers.schedules.LearningRateSchedule):
   """Stepwise cosine learning rate decay with offset.
 
   Learning rate is equivalent to one or more cosine decay(s) starting and
   ending at each interval.
 
   ExampleL
 
@@ -456,38 +459,29 @@
 
       init_total_steps = level_total_steps[0]
 
       cosine_learning_rate = ((init_lr - next_init_lr) * (tf.cos(
           tf.constant(math.pi) * (global_step) /
           (init_total_steps)) + 1.0) / 2.0 + next_init_lr)
       learning_rate = cosine_learning_rate
-      tf.compat.v1.logging.info("DEBUG lr %r next lr %r", learning_rate,
-                                cosine_learning_rate)
-      tf.compat.v1.logging.info("DEBUG lr %r next lr %r inittotalstep %r",
-                                init_lr, next_init_lr, init_total_steps)
 
       for i in range(1, num_levels):
         next_init_lr = lr_levels[i]
         next_start_step = lr_steps[i]
         next_total_steps = level_total_steps[i]
         next_next_init_lr = lr_levels[i + 1] if num_levels > i + 1 else 0.
 
-        tf.compat.v1.logging.info(
-            "DEBUG step %r nilr %r nss %r nts %r nnilr %r", global_step,
-            next_init_lr, next_start_step, next_total_steps, next_next_init_lr)
         next_cosine_learning_rate = ((next_init_lr - next_next_init_lr) *
                                      (tf.cos(
                                          tf.constant(math.pi) *
                                          (global_step - next_start_step) /
                                          (next_total_steps)) + 1.0) / 2.0 +
                                      next_next_init_lr)
         learning_rate = tf.where(global_step >= next_start_step,
                                  next_cosine_learning_rate, learning_rate)
-        tf.compat.v1.logging.info("DEBUG lr %r next lr %r", learning_rate,
-                                  next_cosine_learning_rate)
 
     return learning_rate
 
   def get_config(self):
     return {
         "boundaries": self.boundaries,
         "values": self.values,
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/lr_schedule_test.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/lr_schedule_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for lr_schedule."""
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling.optimization import lr_schedule
 
 
 class PowerAndLinearDecayTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/optimizer_factory.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/optimizer_factory.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,61 +1,62 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Optimizer factory class."""
-from typing import Callable, Optional, Union, List, Tuple
+from typing import Callable, List, Optional, Tuple, Union
 
 import gin
-import tensorflow as tf
-import tensorflow_addons.optimizers as tfa_optimizers
+import tensorflow as tf, tf_keras
 
 from official.modeling.optimization import slide_optimizer
 from official.modeling.optimization import adafactor_optimizer
 from official.modeling.optimization import ema_optimizer
-from official.modeling.optimization import lars_optimizer
+from official.modeling.optimization import lamb
+from official.modeling.optimization import lars
 from official.modeling.optimization import legacy_adamw
 from official.modeling.optimization import lr_schedule
 from official.modeling.optimization.configs import optimization_config as opt_cfg
 
 # Optimizer CLS to be used in both legacy and new path.
 SHARED_OPTIMIZERS = {
-    'sgd_experimental': tf.keras.optimizers.experimental.SGD,
-    'adam_experimental': tf.keras.optimizers.experimental.Adam,
+    'sgd_experimental': tf_keras.optimizers.experimental.SGD,
+    'adam_experimental': tf_keras.optimizers.experimental.Adam,
     'adamw': legacy_adamw.AdamWeightDecay,
-    'adamw_experimental': tf.keras.optimizers.experimental.AdamW,
-    'lamb': tfa_optimizers.LAMB,
-    'lars': lars_optimizer.LARS,
+    'adamw_experimental': tf_keras.optimizers.experimental.AdamW,
+    'lamb': lamb.LAMB,
+    'lars': lars.LARS,
     'slide': slide_optimizer.SLIDE,
     'adafactor': adafactor_optimizer.Adafactor,
+    'adafactor_keras': tf_keras.optimizers.Adafactor,
 }
 
 LEGACY_OPTIMIZERS_CLS = {
-    'sgd': tf.keras.optimizers.legacy.SGD,
-    'adam': tf.keras.optimizers.legacy.Adam,
-    'rmsprop': tf.keras.optimizers.legacy.RMSprop,
-    'adagrad': tf.keras.optimizers.legacy.Adagrad,
+    'sgd': tf_keras.optimizers.legacy.SGD,
+    'adam': tf_keras.optimizers.legacy.Adam,
+    'rmsprop': tf_keras.optimizers.legacy.RMSprop,
+    'adagrad': tf_keras.optimizers.legacy.Adagrad,
 }
 LEGACY_OPTIMIZERS_CLS.update(SHARED_OPTIMIZERS)
 
 NEW_OPTIMIZERS_CLS = {
-    'sgd': tf.keras.optimizers.experimental.SGD,
-    'adam': tf.keras.optimizers.experimental.Adam,
-    'rmsprop': tf.keras.optimizers.experimental.RMSprop,
-    'adagrad': tf.keras.optimizers.experimental.Adagrad,
+    'sgd': tf_keras.optimizers.experimental.SGD,
+    'adam': tf_keras.optimizers.experimental.Adam,
+    'rmsprop': tf_keras.optimizers.experimental.RMSprop,
+    'adagrad': tf_keras.optimizers.experimental.Adagrad,
 }
 NEW_OPTIMIZERS_CLS.update(SHARED_OPTIMIZERS)
 
 LR_CLS = {
     'stepwise': lr_schedule.PiecewiseConstantDecayWithOffset,
     'polynomial': lr_schedule.PolynomialDecayWithOffset,
     'exponential': lr_schedule.ExponentialDecayWithOffset,
@@ -70,27 +71,27 @@
     'linear': lr_schedule.LinearWarmup,
     'polynomial': lr_schedule.PolynomialWarmUp
 }
 
 
 def register_optimizer_cls(key: str,
                            optimizer_config_cls: Union[
-                               tf.keras.optimizers.Optimizer,
-                               tf.keras.optimizers.legacy.Optimizer,
-                               tf.keras.optimizers.experimental.Optimizer
+                               tf_keras.optimizers.Optimizer,
+                               tf_keras.optimizers.legacy.Optimizer,
+                               tf_keras.optimizers.experimental.Optimizer
                            ],
                            use_legacy_optimizer: bool = True):
   """Register customize optimizer cls.
 
   The user will still need to subclass data classes in
   configs.optimization_config to be used with OptimizerFactory.
 
   Args:
     key: A string to that the optimizer_config_cls is registered with.
-    optimizer_config_cls: A class which inherits tf.keras.optimizers.Optimizer.
+    optimizer_config_cls: A class which inherits tf_keras.optimizers.Optimizer.
     use_legacy_optimizer: A boolean that indicates if using legacy optimizers.
   """
   if use_legacy_optimizer:
     if key in LEGACY_OPTIMIZERS_CLS:
       raise ValueError('%s already registered in LEGACY_OPTIMIZERS_CLS.' % key)
     LEGACY_OPTIMIZERS_CLS[key] = optimizer_config_cls
   else:
@@ -164,15 +165,15 @@
     """Build learning rate.
 
     Builds learning rate from config. Learning rate schedule is built according
     to the learning rate config. If learning rate type is consant,
     lr_config.learning_rate is returned.
 
     Returns:
-      tf.keras.optimizers.schedules.LearningRateSchedule instance. If
+      tf_keras.optimizers.schedules.LearningRateSchedule instance. If
       learning rate type is consant, lr_config.learning_rate is returned.
     """
     if self._lr_type == 'constant':
       lr = self._lr_config.learning_rate
     else:
       lr = LR_CLS[self._lr_type](**self._lr_config.as_dict())
 
@@ -180,46 +181,46 @@
       lr = WARMUP_CLS[self._warmup_type](lr, **self._warmup_config.as_dict())
 
     return lr
 
   @gin.configurable
   def build_optimizer(
       self,
-      lr: Union[tf.keras.optimizers.schedules.LearningRateSchedule, float],
+      lr: Union[tf_keras.optimizers.schedules.LearningRateSchedule, float],
       gradient_aggregator: Optional[Callable[
           [List[Tuple[tf.Tensor, tf.Tensor]]], List[Tuple[tf.Tensor,
                                                           tf.Tensor]]]] = None,
       gradient_transformers: Optional[List[Callable[
           [List[Tuple[tf.Tensor, tf.Tensor]]], List[Tuple[tf.Tensor,
                                                           tf.Tensor]]]]] = None,
-      postprocessor: Optional[Callable[[tf.keras.optimizers.Optimizer],
-                                       tf.keras.optimizers.Optimizer]] = None,
+      postprocessor: Optional[Callable[[tf_keras.optimizers.Optimizer],
+                                       tf_keras.optimizers.Optimizer]] = None,
       use_legacy_optimizer: bool = True):
     """Build optimizer.
 
     Builds optimizer from config. It takes learning rate as input, and builds
     the optimizer according to the optimizer config. Typically, the learning
     rate built using self.build_lr() is passed as an argument to this method.
 
     Args:
       lr: A floating point value, or a
-        tf.keras.optimizers.schedules.LearningRateSchedule instance.
+        tf_keras.optimizers.schedules.LearningRateSchedule instance.
       gradient_aggregator: Optional function to overwrite gradient aggregation.
       gradient_transformers: Optional list of functions to use to transform
         gradients before applying updates to Variables. The functions are
         applied after gradient_aggregator. The functions should accept and
         return a list of (gradient, variable) tuples. clipvalue, clipnorm,
         global_clipnorm should not be set when gradient_transformers is passed.
       postprocessor: An optional function for postprocessing the optimizer. It
         takes an optimizer and returns an optimizer.
       use_legacy_optimizer: A boolean that indicates if using legacy optimizers.
 
     Returns:
-      `tf.keras.optimizers.legacy.Optimizer` or
-      `tf.keras.optimizers.experimental.Optimizer` instance.
+      `tf_keras.optimizers.legacy.Optimizer` or
+      `tf_keras.optimizers.experimental.Optimizer` instance.
     """
 
     optimizer_dict = self._optimizer_config.as_dict()
     ## Delete clipnorm, clipvalue, global_clipnorm if None
     if optimizer_dict['clipnorm'] is None:
       del optimizer_dict['clipnorm']
     if optimizer_dict['clipvalue'] is None:
@@ -248,19 +249,19 @@
         raise ValueError(
             'EMA can only work with the legacy optimizer, please set '
             '`use_legacy_optimizer=True`.')
       optimizer = ema_optimizer.ExponentialMovingAverage(
           optimizer, **self._ema_config.as_dict())
     if postprocessor:
       optimizer = postprocessor(optimizer)
-    if isinstance(optimizer, tf.keras.optimizers.Optimizer):
+    if isinstance(optimizer, tf_keras.optimizers.Optimizer):
       return optimizer
     # The following check makes sure the function won't break in older TF
     # version because of missing the experimental/legacy package.
-    if hasattr(tf.keras.optimizers, 'experimental'):
-      if isinstance(optimizer, tf.keras.optimizers.experimental.Optimizer):
+    if hasattr(tf_keras.optimizers, 'experimental'):
+      if isinstance(optimizer, tf_keras.optimizers.experimental.Optimizer):
         return optimizer
-    if hasattr(tf.keras.optimizers, 'legacy'):
-      if isinstance(optimizer, tf.keras.optimizers.legacy.Optimizer):
+    if hasattr(tf_keras.optimizers, 'legacy'):
+      if isinstance(optimizer, tf_keras.optimizers.legacy.Optimizer):
         return optimizer
     raise TypeError('OptimizerFactory.build_optimizer returning a '
                     'non-optimizer object: {}'.format(optimizer))
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/optimizer_factory_test.py` & `tf-models-no-deps-2.16.0/official/modeling/optimization/optimizer_factory_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for optimizer_factory.py."""
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling.optimization import optimizer_factory
 from official.modeling.optimization.configs import optimization_config
 
 
 class OptimizerFactoryTest(tf.test.TestCase, parameterized.TestCase):
 
@@ -95,15 +95,15 @@
     opt_factory = optimizer_factory.OptimizerFactory(opt_config)
     lr = opt_factory.build_learning_rate()
 
     # Dummy function to zero out gradients.
     zero_grads = lambda gv: [(tf.zeros_like(g), v) for g, v in gv]
 
     optimizer = opt_factory.build_optimizer(lr, gradient_aggregator=zero_grads)
-    if isinstance(optimizer, tf.keras.optimizers.experimental.Optimizer):
+    if isinstance(optimizer, tf_keras.optimizers.experimental.Optimizer):
       self.skipTest('New Keras optimizer does not support '
                     '`gradient_aggregator` arg.')
 
     var0 = tf.Variable([1.0, 2.0])
     var1 = tf.Variable([3.0, 4.0])
 
     grads0 = tf.constant([1.0, 1.0])
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/optimization/slide_optimizer.py` & `tf-models-no-deps-2.16.0/official/projects/yt8m/tasks/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,20 +1,16 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""SLIDE optimizer.
-
-A new optimizer that will be open sourced soon.
-"""
-
-SLIDE = "Unimplemented"
+"""Tasks package definition."""
+from official.projects.yt8m.tasks import yt8m_task
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/performance.py` & `tf-models-no-deps-2.16.0/official/modeling/performance.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,43 +11,43 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Functions and classes related to training performance."""
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def configure_optimizer(optimizer,
                         use_float16=False,
                         loss_scale=None,
                         use_graph_rewrite=None):
   """Configures optimizer object with performance options."""
   if use_graph_rewrite is not None:
     logging.warning('`use_graph_rewrite` is deprecated inside '
                     '`configure_optimizer`. Please remove the usage.')
   del use_graph_rewrite
   if use_float16:
     if loss_scale in (None, 'dynamic'):
-      optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)
+      optimizer = tf_keras.mixed_precision.LossScaleOptimizer(optimizer)
     else:
       # loss_scale is a number. We interpret that as a fixed loss scale.
-      optimizer = tf.keras.mixed_precision.LossScaleOptimizer(
+      optimizer = tf_keras.mixed_precision.LossScaleOptimizer(
           optimizer, dynamic=False, initial_scale=loss_scale)
   return optimizer
 
 
 def set_mixed_precision_policy(dtype, loss_scale=None):
-  """Sets the global `tf.keras.mixed_precision.Policy`."""
+  """Sets the global `tf_keras.mixed_precision.Policy`."""
   # TODO(b/191894773): Remove loss_scale argument
   assert loss_scale is None, (
       'The loss_scale argument must be None. The argument exists for '
       'historical reasons and will be removed soon.')
   if dtype == tf.float16:
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
   elif dtype == tf.bfloat16:
-    tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')
+    tf_keras.mixed_precision.set_global_policy('mixed_bfloat16')
   elif dtype == tf.float32:
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
   else:
     raise ValueError('Unexpected dtype: %s' % dtype)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/privacy/__init__.py` & `tf-models-no-deps-2.16.0/official/modeling/privacy/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/privacy/configs.py` & `tf-models-no-deps-2.16.0/official/modeling/privacy/configs.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/privacy/configs_test.py` & `tf-models-no-deps-2.16.0/official/modeling/privacy/configs_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for configs."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling.privacy import configs
 
 
 class ConfigsTest(tf.test.TestCase):
 
   def test_clipping_norm_default(self):
     clipping_norm = configs.DifferentialPrivacyConfig().clipping_norm
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/privacy/ops.py` & `tf-models-no-deps-2.16.0/official/modeling/privacy/ops.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,32 +11,53 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Ops for differential privacy (gradient) transforms."""
 
 from typing import List, Tuple
-import tensorflow as tf
+import warnings
+
+import tensorflow as tf, tf_keras
 
 
 def clip_l2_norm(grads_vars: List[Tuple[tf.Tensor, tf.Tensor]],
                  l2_norm_clip: float) -> List[Tuple[tf.Tensor, tf.Tensor]]:
-  """Clip gradients by global norm."""
+  """DEPRECATED Clip gradients by global norm.
+
+  Args:
+    grads_vars: List of tuple of gradient and its corresponding variables
+    l2_norm_clip: Float for differential privacy norm
+
+  Returns:
+    List of clipped gradients and its corresponding variables
+  """
+  warnings.warn("`clip_l2_norm` deprecated.",
+                DeprecationWarning)
 
   gradients = []
   variables = []
   for (g, v) in grads_vars:
     gradients.append(g)
     variables.append(v)
   clipped_gradients = tf.clip_by_global_norm(gradients, l2_norm_clip)[0]
   return list(zip(clipped_gradients, variables))
 
 
 def add_noise(grads_vars: List[Tuple[tf.Tensor, tf.Tensor]],
               noise_stddev: float) -> List[Tuple[tf.Tensor, tf.Tensor]]:
-  """Add noise to gradients."""
+  """DEPRECATED Add noise to gradients.
+
+  Args:
+    grads_vars: List of tuple of gradient and its corresponding variables
+    noise_stddev: Noise multiplier
+
+  Returns:
+    List of noised gradients and its corresponding variables
+  """
+  warnings.warn("`add_noise` deprecated.", DeprecationWarning)
+
   ret = []
   for (g, v) in grads_vars:
     noise = tf.random.normal(tf.shape(g), stddev=noise_stddev)
     ret.append((g + noise, v))
   return ret
-
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/privacy/ops_test.py` & `tf-models-no-deps-2.16.0/official/modeling/privacy/ops_test.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for ops."""
 
 from unittest import mock
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling.privacy import ops
 
 
 class OpsTest(tf.test.TestCase):
 
   def test_clip_l2_norm(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/tf_utils.py` & `tf-models-no-deps-2.16.0/official/modeling/tf_utils.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,24 +11,25 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Common TF utilities."""
 
 import functools
+import inspect
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.util import deprecation
 from official.modeling import activations
 
 
 @deprecation.deprecated(
     None,
-    "tf.keras.layers.Layer supports multiple positional args and kwargs as "
+    "tf_keras.layers.Layer supports multiple positional args and kwargs as "
     "input tensors. pack/unpack inputs to override __call__ is no longer "
     "needed.")
 def pack_inputs(inputs):
   """Pack a list of `inputs` tensors to a tuple.
 
   Args:
     inputs: a list of tensors.
@@ -45,15 +46,15 @@
     else:
       outputs.append(x)
   return tuple(outputs)
 
 
 @deprecation.deprecated(
     None,
-    "tf.keras.layers.Layer supports multiple positional args and kwargs as "
+    "tf_keras.layers.Layer supports multiple positional args and kwargs as "
     "input tensors. pack/unpack inputs to override __call__ is no longer "
     "needed.")
 def unpack_inputs(inputs):
   """unpack a tuple of `inputs` tensors to a tuple.
 
   Args:
     inputs: a list of tensors.
@@ -84,15 +85,15 @@
 
 
 def get_activation(identifier, use_keras_layer=False, **kwargs):
   """Maps an identifier to a Python function, e.g., "relu" => `tf.nn.relu`.
 
   It checks string first and if it is one of customized activation not in TF,
   the corresponding activation will be returned. For non-customized activation
-  names and callable identifiers, always fallback to tf.keras.activations.get.
+  names and callable identifiers, always fallback to tf_keras.activations.get.
 
   Prefers using keras layers when use_keras_layer=True. Now it only supports
   'relu', 'linear', 'identity', 'swish', 'mish', 'leaky_relu', and 'gelu'.
 
   Args:
     identifier: String name of the activation function or callable.
     use_keras_layer: If True, use keras layer if identifier is allow-listed.
@@ -117,27 +118,27 @@
           "leaky_relu": functools.partial(tf.nn.leaky_relu, **kwargs),
           "hard_swish": activations.hard_swish,
           "hard_sigmoid": activations.hard_sigmoid,
           "mish": activations.mish,
           "gelu": functools.partial(tf.nn.gelu, **kwargs),
       }
       if identifier in keras_layer_allowlist:
-        return tf.keras.layers.Activation(keras_layer_allowlist[identifier])
+        return tf_keras.layers.Activation(keras_layer_allowlist[identifier])
     name_to_fn = {
         "gelu": activations.gelu,
         "simple_swish": activations.simple_swish,
         "hard_swish": activations.hard_swish,
         "relu6": activations.relu6,
         "hard_sigmoid": activations.hard_sigmoid,
         "identity": activations.identity,
         "mish": activations.mish,
     }
     if identifier in name_to_fn:
-      return tf.keras.activations.get(name_to_fn[identifier])
-  return tf.keras.activations.get(identifier)
+      return tf_keras.activations.get(name_to_fn[identifier])
+  return tf_keras.activations.get(identifier)
 
 
 def get_shape_list(tensor, expected_rank=None, name=None):
   """Returns a list of the shape of tensor, preferring static dimensions.
 
   Args:
     tensor: A tf.Tensor object to find the shape of.
@@ -281,13 +282,91 @@
       raise RuntimeError(f"{value} has unknown batch.")
     return context.all_gather(value, axis=axis)
 
 
 def clone_initializer(initializer):
   # Keras initializer is going to be stateless, which mean reusing the same
   # initializer will produce same init value when the shapes are the same.
-  if isinstance(initializer, tf.keras.initializers.Initializer):
+  if isinstance(initializer, tf_keras.initializers.Initializer):
     return initializer.__class__.from_config(initializer.get_config())
   # When the input is string/dict or other serialized configs, caller will
   # create a new keras Initializer instance based on that, and we don't need to
   # do anything
   return initializer
+
+
+def serialize_keras_object(obj):
+  if hasattr(tf_keras.utils, "legacy"):
+    return tf_keras.utils.legacy.serialize_keras_object(obj)
+  else:
+    return tf_keras.utils.serialize_keras_object(obj)
+
+
+def deserialize_keras_object(
+    config, module_objects=None, custom_objects=None, printable_module_name=None
+):
+  if hasattr(tf_keras.utils, "legacy"):
+    return tf_keras.utils.legacy.deserialize_keras_object(
+        config, custom_objects, module_objects, printable_module_name
+    )
+  else:
+    return tf_keras.utils.deserialize_keras_object(
+        config, custom_objects, module_objects, printable_module_name
+    )
+
+
+def serialize_layer(layer, use_legacy_format=False):
+  if (
+      "use_legacy_format"
+      in inspect.getfullargspec(tf_keras.layers.serialize).args
+  ):
+    return tf_keras.layers.serialize(layer, use_legacy_format=use_legacy_format)
+  else:
+    return tf_keras.layers.serialize(layer)
+
+
+def serialize_initializer(initializer, use_legacy_format=False):
+  if (
+      "use_legacy_format"
+      in inspect.getfullargspec(tf_keras.initializers.serialize).args
+  ):
+    return tf_keras.initializers.serialize(
+        initializer, use_legacy_format=use_legacy_format
+    )
+  else:
+    return tf_keras.initializers.serialize(initializer)
+
+
+def serialize_regularizer(regularizer, use_legacy_format=False):
+  if (
+      "use_legacy_format"
+      in inspect.getfullargspec(tf_keras.regularizers.serialize).args
+  ):
+    return tf_keras.regularizers.serialize(
+        regularizer, use_legacy_format=use_legacy_format
+    )
+  else:
+    return tf_keras.regularizers.serialize(regularizer)
+
+
+def serialize_constraint(constraint, use_legacy_format=False):
+  if (
+      "use_legacy_format"
+      in inspect.getfullargspec(tf_keras.constraints.serialize).args
+  ):
+    return tf_keras.constraints.serialize(
+        constraint, use_legacy_format=use_legacy_format
+    )
+  else:
+    return tf_keras.constraints.serialize(constraint)
+
+
+def serialize_activation(activation, use_legacy_format=False):
+  if (
+      "use_legacy_format"
+      in inspect.getfullargspec(tf_keras.activations.serialize).args
+  ):
+    return tf_keras.activations.serialize(
+        activation, use_legacy_format=use_legacy_format
+    )
+  else:
+    return tf_keras.activations.serialize(activation)
```

### Comparing `tf-models-no-deps-2.11.2/official/modeling/tf_utils_test.py` & `tf-models-no-deps-2.16.0/official/modeling/tf_utils_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,26 +11,27 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for tf_utils."""
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.modeling import tf_utils
 
 
 def all_strategy_combinations():
   return combinations.combine(
       strategy=[
           strategy_combinations.cloud_tpu_strategy,
-          strategy_combinations.mirrored_strategy_with_two_gpus,
+          # TODO(b/285797201):disable multi-gpu tests due to hanging.
+          # strategy_combinations.mirrored_strategy_with_two_gpus,
       ],
       mode='eager',
   )
 
 
 class TFUtilsTest(tf.test.TestCase, parameterized.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/configs/bert.py` & `tf-models-no-deps-2.16.0/official/nlp/configs/bert.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -33,13 +33,15 @@
   cls_token_idx: int = 0
   name: Optional[Text] = None
 
 
 @dataclasses.dataclass
 class PretrainerConfig(base_config.Config):
   """Pretrainer configuration."""
-  encoder: encoders.EncoderConfig = encoders.EncoderConfig()
+  encoder: encoders.EncoderConfig = dataclasses.field(
+      default_factory=encoders.EncoderConfig
+  )
   cls_heads: List[ClsHeadConfig] = dataclasses.field(default_factory=list)
   mlm_activation: str = "gelu"
   mlm_initializer_range: float = 0.02
   # Currently only used for mobile bert.
   mlm_output_weights_use_proj: bool = False
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/configs/encoders.py` & `tf-models-no-deps-2.16.0/official/nlp/configs/encoders.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,18 +13,18 @@
 # limitations under the License.
 
 """Transformer Encoders.
 
 Includes configurations and factory methods.
 """
 import dataclasses
-from typing import Optional, Sequence
+from typing import Optional, Sequence, Union
 
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 from official.nlp.modeling import networks
 from official.projects.bigbird import encoder as bigbird_encoder
 
@@ -42,19 +42,48 @@
   attention_dropout_rate: float = 0.1
   max_position_embeddings: int = 512
   type_vocab_size: int = 2
   initializer_range: float = 0.02
   embedding_size: Optional[int] = None
   output_range: Optional[int] = None
   return_all_encoder_outputs: bool = False
+  return_attention_scores: bool = False
+  return_word_embeddings: bool = False
   # Pre/Post-LN Transformer
   norm_first: bool = False
 
 
 @dataclasses.dataclass
+class FunnelEncoderConfig(hyperparams.Config):
+  """Funnel encoder configuration."""
+  vocab_size: int = 30522
+  hidden_size: int = 768
+  num_layers: int = 12
+  num_attention_heads: int = 12
+  max_position_embeddings: int = 512
+  type_vocab_size: int = 16
+  inner_dim: int = 3072
+  hidden_activation: str = "gelu"
+  approx_gelu: bool = True
+  dropout_rate: float = 0.1
+  attention_dropout_rate: float = 0.1
+  pool_type: str = "max"
+  pool_stride: Union[int, Sequence[Union[int, float]]] = 2
+  unpool_length: int = 0
+  initializer_range: float = 0.02
+  output_range: Optional[int] = None
+  embedding_width: Optional[int] = None
+  embedding_layer: Optional[tf_keras.layers.Layer] = None
+  norm_first: bool = False
+  share_rezero: bool = False
+  append_dense_inputs: bool = False
+  transformer_cls: str = "TransformerEncoderBlock"
+
+
+@dataclasses.dataclass
 class MobileBertEncoderConfig(hyperparams.Config):
   """MobileBERT encoder configuration.
 
   Attributes:
     word_vocab_size: number of words in the vocabulary.
     word_embed_size: word embedding size.
     type_vocab_size: number of word types.
@@ -234,14 +263,15 @@
   attention_dropout_rate: float = 0.1
   max_position_embeddings: int = 512
   type_vocab_size: int = 2
   initializer_range: float = 0.02
   embedding_size: Optional[int] = None
   output_range: Optional[int] = None
   return_all_encoder_outputs: bool = False
+  return_attention_scores: bool = False
   # Pre/Post-LN Transformer
   norm_first: bool = False
 
 
 @dataclasses.dataclass
 class FNetEncoderConfig(hyperparams.Config):
   """FNet encoder configuration."""
@@ -254,42 +284,90 @@
   output_dropout: float = 0.1
   attention_dropout: float = 0.1
   max_sequence_length: int = 512
   type_vocab_size: int = 2
   initializer_range: float = 0.02
   embedding_width: Optional[int] = None
   output_range: Optional[int] = None
-  return_all_encoder_outputs: bool = False
-  # Pre/Post-LN Transformer
   norm_first: bool = False
   use_fft: bool = False
   attention_layers: Sequence[int] = ()
 
 
 @dataclasses.dataclass
+class SparseMixerEncoderConfig(hyperparams.Config):
+  """SparseMixer encoder configuration."""
+  vocab_size: int = 30522
+  hidden_size: int = 768
+  num_layers: int = 14
+  moe_layers: Sequence[int] = (5, 6, 7, 8)
+  attention_layers: Sequence[int] = (10, 11, 12, 13)
+  num_experts: int = 16
+  train_capacity_factor: float = 1.
+  eval_capacity_factor: float = 1.
+  examples_per_group: float = 1.
+  use_fft: bool = False
+  num_attention_heads: int = 8
+  max_sequence_length: int = 512
+  type_vocab_size: int = 2
+  inner_dim: int = 3072
+  inner_activation: str = "gelu"
+  output_dropout: float = 0.1
+  attention_dropout: float = 0.1
+  initializer_range: float = 0.02
+  output_range: Optional[int] = None
+  embedding_width: Optional[int] = None
+  norm_first: bool = False
+
+
+@dataclasses.dataclass
 class EncoderConfig(hyperparams.OneOfConfig):
   """Encoder configuration."""
   type: Optional[str] = "bert"
-  albert: AlbertEncoderConfig = AlbertEncoderConfig()
-  bert: BertEncoderConfig = BertEncoderConfig()
-  bert_v2: BertEncoderConfig = BertEncoderConfig()
-  bigbird: BigBirdEncoderConfig = BigBirdEncoderConfig()
-  kernel: KernelEncoderConfig = KernelEncoderConfig()
-  mobilebert: MobileBertEncoderConfig = MobileBertEncoderConfig()
-  reuse: ReuseEncoderConfig = ReuseEncoderConfig()
-  xlnet: XLNetEncoderConfig = XLNetEncoderConfig()
-  query_bert: QueryBertConfig = QueryBertConfig()
-  fnet: FNetEncoderConfig = FNetEncoderConfig()
+  albert: AlbertEncoderConfig = dataclasses.field(
+      default_factory=AlbertEncoderConfig
+  )
+  bert: BertEncoderConfig = dataclasses.field(default_factory=BertEncoderConfig)
+  bert_v2: BertEncoderConfig = dataclasses.field(
+      default_factory=BertEncoderConfig
+  )
+  bigbird: BigBirdEncoderConfig = dataclasses.field(
+      default_factory=BigBirdEncoderConfig
+  )
+  funnel: FunnelEncoderConfig = dataclasses.field(
+      default_factory=FunnelEncoderConfig
+  )
+  kernel: KernelEncoderConfig = dataclasses.field(
+      default_factory=KernelEncoderConfig
+  )
+  mobilebert: MobileBertEncoderConfig = dataclasses.field(
+      default_factory=MobileBertEncoderConfig
+  )
+  reuse: ReuseEncoderConfig = dataclasses.field(
+      default_factory=ReuseEncoderConfig
+  )
+  xlnet: XLNetEncoderConfig = dataclasses.field(
+      default_factory=XLNetEncoderConfig
+  )
+  query_bert: QueryBertConfig = dataclasses.field(
+      default_factory=QueryBertConfig
+  )
+  fnet: FNetEncoderConfig = dataclasses.field(default_factory=FNetEncoderConfig)
+  sparse_mixer: SparseMixerEncoderConfig = dataclasses.field(
+      default_factory=SparseMixerEncoderConfig
+  )
   # If `any` is used, the encoder building relies on any.BUILDER.
-  any: hyperparams.Config = hyperparams.Config()
+  any: hyperparams.Config = dataclasses.field(
+      default_factory=hyperparams.Config
+  )
 
 
 @gin.configurable
 def build_encoder(config: EncoderConfig,
-                  embedding_layer: Optional[tf.keras.layers.Layer] = None,
+                  embedding_layer: Optional[tf_keras.layers.Layer] = None,
                   encoder_cls=None,
                   bypass_config: bool = False):
   """Instantiate a Transformer encoder network from EncoderConfig.
 
   Args:
     config: the one-of encoder config, which provides encoder parameters of a
       chosen encoder.
@@ -308,46 +386,46 @@
   encoder_cfg = config.get()
   if encoder_cls and encoder_cls.__name__ == "EncoderScaffold":
     embedding_cfg = dict(
         vocab_size=encoder_cfg.vocab_size,
         type_vocab_size=encoder_cfg.type_vocab_size,
         hidden_size=encoder_cfg.hidden_size,
         max_seq_length=encoder_cfg.max_position_embeddings,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         dropout_rate=encoder_cfg.dropout_rate,
     )
     hidden_cfg = dict(
         num_attention_heads=encoder_cfg.num_attention_heads,
         intermediate_size=encoder_cfg.intermediate_size,
         intermediate_activation=tf_utils.get_activation(
             encoder_cfg.hidden_activation),
         dropout_rate=encoder_cfg.dropout_rate,
         attention_dropout_rate=encoder_cfg.attention_dropout_rate,
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
     )
     kwargs = dict(
         embedding_cfg=embedding_cfg,
         hidden_cfg=hidden_cfg,
         num_hidden_instances=encoder_cfg.num_layers,
         pooled_output_dim=encoder_cfg.hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         return_all_layer_outputs=encoder_cfg.return_all_encoder_outputs,
         dict_outputs=True)
     return encoder_cls(**kwargs)
 
   if encoder_type == "any":
     encoder = encoder_cfg.BUILDER(encoder_cfg)
     if not isinstance(encoder,
-                      (tf.Module, tf.keras.Model, tf.keras.layers.Layer)):
+                      (tf.Module, tf_keras.Model, tf_keras.layers.Layer)):
       raise ValueError("The BUILDER returns an unexpected instance. The "
                        "`build_encoder` should returns a tf.Module, "
-                       "tf.keras.Model or tf.keras.layers.Layer. However, "
+                       "tf_keras.Model or tf_keras.layers.Layer. However, "
                        f"we get {encoder.__class__}")
     return encoder
 
   if encoder_type == "mobilebert":
     return networks.MobileBERTEncoder(
         word_vocab_size=encoder_cfg.word_vocab_size,
         word_embed_size=encoder_cfg.word_embed_size,
@@ -378,15 +456,15 @@
         num_attention_heads=encoder_cfg.num_attention_heads,
         max_sequence_length=encoder_cfg.max_position_embeddings,
         type_vocab_size=encoder_cfg.type_vocab_size,
         intermediate_size=encoder_cfg.intermediate_size,
         activation=tf_utils.get_activation(encoder_cfg.hidden_activation),
         dropout_rate=encoder_cfg.dropout_rate,
         attention_dropout_rate=encoder_cfg.attention_dropout_rate,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         dict_outputs=True)
 
   if encoder_type == "bigbird":
     # TODO(frederickliu): Support use_gradient_checkpointing and update
     # experiments to use the EncoderScaffold only.
     if encoder_cfg.use_gradient_checkpointing:
@@ -399,76 +477,110 @@
           activation=tf_utils.get_activation(encoder_cfg.hidden_activation),
           dropout_rate=encoder_cfg.dropout_rate,
           attention_dropout_rate=encoder_cfg.attention_dropout_rate,
           num_rand_blocks=encoder_cfg.num_rand_blocks,
           block_size=encoder_cfg.block_size,
           max_position_embeddings=encoder_cfg.max_position_embeddings,
           type_vocab_size=encoder_cfg.type_vocab_size,
-          initializer=tf.keras.initializers.TruncatedNormal(
+          initializer=tf_keras.initializers.TruncatedNormal(
               stddev=encoder_cfg.initializer_range),
           embedding_width=encoder_cfg.embedding_width,
           use_gradient_checkpointing=encoder_cfg.use_gradient_checkpointing)
     embedding_cfg = dict(
         vocab_size=encoder_cfg.vocab_size,
         type_vocab_size=encoder_cfg.type_vocab_size,
         hidden_size=encoder_cfg.hidden_size,
         max_seq_length=encoder_cfg.max_position_embeddings,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         dropout_rate=encoder_cfg.dropout_rate)
     attention_cfg = dict(
         num_heads=encoder_cfg.num_attention_heads,
         key_dim=int(encoder_cfg.hidden_size // encoder_cfg.num_attention_heads),
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         max_rand_mask_length=encoder_cfg.max_position_embeddings,
         num_rand_blocks=encoder_cfg.num_rand_blocks,
         from_block_size=encoder_cfg.block_size,
         to_block_size=encoder_cfg.block_size,
         )
     hidden_cfg = dict(
         num_attention_heads=encoder_cfg.num_attention_heads,
         intermediate_size=encoder_cfg.intermediate_size,
         intermediate_activation=tf_utils.get_activation(
             encoder_cfg.hidden_activation),
         dropout_rate=encoder_cfg.dropout_rate,
         attention_dropout_rate=encoder_cfg.attention_dropout_rate,
         norm_first=encoder_cfg.norm_first,
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         attention_cls=layers.BigBirdAttention,
         attention_cfg=attention_cfg)
     kwargs = dict(
         embedding_cfg=embedding_cfg,
         hidden_cls=layers.TransformerScaffold,
         hidden_cfg=hidden_cfg,
         num_hidden_instances=encoder_cfg.num_layers,
         mask_cls=layers.BigBirdMasks,
         mask_cfg=dict(block_size=encoder_cfg.block_size),
         pooled_output_dim=encoder_cfg.hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         return_all_layer_outputs=False,
         dict_outputs=True,
         layer_idx_as_attention_seed=True)
     return networks.EncoderScaffold(**kwargs)
 
+  if encoder_type == "funnel":
+
+    if encoder_cfg.hidden_activation == "gelu":
+      activation = tf_utils.get_activation(
+          encoder_cfg.hidden_activation,
+          approximate=encoder_cfg.approx_gelu)
+    else:
+      activation = tf_utils.get_activation(encoder_cfg.hidden_activation)
+
+    return networks.FunnelTransformerEncoder(
+        vocab_size=encoder_cfg.vocab_size,
+        hidden_size=encoder_cfg.hidden_size,
+        num_layers=encoder_cfg.num_layers,
+        num_attention_heads=encoder_cfg.num_attention_heads,
+        max_sequence_length=encoder_cfg.max_position_embeddings,
+        type_vocab_size=encoder_cfg.type_vocab_size,
+        inner_dim=encoder_cfg.inner_dim,
+        inner_activation=activation,
+        output_dropout=encoder_cfg.dropout_rate,
+        attention_dropout=encoder_cfg.attention_dropout_rate,
+        pool_type=encoder_cfg.pool_type,
+        pool_stride=encoder_cfg.pool_stride,
+        unpool_length=encoder_cfg.unpool_length,
+        initializer=tf_keras.initializers.TruncatedNormal(
+            stddev=encoder_cfg.initializer_range),
+        output_range=encoder_cfg.output_range,
+        embedding_width=encoder_cfg.embedding_width,
+        embedding_layer=embedding_layer,
+        norm_first=encoder_cfg.norm_first,
+        share_rezero=encoder_cfg.share_rezero,
+        append_dense_inputs=encoder_cfg.append_dense_inputs,
+        transformer_cls=encoder_cfg.transformer_cls,
+        )
+
   if encoder_type == "kernel":
     embedding_cfg = dict(
         vocab_size=encoder_cfg.vocab_size,
         type_vocab_size=encoder_cfg.type_vocab_size,
         hidden_size=encoder_cfg.hidden_size,
         max_seq_length=encoder_cfg.max_position_embeddings,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         dropout_rate=encoder_cfg.dropout_rate)
     attention_cfg = dict(
         num_heads=encoder_cfg.num_attention_heads,
         key_dim=int(encoder_cfg.hidden_size // encoder_cfg.num_attention_heads),
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         feature_transform=encoder_cfg.feature_transform,
         num_random_features=encoder_cfg.num_random_features,
         redraw=encoder_cfg.redraw,
         is_short_seq=encoder_cfg.is_short_seq,
         begin_kernel=encoder_cfg.begin_kernel,
         scale=encoder_cfg.scale,
@@ -477,26 +589,26 @@
         num_attention_heads=encoder_cfg.num_attention_heads,
         intermediate_size=encoder_cfg.intermediate_size,
         intermediate_activation=tf_utils.get_activation(
             encoder_cfg.hidden_activation),
         dropout_rate=encoder_cfg.dropout_rate,
         attention_dropout_rate=encoder_cfg.attention_dropout_rate,
         norm_first=encoder_cfg.norm_first,
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         attention_cls=layers.KernelAttention,
         attention_cfg=attention_cfg)
     kwargs = dict(
         embedding_cfg=embedding_cfg,
         hidden_cls=layers.TransformerScaffold,
         hidden_cfg=hidden_cfg,
         num_hidden_instances=encoder_cfg.num_layers,
         mask_cls=layers.KernelMask,
         pooled_output_dim=encoder_cfg.hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         return_all_layer_outputs=False,
         dict_outputs=True,
         layer_idx_as_attention_seed=True)
     return networks.EncoderScaffold(**kwargs)
 
   if encoder_type == "xlnet":
@@ -515,78 +627,79 @@
         tie_attention_biases=encoder_cfg.tie_attention_biases,
         memory_length=encoder_cfg.memory_length,
         clamp_length=encoder_cfg.clamp_length,
         reuse_length=encoder_cfg.reuse_length,
         inner_activation=encoder_cfg.inner_activation,
         use_cls_mask=encoder_cfg.use_cls_mask,
         embedding_width=encoder_cfg.embedding_width,
-        initializer=tf.keras.initializers.RandomNormal(
+        initializer=tf_keras.initializers.RandomNormal(
             stddev=encoder_cfg.initializer_range))
 
   if encoder_type == "reuse":
     embedding_cfg = dict(
         vocab_size=encoder_cfg.vocab_size,
         type_vocab_size=encoder_cfg.type_vocab_size,
         hidden_size=encoder_cfg.hidden_size,
         max_seq_length=encoder_cfg.max_position_embeddings,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         dropout_rate=encoder_cfg.dropout_rate)
     hidden_cfg = dict(
         num_attention_heads=encoder_cfg.num_attention_heads,
         inner_dim=encoder_cfg.intermediate_size,
         inner_activation=tf_utils.get_activation(
             encoder_cfg.hidden_activation),
         output_dropout=encoder_cfg.dropout_rate,
         attention_dropout=encoder_cfg.attention_dropout_rate,
         norm_first=encoder_cfg.norm_first,
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         reuse_attention=encoder_cfg.reuse_attention,
         use_relative_pe=encoder_cfg.use_relative_pe,
         pe_max_seq_length=encoder_cfg.pe_max_seq_length,
         max_reuse_layer_idx=encoder_cfg.max_reuse_layer_idx)
     kwargs = dict(
         embedding_cfg=embedding_cfg,
         hidden_cls=layers.ReuseTransformer,
         hidden_cfg=hidden_cfg,
         num_hidden_instances=encoder_cfg.num_layers,
         pooled_output_dim=encoder_cfg.hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         return_all_layer_outputs=False,
         dict_outputs=True,
         feed_layer_idx=True,
         recursive=True)
     return networks.EncoderScaffold(**kwargs)
 
   if encoder_type == "query_bert":
     embedding_layer = layers.FactorizedEmbedding(
         vocab_size=encoder_cfg.vocab_size,
         embedding_width=encoder_cfg.embedding_size,
         output_dim=encoder_cfg.hidden_size,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         name="word_embeddings")
     return networks.BertEncoderV2(
         vocab_size=encoder_cfg.vocab_size,
         hidden_size=encoder_cfg.hidden_size,
         num_layers=encoder_cfg.num_layers,
         num_attention_heads=encoder_cfg.num_attention_heads,
         intermediate_size=encoder_cfg.intermediate_size,
         activation=tf_utils.get_activation(encoder_cfg.hidden_activation),
         dropout_rate=encoder_cfg.dropout_rate,
         attention_dropout_rate=encoder_cfg.attention_dropout_rate,
         max_sequence_length=encoder_cfg.max_position_embeddings,
         type_vocab_size=encoder_cfg.type_vocab_size,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         output_range=encoder_cfg.output_range,
         embedding_layer=embedding_layer,
         return_all_encoder_outputs=encoder_cfg.return_all_encoder_outputs,
+        return_attention_scores=encoder_cfg.return_attention_scores,
         dict_outputs=True,
         norm_first=encoder_cfg.norm_first)
 
   if encoder_type == "fnet":
     return networks.FNet(
         vocab_size=encoder_cfg.vocab_size,
         hidden_size=encoder_cfg.hidden_size,
@@ -594,23 +707,49 @@
         num_attention_heads=encoder_cfg.num_attention_heads,
         inner_dim=encoder_cfg.inner_dim,
         inner_activation=tf_utils.get_activation(encoder_cfg.inner_activation),
         output_dropout=encoder_cfg.output_dropout,
         attention_dropout=encoder_cfg.attention_dropout,
         max_sequence_length=encoder_cfg.max_sequence_length,
         type_vocab_size=encoder_cfg.type_vocab_size,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range),
         output_range=encoder_cfg.output_range,
         embedding_width=encoder_cfg.embedding_width,
         embedding_layer=embedding_layer,
         norm_first=encoder_cfg.norm_first,
         use_fft=encoder_cfg.use_fft,
         attention_layers=encoder_cfg.attention_layers)
 
+  if encoder_type == "sparse_mixer":
+    return networks.SparseMixer(
+        vocab_size=encoder_cfg.vocab_size,
+        hidden_size=encoder_cfg.hidden_size,
+        num_layers=encoder_cfg.num_layers,
+        moe_layers=encoder_cfg.moe_layers,
+        attention_layers=encoder_cfg.attention_layers,
+        num_experts=encoder_cfg.num_experts,
+        train_capacity_factor=encoder_cfg.train_capacity_factor,
+        eval_capacity_factor=encoder_cfg.eval_capacity_factor,
+        examples_per_group=encoder_cfg.examples_per_group,
+        use_fft=encoder_cfg.use_fft,
+        num_attention_heads=encoder_cfg.num_attention_heads,
+        max_sequence_length=encoder_cfg.max_sequence_length,
+        type_vocab_size=encoder_cfg.type_vocab_size,
+        inner_dim=encoder_cfg.inner_dim,
+        inner_activation=tf_utils.get_activation(encoder_cfg.inner_activation),
+        output_dropout=encoder_cfg.output_dropout,
+        attention_dropout=encoder_cfg.attention_dropout,
+        initializer=tf_keras.initializers.TruncatedNormal(
+            stddev=encoder_cfg.initializer_range),
+        output_range=encoder_cfg.output_range,
+        embedding_width=encoder_cfg.embedding_width,
+        norm_first=encoder_cfg.norm_first,
+        embedding_layer=embedding_layer)
+
   bert_encoder_cls = networks.BertEncoder
   if encoder_type == "bert_v2":
     bert_encoder_cls = networks.BertEncoderV2
 
   # Uses the default BERTEncoder configuration schema to create the encoder.
   # If it does not match, please add a switch branch by the encoder type.
   return bert_encoder_cls(
@@ -620,15 +759,17 @@
       num_attention_heads=encoder_cfg.num_attention_heads,
       intermediate_size=encoder_cfg.intermediate_size,
       activation=tf_utils.get_activation(encoder_cfg.hidden_activation),
       dropout_rate=encoder_cfg.dropout_rate,
       attention_dropout_rate=encoder_cfg.attention_dropout_rate,
       max_sequence_length=encoder_cfg.max_position_embeddings,
       type_vocab_size=encoder_cfg.type_vocab_size,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=encoder_cfg.initializer_range),
       output_range=encoder_cfg.output_range,
       embedding_width=encoder_cfg.embedding_size,
       embedding_layer=embedding_layer,
       return_all_encoder_outputs=encoder_cfg.return_all_encoder_outputs,
+      return_attention_scores=encoder_cfg.return_attention_scores,
+      return_word_embeddings=encoder_cfg.return_word_embeddings,
       dict_outputs=True,
       norm_first=encoder_cfg.norm_first)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/configs/encoders_test.py` & `tf-models-no-deps-2.16.0/official/nlp/configs/encoders_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.configs.encoders."""
 import os
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.nlp.configs import encoders
 from official.nlp.modeling import networks
 from official.projects.teams import teams
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/configs/experiment_configs.py` & `tf-models-no-deps-2.16.0/official/nlp/configs/experiment_configs.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/configs/finetuning_experiments.py` & `tf-models-no-deps-2.16.0/official/nlp/configs/finetuning_experiments.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/configs/wmt_transformer_experiments.py` & `tf-models-no-deps-2.16.0/official/nlp/configs/wmt_transformer_experiments.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/continuous_finetune_lib.py` & `tf-models-no-deps-2.16.0/official/nlp/continuous_finetune_lib.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """TFM continuous finetuning+eval training driver library."""
 import gc
 import os
 import time
 from typing import Any, Mapping, Optional
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import distribute_utils
 from official.core import config_definitions
 from official.core import task_factory
 from official.core import train_lib
 from official.core import train_utils
 from official.modeling import performance
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/continuous_finetune_lib_test.py` & `tf-models-no-deps-2.16.0/official/nlp/continuous_finetune_lib_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 import os
 
 from absl import flags
 from absl.testing import flagsaver
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # pylint: disable=unused-import
 from official.common import registry_imports
 # pylint: enable=unused-import
 from official.common import flags as tfm_flags
 from official.core import task_factory
 from official.core import train_lib
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/data/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/classifier_data_lib.py` & `tf-models-no-deps-2.16.0/official/nlp/data/classifier_data_lib.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import collections
 import csv
 import importlib
 import json
 import os
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 from official.nlp.tools import tokenization
 
 
 class InputExample(object):
   """A single training/test example for simple seq regression/classification."""
@@ -664,15 +664,15 @@
         self.dataset_name, data_dir=self.data_dir, with_info=True)
     if self.is_regression:
       self._labels = None
     else:
       self._labels = list(range(info.features[self.label_key].num_classes))
 
   def _process_tfds_params_str(self, params_str):
-    """Extracts TFDS parameters from a comma-separated assignements string."""
+    """Extracts TFDS parameters from a comma-separated assignments string."""
     dtype_map = {"int": int, "float": float}
     cast_str_to_bool = lambda s: s.lower() not in ["false", "0"]
 
     tuples = [x.split("=") for x in params_str.split(",")]
     d = {k.strip(): v.strip() for k, v in tuples}
     self.dataset_name = d["dataset"]  # Required.
     self.data_dir = d.get("data_dir", None)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/classifier_data_lib_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/classifier_data_lib_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for third_party.tensorflow_models.official.nlp.data.classifier_data_lib."""
 
 import os
 import tempfile
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 from official.nlp.data import classifier_data_lib
 from official.nlp.tools import tokenization
 
 
 def decode_record(record, name_to_features):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/create_finetuning_data.py` & `tf-models-no-deps-2.16.0/official/nlp/data/create_finetuning_data.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import functools
 import json
 import os
 
 # Import libraries
 from absl import app
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.nlp.data import classifier_data_lib
 from official.nlp.data import sentence_retrieval_lib
 # word-piece tokenizer based squad_lib
 from official.nlp.data import squad_lib as squad_lib_wp
 # sentence-piece tokenizer based squad_lib
 from official.nlp.data import squad_lib_sp
 from official.nlp.data import tagging_data_lib
@@ -161,15 +161,15 @@
 flags.DEFINE_enum(
     "tokenization", "WordPiece", ["WordPiece", "SentencePiece"],
     "Specifies the tokenizer implementation, i.e., whether to use WordPiece "
     "or SentencePiece tokenizer. Canonical BERT uses WordPiece tokenizer, "
     "while ALBERT uses SentencePiece tokenizer.")
 
 flags.DEFINE_string(
-    "tfds_params", "", "Comma-separated list of TFDS parameter assigments for "
+    "tfds_params", "", "Comma-separated list of TFDS parameter assignments for "
     "generic classfication data import (for more details "
     "see the TfdsProcessor class documentation).")
 
 
 def generate_classifier_dataset():
   """Generates classifier dataset and returns input meta data."""
   if FLAGS.classification_task_name in [
@@ -266,15 +266,15 @@
         "boolq":
             classifier_data_lib.BoolQProcessor,
         "wic":
             classifier_data_lib.WnliProcessor,
     }
     task_name = FLAGS.classification_task_name.lower()
     if task_name not in processors:
-      raise ValueError("Task not found: %s" % (task_name))
+      raise ValueError("Task not found: %s" % (task_name,))
 
     processor = processors[task_name](process_text_fn=processor_text_fn)
     return classifier_data_lib.generate_tf_record_from_data_file(
         processor,
         FLAGS.input_data_dir,
         tokenizer,
         train_data_output_path=FLAGS.train_data_output_path,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/create_pretraining_data.py` & `tf-models-no-deps-2.16.0/official/nlp/data/create_pretraining_data.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,41 +15,62 @@
 """Create masked LM/next sentence masked_lm TF examples for BERT."""
 
 import collections
 import itertools
 import random
 
 # Import libraries
+
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.tools import tokenization
 
 FLAGS = flags.FLAGS
 
 flags.DEFINE_string("input_file", None,
                     "Input raw text file (or comma-separated list of files).")
 
 flags.DEFINE_string(
     "output_file", None,
     "Output TF example file (or comma-separated list of files).")
 
-flags.DEFINE_string("vocab_file", None,
-                    "The vocabulary file that the BERT model was trained on.")
+flags.DEFINE_enum(
+    "tokenization",
+    "WordPiece",
+    ["WordPiece", "SentencePiece"],
+    "Specifies the tokenizer implementation, i.e., whether to use WordPiece "
+    "or SentencePiece tokenizer. Canonical BERT uses WordPiece tokenizer, "
+    "while ALBERT uses SentencePiece tokenizer.",
+)
+
+flags.DEFINE_string(
+    "vocab_file",
+    None,
+    "For WordPiece tokenization, the vocabulary file of the tokenizer.",
+)
+
+flags.DEFINE_string(
+    "sp_model_file",
+    "",
+    "For SentencePiece tokenization, the path to the model of the tokenizer.",
+)
 
 flags.DEFINE_bool(
     "do_lower_case", True,
     "Whether to lower case the input text. Should be True for uncased "
     "models and False for cased models.")
 
 flags.DEFINE_bool(
-    "do_whole_word_mask", False,
-    "Whether to use whole word masking rather than per-WordPiece masking.")
+    "do_whole_word_mask",
+    False,
+    "Whether to use whole word masking rather than per-token masking.",
+)
 
 flags.DEFINE_integer(
     "max_ngram_size", None,
     "Mask contiguous whole words (n-grams) of up to `max_ngram_size` using a "
     "weighting scheme to favor shorter n-grams. "
     "Note: `--do_whole_word_mask=True` must also be set when n-gram masking.")
 
@@ -194,40 +215,40 @@
 
 
 def create_float_feature(values):
   feature = tf.train.Feature(float_list=tf.train.FloatList(value=list(values)))
   return feature
 
 
-def create_training_instances(input_files,
-                              tokenizer,
-                              max_seq_length,
-                              dupe_factor,
-                              short_seq_prob,
-                              masked_lm_prob,
-                              max_predictions_per_seq,
-                              rng,
-                              do_whole_word_mask=False,
-                              max_ngram_size=None):
+def create_training_instances(
+    input_files,
+    tokenizer,
+    processor_text_fn,
+    max_seq_length,
+    dupe_factor,
+    short_seq_prob,
+    masked_lm_prob,
+    max_predictions_per_seq,
+    rng,
+    do_whole_word_mask=False,
+    max_ngram_size=None,
+):
   """Create `TrainingInstance`s from raw text."""
   all_documents = [[]]
 
   # Input file format:
   # (1) One sentence per line. These should ideally be actual sentences, not
   # entire paragraphs or arbitrary spans of text. (Because we use the
   # sentence boundaries for the "next sentence prediction" task).
   # (2) Blank lines between documents. Document boundaries are needed so
   # that the "next sentence prediction" task doesn't span between documents.
   for input_file in input_files:
     with tf.io.gfile.GFile(input_file, "rb") as reader:
-      while True:
-        line = tokenization.convert_to_unicode(reader.readline())
-        if not line:
-          break
-        line = line.strip()
+      for line in reader:
+        line = processor_text_fn(line)
 
         # Empty lines are used as document delimiters
         if not line:
           all_documents.append([])
         tokens = tokenizer.tokenize(line)
         if tokens:
           all_documents[-1].append(tokens)
@@ -428,15 +449,15 @@
       return False
   return True
 
 
 def _masking_ngrams(grams, max_ngram_size, max_masked_tokens, rng):
   """Create a list of masking {1, ..., n}-grams from a list of one-grams.
 
-  This is an extention of 'whole word masking' to mask multiple, contiguous
+  This is an extension of 'whole word masking' to mask multiple, contiguous
   words such as (e.g., "the red boat").
 
   Each input gram represents the token indices of a single word,
      words:  ["the", "red", "boat"]
      tokens: ["the", "red", "boa", "##t"]
      grams:  [(0,1), (1,2), (2,4)]
 
@@ -484,25 +505,25 @@
         ngrams[gram_size].append(_Gram(g[0].begin, g[-1].end))
 
   # Shuffle each list of n-grams.
   for v in ngrams.values():
     rng.shuffle(v)
 
   # Create the weighting for n-gram length selection.
-  # Stored cummulatively for `random.choices` below.
+  # Stored cumulatively for `random.choices` below.
   cummulative_weights = list(
       itertools.accumulate([1./n for n in range(1, max_ngram_size+1)]))
 
   output_ngrams = []
   # Keep a bitmask of which tokens have been masked.
   masked_tokens = [False] * num_tokens
   # Loop until we have enough masked tokens or there are no more candidate
   # n-grams of any length.
   # Each code path should ensure one or more elements from `ngrams` are removed
-  # to guarentee this loop terminates.
+  # to guarantee this loop terminates.
   while (sum(masked_tokens) < max_masked_tokens and
          sum(len(s) for s in ngrams.values())):
     # Pick an n-gram size based on our weights.
     sz = random.choices(range(1, max_ngram_size+1),
                         cum_weights=cummulative_weights)[0]
 
     # Ensure this size doesn't result in too many masked tokens.
@@ -531,23 +552,24 @@
 
     # Found a usable n-gram!  Mark its tokens as masked and add it to return.
     masked_tokens[gram.begin:gram.end] = [True] * (gram.end-gram.begin)
     output_ngrams.append(gram)
   return output_ngrams
 
 
-def _wordpieces_to_grams(tokens):
+def _tokens_to_grams(tokens):
   """Reconstitue grams (words) from `tokens`.
 
   E.g.,
      tokens: ['[CLS]', 'That', 'lit', '##tle', 'blue', 'tru', '##ck', '[SEP]']
       grams: [          [1,2), [2,         4),  [4,5) , [5,       6)]
 
   Args:
-    tokens: list of wordpieces
+    tokens: list of tokens (word pieces or sentence pieces).
+
   Returns:
     List of _Grams representing spans of whole words
     (without "[CLS]" and "[SEP]").
   """
   grams = []
   gram_start_pos = None
   for i, token in enumerate(tokens):
@@ -566,15 +588,15 @@
 
 def create_masked_lm_predictions(tokens, masked_lm_prob,
                                  max_predictions_per_seq, vocab_words, rng,
                                  do_whole_word_mask,
                                  max_ngram_size=None):
   """Creates the predictions for the masked LM objective."""
   if do_whole_word_mask:
-    grams = _wordpieces_to_grams(tokens)
+    grams = _tokens_to_grams(tokens)
   else:
     # Here we consider each token to be a word to allow for sub-word masking.
     if max_ngram_size:
       raise ValueError("cannot use ngram masking without whole word masking")
     grams = [_Gram(i, i+1) for i in range(0, len(tokens))
              if tokens[i] not in ["[CLS]", "[SEP]"]]
 
@@ -629,31 +651,59 @@
     # back to add more randomness and avoid biases.
     if rng.random() < 0.5:
       del trunc_tokens[0]
     else:
       trunc_tokens.pop()
 
 
+def get_processor_text_fn(is_sentence_piece, do_lower_case):
+  def processor_text_fn(text):
+    text = tokenization.convert_to_unicode(text)
+    if is_sentence_piece:
+      # Additional preprocessing specific to the SentencePiece tokenizer.
+      text = tokenization.preprocess_text(text, lower=do_lower_case)
+
+    return text.strip()
+
+  return processor_text_fn
+
+
 def main(_):
-  tokenizer = tokenization.FullTokenizer(
-      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)
+  if FLAGS.tokenization == "WordPiece":
+    tokenizer = tokenization.FullTokenizer(
+        vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case
+    )
+    processor_text_fn = get_processor_text_fn(False, FLAGS.do_lower_case)
+  else:
+    assert FLAGS.tokenization == "SentencePiece"
+    tokenizer = tokenization.FullSentencePieceTokenizer(FLAGS.sp_model_file)
+    processor_text_fn = get_processor_text_fn(True, FLAGS.do_lower_case)
 
   input_files = []
   for input_pattern in FLAGS.input_file.split(","):
     input_files.extend(tf.io.gfile.glob(input_pattern))
 
   logging.info("*** Reading from input files ***")
   for input_file in input_files:
     logging.info("  %s", input_file)
 
   rng = random.Random(FLAGS.random_seed)
   instances = create_training_instances(
-      input_files, tokenizer, FLAGS.max_seq_length, FLAGS.dupe_factor,
-      FLAGS.short_seq_prob, FLAGS.masked_lm_prob, FLAGS.max_predictions_per_seq,
-      rng, FLAGS.do_whole_word_mask, FLAGS.max_ngram_size)
+      input_files,
+      tokenizer,
+      processor_text_fn,
+      FLAGS.max_seq_length,
+      FLAGS.dupe_factor,
+      FLAGS.short_seq_prob,
+      FLAGS.masked_lm_prob,
+      FLAGS.max_predictions_per_seq,
+      rng,
+      FLAGS.do_whole_word_mask,
+      FLAGS.max_ngram_size,
+  )
 
   output_files = FLAGS.output_file.split(",")
   logging.info("*** Writing to output files ***")
   for output_file in output_files:
     logging.info("  %s", output_file)
 
   write_instance_to_example_files(instances, tokenizer, FLAGS.max_seq_length,
@@ -661,9 +711,8 @@
                                   FLAGS.gzip_compress,
                                   FLAGS.use_v2_feature_names)
 
 
 if __name__ == "__main__":
   flags.mark_flag_as_required("input_file")
   flags.mark_flag_as_required("output_file")
-  flags.mark_flag_as_required("vocab_file")
   app.run(main)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/create_pretraining_data_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/create_pretraining_data_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.data.create_pretraining_data."""
 import random
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import create_pretraining_data as cpd
 
 _VOCAB_WORDS = ["vocab_1", "vocab_2"]
 
 
 class CreatePretrainingDataTest(tf.test.TestCase):
@@ -39,24 +39,24 @@
     for pos, label in zip(masked_positions, masked_labels):
       output_token = output_tokens[pos]
       if (output_token == "[MASK]" or output_token in _VOCAB_WORDS or
           output_token == input_tokens[pos]):
         continue
       self.fail("invalid mask value: {}".format(output_token))
 
-  def test_wordpieces_to_grams(self):
+  def test_tokens_to_grams(self):
     tests = [
         (["That", "cone"], [(0, 1), (1, 2)]),
         (["That", "cone", "##s"], [(0, 1), (1, 3)]),
         (["Swit", "##zer", "##land"], [(0, 3)]),
         (["[CLS]", "Up", "##dog"], [(1, 3)]),
         (["[CLS]", "Up", "##dog", "[SEP]", "Down"], [(1, 3), (4, 5)]),
     ]
     for inp, expected in tests:
-      output = cpd._wordpieces_to_grams(inp)
+      output = cpd._tokens_to_grams(inp)
       self.assertEqual(expected, output)
 
   def test_window(self):
     input_list = [1, 2, 3, 4]
     window_outputs = [
         (1, [[1], [2], [3], [4]]),
         (2, [[1, 2], [2, 3], [3, 4]]),
@@ -77,16 +77,16 @@
               tokens=tokens,
               masked_lm_prob=1.0,
               max_predictions_per_seq=3,
               vocab_words=_VOCAB_WORDS,
               rng=rng,
               do_whole_word_mask=False,
               max_ngram_size=None))
-      self.assertEqual(len(masked_positions), 3)
-      self.assertEqual(len(masked_labels), 3)
+      self.assertLen(masked_positions, 3)
+      self.assertLen(masked_labels, 3)
       self.assertTokens(tokens, output_tokens, masked_positions, masked_labels)
 
   def test_create_masked_lm_predictions_whole_word(self):
     tokens = ["[CLS]", "a", "##a", "b", "##b", "c", "##c", "[SEP]"]
     rng = random.Random(345)
     for _ in range(0, 5):
       output_tokens, masked_positions, masked_labels = (
@@ -96,16 +96,16 @@
               max_predictions_per_seq=3,
               vocab_words=_VOCAB_WORDS,
               rng=rng,
               do_whole_word_mask=True,
               max_ngram_size=None))
       # since we can't get exactly three tokens without breaking a word we
       # only take two.
-      self.assertEqual(len(masked_positions), 2)
-      self.assertEqual(len(masked_labels), 2)
+      self.assertLen(masked_positions, 2)
+      self.assertLen(masked_labels, 2)
       self.assertTokens(tokens, output_tokens, masked_positions, masked_labels)
       # ensure that we took an entire word.
       self.assertIn(masked_labels, [["a", "##a"], ["b", "##b"], ["c", "##c"]])
 
   def test_create_masked_lm_predictions_ngram(self):
     tokens = ["[CLS]"] + ["tok{}".format(i) for i in range(0, 512)] + ["[SEP]"]
     rng = random.Random(345)
@@ -115,14 +115,14 @@
               tokens=tokens,
               masked_lm_prob=1.0,
               max_predictions_per_seq=76,
               vocab_words=_VOCAB_WORDS,
               rng=rng,
               do_whole_word_mask=True,
               max_ngram_size=3))
-      self.assertEqual(len(masked_positions), 76)
-      self.assertEqual(len(masked_labels), 76)
+      self.assertLen(masked_positions, 76)
+      self.assertLen(masked_labels, 76)
       self.assertTokens(tokens, output_tokens, masked_positions, masked_labels)
 
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/create_xlnet_pretraining_data.py` & `tf-models-no-deps-2.16.0/official/nlp/data/create_xlnet_pretraining_data.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -26,15 +26,15 @@
 # Import libraries
 
 from absl import app
 from absl import flags
 from absl import logging
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.tools import tokenization
 
 special_symbols = {
     "<unk>": 0,
     "<s>": 1,
     "</s>": 2,
@@ -221,15 +221,15 @@
         sentence_id = not sentence_id
       logging.info("Finished processing %s. Number of lines: %d",
                    input_file, line_count)
       if line_count == 0:
         continue
       total_number_of_lines += line_count
       all_tokens = np.array(all_tokens, dtype=np.int64)
-      all_sentence_ids = np.array(all_sentence_ids, dtype=np.bool)
+      all_sentence_ids = np.array(all_sentence_ids, dtype=bool)
       all_data.append((all_tokens, all_sentence_ids))
 
   logging.info("Completed text preprocessing. Total number of lines: %d",
                total_number_of_lines)
   return all_data
 
 
@@ -267,15 +267,15 @@
     total_length: int,
     no_cut_probability: float = 0.5):
   """Splits segments A and B from a single instance of tokens and sentence ids.
 
   Args:
     tokens: The 1D input token ids. This represents an individual entry within a
       batch.
-    sentence_ids: The 1D input sentence ids. This represents an indivdual entry
+    sentence_ids: The 1D input sentence ids. This represents an individual entry
       within a batch. This should be the same length as `tokens`.
     begin_index: The reference beginning index to split data.
     total_length: The target combined length of segments A and B.
     no_cut_probability: The probability of not cutting a segment despite
       a cut possibly existing.
 
   Returns:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/create_xlnet_pretraining_data_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/create_xlnet_pretraining_data_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import tempfile
 from typing import List
 
 from absl import logging
 from absl.testing import parameterized
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import create_xlnet_pretraining_data as cpd
 
 _VOCAB_WORDS = ["vocab_1", "vocab_2"]
 
 
 # pylint: disable=invalid-name
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/data_loader.py` & `tf-models-no-deps-2.16.0/official/nlp/data/data_loader.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """An abstraction that NLP models define input pipelines."""
 
 import abc
 from typing import Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class DataLoader(metaclass=abc.ABCMeta):
   """An abstract class defining the APIs for tf.data input pipeline."""
 
   @abc.abstractmethod
   def load(
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/data_loader_factory.py` & `tf-models-no-deps-2.16.0/official/nlp/data/data_loader_factory.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/data_loader_factory_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/data_loader_factory_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.data.data_loader_factory."""
 
 import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.nlp.data import data_loader_factory
 
 
 @dataclasses.dataclass
 class MyDataConfig(cfg.DataConfig):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/dual_encoder_dataloader.py` & `tf-models-no-deps-2.16.0/official/nlp/data/dual_encoder_dataloader.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,30 +1,31 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Loads dataset for the dual encoder (retrieval) task."""
+import dataclasses
 import functools
 import itertools
 from typing import Iterable, Mapping, Optional, Tuple
 
-import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_hub as hub
 
+from official.common import dataset_fn
 from official.core import config_definitions as cfg
 from official.core import input_reader
 from official.nlp.data import data_loader
 from official.nlp.data import data_loader_factory
 from official.nlp.modeling import layers
 
 
@@ -43,14 +44,15 @@
   # ...or load preprocessing from a SavedModel at this location.
   preprocessing_hub_module_url: str = ''
 
   left_text_fields: Tuple[str] = ('left_input',)
   right_text_fields: Tuple[str] = ('right_input',)
   is_training: bool = True
   seq_length: int = 128
+  file_type: str = 'tfrecord'
 
 
 @data_loader_factory.register_data_loader_cls(DualEncoderDataConfig)
 class DualEncoderDataLoader(data_loader.DataLoader):
   """A class to load dataset for dual encoder task (tasks/dual_encoder)."""
 
   def __init__(self, params):
@@ -136,10 +138,10 @@
 
   def load(self, input_context: Optional[tf.distribute.InputContext] = None):
     """Returns a tf.dataset.Dataset."""
     reader = input_reader.InputReader(
         params=self._params,
         # Skip `decoder_fn` for tfds input.
         decoder_fn=self._decode if self._params.input_path else None,
-        dataset_fn=tf.data.TFRecordDataset,
+        dataset_fn=dataset_fn.pick_dataset_fn(self._params.file_type),
         postprocess_fn=self._bert_preprocess)
     return reader.read(input_context)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/dual_encoder_dataloader_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/dual_encoder_dataloader_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.data.dual_encoder_dataloader."""
 import os
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import dual_encoder_dataloader
 
 
 _LEFT_FEATURE_NAME = 'left_input'
 _RIGHT_FEATURE_NAME = 'right_input'
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/pretrain_dataloader.py` & `tf-models-no-deps-2.16.0/official/nlp/data/pretrain_dataloader.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,29 +1,30 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Loads dataset for the BERT pretraining task."""
+import dataclasses
 from typing import Mapping, Optional
 
 from absl import logging
 
-import dataclasses
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
+from official.common import dataset_fn
 from official.core import config_definitions as cfg
 from official.core import input_reader
 from official.nlp.data import data_loader
 from official.nlp.data import data_loader_factory
 
 
 @dataclasses.dataclass
@@ -38,14 +39,15 @@
   use_position_id: bool = False
   # Historically, BERT implementations take `input_ids` and `segment_ids` as
   # feature names. Inside the TF Model Garden implementation, the Keras model
   # inputs are set as `input_word_ids` and `input_type_ids`. When
   # v2_feature_names is True, the data loader assumes the tf.Examples use
   # `input_word_ids` and `input_type_ids` as keys.
   use_v2_feature_names: bool = False
+  file_type: str = 'tfrecord'
 
 
 @data_loader_factory.register_data_loader_cls(BertPretrainDataConfig)
 class BertPretrainDataLoader(data_loader.DataLoader):
   """A class to load dataset for bert pretraining task."""
 
   def __init__(self, params):
@@ -124,49 +126,49 @@
       x['position_ids'] = record['position_ids']
 
     return x
 
   def load(self, input_context: Optional[tf.distribute.InputContext] = None):
     """Returns a tf.dataset.Dataset."""
     reader = input_reader.InputReader(
-        params=self._params, decoder_fn=self._decode, parser_fn=self._parse)
+        params=self._params,
+        dataset_fn=dataset_fn.pick_dataset_fn(self._params.file_type),
+        decoder_fn=self._decode,
+        parser_fn=self._parse)
     return reader.read(input_context)
 
 
 @dataclasses.dataclass
 class XLNetPretrainDataConfig(cfg.DataConfig):
   """Data config for XLNet pretraining task.
 
   Attributes:
     input_path: See base class.
-    global_batch_size: See base calss.
+    global_batch_size: See base class.
     is_training: See base class.
     seq_length: The length of each sequence.
     max_predictions_per_seq: The number of predictions per sequence.
     reuse_length: The number of tokens in a previous segment to reuse. This
       should be the same value used during pretrain data creation.
     sample_strategy: The strategy used to sample factorization permutations.
       Possible values: 'single_token', 'whole_word', 'token_span', 'word_span'.
-    min_num_tokens: The minimum number of tokens to sample in a span.
-      This is used when `sample_strategy` is 'token_span'.
-    max_num_tokens: The maximum number of tokens to sample in a span.
-      This is used when `sample_strategy` is 'token_span'.
-    min_num_words: The minimum number of words to sample in a span.
-      This is used when `sample_strategy` is 'word_span'.
-    max_num_words: The maximum number of words to sample in a span.
-      This is used when `sample_strategy` is 'word_span'.
-    permutation_size: The length of the longest permutation. This can be set
-      to `reuse_length`. This should NOT be greater than `reuse_length`,
-      otherwise this may introduce data leaks.
+    min_num_tokens: The minimum number of tokens to sample in a span. This is
+      used when `sample_strategy` is 'token_span'.
+    max_num_tokens: The maximum number of tokens to sample in a span. This is
+      used when `sample_strategy` is 'token_span'.
+    min_num_words: The minimum number of words to sample in a span. This is used
+      when `sample_strategy` is 'word_span'.
+    max_num_words: The maximum number of words to sample in a span. This is used
+      when `sample_strategy` is 'word_span'.
+    permutation_size: The length of the longest permutation. This can be set to
+      `reuse_length`. This should NOT be greater than `reuse_length`, otherwise
+      this may introduce data leaks.
     leak_ratio: The percentage of masked tokens that are leaked.
-    segment_sep_id: The ID of the SEP token used when preprocessing
-      the dataset.
-    segment_cls_id: The ID of the CLS token used when preprocessing
-      the dataset.
-
+    segment_sep_id: The ID of the SEP token used when preprocessing the dataset.
+    segment_cls_id: The ID of the CLS token used when preprocessing the dataset.
   """
   input_path: str = ''
   global_batch_size: int = 512
   is_training: bool = True
   seq_length: int = 512
   max_predictions_per_seq: int = 76
   reuse_length: int = 256
@@ -201,20 +203,17 @@
     self._cls_id = params.segment_cls_id
     self._sample_strategy = params.sample_strategy
     self._leak_ratio = params.leak_ratio
 
   def _decode(self, record: tf.Tensor):
     """Decodes a serialized tf.Example."""
     name_to_features = {
-        'input_word_ids':
-            tf.io.FixedLenFeature([self._seq_length], tf.int64),
-        'input_type_ids':
-            tf.io.FixedLenFeature([self._seq_length], tf.int64),
-        'boundary_indices':
-            tf.io.VarLenFeature(tf.int64),
+        'input_word_ids': tf.io.FixedLenFeature([self._seq_length], tf.int64),
+        'input_type_ids': tf.io.FixedLenFeature([self._seq_length], tf.int64),
+        'boundary_indices': tf.io.VarLenFeature(tf.int64),
     }
     example = tf.io.parse_single_example(record, name_to_features)
 
     # tf.Example only supports tf.int64, but the TPU only supports tf.int32.
     # So cast all int64 to int32.
     for name in list(example.keys()):
       t = example[name]
@@ -238,57 +237,60 @@
 
     input_mask = self._online_sample_mask(inputs=inputs, boundary=boundary)
 
     if self._reuse_length > 0:
       if self._permutation_size > self._reuse_length:
         logging.warning(
             '`permutation_size` is greater than `reuse_length` (%d > %d).'
-            'This may introduce data leakage.',
-            self._permutation_size, self._reuse_length)
+            'This may introduce data leakage.', self._permutation_size,
+            self._reuse_length)
 
       # Enable the memory mechanism.
       # Permute the reuse and non-reuse segments separately.
       non_reuse_len = self._seq_length - self._reuse_length
-      if not (self._reuse_length % self._permutation_size == 0
-              and non_reuse_len % self._permutation_size == 0):
+      if not (self._reuse_length % self._permutation_size == 0 and
+              non_reuse_len % self._permutation_size == 0):
         raise ValueError('`reuse_length` and `seq_length` should both be '
                          'a multiple of `permutation_size`.')
 
       # Creates permutation mask and target mask for the first reuse_len tokens.
       # The tokens in this part are reused from the last sequence.
       perm_mask_0, target_mask_0, tokens_0, masked_0 = self._get_factorization(
           inputs=inputs[:self._reuse_length],
           input_mask=input_mask[:self._reuse_length])
 
       # Creates permutation mask and target mask for the rest of tokens in
-      # current example, which are concatentation of two new segments.
+      # current example, which are concatenation of two new segments.
       perm_mask_1, target_mask_1, tokens_1, masked_1 = self._get_factorization(
           inputs[self._reuse_length:], input_mask[self._reuse_length:])
 
-      perm_mask_0 = tf.concat(
-          [perm_mask_0,
-           tf.zeros([self._reuse_length, non_reuse_len], dtype=tf.int32)],
-          axis=1)
-      perm_mask_1 = tf.concat(
-          [tf.ones([non_reuse_len, self._reuse_length], dtype=tf.int32),
-           perm_mask_1], axis=1)
+      perm_mask_0 = tf.concat([
+          perm_mask_0,
+          tf.zeros([self._reuse_length, non_reuse_len], dtype=tf.int32)
+      ],
+                              axis=1)
+      perm_mask_1 = tf.concat([
+          tf.ones([non_reuse_len, self._reuse_length], dtype=tf.int32),
+          perm_mask_1
+      ],
+                              axis=1)
       perm_mask = tf.concat([perm_mask_0, perm_mask_1], axis=0)
       target_mask = tf.concat([target_mask_0, target_mask_1], axis=0)
       tokens = tf.concat([tokens_0, tokens_1], axis=0)
       masked_tokens = tf.concat([masked_0, masked_1], axis=0)
     else:
       # Disable the memory mechanism.
       if self._seq_length % self._permutation_size != 0:
         raise ValueError('`seq_length` should be a multiple of '
                          '`permutation_size`.')
       # Permute the entire sequence together
       perm_mask, target_mask, tokens, masked_tokens = self._get_factorization(
           inputs=inputs, input_mask=input_mask)
-    x['permutation_mask'] = tf.reshape(
-        perm_mask, [self._seq_length, self._seq_length])
+    x['permutation_mask'] = tf.reshape(perm_mask,
+                                       [self._seq_length, self._seq_length])
     x['input_word_ids'] = tokens
     x['masked_tokens'] = masked_tokens
 
     target = tokens
     if self._max_predictions_per_seq is not None:
       indices = tf.range(self._seq_length, dtype=tf.int32)
       bool_target_mask = tf.cast(target_mask, tf.bool)
@@ -309,32 +311,31 @@
       paddings = tf.zeros([pad_len], dtype=target.dtype)
       target = tf.concat([target, paddings], axis=0)
       x['target'] = tf.reshape(target, [self._max_predictions_per_seq])
 
       target_mask = tf.concat([
           tf.ones([actual_num_predict], dtype=tf.int32),
           tf.zeros([pad_len], dtype=tf.int32)
-      ], axis=0)
+      ],
+                              axis=0)
       x['target_mask'] = tf.reshape(target_mask,
                                     [self._max_predictions_per_seq])
     else:
       x['target'] = tf.reshape(target, [self._seq_length])
       x['target_mask'] = tf.reshape(target_mask, [self._seq_length])
     return x
 
-  def _index_pair_to_mask(self,
-                          begin_indices: tf.Tensor,
+  def _index_pair_to_mask(self, begin_indices: tf.Tensor,
                           end_indices: tf.Tensor,
                           inputs: tf.Tensor) -> tf.Tensor:
     """Converts beginning and end indices into an actual mask."""
     non_func_mask = tf.logical_and(
         tf.not_equal(inputs, self._sep_id), tf.not_equal(inputs, self._cls_id))
     all_indices = tf.where(
-        non_func_mask,
-        tf.range(self._seq_length, dtype=tf.int32),
+        non_func_mask, tf.range(self._seq_length, dtype=tf.int32),
         tf.constant(-1, shape=[self._seq_length], dtype=tf.int32))
     candidate_matrix = tf.cast(
         tf.logical_and(all_indices[None, :] >= begin_indices[:, None],
                        all_indices[None, :] < end_indices[:, None]), tf.float32)
     cumsum_matrix = tf.reshape(
         tf.cumsum(tf.reshape(candidate_matrix, [-1])), [-1, self._seq_length])
     masked_matrix = tf.cast(cumsum_matrix <= self._max_predictions_per_seq,
@@ -348,43 +349,37 @@
     non_func_mask = tf.logical_and(
         tf.not_equal(inputs, self._sep_id), tf.not_equal(inputs, self._cls_id))
     non_func_indices = tf.boolean_mask(all_indices, non_func_mask)
 
     masked_pos = tf.random.shuffle(non_func_indices)
     masked_pos = tf.sort(masked_pos[:self._max_predictions_per_seq])
 
-    sparse_indices = tf.stack(
-        [tf.zeros_like(masked_pos), masked_pos], axis=-1)
+    sparse_indices = tf.stack([tf.zeros_like(masked_pos), masked_pos], axis=-1)
     sparse_indices = tf.cast(sparse_indices, tf.int64)
 
     sparse_indices = tf.sparse.SparseTensor(
         sparse_indices,
         values=tf.ones_like(masked_pos),
         dense_shape=(1, self._seq_length))
 
-    target_mask = tf.sparse.to_dense(
-        sp_input=sparse_indices,
-        default_value=0)
+    target_mask = tf.sparse.to_dense(sp_input=sparse_indices, default_value=0)
 
     return tf.squeeze(tf.cast(target_mask, tf.bool))
 
-  def _whole_word_mask(self,
-                       inputs: tf.Tensor,
+  def _whole_word_mask(self, inputs: tf.Tensor,
                        boundary: tf.Tensor) -> tf.Tensor:
     """Samples whole words as prediction targets."""
     pair_indices = tf.concat([boundary[:-1, None], boundary[1:, None]], axis=1)
     cand_pair_indices = tf.random.shuffle(
         pair_indices)[:self._max_predictions_per_seq]
     begin_indices = cand_pair_indices[:, 0]
     end_indices = cand_pair_indices[:, 1]
 
     return self._index_pair_to_mask(
-        begin_indices=begin_indices,
-        end_indices=end_indices,
-        inputs=inputs)
+        begin_indices=begin_indices, end_indices=end_indices, inputs=inputs)
 
   def _token_span_mask(self, inputs: tf.Tensor) -> tf.Tensor:
     """Samples token spans as prediction targets."""
     min_num_tokens = self._params.min_num_tokens
     max_num_tokens = self._params.max_num_tokens
 
     mask_alpha = self._seq_length / self._max_predictions_per_seq
@@ -425,21 +420,17 @@
     # Shuffle valid indices
     num_valid = tf.cast(tf.shape(begin_indices)[0], tf.int32)
     order = tf.random.shuffle(tf.range(num_valid, dtype=tf.int32))
     begin_indices = tf.gather(begin_indices, order)
     end_indices = tf.gather(end_indices, order)
 
     return self._index_pair_to_mask(
-        begin_indices=begin_indices,
-        end_indices=end_indices,
-        inputs=inputs)
-
-  def _word_span_mask(self,
-                      inputs: tf.Tensor,
-                      boundary: tf.Tensor):
+        begin_indices=begin_indices, end_indices=end_indices, inputs=inputs)
+
+  def _word_span_mask(self, inputs: tf.Tensor, boundary: tf.Tensor):
     """Sample whole word spans as prediction targets."""
     min_num_words = self._params.min_num_words
     max_num_words = self._params.max_num_words
 
     # Note: 1.2 is the token-to-word ratio
     mask_alpha = self._seq_length / self._max_predictions_per_seq / 1.2
     round_to_int = lambda x: tf.cast(tf.round(x), tf.int32)
@@ -482,20 +473,17 @@
     # Shuffle valid indices
     num_valid = tf.cast(tf.shape(begin_indices)[0], tf.int32)
     order = tf.random.shuffle(tf.range(num_valid, dtype=tf.int32))
     begin_indices = tf.gather(begin_indices, order)
     end_indices = tf.gather(end_indices, order)
 
     return self._index_pair_to_mask(
-        begin_indices=begin_indices,
-        end_indices=end_indices,
-        inputs=inputs)
+        begin_indices=begin_indices, end_indices=end_indices, inputs=inputs)
 
-  def _online_sample_mask(self,
-                          inputs: tf.Tensor,
+  def _online_sample_mask(self, inputs: tf.Tensor,
                           boundary: tf.Tensor) -> tf.Tensor:
     """Samples target positions for predictions.
 
     Descriptions of each strategy:
       - 'single_token': Samples individual tokens as prediction targets.
       - 'token_span': Samples spans of tokens as prediction targets.
       - 'whole_word': Samples individual words as prediction targets.
@@ -527,36 +515,33 @@
     elif self._sample_strategy == 'whole_word':
       return self._whole_word_mask(inputs, boundary)
     elif self._sample_strategy == 'word_span':
       return self._word_span_mask(inputs, boundary)
     else:
       raise NotImplementedError('Invalid sample strategy.')
 
-  def _get_factorization(self,
-                         inputs: tf.Tensor,
-                         input_mask: tf.Tensor):
+  def _get_factorization(self, inputs: tf.Tensor, input_mask: tf.Tensor):
     """Samples a permutation of the factorization order.
 
     Args:
       inputs: the input tokens.
-      input_mask: the `bool` Tensor of the same shape as `inputs`.
-        If `True`, then this means select for partial prediction.
+      input_mask: the `bool` Tensor of the same shape as `inputs`. If `True`,
+        then this means select for partial prediction.
 
     Returns:
       perm_mask: An `int32` Tensor of shape [seq_length, seq_length] consisting
         of 0s and 1s. If perm_mask[i][j] == 0, then this means that the i-th
         token (in original order) cannot attend to the jth attention token.
       target_mask: An `int32` Tensor of shape [seq_len] consisting of 0s and 1s.
         If target_mask[i] == 1, then the i-th token needs to be predicted and
         the mask will be used as input. This token will be included in the loss.
         If target_mask[i] == 0, then the token (or [SEP], [CLS]) will be used as
         input. This token will not be included in the loss.
       tokens: int32 Tensor of shape [seq_length].
       masked_tokens: int32 Tensor of shape [seq_length].
-
     """
     factorization_length = tf.shape(inputs)[0]
     # Generate permutation indices
     index = tf.range(factorization_length, dtype=tf.int32)
     index = tf.transpose(tf.reshape(index, [-1, self._permutation_size]))
     index = tf.random.shuffle(index)
     index = tf.reshape(tf.transpose(index), [-1])
@@ -572,16 +557,16 @@
 
     smallest_index = -2 * tf.ones([factorization_length], dtype=tf.int32)
 
     # Similar to BERT, randomly leak some masked tokens
     if self._leak_ratio > 0:
       leak_tokens = tf.logical_and(
           masked_tokens,
-          tf.random.uniform([factorization_length],
-                            maxval=1.0) < self._leak_ratio)
+          tf.random.uniform([factorization_length], maxval=1.0) <
+          self._leak_ratio)
       can_attend_self = tf.logical_or(non_masked_or_func_tokens, leak_tokens)
     else:
       can_attend_self = non_masked_or_func_tokens
     to_index = tf.where(can_attend_self, smallest_index, index)
     from_index = tf.where(can_attend_self, to_index + 1, to_index)
 
     # For masked tokens, can attend if i > j
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/pretrain_dataloader_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/pretrain_dataloader_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for official.nlp.data.pretrain_dataloader."""
 import itertools
 import os
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import pretrain_dataloader
 
 
 def create_int_feature(values):
   f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))
   return f
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/pretrain_dynamic_dataloader.py` & `tf-models-no-deps-2.16.0/official/nlp/data/pretrain_dynamic_dataloader.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Dataset loader for the pre-training with dynamic sequence length."""
 from typing import Optional, Tuple
 
 import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.core import input_reader
 from official.nlp.data import data_loader_factory
 from official.nlp.data import pretrain_dataloader
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/pretrain_dynamic_dataloader_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/pretrain_dynamic_dataloader_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Tests for nlp.data.pretrain_dynamic_dataloader."""
 import os
 
 from absl import logging
 from absl.testing import parameterized
 import numpy as np
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
 from official.nlp.data import pretrain_dataloader
 from official.nlp.data import pretrain_dynamic_dataloader
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/question_answering_dataloader.py` & `tf-models-no-deps-2.16.0/official/nlp/data/question_answering_dataloader.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,26 +1,27 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Loads dataset for the question answering (e.g, SQuAD) task."""
+import dataclasses
 from typing import Mapping, Optional
 
-import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
+from official.common import dataset_fn
 from official.core import config_definitions as cfg
 from official.core import input_reader
 from official.nlp.data import data_loader
 from official.nlp.data import data_loader_factory
 
 
 @dataclasses.dataclass
@@ -40,14 +41,15 @@
   query_length: int = 64
   # The path to the vocab file of word piece tokenizer or the
   # model of the sentence piece tokenizer.
   vocab_file: str = ''
   tokenization: str = 'WordPiece'  # WordPiece or SentencePiece
   do_lower_case: bool = True
   xlnet_format: bool = False
+  file_type: str = 'tfrecord'
 
 
 @data_loader_factory.register_data_loader_cls(QADataConfig)
 class QuestionAnsweringDataLoader(data_loader.DataLoader):
   """A class to load dataset for sentence prediction (classification) task."""
 
   def __init__(self, params):
@@ -102,9 +104,12 @@
       if name == 'start_positions' and self._xlnet_format:
         x[name] = tensor
     return (x, y)
 
   def load(self, input_context: Optional[tf.distribute.InputContext] = None):
     """Returns a tf.dataset.Dataset."""
     reader = input_reader.InputReader(
-        params=self._params, decoder_fn=self._decode, parser_fn=self._parse)
+        params=self._params,
+        dataset_fn=dataset_fn.pick_dataset_fn(self._params.file_type),
+        decoder_fn=self._decode,
+        parser_fn=self._parse)
     return reader.read(input_context)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/question_answering_dataloader_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/question_answering_dataloader_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.data.question_answering_dataloader."""
 import os
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import question_answering_dataloader
 
 
 def _create_fake_dataset(output_path, seq_length):
   """Creates a fake dataset."""
   writer = tf.io.TFRecordWriter(output_path)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/sentence_prediction_dataloader.py` & `tf-models-no-deps-2.16.0/official/nlp/data/sentence_prediction_dataloader.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Loads dataset for the sentence prediction (classification) task."""
+import dataclasses
 import functools
 from typing import List, Mapping, Optional, Tuple
 
-import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_hub as hub
 
 from official.common import dataset_fn
 from official.core import config_definitions as cfg
 from official.core import input_reader
 from official.nlp import modeling
 from official.nlp.data import data_loader
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/sentence_prediction_dataloader_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/sentence_prediction_dataloader_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for official.nlp.data.sentence_prediction_dataloader."""
 import os
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from sentencepiece import SentencePieceTrainer
 from official.nlp.data import sentence_prediction_dataloader as loader
 
 
 def _create_fake_preprocessed_dataset(output_path, seq_length, label_type):
   """Creates a fake dataset."""
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/sentence_retrieval_lib.py` & `tf-models-no-deps-2.16.0/official/nlp/data/sentence_retrieval_lib.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/squad_lib.py` & `tf-models-no-deps-2.16.0/official/nlp/data/squad_lib.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,15 +19,15 @@
 import json
 import math
 import os
 
 import six
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.tools import tokenization
 
 
 class SquadExample(object):
   """A single training/test example for simple sequence classification.
 
@@ -488,15 +488,15 @@
   #
   # The original whitespace-tokenized answer will be "(1895-1943).". However
   # after tokenization, our tokens will be "( 1895 - 1943 ) .". So we can match
   # the exact answer, 1895.
   #
   # However, this is not always possible. Consider the following:
   #
-  #   Question: What country is the top exporter of electornics?
+  #   Question: What country is the top exporter of electronics?
   #   Context: The Japanese electronics industry is the lagest in the world.
   #   Answer: Japan
   #
   # In this case, the annotator chose "Japan" as a character sub-span of
   # the word "Japanese". Since our WordPiece tokenizer does not split
   # "Japanese", we just use "Japanese" as the annotation. This is fairly rare
   # in SQuAD, but does happen.
@@ -716,15 +716,15 @@
 
       nbest.append(
           _NbestPrediction(
               text=final_text,
               start_logit=pred.start_logit,
               end_logit=pred.end_logit))
 
-    # if we didn't inlude the empty option in the n-best, inlcude it
+    # if we didn't include the empty option in the n-best, include it
     if version_2_with_negative and not xlnet_format:
       if "" not in seen_predictions:
         nbest.append(
             _NbestPrediction(
                 text="", start_logit=null_start_logit,
                 end_logit=null_end_logit))
     # In very rare edge cases we could have no valid predictions. So we
@@ -811,15 +811,15 @@
   # (the SQuAD eval script also does punctuation stripping/lower casing but
   # our tokenizer does additional normalization like stripping accent
   # characters).
   #
   # What we really want to return is "Steve Smith".
   #
   # Therefore, we have to apply a semi-complicated alignment heruistic between
-  # `pred_text` and `orig_text` to get a character-to-charcter alignment. This
+  # `pred_text` and `orig_text` to get a character-to-character alignment. This
   # can fail in certain cases in which case we just return `orig_text`.
 
   def _strip_spaces(text):
     ns_chars = []
     ns_to_s_map = collections.OrderedDict()
     for (i, c) in enumerate(text):
       if c == " ":
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/squad_lib_sp.py` & `tf-models-no-deps-2.16.0/official/nlp/data/squad_lib_sp.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,15 +22,15 @@
 import copy
 import json
 import math
 import os
 
 from absl import logging
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.tools import tokenization
 
 
 class SquadExample(object):
   """A single training/test example for simple sequence classification.
 
@@ -59,15 +59,15 @@
   def __repr__(self):
     s = ""
     s += "qas_id: %s" % (tokenization.printable_text(self.qas_id))
     s += ", question_text: %s" % (
         tokenization.printable_text(self.question_text))
     s += ", paragraph_text: [%s]" % (" ".join(self.paragraph_text))
     if self.start_position:
-      s += ", start_position: %d" % (self.start_position)
+      s += ", start_position: %d" % (self.start_position,)
     if self.start_position:
       s += ", end_position: %d" % (self.end_position)
     if self.start_position:
       s += ", is_impossible: %r" % (self.is_impossible)
     return s
 
 
@@ -772,15 +772,15 @@
 
       nbest.append(
           _NbestPrediction(
               text=final_text,
               start_logit=pred.start_logit,
               end_logit=pred.end_logit))
 
-    # if we didn't inlude the empty option in the n-best, include it
+    # if we didn't include the empty option in the n-best, include it
     if version_2_with_negative and not xlnet_format:
       if "" not in seen_predictions:
         nbest.append(
             _NbestPrediction(
                 text="", start_logit=null_start_logit,
                 end_logit=null_end_logit))
     # In very rare edge cases we could have no valid predictions. So we
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/tagging_data_lib.py` & `tf-models-no-deps-2.16.0/official/nlp/data/tagging_data_lib.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Library to process data for tagging task such as NER/POS."""
 import collections
 import os
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import classifier_data_lib
 from official.nlp.tools import tokenization
 
 # A negative label id for the padding label, which will not contribute
 # to loss/metrics in training.
 _PADDING_LABEL_ID = -1
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/tagging_data_lib_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/tagging_data_lib_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for official.nlp.data.tagging_data_lib."""
 import os
 import random
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import tagging_data_lib
 from official.nlp.tools import tokenization
 
 
 def _create_fake_file(filename, labels, is_test):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/tagging_dataloader.py` & `tf-models-no-deps-2.16.0/official/nlp/data/tagging_dataloader.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,38 +1,40 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Loads dataset for the tagging (e.g., NER/POS) task."""
+import dataclasses
 from typing import Mapping, Optional
 
-import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
+from official.common import dataset_fn
 from official.core import config_definitions as cfg
 from official.core import input_reader
 from official.nlp.data import data_loader
 from official.nlp.data import data_loader_factory
 
 
 @dataclasses.dataclass
 class TaggingDataConfig(cfg.DataConfig):
   """Data config for tagging (tasks/tagging)."""
   is_training: bool = True
   seq_length: int = 128
   include_sentence_id: bool = False
+  file_type: str = 'tfrecord'
 
 
 @data_loader_factory.register_data_loader_cls(TaggingDataConfig)
 class TaggingDataLoader(data_loader.DataLoader):
   """A class to load dataset for tagging (e.g., NER and POS) task."""
 
   def __init__(self, params: TaggingDataConfig):
@@ -77,9 +79,12 @@
 
     y = record['label_ids']
     return (x, y)
 
   def load(self, input_context: Optional[tf.distribute.InputContext] = None):
     """Returns a tf.dataset.Dataset."""
     reader = input_reader.InputReader(
-        params=self._params, decoder_fn=self._decode, parser_fn=self._parse)
+        params=self._params,
+        dataset_fn=dataset_fn.pick_dataset_fn(self._params.file_type),
+        decoder_fn=self._decode,
+        parser_fn=self._parse)
     return reader.read(input_context)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/tagging_dataloader_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/tagging_dataloader_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for official.nlp.data.tagging_data_loader."""
 import os
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import tagging_dataloader
 
 
 def _create_fake_dataset(output_path, seq_length, include_sentence_id):
   """Creates a fake dataset."""
   writer = tf.io.TFRecordWriter(output_path)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/train_sentencepiece.py` & `tf-models-no-deps-2.16.0/official/nlp/data/train_sentencepiece.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -24,15 +24,15 @@
 import os
 import tempfile
 from typing import List, Tuple
 
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 from sentencepiece import SentencePieceTrainer
 
 
 FLAGS = flags.FLAGS
 flags.DEFINE_string("output_model_path", None,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/wmt_dataloader.py` & `tf-models-no-deps-2.16.0/official/nlp/data/wmt_dataloader.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -30,15 +30,15 @@
 
    This batching scheme decreases the fraction of padding tokens per training
    batch, thus improving the training speed significantly.
 """
 from typing import Dict, Optional
 
 import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_text as tftxt
 from official.core import config_definitions as cfg
 from official.core import input_reader
 from official.nlp.data import data_loader
 from official.nlp.data import data_loader_factory
 
 # Example grouping constants. Defines length boundaries for each group.
@@ -113,15 +113,15 @@
   # Create list of batch sizes for each bucket_id, so that
   # bucket_batch_size[bucket_id] * buckets_max[bucket_id] <= batch_size
   bucket_batch_sizes = [int(batch_size) // x for x in buckets_max]
 
   # Validates bucket batch sizes.
   if any([batch_size <= 0 for batch_size in bucket_batch_sizes]):
     raise ValueError(
-        'The token budget, global batch size, is too small to yeild 0 bucket '
+        'The token budget, global batch size, is too small to yield 0 bucket '
         'window: %s' % str(bucket_batch_sizes))
 
   # bucket_id will be a tensor, so convert this list to a tensor as well.
   bucket_batch_sizes = tf.constant(bucket_batch_sizes, dtype=tf.int64)
 
   def example_to_bucket_id(example):
     """Return int64 bucket id for this example, calculated based on length."""
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/data/wmt_dataloader_test.py` & `tf-models-no-deps-2.16.0/official/nlp/data/wmt_dataloader_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.data.wmt_dataloader."""
 import os
 from absl.testing import parameterized
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from sentencepiece import SentencePieceTrainer
 from official.nlp.data import wmt_dataloader
 
 
 def _generate_line_file(filepath, lines):
   with tf.io.gfile.GFile(filepath, 'w') as f:
@@ -37,15 +37,15 @@
                 value=[src.encode()])),
         'reverse_en': tf.train.Feature(
             bytes_list=tf.train.BytesList(
                 value=[tgt.encode()])),
     }
     if unique_id:
       features['unique_id'] = tf.train.Feature(
-          int64_list=tf.train.Int64List(value=[i])),
+          int64_list=tf.train.Int64List(value=[i]))
     example = tf.train.Example(
         features=tf.train.Features(
             feature=features))
     writer.write(example.SerializeToString())
   writer.close()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/metrics/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/metrics/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/metrics/bleu.py` & `tf-models-no-deps-2.16.0/official/nlp/metrics/bleu.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,15 +21,15 @@
 import collections
 import math
 import re
 import sys
 import unicodedata
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class UnicodeRegex(object):
   """Ad-hoc hack to recognize all punctuation and symbols."""
 
   def __init__(self):
     punctuation = self.property_chars("P")
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/metrics/bleu_test.py` & `tf-models-no-deps-2.16.0/official/nlp/metrics/bleu_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Test functions in compute_blue.py."""
 
 import tempfile
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.metrics import bleu
 
 
 class ComputeBleuTest(tf.test.TestCase):
 
   def _create_temp_file(self, text):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,16 +10,16 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """NLP Modeling Library.
 
-This library provides a set of Keras primitives (`tf.keras.Layer` and
-`tf.keras.Model`) that can be assembled into transformer-based models.
+This library provides a set of Keras primitives (`tf_keras.Layer` and
+`tf_keras.Model`) that can be assembled into transformer-based models.
 They are flexible, validated, interoperable, and both TF1 and TF2 compatible.
 """
 from official.nlp.modeling import layers
 from official.nlp.modeling import losses
 from official.nlp.modeling import models
 from official.nlp.modeling import networks
 from official.nlp.modeling import ops
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/__init__.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,14 +13,16 @@
 # limitations under the License.
 
 """Layers are the fundamental building blocks for NLP models.
 
 They can be used to assemble new `tf.keras` layers or models.
 """
 # pylint: disable=wildcard-import
+
+from official.nlp.modeling.layers import util
 from official.nlp.modeling.layers.attention import *
 from official.nlp.modeling.layers.bigbird_attention import BigBirdAttention
 from official.nlp.modeling.layers.bigbird_attention import BigBirdMasks
 from official.nlp.modeling.layers.block_diag_feedforward import BlockDiagFeedforward
 from official.nlp.modeling.layers.cls_head import *
 from official.nlp.modeling.layers.factorized_embedding import FactorizedEmbedding
 from official.nlp.modeling.layers.gated_feedforward import GatedFeedforward
@@ -33,14 +35,18 @@
 from official.nlp.modeling.layers.mixing import FourierTransformLayer
 from official.nlp.modeling.layers.mixing import HartleyTransformLayer
 from official.nlp.modeling.layers.mixing import LinearTransformLayer
 from official.nlp.modeling.layers.mixing import MixingMechanism
 from official.nlp.modeling.layers.mobile_bert_layers import MobileBertEmbedding
 from official.nlp.modeling.layers.mobile_bert_layers import MobileBertMaskedLM
 from official.nlp.modeling.layers.mobile_bert_layers import MobileBertTransformer
+from official.nlp.modeling.layers.moe import ExpertsChooseMaskedRouter
+from official.nlp.modeling.layers.moe import FeedForwardExperts
+from official.nlp.modeling.layers.moe import MoeLayer
+from official.nlp.modeling.layers.moe import MoeLayerWithBackbone
 from official.nlp.modeling.layers.multi_channel_attention import *
 from official.nlp.modeling.layers.on_device_embedding import OnDeviceEmbedding
 from official.nlp.modeling.layers.pack_optimization import PackBertEmbeddings
 from official.nlp.modeling.layers.pack_optimization import StridedTransformerEncoderBlock
 from official.nlp.modeling.layers.pack_optimization import StridedTransformerScaffold
 from official.nlp.modeling.layers.per_dim_scale_attention import PerDimScaleAttention
 from official.nlp.modeling.layers.position_embedding import PositionEmbedding
@@ -48,15 +54,15 @@
 from official.nlp.modeling.layers.position_embedding import RelativePositionEmbedding
 from official.nlp.modeling.layers.relative_attention import MultiHeadRelativeAttention
 from official.nlp.modeling.layers.relative_attention import TwoStreamRelativeAttention
 from official.nlp.modeling.layers.reuse_attention import ReuseMultiHeadAttention
 from official.nlp.modeling.layers.reuse_transformer import ReuseTransformer
 from official.nlp.modeling.layers.rezero_transformer import ReZeroTransformer
 from official.nlp.modeling.layers.routing import *
-from official.nlp.modeling.layers.self_attention_mask import SelfAttentionMask
+from official.nlp.modeling.layers.self_attention_mask import *
 from official.nlp.modeling.layers.spectral_normalization import *
 from official.nlp.modeling.layers.talking_heads_attention import TalkingHeadsAttention
 from official.nlp.modeling.layers.text_layers import BertPackInputs
 from official.nlp.modeling.layers.text_layers import BertTokenizer
 from official.nlp.modeling.layers.text_layers import FastWordpieceBertTokenizer
 from official.nlp.modeling.layers.text_layers import SentencepieceTokenizer
 from official.nlp.modeling.layers.tn_transformer_expand_condense import TNTransformerExpandCondense
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/attention.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/attention.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,25 +12,25 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based attention layer."""
 # pylint: disable=g-classes-have-attributes
 import math
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-EinsumDense = tf.keras.layers.EinsumDense
-MultiHeadAttention = tf.keras.layers.MultiHeadAttention
+EinsumDense = tf_keras.layers.EinsumDense
+MultiHeadAttention = tf_keras.layers.MultiHeadAttention
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class CachedAttention(tf.keras.layers.MultiHeadAttention):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class CachedAttention(tf_keras.layers.MultiHeadAttention):
   """Attention layer with cache used for autoregressive decoding.
 
-  Arguments are the same as `tf.keras.layers.MultiHeadAttention` layer.
+  Arguments are the same as `tf_keras.layers.MultiHeadAttention` layer.
   """
 
   def _update_cache(self, key, value, cache, decode_loop_step):
     """Updates cache states and gets full-length key/value tensors."""
     # Combines cached keys and values with new keys and values.
     if decode_loop_step is not None:
       # TPU special case.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/attention_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/attention_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,33 +11,31 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for the attention layer."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import attention
 
 
 def _create_cache(batch_size, init_decode_length, num_heads, head_size):
   return {
       "key":
           tf.zeros([batch_size, init_decode_length, num_heads, head_size],
                    dtype=tf.float32),
       "value":
           tf.zeros([batch_size, init_decode_length, num_heads, head_size],
                    dtype=tf.float32)
   }
 
 
-@keras_parameterized.run_all_keras_modes
-class CachedAttentionTest(keras_parameterized.TestCase):
+class CachedAttentionTest(tf.test.TestCase):
 
   def test_masked_attention(self):
     """Test with a mask tensor."""
     num_heads, head_size = 2, 2
     # Create a 3-dimensional input (the first dimension is implicit).
     from_seq_length = 4
     batch_size = 3
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/bigbird_attention.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/bigbird_attention.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based bigbird attention layer."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 MAX_SEQ_LEN = 4096
 
 
 def create_band_mask_from_inputs(from_blocked_mask, to_blocked_mask):
   """Create 3D attention mask from a 2D tensor mask.
 
@@ -364,15 +364,15 @@
       second_last_context_layer, last_context_layer
   ], 2)
   context_layer = tf.reshape(context_layer, (b, h, m, -1)) * from_mask
   context_layer = tf.transpose(context_layer, (0, 2, 1, 3))
   return context_layer
 
 
-class BigBirdMasks(tf.keras.layers.Layer):
+class BigBirdMasks(tf_keras.layers.Layer):
   """Creates bigbird attention masks."""
 
   def __init__(self, block_size, **kwargs):
     super().__init__(**kwargs)
     self._block_size = block_size
 
   def call(self, inputs, mask):
@@ -386,16 +386,16 @@
     encoder_to_mask = tf.reshape(mask, (batch_size, 1, 1, seq_length))
 
     band_mask = create_band_mask_from_inputs(blocked_encoder_mask,
                                              blocked_encoder_mask)
     return [band_mask, encoder_from_mask, encoder_to_mask, blocked_encoder_mask]
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class BigBirdAttention(tf.keras.layers.MultiHeadAttention):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class BigBirdAttention(tf_keras.layers.MultiHeadAttention):
   """BigBird, a sparse attention mechanism.
 
   This layer follows the paper "Big Bird: Transformers for Longer Sequences"
   (https://arxiv.org/abs/2007.14062).
   It reduces this quadratic dependency of attention
   computation to linear.
 
@@ -454,15 +454,15 @@
         batch_size=query_shape[0],
         from_seq_length=from_seq_length,
         to_seq_length=to_seq_length,
         from_block_size=self._from_block_size,
         to_block_size=self._to_block_size,
         rand_attn=rand_attn)
 
-  def call(self, query, value, key=None, attention_mask=None, **kwargs):
+  def call(self, query, value, key=None, attention_mask=None, **kwargs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     if not self._built_from_signature:
       self._build_from_signature(query=query, value=value, key=key)
     if key is None:
       key = value
 
     #   N = `num_attention_heads`
     #   H = `size_per_head`
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/bigbird_attention_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/bigbird_attention_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.projects.bigbird.attention."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import bigbird_attention as attention
 
 
 class BigbirdAttentionTest(tf.test.TestCase):
 
   def test_attention(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/block_diag_feedforward.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/block_diag_feedforward.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,20 +12,20 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based gated feedforward layer."""
 # pylint: disable=g-classes-have-attributes
 from typing import Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
-class BlockDiagFeedforward(tf.keras.layers.Layer):
+class BlockDiagFeedforward(tf_keras.layers.Layer):
   """Block diagonal feedforward layer.
 
   This layer replaces the weight matrix of the output_dense layer with a block
   diagonal matrix to save layer parameters and FLOPs. A linear mixing layer can
   be added optionally to improve layer expressibility.
 
   Args:
@@ -49,116 +49,116 @@
       intermediate_size: int,
       intermediate_activation: str,
       dropout: float,
       num_blocks: int = 1,
       apply_mixing: bool = True,
       kernel_initializer: str = "glorot_uniform",
       bias_initializer: str = "zeros",
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      activity_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      kernel_constraint: Optional[tf.keras.constraints.Constraint] = None,
-      bias_constraint: Optional[tf.keras.constraints.Constraint] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      activity_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      kernel_constraint: Optional[tf_keras.constraints.Constraint] = None,
+      bias_constraint: Optional[tf_keras.constraints.Constraint] = None,
       **kwargs):  # pylint: disable=g-doc-args
     super().__init__(**kwargs)
     self._intermediate_size = intermediate_size
     self._intermediate_activation = intermediate_activation
     self._dropout = dropout
     self._num_blocks = num_blocks
     self._apply_mixing = apply_mixing
 
     if intermediate_size % num_blocks != 0:
       raise ValueError("Intermediate_size (%d) isn't a multiple of num_blocks "
                        "(%d)." % (intermediate_size, num_blocks))
 
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._activity_regularizer = tf.keras.regularizers.get(activity_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._activity_regularizer = tf_keras.regularizers.get(activity_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
 
   def build(self, input_shape):
     hidden_size = input_shape.as_list()[-1]
 
     common_kwargs = dict(
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer,
         activity_regularizer=self._activity_regularizer,
         kernel_constraint=self._kernel_constraint,
         bias_constraint=self._bias_constraint)
 
-    self._intermediate_dense = tf.keras.layers.EinsumDense(
+    self._intermediate_dense = tf_keras.layers.EinsumDense(
         "abc,cde->abde",
         output_shape=(None, self._num_blocks,
                       self._intermediate_size // self._num_blocks),
         bias_axes="de",
         name="intermediate",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
 
-    policy = tf.keras.mixed_precision.global_policy()
+    policy = tf_keras.mixed_precision.global_policy()
     if policy.name == "mixed_bfloat16":
       # bfloat16 causes BERT with the LAMB optimizer to not converge
       # as well, so we use float32.
       policy = tf.float32
-    self._intermediate_activation_layer = tf.keras.layers.Activation(
+    self._intermediate_activation_layer = tf_keras.layers.Activation(
         self._intermediate_activation, dtype=policy)
 
-    self._output_dense = tf.keras.layers.EinsumDense(
+    self._output_dense = tf_keras.layers.EinsumDense(
         "abde,deo->abdo",
         output_shape=(None, self._num_blocks, hidden_size // self._num_blocks),
         bias_axes="do",
         name="output",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
 
     if self._apply_mixing:
-      self._output_mixing = tf.keras.layers.EinsumDense(
+      self._output_mixing = tf_keras.layers.EinsumDense(
           "abdo,de->abeo",
           output_shape=(None, self._num_blocks,
                         hidden_size // self._num_blocks),
           name="output_mixing",
           kernel_initializer=tf_utils.clone_initializer(
               self._kernel_initializer),
           bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
           **common_kwargs)
-    self._output_reshape = tf.keras.layers.Reshape((-1, hidden_size))
+    self._output_reshape = tf_keras.layers.Reshape((-1, hidden_size))
 
-    self._output_dropout = tf.keras.layers.Dropout(rate=self._dropout)
+    self._output_dropout = tf_keras.layers.Dropout(rate=self._dropout)
 
   def get_config(self):
     config = {
         "intermediate_size":
             self._intermediate_size,
         "intermediate_activation":
             self._intermediate_activation,
         "dropout":
             self._dropout,
         "num_blocks":
             self._num_blocks,
         "apply_mixing":
             self._apply_mixing,
         "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
+            tf_keras.initializers.serialize(self._kernel_initializer),
         "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
+            tf_keras.initializers.serialize(self._bias_initializer),
         "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
+            tf_keras.regularizers.serialize(self._kernel_regularizer),
         "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
+            tf_keras.regularizers.serialize(self._bias_regularizer),
         "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
+            tf_keras.regularizers.serialize(self._activity_regularizer),
         "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
+            tf_keras.constraints.serialize(self._kernel_constraint),
         "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint)
+            tf_keras.constraints.serialize(self._bias_constraint)
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs):
     intermediate_output = self._intermediate_dense(inputs)
     intermediate_output = self._intermediate_activation_layer(
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/block_diag_feedforward_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/block_diag_feedforward_test.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,55 +12,53 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based gated feedforward layer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import block_diag_feedforward
 
 
 # This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
 # guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class BlockDiagFeedforwardTest(keras_parameterized.TestCase):
+class BlockDiagFeedforwardTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(BlockDiagFeedforwardTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   @parameterized.parameters(
       (1, True, "float32"),
       (1, True, "mixed_float16"),
       (1, False, "float32"),
       (1, False, "mixed_float16"),
       (2, True, "float32"),
       (2, True, "mixed_float16"),
       (2, False, "float32"),
       (2, False, "mixed_float16"),
   )
   def test_layer_creation(self, num_blocks, apply_mixing, dtype):
-    tf.keras.mixed_precision.set_global_policy(dtype)
+    tf_keras.mixed_precision.set_global_policy(dtype)
     kwargs = dict(
         intermediate_size=128,
         intermediate_activation="relu",
         dropout=0.1,
         num_blocks=num_blocks,
         apply_mixing=apply_mixing,
         kernel_initializer="glorot_uniform",
         bias_initializer="zeros")
     test_layer = block_diag_feedforward.BlockDiagFeedforward(**kwargs)
 
     sequence_length = 64
     width = 128
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   @parameterized.parameters(
       (1, True, "float32"),
       (1, True, "mixed_float16"),
@@ -68,33 +66,33 @@
       (1, False, "mixed_float16"),
       (2, True, "float32"),
       (2, True, "mixed_float16"),
       (2, False, "float32"),
       (2, False, "mixed_float16"),
   )
   def test_layer_invocation(self, num_blocks, apply_mixing, dtype):
-    tf.keras.mixed_precision.set_global_policy(dtype)
+    tf_keras.mixed_precision.set_global_policy(dtype)
     kwargs = dict(
         intermediate_size=16,
         intermediate_activation="relu",
         dropout=0.1,
         num_blocks=num_blocks,
         apply_mixing=apply_mixing,
         kernel_initializer="glorot_uniform",
         bias_initializer="zeros")
     test_layer = block_diag_feedforward.BlockDiagFeedforward(**kwargs)
 
     sequence_length = 16
     width = 32
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(data_tensor, output_tensor)
+    model = tf_keras.Model(data_tensor, output_tensor)
 
     # Invoke the model on test data.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     output_data = model.predict(input_data)
     self.assertEqual(output_data.shape, (batch_size, sequence_length, width))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/cls_head.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/cls_head.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,23 +10,23 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """A Classification head layer which is common used with sequence encoders."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 from official.nlp.modeling.layers import gaussian_process
 from official.nlp.modeling.layers import spectral_normalization
 
 
-class ClassificationHead(tf.keras.layers.Layer):
+class ClassificationHead(tf_keras.layers.Layer):
   """Pooling head for sentence-level classification tasks."""
 
   def __init__(self,
                inner_dim,
                num_classes,
                cls_token_idx=0,
                activation="tanh",
@@ -46,26 +46,26 @@
       **kwargs: Keyword arguments.
     """
     super().__init__(**kwargs)
     self.dropout_rate = dropout_rate
     self.inner_dim = inner_dim
     self.num_classes = num_classes
     self.activation = tf_utils.get_activation(activation)
-    self.initializer = tf.keras.initializers.get(initializer)
+    self.initializer = tf_keras.initializers.get(initializer)
     self.cls_token_idx = cls_token_idx
 
     if self.inner_dim:
-      self.dense = tf.keras.layers.Dense(
+      self.dense = tf_keras.layers.Dense(
           units=self.inner_dim,
           activation=self.activation,
           kernel_initializer=tf_utils.clone_initializer(self.initializer),
           name="pooler_dense")
-    self.dropout = tf.keras.layers.Dropout(rate=self.dropout_rate)
+    self.dropout = tf_keras.layers.Dropout(rate=self.dropout_rate)
 
-    self.out_proj = tf.keras.layers.Dense(
+    self.out_proj = tf_keras.layers.Dense(
         units=num_classes,
         kernel_initializer=tf_utils.clone_initializer(self.initializer),
         name="logits")
 
   def call(self, features: tf.Tensor, only_project: bool = False):
     """Implements call().
 
@@ -93,30 +93,30 @@
 
   def get_config(self):
     config = {
         "cls_token_idx": self.cls_token_idx,
         "dropout_rate": self.dropout_rate,
         "num_classes": self.num_classes,
         "inner_dim": self.inner_dim,
-        "activation": tf.keras.activations.serialize(self.activation),
-        "initializer": tf.keras.initializers.serialize(self.initializer),
+        "activation": tf_keras.activations.serialize(self.activation),
+        "initializer": tf_keras.initializers.serialize(self.initializer),
     }
     config.update(super(ClassificationHead, self).get_config())
     return config
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
     return cls(**config)
 
   @property
   def checkpoint_items(self):
     return {self.dense.name: self.dense}
 
 
-class MultiClsHeads(tf.keras.layers.Layer):
+class MultiClsHeads(tf_keras.layers.Layer):
   """Pooling heads sharing the same pooling stem."""
 
   def __init__(self,
                inner_dim,
                cls_list,
                cls_token_idx=0,
                activation="tanh",
@@ -137,28 +137,28 @@
       **kwargs: Keyword arguments.
     """
     super().__init__(**kwargs)
     self.dropout_rate = dropout_rate
     self.inner_dim = inner_dim
     self.cls_list = cls_list
     self.activation = tf_utils.get_activation(activation)
-    self.initializer = tf.keras.initializers.get(initializer)
+    self.initializer = tf_keras.initializers.get(initializer)
     self.cls_token_idx = cls_token_idx
 
     if self.inner_dim:
-      self.dense = tf.keras.layers.Dense(
+      self.dense = tf_keras.layers.Dense(
           units=inner_dim,
           activation=self.activation,
           kernel_initializer=tf_utils.clone_initializer(self.initializer),
           name="pooler_dense")
-    self.dropout = tf.keras.layers.Dropout(rate=self.dropout_rate)
+    self.dropout = tf_keras.layers.Dropout(rate=self.dropout_rate)
     self.out_projs = []
     for name, num_classes in cls_list:
       self.out_projs.append(
-          tf.keras.layers.Dense(
+          tf_keras.layers.Dense(
               units=num_classes,
               kernel_initializer=tf_utils.clone_initializer(self.initializer),
               name=name))
 
   def call(self, features: tf.Tensor, only_project: bool = False):
     """Implements call().
 
@@ -189,16 +189,16 @@
 
   def get_config(self):
     config = {
         "dropout_rate": self.dropout_rate,
         "cls_token_idx": self.cls_token_idx,
         "cls_list": self.cls_list,
         "inner_dim": self.inner_dim,
-        "activation": tf.keras.activations.serialize(self.activation),
-        "initializer": tf.keras.initializers.serialize(self.initializer),
+        "activation": tf_keras.activations.serialize(self.activation),
+        "initializer": tf_keras.initializers.serialize(self.initializer),
     }
     config.update(super().get_config())
     return config
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
     return cls(**config)
@@ -362,15 +362,15 @@
   """Extracts spectral normalization configs from a given kwarg."""
 
   return dict(
       iteration=kwargs.pop("iteration", 1),
       norm_multiplier=kwargs.pop("norm_multiplier", .99))
 
 
-class PerQueryDenseHead(tf.keras.layers.Layer):
+class PerQueryDenseHead(tf_keras.layers.Layer):
   """Pooling head used for EncT5 style models.
 
     This module projects each query to use a different projection.
 
     For a input shape= [bs, num_queries, hidden_size], it projects each query to
     (features). Ending up with shape= [bs, num_queries, features].
 
@@ -398,15 +398,15 @@
       **kwargs: Keyword arguments.
     """
     super().__init__(**kwargs)
     self.num_queries = num_queries
     self.features = features
 
     self.use_bias = use_bias
-    self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)
+    self.kernel_initializer = tf_keras.initializers.get(kernel_initializer)
 
   def build(self, input_shape):
     input_shape = tf.TensorShape(input_shape)
     # Hidden size.
     last_dim = tf.compat.dimension_value(input_shape[-1])
 
     self.hidden_size = last_dim
@@ -446,15 +446,15 @@
   def get_config(self):
     config = {
         "num_queries":
             self.num_queries,
         "features":
             self.features,
         "kernel_initializer":
-            tf.keras.activations.serialize(self.kernel_initializer),
+            tf_keras.activations.serialize(self.kernel_initializer),
     }
     config.update(super(PerQueryDenseHead, self).get_config())
     return config
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
     return cls(**config)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/cls_head_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/cls_head_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for cls_head."""
 from absl.testing import parameterized
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import cls_head
 
 
 class ClassificationHeadTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(("no_pooler_layer", 0, 2),
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/factorized_embedding.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/factorized_embedding.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,21 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """A factorized embedding layer."""
 # pylint: disable=g-classes-have-attributes
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import on_device_embedding
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 class FactorizedEmbedding(on_device_embedding.OnDeviceEmbedding):
   """A factorized embeddings layer for supporting larger embeddings.
 
   Arguments:
     vocab_size: Number of elements in the vocabulary.
     embedding_width: Width of word embeddings.
     output_dim: The output dimension of this layer.
@@ -59,15 +59,15 @@
 
   def get_config(self):
     config = {'output_dim': self._output_dim}
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def build(self, input_shape):
-    self._embedding_projection = tf.keras.layers.EinsumDense(
+    self._embedding_projection = tf_keras.layers.EinsumDense(
         '...x,xy->...y',
         output_shape=self._output_dim,
         bias_axes=None,
         kernel_initializer=tf_utils.clone_initializer(self._initializer),
         name='embedding_projection')
     super().build(input_shape)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/factorized_embedding_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/factorized_embedding_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for FactorizedEmbedding layer."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import factorized_embedding
 
 
 class FactorizedEmbeddingTest(tf.test.TestCase):
 
   def test_layer_creation(self):
@@ -28,15 +28,15 @@
     output_dim = 45
     test_layer = factorized_embedding.FactorizedEmbedding(
         vocab_size=vocab_size,
         embedding_width=embedding_width,
         output_dim=output_dim)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # The output should be the same as the input, save that it has an extra
     # embedding_width dimension on the end.
     expected_output_shape = [None, sequence_length, output_dim]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
     self.assertEqual(output_tensor.dtype, tf.float32)
@@ -47,19 +47,19 @@
     output_dim = 45
     test_layer = factorized_embedding.FactorizedEmbedding(
         vocab_size=vocab_size,
         embedding_width=embedding_width,
         output_dim=output_dim)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 3
     input_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     output = model.predict(input_data)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/gated_feedforward.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/gated_feedforward.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,23 +12,23 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based gated feedforward layer."""
 # pylint: disable=g-classes-have-attributes
 
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import util
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
+@tf_keras.utils.register_keras_serializable(package="Text")
 @gin.configurable
-class GatedFeedforward(tf.keras.layers.Layer):
+class GatedFeedforward(tf_keras.layers.Layer):
   """Gated linear feedforward layer.
 
   This layer follows the paper "GLU Variants Improve Transformer"
   (https://arxiv.org/abs/2002.05202). In additional, it allows to stack
   multiple feedforward blocks and specify the position of dropout layer.
 
   Args:
@@ -85,21 +85,21 @@
     self._apply_output_layer_norm = apply_output_layer_norm
     self._dropout_position = dropout_position
     if self._dropout_position not in ("before_residual", "after_residual"):
       raise ValueError(
           "The dropout_position should be either `before_residual` or"
           "`after_residual`, got: %s" % self._dropout_position)
 
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._activity_regularizer = tf.keras.regularizers.get(activity_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._activity_regularizer = tf_keras.regularizers.get(activity_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
 
   def build(self, input_shape):
     hidden_size = input_shape.as_list()[-1]
 
     common_kwargs = dict(
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer,
@@ -108,63 +108,63 @@
         bias_constraint=self._bias_constraint)
     self._intermediate_dense = []
     self._inner_activation_layers = []
     self._gate_dense = []
     self._output_dense = []
     self._output_dropout = []
     self._output_layer_norm = []
-    activation_policy = tf.keras.mixed_precision.global_policy()
+    activation_policy = tf_keras.mixed_precision.global_policy()
     if activation_policy.name == "mixed_bfloat16":
       # bfloat16 causes BERT with the LAMB optimizer to not converge
       # as well, so we use float32.
       # TODO(b/154538392): Investigate this.
       activation_policy = tf.float32
     for i in range(self._num_blocks):
       self._intermediate_dense.append(
-          tf.keras.layers.EinsumDense(
+          tf_keras.layers.EinsumDense(
               "abc,cd->abd",
               output_shape=(None, self._inner_dim),
               bias_axes="d",
               name="intermediate_%d" % i,
               kernel_initializer=tf_utils.clone_initializer(
                   self._kernel_initializer),
               bias_initializer=tf_utils.clone_initializer(
                   self._bias_initializer),
               **common_kwargs))
       self._inner_activation_layers.append(
-          tf.keras.layers.Activation(
+          tf_keras.layers.Activation(
               self._inner_activation, dtype=activation_policy))
       if self._use_gate:
         self._gate_dense.append(
-            tf.keras.layers.EinsumDense(
+            tf_keras.layers.EinsumDense(
                 "abc,cd->abd",
                 output_shape=(None, self._inner_dim),
                 bias_axes="d",
                 name="gate_%d" % i,
                 kernel_initializer=tf_utils.clone_initializer(
                     self._kernel_initializer),
                 bias_initializer=tf_utils.clone_initializer(
                     self._bias_initializer),
                 **common_kwargs))
       self._output_dense.append(
-          tf.keras.layers.EinsumDense(
+          tf_keras.layers.EinsumDense(
               "abc,cd->abd",
               output_shape=(None, hidden_size),
               bias_axes="d",
               name="output_%d" % i,
               kernel_initializer=tf_utils.clone_initializer(
                   self._kernel_initializer),
               bias_initializer=tf_utils.clone_initializer(
                   self._bias_initializer),
               **common_kwargs))
-      self._output_dropout.append(tf.keras.layers.Dropout(rate=self._dropout))
+      self._output_dropout.append(tf_keras.layers.Dropout(rate=self._dropout))
       # Use float32 in layernorm for numeric stability.
       if self._apply_output_layer_norm:
         self._output_layer_norm.append(
-            tf.keras.layers.LayerNormalization(
+            tf_keras.layers.LayerNormalization(
                 name="output_layer_norm_%d" % i,
                 axis=-1,
                 epsilon=1e-12,
                 dtype=tf.float32))
 
   def get_config(self):
     config = {
@@ -177,27 +177,27 @@
         "use_gate":
             self._use_gate,
         "num_blocks":
             self._num_blocks,
         "dropout_position":
             self._dropout_position,
         "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
+            tf_keras.initializers.serialize(self._kernel_initializer),
         "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
+            tf_keras.initializers.serialize(self._bias_initializer),
         "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
+            tf_keras.regularizers.serialize(self._kernel_regularizer),
         "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
+            tf_keras.regularizers.serialize(self._bias_regularizer),
         "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
+            tf_keras.regularizers.serialize(self._activity_regularizer),
         "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
+            tf_keras.constraints.serialize(self._kernel_constraint),
         "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint)
+            tf_keras.constraints.serialize(self._bias_constraint)
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs):
     layer_output = inputs
     for i in range(self._num_blocks):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/gated_feedforward_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/gated_feedforward_test.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,56 +12,52 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based gated feedforward layer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import gated_feedforward
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class GatedFeedforwardTest(keras_parameterized.TestCase):
+class GatedFeedforwardTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(GatedFeedforwardTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   @parameterized.parameters(
       (True, 1, "after_residual", "float32"),
       (True, 1, "after_residual", "mixed_float16"),
       (False, 4, "before_residual", "float32"),
       (False, 4, "before_residual", "mixed_float16"),
       (True, 4, "after_residual", "float32"),
       (True, 4, "after_residual", "mixed_float16"),
       (False, 1, "before_residual", "float32"),
       (False, 1, "before_residual", "mixed_float16"),
   )
   def test_layer_creation(self, use_gate, num_blocks, dropout_position, dtype):
-    tf.keras.mixed_precision.set_global_policy(dtype)
+    tf_keras.mixed_precision.set_global_policy(dtype)
     kwargs = dict(
         inner_dim=128,
         inner_activation="relu",
         dropout=0.1,
         use_gate=use_gate,
         num_blocks=num_blocks,
         dropout_position=dropout_position,
         kernel_initializer="glorot_uniform",
         bias_initializer="zeros")
     test_layer = gated_feedforward.GatedFeedforward(**kwargs)
 
     sequence_length = 64
     width = 128
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   @parameterized.parameters(
       (True, 1, "after_residual", "float32"),
       (True, 1, "after_residual", "mixed_float16"),
@@ -70,34 +66,34 @@
       (True, 4, "after_residual", "float32"),
       (True, 4, "after_residual", "mixed_float16"),
       (False, 1, "before_residual", "float32"),
       (False, 1, "before_residual", "mixed_float16"),
   )
   def test_layer_invocation(self, use_gate, num_blocks, dropout_position,
                             dtype):
-    tf.keras.mixed_precision.set_global_policy(dtype)
+    tf_keras.mixed_precision.set_global_policy(dtype)
     kwargs = dict(
         inner_dim=16,
         inner_activation="relu",
         dropout=0.1,
         use_gate=use_gate,
         num_blocks=num_blocks,
         dropout_position=dropout_position,
         kernel_initializer="glorot_uniform",
         bias_initializer="zeros")
     test_layer = gated_feedforward.GatedFeedforward(**kwargs)
 
     sequence_length = 16
     width = 32
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(data_tensor, output_tensor)
+    model = tf_keras.Model(data_tensor, output_tensor)
 
     # Invoke the model on test data.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     output_data = model.predict(input_data)
     self.assertEqual(output_data.shape, (batch_size, sequence_length, width))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/gaussian_process.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/gaussian_process.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,21 +10,21 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Definitions for random feature Gaussian process layer."""
 import math
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 _SUPPORTED_LIKELIHOOD = ('binary_logistic', 'poisson', 'gaussian')
 
 
-class RandomFeatureGaussianProcess(tf.keras.layers.Layer):
+class RandomFeatureGaussianProcess(tf_keras.layers.Layer):
   """Gaussian process layer with random feature approximation [1].
 
   During training, the model updates the maximum a posteriori (MAP) logits
   estimates and posterior precision matrix using minibatch statistics. During
   inference, the model divides the MAP logit estimates by the predictive
   standard deviation, which is equivalent to approximating the posterior mean
   of the predictive probability via the mean-field approximation.
@@ -94,15 +94,15 @@
       gp_cov_momentum: (float) A discount factor used to compute the moving
         average for posterior covariance matrix.
       gp_cov_ridge_penalty: (float) Initial Ridge penalty to posterior
         covariance matrix.
       scale_random_features: (bool) Whether to scale the random feature
         by sqrt(2. / num_inducing).
       use_custom_random_features: (bool) Whether to use custom random
-        features implemented using tf.keras.layers.Dense.
+        features implemented using tf_keras.layers.Dense.
       custom_random_features_initializer: (str or callable) Initializer for
         the random features. Default to random normal which approximates a RBF
         kernel function if activation function is cos.
       custom_random_features_activation: (callable) Activation function for the
         random feature layer. Default to cosine which approximates a RBF
         kernel function.
       l2_regularization: (float) The strength of l2 regularization on the output
@@ -147,22 +147,22 @@
 
     if self.use_custom_random_features:
       # Default to Gaussian RBF kernel.
       self.random_features_bias_initializer = tf.random_uniform_initializer(
           minval=0., maxval=2. * math.pi)
       if self.custom_random_features_initializer is None:
         self.custom_random_features_initializer = (
-            tf.keras.initializers.RandomNormal(stddev=1.))
+            tf_keras.initializers.RandomNormal(stddev=1.))
       if self.custom_random_features_activation is None:
         self.custom_random_features_activation = tf.math.cos
 
   def build(self, input_shape):
     # Defines model layers.
     if self.normalize_input:
-      self._input_norm_layer = tf.keras.layers.LayerNormalization(
+      self._input_norm_layer = tf_keras.layers.LayerNormalization(
           name='gp_input_normalization')
       self._input_norm_layer.build(input_shape)
       input_shape = self._input_norm_layer.compute_output_shape(input_shape)
 
     self._random_feature = self._make_random_feature_layer(
         name='gp_random_feature')
     self._random_feature.build(input_shape)
@@ -173,18 +173,18 @@
           momentum=self.gp_cov_momentum,
           ridge_penalty=self.gp_cov_ridge_penalty,
           likelihood=self.gp_cov_likelihood,
           dtype=self.dtype,
           name='gp_covariance')
       self._gp_cov_layer.build(input_shape)
 
-    self._gp_output_layer = tf.keras.layers.Dense(
+    self._gp_output_layer = tf_keras.layers.Dense(
         units=self.units,
         use_bias=False,
-        kernel_regularizer=tf.keras.regularizers.l2(self.l2_regularization),
+        kernel_regularizer=tf_keras.regularizers.l2(self.l2_regularization),
         dtype=self.dtype,
         name='gp_output_weights',
         **self.gp_output_kwargs)
     self._gp_output_layer.build(input_shape)
 
     self._gp_output_bias = tf.Variable(
         initial_value=[self.gp_output_bias] * self.units,
@@ -193,29 +193,29 @@
         name='gp_output_bias')
 
     self.built = True
 
   def _make_random_feature_layer(self, name):
     """Defines random feature layer depending on kernel type."""
     if not self.use_custom_random_features:
-      # Use default RandomFourierFeatures layer from tf.keras.
-      return tf.keras.layers.experimental.RandomFourierFeatures(
+      # Use default RandomFourierFeatures layer from tf_keras.
+      return tf_keras.layers.experimental.RandomFourierFeatures(
           output_dim=self.num_inducing,
           kernel_initializer=self.gp_kernel_type,
           scale=self.gp_kernel_scale,
           trainable=self.gp_kernel_scale_trainable,
           dtype=self.dtype,
           name=name)
 
     if self.gp_kernel_type.lower() == 'linear':
-      custom_random_feature_layer = tf.keras.layers.Lambda(
+      custom_random_feature_layer = tf_keras.layers.Lambda(
           lambda x: x, name=name)
     else:
       # Use user-supplied configurations.
-      custom_random_feature_layer = tf.keras.layers.Dense(
+      custom_random_feature_layer = tf_keras.layers.Dense(
           units=self.num_inducing,
           use_bias=True,
           activation=self.custom_random_features_activation,
           kernel_initializer=self.custom_random_features_initializer,
           bias_initializer=self.random_features_bias_initializer,
           trainable=False,
           name=name)
@@ -263,15 +263,15 @@
       model_output.append(gp_covmat)
     if self.return_random_features:
       model_output.append(gp_feature)
 
     return model_output
 
 
-class LaplaceRandomFeatureCovariance(tf.keras.layers.Layer):
+class LaplaceRandomFeatureCovariance(tf_keras.layers.Layer):
   """Computes the Gaussian Process covariance using Laplace method.
 
   At training time, this layer updates the Gaussian process posterior using
   model features in minibatches.
 
   Attributes:
     momentum: (float) A discount factor used to compute the moving average for
@@ -320,15 +320,15 @@
         self.ridge_penalty * tf.eye(gp_feature_dim, dtype=self.dtype))
 
     self.precision_matrix = (
         self.add_weight(
             name='gp_precision_matrix',
             shape=(gp_feature_dim, gp_feature_dim),
             dtype=self.dtype,
-            initializer=tf.keras.initializers.Identity(self.ridge_penalty),
+            initializer=tf_keras.initializers.Identity(self.ridge_penalty),
             trainable=False,
             aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA))
     self.built = True
 
   def make_precision_matrix_update_op(self,
                                       gp_feature,
                                       logits,
@@ -413,15 +413,15 @@
     cov_feature_product = tf.matmul(
         feature_cov_matrix, gp_feature, transpose_b=True) * self.ridge_penalty
     gp_cov_matrix = tf.matmul(gp_feature, cov_feature_product)
     return gp_cov_matrix
 
   def _get_training_value(self, training=None):
     if training is None:
-      training = tf.keras.backend.learning_phase()
+      training = tf_keras.backend.learning_phase()
 
     if isinstance(training, int):
       training = bool(training)
 
     return training
 
   def call(self, inputs, logits=None, training=None):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/gaussian_process_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/gaussian_process_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Tests for Gaussian process functions."""
 import os
 import shutil
 
 from absl.testing import parameterized
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import gaussian_process
 
 
 def exact_gaussian_kernel(x1, x2):
   """Computes exact Gaussian kernel value(s) for tensors x1 and x2."""
   x1_squared = tf.reduce_sum(tf.square(x1), list(range(1, len(x1.shape))))
@@ -201,25 +201,25 @@
         precision_mat_before_test, precision_mat_after_test, atol=1e-4)
 
   def test_state_saving_and_loading(self):
     """Tests if the loaded model returns same results."""
     input_data = np.random.random((1, 2))
     rfgp_model = gaussian_process.RandomFeatureGaussianProcess(units=1)
 
-    inputs = tf.keras.Input((2,), batch_size=1)
+    inputs = tf_keras.Input((2,), batch_size=1)
     outputs = rfgp_model(inputs)
-    model = tf.keras.Model(inputs, outputs)
+    model = tf_keras.Model(inputs, outputs)
     gp_output, gp_covmat = model.predict(input_data)
 
     # Save and then load the model.
     temp_dir = self.get_temp_dir()
     self.addCleanup(shutil.rmtree, temp_dir)
     saved_model_dir = os.path.join(temp_dir, 'rfgp_model')
     model.save(saved_model_dir)
-    new_model = tf.keras.models.load_model(saved_model_dir)
+    new_model = tf_keras.models.load_model(saved_model_dir)
 
     gp_output_new, gp_covmat_new = new_model.predict(input_data)
     self.assertAllClose(gp_output, gp_output_new, atol=1e-4)
     self.assertAllClose(gp_covmat, gp_covmat_new, atol=1e-4)
 
 
 class MeanFieldLogitsTest(tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/kernel_attention.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/kernel_attention.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,22 +12,22 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based kernel attention layer."""
 
 import functools
 import math
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 _NUMERIC_STABLER = 1e-6
 
 
-class KernelMask(tf.keras.layers.Layer):
+class KernelMask(tf_keras.layers.Layer):
   """Creates kernel attention mask.
 
     inputs: from_tensor: 2D or 3D Tensor of shape
       [batch_size, from_seq_length, ...].
     mask: a Tensor of shape [batch_size, from_seq_length] which indicates
       which part of the inputs we should not attend.
 
@@ -248,30 +248,36 @@
 
     k_winsum = tf.squeeze(k_winsum, -3)
     denominator = tf.einsum("BTCHD,BTHD->BTCH", chunked_query_matrix, k_winsum)
     denominator = tf.expand_dims(denominator, -1) + _NUMERIC_STABLER
     attention = numerator / denominator
     attention = tf.reshape(attention, new_shape)
 
-    start = tf.zeros([len(old_shape)], dtype=old_shape.dtype)
+    start = tf.zeros([old_shape.shape[0]], dtype=old_shape.dtype)
     attention = tf.slice(attention, start, old_shape)
 
   # Queued window cache (drop instead of decay) not yet supported.
   else:  # Streaming
 
     if window_decay is None or window_decay > 1.0 or window_decay < 0.0:
       raise ValueError("window_decay should be in (0.0, 1.0) and not None.")
     kv = window_decay * cache["kv"] + tf.einsum(
         "BTHD,BTHO->BHOD", key_matrix, value_matrix)
     cache["kv"] = kv
     k_sum = window_decay * cache["k_sum"] + tf.reduce_sum(key_matrix, axis=1)
     cache["k_sum"] = k_sum
     denominator = tf.einsum("BTHD,BHD->BTH", query_matrix, k_sum)
-    attention = tf.einsum("BTHD,BHOD,BTH->BTHO", query_matrix, kv,
-                          1.0 / (denominator + _NUMERIC_STABLER))
+    # The below is equivalent to but converts to TF Lite better than:
+    #   tf.einsum("BTHD,BTH->BTHD",
+    #             query_matrix, 1.0 / (denominator + _NUMERIC_STABLER))
+    inverse_denominator = 1.0 / (denominator + _NUMERIC_STABLER)
+    # Add another dimension to align for the broadcast multiplication.
+    fused_query_denominator = query_matrix * tf.expand_dims(inverse_denominator,
+                                                            -1)
+    attention = tf.einsum("BTHD,BHOD->BTHO", fused_query_denominator, kv)
   return attention
 
 
 def create_projection_matrix(m, d, seed=None):
   r"""Constructs the matrix of random projections.
 
   Constructs a matrix of random orthogonal projections. Each projection vector
@@ -379,27 +385,27 @@
   projection_matrix = tf.cast(projection_matrix, data.dtype)
   if normalize_data:
     data_normalizer = 1.0 / tf.math.sqrt(
         (tf.math.sqrt(tf.dtypes.cast(data.shape[-1], data.dtype))))
   else:
     data_normalizer = 1.0
     lengths = tf.math.square(data)
-    lengths = tf.reduce_sum(lengths, axis=tf.keras.backend.ndim(data) - 1)
-    lengths = tf.expand_dims(lengths, axis=tf.keras.backend.ndim(data) - 1)
+    lengths = tf.reduce_sum(lengths, axis=tf_keras.backend.ndim(data) - 1)
+    lengths = tf.expand_dims(lengths, axis=tf_keras.backend.ndim(data) - 1)
     lengths = tf.math.sqrt(lengths)
     data /= lengths
   ratio = 1.0 / tf.math.sqrt(
       tf.dtypes.cast(projection_matrix.shape[0], data.dtype))
   data_dash = tf.einsum("blhd,md->blhm", data_normalizer * data,
                         projection_matrix)
   diag_data = tf.math.square(data)
   diag_data = tf.math.reduce_sum(
-      diag_data, axis=tf.keras.backend.ndim(data) - 1)
+      diag_data, axis=tf_keras.backend.ndim(data) - 1)
   diag_data = (diag_data / 2.0) * data_normalizer * data_normalizer
-  diag_data = tf.expand_dims(diag_data, axis=tf.keras.backend.ndim(data) - 1)
+  diag_data = tf.expand_dims(diag_data, axis=tf_keras.backend.ndim(data) - 1)
 
   # Calculating coefficients A, B of the FAVOR++ mechanism:
   _, l, _, _ = tf_utils.get_shape_list(data_orig)
 
   l = tf.cast(l, dtype=tf.float32)
   first_sum_of_squares = tf.math.square(data)
   first_sum_of_squares = tf.math.reduce_sum(
@@ -428,15 +434,15 @@
   a_coeff = tf.stop_gradient(a_coeff)
   b_coeff = tf.stop_gradient(b_coeff)
   d_coeff = tf.stop_gradient(d_coeff)
 
   # Calculating diag_omega for the FAVOR++ mechanism:
   diag_omega = tf.math.square(projection_matrix)
   diag_omega = tf.math.reduce_sum(
-      diag_omega, axis=tf.keras.backend.ndim(projection_matrix) - 1)
+      diag_omega, axis=tf_keras.backend.ndim(projection_matrix) - 1)
   diag_omega = tf.expand_dims(diag_omega, axis=0)
   diag_omega = tf.expand_dims(diag_omega, axis=0)
   diag_omega = tf.expand_dims(diag_omega, axis=0)
   diag_omega = a_coeff * diag_omega
 
   if numerical_renormalizer:
     if is_query:
@@ -460,22 +466,22 @@
 
 
 # pylint: disable=g-long-lambda
 _CAUSAL_SUPPORT_TRANSFORM_MAP = {
     "elu":
         functools.partial(
             _generalized_kernel,
-            f=lambda x: tf.keras.activations.elu(x) + 1,
+            f=lambda x: tf_keras.activations.elu(x) + 1,
             h=lambda x: 1),
     "relu":
         functools.partial(
             _generalized_kernel,
             # Improve numerical stability and avoid NaNs in some cases by adding
             # a tiny epsilon.
-            f=lambda x: tf.keras.activations.relu(x) + 1e-3,
+            f=lambda x: tf_keras.activations.relu(x) + 1e-3,
             h=lambda x: 1),
     "square":
         functools.partial(_generalized_kernel, f=tf.math.square, h=lambda x: 1),
     "exp":
         functools.partial(
             _generalized_kernel,
             # Avoid exp explosion by shifting.
@@ -505,15 +511,15 @@
     **_CAUSAL_SUPPORT_TRANSFORM_MAP,
     **_NON_CAUSAL_SUPPORT_TRANSFORM_MAP
 }
 
 # pylint: enable=g-long-lambda
 
 
-class KernelAttention(tf.keras.layers.MultiHeadAttention):
+class KernelAttention(tf_keras.layers.MultiHeadAttention):
   """A variant of efficient transformers which replaces softmax with kernels.
 
   This module combines ideas from the two following papers:
 
   Rethinking Attention with Performers
   (https://arxiv.org/abs/2009.14794)
   - exp (Lemma 1, positive), relu
@@ -732,15 +738,15 @@
           activity_regularizer=self._activity_regularizer,
           kernel_constraint=self._kernel_constraint,
           bias_constraint=self._bias_constraint)
       self._output_dense_softmax = self._make_output_dense(
           self._query_shape.rank - 1,
           common_kwargs,
           name="attention_output_softmax")
-      self._dropout_softmax = tf.keras.layers.Dropout(rate=self._dropout)
+      self._dropout_softmax = tf_keras.layers.Dropout(rate=self._dropout)
 
   def call(self, query, value, key=None, attention_mask=None, cache=None,
            training=False):
     """Compute attention with kernel mechanism.
 
     Args:
       query: Query `Tensor` of shape `[B, T, dim]`.
@@ -822,10 +828,16 @@
         "feature_transform": self._feature_transform,
         "num_random_features": self._num_random_features,
         "seed": self._seed,
         "redraw": self._redraw,
         "is_short_seq": self._is_short_seq,
         "begin_kernel": self._begin_kernel,
         "scale": self._scale,
+        "scale_by_length": self._scale_by_length,
+        "use_causal_windowed": self.use_causal_windowed,
+        "causal_chunk_length": self.causal_chunk_length,
+        "causal_window_length": self.causal_window_length,
+        "causal_window_decay": self.causal_window_decay,
+        "causal_padding": self.causal_padding,
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/kernel_attention_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/kernel_attention_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.projects.kernel.attention."""
 import itertools
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import kernel_attention as attention
 
 
 _FEATURE_TRANSFORM = ["relu", "elu", "exp", "expplus"]
 _REDRAW = [True, False]
 _TRAINING = [True, False]
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/masked_lm.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/masked_lm.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,19 +10,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Masked language model network."""
 # pylint: disable=g-classes-have-attributes
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class MaskedLM(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class MaskedLM(tf_keras.layers.Layer):
   """Masked language model network head for BERT modeling.
 
   This layer implements a masked language model based on the provided
   transformer based encoder. It assumes that the encoder network being passed
   has a "get_embedding_table()" method.
 
   Example:
@@ -46,30 +46,30 @@
                initializer='glorot_uniform',
                output='logits',
                name=None,
                **kwargs):
     super().__init__(name=name, **kwargs)
     self.embedding_table = embedding_table
     self.activation = activation
-    self.initializer = tf.keras.initializers.get(initializer)
+    self.initializer = tf_keras.initializers.get(initializer)
 
     if output not in ('predictions', 'logits'):
       raise ValueError(
           ('Unknown `output` value "%s". `output` can be either "logits" or '
            '"predictions"') % output)
     self._output_type = output
 
   def build(self, input_shape):
     self._vocab_size, hidden_size = self.embedding_table.shape
-    self.dense = tf.keras.layers.Dense(
+    self.dense = tf_keras.layers.Dense(
         hidden_size,
         activation=self.activation,
         kernel_initializer=self.initializer,
         name='transform/dense')
-    self.layer_norm = tf.keras.layers.LayerNormalization(
+    self.layer_norm = tf_keras.layers.LayerNormalization(
         axis=-1, epsilon=1e-12, name='transform/LayerNorm')
     self.bias = self.add_weight(
         'output_bias/bias',
         shape=(self._vocab_size,),
         initializer='zeros',
         trainable=True)
 
@@ -77,18 +77,24 @@
 
   def call(self, sequence_data, masked_positions):
     masked_lm_input = self._gather_indexes(sequence_data, masked_positions)
     lm_data = self.dense(masked_lm_input)
     lm_data = self.layer_norm(lm_data)
     lm_data = tf.matmul(lm_data, self.embedding_table, transpose_b=True)
     logits = tf.nn.bias_add(lm_data, self.bias)
-    masked_positions_length = masked_positions.shape.as_list()[1] or tf.shape(
-        masked_positions)[1]
-    logits = tf.reshape(logits,
-                        [-1, masked_positions_length, self._vocab_size])
+    masked_positions_length = (
+        masked_positions.shape.as_list()[1] or tf.shape(masked_positions)[1]
+    )
+    batch_size = (
+        masked_positions.shape.as_list()[0] or tf.shape(masked_positions)[0]
+    )
+    logits = tf.reshape(
+        logits,
+        [batch_size, masked_positions_length, self._vocab_size],
+    )
     if self._output_type == 'logits':
       return logits
     return tf.nn.log_softmax(logits)
 
   def get_config(self):
     raise NotImplementedError('MaskedLM cannot be directly serialized because '
                               'it has variable sharing logic.')
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/masked_lm_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/masked_lm_test.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,36 +1,31 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for masked language model network."""
-
+from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
-
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import masked_lm
 from official.nlp.modeling.networks import bert_encoder
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class MaskedLMTest(keras_parameterized.TestCase):
+class MaskedLMTest(tf.test.TestCase, parameterized.TestCase):
 
   def create_layer(self,
                    vocab_size,
                    hidden_size,
                    output='predictions',
                    xformer_stack=None):
     # First, create a transformer stack that we can use to get the LM's
@@ -53,16 +48,16 @@
     sequence_length = 32
     hidden_size = 64
     num_predictions = 21
     test_layer = self.create_layer(
         vocab_size=vocab_size, hidden_size=hidden_size)
 
     # Make sure that the output tensor of the masked LM is the right shape.
-    lm_input_tensor = tf.keras.Input(shape=(sequence_length, hidden_size))
-    masked_positions = tf.keras.Input(shape=(num_predictions,), dtype=tf.int32)
+    lm_input_tensor = tf_keras.Input(shape=(sequence_length, hidden_size))
+    masked_positions = tf_keras.Input(shape=(num_predictions,), dtype=tf.int32)
     output = test_layer(lm_input_tensor, masked_positions=masked_positions)
 
     expected_output_shape = [None, num_predictions, vocab_size]
     self.assertEqual(expected_output_shape, output.shape.as_list())
 
   def test_layer_invocation_with_external_logits(self):
     vocab_size = 100
@@ -83,22 +78,22 @@
     logit_layer = self.create_layer(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         xformer_stack=xformer_stack,
         output='logits')
 
     # Create a model from the masked LM layer.
-    lm_input_tensor = tf.keras.Input(shape=(sequence_length, hidden_size))
-    masked_positions = tf.keras.Input(shape=(num_predictions,), dtype=tf.int32)
+    lm_input_tensor = tf_keras.Input(shape=(sequence_length, hidden_size))
+    masked_positions = tf_keras.Input(shape=(num_predictions,), dtype=tf.int32)
     output = test_layer(lm_input_tensor, masked_positions)
     logit_output = logit_layer(lm_input_tensor, masked_positions)
-    logit_output = tf.keras.layers.Activation(tf.nn.log_softmax)(logit_output)
+    logit_output = tf_keras.layers.Activation(tf.nn.log_softmax)(logit_output)
     logit_layer.set_weights(test_layer.get_weights())
-    model = tf.keras.Model([lm_input_tensor, masked_positions], output)
-    logits_model = tf.keras.Model(([lm_input_tensor, masked_positions]),
+    model = tf_keras.Model([lm_input_tensor, masked_positions], output)
+    logits_model = tf_keras.Model(([lm_input_tensor, masked_positions]),
                                   logit_output)
 
     # Invoke the masked LM on some fake data to make sure there are no runtime
     # errors in the code.
     batch_size = 3
     lm_input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, hidden_size))
@@ -111,36 +106,47 @@
 
     # Ensure that the tensor shapes are correct.
     expected_output_shape = (batch_size, num_predictions, vocab_size)
     self.assertEqual(expected_output_shape, ref_outputs.shape)
     self.assertEqual(expected_output_shape, outputs.shape)
     self.assertAllClose(ref_outputs, outputs)
 
-  def test_layer_invocation(self):
+  @parameterized.named_parameters(
+      dict(
+          testcase_name='default',
+          num_predictions=21,
+      ),
+      dict(
+          testcase_name='zero_predictions',
+          num_predictions=0,
+      ),
+  )
+  def test_layer_invocation(self, num_predictions):
     vocab_size = 100
     sequence_length = 32
     hidden_size = 64
-    num_predictions = 21
     test_layer = self.create_layer(
         vocab_size=vocab_size, hidden_size=hidden_size)
 
     # Create a model from the masked LM layer.
-    lm_input_tensor = tf.keras.Input(shape=(sequence_length, hidden_size))
-    masked_positions = tf.keras.Input(shape=(num_predictions,), dtype=tf.int32)
+    lm_input_tensor = tf_keras.Input(shape=(sequence_length, hidden_size))
+    masked_positions = tf_keras.Input(shape=(num_predictions,), dtype=tf.int32)
     output = test_layer(lm_input_tensor, masked_positions)
-    model = tf.keras.Model([lm_input_tensor, masked_positions], output)
+    model = tf_keras.Model([lm_input_tensor, masked_positions], output)
 
     # Invoke the masked LM on some fake data to make sure there are no runtime
     # errors in the code.
     batch_size = 3
     lm_input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, hidden_size))
     masked_position_data = np.random.randint(
         2, size=(batch_size, num_predictions))
-    _ = model.predict([lm_input_data, masked_position_data])
+    res = model.predict([lm_input_data, masked_position_data])
+    expected_shape = (batch_size, num_predictions, vocab_size)
+    self.assertEqual(expected_shape, res.shape)
 
   def test_unknown_output_type_fails(self):
     with self.assertRaisesRegex(ValueError, 'Unknown `output` value "bad".*'):
       _ = self.create_layer(vocab_size=8, hidden_size=8, output='bad')
 
 
 if __name__ == '__main__':
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/masked_softmax.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/masked_softmax.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based softmax layer with optional masking."""
 # pylint: disable=g-classes-have-attributes
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _large_compatible_negative(tensor_type):
   """Large negative number as Tensor.
 
   This function is necessary because the standard value for epsilon
   in this module (-1e9) cannot be represented using `tf.float16`.
@@ -31,16 +31,16 @@
     A large negative number.
   """
   if tensor_type == tf.float16:
     return tf.float16.min
   return -1e9
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class MaskedSoftmax(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class MaskedSoftmax(tf_keras.layers.Layer):
   """Performs a softmax with optional masking on a tensor.
 
   Args:
     mask_expansion_axes: Any axes that should be padded on the mask tensor.
     normalization_axes: On which axes the softmax should perform.
   """
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/masked_softmax_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/masked_softmax_test.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,68 +11,64 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based masked softmax layer."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import masked_softmax
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class MaskedSoftmaxLayerTest(keras_parameterized.TestCase):
+class MaskedSoftmaxLayerTest(tf.test.TestCase):
 
   def test_non_masked_softmax(self):
     test_layer = masked_softmax.MaskedSoftmax()
-    input_tensor = tf.keras.Input(shape=(4, 8))
+    input_tensor = tf_keras.Input(shape=(4, 8))
     output = test_layer(input_tensor)
-    model = tf.keras.Model(input_tensor, output)
+    model = tf_keras.Model(input_tensor, output)
 
     input_data = 10 * np.random.random_sample((3, 4, 8))
     output_data = model.predict(input_data)
     expected_data = tf.nn.softmax(input_data)
     self.assertAllClose(expected_data, output_data)
 
   def test_masked_softmax(self):
     test_layer = masked_softmax.MaskedSoftmax()
-    input_tensor = tf.keras.Input(shape=(4, 8))
-    mask_tensor = tf.keras.Input(shape=(4, 8))
+    input_tensor = tf_keras.Input(shape=(4, 8))
+    mask_tensor = tf_keras.Input(shape=(4, 8))
     output = test_layer(input_tensor, mask_tensor)
-    model = tf.keras.Model([input_tensor, mask_tensor], output)
+    model = tf_keras.Model([input_tensor, mask_tensor], output)
 
     input_data = 10 * np.random.random_sample((3, 4, 8))
     mask_data = np.random.randint(2, size=(3, 4, 8))
 
     output_data = model.predict([input_data, mask_data])
     expected_zeros = np.greater(mask_data, 0)
     is_zeros = np.greater(output_data, 0)
     self.assertAllEqual(expected_zeros, is_zeros)
 
   def test_masked_softmax_with_none_mask(self):
     test_layer = masked_softmax.MaskedSoftmax()
-    input_tensor = tf.keras.Input(shape=(4, 8))
+    input_tensor = tf_keras.Input(shape=(4, 8))
     output = test_layer(input_tensor, None)
-    model = tf.keras.Model(input_tensor, output)
+    model = tf_keras.Model(input_tensor, output)
 
     input_data = 10 * np.random.random_sample((3, 4, 8))
     output_data = model.predict(input_data)
     expected_data = tf.nn.softmax(input_data)
     self.assertAllClose(expected_data, output_data)
 
   def test_softmax_with_axes_expansion(self):
     test_layer = masked_softmax.MaskedSoftmax(mask_expansion_axes=[1])
-    input_tensor = tf.keras.Input(shape=(4, 8))
-    mask_tensor = tf.keras.Input(shape=(8))
+    input_tensor = tf_keras.Input(shape=(4, 8))
+    mask_tensor = tf_keras.Input(shape=(8))
     output = test_layer(input_tensor, mask_tensor)
-    model = tf.keras.Model([input_tensor, mask_tensor], output)
+    model = tf_keras.Model([input_tensor, mask_tensor], output)
 
     input_data = 10 * np.random.random_sample((3, 4, 8))
     mask_data = np.random.randint(2, size=(3, 8))
 
     output_data = model.predict([input_data, mask_data])
     expanded_mask = np.expand_dims(mask_data, axis=1) * np.ones_like(input_data)
     expected_zeros = np.greater(expanded_mask, 0)
@@ -80,18 +76,18 @@
     self.assertAllEqual(expected_zeros, is_zeros)
 
   def test_masked_softmax_high_dims(self):
     test_layer = masked_softmax.MaskedSoftmax(
         mask_expansion_axes=[1], normalization_axes=[6, 7])
     input_shape = [2, 3, 4, 5, 6, 7, 8]
     mask_shape = [5, 6, 7, 8]
-    input_tensor = tf.keras.Input(shape=input_shape)
-    mask_tensor = tf.keras.Input(shape=mask_shape)
+    input_tensor = tf_keras.Input(shape=input_shape)
+    mask_tensor = tf_keras.Input(shape=mask_shape)
     output = test_layer(input_tensor, mask_tensor)
-    model = tf.keras.Model([input_tensor, mask_tensor], output)
+    model = tf_keras.Model([input_tensor, mask_tensor], output)
 
     input_data = 10 * np.random.random_sample([3] + input_shape)
     mask_data = np.random.randint(2, size=[3] + mask_shape)
 
     output_data = model.predict([input_data, mask_data])
     expanded_mask = np.expand_dims(mask_data, axis=1)
     expanded_mask = np.expand_dims(expanded_mask, axis=1)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mat_mul_with_margin.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mat_mul_with_margin.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,21 +13,21 @@
 # limitations under the License.
 
 """Dot product with margin layer."""
 # pylint: disable=g-classes-have-attributes
 
 from typing import Tuple
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class MatMulWithMargin(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class MatMulWithMargin(tf_keras.layers.Layer):
   """This layer computs a dot product matrix given two encoded inputs.
 
   Args:
     logit_scale: The scaling factor of dot products when doing training.
     logit_margin: The margin value between the positive and negative examples
       when doing training.
   """
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mat_mul_with_margin_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mat_mul_with_margin_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,29 +10,28 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for mat_mul_with_margin layer."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import mat_mul_with_margin
 
 
-class MatMulWithMarginTest(keras_parameterized.TestCase):
+class MatMulWithMarginTest(tf.test.TestCase):
 
   def test_layer_invocation(self):
     """Validate that the Keras object can be created and invoked."""
     input_width = 512
     test_layer = mat_mul_with_margin.MatMulWithMargin()
     # Create a 2-dimensional input (the first dimension is implicit).
-    left_encoded = tf.keras.Input(shape=(input_width,), dtype=tf.float32)
-    right_encoded = tf.keras.Input(shape=(input_width,), dtype=tf.float32)
+    left_encoded = tf_keras.Input(shape=(input_width,), dtype=tf.float32)
+    right_encoded = tf_keras.Input(shape=(input_width,), dtype=tf.float32)
     left_logits, right_logits = test_layer(left_encoded, right_encoded)
 
     # Validate that the outputs are of the expected shape.
     expected_output_shape = [None, None]
     self.assertEqual(expected_output_shape, left_logits.shape.as_list())
     self.assertEqual(expected_output_shape, right_logits.shape.as_list())
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mixing.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mixing.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -26,39 +26,41 @@
 can be supported in the future by utilizing the `value` inputs.
 """
 
 import enum
 import functools
 from typing import Callable, Tuple, Union
 
+import gin
 import numpy as np
 from scipy import linalg
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
-_Initializer = Union[str, tf.keras.initializers.Initializer]
+_Initializer = Union[str, tf_keras.initializers.Initializer]
 
-default_kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev=2e-2)
+default_kernel_initializer = tf_keras.initializers.TruncatedNormal(stddev=2e-2)
 
 
+@gin.constants_from_enum
 class MixingMechanism(enum.Enum):
   """Determines the type of mixing layer.
 
   Possible options:
     FOURIER: Fourier Transform mixing.
     LINEAR: Mixing using dense matrix multiplications with learnable weights.
     HARTLEY: Hartley Transform mixing.
   """
   FOURIER = "fourier"
   HARTLEY = "hartley"
   LINEAR = "linear"
 
 
-class MixingLayer(tf.keras.layers.Layer):
+class MixingLayer(tf_keras.layers.Layer):
   """Mixing layer base class.
 
   This class cannot be used directly. It just specifies the API for mixing
   layer subclasses. For interoperability with attention layers, we use the same
   `query` and `value` call signature.
 
   Based on the mixing layers use by FNet
@@ -275,9 +277,9 @@
                        matrix_dim_two: tf.Tensor) -> tf.Tensor:
       """Applies 2D matrix multiplication to input tensors of rank >= 2."""
       return tf.einsum("...ij,jk,ni->...nk", tf.cast(x, tf.complex64),
                        matrix_dim_two, matrix_dim_one)
 
     return functools.partial(
         two_dim_matmul,
-        matrix_dim_one=tf.convert_to_tensor(dft_mat_seq),
-        matrix_dim_two=tf.convert_to_tensor(dft_mat_hidden))
+        matrix_dim_one=dft_mat_seq,
+        matrix_dim_two=dft_mat_hidden)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mixing_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mixing_test.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for mixing.py."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import mixing
 
 
 class MixingTest(tf.test.TestCase):
 
   def test_base_mixing_layer(self):
@@ -60,15 +60,15 @@
   def test_linear_mixing_layer(self):
     batch_size = 2
     max_seq_length = 4
     hidden_dim = 3
 
     inputs = tf.ones((batch_size, max_seq_length, hidden_dim), dtype=tf.float32)
     outputs = mixing.LinearTransformLayer(
-        kernel_initializer=tf.keras.initializers.Ones())(
+        kernel_initializer=tf_keras.initializers.Ones())(
             query=inputs, value=inputs)
 
     # hidden_dim * (max_seq_length * 1) = 12.
     expected_outputs = [
         [
             [12., 12., 12.],
             [12., 12., 12.],
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mobile_bert_layers.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mobile_bert_layers.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """MobileBERT embedding and transformer layers."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 from official.nlp.modeling.layers import on_device_embedding
 from official.nlp.modeling.layers import position_embedding
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class NoNorm(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class NoNorm(tf_keras.layers.Layer):
   """Apply element-wise linear transformation to the last dimension."""
 
   def __init__(self, name=None):
     super().__init__(name=name)
 
   def build(self, shape):
     kernal_size = shape[-1]
@@ -52,39 +52,39 @@
 
   Returns:
     layer norm class.
   """
   if normalization_type == 'no_norm':
     layer = NoNorm(name=name)
   elif normalization_type == 'layer_norm':
-    layer = tf.keras.layers.LayerNormalization(
+    layer = tf_keras.layers.LayerNormalization(
         name=name,
         axis=-1,
         epsilon=1e-12,
         dtype=tf.float32)
   else:
     raise NotImplementedError('Only "no_norm" and "layer_norm" and supported.')
   return layer
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class MobileBertEmbedding(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class MobileBertEmbedding(tf_keras.layers.Layer):
   """Performs an embedding lookup for MobileBERT.
 
   This layer includes word embedding, token type embedding, position embedding.
   """
 
   def __init__(self,
                word_vocab_size,
                word_embed_size,
                type_vocab_size,
                output_embed_size,
                max_sequence_length=512,
                normalization_type='no_norm',
-               initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+               initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
                dropout_rate=0.1,
                **kwargs):
     """Class initialization.
 
     Args:
       word_vocab_size: Number of words in the vocabulary.
       word_embed_size: Word embedding size.
@@ -101,15 +101,15 @@
     super().__init__(**kwargs)
     self.word_vocab_size = word_vocab_size
     self.word_embed_size = word_embed_size
     self.type_vocab_size = type_vocab_size
     self.output_embed_size = output_embed_size
     self.max_sequence_length = max_sequence_length
     self.normalization_type = normalization_type
-    self.initializer = tf.keras.initializers.get(initializer)
+    self.initializer = tf_keras.initializers.get(initializer)
     self.dropout_rate = dropout_rate
 
     self.word_embedding = on_device_embedding.OnDeviceEmbedding(
         self.word_vocab_size,
         self.word_embed_size,
         initializer=tf_utils.clone_initializer(self.initializer),
         name='word_embedding')
@@ -118,34 +118,34 @@
         self.output_embed_size,
         initializer=tf_utils.clone_initializer(self.initializer),
         name='type_embedding')
     self.pos_embedding = position_embedding.PositionEmbedding(
         max_length=max_sequence_length,
         initializer=tf_utils.clone_initializer(self.initializer),
         name='position_embedding')
-    self.word_embedding_proj = tf.keras.layers.EinsumDense(
+    self.word_embedding_proj = tf_keras.layers.EinsumDense(
         'abc,cd->abd',
         output_shape=[None, self.output_embed_size],
         kernel_initializer=tf_utils.clone_initializer(self.initializer),
         bias_axes='d',
         name='embedding_projection')
     self.layer_norm = _get_norm_layer(normalization_type, 'embedding_norm')
-    self.dropout_layer = tf.keras.layers.Dropout(
+    self.dropout_layer = tf_keras.layers.Dropout(
         self.dropout_rate,
         name='embedding_dropout')
 
   def get_config(self):
     config = {
         'word_vocab_size': self.word_vocab_size,
         'word_embed_size': self.word_embed_size,
         'type_vocab_size': self.type_vocab_size,
         'output_embed_size': self.output_embed_size,
         'max_sequence_length': self.max_sequence_length,
         'normalization_type': self.normalization_type,
-        'initializer': tf.keras.initializers.serialize(self.initializer),
+        'initializer': tf_keras.initializers.serialize(self.initializer),
         'dropout_rate': self.dropout_rate
     }
     base_config = super(MobileBertEmbedding, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, input_ids, token_type_ids=None):
     word_embedding_out = self.word_embedding(input_ids)
@@ -163,16 +163,16 @@
       embedding_out += type_embedding_out
     embedding_out = self.layer_norm(embedding_out)
     embedding_out = self.dropout_layer(embedding_out)
 
     return embedding_out
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class MobileBertTransformer(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class MobileBertTransformer(tf_keras.layers.Layer):
   """Transformer block for MobileBERT.
 
   An implementation of one layer (block) of Transformer with bottleneck and
   inverted-bottleneck for MobilerBERT.
 
   Original paper for MobileBERT:
   https://arxiv.org/pdf/2004.02984.pdf
@@ -186,15 +186,15 @@
                hidden_dropout_prob=0.1,
                attention_probs_dropout_prob=0.1,
                intra_bottleneck_size=128,
                use_bottleneck_attention=False,
                key_query_shared_bottleneck=True,
                num_feedforward_networks=4,
                normalization_type='no_norm',
-               initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+               initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
                **kwargs):
     """Class initialization.
 
     Args:
       hidden_size: Hidden size for the Transformer input and output tensor.
       num_attention_heads: Number of attention heads in the Transformer.
       intermediate_size: The size of the "intermediate" (a.k.a., feed
@@ -230,49 +230,49 @@
     self.hidden_dropout_prob = hidden_dropout_prob
     self.attention_probs_dropout_prob = attention_probs_dropout_prob
     self.intra_bottleneck_size = intra_bottleneck_size
     self.use_bottleneck_attention = use_bottleneck_attention
     self.key_query_shared_bottleneck = key_query_shared_bottleneck
     self.num_feedforward_networks = num_feedforward_networks
     self.normalization_type = normalization_type
-    self.initializer = tf.keras.initializers.get(initializer)
+    self.initializer = tf_keras.initializers.get(initializer)
 
     if intra_bottleneck_size % num_attention_heads != 0:
       raise ValueError(
           (f'The bottleneck size {intra_bottleneck_size} is not a multiple '
            f'of the number of attention heads {num_attention_heads}.'))
     attention_head_size = int(intra_bottleneck_size / num_attention_heads)
 
     self.block_layers = {}
     # add input bottleneck
-    dense_layer_2d = tf.keras.layers.EinsumDense(
+    dense_layer_2d = tf_keras.layers.EinsumDense(
         'abc,cd->abd',
         output_shape=[None, self.intra_bottleneck_size],
         bias_axes='d',
         kernel_initializer=tf_utils.clone_initializer(self.initializer),
         name='bottleneck_input/dense')
     layer_norm = _get_norm_layer(self.normalization_type,
                                  name='bottleneck_input/norm')
     self.block_layers['bottleneck_input'] = [dense_layer_2d,
                                              layer_norm]
 
     if self.key_query_shared_bottleneck:
-      dense_layer_2d = tf.keras.layers.EinsumDense(
+      dense_layer_2d = tf_keras.layers.EinsumDense(
           'abc,cd->abd',
           output_shape=[None, self.intra_bottleneck_size],
           bias_axes='d',
           kernel_initializer=tf_utils.clone_initializer(self.initializer),
           name='kq_shared_bottleneck/dense')
       layer_norm = _get_norm_layer(self.normalization_type,
                                    name='kq_shared_bottleneck/norm')
       self.block_layers['kq_shared_bottleneck'] = [dense_layer_2d,
                                                    layer_norm]
 
     # add attention layer
-    attention_layer = tf.keras.layers.MultiHeadAttention(
+    attention_layer = tf_keras.layers.MultiHeadAttention(
         num_heads=self.num_attention_heads,
         key_dim=attention_head_size,
         value_dim=attention_head_size,
         dropout=self.attention_probs_dropout_prob,
         output_shape=self.intra_bottleneck_size,
         kernel_initializer=tf_utils.clone_initializer(self.initializer),
         name='attention')
@@ -282,44 +282,44 @@
                                       layer_norm]
 
     # add stacked feed-forward networks
     self.block_layers['ffn'] = []
     for ffn_layer_idx in range(self.num_feedforward_networks):
       layer_prefix = f'ffn_layer_{ffn_layer_idx}'
       layer_name = layer_prefix + '/intermediate_dense'
-      intermediate_layer = tf.keras.layers.EinsumDense(
+      intermediate_layer = tf_keras.layers.EinsumDense(
           'abc,cd->abd',
           activation=self.intermediate_act_fn,
           output_shape=[None, self.intermediate_size],
           bias_axes='d',
           kernel_initializer=tf_utils.clone_initializer(self.initializer),
           name=layer_name)
       layer_name = layer_prefix + '/output_dense'
-      output_layer = tf.keras.layers.EinsumDense(
+      output_layer = tf_keras.layers.EinsumDense(
           'abc,cd->abd',
           output_shape=[None, self.intra_bottleneck_size],
           bias_axes='d',
           kernel_initializer=tf_utils.clone_initializer(self.initializer),
           name=layer_name)
       layer_name = layer_prefix + '/norm'
       layer_norm = _get_norm_layer(self.normalization_type,
                                    name=layer_name)
       self.block_layers['ffn'].append([intermediate_layer,
                                        output_layer,
                                        layer_norm])
 
     # add output bottleneck
-    bottleneck = tf.keras.layers.EinsumDense(
+    bottleneck = tf_keras.layers.EinsumDense(
         'abc,cd->abd',
         output_shape=[None, self.hidden_size],
         activation=None,
         bias_axes='d',
         kernel_initializer=tf_utils.clone_initializer(self.initializer),
         name='bottleneck_output/dense')
-    dropout_layer = tf.keras.layers.Dropout(
+    dropout_layer = tf_keras.layers.Dropout(
         self.hidden_dropout_prob,
         name='bottleneck_output/dropout')
     layer_norm = _get_norm_layer(self.normalization_type,
                                  name='bottleneck_output/norm')
     self.block_layers['bottleneck_output'] = [bottleneck,
                                               dropout_layer,
                                               layer_norm]
@@ -333,15 +333,15 @@
         'hidden_dropout_prob': self.hidden_dropout_prob,
         'attention_probs_dropout_prob': self.attention_probs_dropout_prob,
         'intra_bottleneck_size': self.intra_bottleneck_size,
         'use_bottleneck_attention': self.use_bottleneck_attention,
         'key_query_shared_bottleneck': self.key_query_shared_bottleneck,
         'num_feedforward_networks': self.num_feedforward_networks,
         'normalization_type': self.normalization_type,
-        'initializer': tf.keras.initializers.serialize(self.initializer),
+        'initializer': tf_keras.initializers.serialize(self.initializer),
     }
     base_config = super(MobileBertTransformer, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self,
            input_tensor,
            attention_mask=None,
@@ -427,16 +427,16 @@
 
     if return_attention_scores:
       return layer_output, attention_scores
     else:
       return layer_output
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class MobileBertMaskedLM(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class MobileBertMaskedLM(tf_keras.layers.Layer):
   """Masked language model network head for BERT modeling.
 
   This layer implements a masked language model based on the provided
   transformer based encoder. It assumes that the encoder network being passed
   has a "get_embedding_table()" method. Different from canonical BERT's masked
   LM layer, when the embedding width is smaller than hidden_size, it adds an
   extra output weights in shape [vocab_size, (hidden_size - embedding_width)].
@@ -462,27 +462,27 @@
         weights, this may reduce the MLM task accuracy but will reduce the model
         params as well.
       **kwargs: keyword arguments.
     """
     super().__init__(**kwargs)
     self.embedding_table = embedding_table
     self.activation = activation
-    self.initializer = tf.keras.initializers.get(initializer)
+    self.initializer = tf_keras.initializers.get(initializer)
 
     if output not in ('predictions', 'logits'):
       raise ValueError(
           ('Unknown `output` value "%s". `output` can be either "logits" or '
            '"predictions"') % output)
     self._output_type = output
     self._output_weights_use_proj = output_weights_use_proj
 
   def build(self, input_shape):
     self._vocab_size, embedding_width = self.embedding_table.shape
     hidden_size = input_shape[-1]
-    self.dense = tf.keras.layers.Dense(
+    self.dense = tf_keras.layers.Dense(
         hidden_size,
         activation=self.activation,
         kernel_initializer=tf_utils.clone_initializer(self.initializer),
         name='transform/dense')
 
     if hidden_size > embedding_width:
       if self._output_weights_use_proj:
@@ -500,15 +500,15 @@
     elif hidden_size == embedding_width:
       self.extra_output_weights = None
     else:
       raise ValueError(
           'hidden size %d cannot be smaller than embedding width %d.' %
           (hidden_size, embedding_width))
 
-    self.layer_norm = tf.keras.layers.LayerNormalization(
+    self.layer_norm = tf_keras.layers.LayerNormalization(
         axis=-1, epsilon=1e-12, name='transform/LayerNorm')
     self.bias = self.add_weight(
         'output_bias/bias',
         shape=(self._vocab_size,),
         initializer='zeros',
         trainable=True)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/mobile_bert_layers_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/mobile_bert_layers_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from absl.testing import parameterized
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import mobile_bert_layers
 from official.nlp.modeling.networks import mobile_bert_encoder
 
 
 def generate_fake_input(batch_size=1, seq_len=5, vocab_size=10000, seed=0):
   """Generate consistent fake integer input sequences."""
@@ -56,15 +56,15 @@
     layer = mobile_bert_layers.MobileBertEmbedding(
         word_vocab_size=16,
         word_embed_size=32,
         type_vocab_size=4,
         output_embed_size=32,
         max_sequence_length=32,
         normalization_type='layer_norm',
-        initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),
+        initializer=tf_keras.initializers.TruncatedNormal(stddev=0.01),
         dropout_rate=0.5)
     layer_config = layer.get_config()
     new_layer = mobile_bert_layers.MobileBertEmbedding.from_config(layer_config)
     self.assertEqual(layer_config, new_layer.get_config())
 
   def test_no_norm(self):
     layer = mobile_bert_layers.NoNorm()
@@ -116,15 +116,15 @@
         hidden_dropout_prob=0.5,
         attention_probs_dropout_prob=0.4,
         intra_bottleneck_size=64,
         use_bottleneck_attention=True,
         key_query_shared_bottleneck=False,
         num_feedforward_networks=2,
         normalization_type='layer_norm',
-        initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01),
+        initializer=tf_keras.initializers.TruncatedNormal(stddev=0.01),
         name='block')
     layer_config = layer.get_config()
     new_layer = mobile_bert_layers.MobileBertTransformer.from_config(
         layer_config)
     self.assertEqual(layer_config, new_layer.get_config())
 
 
@@ -159,16 +159,16 @@
     num_predictions = 21
     test_layer = self.create_layer(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         embedding_width=embedding_width)
 
     # Make sure that the output tensor of the masked LM is the right shape.
-    lm_input_tensor = tf.keras.Input(shape=(sequence_length, hidden_size))
-    masked_positions = tf.keras.Input(shape=(num_predictions,), dtype=tf.int32)
+    lm_input_tensor = tf_keras.Input(shape=(sequence_length, hidden_size))
+    masked_positions = tf_keras.Input(shape=(num_predictions,), dtype=tf.int32)
     output = test_layer(lm_input_tensor, masked_positions=masked_positions)
 
     expected_output_shape = [None, num_predictions, vocab_size]
     self.assertEqual(expected_output_shape, output.shape.as_list())
 
   def test_layer_invocation_with_external_logits(self):
     vocab_size = 100
@@ -192,22 +192,22 @@
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         embedding_width=embedding_width,
         xformer_stack=xformer_stack,
         output='logits')
 
     # Create a model from the masked LM layer.
-    lm_input_tensor = tf.keras.Input(shape=(sequence_length, hidden_size))
-    masked_positions = tf.keras.Input(shape=(num_predictions,), dtype=tf.int32)
+    lm_input_tensor = tf_keras.Input(shape=(sequence_length, hidden_size))
+    masked_positions = tf_keras.Input(shape=(num_predictions,), dtype=tf.int32)
     output = test_layer(lm_input_tensor, masked_positions)
     logit_output = logit_layer(lm_input_tensor, masked_positions)
-    logit_output = tf.keras.layers.Activation(tf.nn.log_softmax)(logit_output)
+    logit_output = tf_keras.layers.Activation(tf.nn.log_softmax)(logit_output)
     logit_layer.set_weights(test_layer.get_weights())
-    model = tf.keras.Model([lm_input_tensor, masked_positions], output)
-    logits_model = tf.keras.Model(([lm_input_tensor, masked_positions]),
+    model = tf_keras.Model([lm_input_tensor, masked_positions], output)
+    logits_model = tf_keras.Model(([lm_input_tensor, masked_positions]),
                                   logit_output)
 
     # Invoke the masked LM on some fake data to make sure there are no runtime
     # errors in the code.
     batch_size = 3
     lm_input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, hidden_size))
@@ -232,18 +232,18 @@
     num_predictions = 21
     test_layer = self.create_layer(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         embedding_width=embedding_width)
 
     # Create a model from the masked LM layer.
-    lm_input_tensor = tf.keras.Input(shape=(sequence_length, hidden_size))
-    masked_positions = tf.keras.Input(shape=(num_predictions,), dtype=tf.int32)
+    lm_input_tensor = tf_keras.Input(shape=(sequence_length, hidden_size))
+    masked_positions = tf_keras.Input(shape=(num_predictions,), dtype=tf.int32)
     output = test_layer(lm_input_tensor, masked_positions)
-    model = tf.keras.Model([lm_input_tensor, masked_positions], output)
+    model = tf_keras.Model([lm_input_tensor, masked_positions], output)
 
     # Invoke the masked LM on some fake data to make sure there are no runtime
     # errors in the code.
     batch_size = 3
     lm_input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, hidden_size))
     masked_position_data = np.random.randint(
@@ -259,15 +259,15 @@
     hidden_size = 8
     sequence_length = 32
     num_predictions = 20
     with self.assertRaisesRegex(
         ValueError, 'hidden size 8 cannot be smaller than embedding width 16.'):
       test_layer = self.create_layer(
           vocab_size=8, hidden_size=8, embedding_width=16)
-      lm_input_tensor = tf.keras.Input(shape=(sequence_length, hidden_size))
-      masked_positions = tf.keras.Input(
+      lm_input_tensor = tf_keras.Input(shape=(sequence_length, hidden_size))
+      masked_positions = tf_keras.Input(
           shape=(num_predictions,), dtype=tf.int32)
       _ = test_layer(lm_input_tensor, masked_positions)
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/moe.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/moe.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,28 +11,26 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Mixture of Experts layers and their routing mechanisms."""
 
 import dataclasses
-from typing import Any, Callable, Optional, Tuple
+from typing import Callable, Optional, Tuple
 
-from absl import logging
-import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
-_InitializerType = tf.keras.initializers.Initializer
+_InitializerType = tf_keras.initializers.Initializer
 
 
-_DEFAULT_KERNEL_INITIALIZER = tf.keras.initializers.TruncatedNormal(stddev=2e-2)
-_DEFAULT_BIAS_INITIALIZER = tf.keras.initializers.Zeros()
+_DEFAULT_KERNEL_INITIALIZER = tf_keras.initializers.TruncatedNormal(stddev=2e-2)
+_DEFAULT_BIAS_INITIALIZER = tf_keras.initializers.Zeros()
 
 
 ################## Routers (gating functions) ##################
 
 
 def _router_z_loss(router_logits: tf.Tensor) -> float:
   """Computes router z-loss.
@@ -44,19 +42,21 @@
   Args:
     router_logits: <float32>[num_groups, tokens_per_group, num_experts] router
       logits.
 
   Returns:
     Scalar router z-loss <float32>.
   """
-  num_groups, tokens_per_group, _ = router_logits.shape
+  num_groups = tf.shape(router_logits)[0]
+  tokens_per_group = router_logits.shape[1]
 
   log_z = tf.math.reduce_logsumexp(router_logits, axis=-1)
   z_loss = log_z**2
-  return tf.math.reduce_sum(z_loss) / (num_groups * tokens_per_group)
+  return tf.math.reduce_sum(z_loss) / tf.cast(
+      num_groups * tokens_per_group, tf.float32)
 
 
 @dataclasses.dataclass
 class RouterMask:
   """Dispatch and combine arrays for expert routing with masked matmuls.
 
   Attributes:
@@ -71,15 +71,15 @@
   """
   dispatch_mask: tf.Tensor
   combine_array: tf.Tensor
 
 RouterOutput = RouterMask
 
 
-class Router(tf.keras.layers.Layer):
+class Router(tf_keras.layers.Layer):
   """Abstract base router class, defining router API and inner workings.
 
   Computations are performed in float32 for stability, and returned after
   conversion according to the precision policy. See the discussion of
   "selective precision" in https://arxiv.org/abs/2101.03961.
 
   Uses Keras add_loss() and add_metric() APIs.
@@ -96,73 +96,80 @@
       self,
       num_experts: int,
       *,
       jitter_noise: float = 0.0,
       use_bias: bool = True,
       kernel_initializer: _InitializerType = _DEFAULT_KERNEL_INITIALIZER,
       bias_initializer: _InitializerType = _DEFAULT_BIAS_INITIALIZER,
+      router_z_loss_weight: float = 0.0,
+      export_metrics: bool = True,
       name: str = "router",
-      dtype: Any = tf.float32,
       **kwargs):
     """Init.
 
     Args:
       num_experts: Number of experts.
       jitter_noise: Amplitude of jitter noise applied to router logits.
       use_bias: Whether or not to use the bias term in computing the router
         weights.
       kernel_initializer: Kernel initializer for router weights.
       bias_initializer: Bias initializer for router weights.
+      router_z_loss_weight: Weight for router_z_loss. Use non-zero values if
+        running into training instability (esp. with dtype 'bfloat16' or lower).
+      export_metrics: Whether to export metrics using Keras add_metric API.
       name: Layer name.
-      dtype: The dtype of the layer's computations and weights. tf.float32 is
-        recommended for stability.
       **kwargs: Forwarded to super.
     """
-    super().__init__(name=name, dtype=dtype, **kwargs)
+    super().__init__(name=name, **kwargs)
 
     self.num_experts = num_experts  # Used to check consistency with
                                     # FeedForwardExperts.
     self.jitter_noise = jitter_noise
+    self.router_z_loss_weight = router_z_loss_weight
+    self._export_metrics = export_metrics
 
-    self.router_weights = tf.keras.layers.Dense(
+    self.router_weights = tf_keras.layers.Dense(
         num_experts,
         use_bias=use_bias,
         kernel_initializer=tf_utils.clone_initializer(kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(bias_initializer),
         name="router_weights",
-        dtype=dtype)
+        dtype=tf.float32)
 
   def call(self,
            inputs: tf.Tensor,
            *,
            expert_capacity: int,
            training: Optional[bool] = None) -> RouterOutput:
     """Computes dispatch and combine arrays for routing to experts.
 
     Args:
       inputs: Inputs to send to experts of shape
         <float>[num_groups, tokens_per_group, hidden_dim].
       expert_capacity: Each group will send this many tokens to each expert.
       training: If true, apply jitter noise during routing. If not provided
-        taken from tf.keras.backend.
+        taken from tf_keras.backend.
 
     Returns:
       Router indices or mask arrays (depending on router type).
     """
     if training is None:
-      training = tf.keras.backend.learning_phase()
+      training = tf_keras.backend.learning_phase()
 
     # inputs shape <float>[num_groups, tokens_per_group, hidden_dim]
     router_probs, router_logits = self._compute_router_probabilities(
         inputs, apply_jitter=training)
     # router_probs <float32>[num_groups, tokens_per_group, num_experts]
     # router_logits <float>[num_groups, tokens_per_group, num_experts]
-    router_z_loss = _router_z_loss(router_logits)
+    unscaled_router_z_loss = _router_z_loss(router_logits)
+    router_z_loss = self.router_z_loss_weight * unscaled_router_z_loss
     self.add_loss(router_z_loss)
-    self.add_metric(router_z_loss, name="router_z_loss")
+    if self._export_metrics:
+      self.add_metric(unscaled_router_z_loss, name="unscaled_router_z_loss")
+      self.add_metric(router_z_loss, name="router_z_loss")
 
     routing_instructions = self._compute_routing_instructions(
         router_probs, expert_capacity)
     return routing_instructions
 
   def _compute_router_probabilities(
       self, inputs: tf.Tensor,
@@ -178,21 +185,21 @@
       - <float32>[num_groups, tokens_per_group, num_experts] probabilities for
         each token and expert. Used for routing tokens to experts.
       - <float32>[num_groups, tokens_per_group, num_experts] raw router logits.
         Used for computing router z-loss.
     """
     if apply_jitter and self.jitter_noise > 0:
       inputs *= tf.random.uniform(
-          inputs.shape,
+          tf.shape(inputs),
           minval=1.0 - self.jitter_noise,
           maxval=1.0 + self.jitter_noise,
           dtype=inputs.dtype)
     # inputs <float>, router_logits <float32>
     router_logits = self.router_weights(inputs)
-    router_probs = tf.keras.activations.softmax(router_logits, axis=-1)
+    router_probs = tf_keras.activations.softmax(router_logits, axis=-1)
     return router_probs, router_logits
 
   def _compute_routing_instructions(self, router_probs: tf.Tensor,
                                     expert_capacity: int) -> RouterOutput:
     """Computes instructions for routing inputs to experts."""
     raise NotImplementedError(
         "Router is an abstract class that should be subclassed.")
@@ -250,121 +257,121 @@
       router_probs: <float32>[num_groups, tokens_per_group, num_experts]
         probabilities used to determine the routing of tokens to the experts.
       expert_capacity: Each group will send this many tokens to each expert.
 
     Returns:
       Dispatch and combine arrays for routing with masked matmuls.
     """
-    num_groups, tokens_per_group, _ = router_probs.shape
+    num_groups = tf.shape(router_probs)[0]
+    tokens_per_group = router_probs.shape[1]
+
     router_probs_t = tf.transpose(router_probs, perm=[0, 2, 1])
     # router_probs_t: <float32>[num_groups, num_experts, tokens_per_group]
-
     # Top expert_capacity router probability and corresponding token indices for
     # each expert.
     # Shapes [num_groups, num_experts, expert_capacity]
-    expert_gate, expert_index = tf.math.top_k(
+    _, expert_index = tf.math.top_k(
         router_probs_t, k=expert_capacity, sorted=False)
 
     # Convert to one-hot mask of expert indices for each token in each group.
-    # Shape: [num_groups, num_experts, expert_capacity, tokens_per_group].
+    # Shape: [num_groups, tokens_per_group, num_experts, expert_capacity].
     dispatch_mask = tf.one_hot(
-        expert_index, tokens_per_group, dtype=router_probs.dtype)
-
-    # Move axes to conform with shape expected by MoeLayer API.
-    # Shape: [num_groups, tokens_per_group, num_experts, expert_capacity]
-    dispatch_mask = tf.transpose(dispatch_mask, perm=[0, 3, 1, 2])
+        expert_index, tokens_per_group, axis=1, dtype=router_probs.dtype)
 
     # The combine array will be used for combining expert outputs, scaled by the
     # router probabilities.
     # Shape: [num_groups, num_experts, tokens_per_group, expert_capacity]
-    combine_array = tf.einsum(
-        "...ec,...tec->...tec",
-        expert_gate,
-        dispatch_mask)
+    combine_array = tf.expand_dims(router_probs, axis=3) * dispatch_mask
 
     # Add load balancing loss.
     # Each expert is choosing tokens until it reaches full capacity, so we don't
     # need an auxiliary loading balancing loss for expert choice routing.
-    self.add_metric(0.0, name="load_balancing_loss")
+    if self._export_metrics:
+      self.add_metric(0.0, name="load_balancing_loss")
 
-    # Gather expert metrics.
-    # Number of tokens that were dispatched to at least one expert.
-    num_tokens = num_groups * tokens_per_group
-    num_tokens_dispatched_somewhere = tf.math.reduce_sum(tf.math.reduce_max(
-        dispatch_mask, axis=(-1, -2)))
-    fraction_tokens_left_behind = 1.0 - num_tokens_dispatched_somewhere / float(
-        num_tokens)
-    # Total number of tokens that were dispatched (one token could be
-    # dispatched to multiple experts).
-    num_tokens_dispatched = tf.math.reduce_sum(dispatch_mask)
-    # Of the tokens dispatched, how confident was the router in its routing?
-    router_confidence = tf.math.reduce_sum(
-        combine_array) / num_tokens_dispatched
-
-    expert_usage = 1.0  # Experts fully utilized when "expert choose tokens"
-
-    self.add_metric(fraction_tokens_left_behind,
-                    name="fraction_tokens_left_behind")
-    self.add_metric(router_confidence, name="router_confidence")
-    self.add_metric(expert_usage, name="expert_usage")
+      # Gather expert metrics.
+      # Number of tokens that were dispatched to at least one expert.
+      num_tokens = num_groups * tokens_per_group
+      num_tokens_dispatched_somewhere = tf.math.reduce_sum(tf.math.reduce_max(
+          dispatch_mask, axis=(-1, -2)))
+      fraction_tokens_left_behind = 1.0 - tf.cast(
+          num_tokens_dispatched_somewhere, tf.float32) / tf.cast(
+              num_tokens, tf.float32)
+
+      # Total number of tokens that were dispatched (one token could be
+      # dispatched to multiple experts).
+      num_tokens_dispatched = tf.math.reduce_sum(dispatch_mask)
+      # Of the tokens dispatched, how confident was the router in its routing?
+      router_confidence = tf.math.reduce_sum(
+          combine_array) / num_tokens_dispatched
+
+      expert_usage = 1.0  # Experts fully utilized when "expert choose tokens"
+
+      self.add_metric(fraction_tokens_left_behind,
+                      name="fraction_tokens_left_behind")
+      self.add_metric(router_confidence, name="router_confidence")
+      self.add_metric(expert_usage, name="expert_usage")
 
     # Return to default dtype now that router computation is complete.
-    dtype = tf.keras.mixed_precision.global_policy().compute_dtype
-    dispatch_mask = tf.cast(dispatch_mask, dtype)
-    combine_array = tf.cast(combine_array, dtype)
+    dispatch_mask = tf.cast(dispatch_mask, self.compute_dtype)
+    combine_array = tf.cast(combine_array, self.compute_dtype)
     output = RouterMask(dispatch_mask, combine_array)
     return output
 
 
 ################## Model layers ##################
 
 
-class FeedForward(tf.keras.layers.Layer):
+class FeedForward(tf_keras.layers.Layer):
   """Feed-forward layer - position independent, dense, nonlinear transformation.
 
   Typically used in an MLP Transformer block.
   """
 
   def __init__(
       self,
       d_ff: int,
       *,
-      dropout_rate: float = 0.1,
-      activation: Callable[[tf.Tensor],
-                           tf.Tensor] = tf.keras.activations.gelu,
+      inner_dropout: float = 0.0,
+      output_dropout: float = 0.0,
+      activation: Callable[[tf.Tensor], tf.Tensor] = tf_keras.activations.gelu,
       kernel_initializer: _InitializerType = _DEFAULT_KERNEL_INITIALIZER,
       bias_initializer: _InitializerType = _DEFAULT_BIAS_INITIALIZER,
       name: str = "feed_forward",
       **kwargs):
     """Initializes layer.
 
     Args:
       d_ff: Dimension of feed-forward layer.
-      dropout_rate: The dropout probability.
+      inner_dropout: The dropout probability to be applied after intermediate
+        activations.
+      output_dropout: The dropout probability to be applied after output layer.
       activation: (Nonlinear) transform applied in layer.
       kernel_initializer: Initialization scheme for kernel.
       bias_initializer: Initialization scheme for bias.
       name: Layer name.
       **kwargs: Forwarded to super.
     """
     super().__init__(name=name, **kwargs)
     self.activation = activation
     self.kernel_initializer = kernel_initializer
     self.bias_initializer = bias_initializer
 
-    self.intermediate_layer = tf.keras.layers.Dense(
+    self.intermediate_layer = tf_keras.layers.Dense(
         d_ff,
         kernel_initializer=tf_utils.clone_initializer(self.kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self.bias_initializer),
         name="intermediate")
-    self.dropout_layer = tf.keras.layers.Dropout(dropout_rate)
+    self.inner_dropout_layer = tf_keras.layers.Dropout(
+        inner_dropout)
+    self.output_dropout_layer = tf_keras.layers.Dropout(output_dropout)
 
   def build(self, input_shape: Tuple[int, int, int]):
     """Creates the input shape dependent output weight variables."""
-    self.output_layer = tf.keras.layers.Dense(
+    self.output_layer = tf_keras.layers.Dense(
         input_shape[-1],
         kernel_initializer=tf_utils.clone_initializer(self.kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self.bias_initializer),
         name="output")
 
   def call(self,
            inputs: tf.Tensor,
@@ -379,20 +386,21 @@
 
     Returns:
       Transformed inputs with the same shape as inputs
         <float>[batch_size, seq_len, hidden_dim].
     """
     x = self.intermediate_layer(inputs)
     x = self.activation(x)
+    x = self.inner_dropout_layer(x, training=training)
     x = self.output_layer(x)
-    x = self.dropout_layer(x, training=training)
+    x = self.output_dropout_layer(x, training=training)
     return x
 
 
-class FeedForwardExperts(tf.keras.layers.Layer):
+class FeedForwardExperts(tf_keras.layers.Layer):
   """Feed-forward layer with multiple experts.
 
   Note that call() takes inputs with shape
   [num_groups, num_experts, expert_capacity, hidden_dim]
   which is different from the usual [batch_size, seq_len, hidden_dim] used by
   the FeedForward layer.
 
@@ -402,57 +410,61 @@
   """
 
   def __init__(
       self,
       num_experts: int,
       d_ff: int,
       *,
-      dropout_rate: float = 0.1,
-      activation: Callable[[tf.Tensor],
-                           tf.Tensor] = tf.keras.activations.gelu,
+      inner_dropout: float = 0.0,
+      output_dropout: float = 0.0,
+      activation: Callable[[tf.Tensor], tf.Tensor] = tf_keras.activations.gelu,
       kernel_initializer: _InitializerType = _DEFAULT_KERNEL_INITIALIZER,
       bias_initializer: _InitializerType = _DEFAULT_BIAS_INITIALIZER,
       name: str = "experts",
       **kwargs):
     """Initializes layer.
 
     Args:
       num_experts: Number of experts (i.e. number of independent feed-forward
         blocks).
       d_ff: Dimension of feed-forward layer of each expert.
-      dropout_rate: The dropout probability (expert_dropout_rate).
+      inner_dropout: The dropout probability to be applied after intermediate
+        activations.
+      output_dropout: The dropout probability to be applied after output layer.
       activation: (Nonlinear) transform applied in layer.
       kernel_initializer: Initialization scheme for kernel.
       bias_initializer: Initialization scheme for bias.
       name: Layer name.
       **kwargs: Forwarded to super.
     """
     super().__init__(name=name, **kwargs)
     self.num_experts = num_experts
     self.activation = activation
     self.kernel_initializer = kernel_initializer
     self.bias_initializer = bias_initializer
 
-    self.intermediate_layer = tf.keras.layers.EinsumDense(
+    self.intermediate_layer = tf_keras.layers.EinsumDense(
         "gech,ehf->gecf",
         output_shape=(self.num_experts, None, d_ff),
         bias_axes="ef",
         kernel_initializer=tf_utils.clone_initializer(self.kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self.bias_initializer),
         name="intermediate")
-    self.dropout_layer = tf.keras.layers.Dropout(dropout_rate)
+    self.inner_dropout_layer = tf_keras.layers.Dropout(
+        inner_dropout)
+    self.output_dropout_layer = tf_keras.layers.Dropout(output_dropout)
 
   def build(self, input_shape: Tuple[int, int, int, int]):
     """Creates the input shape dependent output weight variables."""
     if input_shape[1] != self.num_experts:
       raise ValueError(
           f"Input shape {input_shape} is inconsistent with num_experts "
           f"{self.num_experts}.")
 
-    self.output_layer = tf.keras.layers.EinsumDense(
+    self.output_layer = tf_keras.layers.EinsumDense(
         "gecf,efh->gech",
         output_shape=(self.num_experts, None, input_shape[-1]),
         bias_axes="eh",
         kernel_initializer=tf_utils.clone_initializer(self.kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self.bias_initializer),
         name="output")
 
@@ -469,20 +481,21 @@
 
     Returns:
       Transformed inputs with the same shape as inputs
         <float>[num_groups, num_experts, expert_capacity, hidden_dim].
     """
     x = self.intermediate_layer(inputs)
     x = self.activation(x)
+    x = self.inner_dropout_layer(x, training=training)
     x = self.output_layer(x)
-    x = self.dropout_layer(x, training=training)
+    x = self.output_dropout_layer(x, training=training)
     return x
 
 
-class MoeLayer(tf.keras.layers.Layer):
+class MoeLayer(tf_keras.layers.Layer):
   """Sparse MoE layer with per-token routing.
 
   In this TF implementation, all experts need to fit onto a single device
   allowing for batch parallelism only.
 
   Uses Keras add_loss() and add_metric() APIs.
 
@@ -494,17 +507,15 @@
   def __init__(
       self,
       experts: FeedForwardExperts,
       router: MaskedRouter,
       *,
       train_capacity_factor: float = 1.0,
       eval_capacity_factor: float = 1.0,
-      min_expert_capacity: int = 4,
-      max_group_size: int = 4096,
-      strict_group_size: bool = False,
+      examples_per_group: float = 1.0,
       name: str = "moe",
       **kwargs):
     """Init.
 
     Args:
       experts: Instance of FeedForwardExperts. Needs to have the same
         num_experts as the router.
@@ -518,146 +529,90 @@
           affect how many experts a given token is routed to; see the
           num_selected_experts attributes of "tokens choose" routers.
         - For "experts choose" routing, because experts always fill their
           buffer, increasing the capacity factor will increase the number of
           tokens that an expert will process AND will indirectly increase the
           number of experts that a given token is routed to.
       eval_capacity_factor: As above, but used during evaluation.
-      min_expert_capacity: Minimum token processing capacity for each expert.
-      max_group_size: The total number of tokens on each device is subdivided
-        into groups of this size. Router computations are then performed on a
-        per-group basis. A larger group size will result in slower but more
-        accurate top-k and sorting computations, whereas a smaller group size
-        will result in faster but more approximate (and potentially less stable)
-        routing choices. Note that actual group size may be smaller than
-        max_group_size for consistency with the number of experts and tokens;
-        see also `strict_group_size` attribute. In practice,
-        we find that imperfect routing choices are tolerable and recommend
-        choosing a group size on the order of 4096 tokens, although this number
-        will vary based on model configuration and size.
-      strict_group_size: If True, fail if unable to set the token group size
-        equal to max_group_size. If False (default), the actual group size may
-        be smaller than max_group_size for consistency with the number of
-        experts and tokens.
+      examples_per_group: Number of examples to form a group. Router then
+        performs top_k token selection for each expert on a per group basis.
+        E.g. when `examples_per_group=4.0`, tokens are assigned to experts in
+        groups formed from 4 examples. When `examples_per_group=0.5`,
+        each example is split into 2 groups.
+        `examples_per_group` must divide the local batch size.
+        A larger group size will result in slower but more accurate top-k and
+        sorting computations, whereas a smaller group size will result in faster
+        but more approximate (and potentially less stable) routing choices.
+        In practice, we find that imperfect routing choices are tolerable and
+        recommend choosing a group size on the order of 4096 tokens, although
+        this number will vary based on model configuration and size.
       name: Layer name.
       **kwargs: Forwarded to super.
     """
     super().__init__(name=name, **kwargs)
     self._experts = experts
     self._router = router
 
     self.num_experts = experts.num_experts
     assert experts.num_experts == router.num_experts
 
     self._train_capacity_factor = train_capacity_factor
     self._eval_capacity_factor = eval_capacity_factor
-    self._max_group_size = max_group_size
-    self._min_expert_capacity = min_expert_capacity
-    self._strict_group_size = strict_group_size
+    self._examples_per_group = examples_per_group
 
   def call(self,
            inputs: tf.Tensor,
            *,
            training: Optional[bool] = None) -> tf.Tensor:
     """Applies MoeLayer.
 
     Args:
       inputs: Batch of input embeddings of shape
         <float>[batch_size, seq_length, hidden_dim].
       training: Only apply dropout and jitter noise during training. If not
-        provided taken from tf.keras.backend.
+        provided taken from tf_keras.backend.
 
     Returns:
       Transformed inputs with same shape as inputs:
         <float>[batch_size, seq_length, hidden_dim].
 
     Raises:
       ValueError if we cannot find a group_size satisfying given requirements.
     """
     if training is None:
-      training = tf.keras.backend.learning_phase()
+      training = tf_keras.backend.learning_phase()
 
     # inputs shape [batch_size, seq_length, hidden_dim]
-    per_device_batch_size, seq_length, hidden_dim = inputs.shape
-    num_tokens = per_device_batch_size * seq_length
-    num_groups = self._num_groups(num_tokens, self._max_group_size)
-    tokens_per_group = num_tokens // num_groups
+    batch_size, seq_length, hidden_dim = inputs.shape
+    if batch_size is not None:
+      if self._examples_per_group > batch_size:
+        raise ValueError(
+            f"examples_per_group={self._examples_per_group} is larger than the "
+            "number of examples available in the local (per-device) batch_size="
+            f"{batch_size}. Either decrease examples_per_group or increase the "
+            "batch_size.")
+    tokens_per_group = int(seq_length * self._examples_per_group)
 
     if training:
       capacity_factor = self._train_capacity_factor
     else:
       capacity_factor = self._eval_capacity_factor
     # Each group will send expert_capacity tokens to each expert.
     expert_capacity = int(
         round(capacity_factor * tokens_per_group / self.num_experts))
-    expert_capacity = max(expert_capacity, self._min_expert_capacity)
-    logging.info(
-        "Selected expert_capacity=%d for num_experts=%d and training=%r.",
-        expert_capacity, self.num_experts, training)
 
     # Reshape batch and sequence/token dimensions for expert routing.
-    x = tf.reshape(inputs, (num_groups, tokens_per_group, hidden_dim))
+    x = tf.reshape(inputs, (-1, tokens_per_group, hidden_dim))
 
     x = self._mask_and_dispatch_to_experts(x, expert_capacity, training)
 
     # Return to original input shape.
-    x = tf.reshape(x, (per_device_batch_size, seq_length, hidden_dim))
+    x = tf.reshape(x, (-1, seq_length, hidden_dim))
     return x
 
-  def _num_groups(self, num_tokens: int, max_group_size: int) -> int:
-    """Returns the number of token routing groups.
-
-    Note that the quantities are local to the device.
-
-    We select the smallest num_groups such that:
-    - num_groups >= num_tokens / max_group_size (ensuring the group size is no
-      larger than max_group_size),
-    - num_tokens % num_groups = 0 (ensuring that the group size evenly divides
-      into the num_tokens),
-
-    Args:
-      num_tokens: Number of tokens from input batch.
-      max_group_size: Maximum size of each token routing group. Actual group
-        size may end up being smaller unless strict_group_size==True.
-
-    Returns:
-      Number of token routing groups.
-
-    Raises:
-      ValueError if we cannot find a group_size satisfying the above
-        requirements.
-    """
-    # Increase the number of groups (and decrease the group size) until we have
-    # a viable number of groups.
-    min_num_groups = int(np.ceil(num_tokens / max_group_size))
-    num_groups = min_num_groups
-    while num_groups < num_tokens and num_tokens % num_groups != 0:
-      num_groups += 1
-
-    group_size = num_tokens // num_groups
-    logging.info(
-        "Selected group_size=%d and num_groups=%d for input num_tokens=%d, "
-        "max_group_size=%d, num_experts=%d.",
-        group_size, num_groups, num_tokens, max_group_size, self.num_experts)
-
-    if group_size < self._min_expert_capacity:
-      raise ValueError(
-          f"Local (per-device) group_size {group_size} is smaller than "
-          f"min_expert_capacity {self._min_expert_capacity}, which is probably "
-          "not intended. Please increase max_group_size {max_group_size} to"
-          " seq_length or increase batch_size or decrease min_expert_capacity.")
-
-    if self._strict_group_size and group_size != self._max_group_size:
-      raise ValueError(
-          f"Selected group_size={group_size} is less than the "
-          f"max_group_size={max_group_size}. Exiting because strict mode is "
-          "active (strict_group_size=True)")
-
-    return num_groups
-
   def _mask_and_dispatch_to_experts(self, inputs: tf.Tensor,
                                     expert_capacity: int,
                                     training: bool) -> tf.Tensor:
     """Wraps expert masked routing and dispatching algorithm.
 
     This algorithm takes the following steps:
     (1) Compute dispatch mask and combine array using self._router.
@@ -679,66 +634,71 @@
     router_mask = self._router(
         inputs,
         expert_capacity=expert_capacity,
         training=training)
 
     # Shape [num_groups, num_experts, expert_capacity, hidden_dim]
     expert_inputs = tf.einsum(
-        "gth,gtec->gech",
-        inputs,
-        router_mask.dispatch_mask)
+        "gtec,gth->gech",
+        router_mask.dispatch_mask,
+        inputs)
 
     expert_outputs = self._experts(expert_inputs, training=training)
 
     # Shape [num_groups, tokens_per_group, hidden_dim]
     combined_outputs = tf.einsum(
-        "gech,gtec->gth",
-        expert_outputs,
-        router_mask.combine_array)
+        "gtec,gech->gth",
+        router_mask.combine_array,
+        expert_outputs)
 
     return combined_outputs
 
 
-class MoeLayerWithBackbone(tf.keras.layers.Layer):
+class MoeLayerWithBackbone(tf_keras.layers.Layer):
   """Sparse MoE layer plus a FeedForward layer evaluated for all tokens.
 
   Uses Keras add_loss() and add_metric() APIs.
   """
 
   def __init__(
       self,
       moe: MoeLayer,
       backbone_d_ff: int,
       *,
-      dropout_rate: float = 0.1,
+      inner_dropout: float = 0.0,
+      output_dropout: float = 0.0,
       activation: Callable[[tf.Tensor],
-                           tf.Tensor] = tf.keras.activations.gelu,
+                           tf.Tensor] = tf_keras.activations.gelu,
       kernel_initializer: _InitializerType = _DEFAULT_KERNEL_INITIALIZER,
       bias_initializer: _InitializerType = _DEFAULT_BIAS_INITIALIZER,
       name: str = "moe_with_backbone",
       **kwargs):
     """Init.
 
     Args:
       moe: Instance of MoeLayer with experts and router.
       backbone_d_ff: Dimension of feed-forward layer of a lightweight backbone,
         which is evaluated for all tokens.
-      dropout_rate: Dropout rate for the backbone.
+      inner_dropout: The dropout probability to be applied after intermediate
+        activations for the backbone.
+      output_dropout: The dropout probability to be applied after the output
+        of the backbone.
       activation: (Nonlinear) transform applied in the backbone.
       kernel_initializer: Initialization scheme for kernels in the backbone.
       bias_initializer: Initialization scheme for biases in the backbone.
       name: Layer name.
       **kwargs: Forwarded to super.
     """
     super().__init__(name=name, **kwargs)
     self._moe = moe
 
     self._backbone = FeedForward(
         backbone_d_ff,
-        dropout_rate=dropout_rate,
+        inner_dropout=inner_dropout,
+        output_dropout=output_dropout,
         activation=activation,
         kernel_initializer=tf_utils.clone_initializer(kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(bias_initializer),
         name="backbone")
 
   def call(self,
            inputs: tf.Tensor,
@@ -746,15 +706,15 @@
            training: Optional[bool] = None) -> tf.Tensor:
     """Applies MoeLayerWithBackbone layer.
 
     Args:
       inputs: Batch of input embeddings of shape
         <float>[batch_size, seq_length, hidden_dim].
       training: Only apply dropout and jitter noise during training. If not
-        provided taken from tf.keras.backend.
+        provided taken from tf_keras.backend.
 
     Returns:
       Transformed inputs with same shape as inputs:
         <float>[batch_size, seq_length, hidden_dim].
     """
     return self._backbone(
         inputs, training=training) + self._moe(
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/moe_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/moe_test.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,80 +10,72 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for moe.py."""
 
-import ml_collections
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import moe
 
 
-def small_config() -> ml_collections.ConfigDict:
+def small_config():
   """Creates a small model config that can be used by all tests."""
-  config = ml_collections.ConfigDict()
+  config = {}
+  config['d_ff'] = 32
+  config['output_dropout'] = 0.1
+
+  config['num_experts'] = 2
+  config['expert_d_ff'] = 33
+  config['expert_dropout_rate'] = 0.1
+  config['jitter_noise'] = 0.1
+  config['train_capacity_factor'] = 1.0
+  config['eval_capacity_factor'] = 1.0
+  config['examples_per_group'] = 2.0
 
-  config.d_ff = 32
-  config.dropout_rate = 0.1
-
-  config.num_experts = 2
-  config.expert_d_ff = 33
-  config.expert_dropout_rate = 0.1
-  config.jitter_noise = 0.1
-  config.train_capacity_factor = 1.0
-  config.eval_capacity_factor = 1.0
-  config.min_expert_capacity = 1
-  config.max_group_size = 9
-
-  config.backbone_d_ff = 13
+  config['backbone_d_ff'] = 13
   return config
 
 
-def make_input_ones(batch_size: int = 2,
+def make_input_ones(batch_size: int = 4,
                     seq_length: int = 10,
                     hidden_dim: int = 7) -> tf.Tensor:
-  return tf.ones((batch_size, seq_length, hidden_dim), dtype=tf.float32)
+  return tf.ones((batch_size, seq_length, hidden_dim))
 
 
 def make_experts_input_ones(num_groups: int = 1,
                             num_experts: int = 2,
                             expert_capacity: int = 5,
                             hidden_dim: int = 7) -> tf.Tensor:
-  return tf.ones((num_groups, num_experts, expert_capacity, hidden_dim),
-                 dtype=tf.float32)
+  return tf.ones((num_groups, num_experts, expert_capacity, hidden_dim))
 
 
 class MoeTest(tf.test.TestCase):
 
   def tearDown(self):
     super().tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   def test_router_z_loss_dtype(self):
     x = tf.constant([[[10.0, 5.0]]], dtype=tf.float32)
     y = moe._router_z_loss(x)
     expected = (5 + np.log(np.exp(5) + 1))**2
     self.assertAllClose(expected, y, atol=1e-7)
-
-    x = tf.constant([[[10.0, 5.0]]], dtype=tf.bfloat16)
-    y = moe._router_z_loss(x)
-    expected = 100.0
-    self.assertAllClose(expected, y, atol=1e-7)
+    self.assertDTypeEqual(y, tf.float32)
 
   def test_router_z_loss_shape(self):
     x = make_input_ones(2, 5, 7)
     y = moe._router_z_loss(x)
     expected = (np.log(7) + 1)**2
     self.assertAllClose(expected, y, atol=1e-7)
 
   def test_experts_choose_masked_router_dtype_shape(self):
-    tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')
+    tf_keras.mixed_precision.set_global_policy('mixed_bfloat16')
     num_groups = 2
     tokens_per_group = 3
     hidden_dim = tokens_per_group
     num_experts = tokens_per_group
     expert_capacity = 2
     x = np.zeros([num_groups, tokens_per_group, hidden_dim])
     x[0, 0, 0] += 1
@@ -91,16 +83,16 @@
     x[1, 1:, 1:] += 1
     x[1, -1, -1] += 1
 
     router = moe.ExpertsChooseMaskedRouter(
         num_experts=num_experts,
         jitter_noise=0.1,
         use_bias=True,
-        kernel_initializer=tf.keras.initializers.get('identity'),
-        bias_initializer=tf.keras.initializers.get('ones'))
+        kernel_initializer=tf_keras.initializers.get('identity'),
+        bias_initializer=tf_keras.initializers.get('ones'))
     router_mask = router(x, expert_capacity=expert_capacity, training=False)
 
     self.assertDTypeEqual(router_mask.dispatch_mask, tf.bfloat16)
     self.assertDTypeEqual(router_mask.combine_array, tf.bfloat16)
 
     expect_shape = [num_groups, tokens_per_group, num_experts, expert_capacity]
     self.assertEqual(expect_shape, router_mask.dispatch_mask.shape)
@@ -120,135 +112,126 @@
     self.assertSetEqual({0, 1}, set(out_dm_indices[1, 0, :].astype(np.int32)))
     self.assertSetEqual({0, 1}, set(out_dm_indices[1, 1, :].astype(np.int32)))
     self.assertSetEqual({1, 2}, set(out_dm_indices[1, 2, :].astype(np.int32)))
 
     out_ca = router_mask.combine_array.numpy()
     out_ca = np.dot(out_ca, np.ones((expert_capacity,)))
 
-    expected_combine_array = np.array(
-        [[[0.66, 0.0, 0.0], [0.42, 0.42, 0.16], [0.0, 0.33, 0.33]],
-         [[0.33, 0.33, 0.0], [0.16, 0.42, 0.42], [0.0, 0.0, 0.66]]])
+    expected_combine_array = np.array([[[0.66, 0.0, 0.0], [0.42, 0.42, 0.16],
+                                        [0.0, 0.33, 0.33]],
+                                       [[0.33, 0.33, 0.0], [0.16, 0.42, 0.42],
+                                        [0.0, 0.0, 0.66]]])
     self.assertAllClose(expected_combine_array, out_ca, atol=1e-2)
 
   def test_feed_forward_shape_and_vars(self):
     config = small_config()
-    layer = moe.FeedForward(d_ff=config.d_ff, dropout_rate=config.dropout_rate)
+    layer = moe.FeedForward(
+        d_ff=config['d_ff'], output_dropout=config['output_dropout'])
     inputs = make_input_ones()
     outputs = layer(inputs)
     self.assertAllEqual(tf.shape(inputs), tf.shape(outputs))
     var_names = sorted([v.name for v in layer.trainable_variables])
-    self.assertAllEqual(['feed_forward/intermediate/bias:0',
-                         'feed_forward/intermediate/kernel:0',
-                         'feed_forward/output/bias:0',
-                         'feed_forward/output/kernel:0'], var_names)
+    self.assertAllEqual([
+        'feed_forward/intermediate/bias:0',
+        'feed_forward/intermediate/kernel:0', 'feed_forward/output/bias:0',
+        'feed_forward/output/kernel:0'
+    ], var_names)
 
   def test_feed_forward_manual(self):
     config = small_config()
     layer = moe.FeedForward(
-        d_ff=config.d_ff,
-        dropout_rate=config.dropout_rate,
-        activation=tf.keras.activations.relu,
-        kernel_initializer=tf.keras.initializers.get('ones'),
-        bias_initializer=tf.keras.initializers.get('ones'))
+        d_ff=config['d_ff'],
+        output_dropout=config['output_dropout'],
+        activation=tf_keras.activations.relu,
+        kernel_initializer=tf_keras.initializers.get('ones'),
+        bias_initializer=tf_keras.initializers.get('ones'))
     inputs = make_input_ones(1, 2, 3)
     outputs = layer(inputs, training=False)
-    manual_outputs = tf.constant([[[129.0, 129.0, 129.0],
-                                   [129.0, 129.0, 129.0]]])
+    manual_outputs = tf.constant([[[129.0, 129.0, 129.0], [129.0, 129.0,
+                                                           129.0]]])
     self.assertAllClose(manual_outputs, outputs, atol=1e-7)
 
   def test_feed_forward_experts_shape_and_vars(self):
     config = small_config()
     layer = moe.FeedForwardExperts(
-        num_experts=config.num_experts,
-        d_ff=config.expert_d_ff,
-        dropout_rate=config.expert_dropout_rate)
+        num_experts=config['num_experts'],
+        d_ff=config['expert_d_ff'],
+        output_dropout=config['expert_dropout_rate'])
     inputs = make_experts_input_ones()
     outputs = layer(inputs)
     self.assertAllEqual(tf.shape(inputs), tf.shape(outputs))
     var_names = sorted([v.name for v in layer.trainable_variables])
-    self.assertAllEqual(['experts/intermediate/bias:0',
-                         'experts/intermediate/kernel:0',
-                         'experts/output/bias:0',
-                         'experts/output/kernel:0'], var_names)
+    self.assertAllEqual([
+        'experts/intermediate/bias:0', 'experts/intermediate/kernel:0',
+        'experts/output/bias:0', 'experts/output/kernel:0'
+    ], var_names)
 
   def test_feed_forward_experts_manual(self):
     config = small_config()
     layer = moe.FeedForwardExperts(
         num_experts=1,
-        d_ff=config.expert_d_ff,
-        dropout_rate=config.expert_dropout_rate,
-        activation=tf.keras.activations.relu,
-        kernel_initializer=tf.keras.initializers.get('ones'),
-        bias_initializer=tf.keras.initializers.get('ones'))
+        d_ff=config['expert_d_ff'],
+        output_dropout=config['expert_dropout_rate'],
+        activation=tf_keras.activations.relu,
+        kernel_initializer=tf_keras.initializers.get('ones'),
+        bias_initializer=tf_keras.initializers.get('ones'))
     inputs = make_experts_input_ones(1, 1, 2, 3)
     outputs = layer(inputs, training=False)
     manual_outputs = tf.constant([[[[133.0, 133.0, 133.0],
                                     [133.0, 133.0, 133.0]]]])
     self.assertAllClose(manual_outputs, outputs, atol=1e-7)
 
   def test_moe_layer(self):
     config = small_config()
     experts = moe.FeedForwardExperts(
-        num_experts=config.num_experts,
-        d_ff=config.expert_d_ff,
-        dropout_rate=config.expert_dropout_rate)
+        num_experts=config['num_experts'],
+        d_ff=config['expert_d_ff'],
+        output_dropout=config['expert_dropout_rate'])
     router = moe.ExpertsChooseMaskedRouter(
-        config.num_experts,
-        jitter_noise=config.jitter_noise)
+        config['num_experts'], jitter_noise=config['jitter_noise'])
     moe_layer = moe.MoeLayer(
         experts,
         router,
-        train_capacity_factor=config.train_capacity_factor,
-        eval_capacity_factor=config.eval_capacity_factor,
-        max_group_size=config.max_group_size,
-        min_expert_capacity=config.min_expert_capacity)
+        train_capacity_factor=config['train_capacity_factor'],
+        eval_capacity_factor=config['eval_capacity_factor'],
+        examples_per_group=config['examples_per_group'])
 
     inputs = make_input_ones()
-    with self.assertLogs('absl', level='INFO') as cm:
-      outputs = moe_layer(inputs, training=True)
+    outputs = moe_layer(inputs, training=True)
     self.assertAllEqual(tf.shape(inputs), tf.shape(outputs))
 
-    self.assertEqual(cm.output, [
-        ('INFO:absl:Selected group_size=5 and num_groups=4 for input '
-         'num_tokens=20, max_group_size=9, num_experts=2.'),
-        ('INFO:absl:Selected expert_capacity=2 for num_experts=2 and '
-         'training=True.')])
-
     var_names = sorted([v.name for v in moe_layer.trainable_variables])
-    self.assertAllEqual(['moe/experts/intermediate/bias:0',
-                         'moe/experts/intermediate/kernel:0',
-                         'moe/experts/output/bias:0',
-                         'moe/experts/output/kernel:0',
-                         'moe/router/router_weights/bias:0',
-                         'moe/router/router_weights/kernel:0'], var_names)
+    self.assertAllEqual([
+        'moe/experts/intermediate/bias:0', 'moe/experts/intermediate/kernel:0',
+        'moe/experts/output/bias:0', 'moe/experts/output/kernel:0',
+        'moe/router/router_weights/bias:0', 'moe/router/router_weights/kernel:0'
+    ], var_names)
     self.assertLen(moe_layer.losses, 1)
     metrics = [metric.name for metric in moe_layer.metrics]
     self.assertSetEqual(
         {
-            'router_z_loss', 'load_balancing_loss',
+            'router_z_loss', 'unscaled_router_z_loss', 'load_balancing_loss',
             'fraction_tokens_left_behind', 'router_confidence', 'expert_usage'
         }, set(metrics))
 
   def test_moe_layer_with_backbone(self):
     config = small_config()
     experts = moe.FeedForwardExperts(
-        num_experts=config.num_experts,
-        d_ff=config.expert_d_ff,
-        dropout_rate=config.expert_dropout_rate)
+        num_experts=config['num_experts'],
+        d_ff=config['expert_d_ff'],
+        output_dropout=config['expert_dropout_rate'])
     router = moe.ExpertsChooseMaskedRouter(
-        config.num_experts,
-        jitter_noise=config.jitter_noise)
+        config['num_experts'], jitter_noise=config['jitter_noise'])
     moe_layer = moe.MoeLayer(
         experts,
         router,
-        train_capacity_factor=config.train_capacity_factor,
-        eval_capacity_factor=config.eval_capacity_factor,
-        max_group_size=config.max_group_size,
-        min_expert_capacity=config.min_expert_capacity)
-    layer = moe.MoeLayerWithBackbone(moe_layer, config.backbone_d_ff)
+        train_capacity_factor=config['train_capacity_factor'],
+        eval_capacity_factor=config['eval_capacity_factor'],
+        examples_per_group=config['examples_per_group'])
+    layer = moe.MoeLayerWithBackbone(moe_layer, config['backbone_d_ff'])
 
     inputs = make_input_ones()
     outputs = layer(inputs)
     self.assertAllEqual(tf.shape(inputs), tf.shape(outputs))
 
 
 if __name__ == '__main__':
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/multi_channel_attention.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/multi_channel_attention.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,21 +13,21 @@
 # limitations under the License.
 
 """Multi-channel Attention."""
 # pylint: disable=g-classes-have-attributes
 
 import math
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import masked_softmax
 
 
-class VotingAttention(tf.keras.layers.Layer):
+class VotingAttention(tf_keras.layers.Layer):
   """Voting Attention layer.
 
   Args:
     num_heads: The number of attention heads.
     head_size: Per-head hidden size.
     kernel_initializer: Initializer for dense layer kernels.
     bias_initializer: Initializer for dense layer biases.
@@ -48,37 +48,37 @@
                activity_regularizer=None,
                kernel_constraint=None,
                bias_constraint=None,
                **kwargs):
     super().__init__(**kwargs)
     self._num_heads = num_heads
     self._head_size = head_size
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
 
   def build(self, unused_input_shapes):
     common_kwargs = dict(
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer,
         activity_regularizer=self._activity_regularizer,
         kernel_constraint=self._kernel_constraint,
         bias_constraint=self._bias_constraint)
-    self._query_dense = tf.keras.layers.EinsumDense(
+    self._query_dense = tf_keras.layers.EinsumDense(
         "BAE,ENH->BANH",
         output_shape=(None, self._num_heads, self._head_size),
         bias_axes="NH",
         name="query",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
-    self._key_dense = tf.keras.layers.EinsumDense(
+    self._key_dense = tf_keras.layers.EinsumDense(
         "BAE,ENH->BANH",
         output_shape=(None, self._num_heads, self._head_size),
         bias_axes="NH",
         name="key",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
@@ -99,15 +99,15 @@
     attention_matrix = tf.einsum("BNXY,XY->BNXY", attention_matrix, mask)
     doc_attention_probs = tf.einsum("BNAY->BNA", attention_matrix)
     doc_attention_probs = tf.einsum("BNA->BA", doc_attention_probs)
     infadder = (1.0 - doc_attention_mask) * -100000.0
     return tf.nn.softmax(doc_attention_probs + infadder)
 
 
-class MultiChannelAttention(tf.keras.layers.MultiHeadAttention):
+class MultiChannelAttention(tf_keras.layers.MultiHeadAttention):
   """Multi-channel Attention layer.
 
   Introduced in, [Generating Representative Headlines for News Stories
   ](https://arxiv.org/abs/2001.09386). Expects multiple cross-attention
   target sequences.
 
   Call args:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/multi_channel_attention_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/multi_channel_attention_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for projects.nhnet.multi_channel_attention."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import multi_channel_attention
 
 
 class MultiChannelAttentionTest(tf.test.TestCase):
 
   def test_doc_attention(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/on_device_embedding.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/on_device_embedding.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,19 +11,19 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based one-hot embedding layer."""
 # pylint: disable=g-classes-have-attributes
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class OnDeviceEmbedding(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class OnDeviceEmbedding(tf_keras.layers.Layer):
   """Performs an embedding lookup suitable for accelerator devices.
 
   This layer uses either tf.gather or tf.one_hot to translate integer indices to
   float embeddings.
 
   Args:
     vocab_size: Number of elements in the vocabulary.
@@ -33,68 +33,84 @@
     use_one_hot: Whether to use tf.one_hot over tf.gather for the embedding
       lookup. Defaults to False (that is, using tf.gather). Setting this option
       to True may improve performance, especially on small vocabulary sizes, but
       will generally require more memory.
     scale_factor: Whether to scale the output embeddings. Defaults to None (that
       is, not to scale). Setting this option to a float will let values in
       output embeddings multiplied by scale_factor.
+    weight_fallback_dtype: When keras mix precision inferred wrong dtype for
+      variables, `weight_fallback_dtype` will be used to define the dtype of
+      weights.
   """
 
   def __init__(self,
                vocab_size,
                embedding_width,
                initializer="glorot_uniform",
                use_one_hot=False,
                scale_factor=None,
+               weight_fallback_dtype=tf.float32,
                **kwargs):
 
     super().__init__(**kwargs)
     self._vocab_size = vocab_size
     self._embedding_width = embedding_width
     self._initializer = initializer
     self._use_one_hot = use_one_hot
     self._scale_factor = scale_factor
+    # Backup control of the weight dtype because Keras mix precision sometimes
+    # depends on the input to infer the compute dtype, but the inputs of
+    # this layer are int type.
+    self._weight_fallback_dtype = weight_fallback_dtype
 
   def get_config(self):
     config = {
         "vocab_size": self._vocab_size,
         "embedding_width": self._embedding_width,
         "initializer": self._initializer,
         "use_one_hot": self._use_one_hot,
         "scale_factor": self._scale_factor,
+        "weight_fallback_dtype": self._weight_fallback_dtype,
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def build(self, input_shape):
+    if (
+        self.dtype is not None
+        and not tf.dtypes.as_dtype(self.dtype).is_floating
+    ):
+      # Keras failed to infer the right dtype.
+      dtype = self._weight_fallback_dtype
+    else:
+      dtype = self.dtype
     self.embeddings = self.add_weight(
         "embeddings",
         shape=[self._vocab_size, self._embedding_width],
         initializer=self._initializer,
-        dtype=tf.float32)
+        dtype=dtype)
 
     super().build(input_shape)
 
   def call(self, inputs):
     flat_inputs = tf.reshape(inputs, [-1])
     if self._use_one_hot:
-      dtype = self._compute_dtype
+      dtype = self.compute_dtype
       if not tf.dtypes.as_dtype(dtype).is_floating:
-        # TensorFlow 1 compatibility. In TF1, self._compute_dtype is int32
+        # TensorFlow 1 compatibility. In TF1, self.compute_dtype is int32
         # instead of a floating-point dtype, as the dtype is inferred from the
         # dtype of the inputs
-        dtype = tf.float32
+        dtype = self._weight_fallback_dtype
       one_hot_data = tf.one_hot(
           flat_inputs, depth=self._vocab_size, dtype=dtype)
       embeddings = tf.matmul(one_hot_data, self.embeddings)
     else:
       embeddings = tf.gather(self.embeddings, flat_inputs)
     embeddings = tf.reshape(
         embeddings,
-        # Work around b/142213824: prefer concat to shape over a Python list.
         tf.concat([tf.shape(inputs), [self._embedding_width]], axis=0))
     embeddings.set_shape(inputs.shape.as_list() + [self._embedding_width])
     if self._scale_factor:
       embeddings *= self._scale_factor
     return embeddings
 
   @property
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/on_device_embedding_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/on_device_embedding_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,33 +11,29 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based one-hot embedding layer."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import on_device_embedding
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class OnDeviceEmbeddingTest(keras_parameterized.TestCase):
+class OnDeviceEmbeddingTest(tf.test.TestCase):
 
   def test_layer_creation(self):
     vocab_size = 31
     embedding_width = 27
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size, embedding_width=embedding_width)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # The output should be the same as the input, save that it has an extra
     # embedding_width dimension on the end.
     expected_output_shape = [None, sequence_length, embedding_width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
     self.assertEqual(output_tensor.dtype, tf.float32)
@@ -46,15 +42,15 @@
     vocab_size = 31
     embedding_width = 27
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size, embedding_width=embedding_width,
         dtype="mixed_float16")
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # The output should be the same as the input, save that it has an extra
     # embedding_width dimension on the end.
     expected_output_shape = [None, sequence_length, embedding_width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
     self.assertEqual(output_tensor.dtype, tf.float16)
@@ -62,19 +58,19 @@
   def test_layer_invocation(self):
     vocab_size = 31
     embedding_width = 27
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size, embedding_width=embedding_width)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 3
     input_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     output = model.predict(input_data)
@@ -84,19 +80,19 @@
     vocab_size = 31
     embedding_width = 27
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size, embedding_width=embedding_width,
         dtype="mixed_float16")
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 3
     input_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     output = model.predict(input_data)
@@ -107,15 +103,15 @@
     embedding_width = 27
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size,
         embedding_width=embedding_width,
         use_one_hot=True)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # The output should be the same as the input, save that it has an extra
     # embedding_width dimension on the end.
     expected_output_shape = [None, sequence_length, embedding_width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
     self.assertEqual(output_tensor.dtype, tf.float32)
@@ -126,15 +122,15 @@
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size,
         embedding_width=embedding_width,
         dtype="mixed_float16",
         use_one_hot=True)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # The output should be the same as the input, save that it has an extra
     # embedding_width dimension on the end.
     expected_output_shape = [None, sequence_length, embedding_width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
     self.assertEqual(output_tensor.dtype, tf.float16)
@@ -144,19 +140,19 @@
     embedding_width = 27
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size,
         embedding_width=embedding_width,
         use_one_hot=True)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 3
     input_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     output = model.predict(input_data)
@@ -168,19 +164,19 @@
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size,
         embedding_width=embedding_width,
         dtype="mixed_float16",
         use_one_hot=True)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 3
     input_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     output = model.predict(input_data)
@@ -190,19 +186,19 @@
     vocab_size = 31
     embedding_width = 27
     test_layer = on_device_embedding.OnDeviceEmbedding(
         vocab_size=vocab_size, embedding_width=embedding_width,
         scale_factor=embedding_width**0.5)
     # Create a 2-dimensional input (the first dimension is implicit).
     sequence_length = 23
-    input_tensor = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
+    input_tensor = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
     output_tensor = test_layer(input_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 3
     input_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     output = model.predict(input_data)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/pack_optimization.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/pack_optimization.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,24 +10,24 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Pack sequence optimization on accelerators."""
 from typing import Dict
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import rezero_transformer
 from official.nlp.modeling.layers import self_attention_mask
 from official.nlp.modeling.layers import transformer_encoder_block
 from official.nlp.modeling.layers import transformer_scaffold
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class PackBertEmbeddings(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class PackBertEmbeddings(tf_keras.layers.Layer):
   """Performs packing tricks for BERT inputs to improve TPU utilization."""
 
   def __init__(self, pack_sequences: int, **kwargs):
     super().__init__(**kwargs)
     self.pack_sequences = pack_sequences
 
   def call(self, input_embeddings: tf.Tensor,
@@ -58,15 +58,15 @@
         tf.math.logical_and(attention_mask, packing_mask), tf.float32)
 
     return dict(
         packed_embeddings=packed_embeddings,
         combined_attention_mask=combined_attention_mask)
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 class StridedTransformerEncoderBlock(
     transformer_encoder_block.TransformerEncoderBlock):
   """Transformer layer for packing optimization to stride over inputs."""
 
   def __init__(self, *args, **kwargs):
     super().__init__(*args, **kwargs)
     if self._output_range is not None:
@@ -124,15 +124,15 @@
     if self._norm_first:
       return source_attention_output + layer_output
 
     layer_output = tf.cast(layer_output, tf.float32)
     return self._output_layer_norm(layer_output + attention_output)
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 class StridedReZeroTransformer(rezero_transformer.ReZeroTransformer):
   """ReZeroTransformer for packing optimization to stride over inputs."""
 
   def __init__(self, *args, **kwargs):
     super().__init__(*args, **kwargs)
     if self._output_range is not None:
       raise ValueError(f'{self.__class__} does not '
@@ -175,15 +175,15 @@
                                               tf.float32)
     if self._use_layer_norm:
       layer_output = self._output_layer_norm(layer_output)
 
     return layer_output
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 class StridedTransformerScaffold(transformer_scaffold.TransformerScaffold):
   """TransformerScaffold for packing optimization to stride over inputs."""
 
   def call(self, inputs, stride: tf.Tensor, training=None):
     if isinstance(inputs, (list, tuple)):
       if len(inputs) == 2:
         input_tensor, attention_mask = inputs
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/pack_optimization_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/pack_optimization_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for pack_optimization."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.nlp.modeling.layers import pack_optimization
 
 
 class PackOptimizationTest(tf.test.TestCase):
 
   def test_bert_embedding_packing(self):
     batch_size, seq_len, embed_dim = 2, 4, 8
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/per_dim_scale_attention.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/per_dim_scale_attention.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,20 +11,20 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based attention layer with learnable per dim scaling."""
 import gin
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 @gin.configurable
-@tf.keras.utils.register_keras_serializable(package='Text')
-class PerDimScaleAttention(tf.keras.layers.MultiHeadAttention):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class PerDimScaleAttention(tf_keras.layers.MultiHeadAttention):
   """Learn scales for individual dims.
 
      It can improve quality but might hurt training stability.
   """
 
   def _build_from_signature(self, query, value, key=None):
     super()._build_from_signature(query=query, value=value, key=key)  # pytype: disable=attribute-error
@@ -63,15 +63,15 @@
         attention_scores, training=training)
 
     # `context_layer` = [B, T, N, H]
     attention_output = tf.einsum(self._combine_equation,
                                  attention_scores_dropout, value)
     return attention_output, attention_scores
 
-  def call(
+  def call(  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
       self,
       query,
       value,
       key=None,
       attention_mask=None,
       return_attention_scores=False,
       training=None,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/per_dim_scale_attention_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/per_dim_scale_attention_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for PerDimScaleAttention."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import per_dim_scale_attention as attention
 
 
 class PerDimScaleAttentionTest(tf.test.TestCase):
 
   def test_attention(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/position_embedding.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/position_embedding.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,29 +13,29 @@
 # limitations under the License.
 
 """Keras-based positional embedding layer."""
 # pylint: disable=g-classes-have-attributes
 import math
 from typing import Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
-Initializer = tf.keras.initializers.Initializer
+Initializer = tf_keras.initializers.Initializer
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class PositionEmbedding(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class PositionEmbedding(tf_keras.layers.Layer):
   """Creates a positional embedding.
 
   Example:
   ```python
   position_embedding = PositionEmbedding(max_length=100)
-  inputs = tf.keras.Input((100, 32), dtype=tf.float32)
+  inputs = tf_keras.Input((100, 32), dtype=tf.float32)
   outputs = position_embedding(inputs)
   ```
 
 
   Args:
     max_length: The maximum size of the dynamic sequence.
     initializer: The initializer to use for the embedding weights. Defaults to
@@ -55,28 +55,28 @@
 
     super().__init__(**kwargs)
     if max_length is None:
       raise ValueError(
           "`max_length` must be an Integer, not `None`."
       )
     self._max_length = max_length
-    self._initializer = tf.keras.initializers.get(initializer)
+    self._initializer = tf_keras.initializers.get(initializer)
     self._seq_axis = seq_axis
 
   def get_config(self):
     config = {
         "max_length": self._max_length,
-        "initializer": tf.keras.initializers.serialize(self._initializer),
+        "initializer": tf_keras.initializers.serialize(self._initializer),
         "seq_axis": self._seq_axis,
     }
     base_config = super(PositionEmbedding, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def build(self, input_shape):
-    dimension_list = input_shape.as_list()
+    dimension_list = input_shape
     width = dimension_list[-1]
     weight_sequence_length = self._max_length
 
     self._position_embeddings = self.add_weight(
         "embeddings",
         shape=[weight_sequence_length, width],
         initializer=self._initializer)
@@ -90,16 +90,16 @@
     new_shape = [1 for _ in inputs.get_shape().as_list()]
     new_shape[self._seq_axis] = actual_seq_len
     new_shape[-1] = position_embeddings.get_shape().as_list()[-1]
     position_embeddings = tf.reshape(position_embeddings, new_shape)
     return tf.broadcast_to(position_embeddings, input_shape)
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class RelativePositionEmbedding(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class RelativePositionEmbedding(tf_keras.layers.Layer):
   """Creates a positional embedding.
 
   This layer calculates the position encoding as a mix of sine and cosine
   functions with geometrically increasing wavelengths. Defined and formulized in
    "Attention is All You Need", section 3.5.
   (https://arxiv.org/abs/1706.03762).
 
@@ -223,16 +223,16 @@
       tf.int32,
   )
   val_if_large = tf.math.minimum(val_if_large, num_buckets - 1)
   ret += tf.where(is_small, n, val_if_large)
   return ret
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class RelativePositionBias(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class RelativePositionBias(tf_keras.layers.Layer):
   """Relative position embedding via per-head bias in T5 style.
 
   Reference implementation in MeshTF:
   https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/transformer_layers.py#L1000
 
   This layer implements the relative position bias used in "Exploring the Limits
   of Transfer Learning with a Unified Text-to-Text Transformer"
@@ -250,15 +250,15 @@
     self.num_heads = num_heads
     self.relative_attention_num_buckets = relative_attention_num_buckets
     self.bidirectional = bidirectional
     self.relative_attention_max_distance = relative_attention_max_distance
     if embeddings_initializer:
       self._embed_init = embeddings_initializer
     else:
-      self._embed_init = tf.keras.initializers.TruncatedNormal(stddev=1.0)
+      self._embed_init = tf_keras.initializers.TruncatedNormal(stddev=1.0)
     with tf.name_scope(self.name):
       self._relative_attention_bias = self.add_weight(
           "rel_embedding",
           shape=[self.relative_attention_num_buckets, self.num_heads],
           initializer=self._embed_init,
           dtype=self.dtype,
           trainable=True)
@@ -270,15 +270,15 @@
         "relative_attention_num_buckets":
             self.relative_attention_num_buckets,
         "relative_attention_max_distance":
             self.relative_attention_max_distance,
         "bidirectional":
             self.bidirectional,
         "embeddings_initializer":
-            tf.keras.initializers.serialize(self._embed_init),
+            tf_keras.initializers.serialize(self._embed_init),
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, query: tf.Tensor, key: tf.Tensor):
     """Implements the forward pass.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/position_embedding_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/position_embedding_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,32 +12,28 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based positional embedding layer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import position_embedding
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class PositionEmbeddingLayerTest(keras_parameterized.TestCase):
+class PositionEmbeddingLayerTest(tf.test.TestCase):
 
   def test_static_layer_output_shape(self):
     # Create a 3-dimensional input (the first dimension is implicit).
     sequence_length = 21
     test_layer = position_embedding.PositionEmbedding(
         max_length=sequence_length)
     width = 30
-    input_tensor = tf.keras.Input(shape=(sequence_length, width))
+    input_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(input_tensor)
 
     # When using static positional embedding shapes, the output is expected
     # to be the same as the input shape in all dimensions save batch.
     expected_output_shape = [None, sequence_length, width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
     # The default output dtype for this layer should be tf.float32.
@@ -45,15 +41,15 @@
 
   def test_non_default_axis_static(self):
     # Create a 3-dimensional input (the first dimension is implicit).
     sequence_length = 21
     test_layer = position_embedding.PositionEmbedding(
         max_length=sequence_length, seq_axis=2)
     width = 30
-    input_tensor = tf.keras.Input(shape=(width, sequence_length, width))
+    input_tensor = tf_keras.Input(shape=(width, sequence_length, width))
     output_tensor = test_layer(input_tensor)
 
     # When using static positional embedding shapes, the output is expected
     # to be the same as the input shape in all dimensions save batch.
     expected_output_shape = [None, width, sequence_length, width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
     # The default output dtype for this layer should be tf.float32.
@@ -61,15 +57,15 @@
 
   def test_float16_dtype(self):
     # Create a 3-dimensional input (the first dimension is implicit).
     sequence_length = 21
     test_layer = position_embedding.PositionEmbedding(
         max_length=sequence_length, dtype="float16")
     width = 30
-    input_tensor = tf.keras.Input(shape=(sequence_length, width))
+    input_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(input_tensor)
 
     # When using static positional embedding shapes, the output is expected
     # to be the same as the input shape in all dimensions save batch.
     expected_output_shape = [None, sequence_length, width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
     # The default output dtype for this layer should be tf.float32.
@@ -77,66 +73,63 @@
 
   def test_dynamic_layer_output_shape(self):
     max_sequence_length = 40
     test_layer = position_embedding.PositionEmbedding(
         max_length=max_sequence_length)
     # Create a 3-dimensional input (the first dimension is implicit).
     width = 30
-    input_tensor = tf.keras.Input(shape=(None, width))
+    input_tensor = tf_keras.Input(shape=(None, width))
     output_tensor = test_layer(input_tensor)
 
     # When using dynamic positional embedding shapes, the output is expected
     # to be the same as the input shape in all dimensions - but may be None if
     # the input shape is None there.
     expected_output_shape = [None, None, width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
 
   def test_non_default_axis_dynamic(self):
     max_sequence_length = 60
     test_layer = position_embedding.PositionEmbedding(
         max_length=max_sequence_length, seq_axis=2)
     # Create a 3-dimensional input (the first dimension is implicit).
     width = 30
-    input_tensor = tf.keras.Input(shape=(None, None, width))
+    input_tensor = tf_keras.Input(shape=(None, None, width))
     output_tensor = test_layer(input_tensor)
 
     # When using dynamic positional embedding shapes, the output is expected
     # to be the same as the input shape in all dimensions - but may be None if
     # the input shape is None there.
     expected_output_shape = [None, None, None, width]
     self.assertEqual(expected_output_shape, output_tensor.shape.as_list())
 
   def test_dynamic_layer_slicing(self):
     max_sequence_length = 40
     test_layer = position_embedding.PositionEmbedding(
         max_length=max_sequence_length)
     # Create a 3-dimensional input (the first dimension is implicit).
     width = 30
-    input_tensor = tf.keras.Input(shape=(None, width))
+    input_tensor = tf_keras.Input(shape=(None, width))
     output_tensor = test_layer(input_tensor)
 
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     # Create input data that is shorter than max_sequence_length, which should
     # trigger a down-slice.
     input_length = 17
     # Note: This test explicitly uses a batch size of 1. This is to get around
     # Keras' restriction on Model invocations: inputs are expected to have the
     # same batch cardinality as outputs. In practice, this layer should be used
     # inside a model, where it can be projected when added to another tensor.
     input_data = np.ones((1, input_length, width))
     output_data = model.predict(input_data)
 
     self.assertAllEqual([1, input_length, width], output_data.shape)
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class RelativePositionEmbeddingLayerTest(keras_parameterized.TestCase):
+class RelativePositionEmbeddingLayerTest(tf.test.TestCase):
 
   def test_relative_tensor_input(self):
     hidden_size = 8
     test_layer = position_embedding.RelativePositionEmbedding(
         hidden_size=hidden_size)
 
     # create a 3-dimensional input for test_layer to infer length as 1.
@@ -160,16 +153,15 @@
 
     # expected output is the theoretical result of the input based on
     # sine cosine relative position embedding formula.
     expected_output_tensor = tf.constant([[0, 0, 0, 0, 1, 1, 1, 1]])
     self.assertAllEqual(output_tensor, expected_output_tensor)
 
 
-@keras_parameterized.run_all_keras_modes
-class RelativePositionBiasTest(keras_parameterized.TestCase):
+class RelativePositionBiasTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(("bidirectional", True),
                                   ("unidirectional", False))
   def test_relative_position_bias(self, bidirectional):
     query = tf.zeros((4, 4, 2))
     key = tf.zeros((4, 2, 2))
     l = position_embedding.RelativePositionBias(
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/relative_attention.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/relative_attention.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based relative attention layers."""
 import math
 import string
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 _CHR_IDX = string.ascii_lowercase
 
 
 def _build_proj_equation(free_dims, bound_dims, output_dims):
   """Builds an einsum equation for projections inside multi-head attention."""
   input_str = ""
@@ -65,20 +65,20 @@
   x = tf.slice(x, [0, 0, 0, 0], [-1, klen, -1, -1])
 
   x = tf.transpose(x, perm=[2, 3, 0, 1])
 
   return x
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class MultiHeadRelativeAttention(tf.keras.layers.MultiHeadAttention):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class MultiHeadRelativeAttention(tf_keras.layers.MultiHeadAttention):
   """A multi-head attention layer with relative attention + position encoding.
 
   This layer shares the same input/output projections as the common
-  `tf.keras.layers.MultiHeadAttention` layer.
+  `tf_keras.layers.MultiHeadAttention` layer.
 
   When it calculates attention logits, position encoding is projected to form
   relative keys. The logits are composed by shifted relative logits and content
   logits.
 
   **Note: This layer is currently experimental.
 
@@ -140,15 +140,15 @@
         activity_regularizer=self._activity_regularizer,
         kernel_constraint=self._kernel_constraint,
         bias_constraint=self._bias_constraint)
 
     with tf.init_scope():
       einsum_equation, _, output_rank = _build_proj_equation(
           key_shape.rank - 1, bound_dims=1, output_dims=2)
-      self._encoding_dense = tf.keras.layers.EinsumDense(
+      self._encoding_dense = tf_keras.layers.EinsumDense(
           einsum_equation,
           output_shape=_get_output_shape(output_rank - 1,
                                          [self._num_heads, self._key_dim]),
           bias_axes=None,
           name="encoding",
           **common_kwargs)
 
@@ -224,15 +224,15 @@
     attention_output = self._dropout_layer(attention_scores)
 
     attention_output = tf.einsum(self._combine_equation,
                                  attention_output,
                                  value)
     return attention_output
 
-  def call(self,
+  def call(self,  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
            query,
            value,
            content_attention_bias,
            positional_attention_bias,
            key=None,
            relative_position_encoding=None,
            segment_matrix=None,
@@ -315,29 +315,29 @@
 
     # `attention_output` = [B, S, N, H]
     attention_output = self._output_dense(attention_output)
 
     return attention_output
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
+@tf_keras.utils.register_keras_serializable(package="Text")
 class TwoStreamRelativeAttention(MultiHeadRelativeAttention):
   """Two-stream relative self-attention for XLNet.
 
   In XLNet, each token has two associated vectors at each self-attention layer,
   the content stream (h) and the query stream (g).
 
   The content stream is the self-attention stream as in Transformer XL and
   represents the context and content (the token itself).
 
   The query stream only has access to contextual information and the position,
   but not the content.
 
   This layer shares the same build signature as
-  `tf.keras.layers.MultiHeadAttention` but has different input/output
+  `tf_keras.layers.MultiHeadAttention` but has different input/output
   projections.
 
   **Note: This layer is currently experimental.
 
   Call args:
     content_stream: `Tensor` of shape `[B, T, dim]`.
     content_attention_bias: Bias `Tensor` for content based attention of shape
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/relative_attention_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/relative_attention_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,19 +10,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for the attention layer."""
 
+from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import relative_attention
 
 
 def _create_mock_attention_data(
     num_heads,
     key_dim,
     value_dim,
@@ -107,16 +107,15 @@
         segment_encoding=tf.random.normal(shape=segment_encoding_shape),
         segment_matrix=segment_matrix)
     data.update(segment_data)
 
   return data
 
 
-@keras_parameterized.run_all_keras_modes
-class MultiHeadRelativeAttentionTest(keras_parameterized.TestCase):
+class MultiHeadRelativeAttentionTest(tf.test.TestCase, parameterized.TestCase):
 
   @combinations.generate(combinations.combine(
       value_dim=[32, 64],
       memory_length=[0, 4],
       state=[True, False],
       mask=[True, False],
       segment=[True, False]))
@@ -143,16 +142,15 @@
         include_state=state,
         include_mask=mask,
         include_segment=segment)
     output = test_layer(**data)
     self.assertEqual(output.shape, [batch_size, seq_length, key_dim])
 
 
-@keras_parameterized.run_all_keras_modes
-class TwoStreamRelativeAttentionTest(keras_parameterized.TestCase):
+class TwoStreamRelativeAttentionTest(tf.test.TestCase, parameterized.TestCase):
 
   @combinations.generate(combinations.combine(
       num_predictions=[2, 10],
       memory_length=[0, 4],
       state=[True, False],
       mask=[True, False],
       segment=[True, False]))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/reuse_attention.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/reuse_attention.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 # pylint: disable=g-classes-have-attributes
 
 import collections
 import math
 import string
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
 _CHR_IDX = string.ascii_lowercase
 
 
@@ -105,15 +105,15 @@
   return equation, bias_axes, len(output_str)
 
 
 def _get_output_shape(output_rank, known_last_dims):
   return [None] * (output_rank - len(known_last_dims)) + list(known_last_dims)
 
 
-class ReuseMultiHeadAttention(tf.keras.layers.Layer):
+class ReuseMultiHeadAttention(tf_keras.layers.Layer):
   """MultiHeadAttention layer.
 
   This is an implementation of multi-headed attention as described in the paper
   "Attention is all you Need" (Vaswani et al., 2017).
   If `query`, `key,` `value` are the same, then
   this is self-attention. Each timestep in `query` attends to the
   corresponding sequence in `key`, and returns a fixed-width vector.
@@ -134,27 +134,27 @@
 
   Examples:
 
   Performs 1D cross-attention over two sequence inputs with an attention mask.
   Returns the additional attention weights over heads.
 
   >>> layer = MultiHeadAttention(num_heads=2, key_dim=2)
-  >>> target = tf.keras.Input(shape=[8, 16])
-  >>> source = tf.keras.Input(shape=[4, 16])
+  >>> target = tf_keras.Input(shape=[8, 16])
+  >>> source = tf_keras.Input(shape=[4, 16])
   >>> output_tensor, weights = layer(target, source,
   ...                                return_attention_scores=True)
   >>> print(output_tensor.shape)
   (None, 8, 16)
   >>> print(weights.shape)
   (None, 2, 8, 4)
 
   Performs 2D self-attention over a 5D input tensor on axes 2 and 3.
 
   >>> layer = MultiHeadAttention(num_heads=2, key_dim=2, attention_axes=(2, 3))
-  >>> input_tensor = tf.keras.Input(shape=[5, 3, 4, 16])
+  >>> input_tensor = tf_keras.Input(shape=[5, 3, 4, 16])
   >>> output_tensor = layer(input_tensor, input_tensor)
   >>> print(output_tensor.shape)
   (None, 5, 3, 4, 16)
 
   Args:
     num_heads: Number of attention heads.
     key_dim: Size of each attention head for query and key.
@@ -235,31 +235,31 @@
     if reuse_attention == -1:
       reuse_attention = self._num_heads
     self._reuse_heads = reuse_attention
     self._use_relative_pe = use_relative_pe
     self._pe_max_seq_length = pe_max_seq_length
     self._use_bias = use_bias
     self._output_shape = output_shape
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
     if attention_axes is not None and not isinstance(attention_axes,
                                                      collections.abc.Sized):
       self._attention_axes = (attention_axes,)
     else:
       self._attention_axes = attention_axes
     self._built_from_signature = False
     self._query_shape, self._key_shape, self._value_shape = None, None, None
     # Use relative PE only if reuse_heads < num_heads.
     if self._use_relative_pe and self._reuse_heads < self._num_heads:
       # Determine the dtype from global policy.
-      policy = tf.keras.mixed_precision.global_policy()
+      policy = tf_keras.mixed_precision.global_policy()
       if policy.name == "mixed_bfloat16":
         policy = tf.bfloat16
       elif policy.name == "mixed_float16":
         policy = tf.float16
       else:
         policy = tf.float32
       self._position_embeddings = tf.Variable(
@@ -280,27 +280,27 @@
         "use_bias": self._use_bias,
         "output_shape": self._output_shape,
         "attention_axes": self._attention_axes,
         "reuse_attention": self._reuse_heads,
         "use_relative_pe": self._use_relative_pe,
         "pe_max_seq_length": self._pe_max_seq_length,
         "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
+            tf_keras.initializers.serialize(self._kernel_initializer),
         "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
+            tf_keras.initializers.serialize(self._bias_initializer),
         "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
+            tf_keras.regularizers.serialize(self._kernel_regularizer),
         "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
+            tf_keras.regularizers.serialize(self._bias_regularizer),
         "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
+            tf_keras.regularizers.serialize(self._activity_regularizer),
         "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
+            tf_keras.constraints.serialize(self._kernel_constraint),
         "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint),
+            tf_keras.constraints.serialize(self._bias_constraint),
         "query_shape": self._query_shape,
         "key_shape": self._key_shape,
         "value_shape": self._value_shape,
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
@@ -358,28 +358,28 @@
     # to avoid creating symbolic Tensors that will later pollute any eager
     # operations.
     with tf.init_scope():
       free_dims = self._query_shape.rank - 1
       if self._reuse_heads < self._num_heads:
         einsum_equation, bias_axes, output_rank = _build_proj_equation(
             free_dims, bound_dims=1, output_dims=2)
-        self._query_dense = tf.keras.layers.EinsumDense(
+        self._query_dense = tf_keras.layers.EinsumDense(
             einsum_equation,
             output_shape=_get_output_shape(
                 output_rank - 1,
                 [self._num_heads - self._reuse_heads, self._key_dim]),
             bias_axes=bias_axes if self._use_bias else None,
             name="query",
             kernel_initializer=tf_utils.clone_initializer(
                 self._kernel_initializer),
             bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
             **common_kwargs)
         einsum_equation, bias_axes, output_rank = _build_proj_equation(
             self._key_shape.rank - 1, bound_dims=1, output_dims=2)
-        self._key_dense = tf.keras.layers.EinsumDense(
+        self._key_dense = tf_keras.layers.EinsumDense(
             einsum_equation,
             output_shape=_get_output_shape(
                 output_rank - 1,
                 [self._num_heads - self._reuse_heads, self._key_dim]),
             bias_axes=bias_axes if self._use_bias else None,
             name="key",
             kernel_initializer=tf_utils.clone_initializer(
@@ -388,28 +388,28 @@
             **common_kwargs)
       einsum_equation, bias_axes, output_rank = _build_proj_equation(
           self._value_shape.rank - 1, bound_dims=1, output_dims=2)
 
       self._value_dense = []
       if self._reuse_heads > 0:
         self._value_dense.append(
-            tf.keras.layers.EinsumDense(
+            tf_keras.layers.EinsumDense(
                 einsum_equation,
                 output_shape=_get_output_shape(
                     output_rank - 1, [self._reuse_heads, self._value_dim]),
                 bias_axes=bias_axes if self._use_bias else None,
                 name="value_reuse",
                 kernel_initializer=tf_utils.clone_initializer(
                     self._kernel_initializer),
                 bias_initializer=tf_utils.clone_initializer(
                     self._bias_initializer),
                 **common_kwargs))
       if self._reuse_heads < self._num_heads:
         self._value_dense.append(
-            tf.keras.layers.EinsumDense(
+            tf_keras.layers.EinsumDense(
                 einsum_equation,
                 output_shape=_get_output_shape(
                     output_rank - 1,
                     [self._num_heads - self._reuse_heads, self._value_dim]),
                 bias_axes=bias_axes if self._use_bias else None,
                 name="value_new",
                 kernel_initializer=tf_utils.clone_initializer(
@@ -449,15 +449,15 @@
         output_shape = [self._output_shape]
       else:
         output_shape = self._output_shape
     else:
       output_shape = [self._query_shape[-1]]
     einsum_equation, bias_axes, output_rank = _build_proj_equation(
         free_dims, bound_dims=2, output_dims=len(output_shape))
-    return tf.keras.layers.EinsumDense(
+    return tf_keras.layers.EinsumDense(
         einsum_equation,
         output_shape=_get_output_shape(output_rank - 1, output_shape),
         bias_axes=bias_axes if (use_bias and self._use_bias) else None,
         name=name,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
@@ -476,16 +476,16 @@
       self._attention_axes = tuple(range(1, rank - 2))
     else:
       self._attention_axes = tuple(self._attention_axes)
     self._dot_product_equation, self._combine_equation, attn_scores_rank = (
         _build_attention_equation(rank, attn_axes=self._attention_axes))
     norm_axes = tuple(
         range(attn_scores_rank - len(self._attention_axes), attn_scores_rank))
-    self._softmax = tf.keras.layers.Softmax(axis=norm_axes)
-    self._dropout_layer = tf.keras.layers.Dropout(rate=self._dropout)
+    self._softmax = tf_keras.layers.Softmax(axis=norm_axes)
+    self._dropout_layer = tf_keras.layers.Dropout(rate=self._dropout)
 
   def _masked_softmax(self, attention_scores, attention_mask=None):
     # Normalize the attention scores to probabilities.
     # `attention_scores` = [B, N, T, S]
     if attention_mask is not None:
       # The expand dim happens starting from the `num_heads` dimension,
       # (<batch_dims>, num_heads, <query_attention_dims, key_attention_dims>)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/reuse_attention_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/reuse_attention_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for the attention layer."""
 
 from absl.testing import parameterized
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import reuse_attention as attention
 
 
 class ReuseMultiHeadAttentionTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(
@@ -32,45 +32,45 @@
     """Test that the attention layer can be created without a mask tensor."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=12,
         key_dim=64,
         value_dim=value_dim,
         output_shape=output_shape)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
-    value = tf.keras.Input(shape=(20, 80))
+    query = tf_keras.Input(shape=(40, 80))
+    value = tf_keras.Input(shape=(20, 80))
     output = test_layer(query=query, value=value)
     self.assertEqual(output.shape.as_list(), [None] + output_dims)
 
   def test_non_masked_self_attention(self):
     """Test with one input (self-attenntion) and no mask tensor."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=12, key_dim=64)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
+    query = tf_keras.Input(shape=(40, 80))
     output = test_layer(query, query)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
 
   def test_attention_scores(self):
     """Test attention outputs with coefficients."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=12, key_dim=64)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
+    query = tf_keras.Input(shape=(40, 80))
     output, coef = test_layer(query, query, return_attention_scores=True)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
     self.assertEqual(coef.shape.as_list(), [None, 12, 40, 40])
 
   def test_attention_scores_with_values(self):
     """Test attention outputs with coefficients."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=12, key_dim=64)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
-    value = tf.keras.Input(shape=(60, 80))
+    query = tf_keras.Input(shape=(40, 80))
+    value = tf_keras.Input(shape=(60, 80))
     output, coef = test_layer(query, value, return_attention_scores=True)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
     self.assertEqual(coef.shape.as_list(), [None, 12, 40, 60])
 
   @parameterized.named_parameters(
       ("with_bias", True, 0), ("no_bias", False, 0),
       ("reuse_all_with_bias", True, -1), ("reuse_all_no_bias", False, -1),
@@ -79,22 +79,22 @@
   def test_masked_attention(self, use_bias, reuse_attention):
     """Test with a mask tensor."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=2, key_dim=2, use_bias=use_bias,
         reuse_attention=reuse_attention)
     # Create a 3-dimensional input (the first dimension is implicit).
     batch_size = 3
-    query = tf.keras.Input(shape=(4, 8))
-    value = tf.keras.Input(shape=(2, 8))
-    mask_tensor = tf.keras.Input(shape=(4, 2))
-    reuse_attention_scores = tf.keras.Input(shape=(2, 4, 2))
+    query = tf_keras.Input(shape=(4, 8))
+    value = tf_keras.Input(shape=(2, 8))
+    mask_tensor = tf_keras.Input(shape=(4, 2))
+    reuse_attention_scores = tf_keras.Input(shape=(2, 4, 2))
     output = test_layer(query=query, value=value, attention_mask=mask_tensor,
                         reuse_attention_scores=reuse_attention_scores)
     # Create a model containing the test layer.
-    model = tf.keras.Model(
+    model = tf_keras.Model(
         [query, value, mask_tensor, reuse_attention_scores], output)
 
     # Generate data for the input (non-mask) tensors.
     from_data = 10 * np.random.random_sample((batch_size, 4, 8))
     to_data = 10 * np.random.random_sample((batch_size, 2, 8))
     reuse_scores = np.random.random_sample((batch_size, 2, 4, 2))
     # Invoke the data with a random set of mask data. This should mask at least
@@ -112,18 +112,18 @@
     # same.
     if reuse_attention == -1:
       self.assertAllEqual(masked_output_data, unmasked_output_data)
     else:
       self.assertNotAllClose(masked_output_data, unmasked_output_data)
 
     # Tests the layer with three inputs: Q, K, V.
-    key = tf.keras.Input(shape=(2, 8))
+    key = tf_keras.Input(shape=(2, 8))
     output = test_layer(query, value=value, key=key, attention_mask=mask_tensor,
                         reuse_attention_scores=reuse_attention_scores)
-    model = tf.keras.Model(
+    model = tf_keras.Model(
         [query, value, key, mask_tensor, reuse_attention_scores], output)
 
     masked_output_data = model.predict(
         [from_data, to_data, to_data, mask_data, reuse_scores])
     unmasked_output_data = model.predict(
         [from_data, to_data, to_data, null_mask_data, reuse_scores])
     # Because one data is masked and one is not, the outputs should not be the
@@ -148,33 +148,33 @@
         self.assertLen(test_layer._output_dense[1].trainable_variables, 1)
 
   def test_initializer(self):
     """Test with a specified initializer."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=12,
         key_dim=64,
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
+    query = tf_keras.Input(shape=(40, 80))
     output = test_layer(query, query)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
 
   def test_masked_attention_with_scores(self):
     """Test with a mask tensor."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=2, key_dim=2)
     # Create a 3-dimensional input (the first dimension is implicit).
     batch_size = 3
-    query = tf.keras.Input(shape=(4, 8))
-    value = tf.keras.Input(shape=(2, 8))
-    mask_tensor = tf.keras.Input(shape=(4, 2))
+    query = tf_keras.Input(shape=(4, 8))
+    value = tf_keras.Input(shape=(2, 8))
+    mask_tensor = tf_keras.Input(shape=(4, 2))
     output = test_layer(query=query, value=value, attention_mask=mask_tensor)
 
     # Create a model containing the test layer.
-    model = tf.keras.Model([query, value, mask_tensor], output)
+    model = tf_keras.Model([query, value, mask_tensor], output)
 
     # Generate data for the input (non-mask) tensors.
     from_data = 10 * np.random.random_sample((batch_size, 4, 8))
     to_data = 10 * np.random.random_sample((batch_size, 2, 8))
 
     # Invoke the data with a random set of mask data. This should mask at least
     # one element.
@@ -189,15 +189,15 @@
     # same.
     self.assertNotAllClose(masked_output_data, unmasked_output_data)
 
     # Create a model containing attention scores.
     output, scores = test_layer(
         query=query, value=value, attention_mask=mask_tensor,
         return_attention_scores=True)
-    model = tf.keras.Model([query, value, mask_tensor], [output, scores])
+    model = tf_keras.Model([query, value, mask_tensor], [output, scores])
     masked_output_data_score, masked_score = model.predict(
         [from_data, to_data, mask_data])
     unmasked_output_data_score, unmasked_score = model.predict(
         [from_data, to_data, null_mask_data])
     self.assertNotAllClose(masked_output_data_score, unmasked_output_data_score)
     self.assertAllClose(masked_output_data, masked_output_data_score)
     self.assertAllClose(unmasked_output_data, unmasked_output_data_score)
@@ -226,48 +226,48 @@
     # Invoke the data with a random set of mask data. This should mask at least
     # one element.
     mask_data = np.random.randint(2, size=mask_shape).astype("bool")
     # Invoke the same data, but with a null mask (where no elements are masked).
     null_mask_data = np.ones(mask_shape)
     # Because one data is masked and one is not, the outputs should not be the
     # same.
-    query_tensor = tf.keras.Input(query_shape[1:], name="query")
-    value_tensor = tf.keras.Input(value_shape[1:], name="value")
-    mask_tensor = tf.keras.Input(mask_shape[1:], name="mask")
+    query_tensor = tf_keras.Input(query_shape[1:], name="query")
+    value_tensor = tf_keras.Input(value_shape[1:], name="value")
+    mask_tensor = tf_keras.Input(mask_shape[1:], name="mask")
     output = test_layer(query=query_tensor, value=value_tensor,
                         attention_mask=mask_tensor)
-    model = tf.keras.Model([query_tensor, value_tensor, mask_tensor], output)
+    model = tf_keras.Model([query_tensor, value_tensor, mask_tensor], output)
 
     self.assertNotAllClose(
         model.predict([query, value, mask_data]),
         model.predict([query, value, null_mask_data]))
 
   def test_dropout(self):
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=2, key_dim=2, dropout=0.5)
 
     # Generate data for the input (non-mask) tensors.
-    from_data = tf.keras.backend.ones(shape=(32, 4, 8))
-    to_data = tf.keras.backend.ones(shape=(32, 2, 8))
+    from_data = tf_keras.backend.ones(shape=(32, 4, 8))
+    to_data = tf_keras.backend.ones(shape=(32, 2, 8))
     train_out = test_layer(from_data, to_data, None, None, None, True)
     test_out = test_layer(from_data, to_data, None, None, None, False)
 
     # Output should be close when not in training mode,
     # and should not be close when enabling dropout in training mode.
     self.assertNotAllClose(
-        tf.keras.backend.eval(train_out),
-        tf.keras.backend.eval(test_out))
+        tf_keras.backend.eval(train_out),
+        tf_keras.backend.eval(test_out))
 
   def test_non_masked_self_attention_with_reuse(self):
     """Test with one input (self-attenntion) and no mask tensor."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=12, key_dim=64, reuse_attention=True)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
-    reuse_scores = tf.keras.Input(shape=(12, 40, 40))
+    query = tf_keras.Input(shape=(40, 80))
+    reuse_scores = tf_keras.Input(shape=(12, 40, 40))
     output = test_layer(query, query, reuse_attention_scores=reuse_scores)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
 
   @parameterized.named_parameters(
       ("no_reuse_with_pe_max_seq_length_20", False, 20),
       ("reuse_all_with_pe_max_seq_length_20", True, 20),
       ("reuse_partial_with_pe_max_seq_length_20", 5, 20),
@@ -277,28 +277,28 @@
   def test_non_masked_self_attention_with_relative_pe(self, reuse_attention,
                                                       pe_max_seq_length):
     """Test with one input (self-attenntion) and no mask tensor."""
     test_layer = attention.ReuseMultiHeadAttention(
         num_heads=12, key_dim=64, reuse_attention=reuse_attention,
         use_relative_pe=True, pe_max_seq_length=pe_max_seq_length)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
-    reuse_scores = tf.keras.Input(shape=(12, 40, 40))
+    query = tf_keras.Input(shape=(40, 80))
+    reuse_scores = tf_keras.Input(shape=(12, 40, 40))
     output = test_layer(query, query, reuse_attention_scores=reuse_scores)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
-    query = tf.keras.Input(shape=(30, 80))
-    reuse_scores = tf.keras.Input(shape=(12, 30, 30))
+    query = tf_keras.Input(shape=(30, 80))
+    reuse_scores = tf_keras.Input(shape=(12, 30, 30))
     output = test_layer(query, query, reuse_attention_scores=reuse_scores)
     self.assertEqual(output.shape.as_list(), [None, 30, 80])
-    query = tf.keras.Input(shape=(30, 80))
-    key = tf.keras.Input(shape=(20, 80))
-    reuse_scores = tf.keras.Input(shape=(12, 30, 20))
+    query = tf_keras.Input(shape=(30, 80))
+    key = tf_keras.Input(shape=(20, 80))
+    reuse_scores = tf_keras.Input(shape=(12, 30, 20))
     output = test_layer(query, key, reuse_attention_scores=reuse_scores)
     self.assertEqual(output.shape.as_list(), [None, 30, 80])
-    query = tf.keras.Input(shape=(50, 80))
-    key = tf.keras.Input(shape=(60, 80))
-    reuse_scores = tf.keras.Input(shape=(12, 50, 60))
+    query = tf_keras.Input(shape=(50, 80))
+    key = tf_keras.Input(shape=(60, 80))
+    reuse_scores = tf_keras.Input(shape=(12, 50, 60))
     output = test_layer(query, key, reuse_attention_scores=reuse_scores)
     self.assertEqual(output.shape.as_list(), [None, 50, 80])
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/reuse_transformer.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/reuse_transformer.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based TransformerEncoder block layer."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import reuse_attention as attention
 
 
-class ReuseTransformer(tf.keras.layers.Layer):
+class ReuseTransformer(tf_keras.layers.Layer):
   """Transformer layer.
 
   This layer implements the ReuseTransformer Encoder from
   "Leveraging redundancy in attention with Reuse Transformers".
   (https://arxiv.org/abs/2110.06821)
   """
 
@@ -104,21 +104,21 @@
     self._inner_activation = inner_activation
     self._head_size = head_size
     self._attention_dropout = attention_dropout
     self._attention_dropout_rate = attention_dropout
     self._output_dropout = output_dropout
     self._output_dropout_rate = output_dropout
     self._output_range = output_range
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._activity_regularizer = tf.keras.regularizers.get(activity_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._activity_regularizer = tf_keras.regularizers.get(activity_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
     self._use_bias = use_bias
     self._norm_first = norm_first
     self._norm_epsilon = norm_epsilon
     self._inner_dropout = inner_dropout
     self._reuse_attention = reuse_attention
     self._use_relative_pe = use_relative_pe
     self._pe_max_seq_length = pe_max_seq_length
@@ -126,15 +126,15 @@
     self._max_reuse_layer_idx = max_reuse_layer_idx
     # Overwrite for the first layer and layers greater than max_reuse_layer_idx.
     if self._layer_idx is not None and (
         self._layer_idx == 0 or (self._max_reuse_layer_idx is not None and
                                  self._max_reuse_layer_idx < self._layer_idx)):
       self._reuse_attention = 0
     if attention_initializer:
-      self._attention_initializer = tf.keras.initializers.get(
+      self._attention_initializer = tf_keras.initializers.get(
           attention_initializer)
     else:
       self._attention_initializer = tf_utils.clone_initializer(
           self._kernel_initializer)
     self._attention_axes = attention_axes
 
   def build(self, input_shape):
@@ -173,53 +173,53 @@
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         attention_axes=self._attention_axes,
         reuse_attention=self._reuse_attention,
         use_relative_pe=self._use_relative_pe,
         pe_max_seq_length=self._pe_max_seq_length,
         name="self_attention",
         **common_kwargs)
-    self._attention_dropout = tf.keras.layers.Dropout(
+    self._attention_dropout = tf_keras.layers.Dropout(
         rate=self._output_dropout)
     # Use float32 in layernorm for numeric stability.
     # It is probably safe in mixed_float16, but we haven't validated this yet.
     self._attention_layer_norm = (
-        tf.keras.layers.LayerNormalization(
+        tf_keras.layers.LayerNormalization(
             name="self_attention_layer_norm",
             axis=-1,
             epsilon=self._norm_epsilon,
             dtype=tf.float32))
-    self._intermediate_dense = tf.keras.layers.EinsumDense(
+    self._intermediate_dense = tf_keras.layers.EinsumDense(
         einsum_equation,
         output_shape=(None, self._inner_dim),
         bias_axes="d",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         name="intermediate",
         **common_kwargs)
-    policy = tf.keras.mixed_precision.global_policy()
+    policy = tf_keras.mixed_precision.global_policy()
     if policy.name == "mixed_bfloat16":
       # bfloat16 causes BERT with the LAMB optimizer to not converge
       # as well, so we use float32.
       # TODO(b/154538392): Investigate this.
       policy = tf.float32
-    self._intermediate_activation_layer = tf.keras.layers.Activation(
+    self._intermediate_activation_layer = tf_keras.layers.Activation(
         self._inner_activation, dtype=policy)
-    self._inner_dropout_layer = tf.keras.layers.Dropout(
+    self._inner_dropout_layer = tf_keras.layers.Dropout(
         rate=self._inner_dropout)
-    self._output_dense = tf.keras.layers.EinsumDense(
+    self._output_dense = tf_keras.layers.EinsumDense(
         einsum_equation,
         output_shape=(None, hidden_size),
         bias_axes="d",
         name="output",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
-    self._output_dropout = tf.keras.layers.Dropout(rate=self._output_dropout)
+    self._output_dropout = tf_keras.layers.Dropout(rate=self._output_dropout)
     # Use float32 in layernorm for numeric stability.
-    self._output_layer_norm = tf.keras.layers.LayerNormalization(
+    self._output_layer_norm = tf_keras.layers.LayerNormalization(
         name="output_layer_norm",
         axis=-1,
         epsilon=self._norm_epsilon,
         dtype=tf.float32)
 
     super(ReuseTransformer, self).build(input_shape)
 
@@ -241,37 +241,37 @@
             self._output_range,
         "reuse_attention":
             self._reuse_attention,
         "use_relative_pe": self._use_relative_pe,
         "pe_max_seq_length": self._pe_max_seq_length,
         "max_reuse_layer_idx": self._max_reuse_layer_idx,
         "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
+            tf_keras.initializers.serialize(self._kernel_initializer),
         "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
+            tf_keras.initializers.serialize(self._bias_initializer),
         "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
+            tf_keras.regularizers.serialize(self._kernel_regularizer),
         "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
+            tf_keras.regularizers.serialize(self._bias_regularizer),
         "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
+            tf_keras.regularizers.serialize(self._activity_regularizer),
         "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
+            tf_keras.constraints.serialize(self._kernel_constraint),
         "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint),
+            tf_keras.constraints.serialize(self._bias_constraint),
         "use_bias":
             self._use_bias,
         "norm_first":
             self._norm_first,
         "norm_epsilon":
             self._norm_epsilon,
         "inner_dropout":
             self._inner_dropout,
         "attention_initializer":
-            tf.keras.initializers.serialize(self._attention_initializer),
+            tf_keras.initializers.serialize(self._attention_initializer),
         "attention_axes": self._attention_axes,
     }
     base_config = super(ReuseTransformer, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs):
     """Transformer self-attention encoder block call.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/reuse_transformer_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/reuse_transformer_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,83 +12,83 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based transformer block layer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import reuse_transformer
 
 
 @parameterized.named_parameters(
     ('base', reuse_transformer.ReuseTransformer))
 class ReuseTransformerLayerTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(ReuseTransformerLayerTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   def test_layer_creation(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor, _ = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   def test_layer_creation_with_mask(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor, _ = test_layer([data_tensor, mask_tensor])
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   def test_layer_invocation(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(data_tensor, output_tensor)
+    model = tf_keras.Model(data_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = np.random.random_sample(
         (batch_size, sequence_length, width))
     _ = model.predict(input_data)
 
   def test_layer_invocation_with_mask(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -202,27 +202,27 @@
     _ = new_layer([input_data, mask_data])
     new_layer.set_weights(test_layer.get_weights())
     new_output_tensor, _ = new_layer([input_data, mask_data])
     self.assertAllClose(
         new_output_tensor, output_tensor[:, 0:1, :], atol=0.002, rtol=0.01)
 
   def test_layer_invocation_with_float16_dtype(self, transformer_cls):
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = (np.random.random_sample(
         (batch_size, sequence_length, width)))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -232,34 +232,34 @@
     _ = model.predict([input_data, mask_data])
 
   def test_transform_with_initializer(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output, _ = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output.shape.as_list())
 
   def test_dynamic_layer_sequence(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     # Create a 3-dimensional input (the first dimension is implicit).
     width = 30
-    input_tensor = tf.keras.Input(shape=(None, width))
+    input_tensor = tf_keras.Input(shape=(None, width))
     output_tensor, _ = test_layer(input_tensor)
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     input_length = 17
     input_data = np.ones((1, input_length, width))
     output_data = model.predict(input_data)
 
     self.assertAllEqual([1, input_length, width], output_data.shape)
 
@@ -275,15 +275,15 @@
         inner_activation='relu',
         output_dropout=0.1,
         attention_dropout=0.1,
         use_bias=False,
         norm_first=True,
         norm_epsilon=1e-6,
         inner_dropout=0.1,
-        attention_initializer=tf.keras.initializers.RandomUniform(
+        attention_initializer=tf_keras.initializers.RandomUniform(
             minval=0., maxval=1.))
     # Forward path.
     dummy_tensor = tf.zeros([2, 4, 16], dtype=tf.float32)
     dummy_mask = tf.zeros([2, 4, 4], dtype=tf.float32)
     inputs = [dummy_tensor, dummy_mask]
     output, _ = encoder_block(inputs)
     self.assertEqual(output.shape, (2, 4, hidden_size))
@@ -296,15 +296,15 @@
         inner_activation='relu',
         output_dropout=0.1,
         attention_dropout=0.1,
         use_bias=False,
         norm_first=True,
         norm_epsilon=1e-6,
         inner_dropout=0.1,
-        attention_initializer=tf.keras.initializers.RandomUniform(
+        attention_initializer=tf_keras.initializers.RandomUniform(
             minval=0., maxval=1.))
     encoder_block_config = encoder_block.get_config()
     new_encoder_block = reuse_transformer.ReuseTransformer.from_config(
         encoder_block_config)
     self.assertEqual(encoder_block_config, new_encoder_block.get_config())
 
   @parameterized.parameters({'attention_axes': None}, {'attention_axes': [1]},
@@ -321,89 +321,89 @@
         inner_dropout=0.1,
         num_attention_heads=10,
         attention_axes=attention_axes)
     num_rows = 21
     num_cols = 13
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(num_rows, num_cols, width))
+    data_tensor = tf_keras.Input(shape=(num_rows, num_cols, width))
     output_tensor, _ = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   @parameterized.named_parameters(
-      ('plain', False, False, False),
-      ('plain_returnscore', False, True, False),
-      ('plain_with_relative_pe', False, False, True),
-      ('reuse_all', True, False, False),
-      ('reuse_all_returnscore', True, True, False),
-      ('reuse_all_with_relative_pe', True, False, True),
-      ('reuse_5', 5, False, False),
-      ('reuse_5_returnscore', 5, True, False),
-      ('reuse_5_with_relative_pe', 5, False, True),)
-  def test_layer_invocation_with_mask(self, reuse_attention,
-                                      return_attention_scores, use_relative_pe):
+      ('plain_returnscore', False, False),
+      ('plain_with_relative_pe', False, True),
+      ('reuse_all_returnscore', True, False),
+      ('reuse_all_with_relative_pe', True, True),
+      ('reuse_5_returnscore', 5, False),
+      ('reuse_5_with_relative_pe', 5, True),
+  )
+  def test_layer_invocation_with_mask(self, reuse_attention, use_relative_pe):
     test_layer = reuse_transformer.ReuseTransformer(
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu',
         reuse_attention=reuse_attention,
         use_relative_pe=use_relative_pe)
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
-    return_scores_tensor = tf.keras.Input(shape=(1,))
-    reuse_attention_scores = tf.keras.Input(
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
+    reuse_attention_scores = tf_keras.Input(
         shape=(10, sequence_length, sequence_length))
     output_tensor, _ = test_layer(
         [data_tensor, mask_tensor, reuse_attention_scores])
 
     # Create a model from the test layer.
-    model = tf.keras.Model(
-        ([data_tensor, mask_tensor, reuse_attention_scores],
-         return_scores_tensor), output_tensor)
+    model = tf_keras.Model(
+        [
+            data_tensor,
+            mask_tensor,
+            reuse_attention_scores,
+        ],
+        output_tensor,
+    )
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
     # which here is (batch, sequence_length, sequence_length)
     mask_data = np.random.randint(
         2, size=(batch_size, sequence_length, sequence_length))
     reuse_scores = np.random.rand(
         batch_size, 10, sequence_length, sequence_length)
-    _ = model.predict([input_data, mask_data, reuse_scores],
-                      return_attention_scores)
+    _ = model.predict([input_data, mask_data, reuse_scores])
 
   @parameterized.named_parameters(
       ('without_relative_pe_with_pe_max_seq_length_10', False, 10),
       ('with_relative_pe_with_pe_max_seq_length_10', True, 10),
       ('without_relative_pe_with_pe_max_seq_length_100', False, 100),
       ('with_relative_pe_with_pe_max_seq_length_100', True, 100))
   def test_layer_invocation_with_float16_with_relative_pe(
       self, use_relative_pe, pe_max_seq_length):
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     test_layer = reuse_transformer.ReuseTransformer(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu',
         use_relative_pe=use_relative_pe, pe_max_seq_length=pe_max_seq_length)
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = (np.random.random_sample(
         (batch_size, sequence_length, width)))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/rezero_transformer.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/rezero_transformer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,23 +14,23 @@
 
 """Keras-based rezero-transformer block layer (Transformer with ReZero)."""
 # pylint: disable=g-classes-have-attributes
 from typing import Optional
 
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import util
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
+@tf_keras.utils.register_keras_serializable(package="Text")
 @gin.configurable
-class ReZeroTransformer(tf.keras.layers.Layer):
+class ReZeroTransformer(tf_keras.layers.Layer):
   """Transformer layer with ReZero.
 
   This layer implements the Transformer from "Attention Is All You Need".
   (https://arxiv.org/abs/1706.03762).
   The residual connection implements the ReZero method.
   (https://arxiv.org/abs/2003.04887)
 
@@ -89,20 +89,20 @@
 
     self._num_heads = num_attention_heads
     self._inner_dim = inner_dim
     self._inner_activation = inner_activation
     self._attention_dropout_rate = attention_dropout_rate
     self._dropout_rate = dropout_rate
     self._output_range = output_range
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
     self._use_layer_norm = use_layer_norm
     self._share_rezero = share_rezero
 
   def build(self, input_shape):
     if isinstance(input_shape, tf.TensorShape):
       input_tensor_shape = input_shape
     elif isinstance(input_shape, (list, tuple)):
@@ -134,74 +134,74 @@
     self._attention_head_size = int(hidden_size // self._num_heads)
     common_kwargs = dict(
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer,
         activity_regularizer=self._activity_regularizer,
         kernel_constraint=self._kernel_constraint,
         bias_constraint=self._bias_constraint)
-    self._attention_layer = tf.keras.layers.MultiHeadAttention(
+    self._attention_layer = tf_keras.layers.MultiHeadAttention(
         num_heads=self._num_heads,
         key_dim=self._attention_head_size,
         dropout=self._attention_dropout_rate,
         name="self_attention",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
-    self._attention_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self._attention_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
     if self._use_layer_norm:
       # Use float32 in layernorm for numeric stability.
       # It is probably safe in mixed_float16, but we haven't validated this yet.
       self._attention_layer_norm = (
-          tf.keras.layers.LayerNormalization(
+          tf_keras.layers.LayerNormalization(
               name="self_attention_layer_norm",
               axis=-1,
               epsilon=1e-12,
               dtype=tf.float32))
-    self._intermediate_dense = tf.keras.layers.EinsumDense(
+    self._intermediate_dense = tf_keras.layers.EinsumDense(
         "abc,cd->abd",
         output_shape=(None, self._inner_dim),
         bias_axes="d",
         name="intermediate",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
-    policy = tf.keras.mixed_precision.global_policy()
+    policy = tf_keras.mixed_precision.global_policy()
     if policy.name == "mixed_bfloat16":
       # bfloat16 causes BERT with the LAMB optimizer to not converge
       # as well, so we use float32.
       # TODO(b/154538392): Investigate this.
       policy = tf.float32
-    self._inner_activation_layer = tf.keras.layers.Activation(
+    self._inner_activation_layer = tf_keras.layers.Activation(
         self._inner_activation, dtype=policy)
-    self._output_dense = tf.keras.layers.EinsumDense(
+    self._output_dense = tf_keras.layers.EinsumDense(
         "abc,cd->abd",
         output_shape=(None, hidden_size),
         bias_axes="d",
         name="output",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
-    self._output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self._output_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
     if self._use_layer_norm:
       # Use float32 in layernorm for numeric stability.
-      self._output_layer_norm = tf.keras.layers.LayerNormalization(
+      self._output_layer_norm = tf_keras.layers.LayerNormalization(
           name="output_layer_norm", axis=-1, epsilon=1e-12, dtype=tf.float32)
 
     self._rezero_a = self.add_weight(
         name="rezero_alpha",
-        initializer=tf.keras.initializers.Zeros(),
+        initializer=tf_keras.initializers.Zeros(),
         trainable=True,
         dtype=tf.float32)
 
     if self._share_rezero:
       self._rezero_a_ffn = self._rezero_a
     else:
       self._rezero_a_ffn = self.add_weight(
           name="rezero_alpha_ffn",
-          initializer=tf.keras.initializers.Zeros(),
+          initializer=tf_keras.initializers.Zeros(),
           trainable=True,
           dtype=tf.float32)
 
     super().build(input_shape)
 
   def get_config(self):
     config = {
@@ -218,27 +218,27 @@
         "output_range":
             self._output_range,
         "use_layer_norm":
             self._use_layer_norm,
         "share_rezero":
             self._share_rezero,
         "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
+            tf_keras.initializers.serialize(self._kernel_initializer),
         "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
+            tf_keras.initializers.serialize(self._bias_initializer),
         "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
+            tf_keras.regularizers.serialize(self._kernel_regularizer),
         "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
+            tf_keras.regularizers.serialize(self._bias_regularizer),
         "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
+            tf_keras.regularizers.serialize(self._activity_regularizer),
         "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
+            tf_keras.constraints.serialize(self._kernel_constraint),
         "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint),
+            tf_keras.constraints.serialize(self._bias_constraint),
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def reset_rezero(self):
     self._rezero_a.assign(0.)
     if not self._share_rezero:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/rezero_transformer_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/rezero_transformer_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,48 +12,44 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based rezero-transformer block layer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import rezero_transformer
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class TransformerWithReZeroLayerTest(keras_parameterized.TestCase):
+class TransformerWithReZeroLayerTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(TransformerWithReZeroLayerTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   @parameterized.named_parameters(('no_share_attn_ffn', False),
                                   ('share_attn_ffn', True))
   def test_layer_invocation_with_float16_dtype(self, share_rezero):
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     test_layer = rezero_transformer.ReZeroTransformer(
         num_attention_heads=10,
         intermediate_size=2048,
         intermediate_activation='relu',
         share_rezero=share_rezero)
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = (10 * np.random.random_sample(
         (batch_size, sequence_length, width)))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -66,17 +62,17 @@
     test_layer = rezero_transformer.ReZeroTransformer(
         num_attention_heads=10,
         intermediate_size=2048,
         intermediate_activation='relu',
         use_layer_norm=False)
 
     input_length, width = 16, 30
-    input_tensor = tf.keras.Input(shape=(input_length, width))
+    input_tensor = tf_keras.Input(shape=(input_length, width))
     output_tensor = test_layer(input_tensor)
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     input_data = np.random.rand(2, input_length, width)
     test_layer._rezero_a.assign(1.0)
     test_layer.reset_rezero()
     output_data = model.predict(input_data)
 
     self.assertAllClose(input_data, output_data)
@@ -85,17 +81,17 @@
     test_layer = rezero_transformer.ReZeroTransformer(
         num_attention_heads=10,
         intermediate_size=2048,
         intermediate_activation='relu',
         use_layer_norm=True)
 
     input_length, width = 16, 30
-    input_tensor = tf.keras.Input(shape=(input_length, width))
+    input_tensor = tf_keras.Input(shape=(input_length, width))
     output_tensor = test_layer(input_tensor)
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     input_data = np.random.rand(2, input_length, width) + 2.0
     output_data = model.predict(input_data)
     input_data_normed = (input_data -
                          np.mean(input_data, axis=-1, keepdims=True)) / (
                              np.std(input_data, axis=-1, keepdims=True))
 
@@ -132,15 +128,15 @@
     self.assertAllClose(new_output_tensor, output_tensor, atol=5e-5, rtol=0.003)
 
   def test_separate_qkv(self):
     test_layer = rezero_transformer.ReZeroTransformer(
         num_attention_heads=2,
         intermediate_size=128,
         intermediate_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     # Forward path.
     q_tensor = tf.zeros([2, 4, 16], dtype=tf.float32)
     kv_tensor = tf.zeros([2, 8, 16], dtype=tf.float32)
     dummy_mask = tf.zeros([2, 4, 8], dtype=tf.float32)
     inputs = [q_tensor, kv_tensor, dummy_mask]
     output = test_layer(inputs)
     self.assertEqual(output.shape, q_tensor.shape)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/routing.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/routing.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,19 +14,19 @@
 
 """Layers for Mixture of Experts (MoE) routing.
 
 For MoE routing, we need to separate a set of tokens to sets of tokens.
 Later on, different sets of tokens can potentially go to different experts.
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class TokenImportanceWithMovingAvg(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class TokenImportanceWithMovingAvg(tf_keras.layers.Layer):
   """Routing based on per-token importance value."""
 
   def __init__(self,
                vocab_size,
                init_importance,
                moving_average_beta=0.995,
                **kwargs):
@@ -35,15 +35,15 @@
     self._moving_average_beta = moving_average_beta
     super().__init__(**kwargs)
 
   def build(self, input_shape):
     self._importance_embedding = self.add_weight(
         name="importance_embed",
         shape=(self._vocab_size),
-        initializer=tf.keras.initializers.Constant(self._init_importance),
+        initializer=tf_keras.initializers.Constant(self._init_importance),
         trainable=False)
 
   def get_config(self):
     config = {
         "vocab_size":
             self._vocab_size,
         "init_importance":
@@ -66,16 +66,16 @@
         old_importance * beta + tf.cast(importance * (1.0 - beta),
                                         dtype=tf.float32)))
 
   def call(self, inputs):
     return tf.gather(self._importance_embedding, inputs)
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class SelectTopK(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class SelectTopK(tf_keras.layers.Layer):
   """Select top-k + random-k tokens according to importance."""
 
   def __init__(self,
                top_k=None,
                random_k=None,
                **kwargs):
     self._top_k = top_k
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/routing_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/routing_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for routing."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import routing
 
 
 class TokenImportanceTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_token_importance(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/self_attention_mask.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/self_attention_mask.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras layer that creates a self-attention mask."""
 from typing import Optional
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def get_mask(inputs: tf.Tensor,
              to_mask: tf.Tensor,
              dtype: Optional[tf.DType] = None) -> tf.Tensor:
   """Gets a 3D self-attention mask.
 
@@ -41,16 +41,16 @@
 
   to_mask = tf.cast(
       tf.reshape(to_mask, [batch_size, 1, to_seq_length]), dtype=dtype)
 
   return tf.broadcast_to(to_mask, [batch_size, from_seq_length, to_seq_length])
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class SelfAttentionMask(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class SelfAttentionMask(tf_keras.layers.Layer):
   """Create 3D attention mask from a 2D tensor mask.
 
     inputs[0]: from_tensor: 2D or 3D Tensor of shape
       [batch_size, from_seq_length, ...].
     inputs[1]: to_mask: int32 Tensor of shape [batch_size, to_seq_length].
 
     Returns:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/spectral_normalization.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/spectral_normalization.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -26,32 +26,32 @@
 
 [3] Henry Gouk, Eibe Frank, Bernhard Pfahringer, Michael Cree.
     Regularisation of neural networks by enforcing lipschitz continuity.
     _arXiv preprint arXiv:1804.04368_, 2018. https://arxiv.org/abs/1804.04368
 """
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-class SpectralNormalization(tf.keras.layers.Wrapper):
+class SpectralNormalization(tf_keras.layers.Wrapper):
   """Implements spectral normalization for Dense layer."""
 
   def __init__(self,
                layer,
                iteration=1,
                norm_multiplier=0.95,
                training=True,
                aggregation=tf.VariableAggregation.MEAN,
                inhere_layer_name=False,
                **kwargs):
     """Initializer.
 
     Args:
-      layer: (tf.keras.layers.Layer) A TF Keras layer to apply normalization to.
+      layer: (tf_keras.layers.Layer) A TF Keras layer to apply normalization to.
       iteration: (int) The number of power iteration to perform to estimate
         weight matrix's singular value.
       norm_multiplier: (float) Multiplicative constant to threshold the
         normalization. Usually under normalization, the singular value will
         converge to this value.
       training: (bool) Whether to perform power iteration to update the singular
         value estimate.
@@ -67,21 +67,21 @@
     self.norm_multiplier = norm_multiplier
 
     # Set layer name.
     wrapper_name = kwargs.pop('name', None)
     if inhere_layer_name:
       wrapper_name = layer.name
 
-    if not isinstance(layer, tf.keras.layers.Layer):
-      raise ValueError('`layer` must be a `tf.keras.layer.Layer`. '
+    if not isinstance(layer, tf_keras.layers.Layer):
+      raise ValueError('`layer` must be a `tf_keras.layer.Layer`. '
                        'Observed `{}`'.format(layer))
     super().__init__(
         layer, name=wrapper_name, **kwargs)
 
-  def build(self, input_shape):
+  def build(self, input_shape):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     super().build(input_shape)
     self.layer.kernel._aggregation = self.aggregation  # pylint: disable=protected-access
     self._dtype = self.layer.kernel.dtype
 
     self.w = self.layer.kernel
     self.w_shape = self.w.shape.as_list()
 
@@ -146,29 +146,29 @@
     return u_update_op, v_update_op, w_update_op
 
   def restore_weights(self):
     """Restores layer weights to maintain gradient update (See Alg 1 of [1])."""
     return self.layer.kernel.assign(self.w)
 
 
-class SpectralNormalizationConv2D(tf.keras.layers.Wrapper):
+class SpectralNormalizationConv2D(tf_keras.layers.Wrapper):
   """Implements spectral normalization for Conv2D layer based on [3]."""
 
   def __init__(self,
                layer,
                iteration=1,
                norm_multiplier=0.95,
                training=True,
                aggregation=tf.VariableAggregation.MEAN,
                legacy_mode=False,
                **kwargs):
     """Initializer.
 
     Args:
-      layer: (tf.keras.layers.Layer) A TF Keras layer to apply normalization to.
+      layer: (tf_keras.layers.Layer) A TF Keras layer to apply normalization to.
       iteration: (int) The number of power iteration to perform to estimate
         weight matrix's singular value.
       norm_multiplier: (float) Multiplicative constant to threshold the
         normalization. Usually under normalization, the singular value will
         converge to this value.
       training: (bool) Whether to perform power iteration to update the singular
         value estimate.
@@ -185,21 +185,21 @@
     self.aggregation = aggregation
     self.norm_multiplier = norm_multiplier
     self.legacy_mode = legacy_mode
 
     # Set layer attributes.
     layer._name += '_spec_norm'
 
-    if not isinstance(layer, tf.keras.layers.Conv2D):
+    if not isinstance(layer, tf_keras.layers.Conv2D):
       raise ValueError(
-          'layer must be a `tf.keras.layer.Conv2D` instance. You passed: {input}'
+          'layer must be a `tf_keras.layer.Conv2D` instance. You passed: {input}'
           .format(input=layer))
     super().__init__(layer, **kwargs)
 
-  def build(self, input_shape):
+  def build(self, input_shape):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     if not self.layer.built:
       self.layer.build(input_shape)
     self.layer.kernel._aggregation = self.aggregation  # pylint: disable=protected-access
     self._dtype = self.layer.kernel.dtype
 
     # Shape (kernel_size_1, kernel_size_2, in_channel, out_channel).
     self.w = self.layer.kernel
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/spectral_normalization_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/spectral_normalization_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,20 +19,20 @@
 [1] Hanie Sedghi, Vineet Gupta, Philip M. Long.
     The Singular Values of Convolutional Layers.
     In _International Conference on Learning Representations_, 2019.
 """
 from absl.testing import parameterized
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.layers import spectral_normalization
 
-DenseLayer = tf.keras.layers.Dense(10)
-Conv2DLayer = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='valid')
+DenseLayer = tf_keras.layers.Dense(10)
+Conv2DLayer = tf_keras.layers.Conv2D(filters=64, kernel_size=3, padding='valid')
 
 
 def _compute_spectral_norm(weight):
   if weight.ndim > 2:
     # Computes Conv2D via FFT transform as in [1].
     weight = np.fft.fft2(weight, weight.shape[1:3], axes=[0, 1])
   return np.max(np.linalg.svd(weight, compute_uv=False))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/talking_heads_attention.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/talking_heads_attention.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,32 +14,32 @@
 
 """Talking Head Attention layer."""
 # pylint: disable=g-classes-have-attributes
 import math
 import string
 
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 _CHR_IDX = string.ascii_lowercase
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
+@tf_keras.utils.register_keras_serializable(package="Text")
 @gin.configurable
-class TalkingHeadsAttention(tf.keras.layers.MultiHeadAttention):
+class TalkingHeadsAttention(tf_keras.layers.MultiHeadAttention):
   """Implements Talking-Heads Attention.
 
   This is an implementation of Talking-Heads Attention based on the paper
   Talking-Heads Attention (https://arxiv.org/abs/2003.02436): it enhanced
   multi-head attention by including linearprojections across the attention-heads
   dimension, immediately before and after the softmax operation.
 
-  See the base class `tf.keras.layers.MultiHeadAttention` for more details.
+  See the base class `tf_keras.layers.MultiHeadAttention` for more details.
 
   Args:
     num_heads: Number of attention heads.
     key_dim: Size of each attention head for query and key.
     value_dim:  Size of each attention head for value.
     dropout: Dropout probability.
     use_bias: Boolean, whether the dense layers use bias vectors/matrices.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/talking_heads_attention_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/talking_heads_attention_test.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,77 +12,73 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for the attention layer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import talking_heads_attention
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
 # This test is revised base on attention.MultiHeadAttentionTest.
-@keras_parameterized.run_all_keras_modes
-class TalkingHeadsAttentionTest(keras_parameterized.TestCase):
+class TalkingHeadsAttentionTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(
       ("key_value_same_proj", None, None, [40, 80]),
       ("key_value_different_proj", 32, 60, [40, 60]),
   )
   def test_non_masked_attention(self, value_dim, output_shape, output_dims):
     """Test that the attention layer can be created without a mask tensor."""
     test_layer = talking_heads_attention.TalkingHeadsAttention(
         num_heads=12,
         key_dim=64,
         value_dim=value_dim,
         output_shape=output_shape)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
-    value = tf.keras.Input(shape=(20, 80))
+    query = tf_keras.Input(shape=(40, 80))
+    value = tf_keras.Input(shape=(20, 80))
     output = test_layer(query=query, value=value)
     self.assertEqual(output.shape.as_list(), [None] + output_dims)
 
   def test_non_masked_self_attention(self):
     """Test with one input (self-attenntion) and no mask tensor."""
     test_layer = talking_heads_attention.TalkingHeadsAttention(
         num_heads=12, key_dim=64)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
+    query = tf_keras.Input(shape=(40, 80))
     output = test_layer(query=query, value=query)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
 
   def test_attention_scores(self):
     """Test attention outputs with coefficients."""
     test_layer = talking_heads_attention.TalkingHeadsAttention(
         num_heads=12, key_dim=64)
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
+    query = tf_keras.Input(shape=(40, 80))
     output, coef = test_layer(query=query, value=query,
                               return_attention_scores=True)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
     self.assertEqual(coef.shape.as_list(), [None, 12, 40, 40])
 
   @parameterized.named_parameters(("with_bias", True), ("no_bias", False))
   def test_masked_attention(self, use_bias):
     """Test with a mask tensor."""
     test_layer = talking_heads_attention.TalkingHeadsAttention(
         num_heads=12, key_dim=2, use_bias=use_bias)
     # Create a 3-dimensional input (the first dimension is implicit).
     batch_size = 3
-    query = tf.keras.Input(shape=(4, 8))
-    value = tf.keras.Input(shape=(2, 8))
-    mask_tensor = tf.keras.Input(shape=(4, 2))
+    query = tf_keras.Input(shape=(4, 8))
+    value = tf_keras.Input(shape=(2, 8))
+    mask_tensor = tf_keras.Input(shape=(4, 2))
     output = test_layer(query=query, value=value, attention_mask=mask_tensor)
 
     # Create a model containing the test layer.
-    model = tf.keras.Model([query, value, mask_tensor], output)
+    model = tf_keras.Model([query, value, mask_tensor], output)
 
     # Generate data for the input (non-mask) tensors.
     from_data = 10 * np.random.random_sample((batch_size, 4, 8))
     to_data = 10 * np.random.random_sample((batch_size, 2, 8))
 
     # Invoke the data with a random set of mask data. This should mask at least
     # one element.
@@ -94,18 +90,18 @@
     unmasked_output_data = model.predict([from_data, to_data, null_mask_data])
 
     # Because one data is masked and one is not, the outputs should not be the
     # same.
     self.assertNotAllClose(masked_output_data, unmasked_output_data)
 
     # Tests the layer with three inputs: Q, K, V.
-    key = tf.keras.Input(shape=(2, 8))
+    key = tf_keras.Input(shape=(2, 8))
     output = test_layer(
         query=query, value=value, key=key, attention_mask=mask_tensor)
-    model = tf.keras.Model([query, value, key, mask_tensor], output)
+    model = tf_keras.Model([query, value, key, mask_tensor], output)
 
     masked_output_data = model.predict([from_data, to_data, to_data, mask_data])
     unmasked_output_data = model.predict(
         [from_data, to_data, to_data, null_mask_data])
     # Because one data is masked and one is not, the outputs should not be the
     # same.
     self.assertNotAllClose(masked_output_data, unmasked_output_data)
@@ -118,17 +114,17 @@
       self.assertLen(test_layer._output_dense.trainable_variables, 1)
 
   def test_initializer(self):
     """Test with a specified initializer."""
     test_layer = talking_heads_attention.TalkingHeadsAttention(
         num_heads=12,
         key_dim=64,
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     # Create a 3-dimensional input (the first dimension is implicit).
-    query = tf.keras.Input(shape=(40, 80))
+    query = tf_keras.Input(shape=(40, 80))
     output = test_layer(query=query, value=query)
     self.assertEqual(output.shape.as_list(), [None, 40, 80])
 
   @parameterized.named_parameters(
       ("4d_inputs_one_free_batch", [3, 4], [3, 2], [4, 2], (2,)),
       ("4D_inputs_2D_attention", [3, 4], [3, 2], [3, 4, 3, 2], (1, 2)),
       ("5D_inputs_2D_attention", [5, 3, 4], [5, 3, 2], [3, 4, 3, 2], (2, 3)))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/text_layers.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/text_layers.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Keras Layers for BERT-specific preprocessing."""
 # pylint: disable=g-import-not-at-top
 from typing import Any, Dict, List, Mapping, Optional, Text, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 try:
   # pytype: disable=import-error
   import tensorflow_text as text
   from tensorflow_text.python.ops import bert_tokenizer
   # pytype: enable=import-error
 except ImportError:
@@ -54,15 +54,15 @@
   flat_values_shape = [None] * ragged_tensor.flat_values.shape.rank
   result = result.with_flat_values(
       tf.ensure_shape(result.flat_values, flat_values_shape))
 
   return result
 
 
-class BertTokenizer(tf.keras.layers.Layer):
+class BertTokenizer(tf_keras.layers.Layer):
   """Wraps TF.Text's BertTokenizer with pre-defined vocab as a Keras Layer.
 
   Attributes:
     tokenize_with_offsets: If true, calls
       `text.BertTokenizer.tokenize_with_offsets()` instead of plain
       `text.BertTokenizer.tokenize()` and outputs a triple of
       `(tokens, start_offsets, limit_offsets)`.
@@ -231,15 +231,15 @@
           result[k] = v
         else:
           logging.warning("Could not find %s as token \"%s\" in vocab file %s",
                           k, special_tokens[k], vocab_file)
     return result
 
 
-class SentencepieceTokenizer(tf.keras.layers.Layer):
+class SentencepieceTokenizer(tf_keras.layers.Layer):
   """Wraps `tf_text.SentencepieceTokenizer` as a Keras Layer.
 
   Attributes:
     tokenize_with_offsets: If true, calls
       `SentencepieceTokenizer.tokenize_with_offsets()`
       instead of plain `.tokenize()` and outputs a triple of
       `(tokens, start_offsets, limit_offsets)`.
@@ -433,15 +433,15 @@
         else:
           logging.warning(
               "Could not find %s as token \"%s\" in sentencepiece model, "
               "got \"%s\"", name, special_tokens[name], inverse_token)
     return result
 
 
-class BertPackInputs(tf.keras.layers.Layer):
+class BertPackInputs(tf_keras.layers.Layer):
   """Packs tokens into model inputs for BERT."""
 
   def __init__(self,
                seq_length,
                *,
                start_of_sequence_id=None,
                end_of_segment_id=None,
@@ -598,15 +598,15 @@
       return tf.reshape(t, output_shape)
     # Assemble nest of input tensors as expected by BERT TransformerEncoder.
     return dict(input_word_ids=_reshape(input_word_ids),
                 input_mask=_reshape(input_mask),
                 input_type_ids=_reshape(input_type_ids))
 
 
-class FastWordpieceBertTokenizer(tf.keras.layers.Layer):
+class FastWordpieceBertTokenizer(tf_keras.layers.Layer):
   """A bert tokenizer keras layer using text.FastWordpieceTokenizer.
 
   See details: "Fast WordPiece Tokenization" (https://arxiv.org/abs/2012.15524)
   """
 
   def __init__(self,
                *,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/text_layers_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/text_layers_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests bert.text_layers."""
 
 import os
 import tempfile
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow import estimator as tf_estimator
 
 from sentencepiece import SentencePieceTrainer
 from official.nlp.modeling.layers import text_layers
 
 
 # This test covers the in-process behavior of a BertTokenizer layer.
@@ -99,24 +99,24 @@
     vocab_file = self._make_vocab_file(
         ["[PAD]", "[UNK]", "[CLS]", "[SEP]", "d", "##ef", "abc", "xy"])
 
     def input_fn():
       with tf.init_scope():
         self.assertFalse(tf.executing_eagerly())
       # Build a preprocessing Model.
-      sentences = tf.keras.layers.Input(shape=[], dtype=tf.string)
+      sentences = tf_keras.layers.Input(shape=[], dtype=tf.string)
       bert_tokenizer = text_layers.BertTokenizer(
           vocab_file=vocab_file, lower_case=True)
       special_tokens_dict = bert_tokenizer.get_special_tokens_dict()
       for k, v in special_tokens_dict.items():
         self.assertIsInstance(v, int, "Unexpected type for {}".format(k))
       tokens = bert_tokenizer(sentences)
       packed_inputs = text_layers.BertPackInputs(
           4, special_tokens_dict=special_tokens_dict)(tokens)
-      preprocessing = tf.keras.Model(sentences, packed_inputs)
+      preprocessing = tf_keras.Model(sentences, packed_inputs)
       # Map the dataset.
       ds = tf.data.Dataset.from_tensors(
           (tf.constant(["abc", "DEF"]), tf.constant([0, 1])))
       ds = ds.map(lambda features, labels: (preprocessing(features), labels))
       return ds
 
     def model_fn(features, labels, mode):
@@ -210,24 +210,24 @@
   def test_special_tokens_in_estimator(self):
     """Tests getting special tokens without an Eager init context."""
 
     def input_fn():
       with tf.init_scope():
         self.assertFalse(tf.executing_eagerly())
       # Build a preprocessing Model.
-      sentences = tf.keras.layers.Input(shape=[], dtype=tf.string)
+      sentences = tf_keras.layers.Input(shape=[], dtype=tf.string)
       sentencepiece_tokenizer = text_layers.SentencepieceTokenizer(
           model_file_path=self._spm_path, lower_case=True, nbest_size=0)
       special_tokens_dict = sentencepiece_tokenizer.get_special_tokens_dict()
       for k, v in special_tokens_dict.items():
         self.assertIsInstance(v, int, "Unexpected type for {}".format(k))
       tokens = sentencepiece_tokenizer(sentences)
       packed_inputs = text_layers.BertPackInputs(
           4, special_tokens_dict=special_tokens_dict)(tokens)
-      preprocessing = tf.keras.Model(sentences, packed_inputs)
+      preprocessing = tf_keras.Model(sentences, packed_inputs)
       # Map the dataset.
       ds = tf.data.Dataset.from_tensors(
           (tf.constant(["abc", "DEF"]), tf.constant([0, 1])))
       ds = ds.map(lambda features, labels: (preprocessing(features), labels))
       return ds
 
     def model_fn(features, labels, mode):
@@ -290,17 +290,17 @@
     token_ids_2 = new_tokenizer(inputs)
     self.assertAllEqual(token_ids, token_ids_2)
 
   # TODO(b/170480226): Remove once tf_hub_export_lib_test.py covers saving.
   def test_saving(self):
     sentencepiece_tokenizer = text_layers.SentencepieceTokenizer(
         model_file_path=self._spm_path, lower_case=True, nbest_size=0)
-    inputs = tf.keras.layers.Input([], dtype=tf.string)
+    inputs = tf_keras.layers.Input([], dtype=tf.string)
     outputs = sentencepiece_tokenizer(inputs)
-    model = tf.keras.Model(inputs, outputs)
+    model = tf_keras.Model(inputs, outputs)
     export_path = tempfile.mkdtemp(dir=self.get_temp_dir())
     model.save(export_path, signatures={})
 
 
 class BertPackInputsTest(tf.test.TestCase):
 
   def test_round_robin_correct_outputs(self):
@@ -516,24 +516,24 @@
     vocab_file = self._make_vocab_file(
         ["[PAD]", "[UNK]", "[CLS]", "[SEP]", "d", "##ef", "abc", "xy"])
 
     def input_fn():
       with tf.init_scope():
         self.assertFalse(tf.executing_eagerly())
       # Build a preprocessing Model.
-      sentences = tf.keras.layers.Input(shape=[], dtype=tf.string)
+      sentences = tf_keras.layers.Input(shape=[], dtype=tf.string)
       bert_tokenizer = text_layers.FastWordpieceBertTokenizer(
           vocab_file=vocab_file, lower_case=True)
       special_tokens_dict = bert_tokenizer.get_special_tokens_dict()
       for k, v in special_tokens_dict.items():
         self.assertIsInstance(v, int, "Unexpected type for {}".format(k))
       tokens = bert_tokenizer(sentences)
       packed_inputs = text_layers.BertPackInputs(
           4, special_tokens_dict=special_tokens_dict)(tokens)
-      preprocessing = tf.keras.Model(sentences, packed_inputs)
+      preprocessing = tf_keras.Model(sentences, packed_inputs)
       # Map the dataset.
       ds = tf.data.Dataset.from_tensors(
           (tf.constant(["abc", "DEF"]), tf.constant([0, 1])))
       ds = ds.map(lambda features, labels: (preprocessing(features), labels))
       return ds
 
     def model_fn(features, labels, mode):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/tn_expand_condense.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/tn_expand_condense.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,24 +11,24 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """ExpandCondense tensor network layer used in TN-BERT."""
 # pylint: disable=g-classes-have-attributes
 from typing import List, Optional, Text, Any, Dict
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
-Layer = tf.keras.layers.Layer
-activations = tf.keras.activations
-initializers = tf.keras.initializers
+Layer = tf_keras.layers.Layer
+activations = tf_keras.activations
+initializers = tf_keras.initializers
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 class TNExpandCondense(Layer):
   """A TPU-optimized TensorNetwork layer.
 
   Designed for use in models that currently use Dense layers to achieve
   up projection followed by down projection.
 
   This layer is a TPU-optimized combination of 3 operations:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/tn_expand_condense_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/tn_expand_condense_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,55 +14,40 @@
 
 """Tests for ExpandCondense tensor network layer."""
 
 import os
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.nlp.modeling.layers.tn_expand_condense import TNExpandCondense
 
 
 class TNLayerTest(tf.test.TestCase, parameterized.TestCase):
   """Unit tests for ExpandCondense TN layer.
   """
 
   def setUp(self):
-    super(TNLayerTest, self).setUp()
+    super().setUp()
     self.labels = np.concatenate((np.ones((50, 1)), np.zeros((50, 1))), axis=0)
 
   def _build_model(self, data, proj_multiple=2):
-    model = tf.keras.models.Sequential()
+    model = tf_keras.models.Sequential()
     model.add(
         TNExpandCondense(
             proj_multiplier=proj_multiple,
             use_bias=True,
             activation='relu',
             input_shape=(data.shape[-1],)))
-    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
+    model.add(tf_keras.layers.Dense(1, activation='sigmoid'))
     return model
 
   @parameterized.parameters((768, 6), (1024, 2))
-  def test_keras_layer(self, input_dim, proj_multiple):
-    data = np.random.normal(size=(100, input_dim))
-    data = data.astype(np.float32)
-    tf.keras.__internal__.utils.layer_test(
-        TNExpandCondense,
-        kwargs={
-            'proj_multiplier': proj_multiple,
-            'input_shape': data.shape
-        },
-        input_shape=data.shape,
-        input_data=data,
-        expected_output_shape=(None, data.shape[-1]),
-        expected_output_dtype=data.dtype)
-
-  @parameterized.parameters((768, 6), (1024, 2))
   def test_train(self, input_dim, proj_multiple):
-    tf.keras.utils.set_random_seed(0)
+    tf_keras.utils.set_random_seed(0)
     data = np.random.randint(10, size=(100, input_dim))
     model = self._build_model(data, proj_multiple)
 
     model.compile(
         optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
 
     # Train the model for 5 epochs
@@ -71,15 +56,15 @@
     # Check that loss decreases and accuracy increases
     self.assertGreater(history.history['loss'][0], history.history['loss'][-1])
     self.assertLess(
         history.history['accuracy'][0], history.history['accuracy'][-1])
 
   @parameterized.parameters((768, 6), (1024, 2))
   def test_weights_change(self, input_dim, proj_multiple):
-    tf.keras.utils.set_random_seed(0)
+    tf_keras.utils.set_random_seed(0)
     data = np.random.randint(10, size=(100, input_dim))
     model = self._build_model(data, proj_multiple)
     model.compile(
         optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
 
     before = model.get_weights()
 
@@ -101,15 +86,15 @@
 
     self.assertEqual(expected_output_shape, actual_output_shape)
 
   @parameterized.parameters((768, 6), (1024, 2))
   def test_expandcondense_num_parameters(self, input_dim, proj_multiple):
     data = np.random.randint(10, size=(100, input_dim))
     proj_size = proj_multiple * data.shape[-1]
-    model = tf.keras.models.Sequential()
+    model = tf_keras.models.Sequential()
     model.add(
         TNExpandCondense(
             proj_multiplier=proj_multiple,
             use_bias=True,
             activation='relu',
             input_shape=(data.shape[-1],)))
 
@@ -161,14 +146,14 @@
         optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
 
     # Train the model for 5 epochs
     model.fit(data, self.labels, epochs=5, batch_size=32)
 
     save_path = os.path.join(self.get_temp_dir(), 'test_model')
     model.save(save_path)
-    loaded_model = tf.keras.models.load_model(save_path)
+    loaded_model = tf_keras.models.load_model(save_path)
 
     # Compare model predictions and loaded_model predictions
     self.assertAllEqual(model.predict(data), loaded_model.predict(data))
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/tn_transformer_expand_condense.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/tn_transformer_expand_condense.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,23 +13,23 @@
 # limitations under the License.
 
 """TN-BERT TNTransformerExpandCondense employing Expand-Condense layer instead of Dense."""
 # pylint: disable=g-classes-have-attributes
 # Import libraries
 
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers.tn_expand_condense import TNExpandCondense
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
+@tf_keras.utils.register_keras_serializable(package="Text")
 @gin.configurable
-class TNTransformerExpandCondense(tf.keras.layers.Layer):
+class TNTransformerExpandCondense(tf_keras.layers.Layer):
   """Transformer layer using tensor network Expand-Condense layer.
 
   This layer implements the Transformer from transformer.py, with a single
   tensor network layer replacing the usual intermediate and output Dense
   layers.
 
   Args:
@@ -82,27 +82,27 @@
 
     self._num_heads = num_attention_heads
     self._intermediate_size = intermediate_size
     self._intermediate_activation = intermediate_activation
     self._attention_dropout_rate = attention_dropout_rate
     self._dropout_rate = dropout_rate
     self._output_range = output_range
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._activity_regularizer = tf.keras.regularizers.get(activity_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._activity_regularizer = tf_keras.regularizers.get(activity_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
     self._use_bias = use_bias
     self._norm_first = norm_first
     self._norm_epsilon = norm_epsilon
     self._intermediate_dropout = intermediate_dropout
     if attention_initializer:
-      self._attention_initializer = tf.keras.initializers.get(
+      self._attention_initializer = tf_keras.initializers.get(
           attention_initializer)
     else:
       self._attention_initializer = tf_utils.clone_initializer(
           self._kernel_initializer)
 
   def build(self, input_shape):
     input_tensor = input_shape[0] if len(input_shape) == 2 else input_shape
@@ -131,44 +131,44 @@
     self._attention_head_size = int(hidden_size // self._num_heads)
     common_kwargs = dict(
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer,
         activity_regularizer=self._activity_regularizer,
         kernel_constraint=self._kernel_constraint,
         bias_constraint=self._bias_constraint)
-    self._attention_layer = tf.keras.layers.MultiHeadAttention(
+    self._attention_layer = tf_keras.layers.MultiHeadAttention(
         num_heads=self._num_heads,
         key_dim=self._attention_head_size,
         dropout=self._attention_dropout_rate,
         use_bias=self._use_bias,
         kernel_initializer=self._attention_initializer,
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         name="self_attention",
         **common_kwargs)
-    self._attention_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self._attention_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
     # Use float32 in layernorm for numeric stability.
     # It is probably safe in mixed_float16, but we haven't validated this yet.
     self._attention_layer_norm = (
-        tf.keras.layers.LayerNormalization(
+        tf_keras.layers.LayerNormalization(
             name="self_attention_layer_norm",
             axis=-1,
             epsilon=self._norm_epsilon,
             dtype=tf.float32))
 
     # Substitute Dense layers with a single Expand-Condense layer.
     self._output_dense = TNExpandCondense(
         4,
         use_bias=True,
         activation=self._intermediate_activation,
         kernel_initializer=self._kernel_initializer,
         bias_initializer=self._bias_initializer)
 
-    self._output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self._output_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
     # Use float32 in layernorm for numeric stability.
-    self._output_layer_norm = tf.keras.layers.LayerNormalization(
+    self._output_layer_norm = tf_keras.layers.LayerNormalization(
         name="output_layer_norm",
         axis=-1,
         epsilon=self._norm_epsilon,
         dtype=tf.float32)
 
     super().build(input_shape)
 
@@ -183,37 +183,37 @@
         "dropout_rate":
             self._dropout_rate,
         "attention_dropout_rate":
             self._attention_dropout_rate,
         "output_range":
             self._output_range,
         "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
+            tf_keras.initializers.serialize(self._kernel_initializer),
         "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
+            tf_keras.initializers.serialize(self._bias_initializer),
         "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
+            tf_keras.regularizers.serialize(self._kernel_regularizer),
         "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
+            tf_keras.regularizers.serialize(self._bias_regularizer),
         "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
+            tf_keras.regularizers.serialize(self._activity_regularizer),
         "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
+            tf_keras.constraints.serialize(self._kernel_constraint),
         "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint),
+            tf_keras.constraints.serialize(self._bias_constraint),
         "use_bias":
             self._use_bias,
         "norm_first":
             self._norm_first,
         "norm_epsilon":
             self._norm_epsilon,
         "intermediate_dropout":
             self._intermediate_dropout,
         "attention_initializer":
-            tf.keras.initializers.serialize(self._attention_initializer)
+            tf_keras.initializers.serialize(self._attention_initializer)
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs):
     if isinstance(inputs, (list, tuple)) and len(inputs) == 2:
       input_tensor, attention_mask = inputs
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/tn_transformer_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/tn_transformer_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,85 +12,81 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for TN-BERT transformer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers.tn_transformer_expand_condense import TNTransformerExpandCondense
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
 @parameterized.named_parameters(('tn', TNTransformerExpandCondense))
-class TransformerLayerTest(keras_parameterized.TestCase):
+class TransformerLayerTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(TransformerLayerTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   def test_layer_creation(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=16,
         intermediate_size=2048,
         intermediate_activation='relu')
     sequence_length = 21
     width = 256
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   def test_layer_creation_with_mask(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=16,
         intermediate_size=2048,
         intermediate_activation='relu')
     sequence_length = 21
     width = 256
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   def test_layer_creation_with_incorrect_mask_fails(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=16,
         intermediate_size=2048,
         intermediate_activation='relu')
     sequence_length = 21
     width = 256
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length - 3))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length - 3))
     with self.assertRaisesRegex(ValueError, 'When passing a mask tensor.*'):
       _ = test_layer([data_tensor, mask_tensor])
 
   def test_layer_invocation(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=16,
         intermediate_size=2048,
         intermediate_activation='relu')
     sequence_length = 21
     width = 256
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(data_tensor, output_tensor)
+    model = tf_keras.Model(data_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 16 * np.random.random_sample(
         (batch_size, sequence_length, width))
     _ = model.predict(input_data)
@@ -99,21 +95,21 @@
     test_layer = transformer_cls(
         num_attention_heads=16,
         intermediate_size=2048,
         intermediate_activation='relu')
     sequence_length = 21
     width = 256
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 16 * np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -147,29 +143,29 @@
     _ = new_layer([input_data, mask_data])
     new_layer.set_weights(test_layer.get_weights())
     new_output_tensor = new_layer([input_data, mask_data])
     self.assertAllClose(
         new_output_tensor, output_tensor[:, 0:1, :], atol=5e-5, rtol=0.003)
 
   def test_layer_invocation_with_float16_dtype(self, transformer_cls):
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     test_layer = transformer_cls(
         num_attention_heads=16,
         intermediate_size=2048,
         intermediate_activation='relu')
     sequence_length = 21
     width = 256
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = (16 * np.random.random_sample(
         (batch_size, sequence_length, width)))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -179,34 +175,34 @@
     _ = model.predict([input_data, mask_data])
 
   def test_transform_with_initializer(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=16,
         intermediate_size=2048,
         intermediate_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     sequence_length = 21
     width = 256
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output.shape.as_list())
 
   def test_dynamic_layer_sequence(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=16,
         intermediate_size=2048,
         intermediate_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     # Create a 3-dimensional input (the first dimension is implicit).
     width = 256
-    input_tensor = tf.keras.Input(shape=(None, width))
+    input_tensor = tf_keras.Input(shape=(None, width))
     output_tensor = test_layer(input_tensor)
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     input_length = 17
     input_data = np.ones((1, input_length, width))
     output_data = model.predict(input_data)
 
     self.assertAllEqual([1, input_length, width], output_data.shape)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,24 +13,24 @@
 # limitations under the License.
 
 """Keras-based transformer block layer."""
 # pylint: disable=g-classes-have-attributes
 
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import attention
 from official.nlp.modeling.layers import multi_channel_attention
 from official.nlp.modeling.layers import transformer_encoder_block
 from official.nlp.modeling.layers.util import tf_function_if_eager
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
+@tf_keras.utils.register_keras_serializable(package="Text")
 class Transformer(transformer_encoder_block.TransformerEncoderBlock):
   """Transformer layer.
 
   This layer implements the Transformer from "Attention Is All You Need".
   (https://arxiv.org/abs/1706.03762).
 
   **Warning: this layer is deprecated. Please don't use it. Use the
@@ -103,64 +103,62 @@
         attention_initializer=attention_initializer,
         **kwargs)
     logging.warning("The `Transformer` layer is deprecated. Please directly "
                     "use `TransformerEncoderBlock`.")
 
   def get_config(self):
     return {
-        "num_attention_heads":
-            self._num_heads,
-        "intermediate_size":
-            self._inner_dim,
-        "intermediate_activation":
-            self._inner_activation,
-        "dropout_rate":
-            self._output_dropout_rate,
-        "attention_dropout_rate":
-            self._attention_dropout_rate,
-        "output_range":
-            self._output_range,
-        "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
-        "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
-        "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
-        "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
-        "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
-        "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
-        "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint),
-        "use_bias":
-            self._use_bias,
-        "norm_first":
-            self._norm_first,
-        "norm_epsilon":
-            self._norm_epsilon,
-        "intermediate_dropout":
-            self._inner_dropout,
-        "attention_initializer":
-            tf.keras.initializers.serialize(self._attention_initializer)
+        "num_attention_heads": self._num_heads,
+        "intermediate_size": self._inner_dim,
+        "intermediate_activation": self._inner_activation,
+        "dropout_rate": self._output_dropout_rate,
+        "attention_dropout_rate": self._attention_dropout_rate,
+        "output_range": self._output_range,
+        "kernel_initializer": tf_utils.serialize_initializer(
+            self._kernel_initializer, use_legacy_format=True
+        ),
+        "bias_initializer": tf_utils.serialize_initializer(
+            self._bias_initializer, use_legacy_format=True
+        ),
+        "kernel_regularizer": tf_utils.serialize_regularizer(
+            self._kernel_regularizer, use_legacy_format=True
+        ),
+        "bias_regularizer": tf_utils.serialize_regularizer(
+            self._bias_regularizer, use_legacy_format=True
+        ),
+        "activity_regularizer": tf_utils.serialize_regularizer(
+            self._activity_regularizer, use_legacy_format=True
+        ),
+        "kernel_constraint": tf_utils.serialize_constraint(
+            self._kernel_constraint, use_legacy_format=True
+        ),
+        "bias_constraint": tf_utils.serialize_constraint(
+            self._bias_constraint, use_legacy_format=True
+        ),
+        "use_bias": self._use_bias,
+        "norm_first": self._norm_first,
+        "norm_epsilon": self._norm_epsilon,
+        "intermediate_dropout": self._inner_dropout,
+        "attention_initializer": tf_utils.serialize_initializer(
+            self._attention_initializer, use_legacy_format=True
+        ),
     }
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
+@tf_keras.utils.register_keras_serializable(package="Text")
 @gin.configurable
 class CompiledTransformer(Transformer):
 
   @tf_function_if_eager(experimental_compile=True)
   def call(self, inputs):
     return super().call(inputs)
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class TransformerDecoderBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class TransformerDecoderBlock(tf_keras.layers.Layer):
   """Single transformer layer for decoder.
 
   It has three sub-layers:
   (1) a multi-head self-attention mechanism.
   (2) a encoder-decoder attention.
   (3) a positionwise fully connected feed-forward network.
 
@@ -184,14 +182,16 @@
     norm_first: Whether to normalize inputs to attention and intermediate dense
       layers. If set False, output of attention and intermediate dense layers is
       normalized.
     norm_epsilon: Epsilon value to initialize normalization layers.
     intermediate_dropout: Dropout probability for intermediate_dropout_layer.
     attention_initializer: Initializer for kernels of attention layers. If set
       `None`, attention layers use kernel_initializer as initializer for kernel.
+    self_attention_cls: An optional class to use for self attention.
+    cross_attention_cls: An optional class to use for cross attention.
   """
 
   def __init__(self,
                num_attention_heads,
                intermediate_size,
                intermediate_activation,
                dropout_rate=0.0,
@@ -205,41 +205,52 @@
                kernel_constraint=None,
                bias_constraint=None,
                use_bias=True,
                norm_first=False,
                norm_epsilon=1e-12,
                intermediate_dropout=0.0,
                attention_initializer=None,
+               self_attention_cls=None,
+               cross_attention_cls=None,
                **kwargs):
     super().__init__(**kwargs)
     self.num_attention_heads = num_attention_heads
     self.intermediate_size = intermediate_size
-    self.intermediate_activation = tf.keras.activations.get(
+    self.intermediate_activation = tf_keras.activations.get(
         intermediate_activation)
     self.dropout_rate = dropout_rate
     self.attention_dropout_rate = attention_dropout_rate
     self.multi_channel_cross_attention = multi_channel_cross_attention
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._activity_regularizer = tf.keras.regularizers.get(activity_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._activity_regularizer = tf_keras.regularizers.get(activity_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
     self._use_bias = use_bias
     self._norm_first = norm_first
     self._norm_epsilon = norm_epsilon
     self._intermediate_dropout = intermediate_dropout
     if attention_initializer:
-      self._attention_initializer = tf.keras.initializers.get(
+      self._attention_initializer = tf_keras.initializers.get(
           attention_initializer)
     else:
       self._attention_initializer = tf_utils.clone_initializer(
           self._kernel_initializer)
-    if self.multi_channel_cross_attention:
+
+    self._self_attention_cls = self_attention_cls or attention.CachedAttention
+
+    if cross_attention_cls is not None:
+      self._cross_attention_cls = cross_attention_cls
+      if self.multi_channel_cross_attention:
+        logging.warning(
+            "%s will be used for cross attention", cross_attention_cls
+        )
+    elif self.multi_channel_cross_attention:
       self._cross_attention_cls = multi_channel_attention.MultiChannelAttention
     else:
       self._cross_attention_cls = attention.MultiHeadAttention
 
   def build(self, input_shape):
     target_tensor_shape = tf.TensorShape(input_shape[0])
     if len(target_tensor_shape.as_list()) != 3:
@@ -254,36 +265,36 @@
     common_kwargs = dict(
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer,
         activity_regularizer=self._activity_regularizer,
         kernel_constraint=self._kernel_constraint,
         bias_constraint=self._bias_constraint)
     # Self attention.
-    self.self_attention = attention.CachedAttention(
+    self.self_attention = self._self_attention_cls(
         num_heads=self.num_attention_heads,
         key_dim=self.attention_head_size,
         dropout=self.attention_dropout_rate,
         use_bias=self._use_bias,
         kernel_initializer=tf_utils.clone_initializer(
             self._attention_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         name="self_attention",
         **common_kwargs)
-    self.self_attention_output_dense = tf.keras.layers.EinsumDense(
+    self.self_attention_output_dense = tf_keras.layers.EinsumDense(
         "abc,cd->abd",
         output_shape=(None, hidden_size),
         bias_axes="d",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         name="output",
         **common_kwargs)
-    self.self_attention_dropout = tf.keras.layers.Dropout(
+    self.self_attention_dropout = tf_keras.layers.Dropout(
         rate=self.dropout_rate)
     self.self_attention_layer_norm = (
-        tf.keras.layers.LayerNormalization(
+        tf_keras.layers.LayerNormalization(
             name="self_attention_layer_norm",
             axis=-1,
             epsilon=self._norm_epsilon,
             dtype="float32"))
     # Encoder-decoder attention.
     self.encdec_attention = self._cross_attention_cls(
         num_heads=self.num_attention_heads,
@@ -293,90 +304,90 @@
         use_bias=self._use_bias,
         kernel_initializer=tf_utils.clone_initializer(
             self._attention_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         name="attention/encdec",
         **common_kwargs)
 
-    self.encdec_attention_dropout = tf.keras.layers.Dropout(
+    self.encdec_attention_dropout = tf_keras.layers.Dropout(
         rate=self.dropout_rate)
     self.encdec_attention_layer_norm = (
-        tf.keras.layers.LayerNormalization(
+        tf_keras.layers.LayerNormalization(
             name="attention/encdec_output_layer_norm",
             axis=-1,
             epsilon=self._norm_epsilon,
             dtype="float32"))
 
     # Feed-forward projection.
-    self.intermediate_dense = tf.keras.layers.EinsumDense(
+    self.intermediate_dense = tf_keras.layers.EinsumDense(
         "abc,cd->abd",
         output_shape=(None, self.intermediate_size),
         bias_axes="d",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         name="intermediate",
         **common_kwargs)
-    self.intermediate_activation_layer = tf.keras.layers.Activation(
+    self.intermediate_activation_layer = tf_keras.layers.Activation(
         self.intermediate_activation)
-    self._intermediate_dropout_layer = tf.keras.layers.Dropout(
+    self._intermediate_dropout_layer = tf_keras.layers.Dropout(
         rate=self._intermediate_dropout)
-    self.output_dense = tf.keras.layers.EinsumDense(
+    self.output_dense = tf_keras.layers.EinsumDense(
         "abc,cd->abd",
         output_shape=(None, hidden_size),
         bias_axes="d",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         name="output",
         **common_kwargs)
-    self.output_dropout = tf.keras.layers.Dropout(rate=self.dropout_rate)
-    self.output_layer_norm = tf.keras.layers.LayerNormalization(
+    self.output_dropout = tf_keras.layers.Dropout(rate=self.dropout_rate)
+    self.output_layer_norm = tf_keras.layers.LayerNormalization(
         name="output_layer_norm",
         axis=-1,
         epsilon=self._norm_epsilon,
         dtype="float32")
     super().build(input_shape)
 
   def get_config(self):
     config = {
-        "num_attention_heads":
-            self.num_attention_heads,
-        "intermediate_size":
-            self.intermediate_size,
-        "intermediate_activation":
-            self.intermediate_activation,
-        "dropout_rate":
-            self.dropout_rate,
-        "attention_dropout_rate":
-            self.attention_dropout_rate,
-        "multi_channel_cross_attention":
-            self.multi_channel_cross_attention,
-        "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
-        "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
-        "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
-        "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
-        "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
-        "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
-        "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint),
-        "use_bias":
-            self._use_bias,
-        "norm_first":
-            self._norm_first,
-        "norm_epsilon":
-            self._norm_epsilon,
-        "intermediate_dropout":
-            self._intermediate_dropout,
-        "attention_initializer":
-            tf.keras.initializers.serialize(self._attention_initializer)
+        "num_attention_heads": self.num_attention_heads,
+        "intermediate_size": self.intermediate_size,
+        "intermediate_activation": self.intermediate_activation,
+        "dropout_rate": self.dropout_rate,
+        "attention_dropout_rate": self.attention_dropout_rate,
+        "multi_channel_cross_attention": self.multi_channel_cross_attention,
+        "kernel_initializer": tf_utils.serialize_initializer(
+            self._kernel_initializer, use_legacy_format=True
+        ),
+        "bias_initializer": tf_utils.serialize_initializer(
+            self._bias_initializer, use_legacy_format=True
+        ),
+        "kernel_regularizer": tf_utils.serialize_regularizer(
+            self._kernel_regularizer, use_legacy_format=True
+        ),
+        "bias_regularizer": tf_utils.serialize_regularizer(
+            self._bias_regularizer, use_legacy_format=True
+        ),
+        "activity_regularizer": tf_utils.serialize_regularizer(
+            self._activity_regularizer, use_legacy_format=True
+        ),
+        "kernel_constraint": tf_utils.serialize_constraint(
+            self._kernel_constraint, use_legacy_format=True
+        ),
+        "bias_constraint": tf_utils.serialize_constraint(
+            self._bias_constraint, use_legacy_format=True
+        ),
+        "use_bias": self._use_bias,
+        "norm_first": self._norm_first,
+        "norm_epsilon": self._norm_epsilon,
+        "intermediate_dropout": self._intermediate_dropout,
+        "attention_initializer": tf_utils.serialize_initializer(
+            self._attention_initializer, use_legacy_format=True
+        ),
+        "self_attention_cls": self._self_attention_cls,
+        "cross_attention_cls": self._cross_attention_cls,
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def common_layers_with_encoder(self):
     """Gets layer objects that can make a Transformer encoder block."""
     return [
@@ -418,14 +429,15 @@
         query=self_attention_output,
         value=memory,
         attention_mask=attention_mask)
     if self.multi_channel_cross_attention:
       # Accesses the 5-th input tensor for the doc-attention probabilities.
       cross_attn_inputs["context_attention_weights"] = inputs[-1]
     attention_output = self.encdec_attention(**cross_attn_inputs)
+
     attention_output = self.encdec_attention_dropout(attention_output)
     if self._norm_first:
       attention_output = source_self_attention_output + attention_output
     else:
       attention_output = self.encdec_attention_layer_norm(
           self_attention_output + attention_output)
     if self._norm_first:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_encoder_block.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_encoder_block.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,37 +1,81 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based TransformerEncoder block layer."""
-from typing import Any, Optional
+from typing import Any, Optional, Sequence
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import util
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class TransformerEncoderBlock(tf.keras.layers.Layer):
+class RMSNorm(tf_keras.layers.Layer):
+  """Root mean square layer normalization layer."""
+
+  def __init__(
+      self,
+      axis: int | Sequence[int] = -1,
+      epsilon: float = 1e-6,
+      **kwargs,
+  ):
+    """Initializes RMSNorm.
+
+    Args:
+      axis: The axis that the input is normalized over.
+      epsilon: A small value added to the mean square for numerical stability.
+      **kwargs: Keyword arguments passed to the base layer.
+    """
+    super().__init__(**kwargs)
+    self.axis = [axis] if isinstance(axis, int) else axis
+    self.epsilon = epsilon
+
+  def build(self, input_shape: tf.TensorShape | Sequence[int | None]):
+    input_shape = tf.TensorShape(input_shape)
+    scale_shape = [1] * input_shape.rank
+    for dim in self.axis:
+      scale_shape[dim] = input_shape[dim]
+    with tf.name_scope(self.name):
+      self.scale = self.add_weight(
+          name="scale",
+          shape=scale_shape,
+          initializer="ones",
+          experimental_autocast=False,
+      )
+    super().build(input_shape)
+
+  def call(self, inputs: tf.Tensor) -> tf.Tensor:
+    input_dtype = inputs.dtype
+    inputs = tf.cast(inputs, tf.float32)
+    var = tf.math.reduce_mean(
+        tf.math.square(inputs), axis=self.axis, keepdims=True
+    )
+    outputs = inputs * tf.math.rsqrt(var + self.epsilon) * self.scale
+    return tf.cast(outputs, input_dtype)
+
+
+@tf_keras.utils.register_keras_serializable(package="Text")
+class TransformerEncoderBlock(tf_keras.layers.Layer):
   """TransformerEncoderBlock layer.
 
   This layer implements the Transformer Encoder from
   "Attention Is All You Need". (https://arxiv.org/abs/1706.03762),
-  which combines a `tf.keras.layers.MultiHeadAttention` layer with a
+  which combines a `tf_keras.layers.MultiHeadAttention` layer with a
   two-layer feedforward network.
 
   References:
     [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
     [BERT: Pre-training of Deep Bidirectional Transformers for Language
      Understanding](https://arxiv.org/abs/1810.04805)
   """
@@ -47,14 +91,15 @@
                bias_regularizer=None,
                activity_regularizer=None,
                kernel_constraint=None,
                bias_constraint=None,
                use_bias=True,
                norm_first=False,
                norm_epsilon=1e-12,
+               use_rms_norm=False,
                output_dropout=0.0,
                attention_dropout=0.0,
                inner_dropout=0.0,
                attention_initializer=None,
                attention_axes=None,
                use_query_residual=True,
                key_dim=None,
@@ -72,15 +117,15 @@
     match. If `use_query_residual` is `False`, the `output_last_dim` dictactes
     the last dimension of the output of this module and the
     multi-head-attention.
 
     E.g. let's say input dims are `[batch_size, seq_dim, input_last_dim]`.
     Scenario 1: If `output_last_dim` is not `None`, then the output dims of this
     module would be `[batch_size, seq_dim, output_last_dim]`. Note `key_dim` is
-    overriden by `output_last_dim`.
+    overridden by `output_last_dim`.
     Scenario 2: If `output_last_dim` is `None` and `key_dim` is not `None`, then
     the output dims of this module would be `[batch_size, seq_dim, key_dim]`.
     Scenario 3: If the `output_last_dim` and `key_dim` are both `None`, the
     output dims would be `[batch_size, seq_dim, input_last_dim]`.
 
     Args:
       num_attention_heads: Number of attention heads.
@@ -99,28 +144,29 @@
       bias_constraint: Constraint for dense layer kernels.
       use_bias: Whether to enable use_bias in attention layer. If set False,
         use_bias in attention layer is disabled.
       norm_first: Whether to normalize inputs to attention and intermediate
         dense layers. If set False, output of attention and intermediate dense
         layers is normalized.
       norm_epsilon: Epsilon value to initialize normalization layers.
+      use_rms_norm: Whether to use RMSNorm instead of LayerNorm.
       output_dropout: Dropout probability for the post-attention and output
         dropout.
       attention_dropout: Dropout probability for within the attention layer.
       inner_dropout: Dropout probability for the first Dense layer in a
         two-layer feedforward network.
       attention_initializer: Initializer for kernels of attention layers. If set
         `None`, attention layers use kernel_initializer as initializer for
         kernel.
       attention_axes: axes over which the attention is applied. `None` means
         attention over all axes, but batch, heads, and features.
       use_query_residual: Toggle to execute residual connection after attention.
-      key_dim: `key_dim` for the `tf.keras.layers.MultiHeadAttention`. If
+      key_dim: `key_dim` for the `tf_keras.layers.MultiHeadAttention`. If
         `None`, we use the first `input_shape`'s last dim.
-      value_dim: `value_dim` for the `tf.keras.layers.MultiHeadAttention`.
+      value_dim: `value_dim` for the `tf_keras.layers.MultiHeadAttention`.
       output_last_dim: Final dimension of the output of this module. This also
         dictates the value for the final dimension of the multi-head-attention.
         When it's `None`, we use, in order of decreasing precedence, `key_dim` *
         `num_heads` or the first `input_shape`'s last dim as the output's last
         dim.
       diff_q_kv_att_layer_norm: If `True`, create a separate attention layer
         norm layer for query and key-value if `norm_first` is `True`. Invalid to
@@ -140,33 +186,34 @@
 
     self._num_heads = num_attention_heads
     self._inner_dim = inner_dim
     self._inner_activation = inner_activation
     self._attention_dropout_rate = attention_dropout
     self._output_dropout_rate = output_dropout
     self._output_range = output_range
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._activity_regularizer = tf.keras.regularizers.get(activity_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._activity_regularizer = tf_keras.regularizers.get(activity_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
     self._use_bias = use_bias
     self._norm_first = norm_first
     self._norm_epsilon = norm_epsilon
+    self._use_rms_norm = use_rms_norm
     self._inner_dropout = inner_dropout
     self._use_query_residual = use_query_residual
     self._key_dim = key_dim
     self._value_dim = value_dim
     self._output_last_dim = output_last_dim
     self._diff_q_kv_att_layer_norm = diff_q_kv_att_layer_norm
     self._return_attention_scores = return_attention_scores
     if attention_initializer:
-      self._attention_initializer = tf.keras.initializers.get(
+      self._attention_initializer = tf_keras.initializers.get(
           attention_initializer)
     else:
       self._attention_initializer = tf_utils.clone_initializer(
           self._kernel_initializer)
     self._attention_axes = attention_axes
 
     if self._diff_q_kv_att_layer_norm and not self._norm_first:
@@ -198,132 +245,138 @@
       last_output_shape = self._output_last_dim
 
     common_kwargs = dict(
         bias_regularizer=self._bias_regularizer,
         activity_regularizer=self._activity_regularizer,
         kernel_constraint=self._kernel_constraint,
         bias_constraint=self._bias_constraint)
-    self._attention_layer = tf.keras.layers.MultiHeadAttention(
+    self._attention_layer = tf_keras.layers.MultiHeadAttention(
         num_heads=self._num_heads,
         key_dim=self._key_dim,
         value_dim=self._value_dim,
         dropout=self._attention_dropout_rate,
         use_bias=self._use_bias,
         kernel_initializer=self._attention_initializer,
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         attention_axes=self._attention_axes,
         output_shape=self._output_last_dim,
         name="self_attention",
-        **common_kwargs)
-    self._attention_dropout = tf.keras.layers.Dropout(
-        rate=self._attention_dropout_rate)
+        **common_kwargs
+    )
+    self._attention_dropout = tf_keras.layers.Dropout(
+        rate=self._attention_dropout_rate
+    )
     # Use float32 in layernorm for numeric stability.
     # It is probably safe in mixed_float16, but we haven't validated this yet.
-    self._attention_layer_norm = (
-        tf.keras.layers.LayerNormalization(
-            name="self_attention_layer_norm",
-            axis=-1,
-            epsilon=self._norm_epsilon,
-            dtype=tf.float32))
+    if self._use_rms_norm:
+      self._attention_layer_norm = RMSNorm(
+          epsilon=self._norm_epsilon,
+          name="self_attention_layer_norm",
+      )
+    else:
+      self._attention_layer_norm = tf_keras.layers.LayerNormalization(
+          name="self_attention_layer_norm",
+          axis=-1,
+          epsilon=self._norm_epsilon,
+          dtype=tf.float32,
+      )
     self._attention_layer_norm_kv = self._attention_layer_norm
     if self._diff_q_kv_att_layer_norm:
-      self._attention_layer_norm_kv = (
-          tf.keras.layers.LayerNormalization(
-              name="self_attention_layer_norm_kv",
-              axis=-1,
-              epsilon=self._norm_epsilon,
-              dtype=tf.float32))
+      if self._use_rms_norm:
+        self._attention_layer_norm_kv = RMSNorm(
+            epsilon=self._norm_epsilon,
+            name="self_attention_layer_norm_kv",
+        )
+      else:
+        self._attention_layer_norm_kv = tf_keras.layers.LayerNormalization(
+            name="self_attention_layer_norm_kv",
+            axis=-1,
+            epsilon=self._norm_epsilon,
+            dtype=tf.float32,
+        )
 
-    self._intermediate_dense = tf.keras.layers.EinsumDense(
+    self._intermediate_dense = tf_keras.layers.EinsumDense(
         einsum_equation,
         output_shape=(None, self._inner_dim),
         bias_axes="d",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         name="intermediate",
         **common_kwargs)
-    policy = tf.keras.mixed_precision.global_policy()
+    policy = tf_keras.mixed_precision.global_policy()
     if policy.name == "mixed_bfloat16":
       # bfloat16 causes BERT with the LAMB optimizer to not converge
       # as well, so we use float32.
       # TODO(b/154538392): Investigate this.
       policy = tf.float32
-    self._intermediate_activation_layer = tf.keras.layers.Activation(
+    self._intermediate_activation_layer = tf_keras.layers.Activation(
         self._inner_activation, dtype=policy)
-    self._inner_dropout_layer = tf.keras.layers.Dropout(
+    self._inner_dropout_layer = tf_keras.layers.Dropout(
         rate=self._inner_dropout)
-    self._output_dense = tf.keras.layers.EinsumDense(
+    self._output_dense = tf_keras.layers.EinsumDense(
         einsum_equation,
         output_shape=(None, last_output_shape),
         bias_axes="d",
         name="output",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
         **common_kwargs)
-    self._output_dropout = tf.keras.layers.Dropout(
+    self._output_dropout = tf_keras.layers.Dropout(
         rate=self._output_dropout_rate)
     # Use float32 in layernorm for numeric stability.
-    self._output_layer_norm = tf.keras.layers.LayerNormalization(
+    self._output_layer_norm = tf_keras.layers.LayerNormalization(
         name="output_layer_norm",
         axis=-1,
         epsilon=self._norm_epsilon,
         dtype=tf.float32)
 
     super().build(input_shape)
 
   def get_config(self):
     config = {
-        "num_attention_heads":
-            self._num_heads,
-        "inner_dim":
-            self._inner_dim,
-        "inner_activation":
-            self._inner_activation,
-        "output_dropout":
-            self._output_dropout_rate,
-        "attention_dropout":
-            self._attention_dropout_rate,
-        "output_range":
-            self._output_range,
-        "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
-        "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
-        "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
-        "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
-        "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
-        "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
-        "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint),
-        "use_bias":
-            self._use_bias,
-        "norm_first":
-            self._norm_first,
-        "norm_epsilon":
-            self._norm_epsilon,
-        "inner_dropout":
-            self._inner_dropout,
-        "attention_initializer":
-            tf.keras.initializers.serialize(self._attention_initializer),
-        "attention_axes":
-            self._attention_axes,
-        "use_query_residual":
-            self._use_query_residual,
-        "key_dim":
-            self._key_dim,
-        "value_dim":
-            self._value_dim,
-        "output_last_dim":
-            self._output_last_dim,
-        "diff_q_kv_att_layer_norm":
-            self._diff_q_kv_att_layer_norm,
+        "num_attention_heads": self._num_heads,
+        "inner_dim": self._inner_dim,
+        "inner_activation": self._inner_activation,
+        "output_dropout": self._output_dropout_rate,
+        "attention_dropout": self._attention_dropout_rate,
+        "output_range": self._output_range,
+        "kernel_initializer": tf_utils.serialize_initializer(
+            self._kernel_initializer, use_legacy_format=True
+        ),
+        "bias_initializer": tf_utils.serialize_initializer(
+            self._bias_initializer, use_legacy_format=True
+        ),
+        "kernel_regularizer": tf_utils.serialize_regularizer(
+            self._kernel_regularizer, use_legacy_format=True
+        ),
+        "bias_regularizer": tf_utils.serialize_regularizer(
+            self._bias_regularizer, use_legacy_format=True
+        ),
+        "activity_regularizer": tf_utils.serialize_regularizer(
+            self._activity_regularizer, use_legacy_format=True
+        ),
+        "kernel_constraint": tf_utils.serialize_constraint(
+            self._kernel_constraint, use_legacy_format=True
+        ),
+        "bias_constraint": tf_utils.serialize_constraint(
+            self._bias_constraint, use_legacy_format=True
+        ),
+        "use_bias": self._use_bias,
+        "norm_first": self._norm_first,
+        "norm_epsilon": self._norm_epsilon,
+        "inner_dropout": self._inner_dropout,
+        "attention_initializer": tf_utils.serialize_initializer(
+            self._attention_initializer, use_legacy_format=True
+        ),
+        "attention_axes": self._attention_axes,
+        "use_query_residual": self._use_query_residual,
+        "key_dim": self._key_dim,
+        "value_dim": self._value_dim,
+        "output_last_dim": self._output_last_dim,
+        "diff_q_kv_att_layer_norm": self._diff_q_kv_att_layer_norm,
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs: Any, output_range: Optional[tf.Tensor] = None) -> Any:
     """Transformer self-attention encoder block call.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_encoder_block_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_encoder_block_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,84 +12,83 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based transformer block layer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers.transformer_encoder_block import TransformerEncoderBlock
 
 
-@keras_parameterized.run_all_keras_modes
 @parameterized.named_parameters(('base', TransformerEncoderBlock))
-class TransformerEncoderBlockLayerTest(keras_parameterized.TestCase):
+class TransformerEncoderBlockLayerTest(
+    tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(TransformerEncoderBlockLayerTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   def test_layer_creation(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   def test_layer_creation_with_mask(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   def test_layer_invocation(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(data_tensor, output_tensor)
+    model = tf_keras.Model(data_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     _ = model.predict(input_data)
 
   def test_layer_invocation_with_mask(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -182,27 +181,27 @@
     self.assertAllClose(
         new_output_tensor, output_tensor[:, 0:1, :], atol=5e-5, rtol=0.003)
 
     output_tensor = test_layer([input_data, mask_data], output_range=1)
     self.assertAllClose(new_output_tensor, output_tensor, atol=5e-5, rtol=0.003)
 
   def test_layer_invocation_with_float16_dtype(self, transformer_cls):
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = (10 * np.random.random_sample(
         (batch_size, sequence_length, width)))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -212,63 +211,62 @@
     _ = model.predict([input_data, mask_data])
 
   def test_transform_with_initializer(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output.shape.as_list())
 
   def test_dynamic_layer_sequence(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     # Create a 3-dimensional input (the first dimension is implicit).
     width = 30
-    input_tensor = tf.keras.Input(shape=(None, width))
+    input_tensor = tf_keras.Input(shape=(None, width))
     output_tensor = test_layer(input_tensor)
-    model = tf.keras.Model(input_tensor, output_tensor)
+    model = tf_keras.Model(input_tensor, output_tensor)
 
     input_length = 17
     input_data = np.ones((1, input_length, width))
     output_data = model.predict(input_data)
 
     self.assertAllEqual([1, input_length, width], output_data.shape)
 
   def test_separate_qkv(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=2,
         inner_dim=128,
         inner_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     # Forward path.
     q_tensor = tf.zeros([2, 4, 16], dtype=tf.float32)
     kv_tensor = tf.zeros([2, 8, 16], dtype=tf.float32)
     dummy_mask = tf.zeros([2, 4, 8], dtype=tf.float32)
     inputs = [q_tensor, kv_tensor, dummy_mask]
     output = test_layer(inputs)
     self.assertEqual(output.shape, q_tensor.shape)
 
 
-@keras_parameterized.run_all_keras_modes
-class TransformerEncoderBlockLayerTestWithoutParams(keras_parameterized.TestCase
-                                                   ):
+class TransformerEncoderBlockLayerTestWithoutParams(
+    tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(TransformerEncoderBlockLayerTestWithoutParams, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   def test_raises_invalid_arg_error_when_q_kv_dims_are_different(self):
     test_layer = TransformerEncoderBlock(
         num_attention_heads=2,
         inner_dim=128,
         inner_activation='relu',
         norm_first=True)
@@ -312,29 +310,29 @@
     graph_with_res = tf.Graph()
     with graph_with_res.as_default():
       layer = TransformerEncoderBlock(
           num_attention_heads=2,
           inner_dim=128,
           inner_activation='relu',
           norm_first=norm_first)
-      inputs = tf.keras.Input(shape=(None, None, 2))
+      inputs = tf_keras.Input(shape=(None, None, 2))
       outputs = layer(inputs)
-      tf.keras.Model(inputs=inputs, outputs=outputs)
+      tf_keras.Model(inputs=inputs, outputs=outputs)
 
     graph_without_res = tf.Graph()
     with graph_without_res.as_default():
       layer = TransformerEncoderBlock(
           num_attention_heads=2,
           inner_dim=128,
           inner_activation='relu',
           norm_first=norm_first,
           use_query_residual=False)
-      inputs = tf.keras.Input(shape=(None, None, 2))
+      inputs = tf_keras.Input(shape=(None, None, 2))
       outputs = layer(inputs)
-      tf.keras.Model(inputs=inputs, outputs=outputs)
+      tf_keras.Model(inputs=inputs, outputs=outputs)
     graph_with_res_names = {x.name for x in graph_with_res.get_operations()}
     graph_without_res_names = {
         x.name for x in graph_without_res.get_operations()
     }
 
     self.assertIn('transformer_encoder_block/add',
                   list(graph_with_res_names - graph_without_res_names)[0])
@@ -403,31 +401,52 @@
     dummy_mask = tf.zeros([2, 4, 8], dtype=tf.float32)
     test_layer([q_tensor, kv_tensor, dummy_mask])
 
     self.assertEqual(expected,
                      test_layer._attention_layer.get_config()['value_dim'])
 
 
-@keras_parameterized.run_all_keras_modes
-class TransformerArgumentTest(keras_parameterized.TestCase):
+class TransformerArgumentTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_use_bias_norm_first(self):
     num_attention_heads = 2
     hidden_size = 16
     encoder_block = TransformerEncoderBlock(
         num_attention_heads=num_attention_heads,
         inner_dim=32,
         inner_activation='relu',
         output_dropout=0.1,
         attention_dropout=0.1,
         use_bias=False,
         norm_first=True,
         norm_epsilon=1e-6,
         inner_dropout=0.1,
-        attention_initializer=tf.keras.initializers.RandomUniform(
+        attention_initializer=tf_keras.initializers.RandomUniform(
+            minval=0., maxval=1.))
+    # Forward path.
+    dummy_tensor = tf.zeros([2, 4, 16], dtype=tf.float32)
+    dummy_mask = tf.zeros([2, 4, 4], dtype=tf.float32)
+    inputs = [dummy_tensor, dummy_mask]
+    output = encoder_block(inputs)
+    self.assertEqual(output.shape, (2, 4, hidden_size))
+
+  def test_use_rms_norm(self):
+    num_attention_heads = 2
+    hidden_size = 16
+    encoder_block = TransformerEncoderBlock(
+        num_attention_heads=num_attention_heads,
+        inner_dim=32,
+        inner_activation='relu',
+        output_dropout=0.1,
+        attention_dropout=0.1,
+        use_bias=False,
+        use_rms_norm=True,
+        norm_epsilon=1e-6,
+        inner_dropout=0.1,
+        attention_initializer=tf_keras.initializers.RandomUniform(
             minval=0., maxval=1.))
     # Forward path.
     dummy_tensor = tf.zeros([2, 4, 16], dtype=tf.float32)
     dummy_mask = tf.zeros([2, 4, 4], dtype=tf.float32)
     inputs = [dummy_tensor, dummy_mask]
     output = encoder_block(inputs)
     self.assertEqual(output.shape, (2, 4, hidden_size))
@@ -572,15 +591,15 @@
         inner_activation='relu',
         output_dropout=0.1,
         attention_dropout=0.1,
         use_bias=False,
         norm_first=True,
         norm_epsilon=1e-6,
         inner_dropout=0.1,
-        attention_initializer=tf.keras.initializers.RandomUniform(
+        attention_initializer=tf_keras.initializers.RandomUniform(
             minval=0., maxval=1.),
         use_query_residual=False,
         key_dim=20,
         value_dim=30,
         output_last_dim=40,
         diff_q_kv_att_layer_norm=True)
     encoder_block_config = encoder_block.get_config()
@@ -602,15 +621,15 @@
         inner_dropout=0.1,
         num_attention_heads=10,
         attention_axes=attention_axes)
     num_rows = 21
     num_cols = 13
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(num_rows, num_cols, width))
+    data_tensor = tf_keras.Input(shape=(num_rows, num_cols, width))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   @parameterized.parameters(
       {
           'output_dropout': 0.1,
@@ -636,15 +655,15 @@
         inner_dim=32,
         inner_activation='relu',
         output_dropout=output_dropout,
         attention_dropout=attention_dropout,
         inner_dropout=inner_dropout)
     seq_len = 21
     hidden_size = 512
-    input_tensor = tf.keras.Input(shape=(seq_len, hidden_size))
+    input_tensor = tf_keras.Input(shape=(seq_len, hidden_size))
     _ = test_layer(input_tensor)
 
     true_output_dropout = test_layer._output_dropout.get_config()['rate']
     true_attention_dropout = test_layer._attention_dropout.get_config()['rate']
     true_inner_dropout = test_layer._inner_dropout_layer.get_config()['rate']
     self.assertEqual(true_output_dropout, output_dropout)
     self.assertEqual(true_attention_dropout, attention_dropout)
@@ -667,25 +686,25 @@
 
     test_layer = TransformerEncoderBlock(
         num_attention_heads=num_attention_heads,
         inner_dim=2048,
         inner_activation='relu',
         return_attention_scores=return_attention_scores)
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
 
     expected_layer_output_shape = [None, sequence_length, width]
     expected_attention_scores_shape = [
         None, num_attention_heads, sequence_length, sequence_length
     ]
 
     if return_attention_scores:
       self.assertIsInstance(output_tensor, tuple)
-      self.assertEqual(len(output_tensor), 2)
+      self.assertLen(output_tensor, 2)
       # First is the standard output.
       self.assertEqual(output_tensor[0].shape.as_list(),
                        expected_layer_output_shape)
       # Second is the attention scores.
       self.assertEqual(output_tensor[1].shape.as_list(),
                        expected_attention_scores_shape)
     else:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_scaffold.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_scaffold.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,24 +13,24 @@
 # limitations under the License.
 
 """Keras-based transformer scaffold layer."""
 # pylint: disable=g-classes-have-attributes
 
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import attention
 from official.nlp.modeling.layers import util
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
+@tf_keras.utils.register_keras_serializable(package="Text")
 @gin.configurable
-class TransformerScaffold(tf.keras.layers.Layer):
+class TransformerScaffold(tf_keras.layers.Layer):
   """Transformer scaffold layer.
 
   This layer implements the Transformer from "Attention Is All You Need".
   (https://arxiv.org/abs/1706.03762), with a customizable attention layer and
   feedforward layer option. Users can pass a class to
   `attention_cls`/`feedforward_cls` and associated config to
   `attention_cfg`/`feedforward_cfg`, in which case the scaffold will
@@ -64,14 +64,18 @@
       kwargs will be used to instantiate the feedforward instance: {
         "inner_dim": inner_dim,
         "inner_activation": inner_activation,
         "dropout": dropout_rate,
         "name": "feedforward" }.
     dropout_rate: Dropout probability for the post-attention and output dropout.
     attention_dropout_rate: Dropout probability for within the attention layer.
+    norm_first: Whether to normalize inputs to attention and intermediate
+        dense layers. If set False, output of attention and intermediate dense
+        layers is normalized.
+    norm_epsilon: Epsilon value to initialize normalization layers.
     kernel_initializer: Initializer for dense layer kernels.
     bias_initializer: Initializer for dense layer biases.
     kernel_regularizer: Regularizer for dense layer kernels.
     bias_regularizer: Regularizer for dense layer biases.
     activity_regularizer: Regularizer for dense layer activity.
     kernel_constraint: Constraint for dense layer kernels.
     bias_constraint: Constraint for dense layer kernels.
@@ -84,14 +88,15 @@
                attention_cls=attention.MultiHeadAttention,
                attention_cfg=None,
                feedforward_cls=None,
                feedforward_cfg=None,
                dropout_rate=0.0,
                attention_dropout_rate=0.0,
                norm_first=False,
+               norm_epsilon=1e-12,
                kernel_initializer="glorot_uniform",
                bias_initializer="zeros",
                kernel_regularizer=None,
                bias_regularizer=None,
                activity_regularizer=None,
                kernel_constraint=None,
                bias_constraint=None,
@@ -102,25 +107,26 @@
     super().__init__(**kwargs)
 
     self._attention_cfg = attention_cfg
     self._attention_cls = attention_cls
     self._feedforward_cls = feedforward_cls
     self._feedforward_cfg = feedforward_cfg
     self._norm_first = norm_first
+    self._norm_epsilon = norm_epsilon
     self._num_heads = num_attention_heads
     self._inner_dim = inner_dim
     self._inner_activation = inner_activation
     self._attention_dropout_rate = attention_dropout_rate
     self._dropout_rate = dropout_rate
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
 
   def build(self, input_shape):
     if isinstance(input_shape, tf.TensorShape):
       input_tensor_shape = input_shape
     elif isinstance(input_shape, (list, tuple)):
       input_tensor_shape = tf.TensorShape(input_shape[0])
     else:
@@ -143,16 +149,22 @@
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer,
         activity_regularizer=self._activity_regularizer,
         kernel_constraint=self._kernel_constraint,
         bias_constraint=self._bias_constraint)
 
     def get_layer_instance(instance_or_cls, config, default_config):
-      if isinstance(instance_or_cls, tf.keras.layers.Layer):
+      if isinstance(instance_or_cls, tf_keras.layers.Layer):
         return instance_or_cls
+      elif isinstance(instance_or_cls, dict):
+        return get_layer_instance(
+            tf_keras.utils.deserialize_keras_object(instance_or_cls),
+            config,
+            default_config,
+        )
       else:
         if config is None:
           return instance_or_cls(**default_config)
         else:
           return instance_or_cls(**config)
 
     default_attention_cfg = {
@@ -190,92 +202,95 @@
           config=self._feedforward_cfg,
           default_config=default_feedforward_cfg)
     else:
       self._feedforward_block = None
 
     # self._dropout_rate controls dropout rates at two places:
     # after attention, and after FFN.
-    self._attention_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self._attention_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
     # Use float32 in layernorm for numeric stability.
     # It is probably safe in mixed_float16, but we haven't validated this yet.
     self._attention_layer_norm = (
-        tf.keras.layers.LayerNormalization(
+        tf_keras.layers.LayerNormalization(
             name="self_attention_layer_norm",
             axis=-1,
-            epsilon=1e-12,
+            epsilon=self._norm_epsilon,
             dtype=tf.float32))
 
     if self._feedforward_block is None:
-      self._intermediate_dense = tf.keras.layers.EinsumDense(
+      self._intermediate_dense = tf_keras.layers.EinsumDense(
           "abc,cd->abd",
           output_shape=(None, self._inner_dim),
           bias_axes="d",
           name="intermediate",
           kernel_initializer=tf_utils.clone_initializer(
               self._kernel_initializer),
           bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
           **common_kwargs)
-      policy = tf.keras.mixed_precision.global_policy()
+      policy = tf_keras.mixed_precision.global_policy()
       if policy.name == "mixed_bfloat16":
         # bfloat16 causes BERT with the LAMB optimizer to not converge
         # as well, so we use float32.
         # TODO(b/154538392): Investigate this.
         policy = tf.float32
-      self._intermediate_activation_layer = tf.keras.layers.Activation(
+      self._intermediate_activation_layer = tf_keras.layers.Activation(
           self._inner_activation, dtype=policy)
-      self._output_dense = tf.keras.layers.EinsumDense(
+      self._output_dense = tf_keras.layers.EinsumDense(
           "abc,cd->abd",
           output_shape=(None, hidden_size),
           bias_axes="d",
           name="output",
           kernel_initializer=tf_utils.clone_initializer(
               self._kernel_initializer),
           bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
           **common_kwargs)
 
-    self._output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self._output_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
     # Use float32 in layernorm for numeric stability.
-    self._output_layer_norm = tf.keras.layers.LayerNormalization(
-        name="output_layer_norm", axis=-1, epsilon=1e-12, dtype=tf.float32)
+    self._output_layer_norm = tf_keras.layers.LayerNormalization(
+        name="output_layer_norm",
+        axis=-1,
+        epsilon=self._norm_epsilon,
+        dtype=tf.float32)
 
     super().build(input_shape)
     logging.info("%s configs: %s", self.__class__.__name__, self.get_config())
 
   def get_config(self):
     config = {
-        "attention_cls":
-            self._attention_layer,
-        "feedforward_cls":
-            self._feedforward_block,
-        "num_attention_heads":
-            self._num_heads,
-        "inner_dim":
-            self._inner_dim,
-        "inner_activation":
-            self._inner_activation,
-        "dropout_rate":
-            self._dropout_rate,
-        "attention_dropout_rate":
-            self._attention_dropout_rate,
-        "norm_first":
-            self._norm_first,
-        "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
-        "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
-        "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
-        "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
-        "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
-        "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
-        "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint)
+        "attention_cls": self._attention_layer,
+        "feedforward_cls": self._feedforward_block,
+        "num_attention_heads": self._num_heads,
+        "inner_dim": self._inner_dim,
+        "inner_activation": self._inner_activation,
+        "dropout_rate": self._dropout_rate,
+        "attention_dropout_rate": self._attention_dropout_rate,
+        "norm_first": self._norm_first,
+        "norm_epsilon": self._norm_epsilon,
+        "kernel_initializer": tf_utils.serialize_initializer(
+            self._kernel_initializer, use_legacy_format=True
+        ),
+        "bias_initializer": tf_utils.serialize_initializer(
+            self._bias_initializer, use_legacy_format=True
+        ),
+        "kernel_regularizer": tf_utils.serialize_regularizer(
+            self._kernel_regularizer, use_legacy_format=True
+        ),
+        "bias_regularizer": tf_utils.serialize_regularizer(
+            self._bias_regularizer, use_legacy_format=True
+        ),
+        "activity_regularizer": tf_utils.serialize_regularizer(
+            self._activity_regularizer, use_legacy_format=True
+        ),
+        "kernel_constraint": tf_utils.serialize_constraint(
+            self._kernel_constraint, use_legacy_format=True
+        ),
+        "bias_constraint": tf_utils.serialize_constraint(
+            self._bias_constraint, use_legacy_format=True
+        ),
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs, training=None):
     if isinstance(inputs, (list, tuple)):
       if len(inputs) == 2:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_scaffold_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_scaffold_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,26 +11,25 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based transformer block layer."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.layers import attention
 from official.nlp.modeling.layers import transformer_scaffold
 
 
 # Test class that wraps a standard attention layer. If this layer is called
 # at any point, the list passed to the config object will be filled with a
 # boolean 'True'. We register this class as a Keras serializable so we can
 # test serialization below.
-@tf.keras.utils.register_keras_serializable(package='TestOnlyAttention')
+@tf_keras.utils.register_keras_serializable(package='TestOnlyAttention')
 class ValidatedAttentionLayer(attention.MultiHeadAttention):
 
   def __init__(self, call_list, **kwargs):
     super(ValidatedAttentionLayer, self).__init__(**kwargs)
     self.list = call_list
 
   def call(self, query, value, attention_mask=None):
@@ -44,25 +43,25 @@
     return config
 
 
 # Test class implements a simple feedforward layer. If this layer is called
 # at any point, the list passed to the config object will be filled with a
 # boolean 'True'. We register this class as a Keras serializable so we can
 # test serialization below.
-@tf.keras.utils.register_keras_serializable(package='TestOnlyFeedforward')
-class ValidatedFeedforwardLayer(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='TestOnlyFeedforward')
+class ValidatedFeedforwardLayer(tf_keras.layers.Layer):
 
   def __init__(self, call_list, activation, **kwargs):
     super(ValidatedFeedforwardLayer, self).__init__(**kwargs)
     self.list = call_list
     self.activation = activation
 
   def build(self, input_shape):
-    hidden_size = input_shape.as_list()[-1]
-    self._feedforward_dense = tf.keras.layers.EinsumDense(
+    hidden_size = input_shape[-1]
+    self._feedforward_dense = tf_keras.layers.EinsumDense(
         '...x,xy->...y',
         output_shape=hidden_size,
         bias_axes='y',
         activation=self.activation,
         name='feedforward')
 
   def call(self, inputs):
@@ -72,22 +71,19 @@
   def get_config(self):
     config = super(ValidatedFeedforwardLayer, self).get_config()
     config['call_list'] = []
     config['activation'] = self.activation
     return config
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class TransformerLayerTest(keras_parameterized.TestCase):
+class TransformerLayerTest(tf.test.TestCase):
 
   def tearDown(self):
     super(TransformerLayerTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   def test_layer_creation(self):
     sequence_length = 21
     width = 80
 
     call_list = []
     attention_layer_cfg = {
@@ -99,15 +95,15 @@
         attention_cls=ValidatedAttentionLayer,
         attention_cfg=attention_layer_cfg,
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu')
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
     # If call_list[0] exists and is True, the passed layer class was
     # instantiated from the given config properly.
     self.assertNotEmpty(call_list)
@@ -134,15 +130,15 @@
         feedforward_cls=ValidatedFeedforwardLayer,
         feedforward_cfg=feedforward_layer_cfg,
         num_attention_heads=10,
         inner_dim=None,
         inner_activation=None)
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
     # If call_list[0] exists and is True, the passed layer class was
     # instantiated from the given config properly.
     self.assertNotEmpty(call_list)
@@ -165,17 +161,17 @@
         attention_cls=ValidatedAttentionLayer,
         attention_cfg=attention_layer_cfg,
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu')
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
     # If call_list[0] exists and is True, the passed layer class was
     # instantiated from the given config properly.
     self.assertNotEmpty(call_list)
     self.assertTrue(call_list[0], "The passed layer class wasn't instantiated.")
@@ -194,19 +190,19 @@
         attention_cls=ValidatedAttentionLayer,
         attention_cfg=attention_layer_cfg,
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu')
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(data_tensor, output_tensor)
+    model = tf_keras.Model(data_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     _ = model.predict(input_data)
@@ -236,21 +232,21 @@
         attention_cfg=attention_layer_cfg,
         feedforward_cls=feedforward_layer,
         num_attention_heads=10,
         inner_dim=None,
         inner_activation=None)
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -280,21 +276,21 @@
         attention_cls=ValidatedAttentionLayer,
         attention_cfg=attention_layer_cfg,
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu')
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -304,15 +300,15 @@
     _ = model.predict([input_data, mask_data])
     # If call_list[0] exists and is True, the passed layer class was
     # instantiated from the given config properly.
     self.assertNotEmpty(call_list)
     self.assertTrue(call_list[0], "The passed layer class wasn't instantiated.")
 
   def test_layer_invocation_with_float16_dtype(self):
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     sequence_length = 21
     width = 80
 
     call_list = []
     attention_layer_cfg = {
         'num_heads': 10,
         'key_dim': 8,
@@ -322,21 +318,21 @@
         attention_cls=ValidatedAttentionLayer,
         attention_cfg=attention_layer_cfg,
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu')
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = (10 * np.random.random_sample(
         (batch_size, sequence_length, width)))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -361,18 +357,18 @@
     }
     test_layer = transformer_scaffold.TransformerScaffold(
         attention_cls=ValidatedAttentionLayer,
         attention_cfg=attention_layer_cfg,
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output.shape.as_list())
     # If call_list[0] exists and is True, the passed layer class was
     # instantiated from the given config properly.
     self.assertNotEmpty(call_list)
     self.assertTrue(call_list[0])
@@ -392,21 +388,21 @@
         attention_cls=ValidatedAttentionLayer,
         attention_cfg=attention_layer_cfg,
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu')
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -417,15 +413,15 @@
 
     # Serialize the model config. Pass the serialized data through json to
     # ensure that we can serialize this layer to disk.
     serialized_data = model.get_config()
 
     # Create a new model from the old config, and copy the weights. These models
     # should have identical outputs.
-    new_model = tf.keras.Model.from_config(serialized_data)
+    new_model = tf_keras.Model.from_config(serialized_data)
     new_model.set_weights(model.get_weights())
     output = new_model.predict([input_data, mask_data])
 
     self.assertAllClose(pre_serialization_output, output)
 
     # If the layer was configured correctly, it should have a list attribute
     # (since it should have the custom class and config passed to it).
@@ -458,21 +454,21 @@
         feedforward_cls=ValidatedFeedforwardLayer,
         feedforward_cfg=feedforward_layer_cfg,
         num_attention_heads=10,
         inner_dim=None,
         inner_activation=None)
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -480,15 +476,15 @@
     mask_data = np.random.randint(
         2, size=(batch_size, sequence_length, sequence_length))
     pre_serialization_output = model.predict([input_data, mask_data])
 
     serialized_data = model.get_config()
     # Create a new model from the old config, and copy the weights. These models
     # should have identical outputs.
-    new_model = tf.keras.Model.from_config(serialized_data)
+    new_model = tf_keras.Model.from_config(serialized_data)
     new_model.set_weights(model.get_weights())
     output = new_model.predict([input_data, mask_data])
 
     self.assertAllClose(pre_serialization_output, output)
 
     # If the layer was configured correctly, it should have a list attribute
     # (since it should have the custom class and config passed to it).
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_xl.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_xl.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based Transformer XL layer."""
 
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling.layers import relative_attention
 
 
 def _cache_memory(current_state, previous_state, memory_length, reuse_length=0):
   """Caches hidden states into memory.
@@ -47,16 +47,16 @@
     else:
       new_mem = tf.concat(
           [previous_state, current_state], 1)[:, -memory_length:, :]
 
   return tf.stop_gradient(new_mem)
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class TransformerXLBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class TransformerXLBlock(tf_keras.layers.Layer):
   """Transformer XL block.
 
   This implements a Transformer XL block from "Transformer-XL: Attentive
   Language Models Beyond a Fixed-Length Context"
   (https://arxiv.org/abs/1901.02860).
 
   This block is further extended to allow for the Transformer-XL
@@ -147,40 +147,40 @@
         num_heads=self._num_heads,
         key_dim=self._head_size,
         value_dim=self._head_size,
         dropout=self._attention_dropout_rate,
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         name="rel_attn")
-    self._attention_dropout = tf.keras.layers.Dropout(
+    self._attention_dropout = tf_keras.layers.Dropout(
         rate=self._attention_dropout_rate)
-    self._attention_layer_norm = tf.keras.layers.LayerNormalization(
+    self._attention_layer_norm = tf_keras.layers.LayerNormalization(
         name="self_attention_layer_norm",
         axis=-1,
         epsilon=self._norm_epsilon,
         dtype=tf.float32)
-    self._inner_dense = tf.keras.layers.EinsumDense(
+    self._inner_dense = tf_keras.layers.EinsumDense(
         "abc,cd->abd",
         output_shape=(None, self._inner_size),
         bias_axes="d",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         name="inner")
 
-    self._inner_activation_layer = tf.keras.layers.Activation(
+    self._inner_activation_layer = tf_keras.layers.Activation(
         self._inner_activation)
-    self._inner_dropout_layer = tf.keras.layers.Dropout(
+    self._inner_dropout_layer = tf_keras.layers.Dropout(
         rate=self._inner_dropout)
-    self._output_dense = tf.keras.layers.EinsumDense(
+    self._output_dense = tf_keras.layers.EinsumDense(
         "abc,cd->abd",
         output_shape=(None, hidden_size),
         bias_axes="d",
         name="output",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer))
-    self._output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
-    self._output_layer_norm = tf.keras.layers.LayerNormalization(
+    self._output_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
+    self._output_layer_norm = tf_keras.layers.LayerNormalization(
         name="output_layer_norm",
         axis=-1,
         epsilon=self._norm_epsilon)
 
     super().build(input_shape)
 
   def get_config(self):
@@ -315,15 +315,15 @@
       layer_output = self._output_dropout(layer_output)
       layer_output = self._output_layer_norm(layer_output + attention_stream)
       attention_output[attention_key] = layer_output
 
     return attention_output
 
 
-class TransformerXL(tf.keras.layers.Layer):
+class TransformerXL(tf_keras.layers.Layer):
   """Transformer XL.
 
   This layer combines multiple Transformer XL blocks from "Transformer-XL:
   Attentive Language Models Beyond a Fixed-Length Context"
   (https://arxiv.org/abs/1901.02860).
 
   This layer handles the attention biases as well as memory caching and reuse
@@ -424,15 +424,15 @@
               attention_dropout_rate=self._attention_dropout_rate,
               norm_epsilon=1e-12,
               inner_activation=self._inner_activation,
               two_stream=self._two_stream,
               kernel_initializer="variance_scaling",
               name="layer_%d" % i))
 
-    self.output_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self.output_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
 
   def get_config(self):
     config = {
         "vocab_size":
             self._vocab_size,
         "num_layers":
             self._num_layers,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/transformer_xl_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/transformer_xl_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,19 +10,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Transformer XL."""
 
+from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 
 from official.nlp.modeling.layers import transformer_xl
 
 
 def create_mock_transformer_xl_data(
     batch_size,
     num_heads,
@@ -111,16 +111,15 @@
         2, size=(batch_size, seq_length, total_seq_length))
     data["segment_matrix"] = tf.math.equal(segment_matrix, 1)
     data[segment_encoding_name] = tf.random.normal(shape=segment_encoding_shape)
 
   return data
 
 
-@keras_parameterized.run_all_keras_modes
-class TransformerXLBlockTest(keras_parameterized.TestCase):
+class TransformerXLBlockTest(tf.test.TestCase, parameterized.TestCase):
 
   @combinations.generate(combinations.combine(
       memory_length=[0, 4],
       two_stream=[True, False],
       state=[True, False],
       mask=[True, False],
       segment=[True, False]))
@@ -182,16 +181,15 @@
         two_stream=False)
     transformer_xl_block_config = transformer_xl_block.get_config()
     new_block = transformer_xl.TransformerXLBlock.from_config(
         transformer_xl_block_config)
     self.assertEqual(transformer_xl_block_config, new_block.get_config())
 
 
-@keras_parameterized.run_all_keras_modes
-class TransformerXLTest(keras_parameterized.TestCase):
+class TransformerXLTest(tf.test.TestCase, parameterized.TestCase):
 
   @combinations.generate(combinations.combine(
       two_stream=[True, False],
       memory_length=[0, 4],
       reuse_length=[0, 4],
       tie_attention_biases=[True, False],
       state=[True, False],
@@ -229,40 +227,40 @@
         num_layers=num_layers,
         head_size=head_size,
         hidden_size=hidden_size,
         num_attention_heads=num_heads,
         inner_size=inner_size,
         dropout_rate=0.,
         attention_dropout_rate=0.,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         two_stream=two_stream,
         tie_attention_biases=tie_attention_biases,
         memory_length=memory_length,
         reuse_length=reuse_length,
         inner_activation="relu")
     attention_output, cached_memory_states = transformer_xl_layer(**data)
     if two_stream:
       self.assertEqual(attention_output.shape,
                        [batch_size, num_predictions, hidden_size])
     else:
       self.assertEqual(attention_output.shape,
                        [batch_size, seq_length, hidden_size])
-    self.assertEqual(len(cached_memory_states), num_layers)
+    self.assertLen(cached_memory_states, num_layers)
 
   def test_get_config(self):
     transformer_xl_layer = transformer_xl.TransformerXL(
         vocab_size=32000,
         num_layers=12,
         hidden_size=36,
         head_size=12,
         num_attention_heads=12,
         inner_size=12,
         dropout_rate=0.,
         attention_dropout_rate=0.,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         two_stream=False,
         tie_attention_biases=True,
         memory_length=0,
         reuse_length=0,
         inner_activation="relu")
     transformer_xl_config = transformer_xl_layer.get_config()
     new_transformer_xl = transformer_xl.TransformerXL.from_config(
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/layers/util.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/layers/util.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based transformer block layer."""
 
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class TfFunctionIfEagerDecorator(object):
   """Helper decorator function to optionally apply the @tf.function annotation."""
 
   def __init__(self, **kwargs):
     self.func_kwargs = kwargs
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/losses/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/losses/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Weighted sparse categorical cross-entropy losses."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _adjust_labels(labels, predictions):
   """Adjust the 'labels' tensor by squeezing it if needed."""
   labels = tf.cast(labels, tf.int32)
   if len(predictions.shape) == len(labels.shape):
     labels = tf.squeeze(labels, [-1])
@@ -57,15 +57,15 @@
     RuntimeError if the passed tensors do not have the same rank.
   """
   # When using these functions with the Keras core API, we will need to squeeze
   # the labels tensor - Keras adds a spurious inner dimension.
   labels, predictions = _adjust_labels(labels, predictions)
   _validate_rank(labels, predictions, weights)
 
-  example_losses = tf.keras.losses.sparse_categorical_crossentropy(
+  example_losses = tf_keras.losses.sparse_categorical_crossentropy(
       labels, predictions, from_logits=from_logits)
 
   if weights is None:
     return tf.reduce_mean(example_losses)
   weights = tf.cast(weights, predictions.dtype)
   return tf.math.divide_no_nan(
       tf.reduce_sum(example_losses * weights), tf.reduce_sum(weights))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/losses/weighted_sparse_categorical_crossentropy_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,24 +11,22 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for masked LM loss."""
 import numpy as np
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import layers
 from official.nlp.modeling import networks
 from official.nlp.modeling.losses import weighted_sparse_categorical_crossentropy
 
 
-@keras_parameterized.run_all_keras_modes
-class ClassificationLossTest(keras_parameterized.TestCase):
+class ClassificationLossTest(tf.test.TestCase):
 
   def create_lm_model(self,
                       vocab_size,
                       sequence_length,
                       hidden_size,
                       num_predictions,
                       output="predictions"):
@@ -37,29 +35,29 @@
     xformer_stack = networks.BertEncoder(
         vocab_size=vocab_size,
         num_layers=1,
         sequence_length=sequence_length,
         hidden_size=hidden_size,
         num_attention_heads=4,
     )
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     _ = xformer_stack([word_ids, mask, type_ids])
 
     # Create a maskedLM from the transformer stack.
     test_layer = layers.MaskedLM(
         embedding_table=xformer_stack.get_embedding_table(), output=output)
 
     # Create a model from the masked LM layer.
-    lm_input_tensor = tf.keras.Input(shape=(sequence_length, hidden_size))
-    masked_lm_positions = tf.keras.Input(
+    lm_input_tensor = tf_keras.Input(shape=(sequence_length, hidden_size))
+    masked_lm_positions = tf_keras.Input(
         shape=(num_predictions,), dtype=tf.int32)
     output = test_layer(lm_input_tensor, masked_positions=masked_lm_positions)
-    return tf.keras.Model([lm_input_tensor, masked_lm_positions], output)
+    return tf_keras.Model([lm_input_tensor, masked_lm_positions], output)
 
   def test_loss_3d_input(self):
     """Test overall loss with a 3-dimensional input, from a masked LM."""
     vocab_size = 100
     sequence_length = 32
     hidden_size = 64
     num_predictions = 21
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_classifier.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_classifier.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,21 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """BERT cls-token classifier."""
 # pylint: disable=g-classes-have-attributes
 import collections
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling import layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class BertClassifier(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class BertClassifier(tf_keras.Model):
   """Classifier model based on a BERT-style transformer-based encoder.
 
   This is an implementation of the network structure surrounding a transformer
   encoder as described in "BERT: Pre-training of Deep Bidirectional Transformers
   for Language Understanding" (https://arxiv.org/abs/1810.04805).
 
   The BertClassifier allows a user to pass in a transformer stack, and
@@ -75,15 +75,15 @@
       # Because we have a copy of inputs to create this Model object, we can
       # invoke the Network object with its own input tensors to start the Model.
       outputs = network(inputs)
       if isinstance(outputs, list):
         cls_inputs = outputs[1]
       else:
         cls_inputs = outputs['pooled_output']
-      cls_inputs = tf.keras.layers.Dropout(rate=dropout_rate)(cls_inputs)
+      cls_inputs = tf_keras.layers.Dropout(rate=dropout_rate)(cls_inputs)
     else:
       outputs = network(inputs)
       if isinstance(outputs, list):
         cls_inputs = outputs[0]
       else:
         cls_inputs = outputs['sequence_output']
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_classifier_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_classifier_test.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,26 +11,22 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for BERT trainer network."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import layers
 from official.nlp.modeling import networks
 from official.nlp.modeling.models import bert_classifier
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class BertClassifierTest(keras_parameterized.TestCase):
+class BertClassifierTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(('single_cls', 1, False), ('3_cls', 3, False),
                                   ('3_cls_dictoutputs', 3, True))
   def test_bert_trainer(self, num_classes, dict_outputs):
     """Validate that the Keras object can be created."""
     # Build a transformer network to use within the BERT trainer.
     vocab_size = 100
@@ -39,17 +35,17 @@
         vocab_size=vocab_size, num_layers=2, dict_outputs=dict_outputs)
 
     # Create a BERT trainer with the created network.
     bert_trainer_model = bert_classifier.BertClassifier(
         test_network, num_classes=num_classes)
 
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     # Invoke the trainer model on the inputs. This causes the layer to be built.
     cls_outs = bert_trainer_model([word_ids, mask, type_ids])
 
     # Validate that the outputs are of the expected shape.
     expected_classification_shape = [None, num_classes]
     self.assertAllEqual(expected_classification_shape, cls_outs.shape.as_list())
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_pretrainer.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_pretrainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,23 +16,23 @@
 # pylint: disable=g-classes-have-attributes
 import collections
 import copy
 from typing import List, Optional
 
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 from official.nlp.modeling import networks
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class BertPretrainer(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class BertPretrainer(tf_keras.Model):
   """BERT pretraining model.
 
   [Note] Please use the new `BertPretrainerV2` for your projects.
 
   The BertPretrainer allows a user to pass in a transformer stack, and
   instantiates the masked language model and classification networks that are
   used to create the training objectives.
@@ -88,15 +88,15 @@
     if sequence_output_length is not None and (sequence_output_length <
                                                num_token_predictions):
       raise ValueError(
           "The passed network's output length is %s, which is less than the "
           'requested num_token_predictions %s.' %
           (sequence_output_length, num_token_predictions))
 
-    masked_lm_positions = tf.keras.layers.Input(
+    masked_lm_positions = tf_keras.layers.Input(
         shape=(num_token_predictions,),
         name='masked_lm_positions',
         dtype=tf.int32)
     inputs.append(masked_lm_positions)
 
     if embedding_table is None:
       embedding_table = network.get_embedding_table()
@@ -154,17 +154,17 @@
     return dict(self._config._asdict())
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
     return cls(**config)
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 @gin.configurable
-class BertPretrainerV2(tf.keras.Model):
+class BertPretrainerV2(tf_keras.Model):
   """BERT pretraining model V2.
 
   Adds the masked language model head and optional classification heads upon the
   transformer encoder.
 
   Args:
     encoder_network: A transformer network. This network should output a
@@ -185,19 +185,19 @@
   Outputs: A dictionary of `lm_output`, classification head outputs keyed by
     head names, and also outputs from `encoder_network`, keyed by
     `sequence_output` and `encoder_outputs` (if any).
   """
 
   def __init__(
       self,
-      encoder_network: tf.keras.Model,
+      encoder_network: tf_keras.Model,
       mlm_activation=None,
       mlm_initializer='glorot_uniform',
-      classification_heads: Optional[List[tf.keras.layers.Layer]] = None,
-      customized_masked_lm: Optional[tf.keras.layers.Layer] = None,
+      classification_heads: Optional[List[tf_keras.layers.Layer]] = None,
+      customized_masked_lm: Optional[tf_keras.layers.Layer] = None,
       name: str = 'bert',
       **kwargs):
     super().__init__(self, name=name, **kwargs)
     self._config = {
         'encoder_network': encoder_network,
         'mlm_initializer': mlm_initializer,
         'mlm_activation': mlm_activation,
@@ -214,23 +214,23 @@
       raise ValueError('Classification heads should have unique names.')
 
     self.masked_lm = customized_masked_lm or layers.MaskedLM(
         embedding_table=self.encoder_network.get_embedding_table(),
         activation=mlm_activation,
         initializer=mlm_initializer,
         name='cls/predictions')
-    masked_lm_positions = tf.keras.layers.Input(
+    masked_lm_positions = tf_keras.layers.Input(
         shape=(None,), name='masked_lm_positions', dtype=tf.int32)
     if isinstance(inputs, dict):
       inputs['masked_lm_positions'] = masked_lm_positions
     else:
       inputs.append(masked_lm_positions)
     self.inputs = inputs
 
-  def call(self, inputs):
+  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     if isinstance(inputs, list):
       logging.warning('List inputs to BertPretrainer are discouraged.')
       inputs = dict([
           (ref.name, tensor) for ref, tensor in zip(self.inputs, inputs)
       ])
 
     outputs = dict()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_pretrainer_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_pretrainer_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,26 +12,22 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for BERT pretrainer model."""
 import itertools
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import layers
 from official.nlp.modeling import networks
 from official.nlp.modeling.models import bert_pretrainer
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class BertPretrainerTest(keras_parameterized.TestCase):
+class BertPretrainerTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_bert_pretrainer(self):
     """Validate that the Keras object can be created."""
     # Build a transformer network to use within the BERT trainer.
     vocab_size = 100
     sequence_length = 512
     test_network = networks.BertEncoder(
@@ -44,18 +40,18 @@
     num_token_predictions = 2
     bert_trainer_model = bert_pretrainer.BertPretrainer(
         test_network,
         num_classes=num_classes,
         num_token_predictions=num_token_predictions)
 
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    masked_lm_positions = tf.keras.Input(
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    masked_lm_positions = tf_keras.Input(
         shape=(num_token_predictions,), dtype=tf.int32)
 
     # Invoke the trainer model on the inputs. This causes the layer to be built.
     outputs = bert_trainer_model(
         [word_ids, mask, type_ids, masked_lm_positions])
 
     # Validate that the outputs are of the expected shape.
@@ -105,26 +101,27 @@
     _ = new_bert_trainer_model.to_json()
 
     # If the serialization was successful, the new config should match the old.
     self.assertAllEqual(bert_trainer_model.get_config(),
                         new_bert_trainer_model.get_config())
 
 
-class BertPretrainerV2Test(keras_parameterized.TestCase):
+class BertPretrainerV2Test(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.parameters(itertools.product(
       (False, True),
       (False, True),
       (False, True),
       (False, True),
   ))
   def test_bert_pretrainerv2(self, dict_outputs, return_all_encoder_outputs,
                              use_customized_masked_lm, has_masked_lm_positions):
     """Validate that the Keras object can be created."""
     # Build a transformer network to use within the BERT trainer.
+    del dict_outputs, return_all_encoder_outputs
     vocab_size = 100
     sequence_length = 512
     hidden_size = 48
     num_layers = 2
     test_network = networks.BertEncoderV2(
         vocab_size=vocab_size,
         num_layers=num_layers,
@@ -140,19 +137,19 @@
       customized_masked_lm = None
 
     bert_trainer_model = bert_pretrainer.BertPretrainerV2(
         encoder_network=test_network, customized_masked_lm=customized_masked_lm)
     num_token_predictions = 20
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
     inputs = dict(
-        input_word_ids=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
-        input_mask=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
-        input_type_ids=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32))
+        input_word_ids=tf_keras.Input(shape=(sequence_length,), dtype=tf.int32),
+        input_mask=tf_keras.Input(shape=(sequence_length,), dtype=tf.int32),
+        input_type_ids=tf_keras.Input(shape=(sequence_length,), dtype=tf.int32))
     if has_masked_lm_positions:
-      inputs['masked_lm_positions'] = tf.keras.Input(
+      inputs['masked_lm_positions'] = tf_keras.Input(
           shape=(num_token_predictions,), dtype=tf.int32)
 
     # Invoke the trainer model on the inputs. This causes the layer to be built.
     outputs = bert_trainer_model(inputs)
 
     has_encoder_outputs = True  # dict_outputs or return_all_encoder_outputs
     expected_keys = ['sequence_output', 'pooled_output']
@@ -192,18 +189,18 @@
     bert_trainer_model = bert_pretrainer.BertPretrainerV2(
         encoder_network=test_network,
         classification_heads=[layers.MultiClsHeads(
             inner_dim=5, cls_list=[('foo', 2), ('bar', 3)])])
     num_token_predictions = 20
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
     inputs = dict(
-        input_word_ids=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
-        input_mask=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
-        input_type_ids=tf.keras.Input(shape=(sequence_length,), dtype=tf.int32),
-        masked_lm_positions=tf.keras.Input(
+        input_word_ids=tf_keras.Input(shape=(sequence_length,), dtype=tf.int32),
+        input_mask=tf_keras.Input(shape=(sequence_length,), dtype=tf.int32),
+        input_type_ids=tf_keras.Input(shape=(sequence_length,), dtype=tf.int32),
+        masked_lm_positions=tf_keras.Input(
             shape=(num_token_predictions,), dtype=tf.int32))
 
     # Invoke the trainer model on the inputs. This causes the layer to be built.
     outputs = bert_trainer_model(inputs)
     self.assertEqual(outputs['foo'].shape.as_list(), [None, 2])
     self.assertEqual(outputs['bar'].shape.as_list(), [None, 3])
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_span_labeler.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_span_labeler.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,21 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """BERT Question Answering model."""
 # pylint: disable=g-classes-have-attributes
 import collections
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling import networks
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class BertSpanLabeler(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class BertSpanLabeler(tf_keras.Model):
   """Span labeler model based on a BERT-style transformer-based encoder.
 
   This is an implementation of the network structure surrounding a transformer
   encoder as described in "BERT: Pre-training of Deep Bidirectional Transformers
   for Language Understanding" (https://arxiv.org/abs/1810.04805).
 
   The BertSpanLabeler allows a user to pass in a transformer encoder, and
@@ -76,18 +76,18 @@
         output=output,
         name='span_labeling')
     start_logits, end_logits = span_labeling(sequence_output)
 
     # Use identity layers wrapped in lambdas to explicitly name the output
     # tensors. This allows us to use string-keyed dicts in Keras fit/predict/
     # evaluate calls.
-    start_logits = tf.keras.layers.Lambda(
+    start_logits = tf_keras.layers.Lambda(
         tf.identity, name='start_positions')(
             start_logits)
-    end_logits = tf.keras.layers.Lambda(
+    end_logits = tf_keras.layers.Lambda(
         tf.identity, name='end_positions')(
             end_logits)
 
     logits = [start_logits, end_logits]
 
     # b/164516224
     # Once we've created the network using the Functional API, we call
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_span_labeler_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_span_labeler_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,48 +11,44 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for BERT trainer network."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import networks
 from official.nlp.modeling.models import bert_span_labeler
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class BertSpanLabelerTest(keras_parameterized.TestCase):
+class BertSpanLabelerTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.parameters(True, False)
   def test_bert_trainer(self, dict_outputs):
     """Validate that the Keras object can be created."""
     # Build a transformer network to use within the BERT trainer.
     vocab_size = 100
     sequence_length = 512
     test_network = networks.BertEncoder(
         vocab_size=vocab_size, num_layers=2, dict_outputs=dict_outputs)
 
     # Create a BERT trainer with the created network.
     bert_trainer_model = bert_span_labeler.BertSpanLabeler(test_network)
 
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     # Invoke the trainer model on the inputs. This causes the layer to be built.
     cls_outs = bert_trainer_model([word_ids, mask, type_ids])
 
     # Validate that there are 2 outputs are of the expected shape.
-    self.assertEqual(2, len(cls_outs))
+    self.assertLen(cls_outs, 2)
     expected_shape = [None, sequence_length]
     for out in cls_outs:
       self.assertAllEqual(expected_shape, out.shape.as_list())
 
   def test_bert_trainer_named_compilation(self):
     """Validate compilation using explicit output names."""
     # Build a transformer network to use within the BERT trainer.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_token_classifier.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_token_classifier.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,19 +11,19 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """BERT token classifier."""
 # pylint: disable=g-classes-have-attributes
 import collections
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class BertTokenClassifier(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class BertTokenClassifier(tf_keras.Model):
   """Token classifier model based on a BERT-style transformer-based encoder.
 
   This is an implementation of the network structure surrounding a transformer
   encoder as described in "BERT: Pre-training of Deep Bidirectional Transformers
   for Language Understanding" (https://arxiv.org/abs/1810.04805).
 
   The BertTokenClassifier allows a user to pass in a transformer stack, and
@@ -64,28 +64,28 @@
     # Because we have a copy of inputs to create this Model object, we can
     # invoke the Network object with its own input tensors to start the Model.
     outputs = network(inputs)
     if isinstance(outputs, list):
       sequence_output = outputs[0]
     else:
       sequence_output = outputs['sequence_output']
-    sequence_output = tf.keras.layers.Dropout(rate=dropout_rate)(
+    sequence_output = tf_keras.layers.Dropout(rate=dropout_rate)(
         sequence_output)
 
-    classifier = tf.keras.layers.Dense(
+    classifier = tf_keras.layers.Dense(
         num_classes,
         activation=None,
         kernel_initializer=initializer,
         name='predictions/transform/logits')
     logits = classifier(sequence_output)
     if output == 'logits':
       output_tensors = {'logits': logits}
     elif output == 'predictions':
       output_tensors = {
-          'predictions': tf.keras.layers.Activation(tf.nn.log_softmax)(logits)
+          'predictions': tf_keras.layers.Activation(tf.nn.log_softmax)(logits)
       }
     else:
       raise ValueError(
           ('Unknown `output` value "%s". `output` can be either "logits" or '
            '"predictions"') % output)
 
     if output_encoder_outputs:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/bert_token_classifier_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/bert_token_classifier_test.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,25 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for BERT token classifier."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import networks
 from official.nlp.modeling.models import bert_token_classifier
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class BertTokenClassifierTest(keras_parameterized.TestCase):
+class BertTokenClassifierTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.parameters((True, True), (False, False))
   def test_bert_trainer(self, dict_outputs, output_encoder_outputs):
     """Validate that the Keras object can be created."""
     # Build a transformer network to use within the BERT trainer.
     vocab_size = 100
     sequence_length = 512
@@ -45,17 +41,17 @@
     num_classes = 3
     bert_trainer_model = bert_token_classifier.BertTokenClassifier(
         test_network,
         num_classes=num_classes,
         output_encoder_outputs=output_encoder_outputs)
 
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     # Invoke the trainer model on the inputs. This causes the layer to be built.
     outputs = bert_trainer_model([word_ids, mask, type_ids])
     if output_encoder_outputs:
       logits = outputs['logits']
       encoder_outputs = outputs['encoder_outputs']
       self.assertAllEqual(encoder_outputs.shape.as_list(),
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/dual_encoder.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/dual_encoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,21 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Trainer network for dual encoder style models."""
 # pylint: disable=g-classes-have-attributes
 import collections
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling import layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class DualEncoder(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class DualEncoder(tf_keras.Model):
   """A dual encoder model based on a transformer-based encoder.
 
   This is an implementation of the dual encoder network structure based on the
   transfomer stack, as described in ["Language-agnostic BERT Sentence
   Embedding"](https://arxiv.org/abs/2007.01852)
 
   The DualEncoder allows a user to pass in a transformer stack, and build a dual
@@ -39,66 +39,66 @@
     logit_margin: The margin between positive and negative when doing training.
     output: The output style for this network. Can be either `logits` or
       `predictions`. If set to `predictions`, it will output the embedding
       producted by transformer network.
   """
 
   def __init__(self,
-               network: tf.keras.Model,
+               network: tf_keras.Model,
                max_seq_length: int = 32,
                normalize: bool = True,
                logit_scale: float = 1.0,
                logit_margin: float = 0.0,
                output: str = 'logits',
                **kwargs) -> None:
 
     if output == 'logits':
-      left_word_ids = tf.keras.layers.Input(
+      left_word_ids = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='left_word_ids')
-      left_mask = tf.keras.layers.Input(
+      left_mask = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='left_mask')
-      left_type_ids = tf.keras.layers.Input(
+      left_type_ids = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='left_type_ids')
     else:
       # Keep the consistant with legacy BERT hub module input names.
-      left_word_ids = tf.keras.layers.Input(
+      left_word_ids = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')
-      left_mask = tf.keras.layers.Input(
+      left_mask = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='input_mask')
-      left_type_ids = tf.keras.layers.Input(
+      left_type_ids = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')
 
     left_inputs = [left_word_ids, left_mask, left_type_ids]
     left_outputs = network(left_inputs)
     if isinstance(left_outputs, list):
       left_sequence_output, left_encoded = left_outputs
     else:
       left_sequence_output = left_outputs['sequence_output']
       left_encoded = left_outputs['pooled_output']
     if normalize:
-      left_encoded = tf.keras.layers.Lambda(
+      left_encoded = tf_keras.layers.Lambda(
           lambda x: tf.nn.l2_normalize(x, axis=1))(
               left_encoded)
 
     if output == 'logits':
-      right_word_ids = tf.keras.layers.Input(
+      right_word_ids = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='right_word_ids')
-      right_mask = tf.keras.layers.Input(
+      right_mask = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='right_mask')
-      right_type_ids = tf.keras.layers.Input(
+      right_type_ids = tf_keras.layers.Input(
           shape=(max_seq_length,), dtype=tf.int32, name='right_type_ids')
 
       right_inputs = [right_word_ids, right_mask, right_type_ids]
       right_outputs = network(right_inputs)
       if isinstance(right_outputs, list):
         _, right_encoded = right_outputs
       else:
         right_encoded = right_outputs['pooled_output']
       if normalize:
-        right_encoded = tf.keras.layers.Lambda(
+        right_encoded = tf_keras.layers.Lambda(
             lambda x: tf.nn.l2_normalize(x, axis=1))(
                 right_encoded)
 
       dot_products = layers.MatMulWithMargin(
           logit_scale=logit_scale,
           logit_margin=logit_margin,
           name='dot_product')
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/dual_encoder_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/dual_encoder_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,25 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for dual encoder network."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import networks
 from official.nlp.modeling.models import dual_encoder
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class DualEncoderTest(keras_parameterized.TestCase):
+class DualEncoderTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.parameters((192, 'logits'), (768, 'predictions'))
   def test_dual_encoder(self, hidden_size, output):
     """Validate that the Keras object can be created."""
     # Build a transformer network to use within the dual encoder model.
     vocab_size = 100
     sequence_length = 512
@@ -40,21 +36,21 @@
         dict_outputs=True)
 
     # Create a dual encoder model with the created network.
     dual_encoder_model = dual_encoder.DualEncoder(
         test_network, max_seq_length=sequence_length, output=output)
 
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
-    left_word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    left_mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    left_type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-
-    right_word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    right_mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    right_type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    left_word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    left_mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    left_type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+
+    right_word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    right_mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    right_type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     if output == 'logits':
       outputs = dual_encoder_model([
           left_word_ids, left_mask, left_type_ids, right_word_ids, right_mask,
           right_type_ids
       ])
       _ = outputs['left_logits']
@@ -68,14 +64,15 @@
       expected_encoding_shape = [None, 768]
       self.assertAllEqual(expected_encoding_shape, left_encoded.shape.as_list())
 
   @parameterized.parameters((192, 'logits'), (768, 'predictions'))
   def test_dual_encoder_tensor_call(self, hidden_size, output):
     """Validate that the Keras object can be invoked."""
     # Build a transformer network to use within the dual encoder model.
+    del hidden_size
     sequence_length = 2
     test_network = networks.BertEncoder(vocab_size=100, num_layers=2)
 
     # Create a dual encoder model with the created network.
     dual_encoder_model = dual_encoder.DualEncoder(
         test_network, max_seq_length=sequence_length, output=output)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/electra_pretrainer.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/electra_pretrainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,22 +13,22 @@
 # limitations under the License.
 
 """Trainer network for ELECTRA models."""
 # pylint: disable=g-classes-have-attributes
 
 import copy
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class ElectraPretrainer(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class ElectraPretrainer(tf_keras.Model):
   """ELECTRA network training model.
 
   This is an implementation of the network structure described in "ELECTRA:
   Pre-training Text Encoders as Discriminators Rather Than Generators" (
   https://arxiv.org/abs/2003.10555).
 
   The ElectraPretrainer allows a user to pass in two transformer models, one for
@@ -100,24 +100,24 @@
         output=output_type,
         name='generator_masked_lm')
     self.classification = layers.ClassificationHead(
         inner_dim=generator_network.get_config()['hidden_size'],
         num_classes=num_classes,
         initializer=tf_utils.clone_initializer(mlm_initializer),
         name='generator_classification_head')
-    self.discriminator_projection = tf.keras.layers.Dense(
+    self.discriminator_projection = tf_keras.layers.Dense(
         units=discriminator_network.get_config()['hidden_size'],
         activation=mlm_activation,
         kernel_initializer=tf_utils.clone_initializer(mlm_initializer),
         name='discriminator_projection_head')
-    self.discriminator_head = tf.keras.layers.Dense(
+    self.discriminator_head = tf_keras.layers.Dense(
         units=1,
         kernel_initializer=tf_utils.clone_initializer(mlm_initializer))
 
-  def call(self, inputs):
+  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     """ELECTRA forward pass.
 
     Args:
       inputs: A dict of all inputs, same as the standard BERT model.
 
     Returns:
       outputs: A dict of pretrainer model outputs, including
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/electra_pretrainer_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/electra_pretrainer_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,25 +10,21 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for ELECTRA pre trainer network."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import networks
 from official.nlp.modeling.models import electra_pretrainer
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class ElectraPretrainerTest(keras_parameterized.TestCase):
+class ElectraPretrainerTest(tf.test.TestCase):
 
   def test_electra_pretrainer(self):
     """Validate that the Keras object can be created."""
     # Build a transformer network to use within the ELECTRA trainer.
     vocab_size = 100
     sequence_length = 512
     test_generator_network = networks.BertEncoder(
@@ -50,20 +46,20 @@
         discriminator_network=test_discriminator_network,
         vocab_size=vocab_size,
         num_classes=num_classes,
         num_token_predictions=num_token_predictions,
         disallow_correct=True)
 
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    lm_positions = tf.keras.Input(
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    lm_positions = tf_keras.Input(
         shape=(num_token_predictions,), dtype=tf.int32)
-    lm_ids = tf.keras.Input(shape=(num_token_predictions,), dtype=tf.int32)
+    lm_ids = tf_keras.Input(shape=(num_token_predictions,), dtype=tf.int32)
     inputs = {
         'input_word_ids': word_ids,
         'input_mask': mask,
         'input_type_ids': type_ids,
         'masked_lm_positions': lm_positions,
         'masked_lm_ids': lm_ids
     }
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/seq2seq_transformer.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/seq2seq_transformer.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,25 +12,27 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Implement Seq2Seq Transformer model by TF official NLP library.
 
 Model paper: https://arxiv.org/pdf/1706.03762.pdf
 """
+import inspect
 import math
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
+
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 from official.nlp.modeling.ops import beam_search
 
 EOS_ID = 1
 
 
-class Seq2SeqTransformer(tf.keras.Model):
+class Seq2SeqTransformer(tf_keras.Model):
   """Transformer model with Keras.
 
   Implemented as described in: https://arxiv.org/pdf/1706.03762.pdf
 
   The Transformer model consists of an encoder and decoder. The input is an int
   sequence (or a batch of sequences). The encoder produces a continuous
   representation, and the decoder uses the encoder output to generate
@@ -83,16 +85,16 @@
         initializer=tf.random_normal_initializer(
             mean=0., stddev=self._embedding_width**-0.5),
         scale_factor=self._embedding_width**0.5)
     self.encoder_layer = encoder_layer
     self.decoder_layer = decoder_layer
     self.position_embedding = layers.RelativePositionEmbedding(
         hidden_size=self._embedding_width)
-    self.encoder_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
-    self.decoder_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self.encoder_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
+    self.decoder_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
 
   def get_config(self):
     config = {
         "vocab_size": self._vocab_size,
         "hidden_size": self._embedding_width,
         "dropout_rate": self._dropout_rate,
         "padded_decode": self._padded_decode,
@@ -140,15 +142,15 @@
     else:
       raise KeyError(
           "The call method expects either `inputs` or `embedded_inputs` and "
           "`input_masks` as input features.")
 
     return embedded_inputs, boolean_mask, input_shape, source_dtype
 
-  def call(self, inputs):
+  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     """Calculate target logits or inferred target sequences.
 
     Args:
       inputs: a dictionary of tensors.
         Feature `inputs` (optional): int tensor with shape
           `[batch_size, input_length]`.
         Feature `embedded_inputs` (optional): float tensor with shape
@@ -353,15 +355,15 @@
                                       decoder_outputs)
       logits = tf.squeeze(logits, axis=[1])
       return logits, cache
 
     return symbols_to_logits_fn
 
 
-class TransformerEncoder(tf.keras.layers.Layer):
+class TransformerEncoder(tf_keras.layers.Layer):
   """Transformer encoder.
 
   Transformer encoder is made up of N identical layers. Each layer is composed
   of the sublayers:
     1. Self-attention layer
     2. Feedforward network (which is 2 fully-connected layers)
   """
@@ -390,15 +392,15 @@
       use_bias: Whether to enable use_bias in attention layer. If set False,
         use_bias in attention layer is disabled.
       norm_first: Whether to normalize inputs to attention and intermediate
         dense layers. If set False, output of attention and intermediate dense
         layers is normalized.
       norm_epsilon: Epsilon value to initialize normalization layers.
       intermediate_dropout: Dropout probability for intermediate_dropout_layer.
-      **kwargs: key word arguemnts passed to tf.keras.layers.Layer.
+      **kwargs: key word arguemnts passed to tf_keras.layers.Layer.
     """
 
     super(TransformerEncoder, self).__init__(**kwargs)
     self.num_layers = num_layers
     self.num_attention_heads = num_attention_heads
     self._intermediate_size = intermediate_size
     self._activation = activation
@@ -422,15 +424,15 @@
               attention_dropout=self._attention_dropout_rate,
               use_bias=self._use_bias,
               norm_first=self._norm_first,
               norm_epsilon=self._norm_epsilon,
               inner_dropout=self._intermediate_dropout,
               attention_initializer=attention_initializer(input_shape[2]),
               name=("layer_%d" % i)))
-    self.output_normalization = tf.keras.layers.LayerNormalization(
+    self.output_normalization = tf_keras.layers.LayerNormalization(
         epsilon=self._norm_epsilon, dtype="float32")
     super(TransformerEncoder, self).build(input_shape)
 
   def get_config(self):
     config = {
         "num_layers": self.num_layers,
         "num_attention_heads": self.num_attention_heads,
@@ -465,15 +467,15 @@
 
     output_tensor = encoder_inputs
     output_tensor = self.output_normalization(output_tensor)
 
     return output_tensor
 
 
-class TransformerDecoder(tf.keras.layers.Layer):
+class TransformerDecoder(tf_keras.layers.Layer):
   """Transformer decoder.
 
   Like the encoder, the decoder is made up of N identical layers.
   Each layer is composed of the sublayers:
     1. Self-attention layer
     2. Multi-headed attention layer combining encoder outputs with results from
        the previous self-attention layer.
@@ -487,14 +489,16 @@
                activation="relu",
                dropout_rate=0.0,
                attention_dropout_rate=0.0,
                use_bias=False,
                norm_first=True,
                norm_epsilon=1e-6,
                intermediate_dropout=0.0,
+               self_attention_cls=None,
+               cross_attention_cls=None,
                **kwargs):
     """Initialize a Transformer decoder.
 
     Args:
       num_layers: Number of layers.
       num_attention_heads: Number of attention heads.
       intermediate_size: Size of the intermediate (Feedforward) layer.
@@ -504,61 +508,84 @@
       use_bias: Whether to enable use_bias in attention layer. If set `False`,
         use_bias in attention layer is disabled.
       norm_first: Whether to normalize inputs to attention and intermediate
         dense layers. If set `False`, output of attention and intermediate dense
         layers is normalized.
       norm_epsilon: Epsilon value to initialize normalization layers.
       intermediate_dropout: Dropout probability for intermediate_dropout_layer.
-      **kwargs: key word arguemnts passed to tf.keras.layers.Layer.
+      self_attention_cls: An optional class to use for self attention
+        or a function that provides the class per layer.
+      cross_attention_cls: An optional class to use for cross attention
+        or a function that provides the class per layer.
+      **kwargs: key word arguemnts passed to tf_keras.layers.Layer.
     """
     super(TransformerDecoder, self).__init__(**kwargs)
     self.num_layers = num_layers
     self.num_attention_heads = num_attention_heads
     self._intermediate_size = intermediate_size
     self._activation = activation
     self._dropout_rate = dropout_rate
     self._attention_dropout_rate = attention_dropout_rate
     self._use_bias = use_bias
     self._norm_first = norm_first
     self._norm_epsilon = norm_epsilon
     self._intermediate_dropout = intermediate_dropout
+    self._self_attention_cls = self_attention_cls
+    self._cross_attention_cls = cross_attention_cls
 
   def build(self, input_shape):
     """Implements build() for the layer."""
+
+    def _select_attention_cls(attention_cls, index):
+      cls = None
+      if attention_cls is not None:
+        cls = (
+            attention_cls(index)
+            if inspect.isfunction(attention_cls)
+            else attention_cls
+        )
+      return cls
+
     self.decoder_layers = []
     for i in range(self.num_layers):
+      self_attention_cls = _select_attention_cls(self._self_attention_cls, i)
+      cross_attention_cls = _select_attention_cls(self._cross_attention_cls, i)
       self.decoder_layers.append(
           layers.TransformerDecoderBlock(
               num_attention_heads=self.num_attention_heads,
               intermediate_size=self._intermediate_size,
               intermediate_activation=self._activation,
               dropout_rate=self._dropout_rate,
               attention_dropout_rate=self._attention_dropout_rate,
               use_bias=self._use_bias,
               norm_first=self._norm_first,
               norm_epsilon=self._norm_epsilon,
               intermediate_dropout=self._intermediate_dropout,
               attention_initializer=attention_initializer(input_shape[2]),
-              name=("layer_%d" % i)))
-    self.output_normalization = tf.keras.layers.LayerNormalization(
+              name=("layer_%d" % i),
+              self_attention_cls=self_attention_cls,
+              cross_attention_cls=cross_attention_cls))
+    self.output_normalization = tf_keras.layers.LayerNormalization(
         epsilon=1e-6, dtype="float32")
     super(TransformerDecoder, self).build(input_shape)
 
   def get_config(self):
     config = {
         "num_layers": self.num_layers,
         "num_attention_heads": self.num_attention_heads,
         "intermediate_size": self._intermediate_size,
         "activation": self._activation,
         "dropout_rate": self._dropout_rate,
         "attention_dropout_rate": self._attention_dropout_rate,
         "use_bias": self._use_bias,
         "norm_first": self._norm_first,
         "norm_epsilon": self._norm_epsilon,
-        "intermediate_dropout": self._intermediate_dropout
+        "intermediate_dropout": self._intermediate_dropout,
+        "self_attention_cls": self._self_attention_cls,
+        "cross_attention_cls": self._cross_attention_cls,
     }
     base_config = super(TransformerDecoder, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self,
            target,
            memory,
@@ -616,8 +643,8 @@
       return self.output_normalization(output_tensor)
 
 
 def attention_initializer(hidden_size):
   """Initializer for attention layers in Seq2SeqTransformer."""
   hidden_size = int(hidden_size)
   limit = math.sqrt(6.0 / (hidden_size + hidden_size))
-  return tf.keras.initializers.RandomUniform(minval=-limit, maxval=limit)
+  return tf_keras.initializers.RandomUniform(minval=-limit, maxval=limit)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/t5.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/t5.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -24,15 +24,15 @@
 """
 import dataclasses
 import functools
 import math
 from typing import Callable, Dict, Optional, Sequence, Text, Union
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 ShapeLike = Union[int, Sequence[int], tf.TensorShape]
 Initializer = Callable[..., tf.Tensor]
 
 
@@ -153,15 +153,15 @@
     super().__init__(**kwargs)
     self.vocab_size = vocab_size
     self.features = features
     self.compute_dtype = compute_dtype
     if embeddings_initializer:
       self.embed_init = embeddings_initializer
     else:
-      self.embed_init = tf.keras.initializers.TruncatedNormal(stddev=1.0)
+      self.embed_init = tf_keras.initializers.TruncatedNormal(stddev=1.0)
     with self.name_scope:
       self.embeddings = self.create_variable(
           "embedding", [self.vocab_size, self.features],
           self.embed_init,
           dtype=self.dtype)
 
   @tf.Module.with_name_scope
@@ -220,15 +220,15 @@
   def __init__(self, hidden_size: int, epsilon: float = 1e-6, **kwargs):
     super().__init__(**kwargs)
     self.variance_epsilon = epsilon
     with self.name_scope:
       self.weight = self.create_variable(
           "scale", [hidden_size],
           dtype=self.dtype,
-          initializer=tf.keras.initializers.Ones())
+          initializer=tf_keras.initializers.Ones())
 
   @tf.Module.with_name_scope
   def __call__(self, x):
     # Keeps the computation inside the layer norm to be float32.
     compute_dtype = x.dtype
     x = tf.cast(x, dtype=tf.float32)
     variance = tf.math.reduce_mean(tf.math.square(x), axis=-1, keepdims=True)
@@ -250,22 +250,22 @@
     """Constructs a `Linear` module."""
     super().__init__(**kwargs)
     self.in_features = in_features
     self.out_features = out_features
     self.use_bias = use_bias
     self.w_init = w_init
     if self.use_bias:
-      self.b_init = b_init if b_init else tf.keras.initializers.Zeros()
+      self.b_init = b_init if b_init else tf_keras.initializers.Zeros()
     elif b_init is not None:
       raise ValueError("When not using a bias the b_init must be None.")
 
     with self.name_scope:
       if self.w_init is None:
         stddev = 1 / math.sqrt(self.in_features)
-        self.w_init = tf.keras.initializers.HeNormal()
+        self.w_init = tf_keras.initializers.HeNormal()
 
       self.w = self.create_variable(
           "kernel", [self.in_features, self.out_features],
           initializer=self.w_init,
           dtype=self.dtype)
 
       if self.use_bias:
@@ -318,21 +318,21 @@
       self.kernel_2d_shape = (self.in_features * self.num_heads,
                               self.out_features)
       self.kernel_3d_shape = (self.num_heads, self.in_features,
                               self.out_features)
       self.bias_shape = (self.out_features,)
       bias_rank = 1
     if self.use_bias:
-      self.b_init = b_init or tf.keras.initializers.Zeros()
+      self.b_init = b_init or tf_keras.initializers.Zeros()
     elif b_init is not None:
       raise ValueError("When not using a bias the b_init must be None.")
 
     with self.name_scope:
       if self.w_init is None:
-        self.w_init = tf.keras.initializers.HeNormal()
+        self.w_init = tf_keras.initializers.HeNormal()
 
       self.w = self.create_variable(
           "kernel",
           self.kernel_2d_shape,
           initializer=self.w_init,
           dtype=self.dtype)
 
@@ -585,16 +585,16 @@
 
       if rescale_query or weight_initializer is None:
         query_w_init = weight_initializer
       else:
         init_std_rescaling = tf.math.sqrt(tf.cast(self.d_kv, dtype=self.dtype))
         query_w_init = (
             lambda *args, **kwargs: (  # pylint: disable=g-long-lambda
-                tf_utils.clone_initializer(weight_initializer)(
-                    *args, **kwargs) / init_std_rescaling))
+                tf_utils.clone_initializer(weight_initializer)
+                (*args, **kwargs) / init_std_rescaling))
       self.q = Linear3D(
           self.d_model,
           self.d_kv,
           num_heads=self.num_heads,
           use_bias=self.use_bias,
           w_init=query_w_init,
           b_init=bias_initializer,
@@ -703,27 +703,29 @@
             position_bias, [0, 0, decode_position, 0],
             [bias_shape[0], bias_shape[1], 1, bias_shape[3]])
       scores += position_bias
 
     if mask is not None:
       scores += mask  # (bs, n_heads, qlen, klen)
     weights = tf.nn.softmax(tf.cast(scores, tf.float32), axis=-1)
+    output_scores = weights
     # weights shape = (bs, n_heads, qlen, klen)
     weights = tf.cast(weights, scores.dtype)
     weight_shape = tf_utils.get_shape_list(weights)
     # NOTE: T5 broadcasts along the "length" dim, but unclear which one that
     # corresponds to. We assume it is the query dimension.
     # (bs, n_heads, qlen, klen)
     weight_shape[-2] = 1
     weights = self.dropout(weights, training=training, noise_shape=weight_shape)
 
     c = tf.einsum("bnqk,bknd->bqnd", weights, v)
     c = self.o(c)
 
     outputs = dict(context=c)
+    outputs["attention_scores"] = output_scores
     if cache:
       outputs["cache"] = cache
     return outputs
 
 
 class SelfAttention(Module):
   """Self attention block including residual connection."""
@@ -849,14 +851,15 @@
                d_ff: int,
                ffn_activations: Sequence[str] = ("relu",),
                dropout_rate: Optional[float] = 0.0,
                layer_norm_epsilon: Optional[float] = 1e-6,
                rescale_query: bool = False,
                weight_initializer: Optional[Initializer] = None,
                bias_initializer: Optional[Initializer] = None,
+               return_attention_scores: bool = False,
                **kwargs):
     super().__init__(**kwargs)
     with self.name_scope:
       self.self_attention = SelfAttention(
           d_model=d_model,
           d_kv=d_kv,
           num_heads=num_heads,
@@ -877,14 +880,15 @@
           dropout_rate=dropout_rate,
           activations=ffn_activations,
           weight_initializer=weight_initializer,
           bias_initializer=bias_initializer,
           dtype=self.dtype,
           name="ffn")
       self.ffn_output_dropout = Dropout(dropout_rate)
+      self.return_attention_scores = return_attention_scores
 
   @tf.Module.with_name_scope
   def __call__(self,
                hidden_states,
                attention_mask=None,
                position_bias=None,
                training=False):
@@ -898,15 +902,16 @@
     ffn_output = self.ffn_layer_norm(attn_output)
     ffn_output = self.ffn(ffn_output, training=training)
     tensor_shape = tf_utils.get_shape_list(ffn_output)
     tensor_shape[-2] = 1
     ffn_output = self.ffn_output_dropout(
         ffn_output, noise_shape=tensor_shape, training=training)
     ffn_output = attn_output + ffn_output
-
+    if self.return_attention_scores:
+      return ffn_output, attention_outputs["attention_scores"]
     return ffn_output
 
 
 class EncDecoderBlock(Module):
   """Transformer Decoder Block with enc-decoder cross attention."""
 
   def __init__(self,
@@ -1010,26 +1015,27 @@
   dropout_rate: float = 0.0
   layer_norm_epsilon: float = 1e-6
   shared_embedding: bool = False
   vocab_embeddings_initializer: Optional[Initializer] = None
   relative_attention_num_buckets: int = 32
   relative_attention_max_distance: int = 128
   relative_embeddings_initializer: Optional[Initializer] = None
-  weight_initializer: Optional[Initializer] = (tf.keras.initializers.HeNormal())
+  weight_initializer: Optional[Initializer] = (tf_keras.initializers.HeNormal())
   bias_initializer: Optional[Initializer] = None
   rescale_query: bool = False
   bidirectional: bool = True
   ffn_activations: Sequence[str] = ("relu",)
   logits_via_embedding: bool = True
   num_decoder_layers: Optional[int] = None
   one_hot_embedding: bool = True
   layer_sharing: bool = False
   # If true, uses one relative embedding for all encoder layers and one for all
   # decoder layers. Otherwise, have relative embedding for each layer.
   use_shared_relative_position_bias: bool = True
+  return_attention_scores: bool = False
 
 
 class Encoder(Module):
   """Transformer Model Encoder for sequence to sequence."""
 
   def __init__(self,
                config: T5TransformerParams,
@@ -1095,14 +1101,15 @@
                   num_heads=self.config.num_heads,
                   d_ff=self.config.d_ff,
                   dropout_rate=self.config.dropout_rate,
                   ffn_activations=self.config.ffn_activations,
                   rescale_query=self.config.rescale_query,
                   weight_initializer=self.config.weight_initializer,
                   bias_initializer=self.config.bias_initializer,
+                  return_attention_scores=self.config.return_attention_scores,
                   dtype=self.dtype,
                   name="encoder_block_%d" % layer_idx))
       self.output_norm = RMSNorm(
           hidden_size=self.config.d_model,
           epsilon=self.config.layer_norm_epsilon,
           dtype=self.dtype,
           name="final_layer_norm")
@@ -1135,16 +1142,16 @@
                dense_inputs=None,
                training=False):
     """Applies Transformer model on the inputs.
 
     Args:
       inputs: input word ids. Optional if dense data are provided.
       encoder_mask: the encoder self-attention mask.
-      dense_inputs: dense input data. Concat after the embedding if word ids
-        are provided.
+      dense_inputs: dense input data. Concat after the embedding if word ids are
+        provided.
       training: whether it is training pass, affecting dropouts.
 
     Returns:
       output of a transformer encoder.
     """
     # Casts inputs to the dtype.
     if encoder_mask is not None:
@@ -1164,25 +1171,32 @@
     tensor_shape[-2] = 1
     x = self.input_dropout(x, noise_shape=tensor_shape, training=training)
     if inputs is not None:
       input_length = tf_utils.get_shape_list(inputs)[1]
     else:
       input_length = 0
 
+    attention_outputs = []
     for i in range(cfg.num_layers):
       position_bias = self.get_relpos_bias(input_length, dense_inputs, i)
       x = self.encoder_layers[i](
           x,
           attention_mask=encoder_mask,
           position_bias=position_bias,
           training=training)
+      if self.config.return_attention_scores:
+        x, attention_scores = x
+        attention_outputs.append(attention_scores)
 
     encoded = self.output_norm(x)
     encoded = self.output_dropout(encoded, training=training)
-    return encoded
+    if self.config.return_attention_scores:
+      return encoded, attention_outputs
+    else:
+      return encoded
 
 
 class Decoder(Module):
   """Transformer Model Decoder for sequence to sequence."""
 
   def __init__(self,
                config: T5TransformerParams,
@@ -1369,14 +1383,15 @@
                config: T5TransformerParams,
                compute_dtype: tf.DType = tf.float32,
                **kwargs):
     super().__init__(**kwargs)
     # Builds the model components.
     shared_embedding = config.shared_embedding
     self.compute_dtype = compute_dtype
+    self.config = config
     self.decoder_cfg = dataclasses.replace(config, bidirectional=False)
     if self.decoder_cfg.num_decoder_layers is None:
       self.decoder_cfg.num_decoder_layers = self.decoder_cfg.num_layers
     self.encoder_cfg = dataclasses.replace(config, bidirectional=True)
     with self.name_scope:
       if shared_embedding:
         self.shared_embedding = Embed(
@@ -1552,23 +1567,27 @@
     """
     encoded = self.encode(
         encoder_input_tokens=encoder_input_tokens,
         encoder_segment_ids=encoder_segment_ids,
         encoder_dense_inputs=encoder_dense_inputs,
         encoder_dense_segment_ids=encoder_dense_segment_ids,
         training=training)
+    if self.config.return_attention_scores:
+      encoded, attn_scores = encoded
     outputs = self.decode(
         encoded=encoded,
         decoder_target_tokens=decoder_target_tokens,
         encoder_input_tokens=encoder_input_tokens,  # only used for masks.
         encoder_dense_inputs=encoder_dense_inputs,  # only used for masks.
         decoder_input_tokens=decoder_input_tokens,
         encoder_segment_ids=encoder_segment_ids,
         encoder_dense_segment_ids=encoder_dense_segment_ids,
         decoder_segment_ids=decoder_segment_ids,
         training=training)
     outputs["encoded"] = encoded
+    if self.config.return_attention_scores:
+      outputs["attention_scores"] = attn_scores
     return outputs
 
   @property
   def checkpoint_items(self):
     return dict(encoder=self.encoder, decoder=self.decoder)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/t5_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/t5_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for t5."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.nlp.modeling.models import t5
 
 
 def _create_cache(batch_size,
@@ -58,15 +58,15 @@
 
     # Test initializers.
     l = t5.Embed(
         vocab_size=5,
         features=4,
         compute_dtype=dtype,
         name="foo",
-        embeddings_initializer=tf.keras.initializers.Zeros())
+        embeddings_initializer=tf_keras.initializers.Zeros())
     self.assertAllClose(l(inputs), tf.zeros((2, 2, 4), dtype))
 
   @parameterized.named_parameters(("bfloat16", tf.bfloat16),
                                   ("float32", tf.float32))
   def test_rms_norm(self, dtype):
     l = t5.RMSNorm(hidden_size=4, epsilon=0.0, name="foo")
     inputs = tf.ones((2, 4), dtype=dtype)
@@ -78,40 +78,40 @@
 
   @parameterized.named_parameters(("bfloat16", tf.bfloat16),
                                   ("float32", tf.float32))
   def test_linear(self, dtype):
     l = t5.Linear(
         in_features=4,
         out_features=4,
-        w_init=tf.keras.initializers.Ones(),
+        w_init=tf_keras.initializers.Ones(),
         name="foo")
     inputs = tf.ones((2, 4), dtype=dtype)
     outputs = l(inputs)
     self.assertEqual(outputs.shape, inputs.shape)
     self.assertEqual(outputs.dtype, dtype)
     self.assertLen(l.trainable_variables, 2)
 
   def test_linear3d(self):
     batch_size = 2
     l = t5.Linear3D(
         in_features=4,
         out_features=4,
         num_heads=2,
         to_3d=True,
-        w_init=tf.keras.initializers.Ones(),
+        w_init=tf_keras.initializers.Ones(),
         name="foo")
     inputs = np.ones((batch_size, 2, 4), dtype=np.float32)
     self.assertEqual(l(inputs).shape, (batch_size, 2, 2, 4))
 
     l = t5.Linear3D(
         in_features=2,
         out_features=4,
         num_heads=2,
         to_3d=False,
-        w_init=tf.keras.initializers.Ones(),
+        w_init=tf_keras.initializers.Ones(),
         name="foo")
     inputs = np.ones((batch_size, 2, 2, 2), dtype=np.float32)
     self.assertEqual(l(inputs).shape, (batch_size, 2, 4))
 
   def test_ffn(self):
     inputs = np.ones((2, 4), dtype=np.float32)
     for activation in ["relu", "linear", "gelu", "swish"]:
@@ -136,22 +136,22 @@
 
   @parameterized.named_parameters(("bfloat16", tf.bfloat16),
                                   ("float32", tf.float32))
   def test_relative_position(self, dtype):
     l = t5.RelativePositionEmbedding(
         num_heads=4,
         bidirectional=False,
-        embeddings_initializer=tf.keras.initializers.Ones(),
+        embeddings_initializer=tf_keras.initializers.Ones(),
         compute_dtype=dtype,
         name="foo")
     self.assertEqual(l(4, 2).shape, (1, 4, 4, 2))
     l = t5.RelativePositionEmbedding(
         num_heads=4,
         bidirectional=True,
-        embeddings_initializer=tf.keras.initializers.Ones(),
+        embeddings_initializer=tf_keras.initializers.Ones(),
         compute_dtype=dtype,
         name="bar")
     outputs = l(4, 2)
     self.assertEqual(outputs.shape, (1, 4, 4, 2))
     self.assertEqual(outputs.dtype, dtype)
 
   def test_masks(self):
@@ -168,15 +168,15 @@
   def test_attention(self, distribution):
     num_heads, head_size = 2, 4
     from_seq_length, to_seq_length = 4, 6
     batch_size = 2
     pos_embed = t5.RelativePositionEmbedding(
         num_heads=4,
         bidirectional=False,
-        embeddings_initializer=tf.keras.initializers.Ones(),
+        embeddings_initializer=tf_keras.initializers.Ones(),
         name="pos_embed")
     position_bias = pos_embed(from_seq_length, from_seq_length)
     l = t5.MultiHeadAttention(d_model=4, d_kv=2, num_heads=4, dropout_rate=0.1)
     query = tf.convert_to_tensor(
         np.ones((batch_size, from_seq_length, 4), dtype=np.float32))
     self.assertEqual(
         l(query, position_bias=position_bias)["context"].shape, query.shape)
@@ -230,15 +230,15 @@
     from_seq_length = 4
     # TPU decoding should pre-allocate the entire sequence.
     batch_size = 2
     with distribution.scope():
       pos_embed = t5.RelativePositionEmbedding(
           num_heads=head_size,
           bidirectional=False,
-          embeddings_initializer=tf.keras.initializers.Ones(),
+          embeddings_initializer=tf_keras.initializers.Ones(),
           name="pos_embed")
       l = t5.SelfAttention(
           d_model=4, d_kv=head_size, num_heads=num_heads, dropout_rate=0.1)
       decode_position = 2
 
       @tf.function
       def step(inputs):
@@ -298,15 +298,15 @@
     batch_size = 2
     from_seq_length = 5
     d_model = 4
     l = t5.EncoderBlock(d_model=4, d_kv=3, num_heads=2, d_ff=8, name="foo")
     pos_embed = t5.RelativePositionEmbedding(
         num_heads=2,
         bidirectional=True,
-        embeddings_initializer=tf.keras.initializers.Ones(),
+        embeddings_initializer=tf_keras.initializers.Ones(),
         name="bar")
     attention_mask = t5.make_attention_mask(
         tf.ones((batch_size, from_seq_length)),
         tf.ones((batch_size, from_seq_length)))
     position_bias = pos_embed(from_seq_length, from_seq_length)
     inputs = tf.ones((batch_size, from_seq_length, d_model), dtype=tf.float32)
     outputs = l(
@@ -318,15 +318,15 @@
     from_seq_length = 5
     to_seq_length = 3
     d_model = 4
     l = t5.EncDecoderBlock(d_model=4, d_kv=3, num_heads=2, d_ff=8, name="foo")
     pos_embed = t5.RelativePositionEmbedding(
         num_heads=2,
         bidirectional=True,
-        embeddings_initializer=tf.keras.initializers.Ones(),
+        embeddings_initializer=tf_keras.initializers.Ones(),
         name="bar")
     encoder_decoder_mask = t5.make_attention_mask(
         tf.ones((batch_size, from_seq_length)),
         tf.ones((batch_size, to_seq_length)))
     position_bias = pos_embed(from_seq_length, from_seq_length)
     inputs = tf.ones((batch_size, from_seq_length, d_model), dtype=tf.float32)
     encoder_hidden_states = tf.ones((batch_size, to_seq_length, d_model),
@@ -344,32 +344,56 @@
     config = t5.T5TransformerParams(
         num_layers=2,
         d_model=4,
         d_kv=3,
         num_heads=4,
         d_ff=16,
         vocab_size=10,
-        vocab_embeddings_initializer=tf.keras.initializers.Ones(),
-        relative_embeddings_initializer=tf.keras.initializers.Ones())
+        vocab_embeddings_initializer=tf_keras.initializers.Ones(),
+        relative_embeddings_initializer=tf_keras.initializers.Ones())
     encoder = t5.Encoder(config, compute_dtype=dtype)
     encoded = encoder(tf.zeros((4, 8), dtype=tf.int32))
     self.assertEqual(encoded.shape, (4, 8, config.d_model))
 
+  @parameterized.named_parameters(("return_score", True),
+                                  ("not_return_score", False))
+  def test_encoder_att_scores(self, return_attention_scores):
+    config = t5.T5TransformerParams(
+        num_layers=2,
+        d_model=4,
+        d_kv=3,
+        num_heads=4,
+        d_ff=16,
+        vocab_size=10,
+        vocab_embeddings_initializer=tf_keras.initializers.Ones(),
+        relative_embeddings_initializer=tf_keras.initializers.Ones(),
+        return_attention_scores=return_attention_scores)
+    encoder = t5.Encoder(config, compute_dtype=tf.float32)
+    encoded = encoder(tf.zeros((4, 8), dtype=tf.int32))
+    if return_attention_scores:
+      encoded, scores = encoded
+      self.assertEqual(encoded.shape, (4, 8, config.d_model))
+      self.assertIsNotNone(scores)
+      self.assertLen(scores, 2)
+      self.assertEqual(scores[0].shape, (4, 4, 8, 8))
+    else:
+      self.assertEqual(encoded.shape, (4, 8, config.d_model))
+
   @parameterized.named_parameters(("bfloat16", tf.bfloat16),
                                   ("float32", tf.float32))
   def test_encoder_with_dense(self, dtype):
     config = t5.T5TransformerParams(
         num_layers=2,
         d_model=4,
         d_kv=3,
         num_heads=4,
         d_ff=16,
         vocab_size=10,
-        vocab_embeddings_initializer=tf.keras.initializers.Ones(),
-        relative_embeddings_initializer=tf.keras.initializers.Ones())
+        vocab_embeddings_initializer=tf_keras.initializers.Ones(),
+        relative_embeddings_initializer=tf_keras.initializers.Ones())
     encoder = t5.Encoder(config, compute_dtype=dtype)
     encoded = encoder(
         tf.zeros((4, 8), dtype=tf.int32),
         dense_inputs=tf.ones((4, 2, 4), dtype=dtype))
     self.assertEqual(encoded.shape, (4, 10, config.d_model))
 
   @parameterized.named_parameters(("bfloat16", tf.bfloat16),
@@ -378,38 +402,37 @@
     config = t5.T5TransformerParams(
         num_layers=2,
         d_model=4,
         d_kv=3,
         num_heads=4,
         d_ff=16,
         vocab_size=10,
-        vocab_embeddings_initializer=tf.keras.initializers.Ones(),
-        relative_embeddings_initializer=tf.keras.initializers.Ones())
+        vocab_embeddings_initializer=tf_keras.initializers.Ones(),
+        relative_embeddings_initializer=tf_keras.initializers.Ones())
     encoder = t5.Encoder(config, compute_dtype=dtype)
     encoded = encoder(dense_inputs=tf.ones((4, 2, 4), dtype=dtype))
     self.assertEqual(encoded.shape, (4, 2, config.d_model))
 
   def test_decoder(self):
     max_decode_len = 10
     config = t5.T5TransformerParams(
         num_layers=2,
         d_model=4,
         d_kv=3,
         num_heads=4,
         d_ff=16,
         vocab_size=10,
-        vocab_embeddings_initializer=tf.keras.initializers.Ones(),
-        relative_embeddings_initializer=tf.keras.initializers.Ones())
+        vocab_embeddings_initializer=tf_keras.initializers.Ones(),
+        relative_embeddings_initializer=tf_keras.initializers.Ones())
     decoder = t5.Decoder(config)
     batch_size = 4
     targets = tf.zeros((4, 8), dtype=tf.int32)
     encoded = tf.zeros((4, 8, config.d_model), dtype=tf.float32)
     outputs = decoder(targets, encoded)
     logits = outputs["logits"]
-    cache = outputs["cache"]
     self.assertEqual(logits.shape, (4, 8, config.vocab_size))
 
     cache = {}
     cache[0] = _create_cache(batch_size, max_decode_len, config.num_heads,
                              config.d_kv)
     cache[1] = _create_cache(batch_size, max_decode_len, config.num_heads,
                              config.d_kv)
@@ -476,15 +499,70 @@
         decode_position=1,
         decode=True,
         max_decode_len=max_decode_len,
         cache=cache)
     self.assertEqual(outputs["logits"].shape,
                      (batch_size, 1, config.vocab_size))
     for v in transformer.trainable_variables:
-      print(v.name, v.shape)
+      self.assertEqual(v.dtype, tf.float32)
+
+  def test_transformer_return_attn_scores(self):
+    max_decode_len = 10
+    config = t5.T5TransformerParams(
+        num_layers=1,
+        d_model=8,
+        d_kv=4,
+        num_heads=4,
+        d_ff=32,
+        vocab_size=10,
+        shared_embedding=True,
+        layer_sharing=False,
+        ffn_activations=("relu",),
+        logits_via_embedding=True,
+        return_attention_scores=True,
+    )
+    transformer = t5.T5Transformer(config, compute_dtype=tf.float32)
+    self.assertLen(transformer.trainable_variables, 26)
+    inputs = tf.convert_to_tensor(
+        np.array([[2, 2, 1, 3, 1, 0], [3, 3, 1, 2, 2, 1]])
+    )
+    segments = tf.convert_to_tensor(
+        np.array([[1, 1, 1, 2, 2, 0], [1, 1, 1, 2, 2, 2]])
+    )
+
+    outputs = transformer(
+        encoder_input_tokens=inputs,
+        decoder_input_tokens=inputs,
+        decoder_target_tokens=inputs,
+        encoder_segment_ids=segments,
+        decoder_segment_ids=segments,
+    )
+    self.assertIn("attention_scores", outputs)
+    self.assertLen(outputs["attention_scores"], 1)
+    self.assertEqual(outputs["attention_scores"][0].shape, (2, 4, 6, 6))
+    cache = {}
+    batch_size = 2
+    cache[0] = _create_cache(
+        batch_size,
+        max_decode_len,
+        config.num_heads,
+        config.d_kv,
+        dtype=tf.float32,
+    )
+    outputs = transformer.decode(
+        encoder_input_tokens=inputs,
+        encoded=outputs["encoded"],
+        decoder_target_tokens=tf.ones((batch_size, 1), dtype=tf.int32),
+        decode_position=1,
+        decode=True,
+        max_decode_len=max_decode_len,
+        cache=cache)
+    self.assertEqual(outputs["logits"].shape,
+                     (batch_size, 1, config.vocab_size))
+    for v in transformer.trainable_variables:
       self.assertEqual(v.dtype, tf.float32)
 
   @parameterized.named_parameters(
       ("t5_10_dense", ("relu",), True, 26, False, tf.float32),)
   def test_transformer_with_dense(self, ffn_activations, logits_via_embedding,
                                   expect_num_variables, layer_sharing, dtype):
     max_decode_len = 10
@@ -529,15 +607,14 @@
         decode_position=1,
         decode=True,
         max_decode_len=max_decode_len,
         cache=cache)
     self.assertEqual(outputs["logits"].shape,
                      (batch_size, 1, config.vocab_size))
     for v in transformer.trainable_variables:
-      print(v.name, v.shape)
       self.assertEqual(v.dtype, tf.float32)
 
   @parameterized.named_parameters(
       ("t5_10_dense_layerwise_relpos",
        ("relu",), True, 26, False, tf.float32, False, 1),
       ("t5_10_dense_shared_relpos_d2",
        ("relu",), True, 39, False, tf.float32, True, 2),
@@ -598,15 +675,14 @@
         decode_position=1,
         decode=True,
         max_decode_len=max_decode_len,
         cache=cache)
     self.assertEqual(outputs["logits"].shape,
                      (batch_size, 1, config.vocab_size))
     for v in transformer.trainable_variables:
-      print(v.name, v.shape)
       self.assertEqual(v.dtype, tf.float32)
 
   @parameterized.named_parameters(
       ("t5_10", ("relu",), True, 26, False, tf.float32),)
   def test_transformer_with_dense_only(self, ffn_activations,
                                        logits_via_embedding,
                                        expect_num_variables, layer_sharing,
@@ -650,15 +726,14 @@
         decode_position=1,
         decode=True,
         max_decode_len=max_decode_len,
         cache=cache)
     self.assertEqual(outputs["logits"].shape,
                      (batch_size, 1, config.vocab_size))
     for v in transformer.trainable_variables:
-      print(v.name, v.shape)
       self.assertEqual(v.dtype, tf.float32)
 
   @parameterized.named_parameters(
       ("t5_10", ("relu",), True, 39, tf.float32, 2),
       ("t5_10_bfloat16", ("relu",), True, 39, tf.bfloat16, 2))
   def test_transformer_different_num_decoder_layers(self, ffn_activations,
                                                     logits_via_embedding,
@@ -705,13 +780,12 @@
         decode_position=1,
         decode=True,
         max_decode_len=max_decode_len,
         cache=cache)
     self.assertEqual(outputs["logits"].shape,
                      (batch_size, 1, config.vocab_size))
     for v in transformer.trainable_variables:
-      print(v.name, v.shape)
       self.assertEqual(v.dtype, tf.float32)
 
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/xlnet.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/xlnet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,21 +13,21 @@
 # limitations under the License.
 
 """XLNet models."""
 # pylint: disable=g-classes-have-attributes
 
 from typing import Any, Mapping, Optional, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling import layers
 from official.nlp.modeling import networks
 
 
-class XLNetMaskedLM(tf.keras.layers.Layer):
+class XLNetMaskedLM(tf_keras.layers.Layer):
   """XLNet pretraining head."""
 
   def __init__(self,
                vocab_size: int,
                hidden_size: int,
                initializer: str = 'glorot_uniform',
                activation: str = 'gelu',
@@ -36,20 +36,20 @@
     super().__init__(name=name, **kwargs)
     self._vocab_size = vocab_size
     self._hidden_size = hidden_size
     self._initializer = initializer
     self._activation = activation
 
   def build(self, input_shape):
-    self.dense = tf.keras.layers.Dense(
+    self.dense = tf_keras.layers.Dense(
         units=self._hidden_size,
         activation=self._activation,
         kernel_initializer=self._initializer,
         name='transform/dense')
-    self.layer_norm = tf.keras.layers.LayerNormalization(
+    self.layer_norm = tf_keras.layers.LayerNormalization(
         axis=-1, epsilon=1e-12, name='transform/LayerNorm')
     self.bias = self.add_weight(
         'output_bias/bias',
         shape=(self._vocab_size,),
         initializer='zeros',
         trainable=True)
     super().build(input_shape)
@@ -72,16 +72,16 @@
         'initializer':
             self._initializer
     }
     base_config = super(XLNetMaskedLM, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class XLNetPretrainer(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class XLNetPretrainer(tf_keras.Model):
   """XLNet-based pretrainer.
 
   This is an implementation of the network structure surrounding a
   Transformer-XL encoder as described in "XLNet: Generalized Autoregressive
   Pretraining for Language Understanding" (https://arxiv.org/abs/1906.08237).
 
   Args:
@@ -92,15 +92,15 @@
     mlm_initializer: The initializer (if any) to use in the masked LM. Defaults
       to a Glorot uniform initializer.
 
   """
 
   def __init__(
       self,
-      network: Union[tf.keras.layers.Layer, tf.keras.Model],
+      network: Union[tf_keras.layers.Layer, tf_keras.Model],
       mlm_activation=None,
       mlm_initializer='glorot_uniform',
       name: Optional[str] = None,
       **kwargs):
     super().__init__(name=name, **kwargs)
     self._config = {
         'network': network,
@@ -113,15 +113,15 @@
     self._activation = mlm_activation
     self._initializer = mlm_initializer
     self._masked_lm = XLNetMaskedLM(
         vocab_size=self._vocab_size,
         hidden_size=self._hidden_size,
         initializer=self._initializer)
 
-  def call(self, inputs: Mapping[str, Any]):
+  def call(self, inputs: Mapping[str, Any]):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     input_word_ids = inputs['input_word_ids']
     input_type_ids = inputs['input_type_ids']
     masked_tokens = inputs['masked_tokens']
     permutation_mask = inputs['permutation_mask']
     target_mapping = inputs['target_mapping']
     state = inputs.get('state', None)
 
@@ -148,16 +148,16 @@
     return cls(**config)
 
   @property
   def checkpoint_items(self):
     return dict(encoder=self._network)
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class XLNetClassifier(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class XLNetClassifier(tf_keras.Model):
   """Classifier model based on XLNet.
 
   This is an implementation of the network structure surrounding a
   Transformer-XL encoder as described in "XLNet: Generalized Autoregressive
   Pretraining for Language Understanding" (https://arxiv.org/abs/1906.08237).
 
   Note: This model does not use utilize the memory mechanism used in the
@@ -172,17 +172,17 @@
     summary_type: Method used to summarize a sequence into a compact vector.
     dropout_rate: The dropout probability of the cls head.
     head_name: Name of the classification head.
   """
 
   def __init__(
       self,
-      network: Union[tf.keras.layers.Layer, tf.keras.Model],
+      network: Union[tf_keras.layers.Layer, tf_keras.Model],
       num_classes: int,
-      initializer: tf.keras.initializers.Initializer = 'random_normal',
+      initializer: tf_keras.initializers.Initializer = 'random_normal',
       summary_type: str = 'last',
       dropout_rate: float = 0.1,
       head_name: str = 'sentence_prediction',  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     super().__init__(**kwargs)
     self._network = network
     self._initializer = initializer
@@ -208,15 +208,15 @@
         inner_dim=network.get_config()['hidden_size'],
         num_classes=num_classes,
         initializer=initializer,
         dropout_rate=dropout_rate,
         cls_token_idx=cls_token_idx,
         name=head_name)
 
-  def call(self, inputs: Mapping[str, Any]):
+  def call(self, inputs: Mapping[str, Any]):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     input_ids = inputs['input_word_ids']
     segment_ids = inputs['input_type_ids']
     input_mask = tf.cast(inputs['input_mask'], tf.float32)
     state = inputs.get('mems', None)
 
     attention_output, _ = self._network(
         input_ids=input_ids,
@@ -240,16 +240,16 @@
     items = dict(encoder=self._network)
     if hasattr(self.classifier, 'checkpoint_items'):
       for key, item in self.classifier.checkpoint_items.items():
         items['.'.join([self.classifier.name, key])] = item
     return items
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class XLNetSpanLabeler(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class XLNetSpanLabeler(tf_keras.Model):
   """Span labeler model based on XLNet.
 
   This is an implementation of the network structure surrounding a
   Transformer-XL encoder as described in "XLNet: Generalized Autoregressive
   Pretraining for Language Understanding" (https://arxiv.org/abs/1906.08237).
 
   Args:
@@ -262,20 +262,20 @@
     span_labeling_activation: The activation for the span labeling head.
     initializer: The initializer (if any) to use in the span labeling network.
       Defaults to a Glorot uniform initializer.
   """
 
   def __init__(
       self,
-      network: Union[tf.keras.layers.Layer, tf.keras.Model],
+      network: Union[tf_keras.layers.Layer, tf_keras.Model],
       start_n_top: int = 5,
       end_n_top: int = 5,
       dropout_rate: float = 0.1,
-      span_labeling_activation: tf.keras.initializers.Initializer = 'tanh',
-      initializer: tf.keras.initializers.Initializer = 'glorot_uniform',  # pytype: disable=annotation-type-mismatch  # typed-keras
+      span_labeling_activation: tf_keras.initializers.Initializer = 'tanh',
+      initializer: tf_keras.initializers.Initializer = 'glorot_uniform',  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     super().__init__(**kwargs)
     self._config = {
         'network': network,
         'start_n_top': start_n_top,
         'end_n_top': end_n_top,
         'dropout_rate': dropout_rate,
@@ -301,15 +301,15 @@
         input_width=input_width,
         start_n_top=self._start_n_top,
         end_n_top=self._end_n_top,
         activation=self._activation,
         dropout_rate=self._dropout_rate,
         initializer=self._initializer)
 
-  def call(self, inputs: Mapping[str, Any]):
+  def call(self, inputs: Mapping[str, Any]):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     input_word_ids = inputs['input_word_ids']
     input_type_ids = inputs['input_type_ids']
     input_mask = inputs['input_mask']
     class_index = inputs['class_index']
     paragraph_mask = inputs['paragraph_mask']
     start_positions = inputs.get('start_positions', None)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/models/xlnet_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/models/xlnet_test.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,85 +13,80 @@
 # limitations under the License.
 
 """Tests for XLNet classifier network."""
 
 from absl.testing import parameterized
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import networks
 from official.nlp.modeling.models import xlnet
 
 
-def _get_xlnet_base() -> tf.keras.layers.Layer:
+def _get_xlnet_base() -> tf_keras.layers.Layer:
   """Returns a trivial base XLNet model."""
   return networks.XLNetBase(
       vocab_size=100,
       num_layers=2,
       hidden_size=4,
       num_attention_heads=2,
       head_size=2,
       inner_size=2,
       dropout_rate=0.,
       attention_dropout_rate=0.,
       attention_type='bi',
       bi_data=True,
-      initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+      initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
       two_stream=False,
       tie_attention_biases=True,
       reuse_length=0,
       inner_activation='relu')
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class XLNetMaskedLMTest(keras_parameterized.TestCase):
+class XLNetMaskedLMTest(tf.test.TestCase):
 
   def test_xlnet_masked_lm_head(self):
     hidden_size = 10
     seq_length = 8
     batch_size = 2
     masked_lm = xlnet.XLNetMaskedLM(vocab_size=10,
                                     hidden_size=hidden_size,
                                     initializer='glorot_uniform')
     sequence_data = np.random.uniform(size=(batch_size, seq_length))
     embedding_table = np.random.uniform(size=(hidden_size, hidden_size))
     mlm_output = masked_lm(sequence_data, embedding_table)
     self.assertAllClose(mlm_output.shape, (batch_size, hidden_size))
 
 
-@keras_parameterized.run_all_keras_modes
-class XLNetPretrainerTest(keras_parameterized.TestCase):
+class XLNetPretrainerTest(tf.test.TestCase):
 
   def test_xlnet_trainer(self):
     """Validates that the Keras object can be created."""
     seq_length = 4
     num_predictions = 2
     # Build a simple XLNet based network to use with the XLNet trainer.
     xlnet_base = _get_xlnet_base()
 
     # Create an XLNet trainer with the created network.
     xlnet_trainer_model = xlnet.XLNetPretrainer(network=xlnet_base)
     inputs = dict(
-        input_word_ids=tf.keras.layers.Input(
+        input_word_ids=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_word_ids'),
-        input_type_ids=tf.keras.layers.Input(
+        input_type_ids=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_type_ids'),
-        input_mask=tf.keras.layers.Input(
+        input_mask=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_mask'),
-        permutation_mask=tf.keras.layers.Input(
+        permutation_mask=tf_keras.layers.Input(
             shape=(seq_length, seq_length,), dtype=tf.int32,
             name='permutation_mask'),
-        target_mapping=tf.keras.layers.Input(
+        target_mapping=tf_keras.layers.Input(
             shape=(num_predictions, seq_length), dtype=tf.int32,
             name='target_mapping'),
-        masked_tokens=tf.keras.layers.Input(
+        masked_tokens=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='masked_tokens'))
     logits, _ = xlnet_trainer_model(inputs)
 
     # [None, hidden_size, vocab_size]
     expected_output_shape = [None, 4, 100]
     self.assertAllEqual(expected_output_shape, logits.shape.as_list())
 
@@ -140,42 +135,41 @@
     _ = new_xlnet_trainer_model.to_json()
 
     # If serialization was successful, then the new config should match the old.
     self.assertAllEqual(xlnet_trainer_model.get_config(),
                         new_xlnet_trainer_model.get_config())
 
 
-@keras_parameterized.run_all_keras_modes
-class XLNetClassifierTest(keras_parameterized.TestCase):
+class XLNetClassifierTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_xlnet_trainer(self):
     """Validate that the Keras object can be created."""
     num_classes = 2
     seq_length = 4
     # Build a simple XLNet based network to use with the XLNet trainer.
     xlnet_base = _get_xlnet_base()
 
     # Create an XLNet trainer with the created network.
     xlnet_trainer_model = xlnet.XLNetClassifier(
         network=xlnet_base,
         num_classes=num_classes,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         summary_type='last',
         dropout_rate=0.1)
     inputs = dict(
-        input_word_ids=tf.keras.layers.Input(
+        input_word_ids=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_word_ids'),
-        input_type_ids=tf.keras.layers.Input(
+        input_type_ids=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_type_ids'),
-        input_mask=tf.keras.layers.Input(
+        input_mask=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_mask'),
-        permutation_mask=tf.keras.layers.Input(
+        permutation_mask=tf_keras.layers.Input(
             shape=(seq_length, seq_length,), dtype=tf.int32,
             name='permutation_mask'),
-        masked_tokens=tf.keras.layers.Input(
+        masked_tokens=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='masked_tokens'))
     logits = xlnet_trainer_model(inputs)
 
     expected_classification_shape = [None, num_classes]
     self.assertAllEqual(expected_classification_shape, logits.shape.as_list())
 
   @parameterized.parameters(1, 2)
@@ -186,15 +180,15 @@
     # Build a simple XLNet based network to use with the XLNet trainer.
     xlnet_base = _get_xlnet_base()
 
     # Create an XLNet trainer with the created network.
     xlnet_trainer_model = xlnet.XLNetClassifier(
         network=xlnet_base,
         num_classes=num_classes,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         summary_type='last',
         dropout_rate=0.1)
 
     sequence_shape = (batch_size, seq_length)
     inputs = dict(
         input_word_ids=np.random.randint(
             10, size=sequence_shape, dtype='int32'),
@@ -211,15 +205,15 @@
     # Build a simple XLNet based network to use with the XLNet trainer.
     xlnet_base = _get_xlnet_base()
 
     # Create an XLNet trainer with the created network.
     xlnet_trainer_model = xlnet.XLNetClassifier(
         network=xlnet_base,
         num_classes=2,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         summary_type='last',
         dropout_rate=0.1)
 
     # Create another XLNet trainer via serialization and deserialization.
     config = xlnet_trainer_model.get_config()
     new_xlnet_trainer_model = xlnet.XLNetClassifier.from_config(
         config)
@@ -228,44 +222,43 @@
     _ = new_xlnet_trainer_model.to_json()
 
     # If serialization was successful, then the new config should match the old.
     self.assertAllEqual(xlnet_trainer_model.get_config(),
                         new_xlnet_trainer_model.get_config())
 
 
-@keras_parameterized.run_all_keras_modes
-class XLNetSpanLabelerTest(keras_parameterized.TestCase):
+class XLNetSpanLabelerTest(tf.test.TestCase):
 
   def test_xlnet_trainer(self):
     """Validate that the Keras object can be created."""
     top_n = 2
     seq_length = 4
     # Build a simple XLNet based network to use with the XLNet trainer.
     xlnet_base = _get_xlnet_base()
 
     # Create an XLNet trainer with the created network.
     xlnet_trainer_model = xlnet.XLNetSpanLabeler(
         network=xlnet_base,
         start_n_top=top_n,
         end_n_top=top_n,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         span_labeling_activation='tanh',
         dropout_rate=0.1)
     inputs = dict(
-        input_word_ids=tf.keras.layers.Input(
+        input_word_ids=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_word_ids'),
-        input_type_ids=tf.keras.layers.Input(
+        input_type_ids=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_type_ids'),
-        input_mask=tf.keras.layers.Input(
+        input_mask=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='input_mask'),
-        paragraph_mask=tf.keras.layers.Input(
+        paragraph_mask=tf_keras.layers.Input(
             shape=(seq_length,), dtype=tf.int32, name='paragraph_mask'),
-        class_index=tf.keras.layers.Input(
+        class_index=tf_keras.layers.Input(
             shape=(), dtype=tf.int32, name='class_index'),
-        start_positions=tf.keras.layers.Input(
+        start_positions=tf_keras.layers.Input(
             shape=(), dtype=tf.int32, name='start_positions'))
     outputs = xlnet_trainer_model(inputs)
     self.assertIsInstance(outputs, dict)
 
     # Test tensor value calls for the created model.
     batch_size = 2
     sequence_shape = (batch_size, seq_length)
@@ -303,15 +296,15 @@
     xlnet_base = _get_xlnet_base()
 
     # Create an XLNet trainer with the created network.
     xlnet_trainer_model = xlnet.XLNetSpanLabeler(
         network=xlnet_base,
         start_n_top=2,
         end_n_top=2,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         span_labeling_activation='tanh',
         dropout_rate=0.1)
 
     # Create another XLNet trainer via serialization and deserialization.
     config = xlnet_trainer_model.get_config()
     new_xlnet_trainer_model = xlnet.XLNetSpanLabeler.from_config(
         config)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -25,8 +25,9 @@
 from official.nlp.modeling.networks.encoder_scaffold import EncoderScaffold
 from official.nlp.modeling.networks.fnet import FNet
 from official.nlp.modeling.networks.funnel_transformer import FunnelTransformerEncoder
 from official.nlp.modeling.networks.mobile_bert_encoder import MobileBERTEncoder
 from official.nlp.modeling.networks.packed_sequence_embedding import PackedSequenceEmbedding
 from official.nlp.modeling.networks.span_labeling import SpanLabeling
 from official.nlp.modeling.networks.span_labeling import XLNetSpanLabeling
+from official.nlp.modeling.networks.sparse_mixer import SparseMixer
 from official.nlp.modeling.networks.xlnet_base import XLNetBase
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/albert_encoder.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/albert_encoder.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,23 +11,23 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """ALBERT (https://arxiv.org/abs/1810.04805) text encoder network."""
 # pylint: disable=g-classes-have-attributes
 import collections
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import activations
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class AlbertEncoder(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class AlbertEncoder(tf_keras.Model):
   """ALBERT (https://arxiv.org/abs/1810.04805) text encoder network.
 
   This network implements the encoder described in the paper "ALBERT: A Lite
   BERT for Self-supervised Learning of Language Representations"
   (https://arxiv.org/abs/1909.11942).
 
   Compared with BERT (https://arxiv.org/abs/1810.04805), ALBERT refactorizes
@@ -71,25 +71,25 @@
                num_attention_heads=12,
                max_sequence_length=512,
                type_vocab_size=16,
                intermediate_size=3072,
                activation=activations.gelu,
                dropout_rate=0.1,
                attention_dropout_rate=0.1,
-               initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+               initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
                dict_outputs=False,
                **kwargs):
-    activation = tf.keras.activations.get(activation)
-    initializer = tf.keras.initializers.get(initializer)
+    activation = tf_keras.activations.get(activation)
+    initializer = tf_keras.initializers.get(initializer)
 
-    word_ids = tf.keras.layers.Input(
+    word_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_word_ids')
-    mask = tf.keras.layers.Input(
+    mask = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_mask')
-    type_ids = tf.keras.layers.Input(
+    type_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_type_ids')
 
     if embedding_width is None:
       embedding_width = hidden_size
     embedding_layer = layers.OnDeviceEmbedding(
         vocab_size=vocab_size,
         embedding_width=embedding_width,
@@ -108,27 +108,27 @@
         layers.OnDeviceEmbedding(
             vocab_size=type_vocab_size,
             embedding_width=embedding_width,
             initializer=tf_utils.clone_initializer(initializer),
             use_one_hot=True,
             name='type_embeddings')(type_ids))
 
-    embeddings = tf.keras.layers.Add()(
+    embeddings = tf_keras.layers.Add()(
         [word_embeddings, position_embeddings, type_embeddings])
     embeddings = (
-        tf.keras.layers.LayerNormalization(
+        tf_keras.layers.LayerNormalization(
             name='embeddings/layer_norm',
             axis=-1,
             epsilon=1e-12,
             dtype=tf.float32)(embeddings))
-    embeddings = (tf.keras.layers.Dropout(rate=dropout_rate)(embeddings))
+    embeddings = (tf_keras.layers.Dropout(rate=dropout_rate)(embeddings))
     # We project the 'embedding' output to 'hidden_size' if it is not already
     # 'hidden_size'.
     if embedding_width != hidden_size:
-      embeddings = tf.keras.layers.EinsumDense(
+      embeddings = tf_keras.layers.EinsumDense(
           '...x,xy->...y',
           output_shape=hidden_size,
           bias_axes='y',
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='embedding_projection')(
               embeddings)
 
@@ -147,15 +147,15 @@
       data = shared_layer([data, attention_mask])
       encoder_outputs.append(data)
 
     # Applying a tf.slice op (through subscript notation) to a Keras tensor
     # like this will create a SliceOpLambda layer. This is better than a Lambda
     # layer with Python code, because that is fundamentally less portable.
     first_token_tensor = data[:, 0, :]
-    cls_output = tf.keras.layers.Dense(
+    cls_output = tf_keras.layers.Dense(
         units=hidden_size,
         activation='tanh',
         kernel_initializer=tf_utils.clone_initializer(initializer),
         name='pooler_transform')(
             first_token_tensor)
     if dict_outputs:
       outputs = dict(
@@ -180,18 +180,18 @@
         'embedding_width': embedding_width,
         'hidden_size': hidden_size,
         'num_layers': num_layers,
         'num_attention_heads': num_attention_heads,
         'max_sequence_length': max_sequence_length,
         'type_vocab_size': type_vocab_size,
         'intermediate_size': intermediate_size,
-        'activation': tf.keras.activations.serialize(activation),
+        'activation': tf_keras.activations.serialize(activation),
         'dropout_rate': dropout_rate,
         'attention_dropout_rate': attention_dropout_rate,
-        'initializer': tf.keras.initializers.serialize(initializer),
+        'initializer': tf_keras.initializers.serialize(initializer),
     }
 
     # We are storing the config dict as a namedtuple here to ensure checkpoint
     # compatibility with an earlier version of this model which did not track
     # the config dict attribute. TF does not track immutable attrs which
     # do not contain Trackables, so by creating a config namedtuple instead of
     # a dict we avoid tracking it.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/albert_encoder_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/albert_encoder_test.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,34 +10,26 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for ALBERT transformer-based text encoder network."""
 
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.networks import albert_encoder
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class AlbertEncoderTest(keras_parameterized.TestCase):
+class AlbertEncoderTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(AlbertEncoderTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   @parameterized.named_parameters(
       dict(testcase_name="default", expected_dtype=tf.float32),
       dict(testcase_name="with_float16_dtype", expected_dtype=tf.float16),
   )
   def test_network_creation(self, expected_dtype):
     hidden_size = 32
@@ -45,23 +37,23 @@
 
     kwargs = dict(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3)
     if expected_dtype == tf.float16:
-      tf.keras.mixed_precision.set_global_policy("mixed_float16")
+      tf_keras.mixed_precision.set_global_policy("mixed_float16")
 
     # Create a small TransformerEncoder for testing.
     test_network = albert_encoder.AlbertEncoder(**kwargs)
 
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     data, pooled = test_network([word_ids, mask, type_ids])
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
@@ -90,21 +82,21 @@
         vocab_size=vocab_size,
         embedding_width=8,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=num_layers,
         type_vocab_size=num_types)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     data, pooled = test_network([word_ids, mask, type_ids])
 
     # Create a model based off of this network:
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
@@ -118,15 +110,15 @@
         vocab_size=vocab_size,
         embedding_width=8,
         hidden_size=hidden_size,
         max_sequence_length=max_sequence_length,
         num_attention_heads=2,
         num_layers=num_layers,
         type_vocab_size=num_types)
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     _ = model.predict([word_id_data, mask_data, type_id_data])
 
     # Tests dictionary outputs.
     test_network_dict = albert_encoder.AlbertEncoder(
         vocab_size=vocab_size,
         embedding_width=8,
         hidden_size=hidden_size,
@@ -144,15 +136,15 @@
             input_mask=mask_data,
             input_type_ids=type_id_data))
     self.assertAllEqual(list_outputs[0], dict_outputs["sequence_output"])
     self.assertAllEqual(list_outputs[1], dict_outputs["pooled_output"])
     self.assertLen(dict_outputs["pooled_output"], num_layers)
 
   def test_serialize_deserialize(self):
-    tf.keras.mixed_precision.set_global_policy("mixed_float16")
+    tf_keras.mixed_precision.set_global_policy("mixed_float16")
     # Create a network object that sets all of its config options.
     kwargs = dict(
         vocab_size=100,
         embedding_width=8,
         hidden_size=32,
         num_layers=3,
         num_attention_heads=2,
@@ -162,18 +154,18 @@
         activation="relu",
         dropout_rate=0.05,
         attention_dropout_rate=0.22,
         initializer="glorot_uniform")
     network = albert_encoder.AlbertEncoder(**kwargs)
 
     expected_config = dict(kwargs)
-    expected_config["activation"] = tf.keras.activations.serialize(
-        tf.keras.activations.get(expected_config["activation"]))
-    expected_config["initializer"] = tf.keras.initializers.serialize(
-        tf.keras.initializers.get(expected_config["initializer"]))
+    expected_config["activation"] = tf_keras.activations.serialize(
+        tf_keras.activations.get(expected_config["activation"]))
+    expected_config["initializer"] = tf_keras.initializers.serialize(
+        tf_keras.initializers.get(expected_config["initializer"]))
     self.assertEqual(network.get_config(), expected_config)
 
     # Create another network object from the first object's config.
     new_network = (
         albert_encoder.AlbertEncoder.from_config(
             network.get_config()))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/bert_dense_encoder_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/bert_dense_encoder_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,28 +13,24 @@
 # limitations under the License.
 
 """Tests for transformer-based bert encoder network with dense features as inputs."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.networks import bert_encoder
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class BertEncoderV2Test(keras_parameterized.TestCase):
+class BertEncoderV2Test(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(BertEncoderV2Test, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   def test_dict_outputs_network_creation(self):
     hidden_size = 32
     sequence_length = 21
     dense_sequence_length = 20
     # Create a small dense BertEncoderV2 for testing.
     kwargs = {}
@@ -42,22 +38,22 @@
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         with_dense_inputs=True,
         **kwargs)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
-    dense_inputs = tf.keras.Input(
+    dense_inputs = tf_keras.Input(
         shape=(dense_sequence_length, hidden_size), dtype=tf.float32)
-    dense_mask = tf.keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
-    dense_type_ids = tf.keras.Input(
+    dense_mask = tf_keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
+    dense_type_ids = tf_keras.Input(
         shape=(dense_sequence_length,), dtype=tf.int32)
 
     dict_outputs = test_network(
         dict(
             input_word_ids=word_ids,
             input_mask=mask,
             input_type_ids=type_ids,
@@ -65,15 +61,15 @@
             dense_mask=dense_mask,
             dense_type_ids=dense_type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     self.assertIsInstance(test_network.transformer_layers, list)
     self.assertLen(test_network.transformer_layers, 3)
-    self.assertIsInstance(test_network.pooler_layer, tf.keras.layers.Dense)
+    self.assertIsInstance(test_network.pooler_layer, tf_keras.layers.Dense)
 
     expected_data_shape = [
         None, sequence_length + dense_sequence_length, hidden_size
     ]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
@@ -91,22 +87,22 @@
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         dict_outputs=True,
         with_dense_inputs=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
-    dense_inputs = tf.keras.Input(
+    dense_inputs = tf_keras.Input(
         shape=(dense_sequence_length, hidden_size), dtype=tf.float32)
-    dense_mask = tf.keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
-    dense_type_ids = tf.keras.Input(
+    dense_mask = tf_keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
+    dense_type_ids = tf_keras.Input(
         shape=(dense_sequence_length,), dtype=tf.int32)
 
     dict_outputs = test_network(
         dict(
             input_word_ids=word_ids,
             input_mask=mask,
             input_type_ids=type_ids,
@@ -130,32 +126,32 @@
     self.assertAllEqual(tf.float32, all_encoder_outputs[-1].dtype)
     self.assertAllEqual(tf.float32, pooled.dtype)
 
   def test_dict_outputs_network_creation_with_float16_dtype(self):
     hidden_size = 32
     sequence_length = 21
     dense_sequence_length = 20
-    tf.keras.mixed_precision.set_global_policy("mixed_float16")
+    tf_keras.mixed_precision.set_global_policy("mixed_float16")
     # Create a small BertEncoder for testing.
     test_network = bert_encoder.BertEncoderV2(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         dict_outputs=True,
         with_dense_inputs=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
-    dense_inputs = tf.keras.Input(
+    dense_inputs = tf_keras.Input(
         shape=(dense_sequence_length, hidden_size), dtype=tf.float32)
-    dense_mask = tf.keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
-    dense_type_ids = tf.keras.Input(
+    dense_mask = tf_keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
+    dense_type_ids = tf_keras.Input(
         shape=(dense_sequence_length,), dtype=tf.int32)
 
     dict_outputs = test_network(
         dict(
             input_word_ids=word_ids,
             input_mask=mask,
             input_type_ids=type_ids,
@@ -196,36 +192,36 @@
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types,
         dict_outputs=True,
         with_dense_inputs=True,
         output_range=output_range)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    dense_inputs = tf.keras.Input(
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    dense_inputs = tf_keras.Input(
         shape=(dense_sequence_length, hidden_size), dtype=tf.float32)
-    dense_mask = tf.keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
-    dense_type_ids = tf.keras.Input(
+    dense_mask = tf_keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
+    dense_type_ids = tf_keras.Input(
         shape=(dense_sequence_length,), dtype=tf.int32)
 
     dict_outputs = test_network(
         dict(
             input_word_ids=word_ids,
             input_mask=mask,
             input_type_ids=type_ids,
             dense_inputs=dense_inputs,
             dense_mask=dense_mask,
             dense_type_ids=dense_type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     # Create a model based off of this network:
-    model = tf.keras.Model(
+    model = tf_keras.Model(
         [word_ids, mask, type_ids, dense_inputs, dense_mask, dense_type_ids],
         [data, pooled])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
@@ -263,15 +259,15 @@
             input_mask=mask,
             input_type_ids=type_ids,
             dense_inputs=dense_inputs,
             dense_mask=dense_mask,
             dense_type_ids=dense_type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
-    model = tf.keras.Model(
+    model = tf_keras.Model(
         [word_ids, mask, type_ids, dense_inputs, dense_mask, dense_type_ids],
         [data, pooled])
     outputs = model.predict([
         word_id_data, mask_data, type_id_data, dense_input_data,
         dense_mask_data, dense_type_ids_data
     ])
     self.assertEqual(outputs[0].shape[1],
@@ -285,30 +281,30 @@
         max_sequence_length=max_sequence_length,
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types,
         embedding_width=embedding_width,
         dict_outputs=True)
 
-    dense_inputs = tf.keras.Input(
+    dense_inputs = tf_keras.Input(
         shape=(dense_sequence_length, embedding_width), dtype=tf.float32)
     dense_input_data = np.zeros(
         (batch_size, dense_sequence_length, embedding_width), dtype=float)
 
     dict_outputs = test_network(
         dict(
             input_word_ids=word_ids,
             input_mask=mask,
             input_type_ids=type_ids,
             dense_inputs=dense_inputs,
             dense_mask=dense_mask,
             dense_type_ids=dense_type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
-    model = tf.keras.Model(
+    model = tf_keras.Model(
         [word_ids, mask, type_ids, dense_inputs, dense_mask, dense_type_ids],
         [data, pooled])
     outputs = model.predict([
         word_id_data, mask_data, type_id_data, dense_input_data,
         dense_mask_data, dense_type_ids_data
     ])
     self.assertEqual(outputs[0].shape[-1], hidden_size)
@@ -322,22 +318,22 @@
     test_network = bert_encoder.BertEncoderV2(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         with_dense_inputs=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
-    dense_inputs = tf.keras.Input(
+    dense_inputs = tf_keras.Input(
         shape=(dense_sequence_length, hidden_size), dtype=tf.float32)
-    dense_mask = tf.keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
-    dense_type_ids = tf.keras.Input(
+    dense_mask = tf_keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
+    dense_type_ids = tf_keras.Input(
         shape=(dense_sequence_length,), dtype=tf.int32)
 
     test_network.build(
         dict(
             input_word_ids=word_ids,
             input_mask=mask,
             input_type_ids=type_ids,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/bert_encoder.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/bert_encoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,26 +13,27 @@
 # limitations under the License.
 
 """Transformer-based BERT encoder network."""
 # pylint: disable=g-classes-have-attributes
 
 from typing import Any, Callable, Optional, Union
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 
-_Initializer = Union[str, tf.keras.initializers.Initializer]
+_Initializer = Union[str, tf_keras.initializers.Initializer]
 _Activation = Union[str, Callable[..., Any]]
 
-_approx_gelu = lambda x: tf.keras.activations.gelu(x, approximate=True)
+_approx_gelu = lambda x: tf_keras.activations.gelu(x, approximate=True)
 
 
-class BertEncoderV2(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class BertEncoderV2(tf_keras.layers.Layer):
   """Bi-directional Transformer-based encoder network.
 
   This network implements a bi-directional Transformer-based encoder as
   described in "BERT: Pre-training of Deep Bidirectional Transformers for
   Language Understanding" (https://arxiv.org/abs/1810.04805). It includes the
   embedding lookups and transformer layers, but not the masked language model
   or classification task networks.
@@ -74,36 +75,39 @@
       layers. If set False, output of attention and intermediate dense layers is
       normalized.
     with_dense_inputs: Whether to accept dense embeddings as the input.
     return_attention_scores: Whether to add an additional output containing the
       attention scores of all transformer layers. This will be a list of length
       `num_layers`, and each element will be in the shape [batch_size,
       num_attention_heads, seq_dim, seq_dim].
+    return_word_embeddings: If true, also return the input word embedding
+      sequence in the bert inference output.
   """
 
   def __init__(
       self,
       vocab_size: int,
       hidden_size: int = 768,
       num_layers: int = 12,
       num_attention_heads: int = 12,
       max_sequence_length: int = 512,
       type_vocab_size: int = 16,
       inner_dim: int = 3072,
       inner_activation: _Activation = _approx_gelu,
       output_dropout: float = 0.1,
       attention_dropout: float = 0.1,
-      initializer: _Initializer = tf.keras.initializers.TruncatedNormal(
+      initializer: _Initializer = tf_keras.initializers.TruncatedNormal(
           stddev=0.02),
       output_range: Optional[int] = None,
       embedding_width: Optional[int] = None,
-      embedding_layer: Optional[tf.keras.layers.Layer] = None,
+      embedding_layer: Optional[tf_keras.layers.Layer] = None,
       norm_first: bool = False,
       with_dense_inputs: bool = False,
       return_attention_scores: bool = False,
+      return_word_embeddings: bool = False,
       **kwargs):
     # Pops kwargs that are used in V1 implementation.
     if 'dict_outputs' in kwargs:
       kwargs.pop('dict_outputs')
     if 'return_all_encoder_outputs' in kwargs:
       kwargs.pop('return_all_encoder_outputs')
     if 'intermediate_size' in kwargs:
@@ -114,16 +118,16 @@
       output_dropout = kwargs.pop('dropout_rate')
     if 'attention_dropout_rate' in kwargs:
       attention_dropout = kwargs.pop('attention_dropout_rate')
     super().__init__(**kwargs)
 
     self._output_range = output_range
 
-    activation = tf.keras.activations.get(inner_activation)
-    initializer = tf.keras.initializers.get(initializer)
+    activation = tf_keras.activations.get(inner_activation)
+    initializer = tf_keras.initializers.get(initializer)
 
     if embedding_width is None:
       embedding_width = hidden_size
 
     if embedding_layer is None:
       self._embedding_layer = layers.OnDeviceEmbedding(
           vocab_size=vocab_size,
@@ -141,25 +145,25 @@
     self._type_embedding_layer = layers.OnDeviceEmbedding(
         vocab_size=type_vocab_size,
         embedding_width=embedding_width,
         initializer=tf_utils.clone_initializer(initializer),
         use_one_hot=True,
         name='type_embeddings')
 
-    self._embedding_norm_layer = tf.keras.layers.LayerNormalization(
+    self._embedding_norm_layer = tf_keras.layers.LayerNormalization(
         name='embeddings/layer_norm', axis=-1, epsilon=1e-12, dtype=tf.float32)
 
-    self._embedding_dropout = tf.keras.layers.Dropout(
+    self._embedding_dropout = tf_keras.layers.Dropout(
         rate=output_dropout, name='embedding_dropout')
 
     # We project the 'embedding' output to 'hidden_size' if it is not already
     # 'hidden_size'.
     self._embedding_projection = None
     if embedding_width != hidden_size:
-      self._embedding_projection = tf.keras.layers.EinsumDense(
+      self._embedding_projection = tf_keras.layers.EinsumDense(
           '...x,xy->...y',
           output_shape=hidden_size,
           bias_axes='y',
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='embedding_projection')
 
     self._transformer_layers = []
@@ -175,54 +179,59 @@
           attention_dropout=attention_dropout,
           norm_first=norm_first,
           return_attention_scores=return_attention_scores,
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='transformer/layer_%d' % i)
       self._transformer_layers.append(layer)
 
-    self._pooler_layer = tf.keras.layers.Dense(
+    self._pooler_layer = tf_keras.layers.Dense(
         units=hidden_size,
         activation='tanh',
         kernel_initializer=tf_utils.clone_initializer(initializer),
         name='pooler_transform')
 
     self._config = {
         'vocab_size': vocab_size,
         'hidden_size': hidden_size,
         'num_layers': num_layers,
         'num_attention_heads': num_attention_heads,
         'max_sequence_length': max_sequence_length,
         'type_vocab_size': type_vocab_size,
         'inner_dim': inner_dim,
-        'inner_activation': tf.keras.activations.serialize(activation),
+        'inner_activation': tf_utils.serialize_activation(
+            activation, use_legacy_format=True
+        ),
         'output_dropout': output_dropout,
         'attention_dropout': attention_dropout,
-        'initializer': tf.keras.initializers.serialize(initializer),
+        'initializer': tf_utils.serialize_initializer(
+            initializer, use_legacy_format=True
+        ),
         'output_range': output_range,
         'embedding_width': embedding_width,
         'embedding_layer': embedding_layer,
         'norm_first': norm_first,
         'with_dense_inputs': with_dense_inputs,
         'return_attention_scores': return_attention_scores,
+        'return_word_embeddings': return_word_embeddings,
     }
     if with_dense_inputs:
       self.inputs = dict(
-          input_word_ids=tf.keras.Input(shape=(None,), dtype=tf.int32),
-          input_mask=tf.keras.Input(shape=(None,), dtype=tf.int32),
-          input_type_ids=tf.keras.Input(shape=(None,), dtype=tf.int32),
-          dense_inputs=tf.keras.Input(
+          input_word_ids=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          input_mask=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          input_type_ids=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          dense_inputs=tf_keras.Input(
               shape=(None, embedding_width), dtype=tf.float32),
-          dense_mask=tf.keras.Input(shape=(None,), dtype=tf.int32),
-          dense_type_ids=tf.keras.Input(shape=(None,), dtype=tf.int32),
+          dense_mask=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          dense_type_ids=tf_keras.Input(shape=(None,), dtype=tf.int32),
       )
     else:
       self.inputs = dict(
-          input_word_ids=tf.keras.Input(shape=(None,), dtype=tf.int32),
-          input_mask=tf.keras.Input(shape=(None,), dtype=tf.int32),
-          input_type_ids=tf.keras.Input(shape=(None,), dtype=tf.int32))
+          input_word_ids=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          input_mask=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          input_type_ids=tf_keras.Input(shape=(None,), dtype=tf.int32))
 
   def call(self, inputs):
     word_embeddings = None
     if isinstance(inputs, dict):
       word_ids = inputs.get('input_word_ids')
       mask = inputs.get('input_mask')
       type_ids = inputs.get('input_type_ids')
@@ -234,24 +243,18 @@
     else:
       raise ValueError('Unexpected inputs type to %s.' % self.__class__)
 
     if word_embeddings is None:
       word_embeddings = self._embedding_layer(word_ids)
 
     if dense_inputs is not None:
-      # Concat the dense embeddings at sequence end.
-      word_embeddings = tf.concat([word_embeddings, dense_inputs], axis=1)
-      type_ids = tf.concat([type_ids, dense_type_ids], axis=1)
       mask = tf.concat([mask, dense_mask], axis=1)
 
-    # absolute position embeddings.
-    position_embeddings = self._position_embedding_layer(word_embeddings)
-    type_embeddings = self._type_embedding_layer(type_ids)
-
-    embeddings = word_embeddings + position_embeddings + type_embeddings
+    embeddings = self._get_embeddings(word_ids, type_ids, word_embeddings,
+                                      dense_inputs, dense_type_ids)
     embeddings = self._embedding_norm_layer(embeddings)
     embeddings = self._embedding_dropout(embeddings)
 
     if self._embedding_projection is not None:
       embeddings = self._embedding_projection(embeddings)
 
     attention_mask = self._attention_mask_layer(embeddings, mask)
@@ -275,14 +278,18 @@
 
     output = dict(
         sequence_output=encoder_outputs[-1],
         pooled_output=pooled_output,
         encoder_outputs=encoder_outputs)
     if self._config['return_attention_scores']:
       output['attention_scores'] = attention_outputs
+
+    if self._config['return_word_embeddings']:
+      output['word_embeddings'] = embeddings
+
     return output
 
   def get_embedding_table(self):
     return self._embedding_layer.embeddings
 
   def get_embedding_layer(self):
     return self._embedding_layer
@@ -309,17 +316,35 @@
           'train this model, the embedding layer will no longer be shared. '
           'To work around this, load the model outside of the Keras API.')
       print('WARNING: ' + warn_string)
       logging.warn(warn_string)
 
     return cls(**config)
 
+  def _get_embeddings(self, word_ids: tf.Tensor, type_ids: tf.Tensor,
+                      word_embeddings: Optional[tf.Tensor],
+                      dense_inputs: Optional[tf.Tensor],
+                      dense_type_ids: Optional[tf.Tensor]) -> tf.Tensor:
+    if word_embeddings is None:
+      word_embeddings = self._embedding_layer(word_ids)
+
+    if dense_inputs is not None:
+      # Concat the dense embeddings at sequence end.
+      word_embeddings = tf.concat([word_embeddings, dense_inputs], axis=1)
+      type_ids = tf.concat([type_ids, dense_type_ids], axis=1)
+
+    type_embeddings = self._type_embedding_layer(type_ids)
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class BertEncoder(tf.keras.Model):
+    # absolute position embeddings.
+    position_embeddings = self._position_embedding_layer(word_embeddings)
+    return word_embeddings + position_embeddings + type_embeddings
+
+
+@tf_keras.utils.register_keras_serializable(package='Text')
+class BertEncoder(tf_keras.Model):
   """Bi-directional Transformer-based encoder network.
 
   This network implements a bi-directional Transformer-based encoder as
   described in "BERT: Pre-training of Deep Bidirectional Transformers for
   Language Understanding" (https://arxiv.org/abs/1810.04805). It includes the
   embedding lookups and transformer layers, but not the masked language model
   or classification task networks.
@@ -369,36 +394,39 @@
       all encoder transformer layers. Note: when the following `dict_outputs`
       argument is True, all encoder outputs are always returned in the dict,
       keyed by `encoder_outputs`.
     return_attention_scores: Whether to add an additional output containing the
       attention scores of all transformer layers. This will be a list of length
       `num_layers`, and each element will be in the shape [batch_size,
       num_attention_heads, seq_dim, seq_dim].
+    return_word_embeddings: If true, also return the input word embedding
+      sequence in the bert inference output.
   """
 
   def __init__(
       self,
       vocab_size,
       hidden_size=768,
       num_layers=12,
       num_attention_heads=12,
       max_sequence_length=512,
       type_vocab_size=16,
       inner_dim=3072,
-      inner_activation=lambda x: tf.keras.activations.gelu(x, approximate=True),
+      inner_activation=lambda x: tf_keras.activations.gelu(x, approximate=True),
       output_dropout=0.1,
       attention_dropout=0.1,
-      initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+      initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
       output_range=None,
       embedding_width=None,
       embedding_layer=None,
       norm_first=False,
       dict_outputs=False,
       return_all_encoder_outputs=False,
       return_attention_scores: bool = False,
+      return_word_embeddings: bool = False,
       **kwargs):
     if 'sequence_length' in kwargs:
       kwargs.pop('sequence_length')
       logging.warning('`sequence_length` is a deprecated argument to '
                       '`BertEncoder`, which has no effect for a while. Please '
                       'remove `sequence_length` argument.')
 
@@ -411,22 +439,22 @@
 
     if 'dropout_rate' in kwargs:
       output_dropout = kwargs.pop('dropout_rate')
 
     if 'attention_dropout_rate' in kwargs:
       attention_dropout = kwargs.pop('attention_dropout_rate')
 
-    activation = tf.keras.activations.get(inner_activation)
-    initializer = tf.keras.initializers.get(initializer)
+    activation = tf_keras.activations.get(inner_activation)
+    initializer = tf_keras.initializers.get(initializer)
 
-    word_ids = tf.keras.layers.Input(
+    word_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_word_ids')
-    mask = tf.keras.layers.Input(
+    mask = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_mask')
-    type_ids = tf.keras.layers.Input(
+    type_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_type_ids')
 
     if embedding_width is None:
       embedding_width = hidden_size
 
     if embedding_layer is None:
       embedding_layer_inst = layers.OnDeviceEmbedding(
@@ -448,27 +476,27 @@
         vocab_size=type_vocab_size,
         embedding_width=embedding_width,
         initializer=tf_utils.clone_initializer(initializer),
         use_one_hot=True,
         name='type_embeddings')
     type_embeddings = type_embedding_layer(type_ids)
 
-    embeddings = tf.keras.layers.Add()(
+    embeddings = tf_keras.layers.Add()(
         [word_embeddings, position_embeddings, type_embeddings])
 
-    embedding_norm_layer = tf.keras.layers.LayerNormalization(
+    embedding_norm_layer = tf_keras.layers.LayerNormalization(
         name='embeddings/layer_norm', axis=-1, epsilon=1e-12, dtype=tf.float32)
 
     embeddings = embedding_norm_layer(embeddings)
-    embeddings = (tf.keras.layers.Dropout(rate=output_dropout)(embeddings))
+    embeddings = (tf_keras.layers.Dropout(rate=output_dropout)(embeddings))
 
     # We project the 'embedding' output to 'hidden_size' if it is not already
     # 'hidden_size'.
     if embedding_width != hidden_size:
-      embedding_projection = tf.keras.layers.EinsumDense(
+      embedding_projection = tf_keras.layers.EinsumDense(
           '...x,xy->...y',
           output_shape=hidden_size,
           bias_axes='y',
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='embedding_projection')
       embeddings = embedding_projection(embeddings)
     else:
@@ -502,29 +530,32 @@
       encoder_outputs.append(data)
 
     last_encoder_output = encoder_outputs[-1]
     # Applying a tf.slice op (through subscript notation) to a Keras tensor
     # like this will create a SliceOpLambda layer. This is better than a Lambda
     # layer with Python code, because that is fundamentally less portable.
     first_token_tensor = last_encoder_output[:, 0, :]
-    pooler_layer = tf.keras.layers.Dense(
+    pooler_layer = tf_keras.layers.Dense(
         units=hidden_size,
         activation='tanh',
         kernel_initializer=tf_utils.clone_initializer(initializer),
         name='pooler_transform')
     cls_output = pooler_layer(first_token_tensor)
 
     outputs = dict(
         sequence_output=encoder_outputs[-1],
         pooled_output=cls_output,
         encoder_outputs=encoder_outputs,
     )
     if return_attention_scores:
       outputs['attention_scores'] = attention_outputs
 
+    if return_word_embeddings:
+      outputs['word_embeddings'] = embeddings
+
     if dict_outputs:
       super().__init__(
           inputs=[word_ids, mask, type_ids], outputs=outputs, **kwargs)
     else:
       cls_output = outputs['pooled_output']
       if return_all_encoder_outputs:
         encoder_outputs = outputs['encoder_outputs']
@@ -552,24 +583,29 @@
         'vocab_size': vocab_size,
         'hidden_size': hidden_size,
         'num_layers': num_layers,
         'num_attention_heads': num_attention_heads,
         'max_sequence_length': max_sequence_length,
         'type_vocab_size': type_vocab_size,
         'inner_dim': inner_dim,
-        'inner_activation': tf.keras.activations.serialize(activation),
+        'inner_activation': tf_utils.serialize_activation(
+            activation, use_legacy_format=True
+        ),
         'output_dropout': output_dropout,
         'attention_dropout': attention_dropout,
-        'initializer': tf.keras.initializers.serialize(initializer),
+        'initializer': tf_utils.serialize_initializer(
+            initializer, use_legacy_format=True
+        ),
         'output_range': output_range,
         'embedding_width': embedding_width,
         'embedding_layer': embedding_layer,
         'norm_first': norm_first,
         'dict_outputs': dict_outputs,
         'return_attention_scores': return_attention_scores,
+        'return_word_embeddings': return_word_embeddings,
     }
     # pylint: disable=protected-access
     self._setattr_tracking = False
     self._config = config_dict
     self._setattr_tracking = True
     # pylint: enable=protected-access
 
@@ -600,8 +636,7 @@
           'potentially-shared embedding layer object. If you contine to '
           'train this model, the embedding layer will no longer be shared. '
           'To work around this, load the model outside of the Keras API.')
       print('WARNING: ' + warn_string)
       logging.warn(warn_string)
 
     return cls(**config)
-
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/bert_encoder_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/bert_encoder_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,28 +13,24 @@
 # limitations under the License.
 
 """Tests for transformer-based bert encoder network."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.networks import bert_encoder
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class BertEncoderTest(keras_parameterized.TestCase):
+class BertEncoderTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(BertEncoderTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   @parameterized.named_parameters(
       ("encoder_v2", bert_encoder.BertEncoderV2),
       ("encoder_v1", bert_encoder.BertEncoder),
   )
   def test_dict_outputs_network_creation(self, encoder_cls):
     hidden_size = 32
@@ -47,25 +43,25 @@
     test_network = encoder_cls(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         **kwargs)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     self.assertIsInstance(test_network.transformer_layers, list)
     self.assertLen(test_network.transformer_layers, 3)
-    self.assertIsInstance(test_network.pooler_layer, tf.keras.layers.Dense)
+    self.assertIsInstance(test_network.pooler_layer, tf_keras.layers.Dense)
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
     # The default output dtype is float32.
@@ -83,17 +79,17 @@
     test_network = encoder_cls(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         dict_outputs=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     all_encoder_outputs = dict_outputs["encoder_outputs"]
     pooled = dict_outputs["pooled_output"]
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
@@ -121,17 +117,17 @@
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=num_attention_heads,
         num_layers=num_layers,
         return_attention_scores=True,
         dict_outputs=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     all_attention_outputs = dict_outputs["attention_scores"]
 
     expected_data_shape = [
         None, num_attention_heads, sequence_length, sequence_length
     ]
@@ -142,29 +138,61 @@
     # The default output dtype is float32.
     self.assertAllEqual(tf.float32, all_attention_outputs[-1].dtype)
 
   @parameterized.named_parameters(
       ("encoder_v2", bert_encoder.BertEncoderV2),
       ("encoder_v1", bert_encoder.BertEncoder),
   )
+  def test_dict_outputs_network_creation_return_word_embeddings(
+      self, encoder_cls):
+    hidden_size = 32
+    sequence_length = 21
+    num_attention_heads = 5
+    num_layers = 3
+    # Create a small BertEncoder for testing.
+    test_network = encoder_cls(
+        vocab_size=100,
+        hidden_size=hidden_size,
+        num_attention_heads=num_attention_heads,
+        num_layers=num_layers,
+        return_word_embeddings=True,
+        dict_outputs=True)
+    # Create the inputs (note that the first dimension is implicit).
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    dict_outputs = test_network(
+        dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
+    word_embeddings = dict_outputs["word_embeddings"]
+
+    expected_data_shape = [None, sequence_length, hidden_size]
+    self.assertAllEqual(expected_data_shape, word_embeddings.shape)
+
+    # The default output dtype is float32.
+    self.assertAllEqual(tf.float32, word_embeddings[-1].dtype)
+
+  @parameterized.named_parameters(
+      ("encoder_v2", bert_encoder.BertEncoderV2),
+      ("encoder_v1", bert_encoder.BertEncoder),
+  )
   def test_dict_outputs_network_creation_with_float16_dtype(self, encoder_cls):
     hidden_size = 32
     sequence_length = 21
-    tf.keras.mixed_precision.set_global_policy("mixed_float16")
+    tf_keras.mixed_precision.set_global_policy("mixed_float16")
     # Create a small BertEncoder for testing.
     test_network = encoder_cls(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         dict_outputs=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
@@ -194,24 +222,24 @@
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types,
         output_range=output_range,
         dict_outputs=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     # Create a model based off of this network:
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
@@ -230,15 +258,15 @@
         num_layers=3,
         type_vocab_size=num_types,
         dict_outputs=True)
     dict_outputs = test_network(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     outputs = model.predict([word_id_data, mask_data, type_id_data])
     self.assertEqual(outputs[0].shape[1], sequence_length)
 
     # Creates a BertEncoder with embedding_width != hidden_size
     test_network = encoder_cls(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
@@ -248,32 +276,32 @@
         type_vocab_size=num_types,
         embedding_width=16,
         dict_outputs=True)
     dict_outputs = test_network(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     outputs = model.predict([word_id_data, mask_data, type_id_data])
     self.assertEqual(outputs[0].shape[-1], hidden_size)
     self.assertTrue(hasattr(test_network, "_embedding_projection"))
 
   def test_embeddings_as_inputs(self):
     hidden_size = 32
     sequence_length = 21
     # Create a small BertEncoder for testing.
     test_network = bert_encoder.BertEncoderV2(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     test_network.build(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     embeddings = test_network.get_embedding_layer()(word_ids)
     # Calls with the embeddings.
     dict_outputs = test_network(
         dict(
             input_word_embeddings=embeddings,
@@ -307,42 +335,68 @@
         output_dropout=0.05,
         attention_dropout=0.22,
         initializer="glorot_uniform",
         output_range=-1,
         embedding_width=16,
         embedding_layer=None,
         norm_first=False)
-    network = bert_encoder.BertEncoder(**kwargs)
 
-    # Validate that the config can be forced to JSON.
-    _ = network.to_json()
+    with self.subTest("BertEncoder"):
+      network = bert_encoder.BertEncoder(**kwargs)
+
+      # Validate that the config can be forced to JSON.
+      _ = network.to_json()
 
-    # Tests model saving/loading.
-    model_path = self.get_temp_dir() + "/model"
-    network.save(model_path)
-    _ = tf.keras.models.load_model(model_path)
+      # Tests model saving/loading with SavedModel.
+      model_path = self.get_temp_dir() + "/model"
+      network.save(model_path)
+      _ = tf_keras.models.load_model(model_path)
+
+      # Test model saving/loading with Keras V3.
+      keras_path = self.get_temp_dir() + "/model.keras"
+      network.save(keras_path)
+      _ = tf_keras.models.load_model(keras_path)
+
+    with self.subTest("BertEncoderV2"):
+      new_net = bert_encoder.BertEncoderV2(**kwargs)
+      inputs = new_net.inputs
+      outputs = new_net(inputs)
+      network_v2 = tf_keras.Model(inputs=inputs, outputs=outputs)
+
+      # Validate that the config can be forced to JSON.
+      _ = network_v2.to_json()
+
+      # Tests model saving/loading with SavedModel.
+      model_path = self.get_temp_dir() + "/v2_model"
+      network_v2.save(model_path)
+      _ = tf_keras.models.load_model(model_path)
+
+      # Test model saving/loading with Keras V3.
+      keras_path = self.get_temp_dir() + "/v2_model.keras"
+      network_v2.save(keras_path)
+      _ = tf_keras.models.load_model(keras_path)
 
   def test_network_creation(self):
     hidden_size = 32
     sequence_length = 21
     # Create a small BertEncoder for testing.
     test_network = bert_encoder.BertEncoder(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     data, pooled = test_network([word_ids, mask, type_ids])
 
     self.assertIsInstance(test_network.transformer_layers, list)
     self.assertLen(test_network.transformer_layers, 3)
-    self.assertIsInstance(test_network.pooler_layer, tf.keras.layers.Dense)
+    self.assertIsInstance(test_network.pooler_layer, tf_keras.layers.Dense)
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
     # The default output dtype is float32.
@@ -385,17 +439,17 @@
     test_network = bert_encoder.BertEncoder(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         return_all_encoder_outputs=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     all_encoder_outputs, pooled = test_network([word_ids, mask, type_ids])
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertLen(all_encoder_outputs, 3)
     for data in all_encoder_outputs:
       self.assertAllEqual(expected_data_shape, data.shape.as_list())
@@ -414,17 +468,17 @@
     test_network = bert_encoder.BertEncoder(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=num_attention_heads,
         num_layers=num_layers,
         return_attention_scores=True)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     _, _, all_attention_outputs = test_network([word_ids, mask, type_ids])
 
     expected_data_shape = [
         None, num_attention_heads, sequence_length, sequence_length
     ]
     self.assertLen(all_attention_outputs, num_layers)
     for data in all_attention_outputs:
@@ -432,25 +486,25 @@
 
     # The default output dtype is float32.
     self.assertAllEqual(tf.float32, all_attention_outputs[-1].dtype)
 
   def test_network_creation_with_float16_dtype(self):
     hidden_size = 32
     sequence_length = 21
-    tf.keras.mixed_precision.set_global_policy("mixed_float16")
+    tf_keras.mixed_precision.set_global_policy("mixed_float16")
     # Create a small BertEncoder for testing.
     test_network = bert_encoder.BertEncoder(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     data, pooled = test_network([word_ids, mask, type_ids])
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
@@ -473,21 +527,21 @@
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types,
         output_range=output_range)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     data, pooled = test_network([word_ids, mask, type_ids])
 
     # Create a model based off of this network:
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
@@ -502,39 +556,39 @@
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         max_sequence_length=max_sequence_length,
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types)
     data, pooled = test_network([word_ids, mask, type_ids])
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     outputs = model.predict([word_id_data, mask_data, type_id_data])
     self.assertEqual(outputs[0].shape[1], sequence_length)
 
     # Creates a BertEncoder with embedding_width != hidden_size
     test_network = bert_encoder.BertEncoder(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         max_sequence_length=max_sequence_length,
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types,
         embedding_width=16)
     data, pooled = test_network([word_ids, mask, type_ids])
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     outputs = model.predict([word_id_data, mask_data, type_id_data])
     self.assertEqual(outputs[0].shape[-1], hidden_size)
     self.assertTrue(hasattr(test_network, "_embedding_projection"))
 
 
 class BertEncoderV2CompatibilityTest(tf.test.TestCase):
 
   def tearDown(self):
     super().tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   def test_weights_forward_compatible(self):
     batch_size = 3
 
     hidden_size = 32
     sequence_length = 21
     vocab_size = 57
@@ -659,23 +713,23 @@
         input_mask=mask_data,
         input_type_ids=type_id_data)
 
     kwargs["dict_outputs"] = True
     old_net = bert_encoder.BertEncoder(**kwargs)
     inputs = old_net.inputs
     outputs = old_net(inputs)
-    old_model = tf.keras.Model(inputs=inputs, outputs=outputs)
+    old_model = tf_keras.Model(inputs=inputs, outputs=outputs)
     old_model_outputs = old_model(data)
     ckpt = tf.train.Checkpoint(net=old_model)
     path = ckpt.save(self.get_temp_dir())
     del kwargs["dict_outputs"]
     new_net = bert_encoder.BertEncoderV2(**kwargs)
     inputs = new_net.inputs
     outputs = new_net(inputs)
-    new_model = tf.keras.Model(inputs=inputs, outputs=outputs)
+    new_model = tf_keras.Model(inputs=inputs, outputs=outputs)
     new_ckpt = tf.train.Checkpoint(net=new_model)
     status = new_ckpt.restore(path)
 
     status.assert_existing_objects_matched()
     new_model_outputs = new_model(data)
 
     self.assertAllEqual(old_model_outputs.keys(), new_model_outputs.keys())
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/classification.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/classification.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,20 +11,20 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Classification and regression network."""
 # pylint: disable=g-classes-have-attributes
 import collections
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow.python.util import deprecation
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class Classification(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class Classification(tf_keras.Model):
   """Classification network head for BERT modeling.
 
   This network implements a simple classifier head based on a dense layer. If
   num_classes is one, it can be considered as a regression problem.
 
   *Note* that the network is constructed by
   [Keras Functional API](https://keras.io/guides/functional_api/).
@@ -45,32 +45,32 @@
   def __init__(self,
                input_width,
                num_classes,
                initializer='glorot_uniform',
                output='logits',
                **kwargs):
 
-    cls_output = tf.keras.layers.Input(
+    cls_output = tf_keras.layers.Input(
         shape=(input_width,), name='cls_output', dtype=tf.float32)
 
-    logits = tf.keras.layers.Dense(
+    logits = tf_keras.layers.Dense(
         num_classes,
         activation=None,
         kernel_initializer=initializer,
         name='predictions/transform/logits')(
             cls_output)
 
     if output == 'logits':
       output_tensors = logits
     elif output == 'predictions':
-      policy = tf.keras.mixed_precision.global_policy()
+      policy = tf_keras.mixed_precision.global_policy()
       if policy.name == 'mixed_bfloat16':
         # b/158514794: bf16 is not stable with post-softmax cross-entropy.
         policy = tf.float32
-      output_tensors = tf.keras.layers.Activation(
+      output_tensors = tf_keras.layers.Activation(
           tf.nn.log_softmax, dtype=policy)(
               logits)
     else:
       raise ValueError(
           ('Unknown `output` value "%s". `output` can be either "logits" or '
            '"predictions"') % output)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/classification_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/classification_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,104 +10,96 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for classification network."""
 
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.networks import classification
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class ClassificationTest(keras_parameterized.TestCase):
+class ClassificationTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.parameters(1, 10)
   def test_network_creation(self, num_classes):
     """Validate that the Keras object can be created."""
     input_width = 512
     test_object = classification.Classification(
         input_width=input_width, num_classes=num_classes)
     # Create a 2-dimensional input (the first dimension is implicit).
-    cls_data = tf.keras.Input(shape=(input_width,), dtype=tf.float32)
+    cls_data = tf_keras.Input(shape=(input_width,), dtype=tf.float32)
     output = test_object(cls_data)
 
     # Validate that the outputs are of the expected shape.
     expected_output_shape = [None, num_classes]
     self.assertEqual(expected_output_shape, output.shape.as_list())
 
   @parameterized.parameters(1, 10)
   def test_network_invocation(self, num_classes):
     """Validate that the Keras object can be invoked."""
     input_width = 512
     test_object = classification.Classification(
         input_width=input_width, num_classes=num_classes, output='predictions')
     # Create a 2-dimensional input (the first dimension is implicit).
-    cls_data = tf.keras.Input(shape=(input_width,), dtype=tf.float32)
+    cls_data = tf_keras.Input(shape=(input_width,), dtype=tf.float32)
     output = test_object(cls_data)
 
     # Invoke the network as part of a Model.
-    model = tf.keras.Model(cls_data, output)
+    model = tf_keras.Model(cls_data, output)
     input_data = 10 * np.random.random_sample((3, input_width))
     _ = model.predict(input_data)
 
   def test_network_invocation_with_internal_logits(self):
     """Validate that the logit outputs are correct."""
     input_width = 512
     num_classes = 10
     test_object = classification.Classification(
         input_width=input_width, num_classes=num_classes, output='predictions')
 
     # Create a 2-dimensional input (the first dimension is implicit).
-    cls_data = tf.keras.Input(shape=(input_width,), dtype=tf.float32)
+    cls_data = tf_keras.Input(shape=(input_width,), dtype=tf.float32)
     output = test_object(cls_data)
-    model = tf.keras.Model(cls_data, output)
-    logits_model = tf.keras.Model(test_object.inputs, test_object.logits)
+    model = tf_keras.Model(cls_data, output)
+    logits_model = tf_keras.Model(test_object.inputs, test_object.logits)
 
     batch_size = 3
     input_data = 10 * np.random.random_sample((batch_size, input_width))
     outputs = model.predict(input_data)
     logits = logits_model.predict(input_data)
 
     # Ensure that the tensor shapes are correct.
     expected_output_shape = (batch_size, num_classes)
     self.assertEqual(expected_output_shape, outputs.shape)
     self.assertEqual(expected_output_shape, logits.shape)
 
     # Ensure that the logits, when softmaxed, create the outputs.
-    input_tensor = tf.keras.Input(expected_output_shape[1:])
-    output_tensor = tf.keras.layers.Activation(tf.nn.log_softmax)(input_tensor)
-    softmax_model = tf.keras.Model(input_tensor, output_tensor)
+    input_tensor = tf_keras.Input(expected_output_shape[1:])
+    output_tensor = tf_keras.layers.Activation(tf.nn.log_softmax)(input_tensor)
+    softmax_model = tf_keras.Model(input_tensor, output_tensor)
 
     calculated_softmax = softmax_model.predict(logits)
     self.assertAllClose(outputs, calculated_softmax)
 
   @parameterized.parameters(1, 10)
   def test_network_invocation_with_internal_and_external_logits(
       self, num_classes):
     """Validate that the logit outputs are correct."""
     input_width = 512
     test_object = classification.Classification(
         input_width=input_width, num_classes=num_classes, output='logits')
 
     # Create a 2-dimensional input (the first dimension is implicit).
-    cls_data = tf.keras.Input(shape=(input_width,), dtype=tf.float32)
+    cls_data = tf_keras.Input(shape=(input_width,), dtype=tf.float32)
     output = test_object(cls_data)
-    model = tf.keras.Model(cls_data, output)
-    logits_model = tf.keras.Model(test_object.inputs, test_object.logits)
+    model = tf_keras.Model(cls_data, output)
+    logits_model = tf_keras.Model(test_object.inputs, test_object.logits)
 
     batch_size = 3
     input_data = 10 * np.random.random_sample((batch_size, input_width))
     outputs = model.predict(input_data)
     logits = logits_model.predict(input_data)
 
     # Ensure that the tensor shapes are correct.
@@ -124,35 +116,35 @@
     test_object = classification.Classification(
         input_width=input_width, num_classes=num_classes, output='predictions')
     logit_object = classification.Classification(
         input_width=input_width, num_classes=num_classes, output='logits')
     logit_object.set_weights(test_object.get_weights())
 
     # Create a 2-dimensional input (the first dimension is implicit).
-    cls_data = tf.keras.Input(shape=(input_width,), dtype=tf.float32)
+    cls_data = tf_keras.Input(shape=(input_width,), dtype=tf.float32)
     output = test_object(cls_data)
     logit_output = logit_object(cls_data)
 
-    model = tf.keras.Model(cls_data, output)
-    logits_model = tf.keras.Model(cls_data, logit_output)
+    model = tf_keras.Model(cls_data, output)
+    logits_model = tf_keras.Model(cls_data, logit_output)
 
     batch_size = 3
     input_data = 10 * np.random.random_sample((batch_size, input_width))
     outputs = model.predict(input_data)
     logits = logits_model.predict(input_data)
 
     # Ensure that the tensor shapes are correct.
     expected_output_shape = (batch_size, num_classes)
     self.assertEqual(expected_output_shape, outputs.shape)
     self.assertEqual(expected_output_shape, logits.shape)
 
     # Ensure that the logits, when softmaxed, create the outputs.
-    input_tensor = tf.keras.Input(expected_output_shape[1:])
-    output_tensor = tf.keras.layers.Activation(tf.nn.log_softmax)(input_tensor)
-    softmax_model = tf.keras.Model(input_tensor, output_tensor)
+    input_tensor = tf_keras.Input(expected_output_shape[1:])
+    output_tensor = tf_keras.layers.Activation(tf.nn.log_softmax)(input_tensor)
+    softmax_model = tf_keras.Model(input_tensor, output_tensor)
 
     calculated_softmax = softmax_model.predict(logits)
     self.assertAllClose(outputs, calculated_softmax)
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     network = classification.Classification(
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/encoder_scaffold.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/encoder_scaffold.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,23 +15,23 @@
 """Transformer-based text encoder network."""
 # pylint: disable=g-classes-have-attributes
 import copy
 import inspect
 
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
+@tf_keras.utils.register_keras_serializable(package='Text')
 @gin.configurable
-class EncoderScaffold(tf.keras.Model):
+class EncoderScaffold(tf_keras.Model):
   """Bi-directional Transformer-based encoder network scaffold.
 
   This network allows users to flexibly implement an encoder similar to the one
   described in "BERT: Pre-training of Deep Bidirectional Transformers for
   Language Understanding" (https://arxiv.org/abs/1810.04805).
 
   In this network, users can choose to provide a custom embedding subnetwork
@@ -106,15 +106,15 @@
     feed_layer_idx: whether the scaffold should feed layer index to hidden_cls.
     recursive: whether to pass the second return of the hidden layer as the last
       element among the inputs. None will be passed as the initial state.
   """
 
   def __init__(self,
                pooled_output_dim,
-               pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+               pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
                    stddev=0.02),
                embedding_cls=None,
                embedding_cfg=None,
                embedding_data=None,
                num_hidden_instances=1,
                hidden_cls=layers.Transformer,
                hidden_cfg=None,
@@ -139,19 +139,19 @@
       embedding_layer = None
       position_embedding_layer = None
       type_embedding_layer = None
       embedding_norm_layer = None
     else:
       embedding_network = None
       seq_length = embedding_cfg.get('seq_length', None)
-      word_ids = tf.keras.layers.Input(
+      word_ids = tf_keras.layers.Input(
           shape=(seq_length,), dtype=tf.int32, name='input_word_ids')
-      mask = tf.keras.layers.Input(
+      mask = tf_keras.layers.Input(
           shape=(seq_length,), dtype=tf.int32, name='input_mask')
-      type_ids = tf.keras.layers.Input(
+      type_ids = tf_keras.layers.Input(
           shape=(seq_length,), dtype=tf.int32, name='input_type_ids')
       inputs = [word_ids, mask, type_ids]
 
       embedding_layer = layers.OnDeviceEmbedding(
           vocab_size=embedding_cfg['vocab_size'],
           embedding_width=embedding_cfg['hidden_size'],
           initializer=tf_utils.clone_initializer(embedding_cfg['initializer']),
@@ -170,26 +170,26 @@
           vocab_size=embedding_cfg['type_vocab_size'],
           embedding_width=embedding_cfg['hidden_size'],
           initializer=tf_utils.clone_initializer(embedding_cfg['initializer']),
           use_one_hot=True,
           name='type_embeddings')
       type_embeddings = type_embedding_layer(type_ids)
 
-      embeddings = tf.keras.layers.Add()(
+      embeddings = tf_keras.layers.Add()(
           [word_embeddings, position_embeddings, type_embeddings])
 
-      embedding_norm_layer = tf.keras.layers.LayerNormalization(
+      embedding_norm_layer = tf_keras.layers.LayerNormalization(
           name='embeddings/layer_norm',
           axis=-1,
           epsilon=1e-12,
           dtype=tf.float32)
       embeddings = embedding_norm_layer(embeddings)
 
       embeddings = (
-          tf.keras.layers.Dropout(
+          tf_keras.layers.Dropout(
               rate=embedding_cfg['dropout_rate'])(embeddings))
 
       mask_cfg = {} if mask_cfg is None else mask_cfg
       if inspect.isclass(mask_cls):
         mask_layer = mask_cls(**mask_cfg)
       else:
         mask_layer = mask_cls
@@ -229,28 +229,28 @@
       else:
         data = layer([data, attention_mask])
       layer_output_data.append(data)
       hidden_layers.append(layer)
 
     if layer_norm_before_pooling:
       # Normalize the final output.
-      output_layer_norm = tf.keras.layers.LayerNormalization(
+      output_layer_norm = tf_keras.layers.LayerNormalization(
           name='final_layer_norm',
           axis=-1,
           epsilon=1e-12)
       layer_output_data[-1] = output_layer_norm(layer_output_data[-1])
 
     last_layer_output = layer_output_data[-1]
     # Applying a tf.slice op (through subscript notation) to a Keras tensor
     # like this will create a SliceOpLambda layer. This is better than a Lambda
     # layer with Python code, because that is fundamentally less portable.
     first_token_tensor = last_layer_output[:, 0, :]
-    pooler_layer_initializer = tf.keras.initializers.get(
+    pooler_layer_initializer = tf_keras.initializers.get(
         pooler_layer_initializer)
-    pooler_layer = tf.keras.layers.Dense(
+    pooler_layer = tf_keras.layers.Dense(
         units=pooled_output_dim,
         activation='tanh',
         kernel_initializer=pooler_layer_initializer,
         name='cls_transform')
     cls_output = pooler_layer(first_token_tensor)
 
     if dict_outputs:
@@ -302,15 +302,15 @@
 
     logging.info('EncoderScaffold configs: %s', self.get_config())
 
   def get_config(self):
     config_dict = {
         'num_hidden_instances': self._num_hidden_instances,
         'pooled_output_dim': self._pooled_output_dim,
-        'pooler_layer_initializer': tf.keras.initializers.serialize(
+        'pooler_layer_initializer': tf_keras.initializers.serialize(
             self._pooler_layer_initializer),
         'embedding_cls': self._embedding_network,
         'embedding_cfg': self._embedding_cfg,
         'layer_norm_before_pooling': self._layer_norm_before_pooling,
         'return_all_layer_outputs': self._return_all_layer_outputs,
         'dict_outputs': self._dict_outputs,
         'layer_idx_as_attention_seed': self._layer_idx_as_attention_seed
@@ -323,40 +323,40 @@
     for cfg_name, cfg in cfgs.items():
       if cfg:
         config_dict[cfg_name] = {}
         for k, v in cfg.items():
           # `self._hidden_cfg` may contain `class`, e.g., when `hidden_cfg` is
           # `TransformerScaffold`, `attention_cls` argument can be a `class`.
           if inspect.isclass(v):
-            config_dict[cfg_name][k] = tf.keras.utils.get_registered_name(v)
+            config_dict[cfg_name][k] = tf_keras.utils.get_registered_name(v)
           else:
             config_dict[cfg_name][k] = v
 
     clss = {
         'hidden_cls': self._hidden_cls,
         'mask_cls': self._mask_cls
     }
 
     for cls_name, cls in clss.items():
       if inspect.isclass(cls):
         key = '{}_string'.format(cls_name)
-        config_dict[key] = tf.keras.utils.get_registered_name(cls)
+        config_dict[key] = tf_keras.utils.get_registered_name(cls)
       else:
         config_dict[cls_name] = cls
 
     config_dict.update(self._kwargs)
     return config_dict
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
     cls_names = ['hidden_cls', 'mask_cls']
     for cls_name in cls_names:
       cls_string = '{}_string'.format(cls_name)
       if cls_string in config:
-        config[cls_name] = tf.keras.utils.get_registered_object(
+        config[cls_name] = tf_keras.utils.get_registered_object(
             config[cls_string], custom_objects=custom_objects)
         del config[cls_string]
     return cls(**config)
 
   def get_embedding_table(self):
     if self._embedding_network is None:
       # In this case, we don't have a custom embedding network and can return
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/encoder_scaffold_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/encoder_scaffold_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,97 +12,93 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for EncoderScaffold network."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import activations
 from official.nlp.modeling import layers
 from official.nlp.modeling.networks import encoder_scaffold
 
 
 # Test class that wraps a standard transformer layer. If this layer is called
 # at any point, the list passed to the config object will be filled with a
 # boolean 'True'. We register this class as a Keras serializable so we can
 # test serialization below.
-@tf.keras.utils.register_keras_serializable(package="TestOnly")
+@tf_keras.utils.register_keras_serializable(package="TestOnly")
 class ValidatedTransformerLayer(layers.Transformer):
 
   def __init__(self, call_list, call_class=None, **kwargs):
     super(ValidatedTransformerLayer, self).__init__(**kwargs)
     self.list = call_list
     self.call_class = call_class
 
   def call(self, inputs):
     self.list.append(True)
     return super(ValidatedTransformerLayer, self).call(inputs)
 
   def get_config(self):
     config = super(ValidatedTransformerLayer, self).get_config()
     config["call_list"] = self.list
-    config["call_class"] = tf.keras.utils.get_registered_name(self.call_class)
+    config["call_class"] = tf_keras.utils.get_registered_name(self.call_class)
     return config
 
 
 # Test class that wraps a standard self attention mask layer.
 # If this layer is called at any point, the list passed to the config
 # object will be filled with a
 # boolean 'True'. We register this class as a Keras serializable so we can
 # test serialization below.
-@tf.keras.utils.register_keras_serializable(package="TestOnly")
+@tf_keras.utils.register_keras_serializable(package="TestOnly")
 class ValidatedMaskLayer(layers.SelfAttentionMask):
 
   def __init__(self, call_list, call_class=None, **kwargs):
     super(ValidatedMaskLayer, self).__init__(**kwargs)
     self.list = call_list
     self.call_class = call_class
 
   def call(self, inputs, mask):
     self.list.append(True)
     return super(ValidatedMaskLayer, self).call(inputs, mask)
 
   def get_config(self):
     config = super(ValidatedMaskLayer, self).get_config()
     config["call_list"] = self.list
-    config["call_class"] = tf.keras.utils.get_registered_name(self.call_class)
+    config["call_class"] = tf_keras.utils.get_registered_name(self.call_class)
     return config
 
 
-@tf.keras.utils.register_keras_serializable(package="TestLayerOnly")
-class TestLayer(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="TestLayerOnly")
+class TestLayer(tf_keras.layers.Layer):
   pass
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class EncoderScaffoldLayerClassTest(keras_parameterized.TestCase):
+class EncoderScaffoldLayerClassTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(EncoderScaffoldLayerClassTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   @parameterized.named_parameters(
       dict(testcase_name="only_final_output", return_all_layer_outputs=False),
       dict(testcase_name="all_layer_outputs", return_all_layer_outputs=True))
   def test_network_creation(self, return_all_layer_outputs):
     hidden_size = 32
     sequence_length = 21
     num_hidden_instances = 3
     embedding_cfg = {
         "vocab_size": 100,
         "type_vocab_size": 16,
         "hidden_size": hidden_size,
         "seq_length": sequence_length,
         "max_seq_length": sequence_length,
-        "initializer": tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        "initializer": tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "dropout_rate": 0.1,
     }
 
     call_list = []
     hidden_cfg = {
         "num_attention_heads":
             2,
@@ -111,51 +107,51 @@
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "call_list":
             call_list
     }
     mask_call_list = []
     mask_cfg = {
         "call_list":
             mask_call_list
     }
     # Create a small EncoderScaffold for testing.
     test_network = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=num_hidden_instances,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cls=ValidatedTransformerLayer,
         hidden_cfg=hidden_cfg,
         mask_cls=ValidatedMaskLayer,
         mask_cfg=mask_cfg,
         embedding_cfg=embedding_cfg,
         layer_norm_before_pooling=True,
         return_all_layer_outputs=return_all_layer_outputs)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     output_data, pooled = test_network([word_ids, mask, type_ids])
 
     if return_all_layer_outputs:
       self.assertIsInstance(output_data, list)
       self.assertLen(output_data, num_hidden_instances)
       data = output_data[-1]
     else:
       data = output_data
     self.assertIsInstance(test_network.hidden_layers, list)
     self.assertLen(test_network.hidden_layers, num_hidden_instances)
-    self.assertIsInstance(test_network.pooler_layer, tf.keras.layers.Dense)
+    self.assertIsInstance(test_network.pooler_layer, tf_keras.layers.Dense)
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
     # The default output dtype is float32.
@@ -166,52 +162,52 @@
     # instantiated from the given config properly.
     self.assertNotEmpty(call_list)
     self.assertTrue(call_list[0], "The passed layer class wasn't instantiated.")
 
     self.assertTrue(hasattr(test_network, "_output_layer_norm"))
 
   def test_network_creation_with_float16_dtype(self):
-    tf.keras.mixed_precision.set_global_policy("mixed_float16")
+    tf_keras.mixed_precision.set_global_policy("mixed_float16")
     hidden_size = 32
     sequence_length = 21
     embedding_cfg = {
         "vocab_size": 100,
         "type_vocab_size": 16,
         "hidden_size": hidden_size,
         "seq_length": sequence_length,
         "max_seq_length": sequence_length,
-        "initializer": tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        "initializer": tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "dropout_rate": 0.1,
     }
     hidden_cfg = {
         "num_attention_heads":
             2,
         "intermediate_size":
             3072,
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
     }
     # Create a small EncoderScaffold for testing.
     test_network = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cfg=hidden_cfg,
         embedding_cfg=embedding_cfg)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     data, pooled = test_network([word_ids, mask, type_ids])
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
@@ -227,49 +223,49 @@
     num_types = 7
     embedding_cfg = {
         "vocab_size": vocab_size,
         "type_vocab_size": num_types,
         "hidden_size": hidden_size,
         "seq_length": sequence_length,
         "max_seq_length": sequence_length,
-        "initializer": tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        "initializer": tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "dropout_rate": 0.1,
     }
     hidden_cfg = {
         "num_attention_heads":
             2,
         "intermediate_size":
             3072,
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
     }
     # Create a small EncoderScaffold for testing.
     test_network = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cfg=hidden_cfg,
         embedding_cfg=embedding_cfg,
         dict_outputs=True)
 
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     outputs = test_network([word_ids, mask, type_ids])
 
     # Create a model based off of this network:
-    model = tf.keras.Model([word_ids, mask, type_ids], outputs)
+    model = tf_keras.Model([word_ids, mask, type_ids], outputs)
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
@@ -282,75 +278,75 @@
     num_types = 7
     embedding_cfg = {
         "vocab_size": vocab_size,
         "type_vocab_size": num_types,
         "hidden_size": hidden_size,
         "seq_length": sequence_length,
         "max_seq_length": sequence_length * 2,
-        "initializer": tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        "initializer": tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "dropout_rate": 0.1,
     }
     hidden_cfg = {
         "num_attention_heads":
             2,
         "intermediate_size":
             3072,
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
     }
     # Create a small EncoderScaffold for testing.
     test_network = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cfg=hidden_cfg,
         embedding_cfg=embedding_cfg)
     outputs = test_network([word_ids, mask, type_ids])
-    model = tf.keras.Model([word_ids, mask, type_ids], outputs)
+    model = tf_keras.Model([word_ids, mask, type_ids], outputs)
     _ = model.predict([word_id_data, mask_data, type_id_data])
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     hidden_size = 32
     sequence_length = 21
     embedding_cfg = {
         "vocab_size": 100,
         "type_vocab_size": 16,
         "hidden_size": hidden_size,
         "seq_length": sequence_length,
         "max_seq_length": sequence_length,
-        "initializer": tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        "initializer": tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "dropout_rate": 0.1,
     }
     hidden_cfg = {
         "num_attention_heads":
             2,
         "intermediate_size":
             3072,
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
     }
     # Create a small EncoderScaffold for testing.
     network = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cfg=hidden_cfg,
         embedding_cfg=embedding_cfg)
 
     # Create another network object from the first object's config.
     new_network = encoder_scaffold.EncoderScaffold.from_config(
         network.get_config())
@@ -358,38 +354,37 @@
     # Validate that the config can be forced to JSON.
     _ = new_network.to_json()
 
     # If the serialization was successful, the new config should match the old.
     self.assertAllEqual(network.get_config(), new_network.get_config())
 
 
-class Embeddings(tf.keras.Model):
+class Embeddings(tf_keras.Model):
 
   def __init__(self, vocab_size, hidden_size):
     super().__init__()
     self.inputs = [
-        tf.keras.layers.Input(
+        tf_keras.layers.Input(
             shape=(None,), dtype=tf.int32, name="input_word_ids"),
-        tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name="input_mask")
+        tf_keras.layers.Input(shape=(None,), dtype=tf.int32, name="input_mask")
     ]
     self.attention_mask = layers.SelfAttentionMask()
     self.embedding_layer = layers.OnDeviceEmbedding(
         vocab_size=vocab_size,
         embedding_width=hidden_size,
-        initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
         name="word_embeddings")
 
   def call(self, inputs):
     word_ids, mask = inputs
     word_embeddings = self.embedding_layer(word_ids)
     return word_embeddings, self.attention_mask([word_embeddings, mask])
 
 
-@keras_parameterized.run_all_keras_modes
-class EncoderScaffoldEmbeddingNetworkTest(keras_parameterized.TestCase):
+class EncoderScaffoldEmbeddingNetworkTest(tf.test.TestCase):
 
   def test_network_invocation(self):
     hidden_size = 32
     sequence_length = 21
     vocab_size = 57
 
     # Build an embedding network to swap in for the default network. This one
@@ -405,33 +400,33 @@
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
     }
 
     # Create a small EncoderScaffold for testing.
     test_network = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cfg=hidden_cfg,
         embedding_cls=network)
 
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     data, pooled = test_network([word_ids, mask])
 
     # Create a model based off of this network:
-    model = tf.keras.Model([word_ids, mask], [data, pooled])
+    model = tf_keras.Model([word_ids, mask], [data, pooled])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
@@ -442,48 +437,48 @@
     sequence_length = 21
     vocab_size = 57
 
     # Build an embedding network to swap in for the default network. This one
     # will have 2 inputs (mask and word_ids) instead of 3, and won't use
     # positional embeddings.
 
-    word_ids = tf.keras.layers.Input(
+    word_ids = tf_keras.layers.Input(
         shape=(sequence_length,), dtype=tf.int32, name="input_word_ids")
-    mask = tf.keras.layers.Input(
+    mask = tf_keras.layers.Input(
         shape=(sequence_length,), dtype=tf.int32, name="input_mask")
     embedding_layer = layers.OnDeviceEmbedding(
         vocab_size=vocab_size,
         embedding_width=hidden_size,
-        initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
         name="word_embeddings")
     word_embeddings = embedding_layer(word_ids)
     attention_mask = layers.SelfAttentionMask()([word_embeddings, mask])
-    network = tf.keras.Model([word_ids, mask],
+    network = tf_keras.Model([word_ids, mask],
                              [word_embeddings, attention_mask])
 
     hidden_cfg = {
         "num_attention_heads":
             2,
         "intermediate_size":
             3072,
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
     }
 
     # Create a small EncoderScaffold for testing.
     test_network = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cfg=hidden_cfg,
         embedding_cls=network,
         embedding_data=embedding_layer.embeddings)
 
     # Create another network object from the first object's config.
     new_network = encoder_scaffold.EncoderScaffold.from_config(
@@ -492,22 +487,22 @@
     # Validate that the config can be forced to JSON.
     _ = new_network.to_json()
 
     # If the serialization was successful, the new config should match the old.
     self.assertAllEqual(test_network.get_config(), new_network.get_config())
 
     # Create a model based off of the old and new networks:
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     data, pooled = new_network([word_ids, mask])
-    new_model = tf.keras.Model([word_ids, mask], [data, pooled])
+    new_model = tf_keras.Model([word_ids, mask], [data, pooled])
 
     data, pooled = test_network([word_ids, mask])
-    model = tf.keras.Model([word_ids, mask], [data, pooled])
+    model = tf_keras.Model([word_ids, mask], [data, pooled])
 
     # Copy the weights between models.
     new_model.set_weights(model.get_weights())
 
     # Invoke the models.
     batch_size = 3
     word_id_data = np.random.randint(
@@ -521,30 +516,30 @@
     self.assertAllEqual(cls, new_cls)
 
     # We should not be able to get a reference to the embedding data.
     with self.assertRaisesRegex(RuntimeError, ".*does not have a reference.*"):
       new_network.get_embedding_table()
 
 
-@keras_parameterized.run_all_keras_modes
-class EncoderScaffoldHiddenInstanceTest(keras_parameterized.TestCase):
+class EncoderScaffoldHiddenInstanceTest(
+    tf.test.TestCase, parameterized.TestCase):
 
   def test_network_invocation(self):
     hidden_size = 32
     sequence_length = 21
     vocab_size = 57
     num_types = 7
 
     embedding_cfg = {
         "vocab_size": vocab_size,
         "type_vocab_size": num_types,
         "hidden_size": hidden_size,
         "seq_length": sequence_length,
         "max_seq_length": sequence_length,
-        "initializer": tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        "initializer": tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "dropout_rate": 0.1,
     }
 
     call_list = []
     hidden_cfg = {
         "num_attention_heads":
             2,
@@ -553,15 +548,15 @@
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "call_list":
             call_list
     }
     mask_call_list = []
     mask_cfg = {
         "call_list": mask_call_list
     }
@@ -570,28 +565,28 @@
 
     xformer = ValidatedTransformerLayer(**hidden_cfg)
     xmask = ValidatedMaskLayer(**mask_cfg)
 
     test_network = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cls=xformer,
         mask_cls=xmask,
         embedding_cfg=embedding_cfg)
 
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     data, pooled = test_network([word_ids, mask, type_ids])
 
     # Create a model based off of this network:
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
@@ -620,15 +615,15 @@
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "call_list":
             call_list
     }
     mask_call_list = []
     mask_cfg = {
         "call_list": mask_call_list
     }
@@ -636,54 +631,54 @@
     # instantiated layer object.
     xformer = ValidatedTransformerLayer(**hidden_cfg)
     xmask = ValidatedMaskLayer(**mask_cfg)
 
     test_network_a = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         hidden_cls=xformer,
         mask_cls=xmask,
         embedding_cls=embedding_network)
     # Create a network b with same embedding and hidden layers as network a.
     test_network_b = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         mask_cls=xmask,
         embedding_cls=test_network_a.embedding_network,
         hidden_cls=test_network_a.hidden_layers)
     # Create a network c with same embedding but fewer hidden layers compared to
     # network a and b.
     hidden_layers = test_network_a.hidden_layers
     hidden_layers.pop()
     test_network_c = encoder_scaffold.EncoderScaffold(
         num_hidden_instances=2,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         mask_cls=xmask,
         embedding_cls=test_network_a.embedding_network,
         hidden_cls=hidden_layers)
 
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     # Create model based off of network a:
     data_a, pooled_a = test_network_a([word_ids, mask])
-    model_a = tf.keras.Model([word_ids, mask], [data_a, pooled_a])
+    model_a = tf_keras.Model([word_ids, mask], [data_a, pooled_a])
     # Create model based off of network b:
     data_b, pooled_b = test_network_b([word_ids, mask])
-    model_b = tf.keras.Model([word_ids, mask], [data_b, pooled_b])
+    model_b = tf_keras.Model([word_ids, mask], [data_b, pooled_b])
     # Create model based off of network b:
     data_c, pooled_c = test_network_c([word_ids, mask])
-    model_c = tf.keras.Model([word_ids, mask], [data_c, pooled_c])
+    model_c = tf_keras.Model([word_ids, mask], [data_c, pooled_c])
 
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
     output_a, _ = model_a.predict([word_id_data, mask_data])
     output_b, _ = model_b.predict([word_id_data, mask_data])
@@ -705,15 +700,15 @@
 
     embedding_cfg = {
         "vocab_size": vocab_size,
         "type_vocab_size": num_types,
         "hidden_size": hidden_size,
         "seq_length": sequence_length,
         "max_seq_length": sequence_length,
-        "initializer": tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        "initializer": tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "dropout_rate": 0.1,
     }
 
     call_list = []
     hidden_cfg = {
         "num_attention_heads":
             2,
@@ -722,28 +717,28 @@
         "intermediate_activation":
             activations.gelu,
         "dropout_rate":
             0.1,
         "attention_dropout_rate":
             0.1,
         "kernel_initializer":
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
         "call_list":
             call_list,
         "call_class":
             TestLayer
     }
     mask_call_list = []
     mask_cfg = {"call_list": mask_call_list, "call_class": TestLayer}
     # Create a small EncoderScaffold for testing. This time, we pass an already-
     # instantiated layer object.
     kwargs = dict(
         num_hidden_instances=3,
         pooled_output_dim=hidden_size,
-        pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+        pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=0.02),
         embedding_cfg=embedding_cfg)
 
     if use_hidden_cls_instance:
       xformer = ValidatedTransformerLayer(**hidden_cfg)
       xmask = ValidatedMaskLayer(**mask_cfg)
       test_network = encoder_scaffold.EncoderScaffold(
@@ -763,23 +758,23 @@
     # Validate that the config can be forced to JSON.
     _ = new_network.to_json()
 
     # If the serialization was successful, the new config should match the old.
     self.assertAllEqual(test_network.get_config(), new_network.get_config())
 
     # Create a model based off of the old and new networks:
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     data, pooled = new_network([word_ids, mask, type_ids])
-    new_model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    new_model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
 
     data, pooled = test_network([word_ids, mask, type_ids])
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
 
     # Copy the weights between models.
     new_model.set_weights(model.get_weights())
 
     # Invoke the models.
     batch_size = 3
     word_id_data = np.random.randint(
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/fnet.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/fnet.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,26 +17,26 @@
 Based on ["FNet: Mixing Tokens with Fourier Transforms"]
 (https://aclanthology.org/2022.naacl-main.319/).
 """
 # pylint: disable=g-classes-have-attributes
 
 from typing import Any, Callable, Optional, Sequence, Union
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 
 _Activation = Union[str, Callable[..., Any]]
-_Initializer = Union[str, tf.keras.initializers.Initializer]
+_Initializer = Union[str, tf_keras.initializers.Initializer]
 
-_approx_gelu = lambda x: tf.keras.activations.gelu(x, approximate=True)
+_approx_gelu = lambda x: tf_keras.activations.gelu(x, approximate=True)
 
 
-class FNet(tf.keras.layers.Layer):
+class FNet(tf_keras.layers.Layer):
   """FNet encoder network.
 
   Based on ["FNet: Mixing Tokens with Fourier Transforms"]
   (https://aclanthology.org/2022.naacl-main.319/). FNet is an efficient
   Transformer-like encoder network that replaces self-attention sublayers with
   Fourier sublayers.
 
@@ -47,15 +47,15 @@
 
   Args:
     vocab_size: The size of the token vocabulary.
     hidden_size: The size of the transformer hidden layers.
     num_layers: The number of transformer layers.
     mixing_mechanism: Type of mixing mechanism used in place of self-attention
       layers. Defaults to FNet ('Fourier') mixing.
-    use_fft: Only used for spectral mixing mechanims. Determines whether to use
+    use_fft: Only used for spectral mixing mechanisms. Determines whether to use
       Fast Fourier Transform (True) or the Discrete Fourier Transform (DFT)
       matrix (False; default) to compute the Fourier Transform. See
       layers.FourierTransformLayer or layers.HartleyTransformLayer for advice.
     attention_layers: Specifies which layers, if any, should be attention layers
       in the encoder. The remaining [0, num_layers) setminus attention_layers
       will use the specified `mixing_mechanism`. If using attention layers, a
       good rule of thumb is to place them in the final few layers.
@@ -102,26 +102,26 @@
       num_attention_heads: int = 12,
       max_sequence_length: int = 512,
       type_vocab_size: int = 16,
       inner_dim: int = 3072,
       inner_activation: _Activation = _approx_gelu,
       output_dropout: float = 0.1,
       attention_dropout: float = 0.1,
-      initializer: _Initializer = tf.keras.initializers.TruncatedNormal(
+      initializer: _Initializer = tf_keras.initializers.TruncatedNormal(
           stddev=0.02),
       output_range: Optional[int] = None,
       embedding_width: Optional[int] = None,
-      embedding_layer: Optional[tf.keras.layers.Layer] = None,
+      embedding_layer: Optional[tf_keras.layers.Layer] = None,
       norm_first: bool = False,
       with_dense_inputs: bool = False,
       **kwargs):
     super().__init__(**kwargs)
 
-    activation = tf.keras.activations.get(inner_activation)
-    initializer = tf.keras.initializers.get(initializer)
+    activation = tf_keras.activations.get(inner_activation)
+    initializer = tf_keras.initializers.get(initializer)
 
     if embedding_width is None:
       embedding_width = hidden_size
 
     self._config = {
         'vocab_size': vocab_size,
         'hidden_size': hidden_size,
@@ -129,18 +129,18 @@
         'mixing_mechanism': mixing_mechanism,
         'use_fft': use_fft,
         'attention_layers': attention_layers,
         'num_attention_heads': num_attention_heads,
         'max_sequence_length': max_sequence_length,
         'type_vocab_size': type_vocab_size,
         'inner_dim': inner_dim,
-        'inner_activation': tf.keras.activations.serialize(activation),
+        'inner_activation': tf_keras.activations.serialize(activation),
         'output_dropout': output_dropout,
         'attention_dropout': attention_dropout,
-        'initializer': tf.keras.initializers.serialize(initializer),
+        'initializer': tf_keras.initializers.serialize(initializer),
         'output_range': output_range,
         'embedding_width': embedding_width,
         'embedding_layer': embedding_layer,
         'norm_first': norm_first,
         'with_dense_inputs': with_dense_inputs,
     }
 
@@ -161,25 +161,25 @@
     self._type_embedding_layer = layers.OnDeviceEmbedding(
         vocab_size=type_vocab_size,
         embedding_width=embedding_width,
         initializer=tf_utils.clone_initializer(initializer),
         use_one_hot=True,
         name='type_embeddings')
 
-    self._embedding_norm_layer = tf.keras.layers.LayerNormalization(
+    self._embedding_norm_layer = tf_keras.layers.LayerNormalization(
         name='embeddings/layer_norm', axis=-1, epsilon=1e-12, dtype=tf.float32)
 
-    self._embedding_dropout = tf.keras.layers.Dropout(
+    self._embedding_dropout = tf_keras.layers.Dropout(
         rate=output_dropout, name='embedding_dropout')
 
     # We project the 'embedding' output to 'hidden_size' if it is not already
     # 'hidden_size'.
     self._embedding_projection = None
     if embedding_width != hidden_size:
-      self._embedding_projection = tf.keras.layers.EinsumDense(
+      self._embedding_projection = tf_keras.layers.EinsumDense(
           '...x,xy->...y',
           output_shape=hidden_size,
           bias_axes='y',
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='embedding_projection')
 
     self._transformer_layers = []
@@ -209,42 +209,40 @@
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='transformer/layer_%d' % layer)
       self._transformer_layers.append(block)
 
     self._attention_mask_layer = layers.SelfAttentionMask(
         name='self_attention_mask')
 
-    self._pooler_layer = tf.keras.layers.Dense(
+    self._pooler_layer = tf_keras.layers.Dense(
         units=hidden_size,
         activation='tanh',
         kernel_initializer=tf_utils.clone_initializer(initializer),
         name='pooler_transform')
 
     if with_dense_inputs:
       self.inputs = dict(
-          input_word_ids=tf.keras.Input(
-              shape=(max_sequence_length,), dtype=tf.int32),
-          input_mask=tf.keras.Input(
-              shape=(max_sequence_length,), dtype=tf.int32),
-          input_type_ids=tf.keras.Input(
-              shape=(max_sequence_length,), dtype=tf.int32),
-          dense_inputs=tf.keras.Input(
-              shape=(max_sequence_length, embedding_width), dtype=tf.float32),
-          dense_mask=tf.keras.Input(
-              shape=(max_sequence_length,), dtype=tf.int32),
-          dense_type_ids=tf.keras.Input(
-              shape=(max_sequence_length,), dtype=tf.int32),
+          # The total length of token ids and dense inputs still has to be
+          # max_sequence_length. It is checked in call().
+          input_word_ids=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          input_mask=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          input_type_ids=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          dense_inputs=tf_keras.Input(
+              shape=(None, embedding_width), dtype=tf.float32),
+          dense_mask=tf_keras.Input(shape=(None,), dtype=tf.int32),
+          dense_type_ids=tf_keras.Input(shape=(None,), dtype=tf.int32),
       )
+
     else:
       self.inputs = dict(
-          input_word_ids=tf.keras.Input(
+          input_word_ids=tf_keras.Input(
               shape=(max_sequence_length,), dtype=tf.int32),
-          input_mask=tf.keras.Input(
+          input_mask=tf_keras.Input(
               shape=(max_sequence_length,), dtype=tf.int32),
-          input_type_ids=tf.keras.Input(
+          input_type_ids=tf_keras.Input(
               shape=(max_sequence_length,), dtype=tf.int32))
     self._max_sequence_length = max_sequence_length
 
   def call(self, inputs):
     word_embeddings = None
     if isinstance(inputs, dict):
       word_ids = inputs.get('input_word_ids')
@@ -264,19 +262,17 @@
 
     if dense_inputs is not None:
       # Concat the dense embeddings at sequence end.
       word_embeddings = tf.concat([word_embeddings, dense_inputs], axis=1)
       type_ids = tf.concat([type_ids, dense_type_ids], axis=1)
       mask = tf.concat([mask, dense_mask], axis=1)
 
-    seq_length = word_embeddings.shape[1]
-    if seq_length != self._max_sequence_length:
-      raise ValueError('FNet: Sequence length must be the same as '
-                       '`max_sequence_length` ({}), but it is {}.'.format(
-                           self._max_sequence_length, seq_length))
+    # FNet: Sequence length must be the same as `max_sequence_length`.
+    word_embeddings = tf.ensure_shape(word_embeddings,
+                                      [None, self._max_sequence_length, None])
 
     # Absolute position embeddings.
     position_embeddings = self._position_embedding_layer(word_embeddings)
     type_embeddings = self._type_embedding_layer(type_ids)
 
     embeddings = word_embeddings + position_embeddings + type_embeddings
     embeddings = self._embedding_norm_layer(embeddings)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/fnet_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/fnet_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,25 +13,25 @@
 # limitations under the License.
 
 """Tests for FNet encoder network."""
 
 from typing import Sequence
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling import layers
 from official.nlp.modeling.networks import fnet
 
 
 class FNetTest(parameterized.TestCase, tf.test.TestCase):
 
   def tearDown(self):
     super(FNetTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   @parameterized.named_parameters(
       ("fnet", layers.MixingMechanism.FOURIER, ()),
       ("fnet_hybrid", layers.MixingMechanism.FOURIER, (1, 2)),
       ("hnet", layers.MixingMechanism.HARTLEY, ()),
       ("hnet_hybrid", layers.MixingMechanism.HARTLEY, (1, 2)),
       ("linear", layers.MixingMechanism.LINEAR, ()),
@@ -49,26 +49,26 @@
         num_attention_heads=2,
         max_sequence_length=sequence_length,
         num_layers=num_layers,
         mixing_mechanism=mixing_mechanism,
         attention_layers=attention_layers)
 
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     dict_outputs = test_network(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     self.assertIsInstance(test_network.transformer_layers, list)
     self.assertLen(test_network.transformer_layers, 3)
-    self.assertIsInstance(test_network.pooler_layer, tf.keras.layers.Dense)
+    self.assertIsInstance(test_network.pooler_layer, tf_keras.layers.Dense)
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
     # The default output dtype is float32.
@@ -82,17 +82,17 @@
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         max_sequence_length=sequence_length,
         num_layers=3)
 
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
     test_network.build(
         dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids))
     embeddings = test_network.get_embedding_layer()(word_ids)
 
     # Calls with the embeddings.
     dict_outputs = test_network(
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/funnel_transformer.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/funnel_transformer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,23 +11,25 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Funnel Transformer network."""
 # pylint: disable=g-classes-have-attributes
 
-from typing import Any, Callable, Optional, Union, Sequence
+import math
+from typing import Any, Callable, Optional, Sequence, Union
+
 from absl import logging
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 
-_Initializer = Union[str, tf.keras.initializers.Initializer]
+_Initializer = Union[str, tf_keras.initializers.Initializer]
 _Activation = Union[str, Callable[..., Any]]
 
 _MAX = 'max'
 _AVG = 'avg'
 _TRUNCATED_AVG = 'truncated_avg'
 
 _transformer_cls2str = {
@@ -36,20 +38,20 @@
 }
 
 _str2transformer_cls = {
     'TransformerEncoderBlock': layers.TransformerEncoderBlock,
     'ReZeroTransformer': layers.ReZeroTransformer
 }
 
-_approx_gelu = lambda x: tf.keras.activations.gelu(x, approximate=True)
+_approx_gelu = lambda x: tf_keras.activations.gelu(x, approximate=True)
 
 
 def _get_policy_dtype():
   try:
-    return tf.keras.mixed_precision.global_policy().compute_dtype or tf.float32
+    return tf_keras.mixed_precision.global_policy().compute_dtype or tf.float32
   except AttributeError:  # tf1 has no attribute 'global_policy'
     return tf.float32
 
 
 def _pool_and_concat(mask, unpool_length: int, strides: Union[Sequence[int],
                                                               int],
                      axes: Union[Sequence[int], int]):
@@ -87,16 +89,47 @@
         slice(unpool_length, None, stride)
     ]
     pool_tensor = mask[pool_tensor_shape]
     mask = tf.concat((unpool_tensor, pool_tensor), axis=axis)
   return mask
 
 
-def _create_truncated_avg_transforms(seq_length: int,
-                                     pool_strides: Sequence[int]):
+def _create_fractional_pool_transform(sl: int, pool_factor: float):
+  """Create pooling transform for fractional pooling factor."""
+
+  assert pool_factor > 1.0, '`pool_factor` should be > 1.0.'
+
+  psl = int(sl / pool_factor)
+  gcd_ = math.gcd(sl, psl)
+  # It is expected chunk_sl and chunk_psl are small integers.
+  # The transform is built by tiling a [chunk_sl, chunk_psl] submatrix
+  # gcd_ times. The submatrix sums to chunk_psl.
+  chunk_sl = sl // gcd_
+  chunk_psl = psl // gcd_
+  num_one_entries = chunk_psl - 1
+  num_frac_entries = chunk_sl - (chunk_psl - 1)
+
+  # The transform is of shape [sl, psl].
+  transform = np.zeros((sl, psl))
+  for i in range(sl // chunk_sl):
+    row_start = chunk_sl * i
+    col_start = chunk_psl * i
+    for idx in range(num_one_entries):
+      transform[row_start + idx][col_start + idx] = 1.0
+    for idx in range(num_frac_entries):
+      transform[row_start + num_one_entries + idx][
+          col_start + num_one_entries
+      ] = (1.0 / num_frac_entries)
+
+  return tf.constant(transform, dtype=_get_policy_dtype())
+
+
+def _create_truncated_avg_transforms(
+    seq_length: int, pool_strides: Sequence[int]
+):
   """Computes pooling transforms.
 
   The pooling_transform is of shape [seq_length,
   seq_length//pool_stride] and
   pooling_transform[i,j] = 1.0/pool_stride if i//pool_stride == j
                            0.0                otherwise.
   It's in essense average pooling but truncate the final window if it
@@ -118,23 +151,28 @@
   """
 
   pooling_transforms = []
   for pool_stride in pool_strides:
     if pool_stride == 1:
       pooling_transforms.append(None)
     else:
-      pooled_seq_length = seq_length // pool_stride
-
-      pfac, sl, psl = pool_stride, seq_length, pooled_seq_length
-      transform = [[1.0 if (i // pfac) == j else 0.0
-                    for j in range(psl)]
-                   for i in range(sl)]
-      transform = tf.constant(transform, dtype=_get_policy_dtype())
-
-      pooling_transforms.append(transform / pool_stride)
+      pooled_seq_length = int(seq_length / pool_stride)
+      if (1.0 * pool_stride).is_integer():
+        pfac, sl, psl = pool_stride, seq_length, pooled_seq_length
+
+        transform = [
+            [1.0 if (i // pfac) == j else 0.0 for j in range(psl)]
+            for i in range(sl)
+        ]
+        transform = (
+            tf.constant(transform, dtype=_get_policy_dtype()) / pool_stride
+        )
+      else:
+        transform = _create_fractional_pool_transform(seq_length, pool_stride)
+      pooling_transforms.append(transform)
       seq_length = pooled_seq_length
 
   return pooling_transforms
 
 
 def _create_truncated_avg_masks(input_mask: tf.Tensor,
                                 pool_strides: Sequence[int],
@@ -160,28 +198,32 @@
   attention_masks = []
   seq_length = tf.shape(input_mask)[-1]
   layer_mask = tf.cast(input_mask, dtype=_get_policy_dtype())
   for pool_stride, transform in zip(pool_strides, transforms):
     if pool_stride == 1:
       attention_masks.append(create_2d_mask(seq_length, layer_mask))
     else:
-      pooled_seq_length = seq_length // pool_stride
+      pooled_seq_length = tf.cast(
+          tf.cast(seq_length, tf.float32) / tf.cast(pool_stride, tf.float32),
+          tf.int32,
+      )
       attention_masks.append(create_2d_mask(pooled_seq_length, layer_mask))
 
       layer_mask = tf.cast(
           tf.einsum('BF,FT->BT', layer_mask, transform) > 0.0,
-          dtype=layer_mask.dtype)
+          dtype=layer_mask.dtype,
+      )
       seq_length = pooled_seq_length
   del seq_length
 
   return attention_masks
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class FunnelTransformerEncoder(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class FunnelTransformerEncoder(tf_keras.layers.Layer):
   """Funnel Transformer-based encoder network.
 
   Funnel Transformer Implementation of https://arxiv.org/abs/2006.03236.
   This implementation utilizes the base framework with Bert
   (https://arxiv.org/abs/1810.04805).
   Its output is compatible with `BertEncoder`.
 
@@ -239,34 +281,38 @@
       max_sequence_length: int = 512,
       type_vocab_size: int = 16,
       inner_dim: int = 3072,
       inner_activation: _Activation = _approx_gelu,
       output_dropout: float = 0.1,
       attention_dropout: float = 0.1,
       pool_type: str = _MAX,
-      pool_stride: int = 2,
+      pool_stride: Union[int, Sequence[Union[int, float]]] = 2,
       unpool_length: int = 0,
-      initializer: _Initializer = tf.keras.initializers.TruncatedNormal(
-          stddev=0.02),
+      initializer: _Initializer = tf_keras.initializers.TruncatedNormal(
+          stddev=0.02
+      ),
       output_range: Optional[int] = None,
       embedding_width: Optional[int] = None,
-      embedding_layer: Optional[tf.keras.layers.Layer] = None,
+      embedding_layer: Optional[tf_keras.layers.Layer] = None,
       norm_first: bool = False,
       transformer_cls: Union[
-          str, tf.keras.layers.Layer] = layers.TransformerEncoderBlock,
+          str, tf_keras.layers.Layer
+      ] = layers.TransformerEncoderBlock,
       share_rezero: bool = False,
-      **kwargs):
+      append_dense_inputs: bool = False,
+      **kwargs
+  ):
     super().__init__(**kwargs)
 
     if output_range is not None:
       logging.warning('`output_range` is available as an argument for `call()`.'
                       'The `output_range` as __init__ argument is deprecated.')
 
-    activation = tf.keras.activations.get(inner_activation)
-    initializer = tf.keras.initializers.get(initializer)
+    activation = tf_keras.activations.get(inner_activation)
+    initializer = tf_keras.initializers.get(initializer)
 
     if embedding_width is None:
       embedding_width = hidden_size
 
     if embedding_layer is None:
       self._embedding_layer = layers.OnDeviceEmbedding(
           vocab_size=vocab_size,
@@ -284,25 +330,25 @@
     self._type_embedding_layer = layers.OnDeviceEmbedding(
         vocab_size=type_vocab_size,
         embedding_width=embedding_width,
         initializer=tf_utils.clone_initializer(initializer),
         use_one_hot=True,
         name='type_embeddings')
 
-    self._embedding_norm_layer = tf.keras.layers.LayerNormalization(
+    self._embedding_norm_layer = tf_keras.layers.LayerNormalization(
         name='embeddings/layer_norm', axis=-1, epsilon=1e-12, dtype=tf.float32)
 
-    self._embedding_dropout = tf.keras.layers.Dropout(
+    self._embedding_dropout = tf_keras.layers.Dropout(
         rate=output_dropout, name='embedding_dropout')
 
     # We project the 'embedding' output to 'hidden_size' if it is not already
     # 'hidden_size'.
     self._embedding_projection = None
     if embedding_width != hidden_size:
-      self._embedding_projection = tf.keras.layers.EinsumDense(
+      self._embedding_projection = tf_keras.layers.EinsumDense(
           '...x,xy->...y',
           output_shape=hidden_size,
           bias_axes='y',
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='embedding_projection')
 
     self._transformer_layers = []
@@ -323,31 +369,41 @@
           attention_dropout=attention_dropout,
           norm_first=norm_first,
           kernel_initializer=tf_utils.clone_initializer(initializer),
           share_rezero=share_rezero,
           name='transformer/layer_%d' % i)
       self._transformer_layers.append(layer)
 
-    self._pooler_layer = tf.keras.layers.Dense(
+    self._pooler_layer = tf_keras.layers.Dense(
         units=hidden_size,
         activation='tanh',
         kernel_initializer=tf_utils.clone_initializer(initializer),
         name='pooler_transform')
     if isinstance(pool_stride, int):
       # TODO(b/197133196): Pooling layer can be shared.
       pool_strides = [pool_stride] * num_layers
     else:
       if len(pool_stride) != num_layers:
         raise ValueError('Lengths of pool_stride and num_layers are not equal.')
       pool_strides = pool_stride
-    # TODO(crickwu): explore tf.keras.layers.serialize method.
+
+    is_fractional_pooling = False in [
+        (1.0 * pool_stride).is_integer() for pool_stride in pool_strides
+    ]
+    if is_fractional_pooling and pool_type in [_MAX, _AVG]:
+      raise ValueError(
+          'Fractional pooling is only supported for'
+          ' `pool_type`=`truncated_average`'
+      )
+
+    # TODO(crickwu): explore tf_keras.layers.serialize method.
     if pool_type == _MAX:
-      pool_cls = tf.keras.layers.MaxPooling1D
+      pool_cls = tf_keras.layers.MaxPooling1D
     elif pool_type == _AVG:
-      pool_cls = tf.keras.layers.AveragePooling1D
+      pool_cls = tf_keras.layers.AveragePooling1D
     elif pool_type == _TRUNCATED_AVG:
       # TODO(b/203665205): unpool_length should be implemented.
       if unpool_length != 0:
         raise ValueError('unpool_length is not supported by truncated_avg now.')
     else:
       raise ValueError('pool_type not supported.')
 
@@ -361,99 +417,101 @@
             name='att_input_pool_layer')
         self._att_input_pool_layers.append(att_input_pool_layer)
 
     self._max_sequence_length = max_sequence_length
     self._pool_strides = pool_strides  # This is a list here.
     self._unpool_length = unpool_length
     self._pool_type = pool_type
+    self._append_dense_inputs = append_dense_inputs
 
     self._config = {
-        'vocab_size':
-            vocab_size,
-        'hidden_size':
-            hidden_size,
-        'num_layers':
-            num_layers,
-        'num_attention_heads':
-            num_attention_heads,
-        'max_sequence_length':
-            max_sequence_length,
-        'type_vocab_size':
-            type_vocab_size,
-        'inner_dim':
-            inner_dim,
-        'inner_activation':
-            tf.keras.activations.serialize(activation),
-        'output_dropout':
-            output_dropout,
-        'attention_dropout':
-            attention_dropout,
-        'initializer':
-            tf.keras.initializers.serialize(initializer),
-        'output_range':
-            output_range,
-        'embedding_width':
-            embedding_width,
-        'embedding_layer':
-            embedding_layer,
-        'norm_first':
-            norm_first,
-        'pool_type':
-            pool_type,
-        'pool_stride':
-            pool_stride,
-        'unpool_length':
-            unpool_length,
-        'transformer_cls':
-            _transformer_cls2str.get(transformer_cls, str(transformer_cls))
+        'vocab_size': vocab_size,
+        'hidden_size': hidden_size,
+        'num_layers': num_layers,
+        'num_attention_heads': num_attention_heads,
+        'max_sequence_length': max_sequence_length,
+        'type_vocab_size': type_vocab_size,
+        'inner_dim': inner_dim,
+        'inner_activation': tf_keras.activations.serialize(activation),
+        'output_dropout': output_dropout,
+        'attention_dropout': attention_dropout,
+        'initializer': tf_keras.initializers.serialize(initializer),
+        'output_range': output_range,
+        'embedding_width': embedding_width,
+        'embedding_layer': embedding_layer,
+        'norm_first': norm_first,
+        'pool_type': pool_type,
+        'pool_stride': pool_stride,
+        'unpool_length': unpool_length,
+        'transformer_cls': _transformer_cls2str.get(
+            transformer_cls, str(transformer_cls)
+        ),
     }
 
     self.inputs = dict(
-        input_word_ids=tf.keras.Input(shape=(None,), dtype=tf.int32),
-        input_mask=tf.keras.Input(shape=(None,), dtype=tf.int32),
-        input_type_ids=tf.keras.Input(shape=(None,), dtype=tf.int32))
+        input_word_ids=tf_keras.Input(shape=(None,), dtype=tf.int32),
+        input_mask=tf_keras.Input(shape=(None,), dtype=tf.int32),
+        input_type_ids=tf_keras.Input(shape=(None,), dtype=tf.int32))
 
   def call(self, inputs, output_range: Optional[tf.Tensor] = None):
     # inputs are [word_ids, mask, type_ids]
+    word_embeddings = None
     if isinstance(inputs, (list, tuple)):
       logging.warning('List inputs to  %s are discouraged.', self.__class__)
       if len(inputs) == 3:
         word_ids, mask, type_ids = inputs
         dense_inputs = None
         dense_mask = None
         dense_type_ids = None
       elif len(inputs) == 6:
-        word_ids, mask, type_ids, dense_inputs, dense_mask, dense_type_ids = inputs
+        word_ids, mask, type_ids, dense_inputs, dense_mask, dense_type_ids = (
+            inputs
+        )
       else:
-        raise ValueError('Unexpected inputs to %s with length at %d.' %
-                         (self.__class__, len(inputs)))
+        raise ValueError(
+            'Unexpected inputs to %s with length at %d.'
+            % (self.__class__, len(inputs))
+        )
     elif isinstance(inputs, dict):
       word_ids = inputs.get('input_word_ids')
       mask = inputs.get('input_mask')
       type_ids = inputs.get('input_type_ids')
+      word_embeddings = inputs.get('input_word_embeddings', None)
 
       dense_inputs = inputs.get('dense_inputs', None)
       dense_mask = inputs.get('dense_mask', None)
       dense_type_ids = inputs.get('dense_type_ids', None)
     else:
       raise ValueError('Unexpected inputs type to %s.' % self.__class__)
 
-    word_embeddings = self._embedding_layer(word_ids)
+    if word_embeddings is None:
+      word_embeddings = self._embedding_layer(word_ids)
 
     if dense_inputs is not None:
-      # Concat the dense embeddings at sequence begin so unpool_len can control
-      # embedding not being pooled.
-      word_embeddings = tf.concat([dense_inputs, word_embeddings], axis=1)
-      type_ids = tf.concat([dense_type_ids, type_ids], axis=1)
-      mask = tf.concat([dense_mask, mask], axis=1)
+      # Allow concatenation of the dense embeddings at sequence end if requested
+      # and `unpool_length`` is set as zero
+      if self._append_dense_inputs:
+        if self._unpool_length != 0:
+          raise ValueError(
+              'unpool_length is not supported by append_dense_inputs now.'
+          )
+        word_embeddings = tf.concat([word_embeddings, dense_inputs], axis=1)
+        type_ids = tf.concat([type_ids, dense_type_ids], axis=1)
+        mask = tf.concat([mask, dense_mask], axis=1)
+      else:
+        # Concat the dense embeddings at sequence begin so unpool_len can
+        # control embedding not being pooled.
+        word_embeddings = tf.concat([dense_inputs, word_embeddings], axis=1)
+        type_ids = tf.concat([dense_type_ids, type_ids], axis=1)
+        mask = tf.concat([dense_mask, mask], axis=1)
     # absolute position embeddings
     position_embeddings = self._position_embedding_layer(word_embeddings)
     type_embeddings = self._type_embedding_layer(type_ids)
 
-    embeddings = tf.keras.layers.add(
+    embeddings = tf_keras.layers.add(
         [word_embeddings, position_embeddings, type_embeddings])
     embeddings = self._embedding_norm_layer(embeddings)
     embeddings = self._embedding_dropout(embeddings)
 
     if self._embedding_projection is not None:
       embeddings = self._embedding_projection(embeddings)
 
@@ -466,29 +524,34 @@
       attention_mask = _pool_and_concat(
           attention_mask,
           unpool_length=self._unpool_length,
           strides=self._pool_strides[0],
           axes=[1])
 
       for i, layer in enumerate(self._transformer_layers):
+        transformer_output_range = None
+        if i == self._num_layers - 1:
+          transformer_output_range = output_range
+
         # Bypass no pooling cases.
         if self._pool_strides[i] == 1:
-          x = layer([x, x, attention_mask])
+          x = layer(
+              [x, x, attention_mask], output_range=transformer_output_range
+          )
         else:
           # Pools layer for compressing the query length.
           pooled_inputs = self._att_input_pool_layers[i](
               x[:, self._unpool_length:, :])
           query_inputs = tf.concat(
               values=(tf.cast(
                   x[:, :self._unpool_length, :],
                   dtype=pooled_inputs.dtype), pooled_inputs),
               axis=1)
           x = layer([query_inputs, x, attention_mask],
-                    output_range=output_range if i == self._num_layers -
-                    1 else None)
+                    output_range=transformer_output_range)
         # Pools the corresponding attention_mask.
         if i < len(self._transformer_layers) - 1:
           attention_mask = _pool_and_concat(
               attention_mask,
               unpool_length=self._unpool_length,
               strides=[self._pool_strides[i + 1], self._pool_strides[i]],
               axes=[1, 2])
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/funnel_transformer_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/funnel_transformer_test.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,34 +12,34 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for transformer-based bert encoder network."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.networks import funnel_transformer
 
 
-class SingleLayerModel(tf.keras.Model):
+class SingleLayerModel(tf_keras.Model):
 
   def __init__(self, layer):
     super().__init__()
     self.layer = layer
 
   def call(self, inputs):
     return self.layer(inputs)
 
 
 class FunnelTransformerEncoderTest(parameterized.TestCase, tf.test.TestCase):
 
   def tearDown(self):
     super(FunnelTransformerEncoderTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   @parameterized.named_parameters(
       ("mix_truncated_avg_rezero", "mixed_float16", tf.float16, "truncated_avg",
        "ReZeroTransformer"), ("float32_truncated_avg_rezero", "float32",
                               tf.float32, "truncated_avg", "ReZeroTransformer"),
       ("mix_truncated_avg", "mixed_float16", tf.float16, "truncated_avg",
        "TransformerEncoderBlock"),
@@ -48,15 +48,15 @@
                                     "max", "TransformerEncoderBlock"),
       ("float32_max", "float32", tf.float32, "max", "TransformerEncoderBlock"),
       ("mix_avg", "mixed_float16", tf.float16, "avg",
        "TransformerEncoderBlock"),
       ("float32_avg", "float32", tf.float32, "avg", "TransformerEncoderBlock"))
   def test_network_creation(self, policy, pooled_dtype, pool_type,
                             transformer_cls):
-    tf.keras.mixed_precision.set_global_policy(policy)
+    tf_keras.mixed_precision.set_global_policy(policy)
 
     hidden_size = 32
     sequence_length = 21
     pool_stride = 2
     num_layers = 3
     # Create a small FunnelTransformerEncoder for testing.
     test_network = funnel_transformer.FunnelTransformerEncoder(
@@ -66,24 +66,24 @@
         num_layers=num_layers,
         pool_stride=pool_stride,
         pool_type=pool_type,
         max_sequence_length=sequence_length,
         unpool_length=0,
         transformer_cls=transformer_cls)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network([word_ids, mask, type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     self.assertIsInstance(test_network.transformer_layers, list)
     self.assertLen(test_network.transformer_layers, num_layers)
-    self.assertIsInstance(test_network.pooler_layer, tf.keras.layers.Dense)
+    self.assertIsInstance(test_network.pooler_layer, tf_keras.layers.Dense)
 
     # Stride=2 compresses sequence length to half the size at each layer.
     # For pool_type = max or avg,
     # this configuration gives each layer of seq length: 21->11->6->3.
     # For pool_type = truncated_avg,
     # seq length: 21->10->5->2.
     if pool_type in ["max", "avg"]:
@@ -97,16 +97,20 @@
 
     # The default output dtype is float32.
     # If float_dtype is set to float16, the data output is float32 (from a layer
     # norm) and pool output should be float16.
     self.assertAllEqual(tf.float32, data.dtype)
     self.assertAllEqual(pooled_dtype, pooled.dtype)
 
-  def test_network_creation_dense(self):
-    tf.keras.mixed_precision.set_global_policy("mixed_float16")
+  @parameterized.named_parameters(
+      ("append_dense_inputs", True),
+      ("dense_inputs_at_sequence_begin", False),
+  )
+  def test_network_creation_dense(self, append_dense_inputs):
+    tf_keras.mixed_precision.set_global_policy("mixed_float16")
     pool_type = "avg"
 
     hidden_size = 32
     sequence_length = 21
     dense_sequence_length = 3
     pool_stride = 2
     num_layers = 3
@@ -116,44 +120,75 @@
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=num_layers,
         pool_stride=pool_stride,
         pool_type=pool_type,
         max_sequence_length=sequence_length + dense_sequence_length,
         unpool_length=0,
-        transformer_cls="TransformerEncoderBlock")
+        transformer_cls="TransformerEncoderBlock",
+        append_dense_inputs=append_dense_inputs)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
 
-    dense_inputs = tf.keras.Input(
+    dense_inputs = tf_keras.Input(
         shape=(dense_sequence_length, hidden_size), dtype=tf.float32)
-    dense_mask = tf.keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
-    dense_type_ids = tf.keras.Input(
+    dense_mask = tf_keras.Input(shape=(dense_sequence_length,), dtype=tf.int32)
+    dense_type_ids = tf_keras.Input(
         shape=(dense_sequence_length,), dtype=tf.int32)
 
     dict_outputs = test_network(
         [word_ids, mask, type_ids, dense_inputs, dense_mask, dense_type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     self.assertIsInstance(test_network.transformer_layers, list)
     self.assertLen(test_network.transformer_layers, num_layers)
-    self.assertIsInstance(test_network.pooler_layer, tf.keras.layers.Dense)
+    self.assertIsInstance(test_network.pooler_layer, tf_keras.layers.Dense)
 
     # Stride=2 compresses sequence length to half the size at each layer.
     # For pool_type = max or avg,
     # this configuration gives each layer of seq length: 24->12->6->3.
     expected_data_shape = [None, 3, hidden_size]
     expected_pooled_shape = [None, hidden_size]
 
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
+  @parameterized.named_parameters(
+      ("frac_pool_rezero", "ReZeroTransformer"),
+      ("frac_pool_vanilla", "TransformerEncoderBlock"),
+      )
+  def test_fractional_pooling(self, transformer_cls):
+    hidden_size = 16
+    sequence_length = 32
+    pool_strides = [1.33333, 3, 2, 1]
+    num_layers = 4
+    pool_type = "truncated_avg"
+    test_network = funnel_transformer.FunnelTransformerEncoder(
+        vocab_size=100,
+        hidden_size=hidden_size,
+        num_attention_heads=2,
+        num_layers=num_layers,
+        pool_stride=pool_strides,
+        pool_type=pool_type,
+        max_sequence_length=sequence_length,
+        unpool_length=0,
+        transformer_cls=transformer_cls)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    dict_outputs = test_network([word_ids, mask, type_ids])
+    data = dict_outputs["sequence_output"]
+
+    expected_data_shape = [None, 4, hidden_size]
+
+    self.assertAllEqual(expected_data_shape, data.shape.as_list())
+
   def test_invalid_stride_and_num_layers(self):
     hidden_size = 32
     num_layers = 3
     pool_stride = [2, 2]
     unpool_length = 1
     with self.assertRaisesRegex(ValueError,
                                 "pool_stride and num_layers are not equal"):
@@ -182,17 +217,17 @@
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=num_layers,
         pool_stride=pool_stride,
         unpool_length=unpool_length)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network([word_ids, mask, type_ids])
     all_encoder_outputs = dict_outputs["encoder_outputs"]
     pooled = dict_outputs["pooled_output"]
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertLen(all_encoder_outputs, num_layers)
@@ -206,46 +241,54 @@
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
     # The default output dtype is float32.
     self.assertAllEqual(tf.float32, all_encoder_outputs[-1].dtype)
     self.assertAllEqual(tf.float32, pooled.dtype)
 
   @parameterized.named_parameters(
-      ("all_sequence", None, 3, 0),
-      ("output_range", 1, 1, 0),
-      ("all_sequence_wit_unpool", None, 4, 1),
-      ("output_range_with_unpool", 1, 1, 1),
-      ("output_range_with_large_unpool", 1, 1, 2),
+      ("all_sequence", None, 3, 0, 2),
+      ("output_range", 1, 1, 0, 2),
+      ("all_sequence_with_unpool", None, 4, 1, 2),
+      ("output_range_with_unpool", 1, 1, 1, 2),
+      ("output_range_with_large_unpool", 1, 1, 2, 2),
+      ("output_range_with_no_pooling", 1, 1, 0, 1),
+      ("output_range_with_unpool_and_no_pooling", 1, 1, 1, 1),
   )
-  def test_network_invocation(self, output_range, out_seq_len, unpool_length):
+  def test_network_invocation(
+      self,
+      output_range,
+      out_seq_len,
+      unpool_length,
+      pool_stride,
+  ):
     hidden_size = 32
     sequence_length = 21
     vocab_size = 57
     num_types = 7
-    pool_stride = 2
+    num_layers = 3
     # Create a small FunnelTransformerEncoder for testing.
     test_network = funnel_transformer.FunnelTransformerEncoder(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         num_attention_heads=2,
-        num_layers=3,
+        num_layers=num_layers,
         type_vocab_size=num_types,
         pool_stride=pool_stride,
         unpool_length=unpool_length)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network([word_ids, mask, type_ids],
                                 output_range=output_range)
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     # Create a model based off of this network:
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
@@ -258,42 +301,82 @@
     # sequence_length
     max_sequence_length = 128
     test_network = funnel_transformer.FunnelTransformerEncoder(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         max_sequence_length=max_sequence_length,
         num_attention_heads=2,
-        num_layers=3,
+        num_layers=num_layers,
         type_vocab_size=num_types,
         pool_stride=pool_stride)
     dict_outputs = test_network([word_ids, mask, type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     outputs = model.predict([word_id_data, mask_data, type_id_data])
-    self.assertEqual(outputs[0].shape[1], 3)
+    expected_sequence_length = float(sequence_length)
+    for _ in range(num_layers):
+      expected_sequence_length = np.ceil(expected_sequence_length / pool_stride)
+    self.assertEqual(outputs[0].shape[1], expected_sequence_length)
 
     # Creates a FunnelTransformerEncoder with embedding_width != hidden_size
     test_network = funnel_transformer.FunnelTransformerEncoder(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         max_sequence_length=max_sequence_length,
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types,
         embedding_width=16,
         pool_stride=pool_stride)
     dict_outputs = test_network([word_ids, mask, type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     outputs = model.predict([word_id_data, mask_data, type_id_data])
     self.assertEqual(outputs[0].shape[-1], hidden_size)
     self.assertTrue(hasattr(test_network, "_embedding_projection"))
 
+  def test_embeddings_as_inputs(self):
+    hidden_size = 32
+    sequence_length = 21
+    # Create a small BertEncoder for testing.
+    test_network = funnel_transformer.FunnelTransformerEncoder(
+        vocab_size=100,
+        hidden_size=hidden_size,
+        num_attention_heads=2,
+        num_layers=3,
+        pool_stride=2,
+    )
+    # Create the inputs (note that the first dimension is implicit).
+    word_ids = tf_keras.Input(shape=(sequence_length), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    test_network.build(
+        dict(input_word_ids=word_ids, input_mask=mask, input_type_ids=type_ids)
+    )
+    embeddings = test_network.get_embedding_layer()(word_ids)
+    # Calls with the embeddings.
+    dict_outputs = test_network(
+        dict(
+            input_word_embeddings=embeddings,
+            input_mask=mask,
+            input_type_ids=type_ids,
+        )
+    )
+    all_encoder_outputs = dict_outputs["encoder_outputs"]
+    pooled = dict_outputs["pooled_output"]
+
+    expected_pooled_shape = [None, hidden_size]
+    self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
+
+    # The default output dtype is float32.
+    self.assertAllEqual(tf.float32, all_encoder_outputs[-1].dtype)
+    self.assertAllEqual(tf.float32, pooled.dtype)
+
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     kwargs = dict(
         vocab_size=100,
         hidden_size=32,
         num_layers=3,
         num_attention_heads=2,
@@ -310,18 +393,18 @@
         norm_first=False,
         pool_type="max",
         pool_stride=2,
         unpool_length=0,
         transformer_cls="TransformerEncoderBlock")
     network = funnel_transformer.FunnelTransformerEncoder(**kwargs)
     expected_config = dict(kwargs)
-    expected_config["inner_activation"] = tf.keras.activations.serialize(
-        tf.keras.activations.get(expected_config["inner_activation"]))
-    expected_config["initializer"] = tf.keras.initializers.serialize(
-        tf.keras.initializers.get(expected_config["initializer"]))
+    expected_config["inner_activation"] = tf_keras.activations.serialize(
+        tf_keras.activations.get(expected_config["inner_activation"]))
+    expected_config["initializer"] = tf_keras.initializers.serialize(
+        tf_keras.initializers.get(expected_config["initializer"]))
     self.assertEqual(network.get_config(), expected_config)
     # Create another network object from the first object's config.
     new_network = funnel_transformer.FunnelTransformerEncoder.from_config(
         network.get_config())
 
     # If the serialization was successful, the new config should match the old.
     self.assertAllEqual(network.get_config(), new_network.get_config())
@@ -338,12 +421,12 @@
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
     type_id_data = np.random.randint(
         num_types, size=(batch_size, sequence_length))
 
     _ = network_wrapper.predict([word_id_data, mask_data, type_id_data])
     network_wrapper.save(model_path)
-    _ = tf.keras.models.load_model(model_path)
+    _ = tf_keras.models.load_model(model_path)
 
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/mobile_bert_encoder.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/mobile_bert_encoder.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,21 +10,21 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """MobileBERT text encoder network."""
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling import layers
 
 
 @gin.configurable
-class MobileBERTEncoder(tf.keras.Model):
+class MobileBERTEncoder(tf_keras.Model):
   """A Keras functional API implementation for MobileBERT encoder."""
 
   def __init__(self,
                word_vocab_size=30522,
                word_embed_size=128,
                type_vocab_size=2,
                max_sequence_length=512,
@@ -80,15 +80,15 @@
         input tensors of this encoder. Defaults to `int32`. If you want
         to use `tf.lite` quantization, which does not support `Cast` op,
         please set this argument to `tf.float32` and feed `input_mask`
         tensor with values in `float32` to avoid `tf.cast` in the computation.
       **kwargs: Other keyworded and arguments.
     """
     self._self_setattr_tracking = False
-    initializer = tf.keras.initializers.TruncatedNormal(
+    initializer = tf_keras.initializers.TruncatedNormal(
         stddev=initializer_range)
 
     # layer instantiation
     self.embedding_layer = layers.MobileBertEmbedding(
         word_vocab_size=word_vocab_size,
         word_embed_size=word_embed_size,
         type_vocab_size=type_vocab_size,
@@ -113,19 +113,19 @@
           num_feedforward_networks=num_feedforward_networks,
           normalization_type=normalization_type,
           initializer=initializer,
           name=f'transformer_layer_{layer_idx}')
       self._transformer_layers.append(transformer)
 
     # input tensor
-    input_ids = tf.keras.layers.Input(
+    input_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_word_ids')
-    input_mask = tf.keras.layers.Input(
+    input_mask = tf_keras.layers.Input(
         shape=(None,), dtype=input_mask_dtype, name='input_mask')
-    type_ids = tf.keras.layers.Input(
+    type_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_type_ids')
     self.inputs = [input_ids, input_mask, type_ids]
 
     # The dtype of `attention_mask` will the same as the dtype of `input_mask`.
     attention_mask = layers.SelfAttentionMask()(input_mask, input_mask)
 
     # build the computation graph
@@ -142,15 +142,15 @@
           return_attention_scores=True)
       all_layer_outputs.append(layer_output)
       all_attention_scores.append(attention_score)
       prev_output = layer_output
     first_token = tf.squeeze(prev_output[:, 0:1, :], axis=1)
 
     if classifier_activation:
-      self._pooler_layer = tf.keras.layers.EinsumDense(
+      self._pooler_layer = tf_keras.layers.EinsumDense(
           'ab,bc->ac',
           output_shape=hidden_size,
           activation=tf.tanh,
           bias_axes='c',
           kernel_initializer=initializer,
           name='pooler')
       first_token = self._pooler_layer(first_token)
@@ -158,18 +158,46 @@
       self._pooler_layer = None
 
     outputs = dict(
         sequence_output=prev_output,
         pooled_output=first_token,
         encoder_outputs=all_layer_outputs,
         attention_scores=all_attention_scores)
+    self._config = dict(
+        word_vocab_size=word_vocab_size,
+        word_embed_size=word_embed_size,
+        type_vocab_size=type_vocab_size,
+        max_sequence_length=max_sequence_length,
+        num_blocks=num_blocks,
+        hidden_size=hidden_size,
+        num_attention_heads=num_attention_heads,
+        intermediate_size=intermediate_size,
+        intermediate_act_fn=intermediate_act_fn,
+        hidden_dropout_prob=hidden_dropout_prob,
+        attention_probs_dropout_prob=attention_probs_dropout_prob,
+        intra_bottleneck_size=intra_bottleneck_size,
+        initializer_range=initializer_range,
+        use_bottleneck_attention=use_bottleneck_attention,
+        key_query_shared_bottleneck=key_query_shared_bottleneck,
+        num_feedforward_networks=num_feedforward_networks,
+        normalization_type=normalization_type,
+        classifier_activation=classifier_activation,
+        input_mask_dtype=input_mask_dtype,
+    )
 
     super().__init__(
         inputs=self.inputs, outputs=outputs, **kwargs)
 
+  def get_config(self):
+    return dict(self._config)
+
+  @classmethod
+  def from_config(cls, config):
+    return cls(**config)
+
   def get_embedding_table(self):
     return self.embedding_layer.word_embedding.embeddings
 
   def get_embedding_layer(self):
     return self.embedding_layer.word_embedding
 
   @property
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/mobile_bert_encoder_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/mobile_bert_encoder_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from absl.testing import parameterized
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.nlp.modeling import models
 from official.nlp.modeling.networks import mobile_bert_encoder
 
 
 def generate_fake_input(batch_size=1, seq_len=5, vocab_size=10000, seed=0):
   """Generate consistent fake integer input sequences."""
   np.random.seed(seed)
@@ -51,17 +51,17 @@
         hidden_size=hidden_size,
         num_blocks=num_blocks,
         intermediate_act_fn=act_fn,
         key_query_shared_bottleneck=kq_shared_bottleneck,
         normalization_type=normalization_type,
         classifier_activation=use_pooler)
 
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     outputs = test_network([word_ids, mask, type_ids])
     layer_output, pooler_output = outputs['sequence_output'], outputs[
         'pooled_output']
 
     self.assertIsInstance(test_network.transformer_layers, list)
     self.assertLen(test_network.transformer_layers, num_blocks)
 
@@ -76,17 +76,17 @@
     sequence_length = 16
     num_blocks = 3
     test_network = mobile_bert_encoder.MobileBERTEncoder(
         word_vocab_size=100,
         hidden_size=hidden_size,
         num_blocks=num_blocks)
 
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     outputs = test_network([word_ids, mask, type_ids])
     all_layer_output = outputs['encoder_outputs']
 
     self.assertIsInstance(all_layer_output, list)
     self.assertLen(all_layer_output, num_blocks + 1)
 
   @parameterized.parameters('int32', 'float32')
@@ -97,19 +97,19 @@
     num_blocks = 3
     test_network = mobile_bert_encoder.MobileBERTEncoder(
         word_vocab_size=vocab_size,
         hidden_size=hidden_size,
         num_blocks=num_blocks,
         input_mask_dtype=input_mask_dtype)
 
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=input_mask_dtype)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=input_mask_dtype)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     outputs = test_network([word_ids, mask, type_ids])
-    model = tf.keras.Model([word_ids, mask, type_ids], outputs)
+    model = tf_keras.Model([word_ids, mask, type_ids], outputs)
 
     input_seq = generate_fake_input(
         batch_size=1, seq_len=sequence_length, vocab_size=vocab_size)
     input_mask = generate_fake_input(
         batch_size=1, seq_len=sequence_length, vocab_size=2)
     token_type = generate_fake_input(
         batch_size=1, seq_len=sequence_length, vocab_size=2)
@@ -126,19 +126,19 @@
     sequence_length = 16
     num_blocks = 3
     test_network = mobile_bert_encoder.MobileBERTEncoder(
         word_vocab_size=vocab_size,
         hidden_size=hidden_size,
         num_blocks=num_blocks)
 
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     outputs = test_network([word_ids, mask, type_ids])
-    model = tf.keras.Model([word_ids, mask, type_ids], outputs)
+    model = tf_keras.Model([word_ids, mask, type_ids], outputs)
 
     input_seq = generate_fake_input(
         batch_size=1, seq_len=sequence_length, vocab_size=vocab_size)
     input_mask = generate_fake_input(
         batch_size=1, seq_len=sequence_length, vocab_size=2)
     token_type = generate_fake_input(
         batch_size=1, seq_len=sequence_length, vocab_size=2)
@@ -152,17 +152,17 @@
     hidden_size = 32
     sequence_length = 16
     mobilebert_encoder = mobile_bert_encoder.MobileBERTEncoder(
         word_vocab_size=100, hidden_size=hidden_size)
     num_classes = 5
     classifier = task(network=mobilebert_encoder, num_classes=num_classes)
 
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     prediction = classifier([word_ids, mask, type_ids])
     if task == models.BertTokenClassifier:
       prediction = prediction['logits']
     self.assertAllEqual(prediction.shape.as_list(), prediction_shape)
 
 
 if __name__ == '__main__':
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/packed_sequence_embedding.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/packed_sequence_embedding.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,22 +11,22 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """An embedding network supporting packed sequences and position ids."""
 # pylint: disable=g-classes-have-attributes
 import collections
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class PackedSequenceEmbedding(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class PackedSequenceEmbedding(tf_keras.Model):
   """An embedding network supporting packed sequences and position ids.
 
   This network implements an embedding layer similar to the one described in
   "BERT: Pre-training of Deep Bidirectional Transformers for Language
   Understanding" (https://arxiv.org/abs/1810.04805). On top of it, it supports
   to (1) pack multiple sequences into one sequence and (2) allow additional
   "position_ids" as input.
@@ -56,38 +56,38 @@
                hidden_size,
                max_seq_length,
                initializer,
                dropout_rate,
                use_position_id=False,
                pack_multiple_sequences=False,
                **kwargs):
-    initializer = tf.keras.initializers.get(initializer)
+    initializer = tf_keras.initializers.get(initializer)
     if embedding_width is None:
       embedding_width = hidden_size
     config_dict = {
         'vocab_size': vocab_size,
         'type_vocab_size': type_vocab_size,
         'embedding_width': embedding_width,
         'hidden_size': hidden_size,
         'max_seq_length': max_seq_length,
-        'initializer': tf.keras.initializers.serialize(initializer),
+        'initializer': tf_keras.initializers.serialize(initializer),
         'dropout_rate': dropout_rate,
         'use_position_id': use_position_id,
         'pack_multiple_sequences': pack_multiple_sequences,
     }
 
-    word_ids = tf.keras.layers.Input(
+    word_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_word_ids')
-    mask = tf.keras.layers.Input(
+    mask = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_mask')
-    type_ids = tf.keras.layers.Input(
+    type_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_type_ids')
     inputs = [word_ids, mask, type_ids]
     if use_position_id:
-      position_ids = tf.keras.layers.Input(
+      position_ids = tf_keras.layers.Input(
           shape=(None,), dtype=tf.int32, name='position_ids')
       inputs.append(position_ids)
     else:
       position_ids = None
 
     if pack_multiple_sequences:
       sub_seq_mask = PackedSequenceMask()(word_ids)
@@ -114,35 +114,35 @@
         layers.OnDeviceEmbedding(
             vocab_size=type_vocab_size,
             embedding_width=embedding_width,
             initializer=tf_utils.clone_initializer(initializer),
             use_one_hot=True,
             name='type_embeddings')(type_ids))
 
-    embeddings = tf.keras.layers.Add()(
+    embeddings = tf_keras.layers.Add()(
         [word_embeddings, position_embeddings, type_embeddings])
-    embeddings = tf.keras.layers.LayerNormalization(
+    embeddings = tf_keras.layers.LayerNormalization(
         name='embeddings/layer_norm', axis=-1, epsilon=1e-12, dtype=tf.float32)(
             embeddings)
-    embeddings = tf.keras.layers.Dropout(
+    embeddings = tf_keras.layers.Dropout(
         rate=dropout_rate, dtype=tf.float32)(
             embeddings)
 
     if embedding_width != hidden_size:
-      embeddings = tf.keras.layers.EinsumDense(
+      embeddings = tf_keras.layers.EinsumDense(
           '...x,xy->...y',
           output_shape=hidden_size,
           bias_axes=None,
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='embedding_projection')(
               embeddings)
 
     attention_mask = layers.SelfAttentionMask()(embeddings, mask)
     if sub_seq_mask is not None:
-      attention_mask = tf.keras.layers.Lambda(
+      attention_mask = tf_keras.layers.Lambda(
           lambda x: x[0] * tf.cast(x[1], x[0].dtype))(
               [attention_mask, sub_seq_mask])
 
     outputs = [embeddings, attention_mask]
     super().__init__(
         inputs=inputs, outputs=outputs, **kwargs)
     # TF does not track immutable attrs which do not contain Trackables,
@@ -159,16 +159,16 @@
     return dict(self._config._asdict())
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
     return cls(**config)
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class PackedSequenceMask(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class PackedSequenceMask(tf_keras.layers.Layer):
   """A layer to create a mask to indicate multiple sub sequences."""
 
   def call(self, input_ids):
     """Implements call() for the layer.
 
     Args:
       input_ids: int32 Tensor of shape [batch_size, seq_length].
@@ -185,16 +185,16 @@
     seq_start_token = input_ids[:, 0:1]
     seq_start_loc = tf.cast(tf.equal(input_ids, seq_start_token), tf.int32)
     # Set different ids for different sub sequences.
     seq_ids = tf.expand_dims(tf.cumsum(seq_start_loc, -1), -1)
     return tf.equal(seq_ids, tf.transpose(seq_ids, [0, 2, 1]))
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class PositionEmbeddingWithSubSeqMask(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class PositionEmbeddingWithSubSeqMask(tf_keras.layers.Layer):
   """Creates a positional embedding with sub-sequence masking.
 
   This layer creates a positional embedding as described in "BERT: Pre-training
   of Deep Bidirectional Transformers for Language Understanding"
   (https://arxiv.org/abs/1810.04805). On top of it, it supports
   `position_ids` and `sub_sequence_mask` tensors.
 
@@ -223,21 +223,21 @@
 
     super().__init__(**kwargs)
     if use_dynamic_slicing and max_sequence_length is None:
       raise ValueError(
           'If `use_dynamic_slicing` is True, `max_sequence_length` must be set.'
       )
     self._max_sequence_length = max_sequence_length
-    self._initializer = tf.keras.initializers.get(initializer)
+    self._initializer = tf_keras.initializers.get(initializer)
     self._use_dynamic_slicing = use_dynamic_slicing
 
   def get_config(self):
     config = {
         'max_sequence_length': self._max_sequence_length,
-        'initializer': tf.keras.initializers.serialize(self._initializer),
+        'initializer': tf_keras.initializers.serialize(self._initializer),
         'use_dynamic_slicing': self._use_dynamic_slicing,
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def build(self, input_shape):
     """Implements build() for the layer."""
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/packed_sequence_embedding_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/packed_sequence_embedding_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,72 +14,72 @@
 
 """Tests for official.nlp.modeling.networks.packed_sequence_embedding."""
 
 # Import libraries
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.networks import packed_sequence_embedding
 
 
 class PackedSequenceEmbeddingTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(PackedSequenceEmbeddingTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   @parameterized.parameters([
       (True, True, True),
       (False, False, True),
       (False, True, False),
       (True, False, False),
   ])
   def test_network_creation(self, use_position_id, pack_multiple_sequences,
                             use_float16):
     """Validate that the Keras object can be created."""
     if use_float16:
-      tf.keras.mixed_precision.set_global_policy('mixed_float16')
+      tf_keras.mixed_precision.set_global_policy('mixed_float16')
     seq_length = 16
     vocab_size = 100
     max_position_embeddings = 32
     type_vocab_size = 2
     embedding_width = 16
     hidden_size = 32
     embedding_cfg = dict(
         vocab_size=vocab_size,
         type_vocab_size=2,
         embedding_width=embedding_width,
         hidden_size=hidden_size,
         max_seq_length=max_position_embeddings,
-        initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
         dropout_rate=0.1,
         use_position_id=use_position_id,
         pack_multiple_sequences=pack_multiple_sequences,
     )
     test_object = packed_sequence_embedding.PackedSequenceEmbedding(
         **embedding_cfg)
 
-    input_word_ids = tf.keras.Input(shape=(seq_length,), dtype=tf.int32)
-    input_mask = tf.keras.Input(shape=(seq_length,), dtype=tf.int32)
-    input_type_ids = tf.keras.Input(shape=(seq_length,), dtype=tf.int32)
+    input_word_ids = tf_keras.Input(shape=(seq_length,), dtype=tf.int32)
+    input_mask = tf_keras.Input(shape=(seq_length,), dtype=tf.int32)
+    input_type_ids = tf_keras.Input(shape=(seq_length,), dtype=tf.int32)
     network_inputs = {
         'input_word_ids': input_word_ids,
         'input_mask': input_mask,
         'input_type_ids': input_type_ids,
     }
     if use_position_id:
-      network_inputs['position_ids'] = tf.keras.Input(
+      network_inputs['position_ids'] = tf_keras.Input(
           shape=(seq_length,), dtype=tf.int32)
 
     embedding, mask = test_object(network_inputs)
 
     # Create a model based off of this network:
-    model = tf.keras.Model(network_inputs, [embedding, mask])
+    model = tf_keras.Model(network_inputs, [embedding, mask])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(vocab_size, size=(batch_size, seq_length))
     mask_data = np.random.randint(2, size=(batch_size, seq_length))
     type_id_data = np.random.randint(
@@ -95,32 +95,32 @@
     embeddings, attention_mask = model.predict(feed_input)
     expected_embeddings_shape = [3, seq_length, hidden_size]
     expected_attention_mask_shape = [3, seq_length, seq_length]
     self.assertAllEqual(expected_embeddings_shape, embeddings.shape)
     self.assertAllEqual(expected_attention_mask_shape, attention_mask.shape)
 
   def test_serialize_deserialize(self):
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     # Create a network object that sets all of its config options.
     embedding_cfg = dict(
         vocab_size=100,
         type_vocab_size=2,
         embedding_width=64,
         hidden_size=64,
         max_seq_length=32,
-        initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
         dropout_rate=0.1,
         use_position_id=True,
         pack_multiple_sequences=False,
     )
     network = packed_sequence_embedding.PackedSequenceEmbedding(**embedding_cfg)
 
     expected_config = dict(embedding_cfg)
-    expected_config['initializer'] = tf.keras.initializers.serialize(
-        tf.keras.initializers.get(expected_config['initializer']))
+    expected_config['initializer'] = tf_keras.initializers.serialize(
+        tf_keras.initializers.get(expected_config['initializer']))
     self.assertEqual(network.get_config(), expected_config)
 
     # Create another network object from the first object's config.
     new_network = packed_sequence_embedding.PackedSequenceEmbedding.from_config(
         network.get_config())
 
     # Validate that the config can be forced to JSON.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/span_labeling.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/span_labeling.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,27 +11,27 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Span labeling network."""
 # pylint: disable=g-classes-have-attributes
 import collections
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
 def _apply_paragraph_mask(logits, paragraph_mask):
   """Applies a position mask to calculated logits."""
   masked_logits = logits * (paragraph_mask) - 1e30 * (1 - paragraph_mask)
   return tf.nn.log_softmax(masked_logits, -1), masked_logits
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class SpanLabeling(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class SpanLabeling(tf_keras.Model):
   """Span labeling network head for BERT modeling.
 
   This network implements a simple single-span labeler based on a dense layer.
   *Note* that the network is constructed by
   [Keras Functional API](https://keras.io/guides/functional_api/).
 
   Args:
@@ -46,28 +46,28 @@
   def __init__(self,
                input_width,
                activation=None,
                initializer='glorot_uniform',
                output='logits',
                **kwargs):
 
-    sequence_data = tf.keras.layers.Input(
+    sequence_data = tf_keras.layers.Input(
         shape=(None, input_width), name='sequence_data', dtype=tf.float32)
 
-    intermediate_logits = tf.keras.layers.Dense(
+    intermediate_logits = tf_keras.layers.Dense(
         2,  # This layer predicts start location and end location.
         activation=activation,
         kernel_initializer=initializer,
         name='predictions/transform/logits')(
             sequence_data)
     start_logits, end_logits = self._split_output_tensor(intermediate_logits)
 
-    start_predictions = tf.keras.layers.Activation(tf.nn.log_softmax)(
+    start_predictions = tf_keras.layers.Activation(tf.nn.log_softmax)(
         start_logits)
-    end_predictions = tf.keras.layers.Activation(tf.nn.log_softmax)(end_logits)
+    end_predictions = tf_keras.layers.Activation(tf.nn.log_softmax)(end_logits)
 
     if output == 'logits':
       output_tensors = [start_logits, end_logits]
     elif output == 'predictions':
       output_tensors = [start_predictions, end_predictions]
     else:
       raise ValueError(
@@ -107,15 +107,15 @@
     return dict(self._config._asdict())
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
     return cls(**config)
 
 
-class XLNetSpanLabeling(tf.keras.layers.Layer):
+class XLNetSpanLabeling(tf_keras.layers.Layer):
   """Span labeling network head for XLNet on SQuAD2.0.
 
   This networks implements a span-labeler based on dense layers and question
   possibility classification. This is the complex version seen in the original
   XLNet implementation.
 
   This applies a dense layer to the input sequence data to predict the start
@@ -152,39 +152,39 @@
         'end_n_top': end_n_top,
         'dropout_rate': dropout_rate,
     }
     if start_n_top <= 1:
       raise ValueError('`start_n_top` must be greater than 1.')
     self._start_n_top = start_n_top
     self._end_n_top = end_n_top
-    self.start_logits_dense = tf.keras.layers.Dense(
+    self.start_logits_dense = tf_keras.layers.Dense(
         units=1,
         kernel_initializer=tf_utils.clone_initializer(initializer),
         name='predictions/transform/start_logits')
 
-    self.end_logits_inner_dense = tf.keras.layers.Dense(
+    self.end_logits_inner_dense = tf_keras.layers.Dense(
         units=input_width,
         kernel_initializer=tf_utils.clone_initializer(initializer),
         activation=activation,
         name='predictions/transform/end_logits/inner')
-    self.end_logits_layer_norm = tf.keras.layers.LayerNormalization(
+    self.end_logits_layer_norm = tf_keras.layers.LayerNormalization(
         axis=-1, epsilon=1e-12,
         name='predictions/transform/end_logits/layernorm')
-    self.end_logits_output_dense = tf.keras.layers.Dense(
+    self.end_logits_output_dense = tf_keras.layers.Dense(
         units=1,
         kernel_initializer=tf_utils.clone_initializer(initializer),
         name='predictions/transform/end_logits/output')
 
-    self.answer_logits_inner = tf.keras.layers.Dense(
+    self.answer_logits_inner = tf_keras.layers.Dense(
         units=input_width,
         kernel_initializer=tf_utils.clone_initializer(initializer),
         activation=activation,
         name='predictions/transform/answer_logits/inner')
-    self.answer_logits_dropout = tf.keras.layers.Dropout(rate=dropout_rate)
-    self.answer_logits_output = tf.keras.layers.Dense(
+    self.answer_logits_dropout = tf_keras.layers.Dropout(rate=dropout_rate)
+    self.answer_logits_output = tf_keras.layers.Dense(
         units=1,
         kernel_initializer=tf_utils.clone_initializer(initializer),
         use_bias=False,
         name='predictions/transform/answer_logits/output')
 
   def end_logits(self, inputs):
     """Computes the end logits.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/span_labeling_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/span_labeling_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,33 +10,29 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for span_labeling network."""
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.networks import span_labeling
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class SpanLabelingTest(keras_parameterized.TestCase):
+class SpanLabelingTest(tf.test.TestCase):
 
   def test_network_creation(self):
     """Validate that the Keras object can be created."""
     sequence_length = 15
     input_width = 512
     test_network = span_labeling.SpanLabeling(
         input_width=input_width, output='predictions')
     # Create a 3-dimensional input (the first dimension is implicit).
-    sequence_data = tf.keras.Input(
+    sequence_data = tf_keras.Input(
         shape=(sequence_length, input_width), dtype=tf.float32)
     start_outputs, end_outputs = test_network(sequence_data)
 
     # Validate that the outputs are of the expected shape.
     expected_output_shape = [None, sequence_length]
     self.assertEqual(expected_output_shape, start_outputs.shape.as_list())
     self.assertEqual(expected_output_shape, end_outputs.shape.as_list())
@@ -44,18 +40,18 @@
   def test_network_invocation(self):
     """Validate that the Keras object can be invoked."""
     sequence_length = 15
     input_width = 512
     test_network = span_labeling.SpanLabeling(input_width=input_width)
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    sequence_data = tf.keras.Input(
+    sequence_data = tf_keras.Input(
         shape=(sequence_length, input_width), dtype=tf.float32)
     outputs = test_network(sequence_data)
-    model = tf.keras.Model(sequence_data, outputs)
+    model = tf_keras.Model(sequence_data, outputs)
 
     # Invoke the network as part of a Model.
     batch_size = 3
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, input_width))
     start_outputs, end_outputs = model.predict(input_data)
 
@@ -67,19 +63,19 @@
   def test_network_invocation_with_internal_logit_output(self):
     """Validate that the logit outputs are correct."""
     sequence_length = 15
     input_width = 512
     test_network = span_labeling.SpanLabeling(
         input_width=input_width, output='predictions')
     # Create a 3-dimensional input (the first dimension is implicit).
-    sequence_data = tf.keras.Input(
+    sequence_data = tf_keras.Input(
         shape=(sequence_length, input_width), dtype=tf.float32)
     output = test_network(sequence_data)
-    model = tf.keras.Model(sequence_data, output)
-    logit_model = tf.keras.Model(
+    model = tf_keras.Model(sequence_data, output)
+    logit_model = tf_keras.Model(
         test_network.inputs,
         [test_network.start_logits, test_network.end_logits])
 
     batch_size = 3
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, input_width))
     start_outputs, end_outputs = model.predict(input_data)
@@ -89,17 +85,17 @@
     expected_output_shape = (batch_size, sequence_length)
     self.assertEqual(expected_output_shape, start_outputs.shape)
     self.assertEqual(expected_output_shape, end_outputs.shape)
     self.assertEqual(expected_output_shape, start_logits.shape)
     self.assertEqual(expected_output_shape, end_logits.shape)
 
     # Ensure that the logits, when softmaxed, create the outputs.
-    input_tensor = tf.keras.Input(expected_output_shape[1:])
-    output_tensor = tf.keras.layers.Activation(tf.nn.log_softmax)(input_tensor)
-    softmax_model = tf.keras.Model(input_tensor, output_tensor)
+    input_tensor = tf_keras.Input(expected_output_shape[1:])
+    output_tensor = tf_keras.layers.Activation(tf.nn.log_softmax)(input_tensor)
+    softmax_model = tf_keras.Model(input_tensor, output_tensor)
 
     start_softmax = softmax_model.predict(start_logits)
     self.assertAllClose(start_outputs, start_softmax)
     end_softmax = softmax_model.predict(end_logits)
     self.assertAllClose(end_outputs, end_softmax)
 
   def test_network_invocation_with_external_logit_output(self):
@@ -109,20 +105,20 @@
     test_network = span_labeling.SpanLabeling(
         input_width=input_width, output='predictions')
     logit_network = span_labeling.SpanLabeling(
         input_width=input_width, output='logits')
     logit_network.set_weights(test_network.get_weights())
 
     # Create a 3-dimensional input (the first dimension is implicit).
-    sequence_data = tf.keras.Input(
+    sequence_data = tf_keras.Input(
         shape=(sequence_length, input_width), dtype=tf.float32)
     output = test_network(sequence_data)
     logit_output = logit_network(sequence_data)
-    model = tf.keras.Model(sequence_data, output)
-    logit_model = tf.keras.Model(sequence_data, logit_output)
+    model = tf_keras.Model(sequence_data, output)
+    logit_model = tf_keras.Model(sequence_data, logit_output)
 
     batch_size = 3
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, input_width))
     start_outputs, end_outputs = model.predict(input_data)
     start_logits, end_logits = logit_model.predict(input_data)
 
@@ -130,17 +126,17 @@
     expected_output_shape = (batch_size, sequence_length)
     self.assertEqual(expected_output_shape, start_outputs.shape)
     self.assertEqual(expected_output_shape, end_outputs.shape)
     self.assertEqual(expected_output_shape, start_logits.shape)
     self.assertEqual(expected_output_shape, end_logits.shape)
 
     # Ensure that the logits, when softmaxed, create the outputs.
-    input_tensor = tf.keras.Input(expected_output_shape[1:])
-    output_tensor = tf.keras.layers.Activation(tf.nn.log_softmax)(input_tensor)
-    softmax_model = tf.keras.Model(input_tensor, output_tensor)
+    input_tensor = tf_keras.Input(expected_output_shape[1:])
+    output_tensor = tf_keras.layers.Activation(tf.nn.log_softmax)(input_tensor)
+    softmax_model = tf_keras.Model(input_tensor, output_tensor)
 
     start_softmax = softmax_model.predict(start_logits)
     self.assertAllClose(start_outputs, start_softmax)
     end_softmax = softmax_model.predict(end_logits)
     self.assertAllClose(end_outputs, end_softmax)
 
   def test_serialize_deserialize(self):
@@ -161,16 +157,15 @@
     self.assertAllEqual(network.get_config(), new_network.get_config())
 
   def test_unknown_output_type_fails(self):
     with self.assertRaisesRegex(ValueError, 'Unknown `output` value "bad".*'):
       _ = span_labeling.SpanLabeling(input_width=10, output='bad')
 
 
-@keras_parameterized.run_all_keras_modes
-class XLNetSpanLabelingTest(keras_parameterized.TestCase):
+class XLNetSpanLabelingTest(tf.test.TestCase):
 
   def test_basic_invocation_train(self):
     batch_size = 2
     seq_length = 8
     hidden_size = 4
     sequence_data = np.random.uniform(
         size=(batch_size, seq_length, hidden_size)).astype('float32')
@@ -229,33 +224,33 @@
 
   def test_subclass_invocation(self):
     """Tests basic invocation of this layer wrapped in a subclass."""
     seq_length = 8
     hidden_size = 4
     batch_size = 2
 
-    sequence_data = tf.keras.Input(shape=(seq_length, hidden_size),
+    sequence_data = tf_keras.Input(shape=(seq_length, hidden_size),
                                    dtype=tf.float32)
-    class_index = tf.keras.Input(shape=(), dtype=tf.uint8)
-    paragraph_mask = tf.keras.Input(shape=(seq_length), dtype=tf.float32)
-    start_positions = tf.keras.Input(shape=(), dtype=tf.int32)
+    class_index = tf_keras.Input(shape=(), dtype=tf.uint8)
+    paragraph_mask = tf_keras.Input(shape=(seq_length), dtype=tf.float32)
+    start_positions = tf_keras.Input(shape=(), dtype=tf.int32)
 
     layer = span_labeling.XLNetSpanLabeling(
         input_width=hidden_size,
         start_n_top=5,
         end_n_top=5,
         activation='tanh',
         dropout_rate=0.,
         initializer='glorot_uniform')
 
     output = layer(sequence_data=sequence_data,
                    class_index=class_index,
                    paragraph_mask=paragraph_mask,
                    start_positions=start_positions)
-    model = tf.keras.Model(
+    model = tf_keras.Model(
         inputs={
             'sequence_data': sequence_data,
             'class_index': class_index,
             'paragraph_mask': paragraph_mask,
             'start_positions': start_positions,
         },
         outputs=output)
@@ -278,16 +273,16 @@
 
     # Test `call` without training flag.
     output = model(inputs, training=False)
     self.assertIsInstance(output, dict)
 
     # Test `call` with training flag.
     # Note: this fails due to incompatibility with the functional API.
-    with self.assertRaisesRegexp(AssertionError,
-                                 'Could not compute output KerasTensor'):
+    with self.assertRaisesRegex(AssertionError,
+                                'Could not compute output KerasTensor'):
       model(inputs, training=True)
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     network = span_labeling.XLNetSpanLabeling(
         input_width=128,
         start_n_top=5,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/xlnet_base.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/xlnet_base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras-based XLNet Model."""
 
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 from official.nlp.modeling.layers import transformer_xl
 
 _SEG_ID_CLS = 2
 
@@ -362,15 +362,15 @@
           clamp_length)
 
     relative_position_encoding = position_encoding_layer(
         forward_position_sequence, batch_size)
   return relative_position_encoding
 
 
-class RelativePositionEncoding(tf.keras.layers.Layer):
+class RelativePositionEncoding(tf_keras.layers.Layer):
   """Creates a relative positional encoding.
 
   This layer creates a relative positional encoding as described in
   "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
   (https://arxiv.org/abs/1901.02860).
 
   Rather than an absolute position embedding as in Transformer, this
@@ -408,16 +408,16 @@
     relative_position_encoding = relative_position_encoding[None, :, :]
     if batch_size is not None:
       relative_position_encoding = tf.tile(relative_position_encoding,
                                            [batch_size, 1, 1])
     return relative_position_encoding
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class XLNetBase(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class XLNetBase(tf_keras.layers.Layer):
   """Base XLNet model.
 
   Attributes:
     vocab_size: int, the number of tokens in vocabulary.
     num_layers: int, the number of layers.
     hidden_size: int, the hidden size.
     num_attention_heads: int, the number of attention heads.
@@ -507,17 +507,17 @@
 
     self._embedding_layer = layers.OnDeviceEmbedding(
         vocab_size=self._vocab_size,
         embedding_width=embedding_width,
         initializer=tf_utils.clone_initializer(self._initializer),
         dtype=tf.float32,
         name="word_embedding")
-    self._dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self._dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
 
-    self.embedding_dropout = tf.keras.layers.Dropout(rate=self._dropout_rate)
+    self.embedding_dropout = tf_keras.layers.Dropout(rate=self._dropout_rate)
     self.position_encoding = RelativePositionEncoding(self._hidden_size)
 
     self._transformer_xl = transformer_xl.TransformerXL(
         vocab_size=vocab_size,
         num_layers=num_layers,
         hidden_size=hidden_size,
         num_attention_heads=num_attention_heads,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/networks/xlnet_base_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/networks/xlnet_base_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras based XLNet model."""
+
+from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling.networks import xlnet_base
 
 
-@keras_parameterized.run_all_keras_modes
-class RelativePositionEncodingTest(keras_parameterized.TestCase):
+class RelativePositionEncodingTest(tf.test.TestCase):
 
   def test_positional_embedding(self):
     """A low-dimensional example is tested.
 
      With len(pos_seq)=2 and d_model=4:
 
        pos_seq  = [[1.], [0.]]
@@ -43,15 +43,15 @@
     pos_seq = tf.range(1, -1, -1.0)  # [1., 0.]
     encoding_layer = xlnet_base.RelativePositionEncoding(
         hidden_size=hidden_size)
     encoding = encoding_layer(pos_seq, batch_size=None).numpy().astype(float)
     self.assertAllClose(encoding, target)
 
 
-class ComputePositionEncodingTest(keras_parameterized.TestCase):
+class ComputePositionEncodingTest(tf.test.TestCase, parameterized.TestCase):
 
   @combinations.generate(combinations.combine(
       attention_type=["uni", "bi"],
       bi_data=[False, True],
       ))
   def test_compute_position_encoding_smoke(self, attention_type, bi_data):
     hidden_size = 4
@@ -107,15 +107,15 @@
 
     expected_output = np.array([[1, 1, 1, 0, 0],
                                 [0, 1, 1, 1, 0],
                                 [0, 0, 1, 1, 1]])
     self.assertAllClose(causal_attention_mask, expected_output)
 
 
-class MaskComputationTests(keras_parameterized.TestCase):
+class MaskComputationTests(tf.test.TestCase, parameterized.TestCase):
 
   @combinations.generate(combinations.combine(
       use_input_mask=[False, True],
       use_permutation_mask=[False, True],
       attention_type=["uni", "bi"],
       memory_length=[0, 4],
       ))
@@ -407,15 +407,15 @@
         num_attention_heads=2,
         head_size=2,
         inner_size=2,
         dropout_rate=0.,
         attention_dropout_rate=0.,
         attention_type="bi",
         bi_data=True,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         two_stream=False,
         tie_attention_biases=True,
         reuse_length=0,
         inner_activation="relu")
     input_data = self._generate_data(batch_size=batch_size,
                                      seq_length=seq_length,
                                      num_predictions=num_predictions)
@@ -431,15 +431,15 @@
         num_attention_heads=12,
         head_size=12,
         inner_size=12,
         dropout_rate=0.,
         attention_dropout_rate=0.,
         attention_type="bi",
         bi_data=True,
-        initializer=tf.keras.initializers.RandomNormal(stddev=0.1),
+        initializer=tf_keras.initializers.RandomNormal(stddev=0.1),
         two_stream=False,
         tie_attention_biases=True,
         memory_length=0,
         reuse_length=0,
         inner_activation="relu")
     config = xlnet_model.get_config()
     new_xlnet = xlnet_base.XLNetBase.from_config(config)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/ops/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/ops/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/ops/beam_search.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/ops/beam_search.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Beam search to find the translated sequence with the highest probability."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def inf(dtype):
   """Returns a value close to infinity, but is still finite in `dtype`.
 
   This is useful to get a very large value that is still zero when multiplied by
   zero. The floating-point "Inf" value is NaN when multiplied by zero.
@@ -95,24 +95,27 @@
       tensor = tf.expand_dims(tensor, -1)
     return tensor
 
 
 class SequenceBeamSearch(tf.Module):
   """Implementation of beam search loop."""
 
-  def __init__(self,
-               symbols_to_logits_fn,
-               vocab_size,
-               beam_size,
-               alpha,
-               max_decode_length,
-               eos_id,
-               padded_decode,
-               dtype=tf.float32,
-               decoding_name=None):
+  def __init__(
+      self,
+      symbols_to_logits_fn,
+      vocab_size,
+      beam_size,
+      alpha,
+      max_decode_length,
+      eos_id,
+      padded_decode,
+      dtype=tf.float32,
+      noise_multiplier: float = 0.0,
+      decoding_name=None,
+  ):
     """Initialize sequence beam search.
 
     Args:
       symbols_to_logits_fn: A function to provide logits, which is the interface
         to the Transformer model. The passed in arguments are: ids -> A tensor
         with shape [batch_size * beam_size, index]. index -> A scalar. cache ->
         A nested dictionary of tensors [batch_size * beam_size, ...]. The
@@ -121,30 +124,35 @@
         nested dictionary with the same structure as the input cache.
       vocab_size: An integer, the size of the vocabulary, used for topk
         computation.
       beam_size: An integer, number of beams for beam search.
       alpha: A float, defining the strength of length normalization.
       max_decode_length: An integer, the maximum number of steps to decode a
         sequence.
-      eos_id: An integer. ID of end of sentence token.
+      eos_id: An integer or a list. ID of end of sentence token.
       padded_decode: A bool, indicating if max_sequence_length padding is used
         for beam search.
       dtype: A tensorflow data type used for score computation. The default is
         tf.float32.
+      noise_multiplier: The amount of noise.
       decoding_name: an optional name for the decoding loop tensors.
     """
     self.symbols_to_logits_fn = symbols_to_logits_fn
     self.vocab_size = vocab_size
     self.beam_size = beam_size
     self.alpha = alpha
     self.max_decode_length = max_decode_length
-    self.eos_id = eos_id
+    if isinstance(eos_id, list):
+      self.eos_id = eos_id
+    else:
+      self.eos_id = [eos_id]
     self.padded_decode = padded_decode
     self.dtype = tf.as_dtype(dtype)
     self.decoding_name = decoding_name
+    self.noise_multiplier = noise_multiplier
 
   def search(self, initial_ids, initial_cache):
     """Beam search for sequences with highest scores.
 
     Args:
       initial_ids: initial ids to pass into the symbols_to_logits_fn. int tensor
         with shape [batch_size, 1]
@@ -192,14 +200,21 @@
       else:
         flat_ids = flatten_beam_dim(alive_seq)  # [batch_size * beam_size]
       flat_cache = tf.nest.map_structure(flatten_beam_dim, alive_cache)
 
       flat_logits, flat_cache = self.symbols_to_logits_fn(
           flat_ids, i, flat_cache)
 
+      if self.noise_multiplier > 0:
+        noise = tf.random.uniform(flat_logits.shape, dtype=flat_logits.dtype)
+        # Generates standard Gumbel(0, 1) noise, GSE Tensors
+        noise = -tf.math.log(-tf.math.log(noise))
+        # NOMUTANTS -- may not impact final result.
+        flat_logits = flat_logits + noise * self.noise_multiplier
+
       # Unflatten logits to shape [batch_size, beam_size, vocab_size]
       logits = _unflatten_beam_dim(flat_logits, batch_size, self.beam_size)
       new_cache = tf.nest.map_structure(
           lambda t: _unflatten_beam_dim(t, batch_size, self.beam_size),
           flat_cache)
 
       # Convert logits to normalized log probs
@@ -345,15 +360,20 @@
         state: A dictionary with the current loop state.
 
       Returns:
         new state dictionary.
       """
       # Grow alive sequences by one token.
       new_seq, new_log_probs, topk_ids, new_cache = _grow_alive_seq(state)
-      new_finished_flags = tf.equal(topk_ids, self.eos_id)
+      new_finished_flags = tf.equal(topk_ids, self.eos_id[0])
+      for eos_id in self.eos_id[1:]:
+        one_finished_flags = tf.equal(topk_ids, eos_id)
+        new_finished_flags = tf.logical_or(
+            new_finished_flags, one_finished_flags
+        )
       # Collect top beam_size alive sequences
       alive_state = _get_new_alive_state(new_seq, new_log_probs,
                                          new_finished_flags, new_cache)
 
       # Combine newly finished sequences with existing finished sequences, and
       # collect the top k scoring sequences.
       finished_state = _get_new_finished_state(state, new_seq, new_log_probs,
@@ -563,72 +583,85 @@
       batch_size: int size of batch
       new_beam_size: int number of beams to be pulled from the nested tensors.
 
     Returns:
       Nested structure containing tensors with shape
         [batch_size, new_beam_size, ...]
     """
-    # Computes the i'th coodinate that contains the batch index for gather_nd.
+    # Computes the i'th coordinate that contains the batch index for gather_nd.
     # Batch pos is a tensor like [[0,0,0,0,],[1,1,1,1],..].
     batch_pos = tf.range(batch_size * new_beam_size) // new_beam_size
     batch_pos = tf.reshape(batch_pos, [batch_size, new_beam_size])
 
     # Create coordinates to be passed to tf.gather_nd. Stacking creates a tensor
     # with shape [batch_size, beam_size, 2], where the last dimension contains
     # the (i, j) gathering coordinates.
     coordinates = tf.stack([batch_pos, beam_indices], axis=2)
 
     return tf.nest.map_structure(lambda state: tf.gather_nd(state, coordinates),
                                  nested)
 
 
-def sequence_beam_search(symbols_to_logits_fn,
-                         initial_ids,
-                         initial_cache,
-                         vocab_size,
-                         beam_size,
-                         alpha,
-                         max_decode_length,
-                         eos_id,
-                         padded_decode=False,
-                         dtype="float32",
-                         decoding_name=None):
+def sequence_beam_search(
+    symbols_to_logits_fn,
+    initial_ids,
+    initial_cache,
+    vocab_size,
+    beam_size,
+    alpha,
+    max_decode_length,
+    eos_id,
+    padded_decode=False,
+    dtype="float32",
+    noise_multiplier: float = 0.0,
+    decoding_name=None,
+):
   """Search for sequence of subtoken ids with the largest probability.
 
   Args:
     symbols_to_logits_fn: A function that takes in ids, index, and cache as
       arguments. The passed in arguments will have shape: ids -> A tensor with
-        shape [batch_size * beam_size, index]. index -> A scalar. cache -> A
-        nested dictionary of tensors [batch_size * beam_size, ...].
-      The function must return a tuple of logits and new cache: logits -> A
-        tensor with shape [batch * beam_size, vocab_size]. new cache -> A nested
-        dictionary with the same shape/structure as the inputted cache.
+      shape [batch_size * beam_size, index]. index -> A scalar. cache -> A
+      nested dictionary of tensors [batch_size * beam_size, ...]. The function
+      must return a tuple of logits and new cache: logits -> A tensor with shape
+      [batch * beam_size, vocab_size]. new cache -> A nested dictionary with the
+      same shape/structure as the inputted cache.
     initial_ids: An int32 tensor with shape [batch_size]. Starting ids for each
       batch item.
     initial_cache: A dictionary, containing starting decoder variables
       information.
     vocab_size: An integer, the size of tokens.
     beam_size: An integer, the number of beams.
     alpha: A float, defining the strength of length normalization.
     max_decode_length: An integer, the maximum length to decoded a sequence.
     eos_id: An integer, ID of eos token, used to determine when a sequence has
       finished.
     padded_decode: A bool, indicating if max_sequence_length padding is used for
       beam search.
     dtype: A tensorflow data type used for score computation. The default is
       tf.float32.
+    noise_multiplier: The amount of noise.
     decoding_name: an optional name for the decoding loop tensors.
 
   Returns:
     Top decoded sequences [batch_size, beam_size, max_decode_length]
     sequence scores [batch_size, beam_size]
   """
-  sbs = SequenceBeamSearch(symbols_to_logits_fn, vocab_size, beam_size, alpha,
-                           max_decode_length, eos_id, padded_decode, dtype,
-                           decoding_name)
+  sbs = SequenceBeamSearch(
+      symbols_to_logits_fn,
+      vocab_size,
+      beam_size,
+      alpha,
+      max_decode_length,
+      eos_id,
+      padded_decode,
+      dtype,
+      noise_multiplier,
+      decoding_name,
+  )
   return sbs.search(initial_ids, initial_cache)
 
 
 def _log_prob_from_logits(logits):
   return logits - tf.reduce_logsumexp(logits, axis=2, keepdims=True)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/ops/decoding_module.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/ops/decoding_module.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Base class for Decoding Strategies (beam_search, top_k, top_p and greedy)."""
 
 import abc
 from typing import Any, Callable, Dict, Optional, Tuple
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.framework import dtypes
 from official.modeling import tf_utils
 
 Output = Tuple[tf.Tensor, tf.Tensor, Optional[tf.Tensor]]
 InternalState = Tuple[tf.Tensor, tf.Tensor, tf.Tensor, Dict]
 InitialState = Tuple[Dict[str, Any], Dict[str, Any]]
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/ops/decoding_module_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/ops/decoding_module_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Test decoding utility methods."""
 
 import abc
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.ops import decoding_module
 
 
 def length_normalization(length, dtype):
   """Return length normalization factor."""
   return tf.pow(((5. + tf.cast(length, dtype)) / 6.), 0.0)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/ops/sampling_module.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/ops/sampling_module.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Sampling module for top_k, top_p and greedy decoding."""
 
 import abc
 from typing import Any, Callable, Dict, Optional
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.ops import decoding_module
 
 
 def greedy(log_probs):
   """Returns the top ids and scores based on greedy decoding."""
   log_probs, ids = tf.math.top_k(log_probs, k=1)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/ops/segment_extractor.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/ops/segment_extractor.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,28 +10,28 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Module for extracting segments from sentences in documents."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 # Get a random tensor like `positions` and make some decisions
 def _get_random(positions, random_fn):
   flat_random = random_fn(
       shape=tf.shape(positions.flat_values),
       minval=0,
       maxval=1,
       dtype=tf.float32)
   return positions.with_flat_values(flat_random)
 
 
-# For every position j in a row, sample a position preceeding j or
+# For every position j in a row, sample a position preceding j or
 # a position which is [0, j-1]
 def _random_int_up_to(maxval, random_fn):
   # Need to cast because the int kernel for uniform doesn't support bcast.
   # We add one because maxval is exclusive, and this will get rounded down
   # when we cast back to int.
   float_maxval = tf.cast(maxval, tf.float32)
   return tf.cast(
@@ -83,30 +83,30 @@
   Representations" (https://arxiv.org/pdf/1909.11942.pdf)
 
   Args:
     sentences: a `RaggedTensor` of shape [batch, (num_sentences)] with string
       dtype.
     random_threshold: (optional) A float threshold between 0 and 1, used to
       determine whether to extract a random, out-of-batch sentence or a
-      suceeding sentence. Higher value favors succeeding sentence.
+      succeeding sentence. Higher value favors succeeding sentence.
     random_next_threshold: (optional) A float threshold between 0 and 1, used to
       determine whether to extract either a random, out-of-batch, or succeeding
-      sentence or a preceeding sentence. Higher value favors preceeding
+      sentence or a preceding sentence. Higher value favors preceding
       sentences.
     random_fn: (optional) An op used to generate random float values.
 
   Returns:
-    a tuple of (preceeding_or_random_next, is_suceeding_or_random) where:
-      preceeding_or_random_next: a `RaggedTensor` of strings with the same shape
-        as `sentences` and contains either a preceeding, suceeding, or random
+    a tuple of (preceding_or_random_next, is_succeeding_or_random) where:
+      preceding_or_random_next: a `RaggedTensor` of strings with the same shape
+        as `sentences` and contains either a preceding, succeeding, or random
         out-of-batch sentence respective to its counterpart in `sentences` and
-        dependent on its label in `is_preceeding_or_random_next`.
-      is_suceeding_or_random: a `RaggedTensor` of bool values with the
+        dependent on its label in `is_preceding_or_random_next`.
+      is_succeeding_or_random: a `RaggedTensor` of bool values with the
         same shape as `sentences` and is True if it's corresponding sentence in
-        `preceeding_or_random_next` is a random or suceeding sentence, False
+        `preceding_or_random_next` is a random or succeeding sentence, False
         otherwise.
   """
   # Create a RaggedTensor in the same shape as sentences ([doc, (sentences)])
   # whose values are index positions.
   positions = tf.ragged.range(sentences.row_lengths())
 
   row_lengths_broadcasted = tf.expand_dims(positions.row_lengths(),
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/modeling/ops/segment_extractor_test.py` & `tf-models-no-deps-2.16.0/official/nlp/modeling/ops/segment_extractor_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 # encoding=utf-8
 """Tests for sentence prediction labels."""
 import functools
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.modeling.ops import segment_extractor
 
 
 class NextSentencePredictionTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters([
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/optimization.py` & `tf-models-no-deps-2.16.0/official/nlp/optimization.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,22 +12,24 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Legacy functions and classes related to optimization."""
 
 from absl import logging
 import gin
-import tensorflow as tf
-import tensorflow_addons.optimizers as tfa_optimizers
+import tensorflow as tf, tf_keras
+
+from official.modeling.optimization import lamb
 from official.modeling.optimization import legacy_adamw
 
 AdamWeightDecay = legacy_adamw.AdamWeightDecay
+LAMB = lamb.LAMB
 
 
-class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):
+class WarmUp(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Applies a warmup schedule on a given learning rate decay schedule."""
 
   def __init__(self,
                initial_learning_rate,
                decay_schedule_fn,
                warmup_steps,
                power=1.0,
@@ -71,15 +73,15 @@
                      num_warmup_steps,
                      end_lr=0.0,
                      optimizer_type='adamw',
                      beta_1=0.9,
                      poly_power=1.0):
   """Creates an optimizer with learning rate schedule."""
   # Implements linear decay of the learning rate.
-  lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(
+  lr_schedule = tf_keras.optimizers.schedules.PolynomialDecay(
       initial_learning_rate=init_lr,
       decay_steps=num_train_steps,
       end_learning_rate=end_lr,
       power=poly_power)
   if num_warmup_steps:
     lr_schedule = WarmUp(
         initial_learning_rate=init_lr,
@@ -93,18 +95,19 @@
         weight_decay_rate=0.01,
         beta_1=beta_1,
         beta_2=0.999,
         epsilon=1e-6,
         exclude_from_weight_decay=['LayerNorm', 'layer_norm', 'bias'])
   elif optimizer_type == 'lamb':
     logging.info('using Lamb optimizer')
-    optimizer = tfa_optimizers.LAMB(
+    optimizer = LAMB(
         learning_rate=lr_schedule,
         weight_decay_rate=0.01,
         beta_1=beta_1,
         beta_2=0.999,
         epsilon=1e-6,
-        exclude_from_weight_decay=['LayerNorm', 'layer_norm', 'bias'])
+        exclude_from_weight_decay=['LayerNorm', 'layer_norm', 'bias'],
+    )
   else:
     raise ValueError('Unsupported optimizer type: ', optimizer_type)
 
   return optimizer
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/serving/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/serving/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/serving/export_savedmodel.py` & `tf-models-no-deps-2.16.0/official/nlp/serving/export_savedmodel.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -102,15 +102,15 @@
     raise ValueError("Failed to identify the task class. The provided task "
                      f"name is {task_name}")
   # pylint: enable=protected-access
   # TODO(hongkuny): Figure out how to separate the task config from experiments.
 
   @dataclasses.dataclass
   class Dummy(base_config.Config):
-    task: task_config_cls = task_config_cls()
+    task: task_config_cls = dataclasses.field(default_factory=task_config_cls)
 
   dummy_exp = Dummy()
   dummy_exp = hyperparams.override_params_dict(
       dummy_exp, config_file, is_strict=False)
   dummy_exp.task.validation_data = None
   task = task_cls(dummy_exp.task)
   model = task.build_model()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/serving/export_savedmodel_test.py` & `tf-models-no-deps-2.16.0/official/nlp/serving/export_savedmodel_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for nlp.serving.export_saved_model."""
 
 from absl.testing import parameterized
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
 from official.nlp.serving import export_savedmodel
 from official.nlp.serving import export_savedmodel_util
 from official.nlp.tasks import masked_lm
 from official.nlp.tasks import sentence_prediction
 from official.nlp.tasks import tagging
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/serving/export_savedmodel_util.py` & `tf-models-no-deps-2.16.0/official/nlp/serving/export_savedmodel_util.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,59 +1,64 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Common library to export a SavedModel from the export module."""
-from typing import Dict, List, Optional, Text, Union
+from typing import Dict, List, Optional, Union, Any
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import export_base
 
 get_timestamped_export_dir = export_base.get_timestamped_export_dir
 
 
 def export(export_module: export_base.ExportModule,
-           function_keys: Union[List[Text], Dict[Text, Text]],
-           export_savedmodel_dir: Text,
-           checkpoint_path: Optional[Text] = None,
+           function_keys: Union[List[str], Dict[str, str]],
+           export_savedmodel_dir: str,
+           checkpoint_path: Optional[str] = None,
            timestamped: bool = True,
-           module_key: Optional[Text] = None) -> Text:
+           module_key: Optional[str] = None,
+           checkpoint_kwargs: Optional[Dict[str, Any]] = None) -> str:
   """Exports to SavedModel format.
 
   Args:
     export_module: a ExportModule with the keras Model and serving tf.functions.
     function_keys: a list of string keys to retrieve pre-defined serving
       signatures. The signaute keys will be set with defaults. If a dictionary
       is provided, the values will be used as signature keys.
     export_savedmodel_dir: Output saved model directory.
     checkpoint_path: Object-based checkpoint path or directory.
     timestamped: Whether to export the savedmodel to a timestamped directory.
     module_key: Optional string to identify a checkpoint object to load for the
       model in the export module.
+    checkpoint_kwargs: Optional dict used as keyword args to create the
+      checkpoint object. Not used if module_key is present.
 
   Returns:
     The savedmodel directory path.
   """
   save_options = tf.saved_model.SaveOptions(function_aliases={
       'tpu_candidate': export_module.serve,
   })
   if module_key:
     kwargs = {module_key: export_module.model}
     checkpoint = tf.train.Checkpoint(**kwargs)
+  elif checkpoint_kwargs:
+    checkpoint = tf.train.Checkpoint(**checkpoint_kwargs)
   else:
     checkpoint = None
   return export_base.export(
       export_module,
       function_keys,
       export_savedmodel_dir,
       checkpoint_path,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/serving/serving_modules.py` & `tf-models-no-deps-2.16.0/official/nlp/serving/serving_modules.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Serving export modules for TF Model Garden NLP models."""
 # pylint:disable=missing-class-docstring
 import dataclasses
 from typing import Dict, List, Optional, Text
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_text as tf_text
 
 from official.core import export_base
 from official.modeling.hyperparams import base_config
 from official.nlp.data import sentence_prediction_dataloader
 
 
@@ -61,15 +61,15 @@
     # Text vocab file if tokenization is WordPiece, or sentencepiece.ModelProto
     # file if tokenization is SentencePiece.
     vocab_file: str = ""
     lower_case: bool = True
     # ...or load preprocessing from a SavedModel at this location.
     preprocessing_hub_module_url: str = ""
 
-  def __init__(self, params, model: tf.keras.Model, inference_step=None):
+  def __init__(self, params, model: tf_keras.Model, inference_step=None):
     super().__init__(params, model, inference_step)
     if params.use_v2_feature_names:
       self.input_word_ids_field = "input_word_ids"
       self.input_type_ids_field = "input_type_ids"
     else:
       self.input_word_ids_field = "input_ids"
       self.input_type_ids_field = "segment_ids"
@@ -184,15 +184,15 @@
                 tf.TensorSpec(shape=[None], dtype=tf.string, name="examples"))
     return signatures
 
 
 class MaskedLM(export_base.ExportModule):
   """The export module for the Bert Pretrain (MaskedLM) task."""
 
-  def __init__(self, params, model: tf.keras.Model, inference_step=None):
+  def __init__(self, params, model: tf_keras.Model, inference_step=None):
     super().__init__(params, model, inference_step)
     if params.use_v2_feature_names:
       self.input_word_ids_field = "input_word_ids"
       self.input_type_ids_field = "input_type_ids"
     else:
       self.input_word_ids_field = "input_ids"
       self.input_type_ids_field = "segment_ids"
@@ -265,15 +265,15 @@
   """The export module for the question answering task."""
 
   @dataclasses.dataclass
   class Params(base_config.Config):
     parse_sequence_length: Optional[int] = None
     use_v2_feature_names: bool = True
 
-  def __init__(self, params, model: tf.keras.Model, inference_step=None):
+  def __init__(self, params, model: tf_keras.Model, inference_step=None):
     super().__init__(params, model, inference_step)
     if params.use_v2_feature_names:
       self.input_word_ids_field = "input_word_ids"
       self.input_type_ids_field = "input_type_ids"
     else:
       self.input_word_ids_field = "input_ids"
       self.input_type_ids_field = "segment_ids"
@@ -340,15 +340,15 @@
 
   @dataclasses.dataclass
   class Params(base_config.Config):
     parse_sequence_length: Optional[int] = None
     use_v2_feature_names: bool = True
     output_encoder_outputs: bool = False
 
-  def __init__(self, params, model: tf.keras.Model, inference_step=None):
+  def __init__(self, params, model: tf_keras.Model, inference_step=None):
     super().__init__(params, model, inference_step)
     if params.use_v2_feature_names:
       self.input_word_ids_field = "input_word_ids"
       self.input_type_ids_field = "input_type_ids"
     else:
       self.input_word_ids_field = "input_ids"
       self.input_type_ids_field = "segment_ids"
@@ -416,15 +416,15 @@
 
   @dataclasses.dataclass
   class Params(base_config.Config):
     sentencepiece_model_path: str = ""
     # Needs to be specified if padded_decode is True/on TPUs.
     batch_size: Optional[int] = None
 
-  def __init__(self, params, model: tf.keras.Model, inference_step=None):
+  def __init__(self, params, model: tf_keras.Model, inference_step=None):
     super().__init__(params, model, inference_step)
     self._sp_tokenizer = tf_text.SentencepieceTokenizer(
         model=tf.io.gfile.GFile(params.sentencepiece_model_path, "rb").read(),
         add_eos=True)
     try:
       empty_str_tokenized = self._sp_tokenizer.tokenize("").numpy()
     except tf.errors.InternalError:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/serving/serving_modules_test.py` & `tf-models-no-deps-2.16.0/official/nlp/serving/serving_modules_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for nlp.serving.serving_modules."""
 
 import os
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from sentencepiece import SentencePieceTrainer
 from official.core import export_base
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
 from official.nlp.serving import serving_modules
 from official.nlp.tasks import masked_lm
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/dual_encoder.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/dual_encoder.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Dual encoder (retrieval) task."""
 from typing import Mapping, Tuple
 # Import libraries
 from absl import logging
 import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling import tf_utils
 from official.modeling.hyperparams import base_config
 from official.nlp.configs import encoders
@@ -44,29 +44,32 @@
   logit_scale: float = 1
   logit_margin: float = 0
   bidirectional: bool = False
 
   # Defining k for calculating metrics recall@k.
   eval_top_k: Tuple[int, ...] = (1, 3, 10)
 
-  encoder: encoders.EncoderConfig = (
-      encoders.EncoderConfig())
+  encoder: encoders.EncoderConfig = dataclasses.field(
+      default_factory=encoders.EncoderConfig
+  )
 
 
 @dataclasses.dataclass
 class DualEncoderConfig(cfg.TaskConfig):
   """The model config."""
   # At most one of `init_checkpoint` and `hub_module_url` can
   # be specified.
   init_checkpoint: str = ''
   hub_module_url: str = ''
   # Defines the concrete model config at instantiation time.
-  model: ModelConfig = ModelConfig()
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  model: ModelConfig = dataclasses.field(default_factory=ModelConfig)
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(
+      default_factory=cfg.DataConfig
+  )
 
 
 @task_factory.register_task_cls(DualEncoderConfig)
 class DualEncoderTask(base_task.Task):
   """Task object for dual encoder."""
 
   def build_model(self):
@@ -134,20 +137,20 @@
     dataset = dataset.repeat()
     dataset = dataset.map(
         dummy_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)
     return dataset
 
   def build_metrics(self, training=None):
     del training
-    metrics = [tf.keras.metrics.Mean(name='batch_size_per_core')]
+    metrics = [tf_keras.metrics.Mean(name='batch_size_per_core')]
     for k in self.task_config.model.eval_top_k:
-      metrics.append(tf.keras.metrics.SparseTopKCategoricalAccuracy(
+      metrics.append(tf_keras.metrics.SparseTopKCategoricalAccuracy(
           k=k, name=f'left_recall_at_{k}'))
       if self.task_config.model.bidirectional:
-        metrics.append(tf.keras.metrics.SparseTopKCategoricalAccuracy(
+        metrics.append(tf_keras.metrics.SparseTopKCategoricalAccuracy(
             k=k, name=f'right_recall_at_{k}'))
     return metrics
 
   def process_metrics(self, metrics, labels, model_outputs):
     del labels
 
     metrics = dict([(metric.name, metric) for metric in metrics])
@@ -164,15 +167,15 @@
       if self.task_config.model.bidirectional:
         metrics[f'right_recall_at_{k}'].update_state(ranking_labels,
                                                      right_logits)
     metrics['batch_size_per_core'].update_state(batch_size)
 
   def validation_step(self,
                       inputs,
-                      model: tf.keras.Model,
+                      model: tf_keras.Model,
                       metrics=None) -> Mapping[str, tf.Tensor]:
     outputs = model(inputs)
     loss = self.build_losses(
         labels=None, model_outputs=outputs, aux_losses=model.losses)
     logs = {self.loss: loss}
 
     if metrics:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/dual_encoder_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/dual_encoder_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for official.nlp.tasks.sentence_prediction."""
 import functools
 import os
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.bert import configs
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
 from official.nlp.data import dual_encoder_dataloader
 from official.nlp.tasks import dual_encoder
 from official.nlp.tasks import masked_lm
@@ -49,15 +49,15 @@
 
     strategy = tf.distribute.get_strategy()
     dataset = strategy.distribute_datasets_from_function(
         functools.partial(task.build_inputs, config.train_data))
 
     dataset.batch(10)
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     task.validation_step(next(iterator), model, metrics=metrics)
     model.save(os.path.join(self.get_temp_dir(), "saved_model"))
 
   def test_task(self):
     config = dual_encoder.DualEncoderConfig(
         init_checkpoint=self.get_temp_dir(),
@@ -65,15 +65,15 @@
         train_data=self._train_data_config)
     task = dual_encoder.DualEncoderTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     dataset = task.build_inputs(config.train_data)
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     task.validation_step(next(iterator), model, metrics=metrics)
 
     # Saves a checkpoint.
     pretrain_cfg = bert.PretrainerConfig(
         encoder=encoders.EncoderConfig(
             bert=encoders.BertEncoderConfig(vocab_size=30522, num_layers=1)))
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/electra_task.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/electra_task.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """ELECTRA pretraining task (Joint Masked LM and Replaced Token Detection)."""
 
 import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling import tf_utils
 from official.nlp.configs import bert
 from official.nlp.configs import electra
@@ -28,24 +28,30 @@
 from official.nlp.modeling import layers
 from official.nlp.modeling import models
 
 
 @dataclasses.dataclass
 class ElectraPretrainConfig(cfg.TaskConfig):
   """The model config."""
-  model: electra.ElectraPretrainerConfig = electra.ElectraPretrainerConfig(
-      cls_heads=[
-          bert.ClsHeadConfig(
-              inner_dim=768,
-              num_classes=2,
-              dropout_rate=0.1,
-              name='next_sentence')
-      ])
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  model: electra.ElectraPretrainerConfig = dataclasses.field(
+      default_factory=lambda: electra.ElectraPretrainerConfig(  # pylint: disable=g-long-lambda
+          cls_heads=[
+              bert.ClsHeadConfig(
+                  inner_dim=768,
+                  num_classes=2,
+                  dropout_rate=0.1,
+                  name='next_sentence',
+              )
+          ]
+      )
+  )
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(
+      default_factory=cfg.DataConfig
+  )
 
 
 def _build_pretrainer(
     config: electra.ElectraPretrainerConfig) -> models.ElectraPretrainer:
   """Instantiates ElectraPretrainer from the config."""
   generator_encoder_cfg = config.generator_encoder
   discriminator_encoder_cfg = config.discriminator_encoder
@@ -64,15 +70,15 @@
       discriminator_network=discriminator_network,
       vocab_size=generator_encoder_cfg.vocab_size,
       num_classes=config.num_classes,
       sequence_length=config.sequence_length,
       num_token_predictions=config.num_masked_tokens,
       mlm_activation=tf_utils.get_activation(
           generator_encoder_cfg.hidden_activation),
-      mlm_initializer=tf.keras.initializers.TruncatedNormal(
+      mlm_initializer=tf_keras.initializers.TruncatedNormal(
           stddev=generator_encoder_cfg.initializer_range),
       classification_heads=[
           layers.ClassificationHead(**cfg.as_dict()) for cfg in config.cls_heads
       ],
       disallow_correct=config.disallow_correct)
 
 
@@ -87,28 +93,28 @@
                    labels,
                    model_outputs,
                    metrics,
                    aux_losses=None) -> tf.Tensor:
     metrics = dict([(metric.name, metric) for metric in metrics])
 
     # generator lm and (optional) nsp loss.
-    lm_prediction_losses = tf.keras.losses.sparse_categorical_crossentropy(
+    lm_prediction_losses = tf_keras.losses.sparse_categorical_crossentropy(
         labels['masked_lm_ids'],
         tf.cast(model_outputs['lm_outputs'], tf.float32),
         from_logits=True)
     lm_label_weights = labels['masked_lm_weights']
     lm_numerator_loss = tf.reduce_sum(lm_prediction_losses * lm_label_weights)
     lm_denominator_loss = tf.reduce_sum(lm_label_weights)
     mlm_loss = tf.math.divide_no_nan(lm_numerator_loss, lm_denominator_loss)
     metrics['lm_example_loss'].update_state(mlm_loss)
     if 'next_sentence_labels' in labels:
       sentence_labels = labels['next_sentence_labels']
       sentence_outputs = tf.cast(
           model_outputs['sentence_outputs'], dtype=tf.float32)
-      sentence_loss = tf.keras.losses.sparse_categorical_crossentropy(
+      sentence_loss = tf_keras.losses.sparse_categorical_crossentropy(
           sentence_labels, sentence_outputs, from_logits=True)
       metrics['next_sentence_loss'].update_state(sentence_loss)
       total_loss = mlm_loss + sentence_loss
     else:
       total_loss = mlm_loss
 
     # discriminator replaced token detection (rtd) loss.
@@ -154,27 +160,27 @@
 
     return pretrain_dataloader.BertPretrainDataLoader(params).load(
         input_context)
 
   def build_metrics(self, training=None):
     del training
     metrics = [
-        tf.keras.metrics.SparseCategoricalAccuracy(name='masked_lm_accuracy'),
-        tf.keras.metrics.Mean(name='lm_example_loss'),
-        tf.keras.metrics.SparseCategoricalAccuracy(
+        tf_keras.metrics.SparseCategoricalAccuracy(name='masked_lm_accuracy'),
+        tf_keras.metrics.Mean(name='lm_example_loss'),
+        tf_keras.metrics.SparseCategoricalAccuracy(
             name='discriminator_accuracy'),
     ]
     if self.task_config.train_data.use_next_sentence_label:
       metrics.append(
-          tf.keras.metrics.SparseCategoricalAccuracy(
+          tf_keras.metrics.SparseCategoricalAccuracy(
               name='next_sentence_accuracy'))
-      metrics.append(tf.keras.metrics.Mean(name='next_sentence_loss'))
+      metrics.append(tf_keras.metrics.Mean(name='next_sentence_loss'))
 
-    metrics.append(tf.keras.metrics.Mean(name='discriminator_loss'))
-    metrics.append(tf.keras.metrics.Mean(name='total_loss'))
+    metrics.append(tf_keras.metrics.Mean(name='discriminator_loss'))
+    metrics.append(tf_keras.metrics.Mean(name='total_loss'))
 
     return metrics
 
   def process_metrics(self, metrics, labels, model_outputs):
     metrics = dict([(metric.name, metric) for metric in metrics])
     if 'masked_lm_accuracy' in metrics:
       metrics['masked_lm_accuracy'].update_state(labels['masked_lm_ids'],
@@ -187,16 +193,16 @@
       disc_logits_expanded = tf.expand_dims(model_outputs['disc_logits'], -1)
       discrim_full_logits = tf.concat(
           [-1.0 * disc_logits_expanded, disc_logits_expanded], -1)
       metrics['discriminator_accuracy'].update_state(
           model_outputs['disc_label'], discrim_full_logits,
           labels['input_mask'])
 
-  def train_step(self, inputs, model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer, metrics):
+  def train_step(self, inputs, model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer, metrics):
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
       metrics: a nested structure of metrics objects.
@@ -217,15 +223,15 @@
       scaled_loss = loss / tf.distribute.get_strategy().num_replicas_in_sync
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     optimizer.apply_gradients(list(zip(grads, tvars)))
     self.process_metrics(metrics, inputs, outputs)
     return {self.loss: loss}
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics):
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/electra_task_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/electra_task_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.tasks.electra_task."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.configs import bert
 from official.nlp.configs import electra
 from official.nlp.configs import encoders
 from official.nlp.data import pretrain_dataloader
 from official.nlp.tasks import electra_task
 
@@ -47,14 +47,14 @@
             global_batch_size=1))
     task = electra_task.ElectraPretrainTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     dataset = task.build_inputs(config.train_data)
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     task.validation_step(next(iterator), model, metrics=metrics)
 
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/masked_lm.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/masked_lm.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Masked language task."""
 
 import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling import tf_utils
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
@@ -27,23 +27,33 @@
 from official.nlp.modeling import layers
 from official.nlp.modeling import models
 
 
 @dataclasses.dataclass
 class MaskedLMConfig(cfg.TaskConfig):
   """The model config."""
-  model: bert.PretrainerConfig = bert.PretrainerConfig(cls_heads=[
-      bert.ClsHeadConfig(
-          inner_dim=768, num_classes=2, dropout_rate=0.1, name='next_sentence')
-  ])
+  model: bert.PretrainerConfig = dataclasses.field(
+      default_factory=lambda: bert.PretrainerConfig(  # pylint: disable=g-long-lambda
+          cls_heads=[
+              bert.ClsHeadConfig(
+                  inner_dim=768,
+                  num_classes=2,
+                  dropout_rate=0.1,
+                  name='next_sentence',
+              )
+          ]
+      )
+  )
   # TODO(b/154564893): Mathematically, scale_loss should be True.
   # However, it works better with scale_loss being False.
   scale_loss: bool = False
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(
+      default_factory=cfg.DataConfig
+  )
 
 
 @task_factory.register_task_cls(MaskedLMConfig)
 class MaskedLMTask(base_task.Task):
   """Task object for Mask language modeling."""
 
   def _build_encoder(self, encoder_cfg):
@@ -54,42 +64,42 @@
     encoder_cfg = config.encoder
     encoder_network = self._build_encoder(encoder_cfg)
     cls_heads = [
         layers.ClassificationHead(**cfg.as_dict()) for cfg in config.cls_heads
     ] if config.cls_heads else []
     return models.BertPretrainerV2(
         mlm_activation=tf_utils.get_activation(config.mlm_activation),
-        mlm_initializer=tf.keras.initializers.TruncatedNormal(
+        mlm_initializer=tf_keras.initializers.TruncatedNormal(
             stddev=config.mlm_initializer_range),
         encoder_network=encoder_network,
         classification_heads=cls_heads)
 
   def build_losses(self,
                    labels,
                    model_outputs,
                    metrics,
                    aux_losses=None) -> tf.Tensor:
     with tf.name_scope('MaskedLMTask/losses'):
       metrics = dict([(metric.name, metric) for metric in metrics])
-      lm_prediction_losses = tf.keras.losses.sparse_categorical_crossentropy(
+      lm_prediction_losses = tf_keras.losses.sparse_categorical_crossentropy(
           labels['masked_lm_ids'],
           tf.cast(model_outputs['mlm_logits'], tf.float32),
           from_logits=True)
       lm_label_weights = labels['masked_lm_weights']
       lm_numerator_loss = tf.reduce_sum(lm_prediction_losses *
                                         lm_label_weights)
       lm_denominator_loss = tf.reduce_sum(lm_label_weights)
       mlm_loss = tf.math.divide_no_nan(lm_numerator_loss, lm_denominator_loss)
       metrics['lm_example_loss'].update_state(mlm_loss)
       if 'next_sentence_labels' in labels:
         sentence_labels = labels['next_sentence_labels']
         sentence_outputs = tf.cast(
             model_outputs['next_sentence'], dtype=tf.float32)
         sentence_loss = tf.reduce_mean(
-            tf.keras.losses.sparse_categorical_crossentropy(
+            tf_keras.losses.sparse_categorical_crossentropy(
                 sentence_labels, sentence_outputs, from_logits=True))
         metrics['next_sentence_loss'].update_state(sentence_loss)
         total_loss = mlm_loss + sentence_loss
       else:
         total_loss = mlm_loss
 
       if aux_losses:
@@ -119,38 +129,38 @@
       return dataset
 
     return data_loader_factory.get_data_loader(params).load(input_context)
 
   def build_metrics(self, training=None):
     del training
     metrics = [
-        tf.keras.metrics.SparseCategoricalAccuracy(name='masked_lm_accuracy'),
-        tf.keras.metrics.Mean(name='lm_example_loss')
+        tf_keras.metrics.SparseCategoricalAccuracy(name='masked_lm_accuracy'),
+        tf_keras.metrics.Mean(name='lm_example_loss')
     ]
     # TODO(hongkuny): rethink how to manage metrics creation with heads.
     if self.task_config.train_data.use_next_sentence_label:
       metrics.append(
-          tf.keras.metrics.SparseCategoricalAccuracy(
+          tf_keras.metrics.SparseCategoricalAccuracy(
               name='next_sentence_accuracy'))
-      metrics.append(tf.keras.metrics.Mean(name='next_sentence_loss'))
+      metrics.append(tf_keras.metrics.Mean(name='next_sentence_loss'))
     return metrics
 
   def process_metrics(self, metrics, labels, model_outputs):
     with tf.name_scope('MaskedLMTask/process_metrics'):
       metrics = dict([(metric.name, metric) for metric in metrics])
       if 'masked_lm_accuracy' in metrics:
         metrics['masked_lm_accuracy'].update_state(
             labels['masked_lm_ids'], model_outputs['mlm_logits'],
             labels['masked_lm_weights'])
       if 'next_sentence_accuracy' in metrics:
         metrics['next_sentence_accuracy'].update_state(
             labels['next_sentence_labels'], model_outputs['next_sentence'])
 
-  def train_step(self, inputs, model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer, metrics):
+  def train_step(self, inputs, model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer, metrics):
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
       metrics: a nested structure of metrics objects.
@@ -175,15 +185,15 @@
       grads = tape.gradient(scaled_loss, tvars)
     else:
       grads = tape.gradient(loss, tvars)
     optimizer.apply_gradients(list(zip(grads, tvars)))
     self.process_metrics(metrics, inputs, outputs)
     return {self.loss: loss}
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics):
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/masked_lm_determinism_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/masked_lm_determinism_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests that masked LM models are deterministic when determinism is enabled."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
 from official.nlp.data import pretrain_dataloader
 from official.nlp.tasks import masked_lm
 
 
@@ -50,15 +50,15 @@
     task = masked_lm.MaskedLMTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     dataset = self._build_dataset(config.train_data,
                                   config.model.encoder.get().vocab_size)
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
 
     # Run training
     for _ in range(num_steps):
       logs = task.train_step(next(iterator), model, optimizer, metrics=metrics)
     for metric in metrics:
       logs[metric.name] = metric.result()
 
@@ -83,17 +83,17 @@
                     inner_dim=10, num_classes=2, name="next_sentence")
             ]),
         train_data=pretrain_dataloader.BertPretrainDataConfig(
             max_predictions_per_seq=20,
             seq_length=128,
             global_batch_size=1))
 
-    tf.keras.utils.set_random_seed(1)
+    tf_keras.utils.set_random_seed(1)
     logs1, validation_logs1, weights1 = self._build_and_run_model(config)
-    tf.keras.utils.set_random_seed(1)
+    tf_keras.utils.set_random_seed(1)
     logs2, validation_logs2, weights2 = self._build_and_run_model(config)
 
     self.assertEqual(logs1["loss"], logs2["loss"])
     self.assertEqual(validation_logs1["loss"], validation_logs2["loss"])
     for weight1, weight2 in zip(weights1, weights2):
       self.assertAllEqual(weight1, weight2)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/masked_lm_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/masked_lm_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.tasks.masked_lm."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
 from official.nlp.data import pretrain_dataloader
 from official.nlp.tasks import masked_lm
 
 
@@ -43,15 +43,15 @@
             global_batch_size=1))
     task = masked_lm.MaskedLMTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     dataset = task.build_inputs(config.train_data)
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     task.validation_step(next(iterator), model, metrics=metrics)
 
     # Saves a checkpoint.
     ckpt = tf.train.Checkpoint(model=model, **model.checkpoint_items)
     ckpt.save(config.init_checkpoint)
     task.initialize(model)
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/question_answering.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/question_answering.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import functools
 import json
 import os
 from typing import List, Optional
 
 from absl import logging
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling.hyperparams import base_config
 from official.nlp.configs import encoders
 from official.nlp.data import data_loader_factory
@@ -37,29 +37,33 @@
 from official.nlp.tools import squad_evaluate_v2_0
 from official.nlp.tools import tokenization
 
 
 @dataclasses.dataclass
 class ModelConfig(base_config.Config):
   """A base span labeler configuration."""
-  encoder: encoders.EncoderConfig = encoders.EncoderConfig()
+  encoder: encoders.EncoderConfig = dataclasses.field(
+      default_factory=encoders.EncoderConfig
+  )
 
 
 @dataclasses.dataclass
 class QuestionAnsweringConfig(cfg.TaskConfig):
   """The model config."""
   # At most one of `init_checkpoint` and `hub_module_url` can be specified.
   init_checkpoint: str = ''
   hub_module_url: str = ''
   n_best_size: int = 20
   max_answer_length: int = 30
   null_score_diff_threshold: float = 0.0
-  model: ModelConfig = ModelConfig()
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  model: ModelConfig = dataclasses.field(default_factory=ModelConfig)
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(
+      default_factory=cfg.DataConfig
+  )
 
 
 @dataclasses.dataclass
 class RawAggregatedResult:
   """Raw representation for SQuAD predictions."""
   unique_id: int
   start_logits: List[float]
@@ -103,27 +107,27 @@
       encoder_network = utils.get_encoder_from_hub(
           self.task_config.hub_module_url)
     else:
       encoder_network = encoders.build_encoder(self.task_config.model.encoder)
     encoder_cfg = self.task_config.model.encoder.get()
     return models.BertSpanLabeler(
         network=encoder_network,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=encoder_cfg.initializer_range))
 
   def build_losses(self, labels, model_outputs, aux_losses=None) -> tf.Tensor:
     start_positions = labels['start_positions']
     end_positions = labels['end_positions']
     start_logits, end_logits = model_outputs
 
-    start_loss = tf.keras.losses.sparse_categorical_crossentropy(
+    start_loss = tf_keras.losses.sparse_categorical_crossentropy(
         start_positions,
         tf.cast(start_logits, dtype=tf.float32),
         from_logits=True)
-    end_loss = tf.keras.losses.sparse_categorical_crossentropy(
+    end_loss = tf_keras.losses.sparse_categorical_crossentropy(
         end_positions, tf.cast(end_logits, dtype=tf.float32), from_logits=True)
 
     loss = (tf.reduce_mean(start_loss) + tf.reduce_mean(end_loss)) / 2
     return loss
 
   def _preprocess_eval_data(self, params):
     eval_examples = self.squad_lib.read_squad_examples(
@@ -216,17 +220,17 @@
   def build_metrics(self, training=None):
     if not training:
       # We cannot compute start/end_position_accuracy because start/end_position
       # labels are not available in the validation dataset (b/173794928).
       return []
     # TODO(lehou): a list of metrics doesn't work the same as in compile/fit.
     metrics = [
-        tf.keras.metrics.SparseCategoricalAccuracy(
+        tf_keras.metrics.SparseCategoricalAccuracy(
             name='start_position_accuracy'),
-        tf.keras.metrics.SparseCategoricalAccuracy(
+        tf_keras.metrics.SparseCategoricalAccuracy(
             name='end_position_accuracy'),
     ]
     return metrics
 
   def process_metrics(self, metrics, labels, model_outputs):
     metrics = dict([(metric.name, metric) for metric in metrics])
     start_logits, end_logits = model_outputs
@@ -240,15 +244,15 @@
     compiled_metrics.update_state(
         y_true=labels,  # labels has keys 'start_positions' and 'end_positions'.
         y_pred={
             'start_positions': start_logits,
             'end_positions': end_logits
         })
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics=None):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics=None):
     features, _ = inputs
     unique_ids = features.pop('unique_ids')
     model_outputs = self.inference_step(features, model)
     start_logits, end_logits = model_outputs
     # We cannot compute validation_loss here, because start/end_position
     # labels are not available in the validation dataset (b/173794928).
     logs = {
@@ -343,15 +347,15 @@
     else:
       encoder_network = encoders.build_encoder(self.task_config.model.encoder)
     encoder_cfg = self.task_config.model.encoder.get()
     return models.XLNetSpanLabeler(
         network=encoder_network,
         start_n_top=self.task_config.n_best_size,
         end_n_top=self.task_config.n_best_size,
-        initializer=tf.keras.initializers.RandomNormal(
+        initializer=tf_keras.initializers.RandomNormal(
             stddev=encoder_cfg.initializer_range))
 
   def build_losses(self, labels, model_outputs, aux_losses=None) -> tf.Tensor:
     start_positions = labels['start_positions']
     end_positions = labels['end_positions']
     is_impossible = labels['is_impossible']
     is_impossible = tf.cast(tf.reshape(is_impossible, [-1]), tf.float32)
@@ -360,15 +364,15 @@
     end_logits = model_outputs['end_logits']
     class_logits = model_outputs['class_logits']
 
     start_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(
         start_positions, start_logits)
     end_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(
         end_positions, end_logits)
-    is_impossible_loss = tf.keras.losses.binary_crossentropy(
+    is_impossible_loss = tf_keras.losses.binary_crossentropy(
         is_impossible, class_logits, from_logits=True)
 
     loss = (tf.reduce_mean(start_loss) + tf.reduce_mean(end_loss)) / 2
     loss += tf.reduce_mean(is_impossible_loss) / 2
     return loss
 
   def process_metrics(self, metrics, labels, model_outputs):
@@ -404,15 +408,15 @@
         start_positions=tf.zeros((1), dtype=tf.int32))
     y = dict(
         start_positions=tf.zeros((1), dtype=tf.int32),
         end_positions=tf.ones((1), dtype=tf.int32),
         is_impossible=zero)
     return x, y
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics=None):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics=None):
     features, _ = inputs
     unique_ids = features.pop('unique_ids')
     model_outputs = self.inference_step(features, model)
     start_top_predictions = model_outputs['start_top_predictions']
     end_top_predictions = model_outputs['end_top_predictions']
     start_indexes = model_outputs['start_top_index']
     end_indexes = model_outputs['end_top_index']
@@ -451,15 +455,15 @@
             start_indexes=start_indexes.tolist(),
             end_indexes=end_indexes.tolist(),
             class_logits=class_logits))
     return state
 
 
 def predict(task: QuestionAnsweringTask, params: cfg.DataConfig,
-            model: tf.keras.Model):
+            model: tf_keras.Model):
   """Predicts on the input data.
 
   Args:
     task: A `QuestionAnsweringTask` object.
     params: A `cfg.DataConfig` object.
     model: A keras.Model.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/question_answering_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/question_answering_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for official.nlp.tasks.question_answering."""
 import itertools
 import json
 import os
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
 from official.nlp.data import question_answering_dataloader
 from official.nlp.tasks import masked_lm
 from official.nlp.tasks import question_answering
 
@@ -86,33 +86,35 @@
     task = question_answering.QuestionAnsweringTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     task.initialize(model)
 
     train_dataset = task.build_inputs(config.train_data)
     train_iterator = iter(train_dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(train_iterator), model, optimizer, metrics=metrics)
 
     val_dataset = task.build_inputs(config.validation_data)
     val_iterator = iter(val_dataset)
     logs = task.validation_step(next(val_iterator), model, metrics=metrics)
     # Mock that `logs` is from one replica.
     logs = {x: (logs[x],) for x in logs}
     logs = task.aggregate_logs(step_outputs=logs)
     metrics = task.reduce_aggregated_logs(logs)
     self.assertIn("final_f1", metrics)
-    model.save(os.path.join(self.get_temp_dir(), "saved_model"))
+    model.save(os.path.join(self.get_temp_dir(), "saved_model.keras"),
+               save_format="keras")
 
   @parameterized.parameters(
       itertools.product(
           (False, True),
           ("WordPiece", "SentencePiece"),
       ))
   def test_task(self, version_2_with_negative, tokenization):
+    del tokenization
     # Saves a checkpoint.
     pretrain_cfg = bert.PretrainerConfig(
         encoder=self._encoder_config,
         cls_heads=[
             bert.ClsHeadConfig(
                 inner_dim=10, num_classes=3, name="next_sentence")
         ])
@@ -131,15 +133,15 @@
 
   def _export_bert_tfhub(self):
     encoder = encoders.build_encoder(
         encoders.EncoderConfig(
             bert=encoders.BertEncoderConfig(vocab_size=30522, num_layers=1)))
     encoder_inputs_dict = {x.name: x for x in encoder.inputs}
     encoder_output_dict = encoder(encoder_inputs_dict)
-    core_model = tf.keras.Model(
+    core_model = tf_keras.Model(
         inputs=encoder_inputs_dict, outputs=encoder_output_dict)
     hub_destination = os.path.join(self.get_temp_dir(), "hub")
     core_model.save(hub_destination, include_optimizer=False, save_format="tf")
     return hub_destination
 
   def test_task_with_hub(self):
     hub_module_url = self._export_bert_tfhub()
@@ -234,15 +236,15 @@
     task = question_answering.XLNetQuestionAnsweringTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     task.initialize(model)
 
     train_dataset = task.build_inputs(config.train_data)
     train_iterator = iter(train_dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(train_iterator), model, optimizer, metrics=metrics)
 
     val_dataset = task.build_inputs(config.validation_data)
     val_iterator = iter(val_dataset)
     logs = task.validation_step(next(val_iterator), model, metrics=metrics)
     # Mock that `logs` is from one replica.
     logs = {x: (logs[x],) for x in logs}
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/sentence_prediction.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/sentence_prediction.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 from typing import List, Union, Optional
 
 from absl import logging
 import numpy as np
 import orbit
 from scipy import stats
 from sklearn import metrics as sklearn_metrics
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling import tf_utils
 from official.modeling.hyperparams import base_config
 from official.nlp.configs import encoders
@@ -38,30 +38,30 @@
 
 
 @dataclasses.dataclass
 class ModelConfig(base_config.Config):
   """A classifier/regressor configuration."""
   num_classes: int = 0
   use_encoder_pooler: bool = False
-  encoder: encoders.EncoderConfig = encoders.EncoderConfig()
+  encoder: encoders.EncoderConfig = dataclasses.field(default_factory=encoders.EncoderConfig)
 
 
 @dataclasses.dataclass
 class SentencePredictionConfig(cfg.TaskConfig):
   """The model config."""
   # At most one of `init_checkpoint` and `hub_module_url` can
   # be specified.
   init_checkpoint: str = ''
   init_cls_pooler: bool = False
   hub_module_url: str = ''
   metric_type: str = 'accuracy'
   # Defines the concrete model config at instantiation time.
-  model: ModelConfig = ModelConfig()
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  model: ModelConfig = dataclasses.field(default_factory=ModelConfig)
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
 
 
 @task_factory.register_task_cls(SentencePredictionConfig)
 class SentencePredictionTask(base_task.Task):
   """Task object for sentence_prediction."""
 
   def __init__(self, params: cfg.TaskConfig, logging_dir=None, name=None):
@@ -84,30 +84,30 @@
     else:
       encoder_network = encoders.build_encoder(self.task_config.model.encoder)
     encoder_cfg = self.task_config.model.encoder.get()
     if self.task_config.model.encoder.type == 'xlnet':
       return models.XLNetClassifier(
           network=encoder_network,
           num_classes=self.task_config.model.num_classes,
-          initializer=tf.keras.initializers.RandomNormal(
+          initializer=tf_keras.initializers.RandomNormal(
               stddev=encoder_cfg.initializer_range))
     else:
       return models.BertClassifier(
           network=encoder_network,
           num_classes=self.task_config.model.num_classes,
-          initializer=tf.keras.initializers.TruncatedNormal(
+          initializer=tf_keras.initializers.TruncatedNormal(
               stddev=encoder_cfg.initializer_range),
           use_encoder_pooler=self.task_config.model.use_encoder_pooler)
 
   def build_losses(self, labels, model_outputs, aux_losses=None) -> tf.Tensor:
     label_ids = labels[self.label_field]
     if self.task_config.model.num_classes == 1:
-      loss = tf.keras.losses.mean_squared_error(label_ids, model_outputs)
+      loss = tf_keras.losses.mean_squared_error(label_ids, model_outputs)
     else:
-      loss = tf.keras.losses.sparse_categorical_crossentropy(
+      loss = tf_keras.losses.sparse_categorical_crossentropy(
           label_ids, tf.cast(model_outputs, tf.float32), from_logits=True)
 
     if aux_losses:
       loss += tf.add_n(aux_losses)
     return tf_utils.safe_mean(loss)
 
   def build_inputs(self, params, input_context=None):
@@ -135,23 +135,23 @@
       return dataset
 
     return data_loader_factory.get_data_loader(params).load(input_context)
 
   def build_metrics(self, training=None):
     del training
     if self.task_config.model.num_classes == 1:
-      metrics = [tf.keras.metrics.MeanSquaredError()]
+      metrics = [tf_keras.metrics.MeanSquaredError()]
     elif self.task_config.model.num_classes == 2:
       metrics = [
-          tf.keras.metrics.SparseCategoricalAccuracy(name='cls_accuracy'),
-          tf.keras.metrics.AUC(name='auc', curve='PR'),
+          tf_keras.metrics.SparseCategoricalAccuracy(name='cls_accuracy'),
+          tf_keras.metrics.AUC(name='auc', curve='PR'),
       ]
     else:
       metrics = [
-          tf.keras.metrics.SparseCategoricalAccuracy(name='cls_accuracy'),
+          tf_keras.metrics.SparseCategoricalAccuracy(name='cls_accuracy'),
       ]
     return metrics
 
   def process_metrics(self, metrics, labels, model_outputs):
     for metric in metrics:
       if metric.name == 'auc':
         # Convert the logit to probability and extract the probability of True..
@@ -160,15 +160,15 @@
             tf.expand_dims(tf.nn.softmax(model_outputs)[:, 1], axis=1))
       if metric.name == 'cls_accuracy':
         metric.update_state(labels[self.label_field], model_outputs)
 
   def process_compiled_metrics(self, compiled_metrics, labels, model_outputs):
     compiled_metrics.update_state(labels[self.label_field], model_outputs)
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics=None):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics=None):
     features, labels = inputs, inputs
     outputs = self.inference_step(features, model)
     loss = self.build_losses(
         labels=labels, model_outputs=outputs, aux_losses=model.losses)
     logs = {self.loss: loss}
     if metrics:
       self.process_metrics(metrics, labels, outputs)
@@ -250,15 +250,15 @@
     status.expect_partial().assert_existing_objects_matched()
     logging.info('Finished loading pretrained checkpoint from %s',
                  ckpt_dir_or_file)
 
 
 def predict(task: SentencePredictionTask,
             params: cfg.DataConfig,
-            model: tf.keras.Model,
+            model: tf_keras.Model,
             params_aug: Optional[cfg.DataConfig] = None,
             test_time_aug_wgt: float = 0.3) -> List[Union[int, float]]:
   """Predicts on the input data.
 
   Args:
     task: A `SentencePredictionTask` object.
     params: A `cfg.DataConfig` object.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/sentence_prediction_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/sentence_prediction_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for official.nlp.tasks.sentence_prediction."""
 import functools
 import os
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
 from official.nlp.data import sentence_prediction_dataloader
 from official.nlp.tasks import masked_lm
 from official.nlp.tasks import sentence_prediction
 
@@ -79,15 +79,15 @@
     metrics = task.build_metrics()
 
     strategy = tf.distribute.get_strategy()
     dataset = strategy.distribute_datasets_from_function(
         functools.partial(task.build_inputs, config.train_data))
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)
+    optimizer = tf_keras.optimizers.SGD(learning_rate=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     model.save(os.path.join(self.get_temp_dir(), "saved_model"))
     return task.validation_step(next(iterator), model, metrics=metrics)
 
   @parameterized.named_parameters(
       ("init_cls_pooler", True),
       ("init_encoder", False),
@@ -116,15 +116,15 @@
         init_cls_pooler=init_cls_pooler)
     task = sentence_prediction.SentencePredictionTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     dataset = task.build_inputs(config.train_data)
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)
+    optimizer = tf_keras.optimizers.SGD(learning_rate=0.1)
     task.initialize(model)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     task.validation_step(next(iterator), model, metrics=metrics)
 
   @parameterized.named_parameters(
       {
           "testcase_name": "regression",
@@ -140,22 +140,22 @@
         init_checkpoint=self.get_temp_dir(),
         model=self.get_model_config(num_classes),
         train_data=self._train_data_config)
     task = sentence_prediction.SentencePredictionTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     if num_classes == 1:
-      self.assertIsInstance(metrics[0], tf.keras.metrics.MeanSquaredError)
+      self.assertIsInstance(metrics[0], tf_keras.metrics.MeanSquaredError)
     else:
       self.assertIsInstance(metrics[0],
-                            tf.keras.metrics.SparseCategoricalAccuracy)
+                            tf_keras.metrics.SparseCategoricalAccuracy)
 
     dataset = task.build_inputs(config.train_data)
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)
+    optimizer = tf_keras.optimizers.SGD(learning_rate=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
 
     logs = task.validation_step(next(iterator), model, metrics=metrics)
     loss = logs["loss"].numpy()
     if num_classes == 1:
       self.assertGreater(loss, 1.0)
     else:
@@ -215,15 +215,15 @@
 
   def _export_bert_tfhub(self):
     encoder = encoders.build_encoder(
         encoders.EncoderConfig(
             bert=encoders.BertEncoderConfig(vocab_size=30522, num_layers=1)))
     encoder_inputs_dict = {x.name: x for x in encoder.inputs}
     encoder_output_dict = encoder(encoder_inputs_dict)
-    core_model = tf.keras.Model(
+    core_model = tf_keras.Model(
         inputs=encoder_inputs_dict, outputs=encoder_output_dict)
     hub_destination = os.path.join(self.get_temp_dir(), "hub")
     core_model.save(hub_destination, include_optimizer=False, save_format="tf")
     return hub_destination
 
   def test_task_with_hub(self):
     hub_module_url = self._export_bert_tfhub()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/tagging.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/tagging.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,50 +16,50 @@
 from typing import List, Optional, Tuple
 
 import dataclasses
 import orbit
 
 from seqeval import metrics as seqeval_metrics
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling.hyperparams import base_config
 from official.nlp.configs import encoders
 from official.nlp.data import data_loader_factory
 from official.nlp.modeling import models
 from official.nlp.tasks import utils
 
 
 @dataclasses.dataclass
 class ModelConfig(base_config.Config):
   """A base span labeler configuration."""
-  encoder: encoders.EncoderConfig = encoders.EncoderConfig()
+  encoder: encoders.EncoderConfig = dataclasses.field(default_factory=encoders.EncoderConfig)
   head_dropout: float = 0.1
   head_initializer_range: float = 0.02
 
 
 @dataclasses.dataclass
 class TaggingConfig(cfg.TaskConfig):
   """The model config."""
   # At most one of `init_checkpoint` and `hub_module_url` can be specified.
   init_checkpoint: str = ''
   hub_module_url: str = ''
-  model: ModelConfig = ModelConfig()
+  model: ModelConfig = dataclasses.field(default_factory=ModelConfig)
 
   # The real class names, the order of which should match real label id.
   # Note that a word may be tokenized into multiple word_pieces tokens, and
   # we asssume the real label id (non-negative) is assigned to the first token
   # of the word, and a negative label id is assigned to the remaining tokens.
   # The negative label id will not contribute to loss and metrics.
   class_names: Optional[List[str]] = None
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
 
 
 def _masked_labels_and_weights(y_true):
   """Masks negative values from token level labels.
 
   Args:
     y_true: Token labels, typically shape (batch_size, seq_len), where tokens
@@ -91,24 +91,24 @@
           self.task_config.hub_module_url)
     else:
       encoder_network = encoders.build_encoder(self.task_config.model.encoder)
 
     return models.BertTokenClassifier(
         network=encoder_network,
         num_classes=len(self.task_config.class_names),
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=self.task_config.model.head_initializer_range),
         dropout_rate=self.task_config.model.head_dropout,
         output='logits',
         output_encoder_outputs=True)
 
   def build_losses(self, labels, model_outputs, aux_losses=None) -> tf.Tensor:
     logits = tf.cast(model_outputs['logits'], tf.float32)
     masked_labels, masked_weights = _masked_labels_and_weights(labels)
-    loss = tf.keras.losses.sparse_categorical_crossentropy(
+    loss = tf_keras.losses.sparse_categorical_crossentropy(
         masked_labels, logits, from_logits=True)
     numerator_loss = tf.reduce_sum(loss * masked_weights)
     denominator_loss = tf.reduce_sum(masked_weights)
     loss = tf.math.divide_no_nan(numerator_loss, denominator_loss)
     return loss
 
   def build_inputs(self, params: cfg.DataConfig, input_context=None):
@@ -134,21 +134,21 @@
       dataset = dataset.repeat()
       dataset = dataset.map(
           dummy_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)
       return dataset
 
     return data_loader_factory.get_data_loader(params).load(input_context)
 
-  def inference_step(self, inputs, model: tf.keras.Model):
+  def inference_step(self, inputs, model: tf_keras.Model):
     """Performs the forward step."""
     logits = model(inputs, training=False)['logits']
     return {'logits': logits,
             'predict_ids': tf.argmax(logits, axis=-1, output_type=tf.int32)}
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics=None):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics=None):
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
 
@@ -203,15 +203,15 @@
         'accuracy':
             seqeval_metrics.accuracy_score(label_class, predict_class),
     }
 
 
 def predict(task: TaggingTask,
             params: cfg.DataConfig,
-            model: tf.keras.Model) -> List[Tuple[int, int, List[int]]]:
+            model: tf_keras.Model) -> List[Tuple[int, int, List[int]]]:
   """Predicts on the input data.
 
   Args:
     task: A `TaggingTask` object.
     params: A `cfg.DataConfig` object.
     model: A keras.Model.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/tagging_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/tagging_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for official.nlp.tasks.tagging."""
 import functools
 import os
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.configs import encoders
 from official.nlp.data import tagging_dataloader
 from official.nlp.tasks import tagging
 
 
 def _create_fake_dataset(output_path, seq_length, num_labels, num_examples):
@@ -63,15 +63,15 @@
     metrics = task.build_metrics()
 
     strategy = tf.distribute.get_strategy()
     dataset = strategy.distribute_datasets_from_function(
         functools.partial(task.build_inputs, config.train_data))
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     task.validation_step(next(iterator), model, metrics=metrics)
     model.save(os.path.join(self.get_temp_dir(), "saved_model"))
 
   def test_task(self):
     # Saves a checkpoint.
     encoder = encoders.build_encoder(self._encoder_config)
@@ -85,26 +85,26 @@
         class_names=["O", "B-PER", "I-PER"])
     task = tagging.TaggingTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     dataset = task.build_inputs(config.train_data)
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     task.validation_step(next(iterator), model, metrics=metrics)
     task.initialize(model)
 
   def _export_bert_tfhub(self):
     encoder = encoders.build_encoder(
         encoders.EncoderConfig(
             bert=encoders.BertEncoderConfig(vocab_size=30522, num_layers=1)))
     encoder_inputs_dict = {x.name: x for x in encoder.inputs}
     encoder_output_dict = encoder(encoder_inputs_dict)
-    core_model = tf.keras.Model(
+    core_model = tf_keras.Model(
         inputs=encoder_inputs_dict, outputs=encoder_output_dict)
     hub_destination = os.path.join(self.get_temp_dir(), "hub")
     core_model.save(hub_destination, include_optimizer=False, save_format="tf")
     return hub_destination
 
   def test_task_with_hub(self):
     hub_module_url = self._export_bert_tfhub()
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/translation.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/translation.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Defines the translation task."""
 import dataclasses
 import os
 from typing import Optional
 
 from absl import logging
 import sacrebleu
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_text as tftxt
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling.hyperparams import base_config
 from official.nlp.data import data_loader_factory
@@ -94,16 +94,16 @@
   norm_first: bool = True
   norm_epsilon: float = 1e-6
 
 
 @dataclasses.dataclass
 class ModelConfig(base_config.Config):
   """A base Seq2Seq model configuration."""
-  encoder: EncDecoder = EncDecoder()
-  decoder: EncDecoder = EncDecoder()
+  encoder: EncDecoder = dataclasses.field(default_factory=EncDecoder)
+  decoder: EncDecoder = dataclasses.field(default_factory=EncDecoder)
 
   embedding_width: int = 512
   dropout_rate: float = 0.1
 
   # Decoding.
   padded_decode: bool = False
   decode_max_length: Optional[int] = None
@@ -113,17 +113,19 @@
   # Training.
   label_smoothing: float = 0.1
 
 
 @dataclasses.dataclass
 class TranslationConfig(cfg.TaskConfig):
   """The translation task config."""
-  model: ModelConfig = ModelConfig()
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  model: ModelConfig = dataclasses.field(default_factory=ModelConfig)
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(
+      default_factory=cfg.DataConfig
+  )
   # Tokenization
   sentencepiece_model_path: str = ""
   # Evaluation.
   print_translations: Optional[bool] = None
 
 
 def write_test_record(params, model_dir):
@@ -197,15 +199,15 @@
     else:
       raise ValueError("Setencepiece model path not provided.")
     if (params.validation_data.input_path or
         params.validation_data.tfds_name) and self._logging_dir:
       self._references, self._tf_record_input_path = write_test_record(
           params.validation_data, self.logging_dir)
 
-  def build_model(self) -> tf.keras.Model:
+  def build_model(self) -> tf_keras.Model:
     """Creates model architecture.
 
     Returns:
       A model instance.
     """
     model_cfg = self.task_config.model
     encoder_kwargs = model_cfg.encoder.as_dict()
@@ -260,16 +262,16 @@
     smoothing = self.task_config.model.label_smoothing
     xentropy, weights = _padded_cross_entropy_loss(model_outputs, labels,
                                                    smoothing, self._vocab_size)
     return tf.reduce_sum(xentropy) / tf.reduce_sum(weights)
 
   def train_step(self,
                  inputs,
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
+                 model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer,
                  metrics=None):
     """Does forward and backward.
 
     With distribution strategies, this method runs on devices.
 
     Args:
       inputs: a dictionary of input tensors.
@@ -286,29 +288,29 @@
       loss = self.build_losses(labels=inputs["targets"], model_outputs=outputs)
       # Scales loss as the default gradients allreduce performs sum inside the
       # optimizer.
       scaled_loss = loss / tf.distribute.get_strategy().num_replicas_in_sync
 
       # For mixed precision, when a LossScaleOptimizer is used, the loss is
       # scaled to avoid numeric underflow.
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
 
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
     optimizer.apply_gradients(list(zip(grads, tvars)))
     logs = {self.loss: loss}
     if metrics:
       self.process_metrics(metrics, inputs["targets"], outputs)
     return logs
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics=None):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics=None):
     unique_ids = inputs.pop("unique_id")
     # Validation loss
     outputs = model(inputs, training=False)
     # Computes per-replica loss to help understand if we are overfitting.
     loss = self.build_losses(labels=inputs["targets"], model_outputs=outputs)
     inputs.pop("targets")
     # Beam search to calculate metrics.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/translation_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/translation_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for official.nlp.tasks.translation."""
 import functools
 import os
 
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from sentencepiece import SentencePieceTrainer
 from official.nlp.data import wmt_dataloader
 from official.nlp.tasks import translation
 
 
 def _generate_line_file(filepath, lines):
@@ -93,15 +93,15 @@
             is_training=True, static_batch=True, global_batch_size=24,
             max_seq_length=12),
         sentencepiece_model_path=self._sentencepeice_model_path)
     task = translation.TranslationTask(config)
     model = task.build_model()
     dataset = task.build_inputs(config.train_data)
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(iterator), model, optimizer)
 
   def test_no_sentencepiece_path(self):
     config = translation.TranslationConfig(
         model=translation.ModelConfig(
             encoder=translation.EncDecoder(num_layers=1),
             decoder=translation.EncDecoder(num_layers=1)),
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tasks/utils.py` & `tf-models-no-deps-2.16.0/official/nlp/tasks/utils.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,42 +12,42 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Common utils for tasks."""
 from typing import Any, Callable
 
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_hub as hub
 
 
-def get_encoder_from_hub(hub_model_path: str) -> tf.keras.Model:
+def get_encoder_from_hub(hub_model_path: str) -> tf_keras.Model:
   """Gets an encoder from hub.
 
   Args:
     hub_model_path: The path to the tfhub model.
 
   Returns:
-    A tf.keras.Model.
+    A tf_keras.Model.
   """
-  input_word_ids = tf.keras.layers.Input(
+  input_word_ids = tf_keras.layers.Input(
       shape=(None,), dtype=tf.int32, name='input_word_ids')
-  input_mask = tf.keras.layers.Input(
+  input_mask = tf_keras.layers.Input(
       shape=(None,), dtype=tf.int32, name='input_mask')
-  input_type_ids = tf.keras.layers.Input(
+  input_type_ids = tf_keras.layers.Input(
       shape=(None,), dtype=tf.int32, name='input_type_ids')
   hub_layer = hub.KerasLayer(hub_model_path, trainable=True)
   output_dict = {}
   dict_input = dict(
       input_word_ids=input_word_ids,
       input_mask=input_mask,
       input_type_ids=input_type_ids)
   output_dict = hub_layer(dict_input)
 
-  return tf.keras.Model(inputs=dict_input, outputs=output_dict)
+  return tf_keras.Model(inputs=dict_input, outputs=output_dict)
 
 
 def predict(predict_step_fn: Callable[[Any], Any],
             aggregate_fn: Callable[[Any, Any], Any], dataset: tf.data.Dataset):
   """Runs prediction.
 
   Args:
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/__init__.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/export_tfhub.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/export_tfhub.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/export_tfhub_lib.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/export_tfhub_lib.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,18 +19,18 @@
 import os
 import tempfile
 
 from typing import Optional, Text, Tuple
 
 # Import libraries
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 # pylint: disable=g-direct-tensorflow-import  TODO(b/175369555): Remove these.
 from tensorflow.core.protobuf import saved_model_pb2
-from tensorflow.python.ops import control_flow_ops
+from tensorflow.python.ops import control_flow_assert
 # pylint: enable=g-direct-tensorflow-import
 from official.legacy.bert import configs
 from official.modeling import tf_utils
 from official.nlp.configs import encoders
 from official.nlp.modeling import layers
 from official.nlp.modeling import models
 from official.nlp.modeling import networks
@@ -45,15 +45,15 @@
       num_attention_heads=bert_config.num_attention_heads,
       intermediate_size=bert_config.intermediate_size,
       activation=tf_utils.get_activation(bert_config.hidden_act),
       dropout_rate=bert_config.hidden_dropout_prob,
       attention_dropout_rate=bert_config.attention_probs_dropout_prob,
       max_sequence_length=bert_config.max_position_embeddings,
       type_vocab_size=bert_config.type_vocab_size,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=bert_config.initializer_range),
       embedding_width=bert_config.embedding_size,
       dict_outputs=True)
 
   return bert_encoder
 
 
@@ -76,15 +76,15 @@
 
 
 def _create_model(
     *,
     bert_config: Optional[configs.BertConfig] = None,
     encoder_config: Optional[encoders.EncoderConfig] = None,
     with_mlm: bool,
-) -> Tuple[tf.keras.Model, tf.keras.Model]:
+) -> Tuple[tf_keras.Model, tf_keras.Model]:
   """Creates the model to export and the model to restore the checkpoint.
 
   Args:
     bert_config: A legacy `BertConfig` to create a `BertEncoder` object. Exactly
       one of encoder_config and bert_config must be set.
     encoder_config: An `EncoderConfig` to create an encoder of the configured
       type (`BertEncoder` or other).
@@ -115,15 +115,15 @@
   else:
     # encoder.inputs by default is dict for BertEncoderV2.
     encoder_inputs_dict = encoder.inputs
   encoder_output_dict = encoder(encoder_inputs_dict)
   # For interchangeability with other text representations,
   # add "default" as an alias for BERT's whole-input reptesentations.
   encoder_output_dict["default"] = encoder_output_dict["pooled_output"]
-  core_model = tf.keras.Model(
+  core_model = tf_keras.Model(
       inputs=encoder_inputs_dict, outputs=encoder_output_dict)
 
   if with_mlm:
     if bert_config is not None:
       hidden_act = bert_config.hidden_act
     else:
       assert encoder_config is not None
@@ -134,15 +134,15 @@
         mlm_activation=tf_utils.get_activation(hidden_act))
 
     if isinstance(pretrainer.inputs, dict):
       pretrainer_inputs_dict = pretrainer.inputs
     else:
       pretrainer_inputs_dict = {x.name: x for x in pretrainer.inputs}
     pretrainer_output_dict = pretrainer(pretrainer_inputs_dict)
-    mlm_model = tf.keras.Model(
+    mlm_model = tf_keras.Model(
         inputs=pretrainer_inputs_dict, outputs=pretrainer_output_dict)
     # Set `_auto_track_sub_layers` to False, so that the additional weights
     # from `mlm` sub-object will not be included in the core model.
     # TODO(b/169210253): Use a public API when available.
     core_model._auto_track_sub_layers = False  # pylint: disable=protected-access
     core_model.mlm = mlm_model
     return core_model, pretrainer
@@ -311,15 +311,15 @@
 
 
 def create_preprocessing(*,
                          vocab_file: Optional[str] = None,
                          sp_model_file: Optional[str] = None,
                          do_lower_case: bool,
                          tokenize_with_offsets: bool,
-                         default_seq_length: int) -> tf.keras.Model:
+                         default_seq_length: int) -> tf_keras.Model:
   """Returns a preprocessing Model for given tokenization parameters.
 
   This function builds a Keras Model with attached subobjects suitable for
   saving to a SavedModel. The resulting SavedModel implements the Preprocessor
   API for Text embeddings with Transformer Encoders described at
   https://www.tensorflow.org/hub/common_saved_model_apis/text.
 
@@ -332,15 +332,15 @@
     tokenize_with_offsets: Whether to include the .tokenize_with_offsets
       subobject.
     default_seq_length: The sequence length of preprocessing results from root
       callable. This is also the default sequence length for the
       bert_pack_inputs subobject.
 
   Returns:
-    A tf.keras.Model object with several attached subobjects, suitable for
+    A tf_keras.Model object with several attached subobjects, suitable for
     saving as a preprocessing SavedModel.
   """
   # Select tokenizer.
   if bool(vocab_file) == bool(sp_model_file):
     raise ValueError("Must set exactly one of vocab_file, sp_model_file")
   if vocab_file:
     tokenize = layers.BertTokenizer(
@@ -352,41 +352,41 @@
         model_file_path=sp_model_file,
         lower_case=do_lower_case,
         strip_diacritics=True,  #  Strip diacritics to follow ALBERT model.
         tokenize_with_offsets=tokenize_with_offsets)
 
   # The root object of the preprocessing model can be called to do
   # one-shot preprocessing for users with single-sentence inputs.
-  sentences = tf.keras.layers.Input(shape=(), dtype=tf.string, name="sentences")
+  sentences = tf_keras.layers.Input(shape=(), dtype=tf.string, name="sentences")
   if tokenize_with_offsets:
     tokens, start_offsets, limit_offsets = tokenize(sentences)
   else:
     tokens = tokenize(sentences)
   pack = layers.BertPackInputs(
       seq_length=default_seq_length,
       special_tokens_dict=tokenize.get_special_tokens_dict())
   model_inputs = pack(tokens)
-  preprocessing = tf.keras.Model(sentences, model_inputs)
+  preprocessing = tf_keras.Model(sentences, model_inputs)
 
   # Individual steps of preprocessing are made available as named subobjects
   # to enable more general preprocessing. For saving, they need to be Models
   # in their own right.
-  preprocessing.tokenize = tf.keras.Model(sentences, tokens)
+  preprocessing.tokenize = tf_keras.Model(sentences, tokens)
   # Provide an equivalent to tokenize.get_special_tokens_dict().
   preprocessing.tokenize.get_special_tokens_dict = tf.train.Checkpoint()
   preprocessing.tokenize.get_special_tokens_dict.__call__ = tf.function(
       lambda: tokenize.get_special_tokens_dict(),  # pylint: disable=[unnecessary-lambda]
       input_signature=[])
   if tokenize_with_offsets:
-    preprocessing.tokenize_with_offsets = tf.keras.Model(
+    preprocessing.tokenize_with_offsets = tf_keras.Model(
         sentences, [tokens, start_offsets, limit_offsets])
     preprocessing.tokenize_with_offsets.get_special_tokens_dict = (
         preprocessing.tokenize.get_special_tokens_dict)
   # Conceptually, this should be
-  # preprocessing.bert_pack_inputs = tf.keras.Model(tokens, model_inputs)
+  # preprocessing.bert_pack_inputs = tf_keras.Model(tokens, model_inputs)
   # but technicalities require us to use a wrapper (see comments there).
   # In particular, seq_length can be overridden when calling this.
   preprocessing.bert_pack_inputs = BertPackInputsSavedModelWrapper(pack)
 
   return preprocessing
 
 
@@ -452,23 +452,23 @@
     return
   with tf.name_scope(name):
     return tf.no_op(name="dont_assert")
 
 
 @contextlib.contextmanager
 def _maybe_disable_assert(disable_assert):
-  """Scoped monkey patch of control_flow_ops.Assert to a no-op."""
+  """Scoped monkey patch of control_flow_assert.Assert to a no-op."""
   if not disable_assert:
     yield
     return
 
-  original_assert = control_flow_ops.Assert
-  control_flow_ops.Assert = _dont_assert
+  original_assert = control_flow_assert.Assert
+  control_flow_assert.Assert = _dont_assert
   yield
-  control_flow_ops.Assert = original_assert
+  control_flow_assert.Assert = original_assert
 
 
 def _check_no_assert(saved_model_path):
   """Raises AssertionError if SavedModel contains Assert ops."""
   saved_model_filename = os.path.join(saved_model_path, "saved_model.pb")
   with tf.io.gfile.GFile(saved_model_filename, "rb") as f:
     saved_model = saved_model_pb2.SavedModel.FromString(f.read())
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/export_tfhub_lib_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/export_tfhub_lib_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Tests export_tfhub_lib."""
 
 import os
 import tempfile
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow import estimator as tf_estimator
 import tensorflow_hub as hub
 import tensorflow_text as text
 
 from sentencepiece import SentencePieceTrainer
 from official.legacy.bert import configs
 from official.modeling import tf_utils
@@ -107,15 +107,15 @@
 
 def _read_asset(asset: tf.saved_model.Asset):
   return tf.io.gfile.GFile(asset.asset_path.numpy()).read()
 
 
 def _find_lambda_layers(layer):
   """Returns list of all Lambda layers in a Keras model."""
-  if isinstance(layer, tf.keras.layers.Lambda):
+  if isinstance(layer, tf_keras.layers.Lambda):
     return [layer]
   elif hasattr(layer, "layers"):  # It's nested, like a Model.
     result = []
     for l in layer.layers:
       result += _find_lambda_layers(l)
     return result
   else:
@@ -229,17 +229,17 @@
       ])
       return np.mean(np.std(outputs, axis=0))
 
     self.assertLess(_dropout_mean_stddev(training=False), 1e-6)
     self.assertGreater(_dropout_mean_stddev(training=True), 1e-3)
 
     # Test propagation of seq_length in shape inference.
-    input_word_ids = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
-    input_mask = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
-    input_type_ids = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_word_ids = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_mask = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_type_ids = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
     input_dict = dict(
         input_word_ids=input_word_ids,
         input_mask=input_mask,
         input_type_ids=input_type_ids)
     output_dict = hub_layer(input_dict)
     pooled_output = output_dict["pooled_output"]
     sequence_output = output_dict["sequence_output"]
@@ -465,17 +465,17 @@
       ])
       return np.mean(np.std(outputs, axis=0))
 
     self.assertLess(_dropout_mean_stddev_mlm(training=False), 1e-6)
     self.assertGreater(_dropout_mean_stddev_mlm(training=True), 1e-3)
 
     # Test propagation of seq_length in shape inference.
-    input_word_ids = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
-    input_mask = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
-    input_type_ids = tf.keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_word_ids = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_mask = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
+    input_type_ids = tf_keras.layers.Input(shape=(seq_length,), dtype=tf.int32)
     input_dict = dict(
         input_word_ids=input_word_ids,
         input_mask=input_mask,
         input_type_ids=input_type_ids)
     hub_outputs_dict = hub_layer(input_dict)
     self.assertEqual(hub_outputs_dict["pooled_output"].shape.as_list(),
                      [None, hidden_size])
@@ -1002,25 +1002,25 @@
           k: v.item()  # Numpy to Python.
           for k, v in special_tokens_numpy.items()
       }
 
     def input_fn():
       self.assertFalse(tf.executing_eagerly())
       # Build a preprocessing Model.
-      sentences = tf.keras.layers.Input(shape=[], dtype=tf.string)
+      sentences = tf_keras.layers.Input(shape=[], dtype=tf.string)
       preprocess = tf.saved_model.load(preprocess_export_path)
       tokenize = hub.KerasLayer(preprocess.tokenize)
       special_tokens_dict = _get_special_tokens_dict(tokenize.resolved_object)
       for k, v in special_tokens_dict.items():
         self.assertIsInstance(v, int, "Unexpected type for {}".format(k))
       tokens = tokenize(sentences)
       packed_inputs = layers.BertPackInputs(
           4, special_tokens_dict=special_tokens_dict)(
               tokens)
-      preprocessing = tf.keras.Model(sentences, packed_inputs)
+      preprocessing = tf_keras.Model(sentences, packed_inputs)
       # Map the dataset.
       ds = tf.data.Dataset.from_tensors(
           (tf.constant(["abc", "D EF"]), tf.constant([0, 1])))
       ds = ds.map(lambda features, labels: (preprocessing(features), labels))
       return ds
 
     def model_fn(features, labels, mode):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/squad_evaluate_v1_1.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/squad_evaluate_v1_1.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/squad_evaluate_v2_0.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/squad_evaluate_v2_0.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/tf1_bert_checkpoint_converter_lib.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/tf1_bert_checkpoint_converter_lib.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/tf2_albert_encoder_checkpoint_converter.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/tf2_albert_encoder_checkpoint_converter.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,15 +18,15 @@
 to restore an AlbertEncoder object.
 """
 import os
 
 from absl import app
 from absl import flags
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.albert import configs
 from official.modeling import tf_utils
 from official.nlp.modeling import models
 from official.nlp.modeling import networks
 from official.nlp.tools import tf1_bert_checkpoint_converter_lib
 
 FLAGS = flags.FLAGS
@@ -90,15 +90,15 @@
       num_attention_heads=cfg.num_attention_heads,
       intermediate_size=cfg.intermediate_size,
       activation=tf_utils.get_activation(cfg.hidden_act),
       dropout_rate=cfg.hidden_dropout_prob,
       attention_dropout_rate=cfg.attention_probs_dropout_prob,
       max_sequence_length=cfg.max_position_embeddings,
       type_vocab_size=cfg.type_vocab_size,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=cfg.initializer_range))
   return albert_encoder
 
 
 def _create_pretrainer_model(cfg):
   """Creates a pretrainer with AlbertEncoder from ALBERT configuration.
 
@@ -108,15 +108,15 @@
   Returns:
     A BertPretrainerV2 model.
   """
   albert_encoder = _create_albert_model(cfg)
   pretrainer = models.BertPretrainerV2(
       encoder_network=albert_encoder,
       mlm_activation=tf_utils.get_activation(cfg.hidden_act),
-      mlm_initializer=tf.keras.initializers.TruncatedNormal(
+      mlm_initializer=tf_keras.initializers.TruncatedNormal(
           stddev=cfg.initializer_range))
   # Makes sure masked_lm layer's variables in pretrainer are created.
   _ = pretrainer(pretrainer.inputs)
   return pretrainer
 
 
 def convert_checkpoint(bert_config, output_path, v1_checkpoint,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/tf2_bert_encoder_checkpoint_converter.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/tf2_bert_encoder_checkpoint_converter.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,15 +20,15 @@
 """
 
 import os
 
 from absl import app
 from absl import flags
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.legacy.bert import configs
 from official.modeling import tf_utils
 from official.nlp.modeling import models
 from official.nlp.modeling import networks
 from official.nlp.tools import tf1_bert_checkpoint_converter_lib
 
 FLAGS = flags.FLAGS
@@ -67,15 +67,15 @@
       num_attention_heads=cfg.num_attention_heads,
       intermediate_size=cfg.intermediate_size,
       activation=tf_utils.get_activation(cfg.hidden_act),
       dropout_rate=cfg.hidden_dropout_prob,
       attention_dropout_rate=cfg.attention_probs_dropout_prob,
       max_sequence_length=cfg.max_position_embeddings,
       type_vocab_size=cfg.type_vocab_size,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=cfg.initializer_range),
       embedding_width=cfg.embedding_size)
 
   return bert_encoder
 
 
 def _create_bert_pretrainer_model(cfg):
@@ -87,15 +87,15 @@
   Returns:
     A BertPretrainerV2 model.
   """
   bert_encoder = _create_bert_model(cfg)
   pretrainer = models.BertPretrainerV2(
       encoder_network=bert_encoder,
       mlm_activation=tf_utils.get_activation(cfg.hidden_act),
-      mlm_initializer=tf.keras.initializers.TruncatedNormal(
+      mlm_initializer=tf_keras.initializers.TruncatedNormal(
           stddev=cfg.initializer_range))
   # Makes sure the pretrainer variables are created.
   _ = pretrainer(pretrainer.inputs)
   return pretrainer
 
 
 def convert_checkpoint(bert_config,
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/tokenization.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/tokenization.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,15 +20,15 @@
 """
 
 import collections
 import re
 import unicodedata
 
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 import sentencepiece as spm
 
 SPIECE_UNDERLINE = "▁"
 
 
 def validate_case_matches_checkpoint(do_lower_case, init_checkpoint):
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/tools/tokenization_test.py` & `tf-models-no-deps-2.16.0/official/nlp/tools/tokenization_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import os
 import tempfile
 
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.tools import tokenization
 
 
 class TokenizationTest(tf.test.TestCase):
   """Tokenization test.
```

### Comparing `tf-models-no-deps-2.11.2/official/nlp/train.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/train.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,82 +1,69 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""TFM common training driver."""
+"""A customized training library for the specific task."""
 
 from absl import app
 from absl import flags
 import gin
 
 from official.common import distribute_utils
-# pylint: disable=unused-import
-from official.common import registry_imports
-# pylint: enable=unused-import
 from official.common import flags as tfm_flags
 from official.core import task_factory
 from official.core import train_lib
 from official.core import train_utils
 from official.modeling import performance
-from official.nlp import continuous_finetune_lib
+from official.projects.roformer import roformer_experiments  # pylint: disable=unused-import
 
 FLAGS = flags.FLAGS
 
-flags.DEFINE_integer(
-    'pretrain_steps',
-    default=None,
-    help='The number of total training steps for the pretraining job.')
-
 
 def main(_):
   gin.parse_config_files_and_bindings(FLAGS.gin_file, FLAGS.gin_params)
   params = train_utils.parse_configuration(FLAGS)
   model_dir = FLAGS.model_dir
   if 'train' in FLAGS.mode:
     # Pure eval modes do not output yaml files. Otherwise continuous eval job
     # may race against the train job for writing the same file.
     train_utils.serialize_config(params, model_dir)
 
-  if FLAGS.mode == 'continuous_train_and_eval':
-    continuous_finetune_lib.run_continuous_finetune(
-        FLAGS.mode, params, model_dir, pretrain_steps=FLAGS.pretrain_steps)
-
-  else:
-    # Sets mixed_precision policy. Using 'mixed_float16' or 'mixed_bfloat16'
-    # can have significant impact on model speeds by utilizing float16 in case
-    # of GPUs, and bfloat16 in the case of TPUs. loss_scale takes effect only
-    # when dtype is float16
-    if params.runtime.mixed_precision_dtype:
-      performance.set_mixed_precision_policy(
-          params.runtime.mixed_precision_dtype)
-    distribution_strategy = distribute_utils.get_distribution_strategy(
-        distribution_strategy=params.runtime.distribution_strategy,
-        all_reduce_alg=params.runtime.all_reduce_alg,
-        num_gpus=params.runtime.num_gpus,
-        tpu_address=params.runtime.tpu,
-        **params.runtime.model_parallelism())
-    with distribution_strategy.scope():
-      task = task_factory.get_task(params.task, logging_dir=model_dir)
-
-    train_lib.run_experiment(
-        distribution_strategy=distribution_strategy,
-        task=task,
-        mode=FLAGS.mode,
-        params=params,
-        model_dir=model_dir)
+  # Sets mixed_precision policy. Using 'mixed_float16' or 'mixed_bfloat16'
+  # can have significant impact on model speeds by utilizing float16 in case of
+  # GPUs, and bfloat16 in the case of TPUs. loss_scale takes effect only when
+  # dtype is float16
+  if params.runtime.mixed_precision_dtype:
+    performance.set_mixed_precision_policy(params.runtime.mixed_precision_dtype)
+  distribution_strategy = distribute_utils.get_distribution_strategy(
+      distribution_strategy=params.runtime.distribution_strategy,
+      all_reduce_alg=params.runtime.all_reduce_alg,
+      num_gpus=params.runtime.num_gpus,
+      tpu_address=params.runtime.tpu,
+      **params.runtime.model_parallelism())
+
+  with distribution_strategy.scope():
+    task = task_factory.get_task(params.task, logging_dir=model_dir)
+
+  train_lib.run_experiment(
+      distribution_strategy=distribution_strategy,
+      task=task,
+      mode=FLAGS.mode,
+      params=params,
+      model_dir=model_dir)
 
   train_utils.save_gin_config(FLAGS.mode, model_dir)
 
+
 if __name__ == '__main__':
   tfm_flags.define_flags()
-  flags.mark_flags_as_required(['experiment', 'mode', 'model_dir'])
   app.run(main)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/bigbird/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/bigbird/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/bigbird/encoder.py` & `tf-models-no-deps-2.16.0/official/projects/bigbird/encoder.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,17 +11,18 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Transformer-based text encoder network."""
 # pylint: disable=g-classes-have-attributes
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import activations
+from official.modeling import tf_utils
 from official.nlp import modeling
 from official.nlp.modeling import layers
 from official.projects.bigbird import recompute_grad
 from official.projects.bigbird import recomputing_dropout
 
 
 _MAX_SEQ_LEN = 4096
@@ -46,16 +47,16 @@
       return x
 
     f = recompute_grad.recompute_grad(f)
 
     return f(emb, *mask)
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class BigBirdEncoder(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class BigBirdEncoder(tf_keras.Model):
   """Transformer-based encoder network with BigBird attentions.
 
   *Note* that the network is constructed by
   [Keras Functional API](https://keras.io/guides/functional_api/).
 
   Args:
     vocab_size: The size of the token vocabulary.
@@ -96,23 +97,23 @@
                type_vocab_size=16,
                intermediate_size=3072,
                block_size=64,
                num_rand_blocks=3,
                activation=activations.gelu,
                dropout_rate=0.1,
                attention_dropout_rate=0.1,
-               initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+               initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
                embedding_width=None,
                use_gradient_checkpointing=False,
                **kwargs):
-    activation = tf.keras.activations.get(activation)
-    initializer = tf.keras.initializers.get(initializer)
+    activation = tf_keras.activations.get(activation)
+    initializer = tf_keras.initializers.get(initializer)
 
     if use_gradient_checkpointing:
-      tf.keras.layers.Dropout = recomputing_dropout.RecomputingDropout
+      tf_keras.layers.Dropout = recomputing_dropout.RecomputingDropout
       layer_cls = RecomputeTransformerLayer
     else:
       layer_cls = layers.TransformerScaffold
 
     self._self_setattr_tracking = False
     self._config_dict = {
         'vocab_size': vocab_size,
@@ -120,26 +121,30 @@
         'num_layers': num_layers,
         'num_attention_heads': num_attention_heads,
         'max_position_embeddings': max_position_embeddings,
         'type_vocab_size': type_vocab_size,
         'intermediate_size': intermediate_size,
         'block_size': block_size,
         'num_rand_blocks': num_rand_blocks,
-        'activation': tf.keras.activations.serialize(activation),
+        'activation': tf_utils.serialize_activation(
+            activation, use_legacy_format=True
+        ),
         'dropout_rate': dropout_rate,
         'attention_dropout_rate': attention_dropout_rate,
-        'initializer': tf.keras.initializers.serialize(initializer),
+        'initializer': tf_utils.serialize_initializer(
+            initializer, use_legacy_format=True
+        ),
         'embedding_width': embedding_width,
     }
 
-    word_ids = tf.keras.layers.Input(
+    word_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_word_ids')
-    mask = tf.keras.layers.Input(
+    mask = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_mask')
-    type_ids = tf.keras.layers.Input(
+    type_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_type_ids')
 
     if embedding_width is None:
       embedding_width = hidden_size
     self._embedding_layer = modeling.layers.OnDeviceEmbedding(
         vocab_size=vocab_size,
         embedding_width=embedding_width,
@@ -157,27 +162,27 @@
         vocab_size=type_vocab_size,
         embedding_width=embedding_width,
         initializer=initializer,
         use_one_hot=True,
         name='type_embeddings')
     type_embeddings = self._type_embedding_layer(type_ids)
 
-    embeddings = tf.keras.layers.Add()(
+    embeddings = tf_keras.layers.Add()(
         [word_embeddings, position_embeddings, type_embeddings])
 
-    self._embedding_norm_layer = tf.keras.layers.LayerNormalization(
+    self._embedding_norm_layer = tf_keras.layers.LayerNormalization(
         name='embeddings/layer_norm', axis=-1, epsilon=1e-12, dtype=tf.float32)
 
     embeddings = self._embedding_norm_layer(embeddings)
-    embeddings = tf.keras.layers.Dropout(rate=dropout_rate)(embeddings)
+    embeddings = tf_keras.layers.Dropout(rate=dropout_rate)(embeddings)
 
     # We project the 'embedding' output to 'hidden_size' if it is not already
     # 'hidden_size'.
     if embedding_width != hidden_size:
-      self._embedding_projection = tf.keras.layers.EinsumDense(
+      self._embedding_projection = tf_keras.layers.EinsumDense(
           '...x,xy->...y',
           output_shape=hidden_size,
           bias_axes='y',
           kernel_initializer=initializer,
           name='embedding_projection')
       embeddings = self._embedding_projection(embeddings)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/bigbird/encoder_test.py` & `tf-models-no-deps-2.16.0/official/projects/bigbird/encoder_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.nlp.projects.bigbird.encoder."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.bigbird import encoder
 
 
 class BigBirdEncoderTest(tf.test.TestCase):
 
   def test_encoder(self):
@@ -49,15 +49,15 @@
     inputs = dict(
         input_word_ids=word_id_data,
         input_mask=mask_data,
         input_type_ids=type_id_data)
     ref_outputs = network(inputs)
     model_path = self.get_temp_dir() + "/model"
     network.save(model_path)
-    loaded = tf.keras.models.load_model(model_path)
+    loaded = tf_keras.models.load_model(model_path)
     outputs = loaded(inputs)
     self.assertAllClose(outputs["sequence_output"],
                         ref_outputs["sequence_output"])
 
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/bigbird/experiment_configs.py` & `tf-models-no-deps-2.16.0/official/projects/bigbird/experiment_configs.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/bigbird/recompute_grad.py` & `tf-models-no-deps-2.16.0/official/projects/bigbird/recompute_grad.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,15 +19,15 @@
 import collections
 import os
 import threading
 from typing import Deque, List, NamedTuple, Optional, Sequence
 
 from absl import logging
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class RecomputeContext(
     NamedTuple('RecomputeContext', [
         ('is_recomputing', bool),
         ('seed', tf.Tensor),
         ('children', Deque['RecomputeContext']),
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/bigbird/recomputing_dropout.py` & `tf-models-no-deps-2.16.0/official/projects/bigbird/recomputing_dropout.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Keras dropout layer that is aware of `RecomputeContext`."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.bigbird import recompute_grad as recompute_grad_lib
 from official.projects.bigbird import stateless_dropout as stateless_dropout_lib
 
 
 # Reimplements internal function
 # https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/smart_cond.py.
@@ -53,16 +53,16 @@
   if pred_value:
     return true_fn()
   else:
     return false_fn()
 
 
 # See https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout.
-class RecomputingDropout(tf.keras.layers.Layer):
-  """`tf.keras.layers.Dropout` that supports `recompute_grad`."""
+class RecomputingDropout(tf_keras.layers.Layer):
+  """`tf_keras.layers.Dropout` that supports `recompute_grad`."""
 
   def __init__(self,
                rate,
                noise_shape=None,
                seed=None,
                force_recomputation=False,
                **kwargs):
@@ -74,15 +74,15 @@
         dropout mask that will be multiplied with the input. For instance, if
         inputs have shape `(batch_size, timesteps, features)` and you want the
         dropout mask to be the same for all timesteps, you can use
         `noise_shape=(batch_size, 1, features)`.
       seed: A Python integer to use as random seed.
       force_recomputation: If `True`, then raises an error if called outside a
         recompute context.
-      **kwargs: Keyword arguments for `tf.keras.layers.Layer`.
+      **kwargs: Keyword arguments for `tf_keras.layers.Layer`.
     """
 
     super(RecomputingDropout, self).__init__(**kwargs)
     self.rate = rate
     self.noise_shape = noise_shape
     self.seed = seed
     self.force_recomputation = force_recomputation
@@ -117,15 +117,15 @@
       `inputs` masked according to layer configuration.
 
     Raises:
       ValueError: If `force_recomputation` is `True` and called outside a
         a recompute context.
     """
     if training is None:
-      training = tf.keras.backend.learning_phase()
+      training = tf_keras.backend.learning_phase()
 
     def dropped_inputs():
       """Randomly drops elements of `inputs` when `training=True`."""
       recompute_context = recompute_grad_lib.get_recompute_context()
       if recompute_context is None:
         if self.force_recomputation:
           raise ValueError(
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/bigbird/stateless_dropout.py` & `tf-models-no-deps-2.16.0/official/projects/bigbird/stateless_dropout.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """A replacement for tf.nn.dropout that uses stateless random ops."""
 
 import numbers
 from typing import Optional, Sequence, Text, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _as_shape(shape: Union[Sequence[int], tf.TensorShape]) -> tf.TensorShape:
   """Converts the given object to a TensorShape."""
   return shape if isinstance(shape, tf.TensorShape) else tf.TensorShape(shape)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/common/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/common/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/common/registry_imports.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/common/registry_imports.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/configs/backbones.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/configs/backbones.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -28,8 +28,8 @@
   num_hourglasses: int = 2
   initial_downsample: bool = True
   activation: str = 'relu'
 
 
 @dataclasses.dataclass
 class Backbone(backbones.Backbone):
-  hourglass: Hourglass = Hourglass()
+  hourglass: Hourglass = dataclasses.field(default_factory=Hourglass)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/configs/centernet.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/configs/centernet.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -33,16 +33,20 @@
 class TfExampleDecoder(hyperparams.Config):
   regenerate_source_id: bool = False
 
 
 @dataclasses.dataclass
 class DataDecoder(hyperparams.OneOfConfig):
   type: Optional[str] = 'simple_decoder'
-  simple_decoder: TfExampleDecoder = TfExampleDecoder()
-  label_map_decoder: TfExampleDecoderLabelMap = TfExampleDecoderLabelMap()
+  simple_decoder: TfExampleDecoder = dataclasses.field(
+      default_factory=TfExampleDecoder
+  )
+  label_map_decoder: TfExampleDecoderLabelMap = dataclasses.field(
+      default_factory=TfExampleDecoderLabelMap
+  )
 
 
 @dataclasses.dataclass
 class Parser(hyperparams.Config):
   """Config for parser."""
   bgr_ordering: bool = True
   aug_rand_hflip: bool = True
@@ -62,31 +66,31 @@
 @dataclasses.dataclass
 class DataConfig(cfg.DataConfig):
   """Input config for training."""
   input_path: str = ''
   global_batch_size: int = 32
   is_training: bool = True
   dtype: str = 'float16'
-  decoder: DataDecoder = DataDecoder()
-  parser: Parser = Parser()
+  decoder: DataDecoder = dataclasses.field(default_factory=DataDecoder)
+  parser: Parser = dataclasses.field(default_factory=Parser)
   shuffle_buffer_size: int = 10000
   file_type: str = 'tfrecord'
   drop_remainder: bool = True
 
 
 @dataclasses.dataclass
 class DetectionLoss(hyperparams.Config):
   object_center_weight: float = 1.0
   offset_weight: float = 1.0
   scale_weight: float = 0.1
 
 
 @dataclasses.dataclass
 class Losses(hyperparams.Config):
-  detection: DetectionLoss = DetectionLoss()
+  detection: DetectionLoss = dataclasses.field(default_factory=DetectionLoss)
   gaussian_iou: float = 0.7
   class_offset: int = 1
 
 
 @dataclasses.dataclass
 class CenterNetHead(hyperparams.Config):
   heatmap_bias: float = -2.19
@@ -108,42 +112,58 @@
 
 @dataclasses.dataclass
 class CenterNetModel(hyperparams.Config):
   """Config for centernet model."""
   num_classes: int = 90
   max_num_instances: int = 128
   input_size: List[int] = dataclasses.field(default_factory=list)
-  backbone: backbones.Backbone = backbones.Backbone(
-      type='hourglass', hourglass=backbones.Hourglass(model_id=52))
-  head: CenterNetHead = CenterNetHead()
+  backbone: backbones.Backbone = dataclasses.field(
+      default_factory=lambda: backbones.Backbone(  # pylint: disable=g-long-lambda
+          type='hourglass', hourglass=backbones.Hourglass(model_id=52)
+      )
+  )
+  head: CenterNetHead = dataclasses.field(default_factory=CenterNetHead)
   # pylint: disable=line-too-long
-  detection_generator: CenterNetDetectionGenerator = CenterNetDetectionGenerator()
-  norm_activation: common.NormActivation = common.NormActivation(
-      norm_momentum=0.1, norm_epsilon=1e-5, use_sync_bn=True)
+  detection_generator: CenterNetDetectionGenerator = dataclasses.field(
+      default_factory=CenterNetDetectionGenerator
+  )
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=lambda: common.NormActivation(  # pylint: disable=g-long-lambda
+          norm_momentum=0.1, norm_epsilon=1e-5, use_sync_bn=True
+      )
+  )
 
 
 @dataclasses.dataclass
 class CenterNetDetection(hyperparams.Config):
   # use_center is the only option implemented currently.
   use_centers: bool = True
 
 
 @dataclasses.dataclass
 class CenterNetSubTasks(hyperparams.Config):
-  detection: CenterNetDetection = CenterNetDetection()
+  detection: CenterNetDetection = dataclasses.field(
+      default_factory=CenterNetDetection
+  )
 
 
 @dataclasses.dataclass
 class CenterNetTask(cfg.TaskConfig):
   """Config for centernet task."""
-  model: CenterNetModel = CenterNetModel()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(is_training=False)
-  subtasks: CenterNetSubTasks = CenterNetSubTasks()
-  losses: Losses = Losses()
+  model: CenterNetModel = dataclasses.field(default_factory=CenterNetModel)
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=False)
+  )
+  subtasks: CenterNetSubTasks = dataclasses.field(
+      default_factory=CenterNetSubTasks
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
   gradient_clip_norm: float = 10.0
   per_category_metrics: bool = False
   weight_decay: float = 5e-4
   # Load checkpoints
   init_checkpoint: Optional[str] = None
   init_checkpoint_modules: str = 'all'
   annotation_file: Optional[str] = None
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/configs/centernet_test.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/configs/centernet_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for centernet."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.projects.centernet.common import registry_imports  # pylint: disable=unused-import
 from official.projects.centernet.configs import centernet as exp_cfg
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/dataloaders/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/dataloaders/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/dataloaders/centernet_input.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/dataloaders/centernet_input.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Data parser and processing for Centernet."""
 
 from typing import Tuple
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.ops import box_list
 from official.projects.centernet.ops import box_list_ops
 from official.projects.centernet.ops import preprocess_ops as cn_prep_ops
 from official.vision.dataloaders import parser
 from official.vision.dataloaders import utils
 from official.vision.ops import box_ops
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/losses/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/losses/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/losses/centernet_losses.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/losses/centernet_losses.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Losses for centernet model."""
 
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class PenaltyReducedLogisticFocalLoss(object):
   """Penalty-reduced pixelwise logistic regression with focal loss."""
 
   def __init__(self, alpha=2.0, beta=4.0, sigmoid_clip_value=1e-4):
     """Constructor.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/losses/centernet_losses_test.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/losses/centernet_losses_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for losses of centernet model."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.losses import centernet_losses
 
 LOG_2 = np.log(2)
 LOG_3 = np.log(3)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/backbones/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/backbones/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/backbones/hourglass.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/backbones/hourglass.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Build Hourglass backbone."""
 
 from typing import Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.projects.centernet.modeling.layers import cn_nn_blocks
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.backbones import mobilenet
 from official.vision.modeling.layers import nn_blocks
 
@@ -44,50 +44,50 @@
     100: {
         'blocks_per_stage': [4, 4, 4, 4, 4, 8],
         'channel_dims_per_stage': [2, 2, 3, 3, 3, 4]
     },
 }
 
 
-class Hourglass(tf.keras.Model):
+class Hourglass(tf_keras.Model):
   """CenterNet Hourglass backbone."""
 
   def __init__(
       self,
       model_id: int,
       input_channel_dims: int,
-      input_specs=tf.keras.layers.InputSpec(shape=[None, None, None, 3]),
+      input_specs=tf_keras.layers.InputSpec(shape=[None, None, None, 3]),
       num_hourglasses: int = 1,
       initial_downsample: bool = True,
       activation: str = 'relu',
       use_sync_bn: bool = True,
       norm_momentum=0.1,
       norm_epsilon=1e-5,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
     """Initialize Hourglass backbone.
 
     Args:
       model_id: An `int` of the scale of Hourglass backbone model.
       input_channel_dims: `int`, number of filters used to downsample the
         input image.
-      input_specs: A `tf.keras.layers.InputSpec` of specs of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of specs of the input tensor.
       num_hourglasses: `int``, number of hourglass blocks in backbone. For
         example, hourglass-104 has two hourglass-52 modules.
       initial_downsample: `bool`, whether or not to downsample the input.
       activation: A `str` name of the activation function.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: `float`, momentum for the batch normalization layers.
       norm_epsilon: `float`, epsilon for the batch normalization layers.
       kernel_initializer: A `str` for kernel initializer of conv layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._input_channel_dims = input_channel_dims
     self._model_id = model_id
     self._num_hourglasses = num_hourglasses
     self._initial_downsample = initial_downsample
@@ -100,15 +100,15 @@
     self._norm_epsilon = norm_epsilon
 
     specs = HOURGLASS_SPECS[model_id]
     self._blocks_per_stage = specs['blocks_per_stage']
     self._channel_dims_per_stage = [item * self._input_channel_dims
                                     for item in specs['channel_dims_per_stage']]
 
-    inputs = tf.keras.layers.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.layers.Input(shape=input_specs.shape[1:])
 
     inp_filters = self._channel_dims_per_stage[0]
 
     # Downsample the input
     if initial_downsample:
       prelayer_kernel_size = 7
       prelayer_strides = 2
@@ -199,16 +199,16 @@
             kernel_initializer=self._kernel_initializer,
             kernel_regularizer=self._kernel_regularizer,
             use_sync_bn=self._use_sync_bn,
             norm_momentum=self._norm_momentum,
             norm_epsilon=self._norm_epsilon
         )(x_hg)
 
-        x_downsampled = tf.keras.layers.Add()([inter_hg_conv1, inter_hg_conv2])
-        x_downsampled = tf.keras.layers.ReLU()(x_downsampled)
+        x_downsampled = tf_keras.layers.Add()([inter_hg_conv1, inter_hg_conv2])
+        x_downsampled = tf_keras.layers.ReLU()(x_downsampled)
 
         x_downsampled = nn_blocks.ResidualBlock(
             filters=inp_filters,
             use_projection=False,
             use_explicit_padding=True,
             strides=1,
             bias_regularizer=self._bias_regularizer,
@@ -246,19 +246,19 @@
   @property
   def output_specs(self):
     return self._output_specs
 
 
 @factory.register_backbone_builder('hourglass')
 def build_hourglass(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None
-    ) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None
+    ) -> tf_keras.Model:
   """Builds Hourglass backbone from a configuration."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'hourglass', (f'Inconsistent backbone type '
                                         f'{backbone_type}')
 
   return Hourglass(
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/backbones/hourglass_test.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/backbones/hourglass_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,27 +12,27 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for hourglass module."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.common import registry_imports  # pylint: disable=unused-import
 from official.projects.centernet.configs import backbones
 from official.projects.centernet.modeling.backbones import hourglass
 from official.vision.configs import common
 
 
 class HourglassTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_hourglass(self):
     backbone = hourglass.build_hourglass(
-        input_specs=tf.keras.layers.InputSpec(shape=[None, 512, 512, 3]),
+        input_specs=tf_keras.layers.InputSpec(shape=[None, 512, 512, 3]),
         backbone_config=backbones.Backbone(type='hourglass'),
         norm_activation_config=common.NormActivation(use_sync_bn=True)
     )
     inputs = np.zeros((2, 512, 512, 3), dtype=np.float32)
     outputs = backbone(inputs)
     self.assertEqual(outputs['2_0'].shape, (2, 128, 128, 256))
     self.assertEqual(outputs['2'].shape, (2, 128, 128, 256))
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/centernet_model.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/centernet_model.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,24 +12,24 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Centernet detection models."""
 
 from typing import Mapping, Union, Any
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-class CenterNetModel(tf.keras.Model):
+class CenterNetModel(tf_keras.Model):
   """CenterNet Model."""
 
   def __init__(self,
-               backbone: tf.keras.Model,
-               head: tf.keras.Model,
-               detection_generator: tf.keras.layers.Layer,
+               backbone: tf_keras.Model,
+               head: tf_keras.Model,
+               detection_generator: tf_keras.layers.Layer,
                **kwargs):
     """CenterNet Model.
 
     Args:
       backbone: a backbone network.
       head: a projection head for centernet.
       detection_generator: a detection generator for centernet.
@@ -37,29 +37,29 @@
     """
     super(CenterNetModel, self).__init__(**kwargs)
     # model components
     self._backbone = backbone
     self._detection_generator = detection_generator
     self._head = head
 
-  def call(self,
+  def call(self,  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
            inputs: tf.Tensor,
            training: bool = None,
            **kwargs) -> Mapping[str, tf.Tensor]:
     features = self._backbone(inputs)
     raw_outputs = self._head(features)
     model_outputs = {'raw_output': raw_outputs}
     if not training:
       predictions = self._detection_generator(raw_outputs)
       model_outputs.update(predictions)
     return model_outputs
 
   @property
   def checkpoint_items(
-      self) -> Mapping[str, Union[tf.keras.Model, tf.keras.layers.Layer]]:
+      self) -> Mapping[str, Union[tf_keras.Model, tf_keras.layers.Layer]]:
     """Returns a dictionary of items to be additionally checkpointed."""
     items = dict(backbone=self.backbone, head=self.head)
 
     return items
 
   @property
   def backbone(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/centernet_model_test.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/centernet_model_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,29 +11,29 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Test for centernet detection model."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.configs import backbones
 from official.projects.centernet.modeling import centernet_model
 from official.projects.centernet.modeling.backbones import hourglass
 from official.projects.centernet.modeling.heads import centernet_head
 from official.projects.centernet.modeling.layers import detection_generator
 from official.vision.configs import common
 
 
 class CenterNetTest(parameterized.TestCase, tf.test.TestCase):
 
   def testBuildCenterNet(self):
     backbone = hourglass.build_hourglass(
-        input_specs=tf.keras.layers.InputSpec(shape=[None, 512, 512, 3]),
+        input_specs=tf_keras.layers.InputSpec(shape=[None, 512, 512, 3]),
         backbone_config=backbones.Backbone(type='hourglass'),
         norm_activation_config=common.NormActivation(use_sync_bn=True)
     )
 
     task_config = {
         'ct_heatmaps': 90,
         'ct_offset': 2,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/heads/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/heads/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/heads/centernet_head.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/heads/centernet_head.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,20 +12,20 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains the definitions of head for CenterNet."""
 
 from typing import Any, Dict, List, Mapping
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.modeling.layers import cn_nn_blocks
 
 
-class CenterNetHead(tf.keras.Model):
+class CenterNetHead(tf_keras.Model):
   """CenterNet Head."""
 
   def __init__(self,
                input_specs: Dict[str, tf.TensorShape],
                task_outputs: Mapping[str, int],
                input_levels: List[str],
                heatmap_bias: float = -2.19,
@@ -57,15 +57,15 @@
 
     self._input_specs = input_specs
     self._task_outputs = task_outputs
     self._input_levels = input_levels
     self._heatmap_bias = heatmap_bias
     self._num_inputs = len(input_levels)
 
-    inputs = {level: tf.keras.layers.Input(shape=self._input_specs[level][1:])
+    inputs = {level: tf_keras.layers.Input(shape=self._input_specs[level][1:])
               for level in input_levels}
     outputs = {}
 
     for key in self._task_outputs:
       # pylint: disable=g-complex-comprehension
       outputs[key] = [
           cn_nn_blocks.CenterNetHeadConv(
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/heads/centernet_head_test.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/heads/centernet_head_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,30 +12,30 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Centernet Head."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.modeling.heads import centernet_head
 
 
 class CenterNetHeadTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_decoder_shape(self):
     task_config = {
         'ct_heatmaps': 90,
         'ct_offset': 2,
         'ct_size': 2,
     }
     input_specs = {
-        '2_0': tf.keras.layers.InputSpec(shape=(None, 128, 128, 256)).shape,
-        '2': tf.keras.layers.InputSpec(shape=(None, 128, 128, 256)).shape,
+        '2_0': tf_keras.layers.InputSpec(shape=(None, 128, 128, 256)).shape,
+        '2': tf_keras.layers.InputSpec(shape=(None, 128, 128, 256)).shape,
     }
 
     input_levels = ['2', '2_0']
 
     head = centernet_head.CenterNetHead(
         task_outputs=task_config,
         input_specs=input_specs,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/cn_nn_blocks.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/cn_nn_blocks.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains common building blocks for centernet neural networks."""
 
 from typing import List, Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.layers import nn_blocks
 
 
 def _apply_blocks(inputs, blocks):
   """Apply blocks to inputs."""
   net = inputs
@@ -37,16 +37,16 @@
     use_sync_bn: bool = True,
     norm_momentum: float = 0.1,
     norm_epsilon: float = 1e-5,
     residual_channels: Optional[int] = None,
     initial_stride: int = 1,
     initial_skip_conv: bool = False,
     kernel_initializer: str = 'VarianceScaling',
-    kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-    bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+    kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+    bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
 ):
   """Stack Residual blocks one after the other.
 
   Args:
     reps: `int` for desired number of residual blocks
     out_channels: `int`, filter depth of the final residual block
     use_sync_bn: A `bool`, if True, use synchronized batch normalization.
@@ -57,17 +57,17 @@
       equal to out_channels, then uses a projection shortcut in the final
       residual block
     initial_stride: `int`, stride for the first residual block
     initial_skip_conv: `bool`, if set, the first residual block uses a skip
       convolution. This is useful when the number of channels in the input
       are not the same as residual_channels.
     kernel_initializer: A `str` for kernel initializer of convolutional layers.
-    kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+    kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
       Conv2D. Default to None.
-    bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+    bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
       Default to None.
 
   Returns:
     blocks: A list of residual blocks to be applied in sequence.
   """
   blocks = []
 
@@ -116,31 +116,31 @@
       use_sync_bn=use_sync_bn,
       norm_momentum=norm_momentum,
       norm_epsilon=norm_epsilon,
       kernel_initializer=kernel_initializer,
       kernel_regularizer=kernel_regularizer,
       bias_regularizer=bias_regularizer))
 
-  return tf.keras.Sequential(blocks)
+  return tf_keras.Sequential(blocks)
 
 
-class HourglassBlock(tf.keras.layers.Layer):
+class HourglassBlock(tf_keras.layers.Layer):
   """Hourglass module: an encoder-decoder block."""
 
   def __init__(
       self,
       channel_dims_per_stage: List[int],
       blocks_per_stage: List[int],
       strides: int = 1,
       use_sync_bn: bool = True,
       norm_momentum: float = 0.1,
       norm_epsilon: float = 1e-5,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
     """Initialize Hourglass module.
 
     Args:
       channel_dims_per_stage: List[int], list of filter sizes for Residual
         blocks. the output channels dimensions of stages in
         the network. `channel_dims[0]` is used to define the number of
@@ -154,17 +154,17 @@
         current stage and `blocks_per_stage[1:]` is used at further stages.
         For example, [2, 2, 2, 2, 2, 4].
       strides: `int`, stride parameter to the Residual block.
       use_sync_bn: A `bool`, if True, use synchronized batch normalization.
       norm_momentum: `float`, momentum for the batch normalization layers.
       norm_epsilon: `float`, epsilon for the batch normalization layers.
       kernel_initializer: A `str` for kernel initializer of conv layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       **kwargs: Additional keyword arguments to be passed.
     """
     super(HourglassBlock, self).__init__(**kwargs)
 
     if len(channel_dims_per_stage) != len(blocks_per_stage):
       raise ValueError('filter size and residual block repetition '
@@ -237,15 +237,15 @@
           out_channels=self._filters,
           use_sync_bn=self._use_sync_bn,
           norm_epsilon=self._norm_epsilon,
           bias_regularizer=self._bias_regularizer,
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer)
 
-      self.upsample_layer = tf.keras.layers.UpSampling2D(
+      self.upsample_layer = tf_keras.layers.UpSampling2D(
           size=2,
           interpolation='nearest')
 
     super(HourglassBlock, self).build(input_shape)
 
   def call(self, x, training=None):
     if self._num_stages == 0:
@@ -269,15 +269,15 @@
         'kernel_regularizer': self._kernel_regularizer,
         'bias_regularizer': self._bias_regularizer,
     }
     config.update(super(HourglassBlock, self).get_config())
     return config
 
 
-class CenterNetHeadConv(tf.keras.layers.Layer):
+class CenterNetHeadConv(tf_keras.layers.Layer):
   """Convolution block for the CenterNet head."""
 
   def __init__(self,
                output_filters: int,
                bias_init: float,
                name: str,
                **kwargs):
@@ -293,23 +293,23 @@
     super(CenterNetHeadConv, self).__init__(name=name, **kwargs)
     self._output_filters = output_filters
     self._bias_init = bias_init
 
   def build(self, input_shape):
     n_channels = input_shape[-1]
 
-    self.conv1 = tf.keras.layers.Conv2D(
+    self.conv1 = tf_keras.layers.Conv2D(
         filters=n_channels,
         kernel_size=(3, 3),
         padding='same')
 
-    self.relu = tf.keras.layers.ReLU()
+    self.relu = tf_keras.layers.ReLU()
 
     # Initialize bias to the last Conv2D Layer
-    self.conv2 = tf.keras.layers.Conv2D(
+    self.conv2 = tf_keras.layers.Conv2D(
         filters=self._output_filters,
         kernel_size=(1, 1),
         padding='valid',
         bias_initializer=tf.constant_initializer(self._bias_init))
     super(CenterNetHeadConv, self).build(input_shape)
 
   def call(self, x, training=None):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/cn_nn_blocks_test.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/cn_nn_blocks_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,21 +15,21 @@
 """Tests for Centernet nn_blocks.
 
 It is a literal translation of the PyTorch implementation.
 """
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.modeling.layers import cn_nn_blocks
 from official.vision.modeling.layers import nn_blocks
 
 
-class HourglassBlockPyTorch(tf.keras.layers.Layer):
+class HourglassBlockPyTorch(tf_keras.layers.Layer):
   """An CornerNet-style implementation of the hourglass block."""
 
   def __init__(self, dims, modules, k=0, **kwargs):
     """An CornerNet-style implementation of the hourglass block.
 
     Args:
       dims: input sizes of residual blocks
@@ -59,25 +59,25 @@
     curr_mod = modules[k]
     next_mod = modules[k + 1]
 
     curr_dim = dims[k + 0]
     next_dim = dims[k + 1]
 
     self.up1 = self.make_up_layer(3, curr_dim, curr_dim, curr_mod, **kwargs)
-    self.max1 = tf.keras.layers.MaxPool2D(strides=2)
+    self.max1 = tf_keras.layers.MaxPool2D(strides=2)
     self.low1 = self.make_hg_layer(3, curr_dim, next_dim, curr_mod, **kwargs)
     if self.n - k > 1:
       self.low2 = type(self)(dims, modules, k=k + 1, **kwargs)
     else:
       self.low2 = self.make_low_layer(
           3, next_dim, next_dim, next_mod, **kwargs)
     self.low3 = self.make_hg_layer_revr(
         3, next_dim, curr_dim, curr_mod, **kwargs)
-    self.up2 = tf.keras.layers.UpSampling2D(2)
-    self.merge = tf.keras.layers.Add()
+    self.up2 = tf_keras.layers.UpSampling2D(2)
+    self.merge = tf_keras.layers.Add()
 
     super(HourglassBlockPyTorch, self).build(input_shape)
 
   def call(self, x):
     up1 = self.up1(x)
     max1 = self.max1(x)
     low1 = self.low1(max1)
@@ -87,24 +87,24 @@
     return self.merge([up1, up2])
 
   def make_layer(self, k, inp_dim, out_dim, modules, **kwargs):
     layers = [
         nn_blocks.ResidualBlock(out_dim, 1, use_projection=True, **kwargs)]
     for _ in range(1, modules):
       layers.append(nn_blocks.ResidualBlock(out_dim, 1, **kwargs))
-    return tf.keras.Sequential(layers)
+    return tf_keras.Sequential(layers)
 
   def make_layer_revr(self, k, inp_dim, out_dim, modules, **kwargs):
     layers = []
     for _ in range(modules - 1):
       layers.append(
           nn_blocks.ResidualBlock(inp_dim, 1, **kwargs))
     layers.append(
         nn_blocks.ResidualBlock(out_dim, 1, use_projection=True, **kwargs))
-    return tf.keras.Sequential(layers)
+    return tf_keras.Sequential(layers)
 
   def make_up_layer(self, k, inp_dim, out_dim, modules, **kwargs):
     return self.make_layer(k, inp_dim, out_dim, modules, **kwargs)
 
   def make_low_layer(self, k, inp_dim, out_dim, modules, **kwargs):
     return self.make_layer(k, inp_dim, out_dim, modules, **kwargs)
 
@@ -117,15 +117,15 @@
 
 class NNBlocksTest(parameterized.TestCase, tf.test.TestCase):
 
   def test_hourglass_block(self):
     dims = [256, 256, 384, 384, 384, 512]
     modules = [2, 2, 2, 2, 2, 4]
     model = cn_nn_blocks.HourglassBlock(dims, modules)
-    test_input = tf.keras.Input((512, 512, 256))
+    test_input = tf_keras.Input((512, 512, 256))
     _ = model(test_input)
 
     filter_sizes = [256, 256, 384, 384, 384, 512]
     rep_sizes = [2, 2, 2, 2, 2, 4]
 
     hg_test_input_shape = (1, 512, 512, 256)
     # bb_test_input_shape = (1, 512, 512, 3)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/modeling/layers/detection_generator.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/modeling/layers/detection_generator.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,39 +19,42 @@
 TensorFlow Object Detection API
 in: https://github.com/tensorflow/models/blob/master/research/object_detection
 /meta_architectures/center_net_meta_arch.py
 """
 
 from typing import Any, Mapping
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.ops import loss_ops
 from official.projects.centernet.ops import nms_ops
 from official.vision.ops import box_ops
 
 
-class CenterNetDetectionGenerator(tf.keras.layers.Layer):
+class CenterNetDetectionGenerator(tf_keras.layers.Layer):
   """CenterNet Detection Generator."""
 
   def __init__(self,
-               input_image_dims: int = 512,
+               input_image_dims: tuple[int, int] | int = 512,
                net_down_scale: int = 4,
                max_detections: int = 100,
                peak_error: float = 1e-6,
                peak_extract_kernel_size: int = 3,
                class_offset: int = 1,
                use_nms: bool = False,
                nms_pre_thresh: float = 0.1,
                nms_thresh: float = 0.4,
                **kwargs):
     """Initialize CenterNet Detection Generator.
 
     Args:
-      input_image_dims: An `int` that specifies the input image size.
+      input_image_dims: The input image size. If it is a tuple of two `int`s, it
+        is the size (height, width) of the input images. If it is an `int`, the
+        input images are supposed to be squared images whose height and width
+        are equal.
       net_down_scale: An `int` that specifies stride of the output.
       max_detections: An `int` specifying the maximum number of bounding
         boxes generated. This is an upper bound, so the number of generated
         boxes may be less than this due to thresholding/non-maximum suppression.
       peak_error: A `float` for determining non-valid heatmap locations to mask.
       peak_extract_kernel_size: An `int` indicating the kernel size used when
         performing max-pool over the heatmaps to detect valid center locations
@@ -63,14 +66,17 @@
         filter the bounding boxes.
       nms_pre_thresh: A `float` for pre-nms threshold.
       nms_thresh: A `float` for nms threshold.
       **kwargs: Additional keyword arguments to be passed.
     """
     super(CenterNetDetectionGenerator, self).__init__(**kwargs)
 
+    if isinstance(input_image_dims, int):
+      input_image_dims = (input_image_dims, input_image_dims)
+
     # Object center selection parameters
     self._max_detections = max_detections
     self._peak_error = peak_error
     self._peak_extract_kernel_size = peak_extract_kernel_size
 
     # Used for adjusting class prediction
     self._class_offset = class_offset
@@ -242,18 +248,36 @@
     ymax = tf.clip_by_value(ymax, 0., tf.cast(height, ymax.dtype))
     xmax = tf.clip_by_value(xmax, 0., tf.cast(width, xmax.dtype))
     boxes = tf.stack([ymin, xmin, ymax, xmax], axis=2)
 
     return boxes, detection_classes
 
   def convert_strided_predictions_to_normalized_boxes(self, boxes: tf.Tensor):
+    """Converts strided predictions to normalized boxes.
+
+    Args:
+      boxes: A tf.Tensor of shape [batch_size, num_predictions, 4], representing
+        the strided predictions of the detected objects.
+
+    Returns:
+      A tf.Tensor of shape [batch_size, num_predictions, 4], representing
+        the normalized boxes of the detected objects.
+    """
     boxes = boxes * tf.cast(self._net_down_scale, boxes.dtype)
-    boxes = boxes / tf.cast(self._input_image_dims, boxes.dtype)
-    boxes = tf.clip_by_value(boxes, 0.0, 1.0)
-    return boxes
+
+    height = tf.cast(self._input_image_dims[0], boxes.dtype)
+    width = tf.cast(self._input_image_dims[1], boxes.dtype)
+    ymin = boxes[..., 0:1] / height
+    xmin = boxes[..., 1:2] / width
+    ymax = boxes[..., 2:3] / height
+    xmax = boxes[..., 3:4] / width
+
+    normalized_boxes = tf.concat([ymin, xmin, ymax, xmax], axis=-1)
+    normalized_boxes = tf.clip_by_value(normalized_boxes, 0.0, 1.0)
+    return normalized_boxes
 
   def __call__(self, inputs):
     # Get heatmaps from decoded outputs via final hourglass stack output
     all_ct_heatmaps = inputs['ct_heatmaps']
     all_ct_sizes = inputs['ct_size']
     all_ct_offsets = inputs['ct_offset']
 
@@ -304,16 +328,15 @@
           confidence=scores,
           k=self._max_detections,
           limit_pre_thresh=True,
           pre_nms_thresh=0.1,
           nms_thresh=0.4)
 
     num_det = tf.reduce_sum(tf.cast(scores > 0, dtype=tf.int32), axis=1)
-    boxes = box_ops.denormalize_boxes(
-        boxes, [self._input_image_dims, self._input_image_dims])
+    boxes = box_ops.denormalize_boxes(boxes, self._input_image_dims)
 
     return {
         'boxes': boxes,
         'classes': classes,
         'confidence': scores,
         'num_detections': num_det
     }
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/ops/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/ops/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/ops/box_list.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/ops/box_list.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -29,15 +29,15 @@
 
 Some other notes:
   * Following tensorflow conventions, we use height, width ordering,
   and correspondingly, y,x (or ymin, xmin, ymax, xmax) ordering
   * Tensors are always provided as (flat) [N, 4] tensors.
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _get_dim_as_int(dim):
   """Utility to get v1 or v2 TensorShape dim as an int.
 
   Args:
     dim: The TensorShape dimension to get as an int
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/ops/box_list_ops.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/ops/box_list_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Bounding Box List operations."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.ops import box_list
 from official.vision.ops import sampling_ops
 
 
 def _copy_extra_fields(boxlist_to_copy_to, boxlist_to_copy_from):
   """Copies the extra fields of boxlist_to_copy_from to boxlist_to_copy_to.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/ops/loss_ops.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/ops/loss_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Operations for compute losses for centernet."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import sampling_ops
 
 
 def _get_shape(tensor, num_dims):
   assert len(tensor.shape.as_list()) == num_dims
   return sampling_ops.combined_static_and_dynamic_shape(tensor)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/ops/nms_ops.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/ops/nms_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """nms computation."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import box_ops
 
 NMS_TILE_SIZE = 512
 
 
 # pylint: disable=missing-function-docstring
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/ops/preprocess_ops.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/ops/preprocess_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Preprocessing ops imported from OD API."""
 
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.ops import box_list
 from official.projects.centernet.ops import box_list_ops
 
 
 def _get_or_create_preprocess_rand_vars(generator_func,
                                         function_id,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/ops/target_assigner.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/ops/target_assigner.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Generate targets (center, scale, offsets,...) for centernet."""
 
 from typing import Dict, List
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import sampling_ops
 
 
 def smallest_positive_root(a, b, c):
   """Returns the smallest positive root of a quadratic equation."""
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/ops/target_assigner_test.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/ops/target_assigner_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for targets generations of centernet."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.ops import target_assigner
 from official.vision.ops import preprocess_ops
 
 
 class TargetAssignerTest(tf.test.TestCase, parameterized.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/tasks/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/tasks/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/tasks/centernet.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/tasks/centernet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Centernet task definition."""
 
 from typing import Any, List, Optional, Tuple
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import input_reader
 from official.core import task_factory
 from official.projects.centernet.configs import centernet as exp_cfg
 from official.projects.centernet.dataloaders import centernet_input
 from official.projects.centernet.losses import centernet_losses
@@ -86,22 +86,22 @@
     dataset = reader.read(input_context=input_context)
 
     return dataset
 
   def build_model(self):
     """get an instance of CenterNet."""
     model_config = self.task_config.model
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None] + model_config.input_size)
 
     l2_weight_decay = self.task_config.weight_decay
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (tf.keras.regularizers.l2(
+    l2_regularizer = (tf_keras.regularizers.l2(
         l2_weight_decay / 2.0) if l2_weight_decay else None)
 
     backbone = factory.build_backbone(
         input_specs=input_specs,
         backbone_config=model_config.backbone,
         norm_activation_config=model_config.norm_activation,
         l2_regularizer=l2_regularizer)
@@ -126,27 +126,30 @@
     dg_config = model_config.detection_generator
     detect_generator_obj = detection_generator.CenterNetDetectionGenerator(
         max_detections=dg_config.max_detections,
         peak_error=dg_config.peak_error,
         peak_extract_kernel_size=dg_config.peak_extract_kernel_size,
         class_offset=dg_config.class_offset,
         net_down_scale=self._net_down_scale,
-        input_image_dims=model_config.input_size[0],
+        input_image_dims=(
+            model_config.input_size[0],
+            model_config.input_size[1],
+        ),
         use_nms=dg_config.use_nms,
         nms_pre_thresh=dg_config.nms_pre_thresh,
         nms_thresh=dg_config.nms_thresh)
 
     model = centernet_model.CenterNetModel(
         backbone=backbone,
         head=head,
         detection_generator=detect_generator_obj)
 
     return model
 
-  def initialize(self, model: tf.keras.Model):
+  def initialize(self, model: tf_keras.Model):
     """Loading pretrained checkpoint."""
     if not self.task_config.init_checkpoint:
       return
 
     ckpt_dir_or_file = self.task_config.init_checkpoint
 
     # Restoring checkpoint.
@@ -298,15 +301,15 @@
     losses['total_loss'] = total_loss
     return losses
 
   def build_metrics(self, training=True):
     metrics = []
     metric_names = ['total_loss', 'ct_loss', 'scale_loss', 'ct_offset_loss']
     for name in metric_names:
-      metrics.append(tf.keras.metrics.Mean(name, dtype=tf.float32))
+      metrics.append(tf_keras.metrics.Mean(name, dtype=tf.float32))
 
     if not training:
       if (self.task_config.validation_data.tfds_name
           and self.task_config.annotation_file):
         raise ValueError(
             "Can't evaluate using annotation file when TFDS is used.")
       self.coco_metric = coco_evaluator.COCOEvaluator(
@@ -314,16 +317,16 @@
           include_mask=False,
           per_category_metrics=self.task_config.per_category_metrics)
 
     return metrics
 
   def train_step(self,
                  inputs: Tuple[Any, Any],
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
+                 model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer,
                  metrics: Optional[List[Any]] = None):
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
@@ -342,23 +345,23 @@
       outputs = tf.nest.map_structure(lambda x: tf.cast(x, tf.float32), outputs)
 
       losses = self.build_losses(outputs['raw_output'], labels)
 
       scaled_loss = losses['total_loss'] / num_replicas
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     # compute the gradient
     tvars = model.trainable_variables
     gradients = tape.gradient(scaled_loss, tvars)
 
     # get unscaled loss if the scaled loss was used
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       gradients = optimizer.get_unscaled_gradients(gradients)
 
     if self.task_config.gradient_clip_norm > 0.0:
       gradients, _ = tf.clip_by_global_norm(gradients,
                                             self.task_config.gradient_clip_norm)
 
     optimizer.apply_gradients(list(zip(gradients, tvars)))
@@ -370,15 +373,15 @@
         m.update_state(losses[m.name])
         logs.update({m.name: m.result()})
 
     return logs
 
   def validation_step(self,
                       inputs: Tuple[Any, Any],
-                      model: tf.keras.Model,
+                      model: tf_keras.Model,
                       metrics: Optional[List[Any]] = None):
     """Validation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/train.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/train.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/utils/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/utils/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/config_classes.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/config_classes.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,36 +22,36 @@
 """
 
 import abc
 import dataclasses
 from typing import Dict, Optional
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class Config(abc.ABC):
   """Base config class."""
 
   def get_weights(self):
     """Generates the weights needed to be loaded into the layer."""
     raise NotImplementedError
 
-  def load_weights(self, layer: tf.keras.layers.Layer) -> int:
+  def load_weights(self, layer: tf_keras.layers.Layer) -> int:
     """Assign weights to layer.
 
     Given a layer, this function retrieves the weights for that layer in an
     appropriate format and order, and loads them into the layer. Additionally,
     the number of weights loaded are returned.
 
     If the weights are in an incorrect format, a ValueError
     will be raised by set_weights().
 
     Args:
-      layer: A `tf.keras.layers.Layer`.
+      layer: A `tf_keras.layers.Layer`.
 
     Returns:
 
     """
     weights = self.get_weights()
     layer.set_weights(weights)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/config_data.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/config_data.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/load_weights.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/load_weights.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/utils/checkpoints/read_checkpoints.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/utils/checkpoints/read_checkpoints.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Functions used to convert a TF checkpoint into a dictionary."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def update_weights_dict(weights_dict, variable_key, value):
   """Inserts weight value into a weight dictionary.
 
   This function inserts a weight value into a weights_dict based on the
   variable key. It is designed to organize TF checkpoint weights by organizing
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/centernet/utils/tf2_centernet_checkpoint_converter.py` & `tf-models-no-deps-2.16.0/official/projects/centernet/utils/tf2_centernet_checkpoint_converter.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """A converter from a tf1 OD API checkpoint to a tf2 checkpoint."""
 
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.centernet.common import registry_imports  # pylint: disable=unused-import
 from official.projects.centernet.configs import backbones
 from official.projects.centernet.configs import centernet
 from official.projects.centernet.modeling import centernet_model
 from official.projects.centernet.modeling.heads import centernet_head
 from official.projects.centernet.modeling.layers import detection_generator
@@ -54,15 +54,15 @@
           backbone=backbones.Backbone(
               type="hourglass",
               hourglass=backbones.Hourglass(
                   model_id=model_id, num_hourglasses=num_hourglasses))))
   model_config = task_config.model
 
   backbone = factory.build_backbone(
-      input_specs=tf.keras.layers.InputSpec(shape=[1, 512, 512, 3]),
+      input_specs=tf_keras.layers.InputSpec(shape=[1, 512, 512, 3]),
       backbone_config=model_config.backbone,
       norm_activation_config=model_config.norm_activation)
 
   task_outputs = task_config.get_output_length_dict()
   head = centernet_head.CenterNetHead(
       input_specs=backbone.output_specs,
       task_outputs=task_outputs,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/common/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/common/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/common/registry_imports.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/common/registry_imports.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -31,22 +31,24 @@
 @dataclasses.dataclass
 class DeepMaskHead(maskrcnn_config.MaskHead):
   convnet_variant: str = 'default'
 
 
 @dataclasses.dataclass
 class DeepMaskHeadRCNN(maskrcnn_config.MaskRCNN):
-  mask_head: Optional[DeepMaskHead] = DeepMaskHead()
+  mask_head: Optional[DeepMaskHead] = dataclasses.field(
+      default_factory=DeepMaskHead
+  )
   use_gt_boxes_for_masks: bool = False
 
 
 @dataclasses.dataclass
 class DeepMaskHeadRCNNTask(maskrcnn_config.MaskRCNNTask):
   """Configuration for the deep mask head R-CNN task."""
-  model: DeepMaskHeadRCNN = DeepMaskHeadRCNN()
+  model: DeepMaskHeadRCNN = dataclasses.field(default_factory=DeepMaskHeadRCNN)
 
 
 @exp_factory.register_config_factory('deep_mask_head_rcnn_resnetfpn_coco')
 def deep_mask_head_rcnn_resnetfpn_coco() -> cfg.ExperimentConfig:
   """COCO object detection with Mask R-CNN with deep mask heads."""
   global_batch_size = 64
   steps_per_epoch = int(retinanet_config.COCO_TRAIN_EXAMPLES /
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn_config_test.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/configs/deep_mask_head_rcnn_config_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Check that the config is set correctly."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.deepmac_maskrcnn.configs import deep_mask_head_rcnn
 
 
 class DeepMaskHeadRcnnConfigTest(tf.test.TestCase):
 
   def test_config(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/hourglass_network.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/hourglass_network.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -28,22 +28,22 @@
 # ==============================================================================
 """The Hourglass[1] network.
 
 [1]: https://arxiv.org/abs/1603.06937
 """
 
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 BATCH_NORM_EPSILON = 1e-5
 BATCH_NORM_MOMENTUM = 0.1
 BATCH_NORM_FUSED = True
 
 
-class IdentityLayer(tf.keras.layers.Layer):
+class IdentityLayer(tf_keras.layers.Layer):
   """A layer which passes through the input as it is."""
 
   def call(self, inputs):
     return inputs
 
 
 def _get_padding_for_kernel_size(kernel_size):
@@ -54,22 +54,22 @@
   else:
     raise ValueError('Padding for kernel size {} not known.'.format(
         kernel_size))
 
 
 def batchnorm():
   try:
-    return tf.keras.layers.experimental.SyncBatchNormalization(
+    return tf_keras.layers.experimental.SyncBatchNormalization(
         name='batchnorm', epsilon=1e-5, momentum=0.1)
   except AttributeError:
-    return tf.keras.layers.BatchNormalization(
+    return tf_keras.layers.BatchNormalization(
         name='batchnorm', epsilon=1e-5, momentum=0.1, fused=BATCH_NORM_FUSED)
 
 
-class ConvolutionalBlock(tf.keras.layers.Layer):
+class ConvolutionalBlock(tf_keras.layers.Layer):
   """Block that aggregates Convolution + Norm layer + ReLU."""
 
   def __init__(self, kernel_size, out_channels, stride=1, relu=True,
                padding='same'):
     """Initializes the Convolutional block.
 
     Args:
@@ -83,26 +83,26 @@
 
     if kernel_size > 1:
       padding = 'valid'
       padding_size = _get_padding_for_kernel_size(kernel_size)
 
       # TODO(vighneshb) Explore if removing and using padding option in conv
       # layer works.
-      self.pad = tf.keras.layers.ZeroPadding2D(padding_size)
+      self.pad = tf_keras.layers.ZeroPadding2D(padding_size)
     else:
       self.pad = IdentityLayer()
 
-    self.conv = tf.keras.layers.Conv2D(
+    self.conv = tf_keras.layers.Conv2D(
         filters=out_channels, kernel_size=kernel_size, use_bias=False,
         strides=stride, padding=padding)
 
     self.norm = batchnorm()
 
     if relu:
-      self.relu = tf.keras.layers.ReLU()
+      self.relu = tf_keras.layers.ReLU()
     else:
       self.relu = IdentityLayer()
 
   def call(self, inputs):
     net = self.pad(inputs)
     net = self.conv(net)
     net = self.norm(net)
@@ -119,15 +119,15 @@
       out_channels: int, the desired number of output channels.
       stride: int, the stride for the layer.
     """
     super(SkipConvolution, self).__init__(
         out_channels=out_channels, kernel_size=1, stride=stride, relu=False)
 
 
-class ResidualBlock(tf.keras.layers.Layer):
+class ResidualBlock(tf_keras.layers.Layer):
   """A Residual block."""
 
   def __init__(self, out_channels, skip_conv=False, kernel_size=3, stride=1,
                padding='same'):
     """Initializes the Residual block.
 
     Args:
@@ -138,36 +138,36 @@
       padding: str, the type of padding to use.
     """
 
     super(ResidualBlock, self).__init__()
     self.conv_block = ConvolutionalBlock(
         kernel_size=kernel_size, out_channels=out_channels, stride=stride)
 
-    self.conv = tf.keras.layers.Conv2D(
+    self.conv = tf_keras.layers.Conv2D(
         filters=out_channels, kernel_size=kernel_size, use_bias=False,
         strides=1, padding=padding)
     self.norm = batchnorm()
 
     if skip_conv:
       self.skip = SkipConvolution(out_channels=out_channels,
                                   stride=stride)
     else:
       self.skip = IdentityLayer()
 
-    self.relu = tf.keras.layers.ReLU()
+    self.relu = tf_keras.layers.ReLU()
 
   def call(self, inputs):
     net = self.conv_block(inputs)
     net = self.conv(net)
     net = self.norm(net)
     net_skip = self.skip(inputs)
     return self.relu(net + net_skip)
 
 
-class InputDownsampleBlock(tf.keras.layers.Layer):
+class InputDownsampleBlock(tf_keras.layers.Layer):
   """Block for the initial feature downsampling."""
 
   def __init__(self, out_channels_initial_conv, out_channels_residual_block):
     """Initializes the downsample block.
 
     Args:
       out_channels_initial_conv: int, the desired number of output channels
@@ -183,15 +183,15 @@
     self.residual_block = ResidualBlock(
         out_channels=out_channels_residual_block, stride=2, skip_conv=True)
 
   def call(self, inputs):
     return self.residual_block(self.conv_block(inputs))
 
 
-class InputConvBlock(tf.keras.layers.Layer):
+class InputConvBlock(tf_keras.layers.Layer):
   """Block for the initial feature convolution.
 
   This block is used in the hourglass network when we don't want to downsample
   the input.
   """
 
   def __init__(self, out_channels_initial_conv, out_channels_residual_block):
@@ -279,15 +279,15 @@
 
   for block in blocks:
     net = block(net)
 
   return net
 
 
-class EncoderDecoderBlock(tf.keras.layers.Layer):
+class EncoderDecoderBlock(tf_keras.layers.Layer):
   """An encoder-decoder block which recursively defines the hourglass network."""
 
   def __init__(self, num_stages, channel_dims, blocks_per_stage,
                stagewise_downsample=True, encoder_decoder_shortcut=True):
     """Initializes the encoder-decoder block.
 
     Args:
@@ -312,15 +312,15 @@
 
     out_channels = channel_dims[0]
     out_channels_downsampled = channel_dims[1]
 
     self.encoder_decoder_shortcut = encoder_decoder_shortcut
 
     if encoder_decoder_shortcut:
-      self.merge_features = tf.keras.layers.Add()
+      self.merge_features = tf_keras.layers.Add()
       self.encoder_block1 = _make_repeated_residual_blocks(
           out_channels=out_channels, num_blocks=blocks_per_stage[0],
           initial_stride=1)
 
     initial_stride = 2 if stagewise_downsample else 1
     self.encoder_block2 = _make_repeated_residual_blocks(
         out_channels=out_channels_downsampled,
@@ -339,15 +339,15 @@
           out_channels=out_channels_downsampled,
           num_blocks=blocks_per_stage[1])
 
     self.decoder_block = _make_repeated_residual_blocks(
         residual_channels=out_channels_downsampled,
         out_channels=out_channels, num_blocks=blocks_per_stage[0])
 
-    self.upsample = tf.keras.layers.UpSampling2D(initial_stride)
+    self.upsample = tf_keras.layers.UpSampling2D(initial_stride)
 
   def call(self, inputs):
 
     if self.encoder_decoder_shortcut:
       encoded_outputs = _apply_blocks(inputs, self.encoder_block1)
     encoded_downsampled_outputs = _apply_blocks(inputs, self.encoder_block2)
     inner_block_outputs = _apply_blocks(
@@ -358,15 +358,15 @@
 
     if self.encoder_decoder_shortcut:
       return self.merge_features([encoded_outputs, upsampled_outputs])
     else:
       return upsampled_outputs
 
 
-class HourglassNetwork(tf.keras.Model):
+class HourglassNetwork(tf_keras.Model):
   """The hourglass network."""
 
   def __init__(self, num_stages, input_channel_dims, channel_dims_per_stage,
                blocks_per_stage, num_hourglasses, initial_downsample=True,
                stagewise_downsample=True, encoder_decoder_shortcut=True):
     """Intializes the feature extractor.
 
@@ -433,17 +433,17 @@
           ConvolutionalBlock(
               kernel_size=1, out_channels=channel_dims_per_stage[0], relu=False)
       )
       self.intermediate_residual.append(
           ResidualBlock(out_channels=channel_dims_per_stage[0])
       )
 
-    self.intermediate_relu = tf.keras.layers.ReLU()
+    self.intermediate_relu = tf_keras.layers.ReLU()
 
-  def call(self, inputs):
+  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
 
     if self.initial_downsample:
       inputs = self.downsample_input(inputs)
     else:
       inputs = self.conv_input(inputs)
 
     outputs = []
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/instance_heads.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/instance_heads.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,21 +13,21 @@
 # limitations under the License.
 
 """Instance prediction heads."""
 
 # Import libraries
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.projects.deepmac_maskrcnn.modeling.heads import hourglass_network
 
 
-class DeepMaskHead(tf.keras.layers.Layer):
+class DeepMaskHead(tf_keras.layers.Layer):
   """Creates a mask head."""
 
   def __init__(self,
                num_classes,
                upsample_factor=2,
                num_convs=4,
                num_filters=256,
@@ -55,17 +55,17 @@
         convolution layers is used.
       activation: A `str` that indicates which activation is used, e.g. 'relu',
         'swish', etc.
       use_sync_bn: A `bool` that indicates whether to use synchronized batch
         normalization across different replicas.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
       class_agnostic: A `bool`. If set, we use a single channel mask head that
         is shared between all classes.
       convnet_variant: A `str` denoting the architecture of network used in the
         head. Supported options are 'default', 'hourglass20', 'hourglass52'
         and 'hourglass100'.
       **kwargs: Additional keyword arguments to be passed.
     """
@@ -82,56 +82,56 @@
         'norm_epsilon': norm_epsilon,
         'kernel_regularizer': kernel_regularizer,
         'bias_regularizer': bias_regularizer,
         'class_agnostic': class_agnostic,
         'convnet_variant': convnet_variant,
     }
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation = tf_utils.get_activation(activation)
 
   def _get_conv_op_and_kwargs(self):
-    conv_op = (tf.keras.layers.SeparableConv2D
+    conv_op = (tf_keras.layers.SeparableConv2D
                if self._config_dict['use_separable_conv']
-               else tf.keras.layers.Conv2D)
+               else tf_keras.layers.Conv2D)
     conv_kwargs = {
         'filters': self._config_dict['num_filters'],
         'kernel_size': 3,
         'padding': 'same',
     }
     if self._config_dict['use_separable_conv']:
       conv_kwargs.update({
-          'depthwise_initializer': tf.keras.initializers.VarianceScaling(
+          'depthwise_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'pointwise_initializer': tf.keras.initializers.VarianceScaling(
+          'pointwise_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           'bias_initializer': tf.zeros_initializer(),
           'depthwise_regularizer': self._config_dict['kernel_regularizer'],
           'pointwise_regularizer': self._config_dict['kernel_regularizer'],
           'bias_regularizer': self._config_dict['bias_regularizer'],
       })
     else:
       conv_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.VarianceScaling(
+          'kernel_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           'bias_initializer': tf.zeros_initializer(),
           'kernel_regularizer': self._config_dict['kernel_regularizer'],
           'bias_regularizer': self._config_dict['bias_regularizer'],
       })
 
     return conv_op, conv_kwargs
 
   def _get_bn_op_and_kwargs(self):
 
-    bn_op = (tf.keras.layers.experimental.SyncBatchNormalization
+    bn_op = (tf_keras.layers.experimental.SyncBatchNormalization
              if self._config_dict['use_sync_bn']
-             else tf.keras.layers.BatchNormalization)
+             else tf_keras.layers.BatchNormalization)
     bn_kwargs = {
         'axis': self._bn_axis,
         'momentum': self._config_dict['norm_momentum'],
         'epsilon': self._config_dict['norm_epsilon'],
     }
 
     return bn_op, bn_kwargs
@@ -139,20 +139,20 @@
   def build(self, input_shape):
     """Creates the variables of the head."""
 
     conv_op, conv_kwargs = self._get_conv_op_and_kwargs()
 
     self._build_convnet_variant()
 
-    self._deconv = tf.keras.layers.Conv2DTranspose(
+    self._deconv = tf_keras.layers.Conv2DTranspose(
         filters=self._config_dict['num_filters'],
         kernel_size=self._config_dict['upsample_factor'],
         strides=self._config_dict['upsample_factor'],
         padding='valid',
-        kernel_initializer=tf.keras.initializers.VarianceScaling(
+        kernel_initializer=tf_keras.initializers.VarianceScaling(
             scale=2, mode='fan_out', distribution='untruncated_normal'),
         bias_initializer=tf.zeros_initializer(),
         kernel_regularizer=self._config_dict['kernel_regularizer'],
         bias_regularizer=self._config_dict['bias_regularizer'],
         name='mask-upsampling')
 
     bn_op, bn_kwargs = self._get_bn_op_and_kwargs()
@@ -166,26 +166,26 @@
     conv_kwargs = {
         'filters': num_filters,
         'kernel_size': 1,
         'padding': 'valid',
     }
     if self._config_dict['use_separable_conv']:
       conv_kwargs.update({
-          'depthwise_initializer': tf.keras.initializers.VarianceScaling(
+          'depthwise_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'pointwise_initializer': tf.keras.initializers.VarianceScaling(
+          'pointwise_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           'bias_initializer': tf.zeros_initializer(),
           'depthwise_regularizer': self._config_dict['kernel_regularizer'],
           'pointwise_regularizer': self._config_dict['kernel_regularizer'],
           'bias_regularizer': self._config_dict['bias_regularizer'],
       })
     else:
       conv_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.VarianceScaling(
+          'kernel_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           'bias_initializer': tf.zeros_initializer(),
           'kernel_regularizer': self._config_dict['kernel_regularizer'],
           'bias_regularizer': self._config_dict['bias_regularizer'],
       })
     self._mask_regressor = conv_op(name='mask-logits', **conv_kwargs)
 
@@ -205,19 +205,20 @@
     Returns:
       mask_outputs: A `tf.Tensor` of shape
         [batch_size, num_instances, roi_height * upsample_factor,
          roi_width * upsample_factor], representing the mask predictions.
     """
     roi_features, roi_classes = inputs
     features_shape = tf.shape(roi_features)
-    batch_size, num_rois, height, width, filters = (
-        features_shape[0], features_shape[1], features_shape[2],
-        features_shape[3], features_shape[4])
-    if batch_size is None:
-      batch_size = tf.shape(roi_features)[0]
+    num_rois, height, width, filters = (
+        features_shape[1],
+        features_shape[2],
+        features_shape[3],
+        features_shape[4],
+    )
 
     x = tf.reshape(roi_features, [-1, height, width, filters])
 
     x = self._call_convnet_variant(x)
 
     x = self._deconv(x)
     x = self._deconv_bn(x)
@@ -225,37 +226,23 @@
 
     logits = self._mask_regressor(x)
 
     mask_height = height * self._config_dict['upsample_factor']
     mask_width = width * self._config_dict['upsample_factor']
 
     if self._config_dict['class_agnostic']:
-      logits = tf.reshape(logits, [-1, num_rois, mask_height, mask_width, 1])
+      return tf.reshape(logits, [-1, num_rois, mask_height, mask_width])
     else:
       logits = tf.reshape(
           logits,
           [-1, num_rois, mask_height, mask_width,
            self._config_dict['num_classes']])
-
-    batch_indices = tf.tile(
-        tf.expand_dims(tf.range(batch_size), axis=1), [1, num_rois])
-    mask_indices = tf.tile(
-        tf.expand_dims(tf.range(num_rois), axis=0), [batch_size, 1])
-
-    if self._config_dict['class_agnostic']:
-      class_gather_indices = tf.zeros_like(roi_classes, dtype=tf.int32)
-    else:
-      class_gather_indices = tf.cast(roi_classes, dtype=tf.int32)
-
-    gather_indices = tf.stack(
-        [batch_indices, mask_indices, class_gather_indices],
-        axis=2)
-    mask_outputs = tf.gather_nd(
-        tf.transpose(logits, [0, 1, 4, 2, 3]), gather_indices)
-    return mask_outputs
+      return tf.gather(
+          logits, tf.cast(roi_classes, dtype=tf.int32), axis=-1, batch_dims=2
+      )
 
   def _build_convnet_variant(self):
 
     variant = self._config_dict['convnet_variant']
     if variant == 'default':
       bn_op, bn_kwargs = self._get_bn_op_and_kwargs()
       self._convs = []
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/heads/instance_heads_test.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/heads/instance_heads_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for instance_heads.py."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.deepmac_maskrcnn.modeling.heads import instance_heads as deep_instance_heads
 
 
 class MaskHeadTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/maskrcnn_model.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/maskrcnn_model.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,57 +15,59 @@
 """Mask R-CNN model."""
 
 from typing import List, Mapping, Optional, Union
 
 # Import libraries
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling import maskrcnn_model
+from official.vision.ops import box_ops
 
 
 def resize_as(source, size):
 
   source = tf.transpose(source, (0, 2, 3, 1))
   source = tf.image.resize(source, (size, size))
   return tf.transpose(source, (0, 3, 1, 2))
 
 
 class DeepMaskRCNNModel(maskrcnn_model.MaskRCNNModel):
   """The Mask R-CNN model."""
 
   def __init__(self,
-               backbone: tf.keras.Model,
-               decoder: tf.keras.Model,
-               rpn_head: tf.keras.layers.Layer,
-               detection_head: Union[tf.keras.layers.Layer,
-                                     List[tf.keras.layers.Layer]],
-               roi_generator: tf.keras.layers.Layer,
-               roi_sampler: Union[tf.keras.layers.Layer,
-                                  List[tf.keras.layers.Layer]],
-               roi_aligner: tf.keras.layers.Layer,
-               detection_generator: tf.keras.layers.Layer,
-               mask_head: Optional[tf.keras.layers.Layer] = None,
-               mask_sampler: Optional[tf.keras.layers.Layer] = None,
-               mask_roi_aligner: Optional[tf.keras.layers.Layer] = None,
+               backbone: tf_keras.Model,
+               decoder: tf_keras.Model,
+               rpn_head: tf_keras.layers.Layer,
+               detection_head: Union[tf_keras.layers.Layer,
+                                     List[tf_keras.layers.Layer]],
+               roi_generator: tf_keras.layers.Layer,
+               roi_sampler: Union[tf_keras.layers.Layer,
+                                  List[tf_keras.layers.Layer]],
+               roi_aligner: tf_keras.layers.Layer,
+               detection_generator: tf_keras.layers.Layer,
+               mask_head: Optional[tf_keras.layers.Layer] = None,
+               mask_sampler: Optional[tf_keras.layers.Layer] = None,
+               mask_roi_aligner: Optional[tf_keras.layers.Layer] = None,
                class_agnostic_bbox_pred: bool = False,
                cascade_class_ensemble: bool = False,
                min_level: Optional[int] = None,
                max_level: Optional[int] = None,
                num_scales: Optional[int] = None,
                aspect_ratios: Optional[List[float]] = None,
                anchor_size: Optional[float] = None,
+               outer_boxes_scale: float = 1.0,
                use_gt_boxes_for_masks=False,
                **kwargs):
     """Initializes the Mask R-CNN model.
 
     Args:
-      backbone: `tf.keras.Model`, the backbone network.
-      decoder: `tf.keras.Model`, the decoder network.
+      backbone: `tf_keras.Model`, the backbone network.
+      decoder: `tf_keras.Model`, the decoder network.
       rpn_head: the RPN head.
       detection_head: the detection head or a list of heads.
       roi_generator: the ROI generator.
       roi_sampler: a single ROI sampler or a list of ROI samplers for cascade
         detection heads.
       roi_aligner: the ROI aligner.
       detection_generator: the detection generator.
@@ -82,19 +84,21 @@
         For instances, num_scales=2 adds one additional intermediate anchor
         scales [2^0, 2^0.5] on each level.
       aspect_ratios: A list representing the aspect raito anchors added on each
         level. The number indicates the ratio of width to height. For instances,
         aspect_ratios=[1.0, 2.0, 0.5] adds three anchors on each scale level.
       anchor_size: A number representing the scale of size of the base anchor to
         the feature stride 2^level.
+      outer_boxes_scale: a float to scale up the bounding boxes to generate
+        more inclusive masks. The scale is expected to be >=1.0.
       use_gt_boxes_for_masks: bool, if set, crop using groundtruth boxes instead
         of proposals for training mask head
       **kwargs: keyword arguments to be passed.
     """
-    super(DeepMaskRCNNModel, self).__init__(
+    super().__init__(
         backbone=backbone,
         decoder=decoder,
         rpn_head=rpn_head,
         detection_head=detection_head,
         roi_generator=roi_generator,
         roi_sampler=roi_sampler,
         roi_aligner=roi_aligner,
@@ -105,43 +109,64 @@
         class_agnostic_bbox_pred=class_agnostic_bbox_pred,
         cascade_class_ensemble=cascade_class_ensemble,
         min_level=min_level,
         max_level=max_level,
         num_scales=num_scales,
         aspect_ratios=aspect_ratios,
         anchor_size=anchor_size,
+        outer_boxes_scale=outer_boxes_scale,
         **kwargs)
 
     self._config_dict['use_gt_boxes_for_masks'] = use_gt_boxes_for_masks
 
   def call(self,
            images: tf.Tensor,
            image_shape: tf.Tensor,
            anchor_boxes: Optional[Mapping[str, tf.Tensor]] = None,
            gt_boxes: Optional[tf.Tensor] = None,
            gt_classes: Optional[tf.Tensor] = None,
            gt_masks: Optional[tf.Tensor] = None,
+           gt_outer_boxes: Optional[tf.Tensor] = None,
            training: Optional[bool] = None) -> Mapping[str, tf.Tensor]:
-
+    call_box_outputs_kwargs = {
+        'images': images,
+        'image_shape': image_shape,
+        'anchor_boxes': anchor_boxes,
+        'gt_boxes': gt_boxes,
+        'gt_classes': gt_classes,
+        'training': training
+    }
+    if self.outer_boxes_scale > 1.0:
+      call_box_outputs_kwargs['gt_outer_boxes'] = gt_outer_boxes
     model_outputs, intermediate_outputs = self._call_box_outputs(
-        images=images, image_shape=image_shape, anchor_boxes=anchor_boxes,
-        gt_boxes=gt_boxes, gt_classes=gt_classes, training=training)
+        **call_box_outputs_kwargs)
     if not self._include_mask:
       return model_outputs
 
+    if self.outer_boxes_scale == 1.0:
+      current_rois = intermediate_outputs['current_rois']
+      matched_gt_boxes = intermediate_outputs['matched_gt_boxes']
+      mask_head_gt_boxes = gt_boxes
+    else:
+      current_rois = box_ops.compute_outer_boxes(
+          intermediate_outputs['current_rois'],
+          tf.expand_dims(image_shape, axis=1), self.outer_boxes_scale)
+      matched_gt_boxes = intermediate_outputs['matched_gt_outer_boxes']
+      mask_head_gt_boxes = gt_outer_boxes
+
     model_mask_outputs = self._call_mask_outputs(
         model_box_outputs=model_outputs,
         features=model_outputs['decoder_features'],
-        current_rois=intermediate_outputs['current_rois'],
+        current_rois=current_rois,
         matched_gt_indices=intermediate_outputs['matched_gt_indices'],
-        matched_gt_boxes=intermediate_outputs['matched_gt_boxes'],
+        matched_gt_boxes=matched_gt_boxes,
         matched_gt_classes=intermediate_outputs['matched_gt_classes'],
         gt_masks=gt_masks,
         gt_classes=gt_classes,
-        gt_boxes=gt_boxes,
+        gt_boxes=mask_head_gt_boxes,
         training=training)
     model_outputs.update(model_mask_outputs)
     return model_outputs
 
   def call_images_and_boxes(self, images, boxes):
     """Predict masks given an image and bounding boxes."""
 
@@ -190,15 +215,18 @@
         roi_masks = tf.stop_gradient(roi_masks)
         model_outputs.update({
             'mask_class_targets': roi_classes,
             'mask_targets': roi_masks,
         })
 
     else:
-      rois = model_outputs['detection_boxes']
+      if self.outer_boxes_scale == 1.0:
+        rois = model_outputs['detection_boxes']
+      else:
+        rois = model_outputs['detection_outer_boxes']
       roi_classes = model_outputs['detection_classes']
 
     # Mask RoI align.
     if training and self._config_dict['use_gt_boxes_for_masks']:
       logging.info('Using GT mask roi features.')
       roi_aligner_boxes = gt_boxes
       mask_head_classes = gt_classes
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/modeling/maskrcnn_model_test.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/modeling/maskrcnn_model_test.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for maskrcnn_model.py."""
 
 # Import libraries
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.deepmac_maskrcnn.modeling import maskrcnn_model
 from official.projects.deepmac_maskrcnn.modeling.heads import instance_heads as deep_instance_heads
 from official.vision.modeling.backbones import resnet
 from official.vision.modeling.decoders import fpn
 from official.vision.modeling.heads import dense_prediction_heads
 from official.vision.modeling.heads import instance_heads
@@ -46,15 +46,15 @@
       max_level=max_level,
       num_scales=num_scales,
       aspect_ratios=aspect_ratios,
       anchor_size=3,
       image_size=image_size).multilevel_boxes
   num_anchors_per_location = len(aspect_ratios) * num_scales
 
-  input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, 3])
+  input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, 3])
   backbone = resnet.ResNet(model_id=50, input_specs=input_specs)
   decoder = fpn.FPN(
       min_level=min_level,
       max_level=max_level,
       input_specs=backbone.output_specs)
   rpn_head = dense_prediction_heads.RPNHead(
       min_level=min_level,
@@ -88,35 +88,41 @@
 
   return model, anchor_boxes
 
 
 class MaskRCNNModelTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
-      (False, False,),
-      (False, True,),
-      (True, False,),
-      (True, True,),
+      (False, False, False),
+      (False, True, False),
+      (True, False, True),
+      (True, False, False),
+      (True, True, True),
+      (True, True, False),
   )
-  def test_forward(self, use_gt_boxes_for_masks, training):
+  def test_forward(self, use_gt_boxes_for_masks, training, use_outer_boxes):
     image_size = (256, 256)
     images = np.random.rand(2, image_size[0], image_size[1], 3)
     image_shape = np.array([[224, 100], [100, 224]])
     model, anchor_boxes = construct_model_and_anchors(
         image_size, use_gt_boxes_for_masks)
 
     gt_boxes = tf.zeros((2, 16, 4), dtype=tf.float32)
+    gt_outer_boxes = None
+    if use_outer_boxes:
+      gt_outer_boxes = tf.zeros((2, 16, 4), dtype=tf.float32)
     gt_masks = tf.zeros((2, 16, 32, 32))
     gt_classes = tf.zeros((2, 16), dtype=tf.int32)
     results = model(images.astype(np.uint8),
                     image_shape,
                     anchor_boxes,
                     gt_boxes,
                     gt_classes,
                     gt_masks,
+                    gt_outer_boxes,
                     training=training)
 
     self.assertIn('rpn_boxes', results)
     self.assertIn('rpn_scores', results)
     if training:
       self.assertIn('class_targets', results)
       self.assertIn('box_targets', results)
@@ -133,20 +139,20 @@
       self.assertIn('detection_masks', results)
 
   @parameterized.parameters(
       [(1, 5), (1, 10), (1, 15), (2, 5), (2, 10), (2, 15)]
   )
   def test_image_and_boxes(self, batch_size, num_boxes):
     image_size = (640, 640)
-    images = np.random.rand(1, image_size[0], image_size[1], 3).astype(
+    images = np.random.rand(batch_size, image_size[0], image_size[1], 3).astype(
         np.float32)
     model, _ = construct_model_and_anchors(
         image_size, use_gt_boxes_for_masks=True)
 
-    boxes = np.zeros((1, num_boxes, 4), dtype=np.float32)
+    boxes = np.zeros((batch_size, num_boxes, 4), dtype=np.float32)
     boxes[:, :, [2, 3]] = 1.0
     boxes = tf.constant(boxes)
     results = model.call_images_and_boxes(images, boxes)
     self.assertIn('detection_masks', results)
 
 
 if __name__ == '__main__':
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/detection.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/detection.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Detection input and model functions for serving/inference."""
 
 from typing import Dict, Mapping, Text
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.deepmac_maskrcnn.configs import deep_mask_head_rcnn as cfg
 from official.projects.deepmac_maskrcnn.modeling import maskrcnn_model
 from official.projects.deepmac_maskrcnn.tasks import deep_mask_head_rcnn
 from official.vision.ops import box_ops
 from official.vision.serving import detection
 
@@ -57,15 +57,15 @@
 
   def _build_model(self):
 
     if self._batch_size is None:
       ValueError("batch_size can't be None for detection models")
     if self.params.task.model.detection_generator.nms_version != 'batched':
       ValueError('Only batched_nms is supported.')
-    input_specs = tf.keras.layers.InputSpec(shape=[self._batch_size] +
+    input_specs = tf_keras.layers.InputSpec(shape=[self._batch_size] +
                                             self._input_image_size + [3])
 
     if isinstance(self.params.task.model, cfg.DeepMaskHeadRCNN):
       model = deep_mask_head_rcnn.build_maskrcnn(
           input_specs=input_specs, model_config=self.params.task.model)
     else:
       raise ValueError('Detection module not implemented for {} model.'.format(
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/detection_test.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/detection_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import io
 import os
 
 from absl.testing import parameterized
 import numpy as np
 from PIL import Image
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import exp_factory
 from official.projects.deepmac_maskrcnn.serving import detection
 
 
 class DetectionExportTest(tf.test.TestCase, parameterized.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/serving/export_saved_model.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/serving/export_saved_model.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/tasks/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/tasks/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/tasks/deep_mask_head_rcnn.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/tasks/deep_mask_head_rcnn.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Mask R-CNN variant with support for deep mask heads."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import task_factory
 from official.projects.deepmac_maskrcnn.configs import deep_mask_head_rcnn as deep_mask_head_rcnn_config
 from official.projects.deepmac_maskrcnn.modeling import maskrcnn_model as deep_maskrcnn_model
 from official.projects.deepmac_maskrcnn.modeling.heads import instance_heads as deep_instance_heads
 from official.vision.modeling import backbones
 from official.vision.modeling.decoders import factory as decoder_factory
@@ -29,17 +29,17 @@
 from official.vision.modeling.layers import roi_aligner
 from official.vision.modeling.layers import roi_generator
 from official.vision.modeling.layers import roi_sampler
 from official.vision.tasks import maskrcnn
 
 
 # Taken from modeling/factory.py
-def build_maskrcnn(input_specs: tf.keras.layers.InputSpec,
+def build_maskrcnn(input_specs: tf_keras.layers.InputSpec,
                    model_config: deep_mask_head_rcnn_config.DeepMaskHeadRCNN,
-                   l2_regularizer: tf.keras.regularizers.Regularizer = None):  # pytype: disable=annotation-type-mismatch  # typed-keras
+                   l2_regularizer: tf_keras.regularizers.Regularizer = None):  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds Mask R-CNN model."""
   norm_activation_config = model_config.norm_activation
   backbone = backbones.factory.build_backbone(
       input_specs=input_specs,
       backbone_config=model_config.backbone,
       norm_activation_config=norm_activation_config,
       l2_regularizer=l2_regularizer)
@@ -116,15 +116,16 @@
 
   detection_generator_obj = detection_generator.DetectionGenerator(
       apply_nms=True,
       pre_nms_top_k=generator_config.pre_nms_top_k,
       pre_nms_score_threshold=generator_config.pre_nms_score_threshold,
       nms_iou_threshold=generator_config.nms_iou_threshold,
       max_num_detections=generator_config.max_num_detections,
-      nms_version=generator_config.nms_version)
+      nms_version=generator_config.nms_version,
+      use_sigmoid_probability=generator_config.use_sigmoid_probability)
 
   if model_config.include_mask:
     mask_head = deep_instance_heads.DeepMaskHead(
         num_classes=model_config.num_classes,
         upsample_factor=model_config.mask_head.upsample_factor,
         num_convs=model_config.mask_head.num_convs,
         num_filters=model_config.mask_head.num_filters,
@@ -158,37 +159,50 @@
       roi_generator=roi_generator_obj,
       roi_sampler=roi_sampler_obj,
       roi_aligner=roi_aligner_obj,
       detection_generator=detection_generator_obj,
       mask_head=mask_head,
       mask_sampler=mask_sampler_obj,
       mask_roi_aligner=mask_roi_aligner_obj,
+      class_agnostic_bbox_pred=detection_head_config.class_agnostic_bbox_pred,
+      cascade_class_ensemble=detection_head_config.cascade_class_ensemble,
+      min_level=model_config.min_level,
+      max_level=model_config.max_level,
+      num_scales=model_config.anchor.num_scales,
+      aspect_ratios=model_config.anchor.aspect_ratios,
+      anchor_size=model_config.anchor.anchor_size,
+      outer_boxes_scale=model_config.outer_boxes_scale,
       use_gt_boxes_for_masks=model_config.use_gt_boxes_for_masks)
   return model
 
 
 @task_factory.register_task_cls(deep_mask_head_rcnn_config.DeepMaskHeadRCNNTask)
 class DeepMaskHeadRCNNTask(maskrcnn.MaskRCNNTask):
   """Mask R-CNN with support for deep mask heads."""
 
   def build_model(self):
-    """Build Mask R-CNN model."""
+    """Builds Mask R-CNN model."""
 
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None] + self.task_config.model.input_size)
 
     l2_weight_decay = self.task_config.losses.l2_weight_decay
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (tf.keras.regularizers.l2(
+    l2_regularizer = (tf_keras.regularizers.l2(
         l2_weight_decay / 2.0) if l2_weight_decay else None)
 
     model = build_maskrcnn(
         input_specs=input_specs,
         model_config=self.task_config.model,
         l2_regularizer=l2_regularizer)
 
     if self.task_config.freeze_backbone:
       model.backbone.trainable = False
 
+    # Builds the model through warm-up call.
+    dummy_images = tf_keras.Input(self.task_config.model.input_size)
+    dummy_image_shape = tf_keras.layers.Input([2])
+    _ = model(dummy_images, image_shape=dummy_image_shape, training=False)
+
     return model
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/deepmac_maskrcnn/train.py` & `tf-models-no-deps-2.16.0/official/projects/deepmac_maskrcnn/train.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/mobilebert/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/maxvit/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/mobilebert/distillation.py` & `tf-models-no-deps-2.16.0/official/projects/mobilebert/distillation.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Progressive distillation for MobileBERT student model."""
 import dataclasses
 from typing import List, Optional
 
 from absl import logging
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.modeling import optimization
 from official.modeling import tf_utils
 from official.modeling.fast_training.progressive import policies
 from official.modeling.hyperparams import base_config
 from official.nlp import modeling
@@ -69,30 +69,42 @@
   distill_ground_truth_ratio: float = 0.5
 
 
 @dataclasses.dataclass
 class BertDistillationProgressiveConfig(policies.ProgressiveConfig):
   """Defines the specific distillation behavior."""
   if_copy_embeddings: bool = True
-  layer_wise_distill_config: LayerWiseDistillConfig = LayerWiseDistillConfig()
-  pretrain_distill_config: PretrainDistillConfig = PretrainDistillConfig()
+  layer_wise_distill_config: LayerWiseDistillConfig = dataclasses.field(
+      default_factory=LayerWiseDistillConfig
+  )
+  pretrain_distill_config: PretrainDistillConfig = dataclasses.field(
+      default_factory=PretrainDistillConfig
+  )
 
 
 @dataclasses.dataclass
 class BertDistillationTaskConfig(cfg.TaskConfig):
   """Defines the teacher/student model architecture and training data."""
-  teacher_model: bert.PretrainerConfig = bert.PretrainerConfig(
-      encoder=encoders.EncoderConfig(type='mobilebert'))
-
-  student_model: bert.PretrainerConfig = bert.PretrainerConfig(
-      encoder=encoders.EncoderConfig(type='mobilebert'))
+  teacher_model: bert.PretrainerConfig = dataclasses.field(
+      default_factory=lambda: bert.PretrainerConfig(  # pylint: disable=g-long-lambda
+          encoder=encoders.EncoderConfig(type='mobilebert')
+      )
+  )
+
+  student_model: bert.PretrainerConfig = dataclasses.field(
+      default_factory=lambda: bert.PretrainerConfig(  # pylint: disable=g-long-lambda
+          encoder=encoders.EncoderConfig(type='mobilebert')
+      )
+  )
   # The path to the teacher model checkpoint or its directory.
   teacher_model_init_checkpoint: str = ''
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(
+      default_factory=cfg.DataConfig
+  )
 
 
 def build_sub_encoder(encoder, target_layer_id):
   """Builds an encoder that only computes first few transformer layers."""
   input_ids = encoder.inputs[0]
   input_mask = encoder.inputs[1]
   type_ids = encoder.inputs[2]
@@ -102,15 +114,15 @@
 
   layer_output = embedding_output
   attention_score = None
   for layer_idx in range(target_layer_id + 1):
     layer_output, attention_score = encoder.transformer_layers[layer_idx](
         layer_output, attention_mask, return_attention_scores=True)
 
-  return tf.keras.Model(
+  return tf_keras.Model(
       inputs=[input_ids, input_mask, type_ids],
       outputs=[layer_output, attention_score])
 
 
 class BertDistillationTask(policies.ProgressivePolicy, base_task.Task):
   """Distillation language modeling task progressively."""
 
@@ -148,15 +160,15 @@
                        'the number of student layers.')
 
     ratio = progressive.pretrain_distill_config.distill_ground_truth_ratio
     if ratio < 0 or ratio > 1:
       raise ValueError('distill_ground_truth_ratio has to be within [0, 1].')
 
     # A non-trainable layer for feature normalization for transfer loss
-    self._layer_norm = tf.keras.layers.LayerNormalization(
+    self._layer_norm = tf_keras.layers.LayerNormalization(
         axis=-1,
         beta_initializer='zeros',
         gamma_initializer='ones',
         trainable=False)
 
     # Build the teacher and student pretrainer model.
     self._teacher_pretrainer = self._build_pretrainer(
@@ -178,15 +190,15 @@
       ]
     else:
       cls_heads = []
 
     masked_lm = layers.MobileBertMaskedLM(
         embedding_table=encoder.get_embedding_table(),
         activation=tf_utils.get_activation(pretrainer_cfg.mlm_activation),
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=pretrainer_cfg.mlm_initializer_range),
         name='cls/predictions')
 
     pretrainer = models.BertPretrainerV2(
         encoder_network=encoder,
         classification_heads=cls_heads,
         customized_masked_lm=masked_lm,
@@ -203,15 +215,15 @@
     """Return the total number of steps in this stage."""
     if stage_id + 1 < self.num_stages():
       return self._progressive_config.layer_wise_distill_config.num_steps
     else:
       return self._progressive_config.pretrain_distill_config.num_steps
 
   # override policies.ProgressivePolicy
-  def get_model(self, stage_id, old_model=None) -> tf.keras.Model:
+  def get_model(self, stage_id, old_model=None) -> tf_keras.Model:
     del old_model
     return self.build_model(stage_id)
 
   # override policies.ProgressivePolicy
   def get_optimizer(self, stage_id):
     """Build optimizer for each stage."""
     if stage_id + 1 < self.num_stages():
@@ -234,16 +246,16 @@
             'linear':
                 {'warmup_steps':
                      distill_config.warmup_steps,
                 }
             })
     opt_factory = optimization.OptimizerFactory(params)
     optimizer = opt_factory.build_optimizer(opt_factory.build_learning_rate())
-    if isinstance(optimizer, tf.keras.optimizers.experimental.Optimizer):
-      optimizer = tf.keras.__internal__.optimizers.convert_to_legacy_optimizer(
+    if isinstance(optimizer, tf_keras.optimizers.experimental.Optimizer):
+      optimizer = tf_keras.__internal__.optimizers.convert_to_legacy_optimizer(
           optimizer)
 
     return optimizer
 
   # override policies.ProgressivePolicy
   def get_train_dataset(self, stage_id: int) -> tf.data.Dataset:
     """Return Dataset for this stage."""
@@ -258,15 +270,15 @@
     del stage_id
     if self._the_only_eval_dataset is None:
       self._the_only_eval_dataset = orbit.utils.make_distributed_dataset(
           self._strategy, self.build_inputs, self._eval_data_config)
     return self._the_only_eval_dataset
 
   # override base_task.task
-  def build_model(self, stage_id) -> tf.keras.Model:
+  def build_model(self, stage_id) -> tf_keras.Model:
     """Build teacher/student keras models with outputs for current stage."""
     # Freeze the teacher model.
     self._teacher_pretrainer.trainable = False
     layer_wise_config = self._progressive_config.layer_wise_distill_config
     freeze_previous_layers = layer_wise_config.if_freeze_previous_layers
     student_encoder = self._student_pretrainer.encoder_network
 
@@ -291,15 +303,15 @@
           inputs)
 
       if freeze_previous_layers:
         student_encoder.embedding_layer.trainable = False
         for i in range(stage_id):
           student_encoder.transformer_layers[i].trainable = False
 
-      return tf.keras.Model(
+      return tf_keras.Model(
           inputs=inputs,
           outputs=dict(
               student_output_feature=student_output_feature,
               student_attention_score=student_attention_score,
               teacher_output_feature=teacher_output_feature,
               teacher_attention_score=teacher_attention_score))
     else:
@@ -310,15 +322,15 @@
 
       # Set all student's transformer blocks to trainable.
       if freeze_previous_layers:
         student_encoder.embedding_layer.trainable = True
         for layer in student_encoder.transformer_layers:
           layer.trainable = True
 
-      model = tf.keras.Model(
+      model = tf_keras.Model(
           inputs=inputs,
           outputs=dict(
               student_pretrainer_output=student_pretrainer_output,
               teacher_pretrainer_output=teacher_pretrainer_output,
           ))
       # Checkpoint the student encoder which is the goal of distillation.
       model.checkpoint_items = self._student_pretrainer.checkpoint_items
@@ -362,17 +374,17 @@
     gamma_loss = tf.math.abs(student_var - teacher_var)
     gamma_loss = tf.math.reduce_mean(gamma_loss, axis=None, keepdims=False)
 
     return beta_loss, gamma_loss
 
   def _get_attention_loss(self, teacher_score, student_score):
     # Note that the definition of KLDivergence here is a little different from
-    # the original one (tf.keras.losses.KLDivergence). We adopt this approach
+    # the original one (tf_keras.losses.KLDivergence). We adopt this approach
     # to stay consistent with the TF1 implementation.
-    teacher_weight = tf.keras.activations.softmax(teacher_score, axis=-1)
+    teacher_weight = tf_keras.activations.softmax(teacher_score, axis=-1)
     student_log_weight = tf.nn.log_softmax(student_score, axis=-1)
     kl_divergence = -(teacher_weight * student_log_weight)
     kl_divergence = tf.math.reduce_sum(kl_divergence, axis=-1, keepdims=True)
     kl_divergence = tf.math.reduce_mean(kl_divergence, axis=None,
                                         keepdims=False)
     return kl_divergence
 
@@ -382,15 +394,15 @@
 
     # Layer-wise warmup stage
     if not last_stage:
       distill_config = self._progressive_config.layer_wise_distill_config
       teacher_feature = outputs['teacher_output_feature']
       student_feature = outputs['student_output_feature']
 
-      feature_transfer_loss = tf.keras.losses.mean_squared_error(
+      feature_transfer_loss = tf_keras.losses.mean_squared_error(
           self._layer_norm(teacher_feature), self._layer_norm(student_feature))
       feature_transfer_loss *= distill_config.hidden_distill_factor
       beta_loss, gamma_loss = self._get_distribution_losses(teacher_feature,
                                                             student_feature)
       beta_loss *= distill_config.beta_distill_factor
       gamma_loss *= distill_config.gamma_distill_factor
       total_loss = feature_transfer_loss + beta_loss + gamma_loss
@@ -437,15 +449,15 @@
       total_loss = mlm_loss
 
       if 'next_sentence_labels' in labels:
         sentence_labels = labels['next_sentence_labels']
         sentence_outputs = tf.cast(
             student_pretrainer_output['next_sentence'], dtype=tf.float32)
         sentence_loss = tf.reduce_mean(
-            tf.keras.losses.sparse_categorical_crossentropy(
+            tf_keras.losses.sparse_categorical_crossentropy(
                 sentence_labels, sentence_outputs, from_logits=True))
         total_loss += sentence_loss
 
     # Also update loss-related metrics here, instead of in `process_metrics`.
     metrics = dict([(metric.name, metric) for metric in metrics])
 
     if not last_stage:
@@ -463,26 +475,26 @@
 
     return total_loss
 
   # overrides base_task.Task
   def build_metrics(self, training=None):
     del training
     metrics = [
-        tf.keras.metrics.Mean(name='feature_transfer_mse'),
-        tf.keras.metrics.Mean(name='beta_transfer_loss'),
-        tf.keras.metrics.Mean(name='gamma_transfer_loss'),
-        tf.keras.metrics.SparseCategoricalAccuracy(name='masked_lm_accuracy'),
-        tf.keras.metrics.Mean(name='lm_example_loss'),
-        tf.keras.metrics.Mean(name='total_loss')]
+        tf_keras.metrics.Mean(name='feature_transfer_mse'),
+        tf_keras.metrics.Mean(name='beta_transfer_loss'),
+        tf_keras.metrics.Mean(name='gamma_transfer_loss'),
+        tf_keras.metrics.SparseCategoricalAccuracy(name='masked_lm_accuracy'),
+        tf_keras.metrics.Mean(name='lm_example_loss'),
+        tf_keras.metrics.Mean(name='total_loss')]
     if self._progressive_config.layer_wise_distill_config.if_transfer_attention:
-      metrics.append(tf.keras.metrics.Mean(name='attention_transfer_loss'))
+      metrics.append(tf_keras.metrics.Mean(name='attention_transfer_loss'))
     if self._task_config.train_data.use_next_sentence_label:
-      metrics.append(tf.keras.metrics.SparseCategoricalAccuracy(
+      metrics.append(tf_keras.metrics.SparseCategoricalAccuracy(
           name='next_sentence_accuracy'))
-      metrics.append(tf.keras.metrics.Mean(name='next_sentence_loss'))
+      metrics.append(tf_keras.metrics.Mean(name='next_sentence_loss'))
 
     return metrics
 
   # overrides base_task.Task
   # process non-loss metrics
   def process_metrics(self, metrics, labels, student_pretrainer_output):
     metrics = dict([(metric.name, metric) for metric in metrics])
@@ -494,16 +506,16 @@
             labels['masked_lm_weights'])
       if 'next_sentence_accuracy' in metrics:
         metrics['next_sentence_accuracy'].update_state(
             labels['next_sentence_labels'],
             student_pretrainer_output['next_sentence'])
 
   # overrides base_task.Task
-  def train_step(self, inputs, model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer, metrics):
+  def train_step(self, inputs, model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer, metrics):
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
       metrics: a nested structure of metrics objects.
@@ -532,15 +544,15 @@
     optimizer.apply_gradients(list(zip(grads, tvars)))
     self.process_metrics(
         metrics, inputs,
         outputs['student_pretrainer_output'] if last_stage else None)
     return {self.loss: loss}
 
   # overrides base_task.Task
-  def validation_step(self, inputs, model: tf.keras.Model, metrics):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics):
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/mobilebert/distillation_test.py` & `tf-models-no-deps-2.16.0/official/projects/mobilebert/distillation_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for official.nlp.projects.mobilebert.distillation."""
 import os
 
 from absl import logging
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.modeling import optimization
 from official.modeling import tf_utils
 from official.modeling.fast_training.progressive import trainer as prog_trainer_lib
 from official.nlp.configs import bert
 from official.nlp.configs import encoders
@@ -115,15 +115,15 @@
       ]
     else:
       teacher_cls_heads = []
 
     masked_lm = layers.MobileBertMaskedLM(
         embedding_table=teacher_encoder.get_embedding_table(),
         activation=tf_utils.get_activation(pretrainer_config.mlm_activation),
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=pretrainer_config.mlm_initializer_range),
         name='cls/predictions')
     teacher_pretrainer = models.BertPretrainerV2(
         encoder_network=teacher_encoder,
         classification_heads=teacher_cls_heads,
         customized_masked_lm=masked_lm)
 
@@ -149,15 +149,15 @@
         task_config=exp_config.task)
     metrics = bert_distillation_task.build_metrics()
     train_dataset = bert_distillation_task.get_train_dataset(stage_id=0)
     train_iterator = iter(train_dataset)
 
     eval_dataset = bert_distillation_task.get_eval_dataset(stage_id=0)
     eval_iterator = iter(eval_dataset)
-    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.1)
+    optimizer = tf_keras.optimizers.legacy.SGD(learning_rate=0.1)
 
     # test train/val step for all stages, including the last pretraining stage
     for stage in range(student_block_num + 1):
       step = stage
       bert_distillation_task.update_pt_stage(step)
       model = bert_distillation_task.get_model(stage, None)
       bert_distillation_task.initialize(model)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/mobilebert/export_tfhub.py` & `tf-models-no-deps-2.16.0/official/projects/mobilebert/export_tfhub.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """A script to export the MobileBERT encoder model as a TF-Hub SavedModel."""
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.mobilebert import model_utils
 
 FLAGS = flags.FLAGS
 
 flags.DEFINE_string(
     "bert_config_file", None,
@@ -39,32 +39,32 @@
   encoder = pretrainer.encoder_network
   encoder_inputs_dict = {x.name: x for x in encoder.inputs}
   encoder_output_dict = encoder(encoder_inputs_dict)
 
   # For interchangeability with other text representations,
   # add "default" as an alias for MobileBERT's whole-input reptesentations.
   encoder_output_dict["default"] = encoder_output_dict["pooled_output"]
-  core_model = tf.keras.Model(
+  core_model = tf_keras.Model(
       inputs=encoder_inputs_dict, outputs=encoder_output_dict)
 
   pretrainer_inputs_dict = {x.name: x for x in pretrainer.inputs}
   pretrainer_output_dict = pretrainer(pretrainer_inputs_dict)
-  mlm_model = tf.keras.Model(
+  mlm_model = tf_keras.Model(
       inputs=pretrainer_inputs_dict, outputs=pretrainer_output_dict)
   # Set `_auto_track_sub_layers` to False, so that the additional weights
   # from `mlm` sub-object will not be included in the core model.
   # TODO(b/169210253): Use public API after the bug is resolved.
   core_model._auto_track_sub_layers = False  # pylint: disable=protected-access
   core_model.mlm = mlm_model
   return core_model, pretrainer
 
 
 def export_bert_tfhub(bert_config, model_checkpoint_path, hub_destination,
                       vocab_file, do_lower_case):
-  """Restores a tf.keras.Model and saves for TF-Hub."""
+  """Restores a tf_keras.Model and saves for TF-Hub."""
   core_model, pretrainer = create_mobilebert_model(bert_config)
   checkpoint = tf.train.Checkpoint(**pretrainer.checkpoint_items)
 
   logging.info("Begin to load model")
   checkpoint.restore(model_checkpoint_path).assert_existing_objects_matched()
   logging.info("Loading model finished")
   core_model.vocab_file = tf.saved_model.Asset(vocab_file)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/mobilebert/model_utils.py` & `tf-models-no-deps-2.16.0/official/projects/mobilebert/model_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -155,15 +155,15 @@
       num_feedforward_networks=bert_config.num_feedforward_networks,
       normalization_type=bert_config.normalization_type,
       classifier_activation=bert_config.classifier_activation)
 
   masked_lm = layers.MobileBertMaskedLM(
       embedding_table=mobilebert_encoder.get_embedding_table(),
       activation=tf_utils.get_activation(bert_config.hidden_act),
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=bert_config.initializer_range),
       name="cls/predictions")
 
   pretrainer = models.BertPretrainerV2(
       encoder_network=mobilebert_encoder, customized_masked_lm=masked_lm)
   # Makes sure the pretrainer variables are created.
   _ = pretrainer(pretrainer.inputs)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/mobilebert/run_distillation.py` & `tf-models-no-deps-2.16.0/official/projects/mobilebert/run_distillation.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/mobilebert/tf2_model_checkpoint_converter.py` & `tf-models-no-deps-2.16.0/official/projects/mobilebert/tf2_model_checkpoint_converter.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/mobilebert/utils.py` & `tf-models-no-deps-2.16.0/official/projects/mobilebert/utils.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/maxvit/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/mobilebert/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/configs/movinet.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/configs/movinet.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -115,27 +115,30 @@
   """Configuration for backbones.
 
   Attributes:
     type: 'str', type of backbone be used, on the of fields below.
     movinet: movinet backbone config.
   """
   type: str = 'movinet'
-  movinet: Movinet = Movinet()
+  movinet: Movinet = dataclasses.field(default_factory=Movinet)
 
 
 @dataclasses.dataclass
 class MovinetModel(video_classification.VideoClassificationModel):
   """The MoViNet model config."""
   model_type: str = 'movinet'
-  backbone: Backbone3D = Backbone3D()
-  norm_activation: common.NormActivation = common.NormActivation(
-      activation=None,  # legacy flag, not used.
-      norm_momentum=0.99,
-      norm_epsilon=1e-3,
-      use_sync_bn=True)
+  backbone: Backbone3D = dataclasses.field(default_factory=Backbone3D)
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=lambda: common.NormActivation(  # pylint: disable=g-long-lambda
+          activation=None,  # legacy flag, not used.
+          norm_momentum=0.99,
+          norm_epsilon=1e-3,
+          use_sync_bn=True,
+      )
+  )
   activation: str = 'swish'
   output_states: bool = False
 
 
 @exp_factory.register_config_factory('movinet_kinetics600')
 def movinet_kinetics600() -> cfg.ExperimentConfig:
   """Video classification on Videonet with MoViNet backbone."""
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/configs/movinet_test.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/configs/movinet_test.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for movinet video classification."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.projects.movinet.configs import movinet
 from official.vision.configs import video_classification as exp_cfg
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 Reference: https://arxiv.org/pdf/2103.11511.pdf
 """
 import dataclasses
 import math
 from typing import Dict, Mapping, Optional, Sequence, Tuple, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.projects.movinet.modeling import movinet_layers
 from official.vision.modeling.backbones import factory
 
 # Defines a set of kernel sizes and stride sizes to simplify and shorten
 # architecture definitions for configs below.
@@ -293,28 +293,28 @@
             kernel_sizes=(K53, K15, K15, K33),
             strides=(S12, S11, S11, S11)),
         HeadSpec(project_filters=240, head_filters=1024),
     ),
 }
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class Movinet(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class Movinet(tf_keras.Model):
   """Class to build Movinet family model.
 
   Reference: https://arxiv.org/pdf/2103.11511.pdf
   """
 
   def __init__(self,
                model_id: str = 'a0',
                causal: bool = False,
                use_positional_encoding: bool = False,
                conv_type: str = '3d',
                se_type: str = '3d',
-               input_specs: Optional[tf.keras.layers.InputSpec] = None,
+               input_specs: Optional[tf_keras.layers.InputSpec] = None,
                activation: str = 'swish',
                gating_activation: str = 'sigmoid',
                use_sync_bn: bool = True,
                norm_momentum: float = 0.99,
                norm_epsilon: float = 0.001,
                kernel_initializer: str = 'HeNormal',
                kernel_regularizer: Optional[str] = None,
@@ -346,32 +346,32 @@
       activation: name of the main activation function.
       gating_activation: gating activation to use in squeeze excitation layers.
       use_sync_bn: if True, use synchronized batch normalization.
       norm_momentum: normalization momentum for the moving average.
       norm_epsilon: small float added to variance to avoid dividing by
         zero.
       kernel_initializer: kernel_initializer for convolutional layers.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
+      kernel_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
         Defaults to None.
-      bias_regularizer: tf.keras.regularizers.Regularizer object for Conv2d.
+      bias_regularizer: tf_keras.regularizers.Regularizer object for Conv2d.
         Defaults to None.
       stochastic_depth_drop_rate: the base rate for stochastic depth.
       use_external_states: if True, expects states to be passed as additional
         input.
       output_states: if True, output intermediate states that can be used to run
           the model in streaming mode. Inputting the output states of the
           previous input clip with the current input clip will utilize a stream
           buffer for streaming video.
       average_pooling_type: The average pooling type. Currently supporting
         ['3d', '2d', 'none'].
       **kwargs: keyword arguments to be passed.
     """
     block_specs = BLOCK_SPECS[model_id]
     if input_specs is None:
-      input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, None, 3])
+      input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, None, 3])
 
     if conv_type not in ('3d', '2plus1d', '3d_2plus1d'):
       raise ValueError('Unknown conv type: {}'.format(conv_type))
     if se_type not in ('3d', '2d', '2plus3d', 'none'):
       raise ValueError('Unknown squeeze excitation type: {}'.format(se_type))
 
     self._model_id = model_id
@@ -382,18 +382,15 @@
     self._se_type = se_type
     self._input_specs = input_specs
     self._use_sync_bn = use_sync_bn
     self._activation = activation
     self._gating_activation = gating_activation
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
+    self._norm = tf_keras.layers.BatchNormalization
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     self._stochastic_depth_drop_rate = stochastic_depth_drop_rate
     self._use_external_states = use_external_states
     self._output_states = output_states
     self._average_pooling_type = average_pooling_type
@@ -417,16 +414,16 @@
 
     super(Movinet, self).__init__(inputs=inputs, outputs=outputs, **kwargs)
 
     self._state_specs = state_specs
 
   def _build_network(
       self,
-      input_specs: tf.keras.layers.InputSpec,
-      state_specs: Optional[Mapping[str, tf.keras.layers.InputSpec]] = None,
+      input_specs: tf_keras.layers.InputSpec,
+      state_specs: Optional[Mapping[str, tf_keras.layers.InputSpec]] = None,
   ) -> Tuple[TensorMap, Union[TensorMap, Tuple[TensorMap, TensorMap]]]:
     """Builds the model network.
 
     Args:
       input_specs: the model input spec to use.
       state_specs: a dict mapping a state name to the corresponding state spec.
         State names should match with the `state` input/output dict.
@@ -434,18 +431,18 @@
     Returns:
       Inputs and outputs as a tuple. Inputs are expected to be a dict with
       base input and states. Outputs are expected to be a dict of endpoints
       and (optional) output states.
     """
     state_specs = state_specs if state_specs is not None else {}
 
-    image_input = tf.keras.Input(shape=input_specs.shape[1:], name='inputs')
+    image_input = tf_keras.Input(shape=input_specs.shape[1:], name='inputs')
 
     states = {
-        name: tf.keras.Input(shape=spec.shape[1:], dtype=spec.dtype, name=name)
+        name: tf_keras.Input(shape=spec.shape[1:], dtype=spec.dtype, name=name)
         for name, spec in state_specs.items()
     }
 
     inputs = {**states, 'image': image_input}
     endpoints = {}
 
     x = image_input
@@ -465,14 +462,15 @@
             causal=self._causal,
             activation=self._activation,
             kernel_initializer=self._kernel_initializer,
             kernel_regularizer=self._kernel_regularizer,
             batch_norm_layer=self._norm,
             batch_norm_momentum=self._norm_momentum,
             batch_norm_epsilon=self._norm_epsilon,
+            use_sync_bn=self._use_sync_bn,
             state_prefix='state_stem',
             name='stem')
         x, states = layer_obj(x, states=states)
         endpoints['stem'] = x
       elif isinstance(block, MovinetBlockSpec):
         if not (len(block.expand_filters) == len(block.kernel_sizes) ==
                 len(block.strides)):
@@ -504,14 +502,15 @@
               use_positional_encoding=
               self._use_positional_encoding and self._causal,
               kernel_initializer=self._kernel_initializer,
               kernel_regularizer=self._kernel_regularizer,
               batch_norm_layer=self._norm,
               batch_norm_momentum=self._norm_momentum,
               batch_norm_epsilon=self._norm_epsilon,
+              use_sync_bn=self._use_sync_bn,
               state_prefix=f'state_{name}',
               name=name)
           x, states = layer_obj(x, states=states)
 
           endpoints[name] = x
           stochastic_depth_idx += 1
       elif isinstance(block, HeadSpec):
@@ -520,14 +519,15 @@
             conv_type=self._conv_type,
             activation=self._activation,
             kernel_initializer=self._kernel_initializer,
             kernel_regularizer=self._kernel_regularizer,
             batch_norm_layer=self._norm,
             batch_norm_momentum=self._norm_momentum,
             batch_norm_epsilon=self._norm_epsilon,
+            use_sync_bn=self._use_sync_bn,
             average_pooling_type=self._average_pooling_type,
             state_prefix='state_head',
             name='head')
         x, states = layer_obj(x, states=states)
         endpoints['head'] = x
       else:
         raise ValueError('Unknown block type {}'.format(block))
@@ -636,23 +636,23 @@
   def _get_state_dtype(self, name: str) -> str:
     """Returns the dtype associated with a state."""
     if 'frame_count' in name:
       return 'int32'
     return self.dtype
 
   def initial_state_specs(
-      self, input_shape: Sequence[int]) -> Dict[str, tf.keras.layers.InputSpec]:
+      self, input_shape: Sequence[int]) -> Dict[str, tf_keras.layers.InputSpec]:
     """Creates a mapping of state name to InputSpec from the input shape."""
     state_shapes = self._get_initial_state_shapes(
         self._block_specs,
         input_shape,
         use_positional_encoding=self._use_positional_encoding)
 
     return {
-        name: tf.keras.layers.InputSpec(
+        name: tf_keras.layers.InputSpec(
             shape=shape, dtype=self._get_state_dtype(name))
         for name, shape in state_shapes.items()
     }
 
   def init_states(self, input_shape: Sequence[int]) -> Dict[str, tf.Tensor]:
     """Returns initial states for the first call in steaming mode."""
     state_shapes = self._get_initial_state_shapes(
@@ -703,18 +703,18 @@
   @classmethod
   def from_config(cls, config, custom_objects=None):
     return cls(**config)
 
 
 @factory.register_backbone_builder('movinet')
 def build_movinet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
+    l2_regularizer: tf_keras.regularizers.Regularizer = None) -> tf_keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds MoViNet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   if backbone_type != 'movinet':
     raise ValueError(f'Inconsistent backbone type {backbone_type}')
   if norm_activation_config.activation is not None:
     logging.warn('norm_activation is not used in MoViNets, but specified: '
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_layers.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_layers.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Contains common building blocks for MoViNets.
 
 Reference: https://arxiv.org/pdf/2103.11511.pdf
 """
 
 from typing import Any, Mapping, Optional, Sequence, Tuple, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.vision.modeling.layers import nn_layers
 
 # Default kernel weight decay that may be overridden
 KERNEL_WEIGHT_DECAY = 1.5e-5
 
@@ -61,25 +61,25 @@
         raise ValueError('The `' + name + '` argument must be a tuple of ' +
                          str(size) + ' integers. Received: ' + str(value) + ' '
                          'including element ' + str(single_value) + ' of type' +
                          ' ' + str(type(single_value)))
     return value_tuple
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class Squeeze3D(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class Squeeze3D(tf_keras.layers.Layer):
   """Squeeze3D layer to remove singular dimensions."""
 
   def call(self, inputs):
     """Calls the layer with the given inputs."""
     return tf.squeeze(inputs, axis=(1, 2, 3))
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MobileConv2D(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MobileConv2D(tf_keras.layers.Layer):
   """Conv2D layer with extra options to support mobile devices.
 
   Reshapes 5D video tensor inputs to 4D, allowing Conv2D to run across
   dimensions (2, 3) or (3, 4). Reshapes tensors back to 5D when returning the
   output.
   """
 
@@ -91,28 +91,28 @@
       padding: str = 'valid',
       data_format: Optional[str] = None,
       dilation_rate: Union[int, Sequence[int]] = (1, 1),
       groups: int = 1,
       use_bias: bool = True,
       kernel_initializer: str = 'glorot_uniform',
       bias_initializer: str = 'zeros',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      activity_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      kernel_constraint: Optional[tf.keras.constraints.Constraint] = None,
-      bias_constraint: Optional[tf.keras.constraints.Constraint] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      activity_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      kernel_constraint: Optional[tf_keras.constraints.Constraint] = None,
+      bias_constraint: Optional[tf_keras.constraints.Constraint] = None,
       use_depthwise: bool = False,
       use_temporal: bool = False,
       use_buffered_input: bool = False,  # pytype: disable=annotation-type-mismatch  # typed-keras
       batch_norm_op: Optional[Any] = None,
       activation_op: Optional[Any] = None,
       **kwargs):  # pylint: disable=g-doc-args
     """Initializes mobile conv2d.
 
-    For the majority of arguments, see tf.keras.layers.Conv2D.
+    For the majority of arguments, see tf_keras.layers.Conv2D.
 
     Args:
       use_depthwise: if True, use DepthwiseConv2D instead of Conv2D
       use_temporal: if True, apply Conv2D starting from the temporal dimension
           instead of the spatial dimensions.
       use_buffered_input: if True, the input is expected to be padded
           beforehand. In effect, calling this layer will use 'valid' padding on
@@ -251,34 +251,35 @@
           tf.shape(x)[2],
           x.shape[3]]
     x = tf.reshape(x, output_shape)
 
     return x
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ConvBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ConvBlock(tf_keras.layers.Layer):
   """A Conv followed by optional BatchNorm and Activation."""
 
   def __init__(
       self,
       filters: int,
       kernel_size: Union[int, Sequence[int]],
       strides: Union[int, Sequence[int]] = 1,
       depthwise: bool = False,
       causal: bool = False,
       use_bias: bool = False,
-      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] =
-      tf.keras.regularizers.L2(KERNEL_WEIGHT_DECAY),
+      kernel_initializer: tf_keras.initializers.Initializer = 'HeNormal',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] =
+      tf_keras.regularizers.L2(KERNEL_WEIGHT_DECAY),
       use_batch_norm: bool = True,
-      batch_norm_layer: tf.keras.layers.Layer =
-      tf.keras.layers.BatchNormalization,
+      batch_norm_layer: tf_keras.layers.Layer =
+      tf_keras.layers.BatchNormalization,
       batch_norm_momentum: float = 0.99,
       batch_norm_epsilon: float = 1e-3,
+      use_sync_bn: bool = False,
       activation: Optional[Any] = None,
       conv_type: str = '3d',
       use_buffered_input: bool = False,  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     """Initializes a conv block.
 
     Args:
@@ -290,14 +291,15 @@
       use_bias: use bias for the conv operation.
       kernel_initializer: kernel initializer for the conv operation.
       kernel_regularizer: kernel regularizer for the conv operation.
       use_batch_norm: if True, apply batch norm after the conv operation.
       batch_norm_layer: class to use for batch norm, if applied.
       batch_norm_momentum: momentum of the batch norm operation, if applied.
       batch_norm_epsilon: epsilon of the batch norm operation, if applied.
+      use_sync_bn: if True, use synchronized batch normalization.
       activation: activation after the conv and batch norm operations.
       conv_type: '3d', '2plus1d', or '3d_2plus1d'. '3d' uses the default 3D
           ops. '2plus1d' split any 3D ops into two sequential 2D ops with their
           own batch norm and activation. '3d_2plus1d' is like '2plus1d', but
           uses two sequential 3D ops instead.
       use_buffered_input: if True, the input is expected to be padded
           beforehand. In effect, calling this layer will use 'valid' padding on
@@ -321,14 +323,15 @@
     self._use_bias = use_bias
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._use_batch_norm = use_batch_norm
     self._batch_norm_layer = batch_norm_layer
     self._batch_norm_momentum = batch_norm_momentum
     self._batch_norm_epsilon = batch_norm_epsilon
+    self._use_sync_bn = use_sync_bn
     self._activation = activation
     self._conv_type = conv_type
     self._use_buffered_input = use_buffered_input
 
     if activation is not None:
       self._activation_layer = tf_utils.get_activation(
           activation, use_keras_layer=True)
@@ -347,14 +350,15 @@
         'causal': self._causal,
         'use_bias': self._use_bias,
         'kernel_initializer': self._kernel_initializer,
         'kernel_regularizer': self._kernel_regularizer,
         'use_batch_norm': self._use_batch_norm,
         'batch_norm_momentum': self._batch_norm_momentum,
         'batch_norm_epsilon': self._batch_norm_epsilon,
+        'use_sync_bn': self._use_sync_bn,
         'activation': self._activation,
         'conv_type': self._conv_type,
         'use_buffered_input': self._use_buffered_input,
     }
     base_config = super(ConvBlock, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
@@ -365,19 +369,21 @@
 
     self._batch_norm = None
     self._batch_norm_temporal = None
     if self._use_batch_norm:
       self._batch_norm = self._batch_norm_layer(
           momentum=self._batch_norm_momentum,
           epsilon=self._batch_norm_epsilon,
+          synchronized=self._use_sync_bn,
           name='bn')
       if self._conv_type != '3d' and self._kernel_size[0] > 1:
         self._batch_norm_temporal = self._batch_norm_layer(
             momentum=self._batch_norm_momentum,
             epsilon=self._batch_norm_epsilon,
+            synchronized=self._use_sync_bn,
             name='bn_temporal')
 
     self._conv_temporal = None
     if self._conv_type == '3d_2plus1d' and self._kernel_size[0] > 1:
       self._conv = nn_layers.Conv3D(
           self._filters,
           (1, self._kernel_size[1], self._kernel_size[2]),
@@ -465,16 +471,16 @@
         x = self._batch_norm_temporal(x)
       if self._activation_layer is not None and self._conv_type != '2plus1d':
         x = self._activation_layer(x)
 
     return x
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class StreamBuffer(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class StreamBuffer(tf_keras.layers.Layer):
   """Stream buffer wrapper which caches activations of previous frames."""
 
   def __init__(self,
                buffer_size: int,
                state_prefix: Optional[str] = None,
                **kwargs):
     """Initializes a stream buffer.
@@ -540,34 +546,35 @@
     # frames.
     new_buffer = full_inputs[:, -self._buffer_size:]
     states[self._state_name] = new_buffer
 
     return full_inputs, states
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
+@tf_keras.utils.register_keras_serializable(package='Vision')
 class StreamConvBlock(ConvBlock):
   """ConvBlock with StreamBuffer."""
 
   def __init__(
       self,
       filters: int,
       kernel_size: Union[int, Sequence[int]],
       strides: Union[int, Sequence[int]] = 1,
       depthwise: bool = False,
       causal: bool = False,
       use_bias: bool = False,
-      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = tf.keras
+      kernel_initializer: tf_keras.initializers.Initializer = 'HeNormal',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = tf.keras
       .regularizers.L2(KERNEL_WEIGHT_DECAY),
       use_batch_norm: bool = True,
-      batch_norm_layer: tf.keras.layers.Layer =
-      tf.keras.layers.BatchNormalization,
+      batch_norm_layer: tf_keras.layers.Layer =
+      tf_keras.layers.BatchNormalization,
       batch_norm_momentum: float = 0.99,
       batch_norm_epsilon: float = 1e-3,
+      use_sync_bn: bool = False,
       activation: Optional[Any] = None,
       conv_type: str = '3d',
       state_prefix: Optional[str] = None,  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     """Initializes a stream conv block.
 
     Args:
@@ -579,14 +586,15 @@
       use_bias: use bias for the conv operation.
       kernel_initializer: kernel initializer for the conv operation.
       kernel_regularizer: kernel regularizer for the conv operation.
       use_batch_norm: if True, apply batch norm after the conv operation.
       batch_norm_layer: class to use for batch norm, if applied.
       batch_norm_momentum: momentum of the batch norm operation, if applied.
       batch_norm_epsilon: epsilon of the batch norm operation, if applied.
+      use_sync_bn: if True, use synchronized batch normalization.
       activation: activation after the conv and batch norm operations.
       conv_type: '3d', '2plus1d', or '3d_2plus1d'. '3d' uses the default 3D
           ops. '2plus1d' split any 3D ops into two sequential 2D ops with their
           own batch norm and activation. '3d_2plus1d' is like '2plus1d', but
           uses two sequential 3D ops instead.
       state_prefix: a prefix string to identify states.
       **kwargs: keyword arguments to be passed to this layer.
@@ -609,14 +617,15 @@
         use_bias=use_bias,
         kernel_initializer=kernel_initializer,
         kernel_regularizer=kernel_regularizer,
         use_batch_norm=use_batch_norm,
         batch_norm_layer=batch_norm_layer,
         batch_norm_momentum=batch_norm_momentum,
         batch_norm_epsilon=batch_norm_epsilon,
+        use_sync_bn=use_sync_bn,
         activation=activation,
         conv_type=conv_type,
         use_buffered_input=use_buffer,
         **kwargs)
 
     self._stream_buffer = None
     if use_buffer:
@@ -671,31 +680,31 @@
         x = self._batch_norm_temporal(x)
       if self._activation_layer is not None and self._conv_type != '2plus1d':
         x = self._activation_layer(x)
 
     return x, states
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class StreamSqueezeExcitation(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class StreamSqueezeExcitation(tf_keras.layers.Layer):
   """Squeeze and excitation layer with causal mode.
 
   Reference: https://arxiv.org/pdf/1709.01507.pdf
   """
 
   def __init__(
       self,
       hidden_filters: int,
       se_type: str = '3d',
       activation: nn_layers.Activation = 'swish',
       gating_activation: nn_layers.Activation = 'sigmoid',
       causal: bool = False,
       conv_type: str = '3d',
-      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = tf.keras
+      kernel_initializer: tf_keras.initializers.Initializer = 'HeNormal',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = tf.keras
       .regularizers.L2(KERNEL_WEIGHT_DECAY),
       use_positional_encoding: bool = False,
       state_prefix: Optional[str] = None,  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     """Implementation for squeeze and excitation.
 
     Args:
@@ -824,28 +833,28 @@
 
     x = self._se_reduce(x)
     x = self._se_expand(x)
 
     return x * inputs, states
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MobileBottleneck(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MobileBottleneck(tf_keras.layers.Layer):
   """A depthwise inverted bottleneck block.
 
   Uses dependency injection to allow flexible definition of different layers
   within this block.
   """
 
   def __init__(self,
-               expansion_layer: tf.keras.layers.Layer,
-               feature_layer: tf.keras.layers.Layer,
-               projection_layer: tf.keras.layers.Layer,
-               attention_layer: Optional[tf.keras.layers.Layer] = None,
-               skip_layer: Optional[tf.keras.layers.Layer] = None,
+               expansion_layer: tf_keras.layers.Layer,
+               feature_layer: tf_keras.layers.Layer,
+               projection_layer: tf_keras.layers.Layer,
+               attention_layer: Optional[tf_keras.layers.Layer] = None,
+               skip_layer: Optional[tf_keras.layers.Layer] = None,
                stochastic_depth_drop_rate: Optional[float] = None,
                **kwargs):
     """Implementation for mobile bottleneck.
 
     Args:
       expansion_layer: initial layer used for pointwise expansion.
       feature_layer: main layer used for computing 3D features.
@@ -859,15 +868,15 @@
     """
     super(MobileBottleneck, self).__init__(**kwargs)
 
     self._projection_layer = projection_layer
     self._attention_layer = attention_layer
     self._skip_layer = skip_layer
     self._stochastic_depth_drop_rate = stochastic_depth_drop_rate
-    self._identity = tf.keras.layers.Activation(tf.identity)
+    self._identity = tf_keras.layers.Activation(tf.identity)
     self._rezero = nn_layers.Scale(initializer='zeros', name='rezero')
 
     if stochastic_depth_drop_rate:
       self._stochastic_depth = nn_layers.StochasticDepth(
           stochastic_depth_drop_rate, name='stochastic_depth')
     else:
       self._stochastic_depth = None
@@ -917,30 +926,31 @@
       skip = self._skip_layer(inputs)
     else:
       skip = inputs
 
     return x + skip, states
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class SkipBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SkipBlock(tf_keras.layers.Layer):
   """Skip block for bottleneck blocks."""
 
   def __init__(
       self,
       out_filters: int,
       downsample: bool = False,
       conv_type: str = '3d',
-      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] =
-      tf.keras.regularizers.L2(KERNEL_WEIGHT_DECAY),
-      batch_norm_layer: tf.keras.layers.Layer =
-      tf.keras.layers.BatchNormalization,
+      kernel_initializer: tf_keras.initializers.Initializer = 'HeNormal',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] =
+      tf_keras.regularizers.L2(KERNEL_WEIGHT_DECAY),
+      batch_norm_layer: tf_keras.layers.Layer =
+      tf_keras.layers.BatchNormalization,
       batch_norm_momentum: float = 0.99,
       batch_norm_epsilon: float = 1e-3,  # pytype: disable=annotation-type-mismatch  # typed-keras
+      use_sync_bn: bool = False,
       **kwargs):
     """Implementation for skip block.
 
     Args:
       out_filters: the number of projected output filters.
       downsample: if True, downsamples the input by a factor of 2 by applying
           average pooling with a 3x3 kernel size on the spatial dimensions.
@@ -949,48 +959,51 @@
           own batch norm and activation. '3d_2plus1d' is like '2plus1d', but
           uses two sequential 3D ops instead.
       kernel_initializer: kernel initializer for the conv operations.
       kernel_regularizer: kernel regularizer for the conv projection.
       batch_norm_layer: class to use for batch norm.
       batch_norm_momentum: momentum of the batch norm operation.
       batch_norm_epsilon: epsilon of the batch norm operation.
+      use_sync_bn: if True, use synchronized batch normalization.
       **kwargs: keyword arguments to be passed to this layer.
     """
     super(SkipBlock, self).__init__(**kwargs)
 
     self._out_filters = out_filters
     self._downsample = downsample
     self._conv_type = conv_type
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._batch_norm_layer = batch_norm_layer
     self._batch_norm_momentum = batch_norm_momentum
     self._batch_norm_epsilon = batch_norm_epsilon
+    self._use_sync_bn = use_sync_bn
 
     self._projection = ConvBlock(
         filters=self._out_filters,
         kernel_size=1,
         conv_type=conv_type,
         kernel_initializer=kernel_initializer,
         kernel_regularizer=kernel_regularizer,
         use_batch_norm=True,
         batch_norm_layer=self._batch_norm_layer,
         batch_norm_momentum=self._batch_norm_momentum,
         batch_norm_epsilon=self._batch_norm_epsilon,
+        use_sync_bn=self._use_sync_bn,
         name='skip_project')
 
     if downsample:
       if self._conv_type == '2plus1d':
-        self._pool = tf.keras.layers.AveragePooling2D(
+        self._pool = tf_keras.layers.AveragePooling2D(
             pool_size=(3, 3),
             strides=(2, 2),
             padding='same',
             name='skip_pool')
       else:
-        self._pool = tf.keras.layers.AveragePooling3D(
+        self._pool = tf_keras.layers.AveragePooling3D(
             pool_size=(1, 3, 3),
             strides=(1, 2, 2),
             padding='same',
             name='skip_pool')
     else:
       self._pool = None
 
@@ -1000,14 +1013,15 @@
         'out_filters': self._out_filters,
         'downsample': self._downsample,
         'conv_type': self._conv_type,
         'kernel_initializer': self._kernel_initializer,
         'kernel_regularizer': self._kernel_regularizer,
         'batch_norm_momentum': self._batch_norm_momentum,
         'batch_norm_epsilon': self._batch_norm_epsilon,
+        'use_sync_bn': self._use_sync_bn
     }
     base_config = super(SkipBlock, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs):
     """Calls the layer with the given inputs."""
     x = inputs
@@ -1021,16 +1035,16 @@
         x = tf.reshape(
             x,
             [tf.shape(inputs)[0], -1, tf.shape(x)[1],
              tf.shape(x)[2], x.shape[3]])
     return self._projection(x)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MovinetBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MovinetBlock(tf_keras.layers.Layer):
   """A basic block for MoViNets.
 
   Applies a mobile inverted bottleneck with pointwise expansion, 3D depthwise
   convolution, 3D squeeze excite, pointwise projection, and residual connection.
   """
 
   def __init__(
@@ -1043,21 +1057,22 @@
       activation: nn_layers.Activation = 'swish',
       gating_activation: nn_layers.Activation = 'sigmoid',
       se_ratio: float = 0.25,
       stochastic_depth_drop_rate: float = 0.,
       conv_type: str = '3d',
       se_type: str = '3d',
       use_positional_encoding: bool = False,
-      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = tf.keras
+      kernel_initializer: tf_keras.initializers.Initializer = 'HeNormal',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = tf.keras
       .regularizers.L2(KERNEL_WEIGHT_DECAY),
-      batch_norm_layer: tf.keras.layers.Layer =
-      tf.keras.layers.BatchNormalization,
+      batch_norm_layer: tf_keras.layers.Layer =
+      tf_keras.layers.BatchNormalization,
       batch_norm_momentum: float = 0.99,
       batch_norm_epsilon: float = 1e-3,
+      use_sync_bn: bool = False,
       state_prefix: Optional[str] = None,  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     """Implementation for MoViNet block.
 
     Args:
       out_filters: number of output filters for the final projection.
       expand_filters: number of expansion filters after the input.
@@ -1079,14 +1094,15 @@
       use_positional_encoding: add a positional encoding after the (cumulative)
           global average pooling layer in the squeeze excite layer.
       kernel_initializer: kernel initializer for the conv operations.
       kernel_regularizer: kernel regularizer for the conv operations.
       batch_norm_layer: class to use for batch norm.
       batch_norm_momentum: momentum of the batch norm operation.
       batch_norm_epsilon: epsilon of the batch norm operation.
+      use_sync_bn: if True, use synchronized batch normalization.
       state_prefix: a prefix string to identify states.
       **kwargs: keyword arguments to be passed to this layer.
     """
     super(MovinetBlock, self).__init__(**kwargs)
 
     self._kernel_size = normalize_tuple(kernel_size, 3, 'kernel_size')
     self._strides = normalize_tuple(strides, 3, 'strides')
@@ -1107,27 +1123,29 @@
     self._se_type = se_type
     self._use_positional_encoding = use_positional_encoding
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._batch_norm_layer = batch_norm_layer
     self._batch_norm_momentum = batch_norm_momentum
     self._batch_norm_epsilon = batch_norm_epsilon
+    self._use_sync_bn = use_sync_bn
     self._state_prefix = state_prefix
 
     self._expansion = ConvBlock(
         expand_filters,
         (1, 1, 1),
         activation=activation,
         conv_type=conv_type,
         kernel_initializer=kernel_initializer,
         kernel_regularizer=kernel_regularizer,
         use_batch_norm=True,
         batch_norm_layer=self._batch_norm_layer,
         batch_norm_momentum=self._batch_norm_momentum,
         batch_norm_epsilon=self._batch_norm_epsilon,
+        use_sync_bn=self._use_sync_bn,
         name='expansion')
     self._feature = StreamConvBlock(
         expand_filters,
         self._kernel_size,
         strides=self._strides,
         depthwise=True,
         causal=self._causal,
@@ -1135,27 +1153,29 @@
         conv_type=conv_type,
         kernel_initializer=kernel_initializer,
         kernel_regularizer=kernel_regularizer,
         use_batch_norm=True,
         batch_norm_layer=self._batch_norm_layer,
         batch_norm_momentum=self._batch_norm_momentum,
         batch_norm_epsilon=self._batch_norm_epsilon,
+        use_sync_bn=self._use_sync_bn,
         state_prefix=state_prefix,
         name='feature')
     self._projection = ConvBlock(
         out_filters,
         (1, 1, 1),
         activation=None,
         conv_type=conv_type,
         kernel_initializer=kernel_initializer,
         kernel_regularizer=kernel_regularizer,
         use_batch_norm=True,
         batch_norm_layer=self._batch_norm_layer,
         batch_norm_momentum=self._batch_norm_momentum,
         batch_norm_epsilon=self._batch_norm_epsilon,
+        use_sync_bn=self._use_sync_bn,
         name='projection')
     self._attention = None
     if se_type != 'none':
       self._attention = StreamSqueezeExcitation(
           se_hidden_filters,
           se_type=se_type,
           activation=activation,
@@ -1183,14 +1203,15 @@
         'conv_type': self._conv_type,
         'se_type': self._se_type,
         'use_positional_encoding': self._use_positional_encoding,
         'kernel_initializer': self._kernel_initializer,
         'kernel_regularizer': self._kernel_regularizer,
         'batch_norm_momentum': self._batch_norm_momentum,
         'batch_norm_epsilon': self._batch_norm_epsilon,
+        'use_sync_bn': self._use_sync_bn,
         'state_prefix': self._state_prefix,
     }
     base_config = super(MovinetBlock, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def build(self, input_shape):
     """Builds the layer with the given input shape."""
@@ -1230,36 +1251,37 @@
     Returns:
       the output tensor and states
     """
     states = dict(states) if states is not None else {}
     return self._mobile_bottleneck(inputs, states=states)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class Stem(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class Stem(tf_keras.layers.Layer):
   """Stem layer for video networks.
 
   Applies an initial convolution block operation.
   """
 
   def __init__(
       self,
       out_filters: int,
       kernel_size: Union[int, Sequence[int]],
       strides: Union[int, Sequence[int]] = (1, 1, 1),
       causal: bool = False,
       conv_type: str = '3d',
       activation: nn_layers.Activation = 'swish',
-      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = tf.keras
+      kernel_initializer: tf_keras.initializers.Initializer = 'HeNormal',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = tf.keras
       .regularizers.L2(KERNEL_WEIGHT_DECAY),
-      batch_norm_layer: tf.keras.layers.Layer =
-      tf.keras.layers.BatchNormalization,
+      batch_norm_layer: tf_keras.layers.Layer =
+      tf_keras.layers.BatchNormalization,
       batch_norm_momentum: float = 0.99,
       batch_norm_epsilon: float = 1e-3,
+      use_sync_bn: bool = False,
       state_prefix: Optional[str] = None,  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     """Implementation for video model stem.
 
     Args:
       out_filters: number of output filters.
       kernel_size: kernel size of the convolution.
@@ -1271,14 +1293,15 @@
           uses two sequential 3D ops instead.
       activation: the input activation name.
       kernel_initializer: kernel initializer for the conv operations.
       kernel_regularizer: kernel regularizer for the conv operations.
       batch_norm_layer: class to use for batch norm.
       batch_norm_momentum: momentum of the batch norm operation.
       batch_norm_epsilon: epsilon of the batch norm operation.
+      use_sync_bn: if True, use synchronized batch normalization.
       state_prefix: a prefix string to identify states.
       **kwargs: keyword arguments to be passed to this layer.
     """
     super(Stem, self).__init__(**kwargs)
 
     self._out_filters = out_filters
     self._kernel_size = normalize_tuple(kernel_size, 3, 'kernel_size')
@@ -1287,14 +1310,15 @@
     self._conv_type = conv_type
     self._activation = activation
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._batch_norm_layer = batch_norm_layer
     self._batch_norm_momentum = batch_norm_momentum
     self._batch_norm_epsilon = batch_norm_epsilon
+    self._use_sync_bn = use_sync_bn
     self._state_prefix = state_prefix
 
     self._stem = StreamConvBlock(
         filters=self._out_filters,
         kernel_size=self._kernel_size,
         strides=self._strides,
         causal=self._causal,
@@ -1302,14 +1326,15 @@
         conv_type=self._conv_type,
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         use_batch_norm=True,
         batch_norm_layer=self._batch_norm_layer,
         batch_norm_momentum=self._batch_norm_momentum,
         batch_norm_epsilon=self._batch_norm_epsilon,
+        use_sync_bn=self._use_sync_bn,
         state_prefix=self._state_prefix,
         name='stem')
 
   def get_config(self):
     """Returns a dictionary containing the config used for initialization."""
     config = {
         'out_filters': self._out_filters,
@@ -1318,14 +1343,15 @@
         'causal': self._causal,
         'activation': self._activation,
         'conv_type': self._conv_type,
         'kernel_initializer': self._kernel_initializer,
         'kernel_regularizer': self._kernel_regularizer,
         'batch_norm_momentum': self._batch_norm_momentum,
         'batch_norm_epsilon': self._batch_norm_epsilon,
+        'use_sync_bn': self._use_sync_bn,
         'state_prefix': self._state_prefix,
     }
     base_config = super(Stem, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self,
            inputs: tf.Tensor,
@@ -1341,33 +1367,34 @@
     Returns:
       the output tensor and states
     """
     states = dict(states) if states is not None else {}
     return self._stem(inputs, states=states)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class Head(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class Head(tf_keras.layers.Layer):
   """Head layer for video networks.
 
   Applies pointwise projection and global pooling.
   """
 
   def __init__(
       self,
       project_filters: int,
       conv_type: str = '3d',
       activation: nn_layers.Activation = 'swish',
-      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = tf.keras
+      kernel_initializer: tf_keras.initializers.Initializer = 'HeNormal',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = tf.keras
       .regularizers.L2(KERNEL_WEIGHT_DECAY),
-      batch_norm_layer: tf.keras.layers.Layer =
-      tf.keras.layers.BatchNormalization,
+      batch_norm_layer: tf_keras.layers.Layer =
+      tf_keras.layers.BatchNormalization,
       batch_norm_momentum: float = 0.99,
       batch_norm_epsilon: float = 1e-3,
+      use_sync_bn: bool = False,
       average_pooling_type: str = '3d',
       state_prefix: Optional[str] = None,  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     """Implementation for video model head.
 
     Args:
       project_filters: number of pointwise projection filters.
@@ -1377,14 +1404,15 @@
           uses two sequential 3D ops instead.
       activation: the input activation name.
       kernel_initializer: kernel initializer for the conv operations.
       kernel_regularizer: kernel regularizer for the conv operations.
       batch_norm_layer: class to use for batch norm.
       batch_norm_momentum: momentum of the batch norm operation.
       batch_norm_epsilon: epsilon of the batch norm operation.
+      use_sync_bn: if True, use synchronized batch normalization.
       average_pooling_type: The average pooling type. Currently supporting
         ['3d', '2d', 'none'].
       state_prefix: a prefix string to identify states.
       **kwargs: keyword arguments to be passed to this layer.
     """
     super(Head, self).__init__(**kwargs)
 
@@ -1392,26 +1420,28 @@
     self._conv_type = conv_type
     self._activation = activation
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._batch_norm_layer = batch_norm_layer
     self._batch_norm_momentum = batch_norm_momentum
     self._batch_norm_epsilon = batch_norm_epsilon
+    self._use_sync_bn = use_sync_bn
     self._state_prefix = state_prefix
 
     self._project = ConvBlock(
         filters=project_filters,
         kernel_size=1,
         activation=activation,
         conv_type=conv_type,
         kernel_regularizer=kernel_regularizer,
         use_batch_norm=True,
         batch_norm_layer=self._batch_norm_layer,
         batch_norm_momentum=self._batch_norm_momentum,
         batch_norm_epsilon=self._batch_norm_epsilon,
+        use_sync_bn=self._use_sync_bn,
         name='project')
     if average_pooling_type.lower() == '3d':
       self._pool = nn_layers.GlobalAveragePool3D(
           keepdims=True, causal=False, state_prefix=state_prefix)
     elif average_pooling_type.lower() == '2d':
       self._pool = nn_layers.SpatialAveragePool3D(keepdims=True)
     elif average_pooling_type == 'none':
@@ -1426,14 +1456,15 @@
         'project_filters': self._project_filters,
         'conv_type': self._conv_type,
         'activation': self._activation,
         'kernel_initializer': self._kernel_initializer,
         'kernel_regularizer': self._kernel_regularizer,
         'batch_norm_momentum': self._batch_norm_momentum,
         'batch_norm_epsilon': self._batch_norm_epsilon,
+        'use_sync_bn': self._use_sync_bn,
         'state_prefix': self._state_prefix,
     }
     base_config = super(Head, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(
       self,
@@ -1455,16 +1486,16 @@
     if self._pool is not None:
       outputs = self._pool(x, states=states, output_states=True)
     else:
       outputs = (x, states)
     return outputs
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ClassifierHead(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ClassifierHead(tf_keras.layers.Layer):
   """Head layer for video networks.
 
   Applies dense projection, dropout, and classifier projection. Expects input
   to be pooled vector with shape [batch_size, 1, 1, 1, num_channels]
   """
 
   def __init__(
@@ -1472,17 +1503,17 @@
       head_filters: int,
       num_classes: int,
       dropout_rate: float = 0.,
       conv_type: str = '3d',
       activation: nn_layers.Activation = 'swish',
       output_activation: Optional[nn_layers.Activation] = None,
       max_pool_predictions: bool = False,
-      kernel_initializer: tf.keras.initializers.Initializer = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] =
-      tf.keras.regularizers.L2(KERNEL_WEIGHT_DECAY),  # pytype: disable=annotation-type-mismatch  # typed-keras
+      kernel_initializer: tf_keras.initializers.Initializer = 'HeNormal',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] =
+      tf_keras.regularizers.L2(KERNEL_WEIGHT_DECAY),  # pytype: disable=annotation-type-mismatch  # typed-keras
       **kwargs):
     """Implementation for video model classifier head.
 
     Args:
       head_filters: number of dense head projection filters.
       num_classes: number of output classes for the final logits.
       dropout_rate: the dropout rate applied to the head projection.
@@ -1507,39 +1538,39 @@
     self._conv_type = conv_type
     self._activation = activation
     self._output_activation = output_activation
     self._max_pool_predictions = max_pool_predictions
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
 
-    self._dropout = tf.keras.layers.Dropout(dropout_rate)
+    self._dropout = tf_keras.layers.Dropout(dropout_rate)
     self._head = ConvBlock(
         filters=head_filters,
         kernel_size=1,
         activation=activation,
         use_bias=True,
         use_batch_norm=False,
         conv_type=conv_type,
         kernel_initializer=kernel_initializer,
         kernel_regularizer=kernel_regularizer,
         name='head')
     self._classifier = ConvBlock(
         filters=num_classes,
         kernel_size=1,
-        kernel_initializer=tf.keras.initializers.random_normal(stddev=0.01),
+        kernel_initializer=tf_keras.initializers.random_normal(stddev=0.01),
         kernel_regularizer=None,
         use_bias=True,
         use_batch_norm=False,
         conv_type=conv_type,
         name='classifier')
     self._max_pool = nn_layers.TemporalSoftmaxPool()
     self._squeeze = Squeeze3D()
 
     output_activation = output_activation if output_activation else 'linear'
-    self._cast = tf.keras.layers.Activation(
+    self._cast = tf_keras.layers.Activation(
         output_activation, dtype='float32', name='cast')
 
   def get_config(self):
     """Returns a dictionary containing the config used for initialization."""
     config = {
         'head_filters': self._head_filters,
         'num_classes': self._num_classes,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_layers_test.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_layers_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for movinet_layers.py."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.movinet.modeling import movinet_layers
 from official.vision.modeling.layers import nn_layers
 
 
 class MovinetLayersTest(parameterized.TestCase, tf.test.TestCase):
 
@@ -60,15 +60,15 @@
            [[12., 12., 12.],
             [12., 12., 12.]]]]])
 
     self.assertEqual(predicted.shape, expected.shape)
     self.assertAllClose(predicted, expected)
 
   def test_mobile_conv2d_bn(self):
-    batch_norm_op = tf.keras.layers.BatchNormalization(
+    batch_norm_op = tf_keras.layers.BatchNormalization(
         momentum=0.9,
         epsilon=1.,
         name='bn')
     conv2d = movinet_layers.MobileConv2D(
         filters=3,
         kernel_size=(3, 3),
         strides=(1, 1),
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_model.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,36 +15,36 @@
 """Build Movinet for video classification.
 
 Reference: https://arxiv.org/pdf/2103.11511.pdf
 """
 from typing import Any, Dict, Mapping, Optional, Sequence, Tuple, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.movinet.configs import movinet as cfg
 from official.projects.movinet.modeling import movinet_layers
 from official.vision.modeling import backbones
 from official.vision.modeling import factory_3d as model_factory
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MovinetClassifier(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MovinetClassifier(tf_keras.Model):
   """A video classification class builder."""
 
   def __init__(
       self,
-      backbone: tf.keras.Model,
+      backbone: tf_keras.Model,
       num_classes: int,
-      input_specs: Optional[Mapping[str, tf.keras.layers.InputSpec]] = None,
+      input_specs: Optional[Mapping[str, tf_keras.layers.InputSpec]] = None,
       activation: str = 'swish',
       dropout_rate: float = 0.0,
       kernel_initializer: str = 'HeNormal',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       output_states: bool = False,
       **kwargs):
     """Movinet initialization function.
 
     Args:
       backbone: A 3d backbone network.
       num_classes: Number of classes in classification task.
@@ -58,15 +58,15 @@
           the model in streaming mode. Inputting the output states of the
           previous input clip with the current input clip will utilize a stream
           buffer for streaming video.
       **kwargs: Keyword arguments to be passed.
     """
     if not input_specs:
       input_specs = {
-          'image': tf.keras.layers.InputSpec(shape=[None, None, None, None, 3])
+          'image': tf_keras.layers.InputSpec(shape=[None, None, None, None, 3])
       }
 
     self._num_classes = num_classes
     self._input_specs = input_specs
     self._activation = activation
     self._dropout_rate = dropout_rate
     self._kernel_initializer = kernel_initializer
@@ -86,17 +86,17 @@
         inputs=inputs, outputs=outputs, **kwargs)
 
     # Move backbone after super() call so Keras is happy
     self._backbone = backbone
 
   def _build_backbone(
       self,
-      backbone: tf.keras.Model,
-      input_specs: Mapping[str, tf.keras.layers.InputSpec],
-      state_specs: Optional[Mapping[str, tf.keras.layers.InputSpec]] = None,
+      backbone: tf_keras.Model,
+      input_specs: Mapping[str, tf_keras.layers.InputSpec],
+      state_specs: Optional[Mapping[str, tf_keras.layers.InputSpec]] = None,
   ) -> Tuple[Mapping[str, Any], Any, Any]:
     """Builds the backbone network and gets states and endpoints.
 
     Args:
       backbone: the model backbone.
       input_specs: the model input spec to use.
       state_specs: a dict of states such that, if any of the keys match for a
@@ -106,18 +106,18 @@
       inputs: a dict of input specs.
       endpoints: a dict of model endpoints.
       states: a dict of model states.
     """
     state_specs = state_specs if state_specs is not None else {}
 
     states = {
-        name: tf.keras.Input(shape=spec.shape[1:], dtype=spec.dtype, name=name)
+        name: tf_keras.Input(shape=spec.shape[1:], dtype=spec.dtype, name=name)
         for name, spec in state_specs.items()
     }
-    image = tf.keras.Input(shape=input_specs['image'].shape[1:], name='image')
+    image = tf_keras.Input(shape=input_specs['image'].shape[1:], name='image')
     inputs = {**states, 'image': image}
 
     if backbone.use_external_states:
       before_states = states
       endpoints, states = backbone(inputs)
       after_states = states
 
@@ -144,18 +144,18 @@
                 mismatched_shapes))
     else:
       endpoints, states = backbone(inputs)
     return inputs, endpoints, states
 
   def _build_network(
       self,
-      backbone: tf.keras.Model,
-      input_specs: Mapping[str, tf.keras.layers.InputSpec],
-      state_specs: Optional[Mapping[str, tf.keras.layers.InputSpec]] = None,
-  ) -> Tuple[Mapping[str, tf.keras.Input], Union[Tuple[Mapping[  # pytype: disable=invalid-annotation  # typed-keras
+      backbone: tf_keras.Model,
+      input_specs: Mapping[str, tf_keras.layers.InputSpec],
+      state_specs: Optional[Mapping[str, tf_keras.layers.InputSpec]] = None,
+  ) -> Tuple[Mapping[str, tf_keras.Input], Union[Tuple[Mapping[  # pytype: disable=invalid-annotation  # typed-keras
       str, tf.Tensor], Mapping[str, tf.Tensor]], Mapping[str, tf.Tensor]]]:
     """Builds the model network.
 
     Args:
       backbone: the model backbone.
       input_specs: the model input spec to use.
       state_specs: a dict of states such that, if any of the keys match for a
@@ -181,29 +181,29 @@
             x)
 
     outputs = (x, states) if self._output_states else x
 
     return inputs, outputs
 
   def initial_state_specs(
-      self, input_shape: Sequence[int]) -> Dict[str, tf.keras.layers.InputSpec]:
+      self, input_shape: Sequence[int]) -> Dict[str, tf_keras.layers.InputSpec]:
     return self._backbone.initial_state_specs(input_shape=input_shape)
 
   @tf.function
   def init_states(self, input_shape: Sequence[int]) -> Dict[str, tf.Tensor]:
     """Returns initial states for the first call in steaming mode."""
     return self._backbone.init_states(input_shape)
 
   @property
   def checkpoint_items(self) -> Dict[str, Any]:
     """Returns a dictionary of items to be additionally checkpointed."""
     return dict(backbone=self.backbone)
 
   @property
-  def backbone(self) -> tf.keras.Model:
+  def backbone(self) -> tf_keras.Model:
     """Returns the backbone of the model."""
     return self._backbone
 
   def get_config(self):
     config = {
         'backbone': self._backbone,
         'activation': self._activation,
@@ -217,29 +217,29 @@
     }
     return config
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
     # Each InputSpec may need to be deserialized
     # This handles the case where we want to load a saved_model loaded with
-    # `tf.keras.models.load_model`
+    # `tf_keras.models.load_model`
     if config['input_specs']:
       for name in config['input_specs']:
         if isinstance(config['input_specs'][name], dict):
-          config['input_specs'][name] = tf.keras.layers.deserialize(
+          config['input_specs'][name] = tf_keras.layers.deserialize(
               config['input_specs'][name])
     return cls(**config)
 
 
 @model_factory.register_model_builder('movinet')
 def build_movinet_model(
-    input_specs: Mapping[str, tf.keras.layers.InputSpec],
+    input_specs: Mapping[str, tf_keras.layers.InputSpec],
     model_config: cfg.MovinetModel,
     num_classes: int,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None):
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None):
   """Builds movinet model."""
   logging.info('Building movinet model with num classes: %s', num_classes)
   if l2_regularizer is not None:
     logging.info('Building movinet model with regularizer: %s',
                  l2_regularizer.get_config())
 
   input_specs_dict = {'image': input_specs}
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_model_test.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_model_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,30 +12,30 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for movinet_model.py."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.movinet.modeling import movinet
 from official.projects.movinet.modeling import movinet_model
 
 
 class MovinetModelTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(False, True)
   def test_movinet_classifier_creation(self, is_training):
     """Test for creation of a Movinet classifier."""
     temporal_size = 16
     spatial_size = 224
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, temporal_size, spatial_size, spatial_size, 3])
     backbone = movinet.Movinet(model_id='a0', input_specs=input_specs)
 
     num_classes = 1000
     model = movinet_model.MovinetClassifier(
         backbone=backbone,
         num_classes=num_classes,
@@ -44,15 +44,15 @@
 
     inputs = np.random.rand(2, temporal_size, spatial_size, spatial_size, 3)
     logits = model(inputs, training=is_training)
     self.assertAllEqual([2, num_classes], logits.shape)
 
   def test_movinet_classifier_stream(self):
     """Test if the classifier can be run in streaming mode."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         use_external_states=True,
     )
     model = movinet_model.MovinetClassifier(
@@ -71,15 +71,15 @@
     predicted = output
 
     self.assertEqual(predicted.shape, expected.shape)
     self.assertAllClose(predicted, expected, 1e-5, 1e-5)
 
   def test_movinet_classifier_stream_pos_enc(self):
     """Test if the classifier can be run in streaming mode with pos encoding."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         use_external_states=True,
         use_positional_encoding=True,
     )
@@ -99,15 +99,15 @@
     predicted = output
 
     self.assertEqual(predicted.shape, expected.shape)
     self.assertAllClose(predicted, expected, 1e-5, 1e-5)
 
   def test_movinet_classifier_stream_pos_enc_2plus1d(self):
     """Test if the model can run in streaming mode with pos encoding, (2+1)D."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         use_external_states=True,
         use_positional_encoding=True,
         conv_type='2plus1d',
@@ -128,15 +128,15 @@
     predicted = output
 
     self.assertEqual(predicted.shape, expected.shape)
     self.assertAllClose(predicted, expected, 1e-5, 1e-5)
 
   def test_movinet_classifier_mobile(self):
     """Test if the model can run with mobile parameters."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         use_external_states=True,
         conv_type='2plus1d',
         se_type='2plus3d',
@@ -180,16 +180,16 @@
   def test_saved_model_save_load(self):
     backbone = movinet.Movinet('a0')
     model = movinet_model.MovinetClassifier(
         backbone, num_classes=600)
     model.build([1, 5, 172, 172, 3])
     model.compile(metrics=['acc'])
 
-    tf.keras.models.save_model(model, '/tmp/movinet/')
-    loaded_model = tf.keras.models.load_model('/tmp/movinet/')
+    tf_keras.models.save_model(model, '/tmp/movinet/')
+    loaded_model = tf_keras.models.load_model('/tmp/movinet/')
 
     output = loaded_model(dict(image=tf.ones([1, 1, 1, 1, 3])))
 
     self.assertAllEqual(output.shape, [1, 600])
 
   @parameterized.parameters(
       ('a0', 3.126071),
@@ -198,29 +198,29 @@
       ('a3', 7.443289),
       ('a4', 11.422727),
       ('a5', 18.763355),
       ('t0', 1.740502),
   )
   def test_movinet_models(self, model_id, expected_params_millions):
     """Test creation of MoViNet family models with states."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     model = movinet_model.MovinetClassifier(
         backbone=movinet.Movinet(
             model_id=model_id,
             causal=True),
         num_classes=600)
     model.build([1, 1, 1, 1, 3])
     num_params_millions = model.count_params() / 1e6
 
     self.assertEqual(num_params_millions, expected_params_millions)
 
   def test_movinet_a0_2plus1d(self):
     """Test creation of MoViNet with 2plus1d configuration."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     model_2plus1d = movinet_model.MovinetClassifier(
         backbone=movinet.Movinet(
             model_id='a0',
             conv_type='2plus1d'),
         num_classes=600)
     model_2plus1d.build([1, 1, 1, 1, 3])
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/modeling/movinet_test.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/modeling/movinet_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,45 +11,45 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for movinet.py."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.movinet.modeling import movinet
 
 
 class MoViNetTest(parameterized.TestCase, tf.test.TestCase):
 
   def test_network_creation(self):
     """Test creation of MoViNet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     network = movinet.Movinet(
         model_id='a0',
         causal=True,
     )
-    inputs = tf.keras.Input(shape=(8, 128, 128, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(8, 128, 128, 3), batch_size=1)
     endpoints, states = network(inputs)
 
     self.assertAllEqual(endpoints['stem'].shape, [1, 8, 64, 64, 8])
     self.assertAllEqual(endpoints['block0_layer0'].shape, [1, 8, 32, 32, 8])
     self.assertAllEqual(endpoints['block1_layer0'].shape, [1, 8, 16, 16, 32])
     self.assertAllEqual(endpoints['block2_layer0'].shape, [1, 8, 8, 8, 56])
     self.assertAllEqual(endpoints['block3_layer0'].shape, [1, 8, 8, 8, 56])
     self.assertAllEqual(endpoints['block4_layer0'].shape, [1, 8, 4, 4, 104])
     self.assertAllEqual(endpoints['head'].shape, [1, 1, 1, 1, 480])
 
     self.assertNotEmpty(states)
 
   def test_network_with_states(self):
     """Test creation of MoViNet family models with states."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         use_external_states=True,
     )
     inputs = tf.ones([1, 8, 128, 128, 3])
@@ -66,15 +66,15 @@
     self.assertAllEqual(endpoints['head'].shape, [1, 1, 1, 1, 480])
 
     self.assertNotEmpty(init_states)
     self.assertNotEmpty(new_states)
 
   def test_movinet_stream(self):
     """Test if the backbone can be run in streaming mode."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         use_external_states=True,
     )
     inputs = tf.ones([1, 5, 128, 128, 3])
@@ -96,15 +96,15 @@
     expected = tf.reduce_mean(expected, 1, keepdims=True)
 
     self.assertEqual(predicted.shape, expected.shape)
     self.assertAllClose(predicted, expected, 1e-5, 1e-5)
 
   def test_movinet_stream_nse(self):
     """Test if the backbone can be run in streaming mode w/o SE layer."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         use_external_states=True,
         se_type='none',
     )
@@ -138,15 +138,15 @@
     # From now on, there are only 'stream_buffer' for the convolutions.
     for state_key in state_keys:
       self.assertIn(
           'stream_buffer', state_key,
           msg=f'Expecting stream_buffer only, found {state_key}')
 
   def test_movinet_2plus1d_stream(self):
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         conv_type='2plus1d',
         use_external_states=True,
     )
@@ -168,15 +168,15 @@
     expected = expected_endpoints['head']
     expected = tf.reduce_mean(expected, 1, keepdims=True)
 
     self.assertEqual(predicted.shape, expected.shape)
     self.assertAllClose(predicted, expected, 1e-5, 1e-5)
 
   def test_movinet_3d_2plus1d_stream(self):
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = movinet.Movinet(
         model_id='a0',
         causal=True,
         conv_type='3d_2plus1d',
         use_external_states=True,
     )
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/tools/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/tools/convert_3d_2plus1d.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/tools/convert_3d_2plus1d.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Converts '3d_2plus1d' checkpoints into '2plus1d'."""
 
 from absl import app
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.movinet.modeling import movinet
 from official.projects.movinet.modeling import movinet_model
 
 flags.DEFINE_string(
     'input_checkpoint_path', None,
     'Checkpoint path to load.')
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/tools/convert_3d_2plus1d_test.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/tools/convert_3d_2plus1d_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for convert_3d_2plus1d."""
 
 import os
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.movinet.modeling import movinet
 from official.projects.movinet.modeling import movinet_model
 from official.projects.movinet.tools import convert_3d_2plus1d
 
 FLAGS = flags.FLAGS
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/tools/export_saved_model.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/tools/export_saved_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -50,15 +50,15 @@
 To use an exported saved_model, refer to export_saved_model_test.py.
 """
 
 from typing import Optional, Tuple
 
 from absl import app
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.movinet.modeling import movinet
 from official.projects.movinet.modeling import movinet_model
 
 flags.DEFINE_string(
     'export_path', '/tmp/movinet/',
     'Export path to save the saved_model file.')
@@ -106,54 +106,64 @@
 flags.DEFINE_bool(
     'bundle_input_init_states_fn', True,
     'Add init_states as a function signature to the saved model.'
     'This is not necessary if the input shape is static (e.g., for TF Lite).')
 flags.DEFINE_string(
     'checkpoint_path', '',
     'Checkpoint path to load. Leave blank for default initialization.')
+flags.DEFINE_bool(
+    'assert_checkpoint_objects_matched',
+    True,
+    'Whether to check the checkpoint objects exactly match those of the model.',
+)
 
 FLAGS = flags.FLAGS
 
 
 def export_saved_model(
-    model: tf.keras.Model,
+    model: tf_keras.Model,
     input_shape: Tuple[int, int, int, int, int],
     export_path: str = '/tmp/movinet/',
     causal: bool = False,
     bundle_input_init_states_fn: bool = True,
-    checkpoint_path: Optional[str] = None) -> None:
+    checkpoint_path: Optional[str] = None,
+    assert_checkpoint_objects_matched: bool = True,
+) -> None:
   """Exports a MoViNet model to a saved model.
 
   Args:
-    model: the tf.keras.Model to export.
-    input_shape: The 5D spatiotemporal input shape of size
-      [batch_size, num_frames, image_height, image_width, num_channels].
-      Set the field or a shape position in the field to None for dynamic input.
+    model: the tf_keras.Model to export.
+    input_shape: The 5D spatiotemporal input shape of size [batch_size,
+      num_frames, image_height, image_width, num_channels]. Set the field or a
+      shape position in the field to None for dynamic input.
     export_path: Export path to save the saved_model file.
     causal: Run the model in causal mode.
     bundle_input_init_states_fn: Add init_states as a function signature to the
-      saved model. This is not necessary if the input shape is static (e.g.,
-      for TF Lite).
+      saved model. This is not necessary if the input shape is static (e.g., for
+      TF Lite).
     checkpoint_path: Checkpoint path to load. Leave blank to keep the model's
       initialization.
+    assert_checkpoint_objects_matched: Whether to check the checkpoint objects
+      exactly match those of the model.
   """
 
   # Use dimensions of 1 except the channels to export faster,
   # since we only really need the last dimension to build and get the output
   # states. These dimensions can be set to `None` once the model is built.
   input_shape_concrete = [1 if s is None else s for s in input_shape]
   model.build(input_shape_concrete)
 
   # Compile model to generate some internal Keras variables.
   model.compile()
 
   if checkpoint_path:
     checkpoint = tf.train.Checkpoint(model=model)
     status = checkpoint.restore(checkpoint_path)
-    status.assert_existing_objects_matched()
+    if assert_checkpoint_objects_matched:
+      status.assert_existing_objects_matched()
 
   if causal:
     # Call the model once to get the output states. Call again with `states`
     # input to ensure that the inputs with the `states` argument is built
     # with the full output state shapes.
     input_image = tf.ones(input_shape_concrete)
     _, states = model({
@@ -181,19 +191,19 @@
         tf.TensorSpec([5], dtype=tf.int32))
 
     if bundle_input_init_states_fn:
       signatures = {'call': predict_fn, 'init_states': init_states_fn}
     else:
       signatures = predict_fn
 
-    tf.keras.models.save_model(
+    tf_keras.models.save_model(
         model, export_path, signatures=signatures)
   else:
     _ = model(tf.ones(input_shape_concrete))
-    tf.keras.models.save_model(model, export_path)
+    tf_keras.models.save_model(model, export_path)
 
 
 def build_and_export_saved_model(
     export_path: str = '/tmp/movinet/',
     model_id: str = 'a0',
     causal: bool = False,
     conv_type: str = '3d',
@@ -201,50 +211,52 @@
     activation: str = 'swish',
     classifier_activation: str = 'swish',
     gating_activation: str = 'sigmoid',
     use_positional_encoding: bool = False,
     num_classes: int = 600,
     input_shape: Optional[Tuple[int, int, int, int, int]] = None,
     bundle_input_init_states_fn: bool = True,
-    checkpoint_path: Optional[str] = None) -> None:
+    checkpoint_path: Optional[str] = None,
+    assert_checkpoint_objects_matched: bool = True,
+) -> None:
   """Builds and exports a MoViNet model to a saved model.
 
   Args:
     export_path: Export path to save the saved_model file.
     model_id: MoViNet model name.
     causal: Run the model in causal mode.
-    conv_type: 3d, 2plus1d, or 3d_2plus1d. 3d configures the network
-      to use the default 3D convolution. 2plus1d uses (2+1)D convolution
-      with Conv2D operations and 2D reshaping (e.g., a 5x3x3 kernel becomes
-      3x3 followed by 5x1 conv). 3d_2plus1d uses (2+1)D convolution with
-      Conv3D and no 2D reshaping (e.g., a 5x3x3 kernel becomes 1x3x3
-      followed by 5x1x1 conv).
-    se_type:
-      3d, 2d, or 2plus3d. 3d uses the default 3D spatiotemporal global average
-      pooling for squeeze excitation. 2d uses 2D spatial global average pooling
-      on each frame. 2plus3d concatenates both 3D and 2D global average
+    conv_type: 3d, 2plus1d, or 3d_2plus1d. 3d configures the network to use the
+      default 3D convolution. 2plus1d uses (2+1)D convolution with Conv2D
+      operations and 2D reshaping (e.g., a 5x3x3 kernel becomes 3x3 followed by
+      5x1 conv). 3d_2plus1d uses (2+1)D convolution with Conv3D and no 2D
+      reshaping (e.g., a 5x3x3 kernel becomes 1x3x3 followed by 5x1x1 conv).
+    se_type: 3d, 2d, or 2plus3d. 3d uses the default 3D spatiotemporal global
+      average pooling for squeeze excitation. 2d uses 2D spatial global average
+      pooling on each frame. 2plus3d concatenates both 3D and 2D global average
       pooling.
     activation: The main activation to use across layers.
     classifier_activation: The classifier activation to use.
     gating_activation: The gating activation to use in squeeze-excitation
       layers.
     use_positional_encoding: Whether to use positional encoding (only applied
       when causal=True).
     num_classes: The number of classes for prediction.
-    input_shape: The 5D spatiotemporal input shape of size
-      [batch_size, num_frames, image_height, image_width, num_channels].
-      Set the field or a shape position in the field to None for dynamic input.
+    input_shape: The 5D spatiotemporal input shape of size [batch_size,
+      num_frames, image_height, image_width, num_channels]. Set the field or a
+      shape position in the field to None for dynamic input.
     bundle_input_init_states_fn: Add init_states as a function signature to the
-      saved model. This is not necessary if the input shape is static (e.g.,
-      for TF Lite).
+      saved model. This is not necessary if the input shape is static (e.g., for
+      TF Lite).
     checkpoint_path: Checkpoint path to load. Leave blank for default
       initialization.
+    assert_checkpoint_objects_matched: Whether to check the checkpoint objects
+      exactly match those of the model.
   """
 
-  input_specs = tf.keras.layers.InputSpec(shape=input_shape)
+  input_specs = tf_keras.layers.InputSpec(shape=input_shape)
 
   # Override swish activation implementation to remove custom gradients
   if activation == 'swish':
     activation = 'simple_swish'
   if classifier_activation == 'swish':
     classifier_activation = 'simple_swish'
 
@@ -268,15 +280,17 @@
 
   export_saved_model(
       model=model,
       input_shape=input_shape,
       export_path=export_path,
       causal=causal,
       bundle_input_init_states_fn=bundle_input_init_states_fn,
-      checkpoint_path=checkpoint_path)
+      checkpoint_path=checkpoint_path,
+      assert_checkpoint_objects_matched=assert_checkpoint_objects_matched,
+  )
 
 
 def main(_) -> None:
   input_shape = (
       FLAGS.batch_size, FLAGS.num_frames, FLAGS.image_size, FLAGS.image_size, 3)
   build_and_export_saved_model(
       export_path=FLAGS.export_path,
@@ -287,13 +301,15 @@
       activation=FLAGS.activation,
       classifier_activation=FLAGS.classifier_activation,
       gating_activation=FLAGS.gating_activation,
       use_positional_encoding=FLAGS.use_positional_encoding,
       num_classes=FLAGS.num_classes,
       input_shape=input_shape,
       bundle_input_init_states_fn=FLAGS.bundle_input_init_states_fn,
-      checkpoint_path=FLAGS.checkpoint_path)
+      checkpoint_path=FLAGS.checkpoint_path,
+      assert_checkpoint_objects_matched=FLAGS.assert_checkpoint_objects_matched,
+  )
   print(' ----- Done. Saved Model is saved at {}'.format(FLAGS.export_path))
 
 
 if __name__ == '__main__':
   app.run(main)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/tools/export_saved_model_test.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/tools/export_saved_model_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for export_saved_model."""
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_hub as hub
 
 from official.projects.movinet.tools import export_saved_model
 
 FLAGS = flags.FLAGS
 
 
@@ -33,21 +33,21 @@
     FLAGS.causal = False
     FLAGS.num_classes = 600
 
     export_saved_model.main('unused_args')
 
     encoder = hub.KerasLayer(saved_model_path, trainable=True)
 
-    inputs = tf.keras.layers.Input(
+    inputs = tf_keras.layers.Input(
         shape=[None, None, None, 3],
         dtype=tf.float32)
 
     outputs = encoder(dict(image=inputs))
 
-    model = tf.keras.Model(inputs, outputs)
+    model = tf_keras.Model(inputs, outputs)
 
     example_input = tf.ones([1, 8, 172, 172, 3])
     outputs = model(example_input)
 
     self.assertAllEqual(outputs.shape, [1, 600])
 
   def test_movinet_export_a0_stream_with_tfhub(self):
@@ -58,34 +58,34 @@
     FLAGS.causal = True
     FLAGS.num_classes = 600
 
     export_saved_model.main('unused_args')
 
     encoder = hub.KerasLayer(saved_model_path, trainable=True)
 
-    image_input = tf.keras.layers.Input(
+    image_input = tf_keras.layers.Input(
         shape=[None, None, None, 3],
         dtype=tf.float32,
         name='image')
 
     init_states_fn = encoder.resolved_object.signatures['init_states']
     state_shapes = {
         name: ([s if s > 0 else None for s in state.shape], state.dtype)
         for name, state in init_states_fn(tf.constant([0, 0, 0, 0, 3])).items()
     }
     states_input = {
-        name: tf.keras.Input(shape[1:], dtype=dtype, name=name)
+        name: tf_keras.Input(shape[1:], dtype=dtype, name=name)
         for name, (shape, dtype) in state_shapes.items()
     }
 
     inputs = {**states_input, 'image': image_input}
 
     outputs = encoder(inputs)
 
-    model = tf.keras.Model(inputs, outputs)
+    model = tf_keras.Model(inputs, outputs)
 
     example_input = tf.ones([1, 8, 172, 172, 3])
     frames = tf.split(example_input, example_input.shape[1], axis=1)
 
     init_states = init_states_fn(tf.shape(example_input))
 
     expected_outputs, _ = model({**init_states, 'image': example_input})
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/tools/quantize_movinet.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/tools/quantize_movinet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -168,15 +168,15 @@
   valid_dataset = task.build_inputs(config.task.validation_data)
   valid_dataset = valid_dataset.map(lambda x, y: (x['image'], y))
   valid_dataset = valid_dataset.prefetch(32)
   return valid_dataset
 
 
 def stateful_representative_dataset_generator(
-    model: tf.keras.Model,
+    model: tf_keras.Model,
     dataset_iter: Any,
     init_states: Mapping[str, tf.Tensor],
     save_dataset_to_tfrecords: bool = False,
     max_saved_files: int = 100,
     output_dataset_dir: Optional[str] = None,
     num_samples_per_video: int = 3,
     num_calibration_videos: int = 100):
@@ -266,35 +266,35 @@
 def quantize_movinet(dataset_fn):
   """Quantizes Movinet."""
   valid_dataset = dataset_fn()
   dataset_iter = iter(valid_dataset)
 
   # Load model
   encoder = hub.KerasLayer(FLAGS.saved_model_with_states_dir, trainable=False)
-  inputs = tf.keras.layers.Input(
+  inputs = tf_keras.layers.Input(
       shape=[1, FLAGS.image_size, FLAGS.image_size, 3],
       dtype=tf.float32,
       name='image')
 
   # Define the state inputs, which is a dict that maps state names to tensors.
   init_states_fn = encoder.resolved_object.signatures['init_states']
   state_shapes = {
       name: ([s if s > 0 else None for s in state.shape], state.dtype)
       for name, state in init_states_fn(
           tf.constant([1, 1, FLAGS.image_size, FLAGS.image_size, 3])).items()
   }
   states_input = {
-      name: tf.keras.Input(shape[1:], dtype=dtype, name=name)
+      name: tf_keras.Input(shape[1:], dtype=dtype, name=name)
       for name, (shape, dtype) in state_shapes.items()
   }
 
   # The inputs to the model are the states and the video
   inputs = {**states_input, 'image': inputs}
   outputs = encoder(inputs)
-  model = tf.keras.Model(inputs, outputs, name='movinet_stream')
+  model = tf_keras.Model(inputs, outputs, name='movinet_stream')
   input_shape = tf.constant(
       [1, FLAGS.num_frames, FLAGS.image_size, FLAGS.image_size, 3])
   init_states = init_states_fn(input_shape)
 
   # config representative_datset_fn
   representative_dataset = functools.partial(
       stateful_representative_dataset_generator,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/train.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/train.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/movinet/train_test.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/train_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import json
 import os
 import random
 
 from absl import flags
 from absl import logging
 from absl.testing import flagsaver
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.movinet import train as train_lib
 from official.vision.dataloaders import tfexample_utils
 
 FLAGS = flags.FLAGS
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/configs.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/configs.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/configs_test.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/configs_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for configs."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.projects.nhnet import configs
 
 BERT2BERT_CONFIG = {
     "vocab_size": 30522,
     "hidden_size": 768,
     "num_hidden_layers": 12,
     "num_attention_heads": 12,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/decoder.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/decoder.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,22 +10,22 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Transformer decoder that mimics a BERT encoder, to load BERT checkpoints."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import model_utils as transformer_utils
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 
 
-class TransformerDecoder(tf.keras.layers.Layer):
+class TransformerDecoder(tf_keras.layers.Layer):
   """Transformer decoder stack."""
 
   def __init__(self,
                num_hidden_layers=12,
                hidden_size=768,
                num_attention_heads=12,
                intermediate_size=3072,
@@ -56,15 +56,15 @@
       self.layers.append(
           layers.TransformerDecoderBlock(
               num_attention_heads=self.num_attention_heads,
               intermediate_size=self.intermediate_size,
               intermediate_activation=self.intermediate_activation,
               dropout_rate=self.hidden_dropout_prob,
               attention_dropout_rate=self.attention_probs_dropout_prob,
-              kernel_initializer=tf.keras.initializers.TruncatedNormal(
+              kernel_initializer=tf_keras.initializers.TruncatedNormal(
                   stddev=self.initializer_range),
               multi_channel_cross_attention=self.multi_channel_cross_attention,
               name=("layer_%d" % i)))
     super(TransformerDecoder, self).build(unused_input_shapes)
 
   def call(self, inputs, cache=None, decode_loop_step=None):
     """Return the output of the decoder layer stacks.
@@ -159,25 +159,25 @@
     else:
       length = tf_utils.get_shape_list(input_tensor, expected_rank=2)[1]
     bias = transformer_utils.get_decoder_self_attention_bias(length)
 
   return tf.where(bias < 0, tf.zeros_like(bias), tf.ones_like(bias))
 
 
-class AttentionBias(tf.keras.layers.Layer):
+class AttentionBias(tf_keras.layers.Layer):
 
   def __init__(self, bias_type, **kwargs):
     super(AttentionBias, self).__init__(**kwargs)
     self.bias_type = bias_type
 
   def call(self, inputs):
     return get_attention_bias(inputs, self.bias_type)
 
 
-class EmbeddingPostprocessor(tf.keras.layers.Layer):
+class EmbeddingPostprocessor(tf_keras.layers.Layer):
   """Performs various post-processing on a word embedding tensor."""
 
   def __init__(self,
                use_type_embeddings=False,
                token_type_vocab_size=None,
                use_position_embeddings=True,
                max_position_embeddings=512,
@@ -190,15 +190,15 @@
     self.token_type_vocab_size = token_type_vocab_size
     self.use_position_embeddings = use_position_embeddings
     self.max_position_embeddings = max_position_embeddings
     self.dropout_prob = dropout_prob
     self.initializer_range = initializer_range
 
     if not initializer:
-      self.initializer = tf.keras.initializers.TruncatedNormal(
+      self.initializer = tf_keras.initializers.TruncatedNormal(
           stddev=initializer_range)
     else:
       self.initializer = initializer
 
     if self.use_type_embeddings and not self.token_type_vocab_size:
       raise ValueError("If `use_type_embeddings` is True, then "
                        "`token_type_vocab_size` must be specified.")
@@ -208,30 +208,30 @@
     (word_embeddings_shape, _) = input_shapes
     width = word_embeddings_shape.as_list()[-1]
     self.type_embeddings = None
     if self.use_type_embeddings:
       self.type_embeddings = self.add_weight(
           "type_embeddings",
           shape=[self.token_type_vocab_size, width],
-          initializer=tf.keras.initializers.TruncatedNormal(
+          initializer=tf_keras.initializers.TruncatedNormal(
               stddev=self.initializer_range),
           dtype=self.dtype)
 
     self.position_embeddings = None
     if self.use_position_embeddings:
       self.position_embeddings = self.add_weight(
           "position_embeddings",
           shape=[self.max_position_embeddings, width],
-          initializer=tf.keras.initializers.TruncatedNormal(
+          initializer=tf_keras.initializers.TruncatedNormal(
               stddev=self.initializer_range),
           dtype=self.dtype)
 
-    self.output_layer_norm = tf.keras.layers.LayerNormalization(
+    self.output_layer_norm = tf_keras.layers.LayerNormalization(
         name="layer_norm", axis=-1, epsilon=1e-12, dtype=tf.float32)
-    self.output_dropout = tf.keras.layers.Dropout(
+    self.output_dropout = tf_keras.layers.Dropout(
         rate=self.dropout_prob, dtype=tf.float32)
     super(EmbeddingPostprocessor, self).build(input_shapes)
 
   def __call__(self, word_embeddings, token_type_ids=None, **kwargs):
     inputs = tf_utils.pack_inputs([word_embeddings, token_type_ids])
     return super(EmbeddingPostprocessor, self).__call__(inputs, **kwargs)  # pytype: disable=attribute-error  # typed-keras
 
@@ -263,15 +263,15 @@
 
     output = self.output_layer_norm(output)
     output = self.output_dropout(output)
 
     return output
 
 
-class Decoder(tf.keras.layers.Layer):
+class Decoder(tf_keras.layers.Layer):
   """The decoder network which can reuse encoder embeddings for target."""
 
   def __init__(self, config, embedding_lookup=None, **kwargs):
     super(Decoder, self).__init__(**kwargs)
     self.config = config
     # Shares vocabulary embedding.
     self.embedding_lookup = None
@@ -280,23 +280,23 @@
 
   def build(self, unused_input_shapes):
     """Implements build() for the layer."""
     if self.embedding_lookup is None:
       self.embedding_lookup = layers.OnDeviceEmbedding(
           vocab_size=self.config.vocab_size,
           embedding_width=self.config.hidden_size,
-          initializer=tf.keras.initializers.TruncatedNormal(
+          initializer=tf_keras.initializers.TruncatedNormal(
               stddev=self.config.initializer_range),
           name="target_embeddings")
     self.embedding_postprocessor = EmbeddingPostprocessor(
         use_type_embeddings=False,
         use_position_embeddings=True,
         max_position_embeddings=self.config.max_position_embeddings,
         dropout_prob=self.config.hidden_dropout_prob,
-        initializer=tf.keras.initializers.VarianceScaling(
+        initializer=tf_keras.initializers.VarianceScaling(
             scale=self.config.initializer_gain,
             mode="fan_avg",
             distribution="uniform"),
         name="embedding_postprocessor")
     # Decoder can use a different intermediate size.
     self.multi_channel_cross_attention = self.config.get(
         "multi_channel_cross_attention", False)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/decoder_test.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/decoder_test.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for projects.nhnet.decoder."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.nlp.modeling import layers
 from official.projects.nhnet import configs
 from official.projects.nhnet import decoder
 from official.projects.nhnet import utils
 
 
 class DecoderTest(tf.test.TestCase):
@@ -39,26 +39,26 @@
         attention_probs_dropout_prob=self._config.attention_probs_dropout_prob,
         initializer_range=self._config.initializer_range)
     decoder_block.build(None)
     self.assertEqual(len(decoder_block.layers), self._config.num_hidden_layers)
 
   def test_bert_decoder(self):
     seq_length = 10
-    encoder_input_ids = tf.keras.layers.Input(
+    encoder_input_ids = tf_keras.layers.Input(
         shape=(seq_length,), name="encoder_input_ids", dtype=tf.int32)
-    target_ids = tf.keras.layers.Input(
+    target_ids = tf_keras.layers.Input(
         shape=(seq_length,), name="target_ids", dtype=tf.int32)
-    encoder_outputs = tf.keras.layers.Input(
+    encoder_outputs = tf_keras.layers.Input(
         shape=(seq_length, self._config.hidden_size),
         name="all_encoder_outputs",
         dtype=tf.float32)
     embedding_lookup = layers.OnDeviceEmbedding(
         vocab_size=self._config.vocab_size,
         embedding_width=self._config.hidden_size,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=self._config.initializer_range),
         name="word_embeddings")
     cross_attention_bias = decoder.AttentionBias(bias_type="single_cross")(
         encoder_input_ids)
     self_attention_bias = decoder.AttentionBias(bias_type="decoder_self")(
         target_ids)
     inputs = dict(
@@ -68,44 +68,44 @@
         all_encoder_outputs=encoder_outputs)
     decoder_layer = decoder.Decoder(self._config, embedding_lookup)
     outputs = decoder_layer(inputs)
     model_inputs = dict(
         encoder_input_ids=encoder_input_ids,
         target_ids=target_ids,
         all_encoder_outputs=encoder_outputs)
-    model = tf.keras.Model(inputs=model_inputs, outputs=outputs, name="test")
+    model = tf_keras.Model(inputs=model_inputs, outputs=outputs, name="test")
     self.assertLen(decoder_layer.trainable_weights, 30)
     # Forward path.
     fake_inputs = {
         "encoder_input_ids": np.zeros((2, 10), dtype=np.int32),
         "target_ids": np.zeros((2, 10), dtype=np.int32),
         "all_encoder_outputs": np.zeros((2, 10, 16), dtype=np.float32),
     }
     output_tensor = model(fake_inputs)
     self.assertEqual(output_tensor.shape, (2, 10, 16))
 
   def test_multi_doc_decoder(self):
     self._config = utils.get_test_params(cls=configs.NHNetConfig)
     seq_length = 10
     num_docs = 5
-    encoder_input_ids = tf.keras.layers.Input(
+    encoder_input_ids = tf_keras.layers.Input(
         shape=(num_docs, seq_length), name="encoder_input_ids", dtype=tf.int32)
-    target_ids = tf.keras.layers.Input(
+    target_ids = tf_keras.layers.Input(
         shape=(seq_length,), name="target_ids", dtype=tf.int32)
-    encoder_outputs = tf.keras.layers.Input(
+    encoder_outputs = tf_keras.layers.Input(
         shape=(num_docs, seq_length, self._config.hidden_size),
         name="all_encoder_outputs",
         dtype=tf.float32)
     embedding_lookup = layers.OnDeviceEmbedding(
         vocab_size=self._config.vocab_size,
         embedding_width=self._config.hidden_size,
-        initializer=tf.keras.initializers.TruncatedNormal(
+        initializer=tf_keras.initializers.TruncatedNormal(
             stddev=self._config.initializer_range),
         name="word_embeddings")
-    doc_attention_probs = tf.keras.layers.Input(
+    doc_attention_probs = tf_keras.layers.Input(
         shape=(self._config.num_decoder_attn_heads, seq_length, num_docs),
         name="doc_attention_probs",
         dtype=tf.float32)
     cross_attention_bias = decoder.AttentionBias(bias_type="multi_cross")(
         encoder_input_ids)
     self_attention_bias = decoder.AttentionBias(bias_type="decoder_self")(
         target_ids)
@@ -120,15 +120,15 @@
     decoder_layer = decoder.Decoder(self._config, embedding_lookup)
     outputs = decoder_layer(inputs)
     model_inputs = dict(
         encoder_input_ids=encoder_input_ids,
         target_ids=target_ids,
         all_encoder_outputs=encoder_outputs,
         doc_attention_probs=doc_attention_probs)
-    model = tf.keras.Model(inputs=model_inputs, outputs=outputs, name="test")
+    model = tf_keras.Model(inputs=model_inputs, outputs=outputs, name="test")
     self.assertLen(decoder_layer.trainable_weights, 30)
     # Forward path.
     fake_inputs = {
         "encoder_input_ids":
             np.zeros((2, num_docs, seq_length), dtype=np.int32),
         "target_ids":
             np.zeros((2, seq_length), dtype=np.int32),
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/evaluation.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/evaluation.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import os
 
 # Import libraries
 
 from absl import logging
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.transformer import metrics as metrics_v2
 from official.legacy.transformer.utils import metrics
 from official.projects.nhnet import input_pipeline
 from official.projects.nhnet import models
 
 
@@ -131,18 +131,18 @@
       return targets, logits
 
     outputs = strategy.run(_test_step_fn, args=(inputs,))
 
     return tf.nest.map_structure(strategy.experimental_local_results, outputs)
 
   metrics_and_funcs = [
-      (tf.keras.metrics.Mean("bleu", dtype=tf.float32), bleu_score),
-      (tf.keras.metrics.Mean("rouge_2_fscore",
+      (tf_keras.metrics.Mean("bleu", dtype=tf.float32), bleu_score),
+      (tf_keras.metrics.Mean("rouge_2_fscore",
                              dtype=tf.float32), rouge_2_fscore),
-      (tf.keras.metrics.Mean("rouge_l_fscore",
+      (tf_keras.metrics.Mean("rouge_l_fscore",
                              dtype=tf.float32), rouge_l_fscore),
   ]
   eval_results = {}
   for latest_checkpoint in tf.train.checkpoints_iterator(
       model_dir, timeout=timeout):
     checkpoint = tf.train.Checkpoint(model=model, global_step=global_step)
     checkpoint.restore(latest_checkpoint).expect_partial()
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/input_pipeline.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/input_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Input pipelines."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def decode_record(record, name_to_features):
   """Decodes a record to a TensorFlow example."""
   example = tf.io.parse_single_example(record, name_to_features)
 
   # tf.Example only supports tf.int64, but the TPU only supports tf.int32.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/models.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/models.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """tf.keras Models for NHNet."""
 from typing import Optional, Text
 
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.modeling.hyperparams import params_dict
 from official.nlp.modeling import networks
 from official.nlp.modeling.layers import multi_channel_attention
 from official.nlp.modeling.ops import beam_search
 from official.projects.nhnet import configs
@@ -62,15 +62,15 @@
   # pad
   pad_ids = tf.ones([batch_size], tf.int32) * pad_token_id
   targets = tf.concat([targets, tf.expand_dims(pad_ids, axis=1)], axis=1)
   tf.assert_equal(tf.shape(targets), (batch_size, seq_len))
   return targets
 
 
-class Bert2Bert(tf.keras.Model):
+class Bert2Bert(tf_keras.Model):
   """Bert2Bert encoder decoder model for training."""
 
   def __init__(self, params, bert_layer, decoder_layer, name=None):
     super(Bert2Bert, self).__init__(name=name)
     self.params = params
     if not bert_layer.built:
       raise ValueError("bert_layer should be built.")
@@ -307,15 +307,15 @@
           decoder_self_attention_bias,
           step=i,
           cache=cache if self.params.use_cache else None)
       return logits, cache
 
     return _symbols_to_logits_fn
 
-  def call(self, inputs, mode="training"):
+  def call(self, inputs, mode="training"):  # pytype: disable=signature-mismatch  # overriding-default-value-checks
     input_shape = tf_utils.get_shape_list(inputs["input_ids"], expected_rank=3)
     batch_size, num_docs, len_passage = (input_shape[0], input_shape[1],
                                          input_shape[2])
     input_ids = tf.reshape(inputs["input_ids"], [-1, len_passage])
     input_mask = tf.reshape(inputs["input_mask"], [-1, len_passage])
     segment_ids = tf.reshape(inputs["segment_ids"], [-1, len_passage])
     all_encoder_outputs, _ = self.bert_layer(
@@ -386,35 +386,35 @@
 
   Args:
     params: ParamsDict.
 
   Returns:
     two keras Layers, bert_model_layer and decoder_layer
   """
-  input_ids = tf.keras.layers.Input(
+  input_ids = tf_keras.layers.Input(
       shape=(None,), name="input_ids", dtype=tf.int32)
-  input_mask = tf.keras.layers.Input(
+  input_mask = tf_keras.layers.Input(
       shape=(None,), name="input_mask", dtype=tf.int32)
-  segment_ids = tf.keras.layers.Input(
+  segment_ids = tf_keras.layers.Input(
       shape=(None,), name="segment_ids", dtype=tf.int32)
-  target_ids = tf.keras.layers.Input(
+  target_ids = tf_keras.layers.Input(
       shape=(None,), name="target_ids", dtype=tf.int32)
   bert_config = utils.get_bert_config_from_params(params)
   bert_model_layer = networks.BertEncoder(
       vocab_size=bert_config.vocab_size,
       hidden_size=bert_config.hidden_size,
       num_layers=bert_config.num_hidden_layers,
       num_attention_heads=bert_config.num_attention_heads,
       intermediate_size=bert_config.intermediate_size,
       activation=tf_utils.get_activation(bert_config.hidden_act),
       dropout_rate=bert_config.hidden_dropout_prob,
       attention_dropout_rate=bert_config.attention_probs_dropout_prob,
       max_sequence_length=bert_config.max_position_embeddings,
       type_vocab_size=bert_config.type_vocab_size,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=bert_config.initializer_range),
       return_all_encoder_outputs=True,
       name="bert_encoder")
   all_encoder_outputs, _ = bert_model_layer(
       [input_ids, input_mask, segment_ids])
   # pylint: disable=protected-access
   decoder_layer = decoder.Decoder(params, bert_model_layer._embedding_layer)
@@ -438,45 +438,45 @@
 
   Args:
     params: ParamsDict.
 
   Returns:
     two keras Layers, bert_model_layer and decoder_layer
   """
-  input_ids = tf.keras.layers.Input(
+  input_ids = tf_keras.layers.Input(
       shape=(None,), name="input_ids", dtype=tf.int32)
-  input_mask = tf.keras.layers.Input(
+  input_mask = tf_keras.layers.Input(
       shape=(None,), name="input_mask", dtype=tf.int32)
-  segment_ids = tf.keras.layers.Input(
+  segment_ids = tf_keras.layers.Input(
       shape=(None,), name="segment_ids", dtype=tf.int32)
   bert_config = utils.get_bert_config_from_params(params)
   bert_model_layer = networks.BertEncoder(
       vocab_size=bert_config.vocab_size,
       hidden_size=bert_config.hidden_size,
       num_layers=bert_config.num_hidden_layers,
       num_attention_heads=bert_config.num_attention_heads,
       intermediate_size=bert_config.intermediate_size,
       activation=tf_utils.get_activation(bert_config.hidden_act),
       dropout_rate=bert_config.hidden_dropout_prob,
       attention_dropout_rate=bert_config.attention_probs_dropout_prob,
       max_sequence_length=bert_config.max_position_embeddings,
       type_vocab_size=bert_config.type_vocab_size,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=bert_config.initializer_range),
       return_all_encoder_outputs=True,
       name="bert_encoder")
   bert_model_layer([input_ids, input_mask, segment_ids])
 
-  input_ids = tf.keras.layers.Input(
+  input_ids = tf_keras.layers.Input(
       shape=(None, None), name="input_ids", dtype=tf.int32)
-  all_encoder_outputs = tf.keras.layers.Input((None, None, params.hidden_size),
+  all_encoder_outputs = tf_keras.layers.Input((None, None, params.hidden_size),
                                               dtype=tf.float32)
-  target_ids = tf.keras.layers.Input(
+  target_ids = tf_keras.layers.Input(
       shape=(None,), name="target_ids", dtype=tf.int32)
-  doc_attention_probs = tf.keras.layers.Input(
+  doc_attention_probs = tf_keras.layers.Input(
       (params.num_decoder_attn_heads, None, None), dtype=tf.float32)
   # pylint: disable=protected-access
   decoder_layer = decoder.Decoder(params, bert_model_layer._embedding_layer)
   # pylint: enable=protected-access
   cross_attention_bias = decoder.AttentionBias(bias_type="multi_cross")(
       input_ids)
   self_attention_bias = decoder.AttentionBias(bias_type="decoder_self")(
@@ -490,15 +490,15 @@
   _ = decoder_layer(decoder_inputs)
 
   return bert_model_layer, decoder_layer
 
 
 def create_transformer_model(params,
                              init_checkpoint: Optional[Text] = None
-                            ) -> tf.keras.Model:
+                            ) -> tf_keras.Model:
   """A helper to create Transformer model."""
   bert_layer, decoder_layer = get_bert2bert_layers(params=params)
   model = Bert2Bert(
       params=params,
       bert_layer=bert_layer,
       decoder_layer=decoder_layer,
       name="transformer")
@@ -512,15 +512,15 @@
 
   return model
 
 
 def create_bert2bert_model(
     params: configs.BERT2BERTConfig,
     cls=Bert2Bert,
-    init_checkpoint: Optional[Text] = None) -> tf.keras.Model:
+    init_checkpoint: Optional[Text] = None) -> tf_keras.Model:
   """A helper to create Bert2Bert model."""
   bert_layer, decoder_layer = get_bert2bert_layers(params=params)
   if init_checkpoint:
     utils.initialize_bert2bert_from_pretrained_bert(bert_layer, decoder_layer,
                                                     init_checkpoint)
   return cls(
       params=params,
@@ -528,15 +528,15 @@
       decoder_layer=decoder_layer,
       name="bert2bert")
 
 
 def create_nhnet_model(
     params: configs.NHNetConfig,
     cls=NHNet,
-    init_checkpoint: Optional[Text] = None) -> tf.keras.Model:
+    init_checkpoint: Optional[Text] = None) -> tf_keras.Model:
   """A helper to create NHNet model."""
   bert_layer, decoder_layer = get_nhnet_layers(params=params)
   model = cls(
       params=params,
       bert_layer=bert_layer,
       decoder_layer=decoder_layer,
       name="nhnet")
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/models_test.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/models_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Tests for projects.nhnet.models."""
 
 import os
 
 from absl import logging
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # pylint: disable=g-direct-tensorflow-import
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 # pylint: enable=g-direct-tensorflow-import
 from official.projects.nhnet import configs
 from official.projects.nhnet import models
@@ -220,15 +220,15 @@
   def _count_params(self, layer, trainable_only=True):
     """Returns the count of all model parameters, or just trainable ones."""
     if not trainable_only:
       return layer.count_params()
     else:
       return int(
           np.sum([
-              tf.keras.backend.count_params(p) for p in layer.trainable_weights
+              tf_keras.backend.count_params(p) for p in layer.trainable_weights
           ]))
 
   def test_create_nhnet_layers(self):
     single_doc_bert, single_doc_decoder = models.get_bert2bert_layers(
         self._bert2bert_config)
     multi_doc_bert, multi_doc_decoder = models.get_nhnet_layers(
         self._nhnet_config)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/optimizer.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/optimizer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,20 +10,20 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Optimizer and learning rate scheduler."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling.hyperparams import params_dict
 
 
-class LearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
+class LearningRateSchedule(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Learning rate schedule."""
 
   def __init__(self, initial_learning_rate, hidden_size, warmup_steps):
     """Initialize configuration of the learning rate schedule.
 
     Args:
       initial_learning_rate: A float, the initial learning rate.
@@ -64,12 +64,12 @@
     }
 
 
 def create_optimizer(params: params_dict.ParamsDict):
   """Creates optimizer."""
   lr_schedule = LearningRateSchedule(params.learning_rate, params.hidden_size,
                                      params.learning_rate_warmup_steps)
-  return tf.keras.optimizers.Adam(
+  return tf_keras.optimizers.Adam(
       learning_rate=lr_schedule,
       beta_1=params.adam_beta1,
       beta_2=params.adam_beta2,
       epsilon=params.adam_epsilon)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/raw_data_process.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/raw_data_process.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/raw_data_processor.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/raw_data_processor.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,19 +12,19 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Library for processing crawled content and generating tfrecords."""
 
 import collections
 import json
-import multiprocessing
+import multiprocessing.pool
 import os
 import urllib.parse
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.data import classifier_data_lib
 from official.nlp.tools import tokenization
 
 
 class RawDataProcessor(object):
   """Data converter for story examples."""
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/trainer.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/trainer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,15 +18,15 @@
 
 # Import libraries
 
 from absl import app
 from absl import flags
 from absl import logging
 from six.moves import zip
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import distribute_utils
 from official.legacy.transformer import metrics as transformer_metrics
 from official.modeling.hyperparams import params_dict
 from official.projects.nhnet import evaluation
 from official.projects.nhnet import input_pipeline
 from official.projects.nhnet import models
@@ -87,15 +87,15 @@
   flags.DEFINE_bool("enable_mlir_bridge", True,
                     "Use MLIR TF/XLA bridge (experimental).")
 
 
 # pylint: disable=protected-access
 
 
-class Trainer(tf.keras.Model):
+class Trainer(tf_keras.Model):
   """A training only model."""
 
   def __init__(self, model, params):
     super(Trainer, self).__init__()
     self.model = model
     self.params = params
     self._num_replicas_in_sync = tf.distribute.get_strategy(
@@ -116,15 +116,15 @@
       # Scales the loss, which results in using the average loss across all
       # of the replicas for backprop.
       scaled_loss = loss / self._num_replicas_in_sync
 
     tvars = self.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     self.optimizer.apply_gradients(list(zip(grads, tvars)))
-    if isinstance(self.optimizer, tf.keras.optimizers.experimental.Optimizer):
+    if isinstance(self.optimizer, tf_keras.optimizers.experimental.Optimizer):
       learning_rate = self.optimizer.learning_rate
     else:
       learning_rate = self.optimizer._decayed_lr(var_dtype=tf.float32)
     return {
         "training_loss": loss,
         "learning_rate": learning_rate,
     }
@@ -147,15 +147,15 @@
     opt = optimizer.create_optimizer(params)
     trainer = Trainer(model, params)
 
     trainer.compile(
         optimizer=opt,
         steps_per_execution=FLAGS.steps_per_loop)
     summary_dir = os.path.join(FLAGS.model_dir, "summaries")
-    summary_callback = tf.keras.callbacks.TensorBoard(
+    summary_callback = tf_keras.callbacks.TensorBoard(
         summary_dir, update_freq=max(100, FLAGS.steps_per_loop))
     checkpoint = tf.train.Checkpoint(
         model=model, optimizer=opt, global_step=opt.iterations)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
         directory=FLAGS.model_dir,
         max_to_keep=10,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/trainer_test.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/trainer_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for official.projects.nhnet.trainer."""
 
 import os
 
 from absl import flags
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # pylint: disable=g-direct-tensorflow-import
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 # pylint: enable=g-direct-tensorflow-import
 from official.projects.nhnet import trainer
 from official.projects.nhnet import utils
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/nhnet/utils.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Utility helpers for Bert2Bert."""
 from typing import Optional, Text
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.legacy.bert import configs
 from official.modeling.hyperparams import params_dict
 from official.projects.nhnet import configs as nhnet_configs
 
 
 def get_bert_config_from_params(
@@ -43,16 +43,16 @@
   ]
 
 
 # pylint: enable=protected-access
 
 
 def initialize_bert2bert_from_pretrained_bert(
-    bert_encoder: tf.keras.layers.Layer,
-    bert_decoder: tf.keras.layers.Layer,
+    bert_encoder: tf_keras.layers.Layer,
+    bert_decoder: tf_keras.layers.Layer,
     init_checkpoint: Optional[Text] = None) -> None:
   """Helper function to initialze Bert2Bert from Bert pretrained checkpoint."""
   ckpt = tf.train.Checkpoint(model=bert_encoder)
   logging.info(
       "Checkpoint file %s found and restoring from "
       "initial checkpoint for core model.", init_checkpoint)
   status = ckpt.restore(init_checkpoint)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/panoptic/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/movinet/tools/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/panoptic/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/nhnet/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/panoptic/configs/panoptic_deeplab.py` & `tf-models-no-deps-2.16.0/official/projects/panoptic/configs/panoptic_deeplab.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -41,15 +41,17 @@
   # for eval. In that case, groundtruth_padded_size has to be specified too to
   # allow for batching the variable input sizes of images.
   resize_eval_groundtruth: bool = True
   groundtruth_padded_size: List[int] = dataclasses.field(default_factory=list)
   aug_scale_min: float = 1.0
   aug_scale_max: float = 1.0
   aug_rand_hflip: bool = True
-  aug_type: common.Augmentation = common.Augmentation()
+  aug_type: common.Augmentation = dataclasses.field(
+      default_factory=common.Augmentation
+  )
   sigma: float = 8.0
   small_instance_area_threshold: int = 4096
   small_instance_weight: float = 3.0
   dtype = 'float32'
 
 
 @dataclasses.dataclass
@@ -58,22 +60,24 @@
   panoptic_category_mask_key: str = 'image/panoptic/category_mask'
   panoptic_instance_mask_key: str = 'image/panoptic/instance_mask'
 
 
 @dataclasses.dataclass
 class DataDecoder(common.DataDecoder):
   """Data decoder config."""
-  simple_decoder: TfExampleDecoder = TfExampleDecoder()
+  simple_decoder: TfExampleDecoder = dataclasses.field(
+      default_factory=TfExampleDecoder
+  )
 
 
 @dataclasses.dataclass
 class DataConfig(cfg.DataConfig):
   """Input config for training."""
-  decoder: DataDecoder = DataDecoder()
-  parser: Parser = Parser()
+  decoder: DataDecoder = dataclasses.field(default_factory=DataDecoder)
+  parser: Parser = dataclasses.field(default_factory=Parser)
   input_path: str = ''
   drop_remainder: bool = True
   file_type: str = 'tfrecord'
   is_training: bool = True
   global_batch_size: int = 1
 
 
@@ -122,23 +126,34 @@
 @dataclasses.dataclass
 class PanopticDeeplab(hyperparams.Config):
   """Panoptic Deeplab model config."""
   num_classes: int = 2
   input_size: List[int] = dataclasses.field(default_factory=list)
   min_level: int = 3
   max_level: int = 6
-  norm_activation: common.NormActivation = common.NormActivation()
-  backbone: backbones.Backbone = backbones.Backbone(
-      type='resnet', resnet=backbones.ResNet())
-  decoder: decoders.Decoder = decoders.Decoder(type='aspp')
-  semantic_head: SemanticHead = SemanticHead()
-  instance_head: InstanceHead = InstanceHead()
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=common.NormActivation
+  )
+  backbone: backbones.Backbone = dataclasses.field(
+      default_factory=lambda: backbones.Backbone(
+          type='resnet', resnet=backbones.ResNet()
+      )
+  )
+  decoder: decoders.Decoder = dataclasses.field(
+      default_factory=lambda: decoders.Decoder(
+          type='aspp', aspp=decoders.ASPP(level=3)
+      )
+  )
+  semantic_head: SemanticHead = dataclasses.field(default_factory=SemanticHead)
+  instance_head: InstanceHead = dataclasses.field(default_factory=InstanceHead)
   shared_decoder: bool = False
   generate_panoptic_masks: bool = True
-  post_processor: PanopticDeeplabPostProcessor = PanopticDeeplabPostProcessor()
+  post_processor: PanopticDeeplabPostProcessor = dataclasses.field(
+      default_factory=PanopticDeeplabPostProcessor
+  )
 
 
 @dataclasses.dataclass
 class Losses(hyperparams.Config):
   label_smoothing: float = 0.0
   ignore_label: int = 0
   class_weights: List[float] = dataclasses.field(default_factory=list)
@@ -163,24 +178,28 @@
   report_per_class_iou: bool = False
   report_train_mean_iou: bool = True  # Turning this off can speed up training.
 
 
 @dataclasses.dataclass
 class PanopticDeeplabTask(cfg.TaskConfig):
   """Panoptic deeplab task config."""
-  model: PanopticDeeplab = PanopticDeeplab()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(
-      is_training=False,
-      drop_remainder=False)
-  losses: Losses = Losses()
+  model: PanopticDeeplab = dataclasses.field(default_factory=PanopticDeeplab)
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(  # pylint: disable=g-long-lambda
+          is_training=False, drop_remainder=False
+      )
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
   init_checkpoint: Optional[str] = None
   init_checkpoint_modules: Union[
       str, List[str]] = 'all'  # all, backbone, and/or decoder
-  evaluation: Evaluation = Evaluation()
+  evaluation: Evaluation = dataclasses.field(default_factory=Evaluation)
 
 
 @exp_factory.register_config_factory('panoptic_deeplab_resnet_coco')
 def panoptic_deeplab_resnet_coco() -> cfg.ExperimentConfig:
   """COCO panoptic segmentation with Panoptic Deeplab."""
   train_steps = 200000
   train_batch_size = 64
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/panoptic/configs/panoptic_maskrcnn.py` & `tf-models-no-deps-2.16.0/official/projects/panoptic/configs/panoptic_maskrcnn.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,27 +19,30 @@
 from typing import List, Optional
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.modeling import optimization
 from official.projects.deepmac_maskrcnn.configs import deep_mask_head_rcnn as deepmac_maskrcnn
+from official.projects.uvit.configs import backbones as uvit_backbones
 from official.vision.configs import common
 from official.vision.configs import maskrcnn
 from official.vision.configs import semantic_segmentation
+from official.vision.configs.google import backbones
 
 
 SEGMENTATION_MODEL = semantic_segmentation.SemanticSegmentationModel
 SEGMENTATION_HEAD = semantic_segmentation.SegmentationHead
 
 _COCO_INPUT_PATH_BASE = 'coco/tfrecords'
 _COCO_TRAIN_EXAMPLES = 118287
 _COCO_VAL_EXAMPLES = 5000
 
 # pytype: disable=wrong-keyword-args
+# pylint: disable=unexpected-keyword-arg
 
 
 @dataclasses.dataclass
 class Parser(maskrcnn.Parser):
   """Panoptic Mask R-CNN parser config."""
   # If segmentation_resize_eval_groundtruth is set to False, original image
   # sizes are used for eval. In that case,
@@ -62,22 +65,24 @@
   panoptic_category_mask_key: str = 'image/panoptic/category_mask'
   panoptic_instance_mask_key: str = 'image/panoptic/instance_mask'
 
 
 @dataclasses.dataclass
 class DataDecoder(common.DataDecoder):
   """Data decoder config."""
-  simple_decoder: TfExampleDecoder = TfExampleDecoder()
+  simple_decoder: TfExampleDecoder = dataclasses.field(
+      default_factory=TfExampleDecoder
+  )
 
 
 @dataclasses.dataclass
 class DataConfig(maskrcnn.DataConfig):
   """Input config for training."""
-  decoder: DataDecoder = DataDecoder()
-  parser: Parser = Parser()
+  decoder: DataDecoder = dataclasses.field(default_factory=DataDecoder)
+  parser: Parser = dataclasses.field(default_factory=Parser)
 
 
 @dataclasses.dataclass
 class PanopticSegmentationGenerator(hyperparams.Config):
   """Panoptic segmentation generator config."""
   output_size: List[int] = dataclasses.field(
       default_factory=list)
@@ -88,35 +93,58 @@
   things_class_label: int = 1
   void_class_label: int = 0
   void_instance_id: int = 0
   rescale_predictions: bool = False
 
 
 @dataclasses.dataclass
+class Backbone(backbones.Backbone):
+  """Configuration for backbones.
+
+  Attributes:
+    type: "str", type of backbone be used, one the of fields below.
+    uvit: uvit backbone config.
+  """
+  type: Optional[str] = None
+  uvit: uvit_backbones.VisionTransformer = dataclasses.field(
+      default_factory=uvit_backbones.VisionTransformer
+  )
+
+
+@dataclasses.dataclass
 class PanopticMaskRCNN(deepmac_maskrcnn.DeepMaskHeadRCNN):
   """Panoptic Mask R-CNN model config."""
-  segmentation_model: semantic_segmentation.SemanticSegmentationModel = (
-      SEGMENTATION_MODEL(num_classes=2))
-  include_mask = True
+  backbone: Backbone = dataclasses.field(
+      default_factory=lambda: Backbone(type='resnet', resnet=backbones.ResNet())
+  )
+  segmentation_model: SEGMENTATION_MODEL = dataclasses.field(
+      default_factory=lambda: SEGMENTATION_MODEL(num_classes=2)
+  )
+  include_mask: bool = True
   shared_backbone: bool = True
   shared_decoder: bool = True
   stuff_classes_offset: int = 0
   generate_panoptic_masks: bool = True
-  panoptic_segmentation_generator: PanopticSegmentationGenerator = PanopticSegmentationGenerator()  # pylint:disable=line-too-long
+  panoptic_segmentation_generator: PanopticSegmentationGenerator = (
+      dataclasses.field(default_factory=PanopticSegmentationGenerator)
+  )
 
 
 @dataclasses.dataclass
 class Losses(maskrcnn.Losses):
   """Panoptic Mask R-CNN loss config."""
   semantic_segmentation_label_smoothing: float = 0.0
   semantic_segmentation_ignore_label: int = 255
   semantic_segmentation_gt_is_matting_map: bool = False
   semantic_segmentation_class_weights: List[float] = dataclasses.field(
       default_factory=list)
   semantic_segmentation_use_groundtruth_dimension: bool = True
+  # If true, use binary cross entropy (sigmoid) in loss, otherwise, use
+  # categorical cross entropy (softmax).
+  semantic_segmentation_use_binary_cross_entropy: bool = False
   semantic_segmentation_top_k_percent_pixels: float = 1.0
   instance_segmentation_weight: float = 1.0
   semantic_segmentation_weight: float = 0.5
 
 
 @dataclasses.dataclass
 class PanopticQualityEvaluator(hyperparams.Config):
@@ -130,33 +158,42 @@
   rescale_predictions: bool = False
   report_per_class_metrics: bool = False
 
 
 @dataclasses.dataclass
 class PanopticMaskRCNNTask(maskrcnn.MaskRCNNTask):
   """Panoptic Mask R-CNN task config."""
-  model: PanopticMaskRCNN = PanopticMaskRCNN()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(is_training=False,
-                                           drop_remainder=False)
-  segmentation_evaluation: semantic_segmentation.Evaluation = semantic_segmentation.Evaluation()  # pylint: disable=line-too-long
-  losses: Losses = Losses()
+  model: PanopticMaskRCNN = dataclasses.field(default_factory=PanopticMaskRCNN)
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(  # pylint: disable=g-long-lambda
+          is_training=False, drop_remainder=False
+      )
+  )
+  segmentation_evaluation: semantic_segmentation.Evaluation = dataclasses.field(
+      default_factory=semantic_segmentation.Evaluation
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
   init_checkpoint: Optional[str] = None
   segmentation_init_checkpoint: Optional[str] = None
 
   # 'init_checkpoint_modules' controls the modules that need to be initialized
   # from checkpoint paths given by 'init_checkpoint' and/or
   # 'segmentation_init_checkpoint. Supports modules:
   # 'backbone': Initialize MaskRCNN backbone
   # 'segmentation_backbone': Initialize segmentation backbone
   # 'segmentation_decoder': Initialize segmentation decoder
   # 'all': Initialize all modules
   init_checkpoint_modules: Optional[List[str]] = dataclasses.field(
       default_factory=list)
-  panoptic_quality_evaluator: PanopticQualityEvaluator = PanopticQualityEvaluator()  # pylint: disable=line-too-long
+  panoptic_quality_evaluator: PanopticQualityEvaluator = dataclasses.field(
+      default_factory=PanopticQualityEvaluator
+  )
 
 
 @exp_factory.register_config_factory('panoptic_fpn_coco')
 def panoptic_fpn_coco() -> cfg.ExperimentConfig:
   """COCO panoptic segmentation with Panoptic Mask R-CNN."""
   train_batch_size = 64
   eval_batch_size = 8
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/panoptic/tasks/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/panoptic/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/panoptic/tasks/panoptic_deeplab.py` & `tf-models-no-deps-2.16.0/official/projects/panoptic/tasks/panoptic_deeplab.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Panoptic Deeplab task definition."""
 from typing import Any, Dict, List, Mapping, Optional, Tuple
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import dataset_fn
 from official.core import base_task
 from official.core import task_factory
 from official.projects.panoptic.configs import panoptic_deeplab as exp_cfg
 from official.projects.panoptic.dataloaders import panoptic_deeplab_input
 from official.projects.panoptic.losses import panoptic_deeplab_losses
@@ -32,31 +32,37 @@
 
 @task_factory.register_task_cls(exp_cfg.PanopticDeeplabTask)
 class PanopticDeeplabTask(base_task.Task):
   """A task for Panoptic Deeplab."""
 
   def build_model(self):
     """Builds panoptic deeplab model."""
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None] + self.task_config.model.input_size)
 
     l2_weight_decay = self.task_config.losses.l2_weight_decay
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (tf.keras.regularizers.l2(
+    l2_regularizer = (tf_keras.regularizers.l2(
         l2_weight_decay / 2.0) if l2_weight_decay else None)
 
     model = factory.build_panoptic_deeplab(
         input_specs=input_specs,
         model_config=self.task_config.model,
         l2_regularizer=l2_regularizer)
+
+    # Builds the model through warm-up call.
+    dummy_images = tf_keras.Input(self.task_config.model.input_size)
+    # Note that image_info is always in the shape of [4, 2].
+    dummy_image_info = tf_keras.layers.Input([4, 2])
+    _ = model(dummy_images, dummy_image_info, training=False)
     return model
 
-  def initialize(self, model: tf.keras.Model):
+  def initialize(self, model: tf_keras.Model):
     """Loads pretrained checkpoint."""
     if not self.task_config.init_checkpoint:
       return
 
     ckpt_dir_or_file = self.task_config.init_checkpoint
     if tf.io.gfile.isdir(ckpt_dir_or_file):
       ckpt_dir_or_file = tf.train.latest_checkpoint(ckpt_dir_or_file)
@@ -182,27 +188,27 @@
         'instance_center_heatmap_loss': instance_center_heatmap_loss,
         'instance_center_offset_loss': instance_center_offset_loss
     }
 
     return losses
 
   def build_metrics(self, training: bool = True) -> List[
-      tf.keras.metrics.Metric]:
+      tf_keras.metrics.Metric]:
     """Build metrics."""
     eval_config = self.task_config.evaluation
     metrics = []
     if training:
       metric_names = [
           'total_loss',
           'segmentation_loss',
           'instance_center_heatmap_loss',
           'instance_center_offset_loss',
           'model_loss']
       for name in metric_names:
-        metrics.append(tf.keras.metrics.Mean(name, dtype=tf.float32))
+        metrics.append(tf_keras.metrics.Mean(name, dtype=tf.float32))
 
       if eval_config.report_train_mean_iou:
         self.train_mean_iou = segmentation_metrics.MeanIoU(
             name='train_mean_iou',
             num_classes=self.task_config.model.num_classes,
             rescale_predictions=False,
             dtype=tf.float32)
@@ -227,16 +233,16 @@
                 rescale_predictions=eval_config.rescale_predictions))
 
     return metrics
 
   def train_step(
       self,
       inputs: Tuple[Any, Any],
-      model: tf.keras.Model,
-      optimizer: tf.keras.optimizers.Optimizer,
+      model: tf_keras.Model,
+      optimizer: tf_keras.optimizers.Optimizer,
       metrics: Optional[List[Any]] = None) -> Dict[str, Any]:
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
@@ -261,21 +267,21 @@
           labels=labels,
           model_outputs=outputs,
           aux_losses=model.losses)
       scaled_loss = losses['total_loss'] / num_replicas
 
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     # Scales back gradient when LossScaleOptimizer is used.
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
     optimizer.apply_gradients(list(zip(grads, tvars)))
 
     logs = {self.loss: losses['total_loss']}
 
     if metrics:
       for m in metrics:
@@ -297,15 +303,15 @@
       })
 
     return logs
 
   def validation_step(
       self,
       inputs: Tuple[Any, Any],
-      model: tf.keras.Model,
+      model: tf_keras.Model,
       metrics: Optional[List[Any]] = None) -> Dict[str, Any]:
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/panoptic/tasks/panoptic_maskrcnn.py` & `tf-models-no-deps-2.16.0/official/projects/panoptic/tasks/panoptic_maskrcnn.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,23 +12,24 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Panoptic MaskRCNN task definition."""
 from typing import Any, Dict, List, Mapping, Optional, Tuple
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import dataset_fn
 from official.core import task_factory
 from official.projects.panoptic.configs import panoptic_maskrcnn as exp_cfg
 from official.projects.panoptic.dataloaders import panoptic_maskrcnn_input
 from official.projects.panoptic.modeling import factory
+from official.vision.dataloaders import input_reader
 from official.vision.dataloaders import input_reader_factory
-from official.vision.evaluation import panoptic_quality_evaluator
+from official.vision.evaluation import panoptic_quality
 from official.vision.evaluation import segmentation_metrics
 from official.vision.losses import segmentation_losses
 from official.vision.tasks import maskrcnn
 
 
 @task_factory.register_task_cls(exp_cfg.PanopticMaskRCNNTask)
 class PanopticMaskRCNNTask(maskrcnn.MaskRCNNTask):
@@ -36,39 +37,54 @@
   """A single-replica view of training procedure.
 
   Panoptic Mask R-CNN task provides artifacts for training/evalution procedures,
   including loading/iterating over Datasets, initializing the model, calculating
   the loss, post-processing, and customized metrics with reduction.
   """
 
-  def build_model(self) -> tf.keras.Model:
-    """Build Panoptic Mask R-CNN model."""
+  def __init__(self,
+               params,
+               logging_dir: Optional[str] = None,
+               name: Optional[str] = None):
+    super().__init__(params, logging_dir=logging_dir, name=name)
+    self.segmentation_train_mean_iou = None
+    self.segmentation_perclass_iou_metric = None
+    self.panoptic_quality_metric = None
 
-    input_specs = tf.keras.layers.InputSpec(
+  def build_model(self) -> tf_keras.Model:
+    """Builds Panoptic Mask R-CNN model."""
+
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None] + self.task_config.model.input_size)
 
     l2_weight_decay = self.task_config.losses.l2_weight_decay
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (tf.keras.regularizers.l2(
+    l2_regularizer = (tf_keras.regularizers.l2(
         l2_weight_decay / 2.0) if l2_weight_decay else None)
 
     model = factory.build_panoptic_maskrcnn(
         input_specs=input_specs,
         model_config=self.task_config.model,
         l2_regularizer=l2_regularizer)
 
     if self.task_config.freeze_backbone:
       model.backbone.trainable = False
 
+    # Builds the model through warm-up call.
+    dummy_images = tf_keras.Input(self.task_config.model.input_size)
+    # Note that image_info is always in the shape of [4, 2].
+    dummy_image_info = tf_keras.layers.Input([4, 2])
+    _ = model(dummy_images, image_info=dummy_image_info, training=False)
+
     return model
 
-  def initialize(self, model: tf.keras.Model) -> None:
-    """Loading pretrained checkpoint."""
+  def initialize(self, model: tf_keras.Model) -> None:
+    """Loads pretrained checkpoint."""
 
     if not self.task_config.init_checkpoint:
       return
 
     def _get_checkpoint_path(checkpoint_dir_or_file):
       checkpoint_path = checkpoint_dir_or_file
       if tf.io.gfile.isdir(checkpoint_dir_or_file):
@@ -84,15 +100,26 @@
         ckpt = tf.train.Checkpoint(**model.checkpoint_items)
         status = ckpt.read(checkpoint_path)
         status.expect_partial().assert_existing_objects_matched()
 
       elif init_module == 'backbone':
         checkpoint_path = _get_checkpoint_path(
             self.task_config.init_checkpoint)
-        ckpt = tf.train.Checkpoint(backbone=model.backbone)
+
+        if self.task_config.model.backbone.type == 'uvit':
+          model.backbone.load_checkpoint(ckpt_filepath=checkpoint_path)
+        else:
+          ckpt = tf.train.Checkpoint(backbone=model.backbone)
+          status = ckpt.read(checkpoint_path)
+          status.expect_partial().assert_existing_objects_matched()
+
+      elif init_module == 'decoder':
+        checkpoint_path = _get_checkpoint_path(
+            self.task_config.init_checkpoint)
+        ckpt = tf.train.Checkpoint(decoder=model.decoder)
         status = ckpt.read(checkpoint_path)
         status.expect_partial().assert_existing_objects_matched()
 
       elif init_module == 'segmentation_backbone':
         checkpoint_path = _get_checkpoint_path(
             self.task_config.segmentation_init_checkpoint)
         ckpt = tf.train.Checkpoint(
@@ -106,26 +133,26 @@
         ckpt = tf.train.Checkpoint(
             segmentation_decoder=model.segmentation_decoder)
         status = ckpt.read(checkpoint_path)
         status.expect_partial().assert_existing_objects_matched()
 
       else:
         raise ValueError(
-            "Only 'all', 'backbone', 'segmentation_backbone' and/or "
-            "segmentation_backbone' can be used to initialize the model, but "
+            "Only 'all', 'backbone', 'decoder', 'segmentation_backbone' and/or "
+            "'segmentation_decoder' can be used to initialize the model, but "
             "got {}".format(init_module))
       logging.info('Finished loading pretrained checkpoint from %s for %s',
                    checkpoint_path, init_module)
 
   def build_inputs(
       self,
       params: exp_cfg.DataConfig,
       input_context: Optional[tf.distribute.InputContext] = None
   ) -> tf.data.Dataset:
-    """Build input dataset."""
+    """Builds input dataset."""
     decoder_cfg = params.decoder.get()
     if params.decoder.type == 'simple_decoder':
       decoder = panoptic_maskrcnn_input.TfExampleDecoder(
           regenerate_source_id=decoder_cfg.regenerate_source_id,
           mask_binarize_threshold=decoder_cfg.mask_binarize_threshold,
           include_panoptic_masks=decoder_cfg.include_panoptic_masks,
           panoptic_category_mask_key=decoder_cfg.panoptic_category_mask_key,
@@ -136,64 +163,72 @@
     parser = panoptic_maskrcnn_input.Parser(
         output_size=self.task_config.model.input_size[:2],
         min_level=self.task_config.model.min_level,
         max_level=self.task_config.model.max_level,
         num_scales=self.task_config.model.anchor.num_scales,
         aspect_ratios=self.task_config.model.anchor.aspect_ratios,
         anchor_size=self.task_config.model.anchor.anchor_size,
-        dtype=params.dtype,
         rpn_match_threshold=params.parser.rpn_match_threshold,
         rpn_unmatched_threshold=params.parser.rpn_unmatched_threshold,
         rpn_batch_size_per_im=params.parser.rpn_batch_size_per_im,
         rpn_fg_fraction=params.parser.rpn_fg_fraction,
         aug_rand_hflip=params.parser.aug_rand_hflip,
+        aug_rand_vflip=params.parser.aug_rand_vflip,
         aug_scale_min=params.parser.aug_scale_min,
         aug_scale_max=params.parser.aug_scale_max,
+        aug_type=params.parser.aug_type,
         skip_crowd_during_training=params.parser.skip_crowd_during_training,
         max_num_instances=params.parser.max_num_instances,
+        outer_boxes_scale=self.task_config.model.outer_boxes_scale,
         mask_crop_size=params.parser.mask_crop_size,
         segmentation_resize_eval_groundtruth=params.parser
         .segmentation_resize_eval_groundtruth,
         segmentation_groundtruth_padded_size=params.parser
         .segmentation_groundtruth_padded_size,
         segmentation_ignore_label=params.parser.segmentation_ignore_label,
         panoptic_ignore_label=params.parser.panoptic_ignore_label,
-        include_panoptic_masks=params.parser.include_panoptic_masks)
+        include_panoptic_masks=params.parser.include_panoptic_masks,
+        dtype=params.dtype,
+    )
 
     reader = input_reader_factory.input_reader_generator(
         params,
         dataset_fn=dataset_fn.pick_dataset_fn(params.file_type),
         decoder_fn=decoder.decode,
-        parser_fn=parser.parse_fn(params.is_training))
+        combine_fn=input_reader.create_combine_fn(params),
+        parser_fn=parser.parse_fn(params.is_training),
+    )
     dataset = reader.read(input_context=input_context)
 
     return dataset
 
   def build_losses(self,
                    outputs: Mapping[str, Any],
                    labels: Mapping[str, Any],
                    aux_losses: Optional[Any] = None) -> Dict[str, tf.Tensor]:
-    """Build Panoptic Mask R-CNN losses."""
+    """Builds Panoptic Mask R-CNN losses."""
     params = self.task_config.losses
 
     use_groundtruth_dimension = (
         params.semantic_segmentation_use_groundtruth_dimension)
 
     segmentation_loss_fn = segmentation_losses.SegmentationLoss(
         label_smoothing=params.semantic_segmentation_label_smoothing,
         class_weights=params.semantic_segmentation_class_weights,
         ignore_label=params.semantic_segmentation_ignore_label,
         gt_is_matting_map=params.semantic_segmentation_gt_is_matting_map,
         use_groundtruth_dimension=use_groundtruth_dimension,
+        use_binary_cross_entropy=params
+        .semantic_segmentation_use_binary_cross_entropy,
         top_k_percent_pixels=params.semantic_segmentation_top_k_percent_pixels)
 
     instance_segmentation_weight = params.instance_segmentation_weight
     semantic_segmentation_weight = params.semantic_segmentation_weight
 
-    losses = super(PanopticMaskRCNNTask, self).build_losses(
+    losses = super().build_losses(
         outputs=outputs,
         labels=labels,
         aux_losses=None)
     maskrcnn_loss = losses['model_loss']
     segmentation_loss = segmentation_loss_fn(
         outputs['segmentation_outputs'],
         labels['gt_segmentation_mask'])
@@ -211,75 +246,66 @@
         'total_loss': total_loss,
         'maskrcnn_loss': maskrcnn_loss,
         'segmentation_loss': segmentation_loss,
         'model_loss': model_loss,
     })
     return losses
 
-  def build_metrics(self, training: bool = True) -> List[
-      tf.keras.metrics.Metric]:
-    """Build detection metrics."""
-    metrics = []
-    num_segmentation_classes = (
-        self.task_config.model.segmentation_model.num_classes)
+  def build_metrics(
+      self, training: bool = True
+  ) -> List[tf_keras.metrics.Metric]:
+    """Builds detection metrics."""
+    metrics = super().build_metrics(training)
+
     if training:
-      metric_names = [
-          'total_loss',
-          'rpn_score_loss',
-          'rpn_box_loss',
-          'frcnn_cls_loss',
-          'frcnn_box_loss',
-          'mask_loss',
-          'maskrcnn_loss',
-          'segmentation_loss',
-          'model_loss'
-      ]
+      metric_names = ['maskrcnn_loss', 'segmentation_loss']
       for name in metric_names:
-        metrics.append(tf.keras.metrics.Mean(name, dtype=tf.float32))
+        metrics.append(tf_keras.metrics.Mean(name, dtype=tf.float32))
 
       if self.task_config.segmentation_evaluation.report_train_mean_iou:
         self.segmentation_train_mean_iou = segmentation_metrics.MeanIoU(
             name='train_mean_iou',
-            num_classes=num_segmentation_classes,
+            num_classes=self.task_config.model.segmentation_model.num_classes,
             rescale_predictions=False,
-            dtype=tf.float32)
-
+            dtype=tf.float32,
+        )
     else:
-      if self.task_config.use_coco_metrics:
-        self._build_coco_metrics()
-
-      rescale_predictions = (not self.task_config.validation_data.parser
-                             .segmentation_resize_eval_groundtruth)
-
+      rescale_predictions = (
+          not self.task_config.validation_data.parser.segmentation_resize_eval_groundtruth
+      )
       self.segmentation_perclass_iou_metric = segmentation_metrics.PerClassIoU(
           name='per_class_iou',
-          num_classes=num_segmentation_classes,
+          num_classes=self.task_config.model.segmentation_model.num_classes,
           rescale_predictions=rescale_predictions,
-          dtype=tf.float32)
+          dtype=tf.float32,
+      )
 
-      if self.task_config.model.generate_panoptic_masks:
+      if (
+          self.task_config.model.generate_panoptic_masks
+          and self.task_config.panoptic_quality_evaluator is not None
+      ):
         if not self.task_config.validation_data.parser.include_panoptic_masks:
-          raise ValueError('`include_panoptic_masks` should be set to True when'
-                           ' computing panoptic quality.')
+          raise ValueError(
+              '`include_panoptic_masks` should be set to True when'
+              ' computing panoptic quality.'
+          )
         pq_config = self.task_config.panoptic_quality_evaluator
-        self.panoptic_quality_metric = (
-            panoptic_quality_evaluator.PanopticQualityEvaluator(
-                num_categories=pq_config.num_categories,
-                ignored_label=pq_config.ignored_label,
-                max_instances_per_category=pq_config.max_instances_per_category,
-                offset=pq_config.offset,
-                is_thing=pq_config.is_thing,
-                rescale_predictions=pq_config.rescale_predictions))
+        self.panoptic_quality_metric = panoptic_quality.PanopticQualityV2(
+            num_categories=pq_config.num_categories,
+            is_thing=pq_config.is_thing,
+            ignored_label=pq_config.ignored_label,
+            rescale_predictions=pq_config.rescale_predictions,
+        )
 
     return metrics
 
   def train_step(self,
                  inputs: Tuple[Any, Any],
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
+                 model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer,
                  metrics: Optional[List[Any]] = None) -> Dict[str, Any]:
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
@@ -288,50 +314,54 @@
     Returns:
       A dictionary of logs.
     """
     images, labels = inputs
     num_replicas = tf.distribute.get_strategy().num_replicas_in_sync
 
     with tf.GradientTape() as tape:
-      outputs = model(
-          images,
-          image_info=labels['image_info'],
-          anchor_boxes=labels['anchor_boxes'],
-          gt_boxes=labels['gt_boxes'],
-          gt_classes=labels['gt_classes'],
-          gt_masks=(labels['gt_masks'] if self.task_config.model.include_mask
-                    else None),
-          training=True)
+      model_kwargs = {
+          'image_info': labels['image_info'],
+          'anchor_boxes': labels['anchor_boxes'],
+          'gt_boxes': labels['gt_boxes'],
+          'gt_classes': labels['gt_classes'],
+          'training': True,
+      }
+      if self.task_config.model.include_mask:
+        model_kwargs['gt_masks'] = labels['gt_masks']
+        if self.task_config.model.outer_boxes_scale > 1.0:
+          model_kwargs['gt_outer_boxes'] = labels['gt_outer_boxes']
+      outputs = model(images, **model_kwargs)
       outputs = tf.nest.map_structure(
           lambda x: tf.cast(x, tf.float32), outputs)
 
       # Computes per-replica loss.
       losses = self.build_losses(
           outputs=outputs, labels=labels, aux_losses=model.losses)
       scaled_loss = losses['total_loss'] / num_replicas
 
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     # Scales back gradient when LossScaleOptimizer is used.
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
     optimizer.apply_gradients(list(zip(grads, tvars)))
 
     logs = {self.loss: losses['total_loss']}
 
     if metrics:
       for m in metrics:
         m.update_state(losses[m.name])
 
-    if self.task_config.segmentation_evaluation.report_train_mean_iou:
+    if (self.task_config.segmentation_evaluation.report_train_mean_iou and
+        self.segmentation_train_mean_iou is not None):
       segmentation_labels = {
           'masks': labels['gt_segmentation_mask'],
           'valid_masks': labels['gt_segmentation_valid_mask'],
           'image_info': labels['image_info']
       }
       self.process_metrics(
           metrics=[self.segmentation_train_mean_iou],
@@ -340,18 +370,43 @@
       logs.update({
           self.segmentation_train_mean_iou.name:
               self.segmentation_train_mean_iou.result()
       })
 
     return logs
 
-  def validation_step(self,
-                      inputs: Tuple[Any, Any],
-                      model: tf.keras.Model,
-                      metrics: Optional[List[Any]] = None) -> Dict[str, Any]:
+  def _update_metrics(self, labels, outputs, logs):
+    super()._update_metrics(labels, outputs, logs)
+
+    if self.segmentation_perclass_iou_metric is not None:
+      segmentation_labels = {
+          'masks': labels['groundtruths']['gt_segmentation_mask'],
+          'valid_masks': labels['groundtruths']['gt_segmentation_valid_mask'],
+          'image_info': labels['image_info'],
+      }
+      self.segmentation_perclass_iou_metric.update_state(
+          segmentation_labels, outputs['segmentation_outputs']
+      )
+
+    if self.panoptic_quality_metric is not None:
+      pq_metric_labels = {
+          'category_mask': labels['groundtruths']['gt_panoptic_category_mask'],
+          'instance_mask': labels['groundtruths']['gt_panoptic_instance_mask'],
+          'image_info': labels['image_info'],
+      }
+      self.panoptic_quality_metric.update_state(
+          pq_metric_labels, outputs['panoptic_outputs']
+      )
+
+  def validation_step(
+      self,
+      inputs: Tuple[Any, Any],
+      model: tf_keras.Model,
+      metrics: Optional[List[Any]] = None,
+  ) -> Dict[str, Any]:
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
 
@@ -360,92 +415,93 @@
     """
     images, labels = inputs
 
     outputs = model(
         images,
         anchor_boxes=labels['anchor_boxes'],
         image_info=labels['image_info'],
-        training=False)
+        training=False,
+    )
 
     logs = {self.loss: 0}
-    if self._task_config.use_coco_metrics:
-      coco_model_outputs = {
-          'detection_masks': outputs['detection_masks'],
-          'detection_boxes': outputs['detection_boxes'],
-          'detection_scores': outputs['detection_scores'],
-          'detection_classes': outputs['detection_classes'],
-          'num_detections': outputs['num_detections'],
-          'source_id': labels['groundtruths']['source_id'],
-          'image_info': labels['image_info']
-      }
-      logs.update(
-          {self.coco_metric.name: (labels['groundtruths'], coco_model_outputs)})
-
-    segmentation_labels = {
-        'masks': labels['groundtruths']['gt_segmentation_mask'],
-        'valid_masks': labels['groundtruths']['gt_segmentation_valid_mask'],
-        'image_info': labels['image_info']
-    }
-
-    self.segmentation_perclass_iou_metric.update_state(
-        segmentation_labels, outputs['segmentation_outputs'])
-
-    if self.task_config.model.generate_panoptic_masks:
-      pq_metric_labels = {
-          'category_mask': labels['groundtruths']['gt_panoptic_category_mask'],
-          'instance_mask': labels['groundtruths']['gt_panoptic_instance_mask'],
-          'image_info': labels['image_info']
-      }
-      logs.update({
-          self.panoptic_quality_metric.name:
-              (pq_metric_labels, outputs['panoptic_outputs'])})
+    self._update_metrics(labels, outputs, logs)
     return logs
 
   def aggregate_logs(self, state=None, step_outputs=None):
-    if state is None:
-      self.segmentation_perclass_iou_metric.reset_states()
-      state = [self.segmentation_perclass_iou_metric]
-      if self.task_config.use_coco_metrics:
-        self.coco_metric.reset_states()
-        state.append(self.coco_metric)
-      if self.task_config.model.generate_panoptic_masks:
-        self.panoptic_quality_metric.reset_states()
-        state.append(self.panoptic_quality_metric)
-
-    if self.task_config.use_coco_metrics:
-      self.coco_metric.update_state(step_outputs[self.coco_metric.name][0],
-                                    step_outputs[self.coco_metric.name][1])
+    is_first_step = not state
+    super().aggregate_logs(state, step_outputs)
 
-    if self.task_config.model.generate_panoptic_masks:
-      self.panoptic_quality_metric.update_state(
-          step_outputs[self.panoptic_quality_metric.name][0],
-          step_outputs[self.panoptic_quality_metric.name][1])
+    if is_first_step:
+      if not isinstance(state, list):
+        state = []
+      if self.segmentation_perclass_iou_metric is not None:
+        state.append(self.segmentation_perclass_iou_metric)
+      if self.panoptic_quality_metric is not None:
+        state.append(self.panoptic_quality_metric)
 
+    if not state:
+      # Create an arbitrary state to indicate it's not the first step in the
+      # following calls to this function.
+      state = True
     return state
 
-  def reduce_aggregated_logs(self, aggregated_logs, global_step=None):
-    result = super().reduce_aggregated_logs(
-        aggregated_logs=aggregated_logs, global_step=global_step)
-
+  def _reduce_semantic_metrics(self, logs: Dict[str, Any]):
+    """Updates the per class and mean semantic metrics in the logs."""
     ious = self.segmentation_perclass_iou_metric.result()
     if self.task_config.segmentation_evaluation.report_per_class_iou:
       for i, value in enumerate(ious.numpy()):
-        result.update({'segmentation_iou/class_{}'.format(i): value})
-    # Computes mean IoU
-    result.update({'segmentation_mean_iou': tf.reduce_mean(ious).numpy()})
-
-    if self.task_config.model.generate_panoptic_masks:
-      report_per_class_metrics = (
-          self.task_config.panoptic_quality_evaluator.report_per_class_metrics)
-      panoptic_quality_results = self.panoptic_quality_metric.result()
-      for k, value in panoptic_quality_results.items():
-        if k.endswith('per_class'):
-          if report_per_class_metrics:
-            for i, per_class_value in enumerate(value):
-              metric_key = 'panoptic_quality/{}/class_{}'.format(k, i)
-              result[metric_key] = per_class_value
-          else:
-            continue
-        else:
-          result['panoptic_quality/{}'.format(k)] = value
+        logs.update({'segmentation_iou/class_{}'.format(i): value})
+    logs.update({'segmentation_mean_iou': tf.reduce_mean(ious)})
+
+  def _reduce_panoptic_metrics(self, logs: Dict[str, Any]):
+    """Updates the per class and mean panoptic metrics in the logs."""
+    result = self.panoptic_quality_metric.result()
+    valid_thing_classes = result['valid_thing_classes']
+    valid_stuff_classes = result['valid_stuff_classes']
+    valid_classes = valid_stuff_classes | valid_thing_classes
+    num_categories = tf.math.count_nonzero(valid_classes, dtype=tf.float32)
+    num_thing_categories = tf.math.count_nonzero(
+        valid_thing_classes, dtype=tf.float32
+    )
+    num_stuff_categories = tf.math.count_nonzero(
+        valid_stuff_classes, dtype=tf.float32
+    )
+    valid_thing_classes = tf.cast(valid_thing_classes, dtype=tf.float32)
+    valid_stuff_classes = tf.cast(valid_stuff_classes, dtype=tf.float32)
+
+    logs['panoptic_quality/All_num_categories'] = num_categories
+    logs['panoptic_quality/Things_num_categories'] = num_thing_categories
+    logs['panoptic_quality/Stuff_num_categories'] = num_stuff_categories
+    for metric in ['pq', 'sq', 'rq']:
+      metric_per_class = result[f'{metric}_per_class']
+      logs[f'panoptic_quality/All_{metric}'] = tf.math.divide_no_nan(
+          tf.reduce_sum(metric_per_class), num_categories
+      )
+      logs[f'panoptic_quality/Things_{metric}'] = tf.math.divide_no_nan(
+          tf.reduce_sum(metric_per_class * valid_thing_classes),
+          num_thing_categories,
+      )
+      logs[f'panoptic_quality/Stuff_{metric}'] = tf.math.divide_no_nan(
+          tf.reduce_sum(metric_per_class * valid_stuff_classes),
+          num_stuff_categories,
+      )
+      if self.task_config.panoptic_quality_evaluator.report_per_class_metrics:
+        for i, is_valid in enumerate(valid_classes.numpy()):
+          if is_valid:
+            logs[f'panoptic_quality/{metric}/class_{i}'] = metric_per_class[i]
 
-    return result
+  def reduce_aggregated_logs(
+      self,
+      aggregated_logs: Dict[str, Any],
+      global_step: Optional[tf.Tensor] = None,
+  ) -> Dict[str, tf.Tensor]:
+    """Optional reduce of aggregated logs over validation steps."""
+    logs = super().reduce_aggregated_logs(aggregated_logs, global_step)
+
+    if self.segmentation_perclass_iou_metric is not None:
+      self._reduce_semantic_metrics(logs)
+      self.segmentation_perclass_iou_metric.reset_state()
+    if self.panoptic_quality_metric is not None:
+      self._reduce_panoptic_metrics(logs)
+      self.panoptic_quality_metric.reset_state()
+
+    return logs
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/panoptic/train.py` & `tf-models-no-deps-2.16.0/official/projects/panoptic/train.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,13 +18,15 @@
 
 from official.common import flags as tfm_flags
 # pylint: disable=unused-import
 from official.projects.panoptic.configs import panoptic_deeplab
 from official.projects.panoptic.configs import panoptic_maskrcnn
 from official.projects.panoptic.tasks import panoptic_deeplab as panoptic_deeplab_task
 from official.projects.panoptic.tasks import panoptic_maskrcnn as panoptic_maskrcnn_task
+from official.projects.uvit import configs
+from official.projects.uvit import tasks
 from official.vision import train
 # pylint: enable=unused-import
 
 if __name__ == '__main__':
   tfm_flags.define_flags()
   app.run(train.main)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/panoptic/configs/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/roformer.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/roformer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Roformer model configurations and instantiation methods."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.modeling.hyperparams import base_config
 from official.nlp.configs import encoders
 from official.projects.roformer import roformer_encoder
 
 
@@ -42,12 +42,12 @@
       num_attention_heads=encoder_cfg.num_attention_heads,
       intermediate_size=encoder_cfg.intermediate_size,
       activation=tf_utils.get_activation(encoder_cfg.hidden_activation),
       dropout_rate=encoder_cfg.dropout_rate,
       attention_dropout_rate=encoder_cfg.attention_dropout_rate,
       max_sequence_length=encoder_cfg.max_position_embeddings,
       type_vocab_size=encoder_cfg.type_vocab_size,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=encoder_cfg.initializer_range),
       output_range=encoder_cfg.output_range,
       embedding_width=encoder_cfg.embedding_size,
       norm_first=encoder_cfg.norm_first)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/roformer_attention.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/roformer_attention.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,37 +10,40 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Roformer attention layer."""
 # pylint: disable=g-classes-have-attributes
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-EinsumDense = tf.keras.layers.EinsumDense
-MultiHeadAttention = tf.keras.layers.MultiHeadAttention
+EinsumDense = tf_keras.layers.EinsumDense
+MultiHeadAttention = tf_keras.layers.MultiHeadAttention
 
 
 def _build_trig_vector(length, key_dim):
   """Builds the trig vector."""
-  tf_dtype = tf.keras.mixed_precision.global_policy().compute_dtype
+  tf_dtype = tf_keras.mixed_precision.global_policy().compute_dtype
   position_ids = tf.cast(tf.range(length), dtype=tf_dtype)
   position_ids = tf.expand_dims(position_ids, axis=0)
   steps = key_dim // 2
-  indices = tf.cast(tf.range(steps), dtype=tf_dtype)
-  indices = tf.pow(tf.constant(10000.0, dtype=tf_dtype), -2 * indices / steps)
-  vec = tf.einsum('bl,d->bld', position_ids, indices)
+  # 2 (i - 1) / key_dim = (i - 1) / steps: (-1 achieved with zero-indexing)
+  wavenumber_exponent = -tf.cast(tf.range(steps), dtype=tf_dtype) / steps
+  wavenumbers = tf.pow(
+      tf.constant(10000.0, dtype=tf_dtype), wavenumber_exponent
+  )
+  vec = tf.einsum('bl,d->bld', position_ids, wavenumbers)
   sin_vec = tf.repeat(tf.sin(vec), repeats=2, axis=-1)
   cos_vec = tf.repeat(tf.cos(vec), repeats=2, axis=-1)
   sin_vec, cos_vec = tf.expand_dims(sin_vec, 2), tf.expand_dims(cos_vec, 2)
   return sin_vec, cos_vec
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class RoformerAttention(tf.keras.layers.MultiHeadAttention):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class RoformerAttention(tf_keras.layers.MultiHeadAttention):
   """Roformer Attention."""
 
   def __init__(self,
                q_max_sequence_length,
                kv_max_sequence_length,
                output_range=None,
                **kwargs):
@@ -83,15 +86,15 @@
     k2 = tf.reshape(k2, k_shape)
     ret_q = q * self.q_cos_vec[:, 0:q_len,
                                ...] + q2 * self.q_sin_vec[:, 0:q_len, ...]
     ret_w = k * self.k_cos_vec[:, 0:k_len,
                                ...] + k2 * self.k_sin_vec[:, 0:k_len, ...]
     return ret_q, ret_w, v
 
-  def call(self,
+  def call(self,  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
            query,
            value,
            key=None,
            attention_mask=None,
            return_attention_scores=False,
            training=None):
     if not self._built_from_signature:
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/roformer_attention_test.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/roformer_attention_test.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,19 +10,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for the attention layer."""
 
+from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.projects.roformer import roformer_attention
 
 
 def _create_mock_attention_data(num_heads,
                                 key_dim,
                                 value_dim,
                                 q_seq_length,
@@ -58,16 +58,15 @@
     mask_data = np.random.randint(2, size=mask_shape).astype("float32")
     mask_data = dict(attention_mask=mask_data)
     data.update(mask_data)
 
   return data
 
 
-@keras_parameterized.run_all_keras_modes
-class RoformerAttentionTest(keras_parameterized.TestCase):
+class RoformerAttentionTest(tf.test.TestCase, parameterized.TestCase):
 
   def setUp(self):
     super(RoformerAttentionTest, self).setUp()
     np.random.seed(0)
     tf.random.set_seed(0)
 
   @combinations.generate(
@@ -75,15 +74,15 @@
   def test_trig_vector(self, length, key_dim):
     sin_emb, cos_emb = roformer_attention._build_trig_vector(length, key_dim)
     length = tf.shape(sin_emb)[1]
     key_dim = tf.shape(sin_emb)[3]
     for m in range(0, length):
       half_d = key_dim // 2
       std_emb = tf.range(half_d, dtype=tf.float32)
-      std_emb = tf.pow(10000.0, -2 * std_emb / float(half_d))
+      std_emb = tf.pow(10000.0, -std_emb / float(half_d))
       std_emb = m * std_emb
       std_sin_emb = tf.sin(std_emb)
       std_cos_emb = tf.cos(std_emb)
       tf.assert_equal(sin_emb[:, m, :, 0::2], std_sin_emb)
       tf.assert_equal(sin_emb[:, m, :, 1::2], std_sin_emb)
       tf.assert_equal(cos_emb[:, m, :, 0::2], std_cos_emb)
       tf.assert_equal(cos_emb[:, m, :, 1::2], std_cos_emb)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/roformer_encoder.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/roformer_encoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,23 +13,23 @@
 # limitations under the License.
 
 """Roformer encoder network."""
 # pylint: disable=g-classes-have-attributes
 
 import collections
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 from official.projects.roformer import roformer_encoder_block
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class RoformerEncoder(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class RoformerEncoder(tf_keras.Model):
   """Bi-directional Transformer-based encoder network with Roformer.
 
   Roformer paper: https://arxiv.org/abs/2104.09864
 
   *Note* that the network is constructed by
   [Keras Functional API](https://keras.io/guides/functional_api/).
 
@@ -73,18 +73,18 @@
       vocab_size,
       hidden_size=768,  # FIXME: hidden_size per head should be even!
       num_layers=12,
       num_attention_heads=12,
       max_sequence_length=512,
       type_vocab_size=16,
       inner_dim=3072,
-      inner_activation=lambda x: tf.keras.activations.gelu(x, approximate=True),
+      inner_activation=lambda x: tf_keras.activations.gelu(x, approximate=True),
       output_dropout=0.1,
       attention_dropout=0.1,
-      initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02),
+      initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02),
       output_range=None,
       embedding_width=None,
       embedding_layer=None,
       norm_first=False,
       **kwargs):
     if 'intermediate_size' in kwargs:
       inner_dim = kwargs['intermediate_size']
@@ -95,22 +95,22 @@
     if 'dropout_rate' in kwargs:
       output_dropout = kwargs['dropout_rate']
       del kwargs['dropout_rate']
     if 'attention_dropout_rate' in kwargs:
       attention_dropout = kwargs['attention_dropout_rate']
       del kwargs['attention_dropout_rate']
 
-    activation = tf.keras.activations.get(inner_activation)
-    initializer = tf.keras.initializers.get(initializer)
+    activation = tf_keras.activations.get(inner_activation)
+    initializer = tf_keras.initializers.get(initializer)
 
-    word_ids = tf.keras.layers.Input(
+    word_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_word_ids')
-    mask = tf.keras.layers.Input(
+    mask = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_mask')
-    type_ids = tf.keras.layers.Input(
+    type_ids = tf_keras.layers.Input(
         shape=(None,), dtype=tf.int32, name='input_type_ids')
 
     if embedding_width is None:
       embedding_width = hidden_size
 
     if embedding_layer is None:
       embedding_layer_inst = layers.on_device_embedding.OnDeviceEmbedding(
@@ -128,26 +128,26 @@
         embedding_width=embedding_width,
         initializer=tf_utils.clone_initializer(initializer),
         use_one_hot=True,
         name='type_embeddings')
     type_embeddings = type_embedding_layer(type_ids)
 
     # Roformer does not have absolute position embedding
-    embeddings = tf.keras.layers.Add()([word_embeddings, type_embeddings])
+    embeddings = tf_keras.layers.Add()([word_embeddings, type_embeddings])
 
-    embedding_norm_layer = tf.keras.layers.LayerNormalization(
+    embedding_norm_layer = tf_keras.layers.LayerNormalization(
         name='embeddings/layer_norm', axis=-1, epsilon=1e-12, dtype=tf.float32)
 
     embeddings = embedding_norm_layer(embeddings)
-    embeddings = (tf.keras.layers.Dropout(rate=output_dropout)(embeddings))
+    embeddings = (tf_keras.layers.Dropout(rate=output_dropout)(embeddings))
 
     # We project the 'embedding' output to 'hidden_size' if it is not already
     # 'hidden_size'.
     if embedding_width != hidden_size:
-      embedding_projection = tf.keras.layers.EinsumDense(
+      embedding_projection = tf_keras.layers.EinsumDense(
           '...x,xy->...y',
           output_shape=hidden_size,
           bias_axes='y',
           kernel_initializer=tf_utils.clone_initializer(initializer),
           name='embedding_projection')
       embeddings = embedding_projection(embeddings)
     else:
@@ -179,15 +179,15 @@
       encoder_outputs.append(data)
 
     last_encoder_output = encoder_outputs[-1]
     # Applying a tf.slice op (through subscript notation) to a Keras tensor
     # like this will create a SliceOpLambda layer. This is better than a Lambda
     # layer with Python code, because that is fundamentally less portable.
     first_token_tensor = last_encoder_output[:, 0, :]
-    pooler_layer = tf.keras.layers.Dense(
+    pooler_layer = tf_keras.layers.Dense(
         units=hidden_size,
         activation='tanh',
         kernel_initializer=tf_utils.clone_initializer(initializer),
         name='pooler_transform')
     cls_output = pooler_layer(first_token_tensor)
 
     outputs = dict(
@@ -209,18 +209,18 @@
         'vocab_size': vocab_size,
         'hidden_size': hidden_size,
         'num_layers': num_layers,
         'num_attention_heads': num_attention_heads,
         'max_sequence_length': max_sequence_length,
         'type_vocab_size': type_vocab_size,
         'inner_dim': inner_dim,
-        'inner_activation': tf.keras.activations.serialize(activation),
+        'inner_activation': tf_keras.activations.serialize(activation),
         'output_dropout': output_dropout,
         'attention_dropout': attention_dropout,
-        'initializer': tf.keras.initializers.serialize(initializer),
+        'initializer': tf_keras.initializers.serialize(initializer),
         'output_range': output_range,
         'embedding_width': embedding_width,
         'embedding_layer': embedding_layer,
         'norm_first': norm_first,
     }
 
     # We are storing the config dict as a namedtuple here to ensure checkpoint
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/roformer_encoder_block.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/roformer_encoder_block.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,21 +10,21 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Roformer TransformerEncoder block layer."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling import tf_utils
 from official.projects.roformer import roformer_attention
 
 
-@tf.keras.utils.register_keras_serializable(package="Text")
-class RoformerEncoderBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package="Text")
+class RoformerEncoderBlock(tf_keras.layers.Layer):
   """RoformerEncoderBlock layer."""
 
   def __init__(self,
                num_attention_heads,
                inner_dim,
                inner_activation,
                q_max_sequence_length=512,
@@ -91,29 +91,29 @@
     self._inner_dim = inner_dim
     self._inner_activation = inner_activation
     self._attention_dropout = attention_dropout
     self._attention_dropout_rate = attention_dropout
     self._output_dropout = output_dropout
     self._output_dropout_rate = output_dropout
     self._output_range = output_range
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self._bias_initializer = tf.keras.initializers.get(bias_initializer)
-    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
-    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)
-    self._activity_regularizer = tf.keras.regularizers.get(activity_regularizer)
-    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)
-    self._bias_constraint = tf.keras.constraints.get(bias_constraint)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self._bias_initializer = tf_keras.initializers.get(bias_initializer)
+    self._kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
+    self._bias_regularizer = tf_keras.regularizers.get(bias_regularizer)
+    self._activity_regularizer = tf_keras.regularizers.get(activity_regularizer)
+    self._kernel_constraint = tf_keras.constraints.get(kernel_constraint)
+    self._bias_constraint = tf_keras.constraints.get(bias_constraint)
     self._use_bias = use_bias
     self._norm_first = norm_first
     self._norm_epsilon = norm_epsilon
     self._inner_dropout = inner_dropout
     self._q_max_sequence_length = q_max_sequence_length
     self._kv_max_sequence_length = kv_max_sequence_length
     if attention_initializer:
-      self._attention_initializer = tf.keras.initializers.get(
+      self._attention_initializer = tf_keras.initializers.get(
           attention_initializer)
     else:
       self._attention_initializer = tf_utils.clone_initializer(
           self._kernel_initializer)
     self._attention_axes = attention_axes
 
   def build(self, input_shape):
@@ -149,50 +149,50 @@
         key_dim=self._attention_head_size,
         dropout=self._attention_dropout,
         use_bias=self._use_bias,
         kernel_initializer=self._attention_initializer,
         attention_axes=self._attention_axes,
         name="self_attention",
         **common_kwargs)
-    self._attention_dropout = tf.keras.layers.Dropout(rate=self._output_dropout)
+    self._attention_dropout = tf_keras.layers.Dropout(rate=self._output_dropout)
     # Use float32 in layernorm for numeric stability.
     # It is probably safe in mixed_float16, but we haven't validated this yet.
     self._attention_layer_norm = (
-        tf.keras.layers.LayerNormalization(
+        tf_keras.layers.LayerNormalization(
             name="self_attention_layer_norm",
             axis=-1,
             epsilon=self._norm_epsilon,
             dtype=tf.float32))
-    self._intermediate_dense = tf.keras.layers.EinsumDense(
+    self._intermediate_dense = tf_keras.layers.EinsumDense(
         einsum_equation,
         output_shape=(None, self._inner_dim),
         bias_axes="d",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         name="intermediate",
         **common_kwargs)
-    policy = tf.keras.mixed_precision.global_policy()
+    policy = tf_keras.mixed_precision.global_policy()
     if policy.name == "mixed_bfloat16":
       # bfloat16 causes BERT with the LAMB optimizer to not converge
       # as well, so we use float32.
       # TODO(b/154538392): Investigate this.
       policy = tf.float32
-    self._intermediate_activation_layer = tf.keras.layers.Activation(
+    self._intermediate_activation_layer = tf_keras.layers.Activation(
         self._inner_activation, dtype=policy)
-    self._inner_dropout_layer = tf.keras.layers.Dropout(
+    self._inner_dropout_layer = tf_keras.layers.Dropout(
         rate=self._inner_dropout)
-    self._output_dense = tf.keras.layers.EinsumDense(
+    self._output_dense = tf_keras.layers.EinsumDense(
         einsum_equation,
         output_shape=(None, hidden_size),
         bias_axes="d",
         name="output",
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         **common_kwargs)
-    self._output_dropout = tf.keras.layers.Dropout(rate=self._output_dropout)
+    self._output_dropout = tf_keras.layers.Dropout(rate=self._output_dropout)
     # Use float32 in layernorm for numeric stability.
-    self._output_layer_norm = tf.keras.layers.LayerNormalization(
+    self._output_layer_norm = tf_keras.layers.LayerNormalization(
         name="output_layer_norm",
         axis=-1,
         epsilon=self._norm_epsilon,
         dtype=tf.float32)
 
     super(RoformerEncoderBlock, self).build(input_shape)
 
@@ -207,37 +207,37 @@
         "output_dropout":
             self._output_dropout_rate,
         "attention_dropout":
             self._attention_dropout_rate,
         "output_range":
             self._output_range,
         "kernel_initializer":
-            tf.keras.initializers.serialize(self._kernel_initializer),
+            tf_keras.initializers.serialize(self._kernel_initializer),
         "bias_initializer":
-            tf.keras.initializers.serialize(self._bias_initializer),
+            tf_keras.initializers.serialize(self._bias_initializer),
         "kernel_regularizer":
-            tf.keras.regularizers.serialize(self._kernel_regularizer),
+            tf_keras.regularizers.serialize(self._kernel_regularizer),
         "bias_regularizer":
-            tf.keras.regularizers.serialize(self._bias_regularizer),
+            tf_keras.regularizers.serialize(self._bias_regularizer),
         "activity_regularizer":
-            tf.keras.regularizers.serialize(self._activity_regularizer),
+            tf_keras.regularizers.serialize(self._activity_regularizer),
         "kernel_constraint":
-            tf.keras.constraints.serialize(self._kernel_constraint),
+            tf_keras.constraints.serialize(self._kernel_constraint),
         "bias_constraint":
-            tf.keras.constraints.serialize(self._bias_constraint),
+            tf_keras.constraints.serialize(self._bias_constraint),
         "use_bias":
             self._use_bias,
         "norm_first":
             self._norm_first,
         "norm_epsilon":
             self._norm_epsilon,
         "inner_dropout":
             self._inner_dropout,
         "attention_initializer":
-            tf.keras.initializers.serialize(self._attention_initializer),
+            tf_keras.initializers.serialize(self._attention_initializer),
         "attention_axes":
             self._attention_axes,
     }
     base_config = super(RoformerEncoderBlock, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/roformer_encoder_block_test.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/roformer_encoder_block_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,85 +12,83 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Keras-based transformer block layer."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.projects.roformer import roformer_encoder_block
 
 
-@keras_parameterized.run_all_keras_modes
 @parameterized.named_parameters(
     ('base', roformer_encoder_block.RoformerEncoderBlock))
-class RoformerEncoderBlockTest(keras_parameterized.TestCase):
+class RoformerEncoderBlockTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(RoformerEncoderBlockTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy('float32')
+    tf_keras.mixed_precision.set_global_policy('float32')
 
   def test_layer_creation(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   def test_layer_creation_with_mask(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
   def test_layer_invocation(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output_tensor = test_layer(data_tensor)
 
     # Create a model from the test layer.
-    model = tf.keras.Model(data_tensor, output_tensor)
+    model = tf_keras.Model(data_tensor, output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     _ = model.predict(input_data)
 
   def test_layer_invocation_with_mask(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = 10 * np.random.random_sample(
         (batch_size, sequence_length, width))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -180,27 +178,27 @@
     _ = new_layer([input_data, mask_data])
     new_layer.set_weights(test_layer.get_weights())
     new_output_tensor = new_layer([input_data, mask_data])
     self.assertAllClose(
         new_output_tensor, output_tensor[:, 0:1, :], atol=5e-5, rtol=0.003)
 
   def test_layer_invocation_with_float16_dtype(self, transformer_cls):
-    tf.keras.mixed_precision.set_global_policy('mixed_float16')
+    tf_keras.mixed_precision.set_global_policy('mixed_float16')
     test_layer = transformer_cls(
         num_attention_heads=10, inner_dim=2048, inner_activation='relu')
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     # Create a 2-dimensional input (the first dimension is implicit).
-    mask_tensor = tf.keras.Input(shape=(sequence_length, sequence_length))
+    mask_tensor = tf_keras.Input(shape=(sequence_length, sequence_length))
     output_tensor = test_layer([data_tensor, mask_tensor])
 
     # Create a model from the test layer.
-    model = tf.keras.Model([data_tensor, mask_tensor], output_tensor)
+    model = tf_keras.Model([data_tensor, mask_tensor], output_tensor)
 
     # Invoke the model on test data. We can't validate the output data itself
     # (the NN is too complex) but this will rule out structural runtime errors.
     batch_size = 6
     input_data = (10 * np.random.random_sample(
         (batch_size, sequence_length, width)))
     # The attention mask should be of shape (batch, from_seq_len, to_seq_len),
@@ -210,55 +208,54 @@
     _ = model.predict([input_data, mask_data])
 
   def test_transform_with_initializer(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=10,
         inner_dim=2048,
         inner_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     sequence_length = 21
     width = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(sequence_length, width))
+    data_tensor = tf_keras.Input(shape=(sequence_length, width))
     output = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output.shape.as_list())
 
   def test_separate_qkv(self, transformer_cls):
     test_layer = transformer_cls(
         num_attention_heads=2,
         inner_dim=128,
         inner_activation='relu',
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(stddev=0.02))
     # Forward path.
     q_tensor = tf.zeros([2, 4, 16], dtype=tf.float32)
     kv_tensor = tf.zeros([2, 8, 16], dtype=tf.float32)
     dummy_mask = tf.zeros([2, 4, 8], dtype=tf.float32)
     inputs = [q_tensor, kv_tensor, dummy_mask]
     output = test_layer(inputs)
     self.assertEqual(output.shape, q_tensor.shape)
 
 
-@keras_parameterized.run_all_keras_modes
-class RoformerArgumentTest(keras_parameterized.TestCase):
+class RoformerArgumentTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_raises(self):
     num_attention_heads = 2
     with self.assertRaisesRegex(ValueError, 'The inner_dim of.*'):
       _ = roformer_encoder_block.RoformerEncoderBlock(
           num_attention_heads=num_attention_heads,
           inner_dim=31,
           inner_activation='relu',
           output_dropout=0.1,
           attention_dropout=0.1,
           use_bias=False,
           norm_first=True,
           norm_epsilon=1e-6,
           inner_dropout=0.1,
-          attention_initializer=tf.keras.initializers.RandomUniform(
+          attention_initializer=tf_keras.initializers.RandomUniform(
               minval=0., maxval=1.))
 
   def test_use_bias_norm_first(self):
     num_attention_heads = 2
     hidden_size = 16
     encoder_block = roformer_encoder_block.RoformerEncoderBlock(
         num_attention_heads=num_attention_heads,
@@ -266,15 +263,15 @@
         inner_activation='relu',
         output_dropout=0.1,
         attention_dropout=0.1,
         use_bias=False,
         norm_first=True,
         norm_epsilon=1e-6,
         inner_dropout=0.1,
-        attention_initializer=tf.keras.initializers.RandomUniform(
+        attention_initializer=tf_keras.initializers.RandomUniform(
             minval=0., maxval=1.))
     # Forward path.
     dummy_tensor = tf.zeros([2, 4, 16], dtype=tf.float32)
     dummy_mask = tf.zeros([2, 4, 4], dtype=tf.float32)
     inputs = [dummy_tensor, dummy_mask]
     output = encoder_block(inputs)
     self.assertEqual(output.shape, (2, 4, hidden_size))
@@ -287,15 +284,15 @@
         inner_activation='relu',
         output_dropout=0.1,
         attention_dropout=0.1,
         use_bias=False,
         norm_first=True,
         norm_epsilon=1e-6,
         inner_dropout=0.1,
-        attention_initializer=tf.keras.initializers.RandomUniform(
+        attention_initializer=tf_keras.initializers.RandomUniform(
             minval=0., maxval=1.))
     encoder_block_config = encoder_block.get_config()
     new_encoder_block = roformer_encoder_block.RoformerEncoderBlock.from_config(
         encoder_block_config)
     self.assertEqual(encoder_block_config, new_encoder_block.get_config())
 
   @parameterized.parameters({'attention_axes': None}, {'attention_axes': [1]},
@@ -311,15 +308,15 @@
         norm_epsilon=1e-6,
         inner_dropout=0.1,
         num_attention_heads=10,
         attention_axes=attention_axes)
     seq_len = 21
     dimensions = 80
     # Create a 3-dimensional input (the first dimension is implicit).
-    data_tensor = tf.keras.Input(shape=(seq_len, dimensions))
+    data_tensor = tf_keras.Input(shape=(seq_len, dimensions))
     output_tensor = test_layer(data_tensor)
     # The default output of a transformer layer should be the same as the input.
     self.assertEqual(data_tensor.shape.as_list(), output_tensor.shape.as_list())
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/roformer_encoder_test.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/roformer_encoder_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,49 +12,45 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for transformer-based bert encoder network."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.projects.roformer import roformer_encoder
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class RoformerEncoderTest(keras_parameterized.TestCase):
+class RoformerEncoderTest(tf.test.TestCase, parameterized.TestCase):
 
   def tearDown(self):
     super(RoformerEncoderTest, self).tearDown()
-    tf.keras.mixed_precision.set_global_policy("float32")
+    tf_keras.mixed_precision.set_global_policy("float32")
 
   def test_network_creation(self):
     hidden_size = 32
     sequence_length = 21
     # Create a small BertEncoder for testing.
     test_network = roformer_encoder.RoformerEncoder(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network([word_ids, mask, type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     self.assertIsInstance(test_network.transformer_layers, list)
     self.assertLen(test_network.transformer_layers, 3)
-    self.assertIsInstance(test_network.pooler_layer, tf.keras.layers.Dense)
+    self.assertIsInstance(test_network.pooler_layer, tf_keras.layers.Dense)
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
     self.assertAllEqual(expected_pooled_shape, pooled.shape.as_list())
 
     # The default output dtype is float32.
@@ -67,17 +63,17 @@
     # Create a small BertEncoder for testing.
     test_network = roformer_encoder.RoformerEncoder(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network([word_ids, mask, type_ids])
     all_encoder_outputs = dict_outputs["encoder_outputs"]
     pooled = dict_outputs["pooled_output"]
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertLen(all_encoder_outputs, 3)
@@ -88,25 +84,25 @@
     # The default output dtype is float32.
     self.assertAllEqual(tf.float32, all_encoder_outputs[-1].dtype)
     self.assertAllEqual(tf.float32, pooled.dtype)
 
   def test_network_creation_with_float16_dtype(self):
     hidden_size = 32
     sequence_length = 21
-    tf.keras.mixed_precision.set_global_policy("mixed_float16")
+    tf_keras.mixed_precision.set_global_policy("mixed_float16")
     # Create a small BertEncoder for testing.
     test_network = roformer_encoder.RoformerEncoder(
         vocab_size=100,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network([word_ids, mask, type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     expected_data_shape = [None, sequence_length, hidden_size]
     expected_pooled_shape = [None, hidden_size]
     self.assertAllEqual(expected_data_shape, data.shape.as_list())
@@ -131,23 +127,23 @@
         vocab_size=vocab_size,
         hidden_size=hidden_size,
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types,
         output_range=output_range)
     # Create the inputs (note that the first dimension is implicit).
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
     dict_outputs = test_network([word_ids, mask, type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
 
     # Create a model based off of this network:
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
 
     # Invoke the model. We can't validate the output data here (the model is too
     # complex) but this will catch structural runtime errors.
     batch_size = 3
     word_id_data = np.random.randint(
         vocab_size, size=(batch_size, sequence_length))
     mask_data = np.random.randint(2, size=(batch_size, sequence_length))
@@ -164,15 +160,15 @@
         max_sequence_length=max_sequence_length,
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types)
     dict_outputs = test_network([word_ids, mask, type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     outputs = model.predict([word_id_data, mask_data, type_id_data])
     self.assertEqual(outputs[0].shape[1], sequence_length)
 
     # Creates a BertEncoder with embedding_width != hidden_size
     test_network = roformer_encoder.RoformerEncoder(
         vocab_size=vocab_size,
         hidden_size=hidden_size,
@@ -180,15 +176,15 @@
         num_attention_heads=2,
         num_layers=3,
         type_vocab_size=num_types,
         embedding_width=16)
     dict_outputs = test_network([word_ids, mask, type_ids])
     data = dict_outputs["sequence_output"]
     pooled = dict_outputs["pooled_output"]
-    model = tf.keras.Model([word_ids, mask, type_ids], [data, pooled])
+    model = tf_keras.Model([word_ids, mask, type_ids], [data, pooled])
     outputs = model.predict([word_id_data, mask_data, type_id_data])
     self.assertEqual(outputs[0].shape[-1], hidden_size)
     self.assertTrue(hasattr(test_network, "_embedding_projection"))
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     kwargs = dict(
@@ -205,30 +201,30 @@
         initializer="glorot_uniform",
         output_range=-1,
         embedding_width=16,
         embedding_layer=None,
         norm_first=False)
     network = roformer_encoder.RoformerEncoder(**kwargs)
     expected_config = dict(kwargs)
-    expected_config["inner_activation"] = tf.keras.activations.serialize(
-        tf.keras.activations.get(expected_config["inner_activation"]))
-    expected_config["initializer"] = tf.keras.initializers.serialize(
-        tf.keras.initializers.get(expected_config["initializer"]))
+    expected_config["inner_activation"] = tf_keras.activations.serialize(
+        tf_keras.activations.get(expected_config["inner_activation"]))
+    expected_config["initializer"] = tf_keras.initializers.serialize(
+        tf_keras.initializers.get(expected_config["initializer"]))
     self.assertEqual(network.get_config(), expected_config)
     # Create another network object from the first object's config.
     new_network = roformer_encoder.RoformerEncoder.from_config(
         network.get_config())
 
     # Validate that the config can be forced to JSON.
     _ = network.to_json()
 
     # If the serialization was successful, the new config should match the old.
     self.assertAllEqual(network.get_config(), new_network.get_config())
 
     # Tests model saving/loading.
     model_path = self.get_temp_dir() + "/model"
     network.save(model_path)
-    _ = tf.keras.models.load_model(model_path)
+    _ = tf_keras.models.load_model(model_path)
 
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/roformer_experiments.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/roformer_experiments.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/roformer/train.py` & `tf-models-no-deps-2.16.0/official/projects/qat/nlp/train.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,34 +1,35 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""A customized training library for the specific task."""
+"""TFM common training driver."""
 
 from absl import app
 from absl import flags
 import gin
 
 from official.common import distribute_utils
+from official.common import registry_imports  # pylint: disable=unused-import
 from official.common import flags as tfm_flags
 from official.core import task_factory
 from official.core import train_lib
 from official.core import train_utils
 from official.modeling import performance
-from official.projects.roformer import roformer_experiments  # pylint: disable=unused-import
+from official.projects.qat.nlp import registry_imports as qat_registry_imports  # pylint: disable=unused-import
 
 FLAGS = flags.FLAGS
 
 
 def main(_):
   gin.parse_config_files_and_bindings(FLAGS.gin_file, FLAGS.gin_params)
   params = train_utils.parse_configuration(FLAGS)
@@ -46,24 +47,22 @@
     performance.set_mixed_precision_policy(params.runtime.mixed_precision_dtype)
   distribution_strategy = distribute_utils.get_distribution_strategy(
       distribution_strategy=params.runtime.distribution_strategy,
       all_reduce_alg=params.runtime.all_reduce_alg,
       num_gpus=params.runtime.num_gpus,
       tpu_address=params.runtime.tpu,
       **params.runtime.model_parallelism())
-
   with distribution_strategy.scope():
     task = task_factory.get_task(params.task, logging_dir=model_dir)
 
   train_lib.run_experiment(
       distribution_strategy=distribution_strategy,
       task=task,
       mode=FLAGS.mode,
       params=params,
       model_dir=model_dir)
 
   train_utils.save_gin_config(FLAGS.mode, model_dir)
 
-
 if __name__ == '__main__':
   tfm_flags.define_flags()
   app.run(main)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/teams/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/panoptic/tasks/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/teams/teams.py` & `tf-models-no-deps-2.16.0/official/projects/teams/teams.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """TEAMS model configurations and instantiation methods."""
 import dataclasses
 
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.modeling.hyperparams import base_config
 from official.nlp.configs import encoders
 from official.nlp.modeling import layers
 from official.nlp.modeling import networks
 
@@ -39,16 +39,20 @@
   # Whether share embedding network between generator and discriminator.
   tie_embeddings: bool = True
   # Number of bottom layers shared between generator and discriminator.
   # Non-positive value implies no sharing.
   num_shared_generator_hidden_layers: int = 3
   # Number of bottom layers shared between different discriminator tasks.
   num_discriminator_task_agnostic_layers: int = 11
-  generator: encoders.BertEncoderConfig = encoders.BertEncoderConfig()
-  discriminator: encoders.BertEncoderConfig = encoders.BertEncoderConfig()
+  generator: encoders.BertEncoderConfig = dataclasses.field(
+      default_factory=encoders.BertEncoderConfig
+  )
+  discriminator: encoders.BertEncoderConfig = dataclasses.field(
+      default_factory=encoders.BertEncoderConfig
+  )
 
 
 class TeamsEncoderConfig(encoders.BertEncoderConfig):
   pass
 
 
 @gin.configurable
@@ -68,38 +72,38 @@
   """
   embedding_cfg = dict(
       vocab_size=bert_config.vocab_size,
       type_vocab_size=bert_config.type_vocab_size,
       hidden_size=bert_config.hidden_size,
       embedding_width=bert_config.embedding_size,
       max_seq_length=bert_config.max_position_embeddings,
-      initializer=tf.keras.initializers.TruncatedNormal(
+      initializer=tf_keras.initializers.TruncatedNormal(
           stddev=bert_config.initializer_range),
       dropout_rate=bert_config.dropout_rate,
   )
   hidden_cfg = dict(
       num_attention_heads=bert_config.num_attention_heads,
       intermediate_size=bert_config.intermediate_size,
       intermediate_activation=tf_utils.get_activation(
           bert_config.hidden_activation),
       dropout_rate=bert_config.dropout_rate,
       attention_dropout_rate=bert_config.attention_dropout_rate,
-      kernel_initializer=tf.keras.initializers.TruncatedNormal(
+      kernel_initializer=tf_keras.initializers.TruncatedNormal(
           stddev=bert_config.initializer_range),
   )
   if embedding_network is None:
     embedding_network = networks.PackedSequenceEmbedding
   if hidden_layers is None:
     hidden_layers = layers.Transformer
   kwargs = dict(
       embedding_cfg=embedding_cfg,
       embedding_cls=embedding_network,
       hidden_cls=hidden_layers,
       hidden_cfg=hidden_cfg,
       num_hidden_instances=bert_config.num_layers,
       pooled_output_dim=bert_config.hidden_size,
-      pooler_layer_initializer=tf.keras.initializers.TruncatedNormal(
+      pooler_layer_initializer=tf_keras.initializers.TruncatedNormal(
           stddev=bert_config.initializer_range),
       dict_outputs=True)
 
   # Relies on gin configuration to define the Transformer encoder arguments.
   return networks.EncoderScaffold(**kwargs)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/teams/teams_experiments.py` & `tf-models-no-deps-2.16.0/official/projects/teams/teams_experiments.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/teams/teams_pretrainer.py` & `tf-models-no-deps-2.16.0/official/projects/teams/teams_pretrainer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,24 +11,24 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Trainer network for TEAMS models."""
 # pylint: disable=g-classes-have-attributes
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.modeling import layers
 from official.nlp.modeling import models
 
 _LOGIT_PENALTY_MULTIPLIER = 10000
 
 
-class ReplacedTokenDetectionHead(tf.keras.layers.Layer):
+class ReplacedTokenDetectionHead(tf_keras.layers.Layer):
   """Replaced token detection discriminator head.
 
   Arguments:
     encoder_cfg: Encoder config, used to create hidden layers and head.
     num_task_agnostic_layers: Number of task agnostic layers in the
       discriminator.
     output: The output style for this network. Can be either 'logits' or
@@ -56,20 +56,20 @@
               num_attention_heads=self.hidden_cfg['num_attention_heads'],
               intermediate_size=self.hidden_cfg['intermediate_size'],
               intermediate_activation=self.activation,
               dropout_rate=self.hidden_cfg['dropout_rate'],
               attention_dropout_rate=self.hidden_cfg['attention_dropout_rate'],
               kernel_initializer=tf_utils.clone_initializer(self.initializer),
               name='transformer/layer_%d_rtd' % i))
-    self.dense = tf.keras.layers.Dense(
+    self.dense = tf_keras.layers.Dense(
         self.hidden_size,
         activation=self.activation,
         kernel_initializer=tf_utils.clone_initializer(self.initializer),
         name='transform/rtd_dense')
-    self.rtd_head = tf.keras.layers.Dense(
+    self.rtd_head = tf_keras.layers.Dense(
         units=1,
         kernel_initializer=tf_utils.clone_initializer(self.initializer),
         name='transform/rtd_head')
 
     if output not in ('predictions', 'logits'):
       raise ValueError(
           ('Unknown `output` value "%s". `output` can be either "logits" or '
@@ -91,15 +91,15 @@
     data = sequence_data
     for hidden_layer in self.hidden_layers:
       data = hidden_layer([sequence_data, attention_mask])
     rtd_logits = self.rtd_head(self.dense(data))
     return tf.squeeze(rtd_logits, axis=-1)
 
 
-class MultiWordSelectionHead(tf.keras.layers.Layer):
+class MultiWordSelectionHead(tf_keras.layers.Layer):
   """Multi-word selection discriminator head.
 
   Arguments:
     embedding_table: The embedding table.
     activation: The activation, if any, for the dense layer.
     initializer: The intializer for the dense layer. Defaults to a Glorot
       uniform initializer.
@@ -113,23 +113,23 @@
                initializer='glorot_uniform',
                output='logits',
                name='mws',
                **kwargs):
     super(MultiWordSelectionHead, self).__init__(name=name, **kwargs)
     self.embedding_table = embedding_table
     self.activation = activation
-    self.initializer = tf.keras.initializers.get(initializer)
+    self.initializer = tf_keras.initializers.get(initializer)
 
     self._vocab_size, self.embed_size = self.embedding_table.shape
-    self.dense = tf.keras.layers.Dense(
+    self.dense = tf_keras.layers.Dense(
         self.embed_size,
         activation=self.activation,
         kernel_initializer=self.initializer,
         name='transform/mws_dense')
-    self.layer_norm = tf.keras.layers.LayerNormalization(
+    self.layer_norm = tf_keras.layers.LayerNormalization(
         axis=-1, epsilon=1e-12, name='transform/mws_layernorm')
 
     if output not in ('predictions', 'logits'):
       raise ValueError(
           ('Unknown `output` value "%s". `output` can be either "logits" or '
            '"predictions"') % output)
     self._output_type = output
@@ -198,16 +198,16 @@
     flat_sequence_tensor = tf.reshape(sequence_tensor,
                                       [batch_size * seq_length, width])
     output_tensor = tf.gather(flat_sequence_tensor, flat_positions)
 
     return output_tensor
 
 
-@tf.keras.utils.register_keras_serializable(package='Text')
-class TeamsPretrainer(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Text')
+class TeamsPretrainer(tf_keras.Model):
   """TEAMS network training model.
 
   This is an implementation of the network structure described in "Training
   ELECTRA Augmented with Multi-word Selection"
   (https://arxiv.org/abs/2106.00139).
 
   The TeamsPretrainer allows a user to pass in two transformer encoders, one
@@ -295,15 +295,15 @@
         embedding_table=self.discriminator_mws_network.embedding_network
         .get_embedding_table(),
         activation=hidden_cfg['intermediate_activation'],
         initializer=hidden_cfg['kernel_initializer'],
         output=output_type,
         name='discriminator_mws')
 
-  def call(self, inputs):
+  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     """TEAMS forward pass.
 
     Args:
       inputs: A dict of all inputs, same as the standard BERT model.
 
     Returns:
       outputs: A dict of pretrainer model outputs, including
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/teams/teams_pretrainer_test.py` & `tf-models-no-deps-2.16.0/official/projects/teams/teams_pretrainer_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,39 +10,35 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for TEAMS pre trainer network."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import activations
 from official.nlp.modeling.networks import encoder_scaffold
 from official.nlp.modeling.networks import packed_sequence_embedding
 from official.projects.teams import teams_pretrainer
 
 
-# This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
-# guarantees forward compatibility of this code for the V2 switchover.
-@keras_parameterized.run_all_keras_modes
-class TeamsPretrainerTest(keras_parameterized.TestCase):
+class TeamsPretrainerTest(tf.test.TestCase):
 
   # Build a transformer network to use within the TEAMS trainer.
   def _get_network(self, vocab_size):
     sequence_length = 512
     hidden_size = 50
     embedding_cfg = {
         'vocab_size': vocab_size,
         'type_vocab_size': 1,
         'hidden_size': hidden_size,
         'embedding_width': hidden_size,
         'max_seq_length': sequence_length,
-        'initializer': tf.keras.initializers.TruncatedNormal(stddev=0.02),
+        'initializer': tf_keras.initializers.TruncatedNormal(stddev=0.02),
         'dropout_rate': 0.1,
     }
     embedding_inst = packed_sequence_embedding.PackedSequenceEmbedding(
         **embedding_cfg)
     hidden_cfg = {
         'num_attention_heads':
             2,
@@ -51,15 +47,15 @@
         'intermediate_activation':
             activations.gelu,
         'dropout_rate':
             0.1,
         'attention_dropout_rate':
             0.1,
         'kernel_initializer':
-            tf.keras.initializers.TruncatedNormal(stddev=0.02),
+            tf_keras.initializers.TruncatedNormal(stddev=0.02),
     }
     return encoder_scaffold.EncoderScaffold(
         num_hidden_instances=2,
         pooled_output_dim=hidden_size,
         embedding_cfg=embedding_cfg,
         embedding_cls=embedding_inst,
         hidden_cfg=hidden_cfg,
@@ -79,20 +75,20 @@
         num_discriminator_task_agnostic_layers=1,
         vocab_size=vocab_size,
         candidate_size=candidate_size)
 
     # Create a set of 2-dimensional inputs (the first dimension is implicit).
     num_token_predictions = 2
     sequence_length = 128
-    word_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    mask = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    type_ids = tf.keras.Input(shape=(sequence_length,), dtype=tf.int32)
-    lm_positions = tf.keras.Input(
+    word_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    mask = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    type_ids = tf_keras.Input(shape=(sequence_length,), dtype=tf.int32)
+    lm_positions = tf_keras.Input(
         shape=(num_token_predictions,), dtype=tf.int32)
-    lm_ids = tf.keras.Input(shape=(num_token_predictions,), dtype=tf.int32)
+    lm_ids = tf_keras.Input(shape=(num_token_predictions,), dtype=tf.int32)
     inputs = {
         'input_word_ids': word_ids,
         'input_mask': mask,
         'input_type_ids': type_ids,
         'masked_lm_positions': lm_positions,
         'masked_lm_ids': lm_ids
     }
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/teams/teams_task.py` & `tf-models-no-deps-2.16.0/official/projects/teams/teams_task.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,32 +11,36 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """TEAMS pretraining task (Joint Masked LM, Replaced Token Detection and )."""
 
 import dataclasses
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import task_factory
 from official.modeling import tf_utils
 from official.nlp.data import pretrain_dataloader
 from official.nlp.modeling import layers
 from official.projects.teams import teams
 from official.projects.teams import teams_pretrainer
 
 
 @dataclasses.dataclass
 class TeamsPretrainTaskConfig(cfg.TaskConfig):
   """The model config."""
-  model: teams.TeamsPretrainerConfig = teams.TeamsPretrainerConfig()
-  train_data: cfg.DataConfig = cfg.DataConfig()
-  validation_data: cfg.DataConfig = cfg.DataConfig()
+  model: teams.TeamsPretrainerConfig = dataclasses.field(
+      default_factory=teams.TeamsPretrainerConfig
+  )
+  train_data: cfg.DataConfig = dataclasses.field(default_factory=cfg.DataConfig)
+  validation_data: cfg.DataConfig = dataclasses.field(
+      default_factory=cfg.DataConfig
+  )
 
 
 def _get_generator_hidden_layers(discriminator_network, num_hidden_layers,
                                  num_shared_layers):
   if num_shared_layers <= 0:
     num_shared_layers = 0
     hidden_layers = []
@@ -71,15 +75,15 @@
       discriminator_mws_network=discriminator_network,
       num_discriminator_task_agnostic_layers=config
       .num_discriminator_task_agnostic_layers,
       vocab_size=generator_encoder_cfg.vocab_size,
       candidate_size=config.candidate_size,
       mlm_activation=tf_utils.get_activation(
           generator_encoder_cfg.hidden_activation),
-      mlm_initializer=tf.keras.initializers.TruncatedNormal(
+      mlm_initializer=tf_keras.initializers.TruncatedNormal(
           stddev=generator_encoder_cfg.initializer_range))
 
 
 @task_factory.register_task_cls(TeamsPretrainTaskConfig)
 class TeamsPretrainTask(base_task.Task):
   """TEAMS Pretrain Task (Masked LM + RTD + MWS)."""
 
@@ -91,15 +95,15 @@
                    model_outputs,
                    metrics,
                    aux_losses=None) -> tf.Tensor:
     with tf.name_scope('TeamsPretrainTask/losses'):
       metrics = dict([(metric.name, metric) for metric in metrics])
 
       # Generator MLM loss.
-      lm_prediction_losses = tf.keras.losses.sparse_categorical_crossentropy(
+      lm_prediction_losses = tf_keras.losses.sparse_categorical_crossentropy(
           labels['masked_lm_ids'],
           tf.cast(model_outputs['lm_outputs'], tf.float32),
           from_logits=True)
       lm_label_weights = labels['masked_lm_weights']
       lm_numerator_loss = tf.reduce_sum(lm_prediction_losses * lm_label_weights)
       lm_denominator_loss = tf.reduce_sum(lm_label_weights)
       mlm_loss = tf.math.divide_no_nan(lm_numerator_loss, lm_denominator_loss)
@@ -119,15 +123,15 @@
       metrics['replaced_token_detection_loss'].update_state(rtd_loss)
       weight = self.task_config.model.discriminator_rtd_loss_weight
       total_loss = total_loss + weight * rtd_loss
 
       # Discriminator MWS loss.
       mws_logits = model_outputs['disc_mws_logits']
       mws_labels = model_outputs['disc_mws_label']
-      mws_loss = tf.keras.losses.sparse_categorical_crossentropy(
+      mws_loss = tf_keras.losses.sparse_categorical_crossentropy(
           mws_labels, mws_logits, from_logits=True)
       mws_numerator_loss = tf.reduce_sum(mws_loss * lm_label_weights)
       mws_denominator_loss = tf.reduce_sum(lm_label_weights)
       mws_loss = tf.math.divide_no_nan(mws_numerator_loss, mws_denominator_loss)
       metrics['multiword_selection_loss'].update_state(mws_loss)
       weight = self.task_config.model.discriminator_mws_loss_weight
       total_loss = total_loss + weight * mws_loss
@@ -161,23 +165,23 @@
 
     return pretrain_dataloader.BertPretrainDataLoader(params).load(
         input_context)
 
   def build_metrics(self, training=None):
     del training
     metrics = [
-        tf.keras.metrics.SparseCategoricalAccuracy(name='masked_lm_accuracy'),
-        tf.keras.metrics.Mean(name='masked_lm_loss'),
-        tf.keras.metrics.SparseCategoricalAccuracy(
+        tf_keras.metrics.SparseCategoricalAccuracy(name='masked_lm_accuracy'),
+        tf_keras.metrics.Mean(name='masked_lm_loss'),
+        tf_keras.metrics.SparseCategoricalAccuracy(
             name='replaced_token_detection_accuracy'),
-        tf.keras.metrics.Mean(name='replaced_token_detection_loss'),
-        tf.keras.metrics.SparseCategoricalAccuracy(
+        tf_keras.metrics.Mean(name='replaced_token_detection_loss'),
+        tf_keras.metrics.SparseCategoricalAccuracy(
             name='multiword_selection_accuracy'),
-        tf.keras.metrics.Mean(name='multiword_selection_loss'),
-        tf.keras.metrics.Mean(name='total_loss'),
+        tf_keras.metrics.Mean(name='multiword_selection_loss'),
+        tf_keras.metrics.Mean(name='total_loss'),
     ]
     return metrics
 
   def process_metrics(self, metrics, labels, model_outputs):
     with tf.name_scope('TeamsPretrainTask/process_metrics'):
       metrics = dict([(metric.name, metric) for metric in metrics])
       if 'masked_lm_accuracy' in metrics:
@@ -195,16 +199,16 @@
             labels['input_mask'])
 
       if 'multiword_selection_accuracy' in metrics:
         metrics['multiword_selection_accuracy'].update_state(
             model_outputs['disc_mws_label'], model_outputs['disc_mws_logits'],
             labels['masked_lm_weights'])
 
-  def train_step(self, inputs, model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer, metrics):
+  def train_step(self, inputs, model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer, metrics):
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
       metrics: a nested structure of metrics objects.
@@ -225,15 +229,15 @@
       scaled_loss = loss / tf.distribute.get_strategy().num_replicas_in_sync
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     optimizer.apply_gradients(list(zip(grads, tvars)))
     self.process_metrics(metrics, inputs, outputs)
     return {self.loss: loss}
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics):
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/teams/teams_task_test.py` & `tf-models-no-deps-2.16.0/official/projects/teams/teams_task_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for teams_task."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.nlp.configs import encoders
 from official.nlp.data import pretrain_dataloader
 from official.projects.teams import teams
 from official.projects.teams import teams_task
 
 
@@ -44,13 +44,13 @@
             global_batch_size=1))
     task = teams_task.TeamsPretrainTask(config)
     model = task.build_model()
     metrics = task.build_metrics()
     dataset = task.build_inputs(config.train_data)
 
     iterator = iter(dataset)
-    optimizer = tf.keras.optimizers.SGD(lr=0.1)
+    optimizer = tf_keras.optimizers.SGD(lr=0.1)
     task.train_step(next(iterator), model, optimizer, metrics=metrics)
     task.validation_step(next(iterator), model, metrics=metrics)
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/teams/train.py` & `tf-models-no-deps-2.16.0/official/projects/teams/train.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/dataset.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/dataset.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 import functools
 import json
 import os
 
 from absl import logging
 import apache_beam as beam
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets.public_api as tfds
 
 from official.projects.triviaqa import preprocess
 
 _CITATION = """
 @article{2017arXivtriviaqa,
        author = {{Joshi}, Mandar and {Choi}, Eunsol and {Weld},
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/download_and_prepare.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/download_and_prepare.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/evaluate.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/evaluate.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Evalutes TriviaQA predictions."""
 import json
 
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.triviaqa import evaluation
 
 flags.DEFINE_string('gold_path', None,
                     'Path to golden validation, i.e. wikipedia-dev.json.')
 
 flags.DEFINE_string('predictions_path', None,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/evaluation.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/evaluation.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/inputs.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/inputs.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Input processing for TriviaQA."""
 import os
 from typing import Optional, Text, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 from official.modeling import tf_utils
 from official.projects.triviaqa import dataset  # pylint: disable=unused-import
 
 
 def _flatten_dims(tensor: tf.Tensor,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/modeling.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/modeling.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,49 +1,49 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Modeling for TriviaQA."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp.configs import encoders
 
 
-class TriviaQaHead(tf.keras.layers.Layer):
+class TriviaQaHead(tf_keras.layers.Layer):
   """Computes logits given token and global embeddings."""
 
   def __init__(self,
                intermediate_size,
                intermediate_activation=tf_utils.get_activation('gelu'),
                dropout_rate=0.0,
                attention_dropout_rate=0.0,
                **kwargs):
     super(TriviaQaHead, self).__init__(**kwargs)
-    self._attention_dropout = tf.keras.layers.Dropout(attention_dropout_rate)
-    self._intermediate_dense = tf.keras.layers.Dense(intermediate_size)
-    self._intermediate_activation = tf.keras.layers.Activation(
+    self._attention_dropout = tf_keras.layers.Dropout(attention_dropout_rate)
+    self._intermediate_dense = tf_keras.layers.Dense(intermediate_size)
+    self._intermediate_activation = tf_keras.layers.Activation(
         intermediate_activation)
-    self._output_dropout = tf.keras.layers.Dropout(dropout_rate)
-    self._output_layer_norm = tf.keras.layers.LayerNormalization()
-    self._logits_dense = tf.keras.layers.Dense(2)
+    self._output_dropout = tf_keras.layers.Dropout(dropout_rate)
+    self._output_layer_norm = tf_keras.layers.LayerNormalization()
+    self._logits_dense = tf_keras.layers.Dense(2)
 
   def build(self, input_shape):
     output_shape = input_shape['token_embeddings'][-1]
-    self._output_dense = tf.keras.layers.Dense(output_shape)
+    self._output_dense = tf_keras.layers.Dense(output_shape)
     super(TriviaQaHead, self).build(input_shape)
 
   def call(self, inputs, training=None):
     token_embeddings = inputs['token_embeddings']
     token_ids = inputs['token_ids']
     question_lengths = inputs['question_lengths']
     x = self._attention_dropout(token_embeddings, training=training)
@@ -55,22 +55,22 @@
     logits = self._logits_dense(outputs)
     logits -= tf.expand_dims(
         tf.cast(tf.equal(token_ids, 0), tf.float32) + tf.sequence_mask(
             question_lengths, logits.shape[-2], dtype=tf.float32), -1) * 1e6
     return logits
 
 
-class TriviaQaModel(tf.keras.Model):
+class TriviaQaModel(tf_keras.Model):
   """Model for TriviaQA."""
 
   def __init__(self, model_config: encoders.EncoderConfig, sequence_length: int,
                **kwargs):
     inputs = dict(
-        token_ids=tf.keras.Input((sequence_length,), dtype=tf.int32),
-        question_lengths=tf.keras.Input((), dtype=tf.int32))
+        token_ids=tf_keras.Input((sequence_length,), dtype=tf.int32),
+        question_lengths=tf_keras.Input((), dtype=tf.int32))
     encoder = encoders.build_encoder(model_config)
     x = encoder(
         dict(
             input_word_ids=inputs['token_ids'],
             input_mask=tf.cast(inputs['token_ids'] > 0, tf.int32),
             input_type_ids=1 -
             tf.sequence_mask(inputs['question_lengths'], sequence_length,
@@ -87,15 +87,15 @@
     self._encoder = encoder
 
   @property
   def encoder(self):
     return self._encoder
 
 
-class SpanOrCrossEntropyLoss(tf.keras.losses.Loss):
+class SpanOrCrossEntropyLoss(tf_keras.losses.Loss):
   """Cross entropy loss for multiple correct answers.
 
   See https://arxiv.org/abs/1710.10723.
   """
 
   def call(self, y_true, y_pred):
     y_pred_masked = y_pred - tf.cast(y_true < 0.5, tf.float32) * 1e6
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/predict.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/predict.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -18,15 +18,15 @@
 import functools
 import json
 import operator
 
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 import sentencepiece as spm
 from official.nlp.configs import encoders  # pylint: disable=unused-import
 from official.projects.triviaqa import evaluation
 from official.projects.triviaqa import inputs
 from official.projects.triviaqa import prediction
@@ -151,15 +151,15 @@
   # Initialize datasets.
   with worker_context():
     _ = tf.random.get_global_generator()
     dataset = inputs.read_batches(
         FLAGS.data_dir, FLAGS.split, FLAGS.batch_size, include_answers=False)
   # Initialize model and compile.
   with strategy.scope():
-    model = tf.keras.models.load_model(FLAGS.saved_model_dir, compile=False)
+    model = tf_keras.models.load_model(FLAGS.saved_model_dir, compile=False)
   logging.info('Model initialized. Beginning prediction loop.')
   logits_fn = tf.function(
       functools.partial(prediction.distributed_logits_fn, model))
   decode_logits_fn = tf.function(
       functools.partial(prediction.decode_logits, FLAGS.decode_top_k,
                         FLAGS.decode_max_size))
   split_and_pad_fn = tf.function(
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/prediction.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/prediction.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Functions for inference."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def split_and_pad(strategy, batch_size, x):
   """Split and pad for interence."""
   per_replica_size = batch_size // strategy.num_replicas_in_sync
 
   def slice_fn(x, i):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/preprocess.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/preprocess.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/sentencepiece_pb2.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/sentencepiece_pb2.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/triviaqa/train.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/train.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,15 +20,15 @@
 import operator
 import os
 
 from absl import app
 from absl import flags
 from absl import logging
 import gin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 import sentencepiece as spm
 from official.nlp import optimization as nlp_optimization
 from official.nlp.configs import encoders
 from official.projects.triviaqa import evaluation
 from official.projects.triviaqa import inputs
@@ -176,15 +176,15 @@
       weight_decay_rate=weight_decay_rate,
       dropout_rate=FLAGS.dropout_rate,
       attention_dropout_rate=FLAGS.attention_dropout_rate,
       label_smoothing=FLAGS.label_smoothing)
   logging.info(hparams)
   learning_rate_schedule = nlp_optimization.WarmUp(
       learning_rate,
-      tf.keras.optimizers.schedules.PolynomialDecay(
+      tf_keras.optimizers.schedules.PolynomialDecay(
           learning_rate,
           num_decay_steps,
           end_learning_rate=0.,
           power=learning_rate_polynomial_decay_rate), num_warmup_steps)
   with strategy.scope():
     optimizer = nlp_optimization.AdamWeightDecay(
         learning_rate_schedule,
@@ -209,15 +209,15 @@
     val_summary_writer = tf.summary.create_file_writer(
         os.path.join(model_dir, 'val'))
     best_exact_match = 0.
     for epoch in range(len(ckpt_manager.checkpoints), num_epochs):
       model.fit(
           train_dataset,
           callbacks=[
-              tf.keras.callbacks.TensorBoard(model_dir, write_graph=False),
+              tf_keras.callbacks.TensorBoard(model_dir, write_graph=False),
           ])
       ckpt_path = ckpt_manager.save()
       if evaluate_fn is None:
         continue
       metrics = evaluate_fn()
       logging.info('Epoch %d: %s', epoch + 1, metrics)
       if best_exact_match < metrics['exact_match']:
@@ -229,20 +229,20 @@
           tf.summary.scalar(name, data, epoch + 1)
 
 
 def evaluate(sp_processor, features_map_fn, labels_map_fn, logits_fn,
              decode_logits_fn, split_and_pad_fn, distribute_strategy,
              validation_dataset, ground_truth):
   """Run evaluation."""
-  loss_metric = tf.keras.metrics.Mean()
+  loss_metric = tf_keras.metrics.Mean()
 
   @tf.function
   def update_loss(y, logits):
     loss_fn = modeling.SpanOrCrossEntropyLoss(
-        reduction=tf.keras.losses.Reduction.NONE)
+        reduction=tf_keras.losses.Reduction.NONE)
     return loss_metric(loss_fn(y, logits))
 
   predictions = collections.defaultdict(list)
   for _, (features, labels) in validation_dataset.enumerate():
     token_ids = features['token_ids']
     y = labels_map_fn(token_ids, labels)
     x = split_and_pad_fn(features_map_fn(features))
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/nlp/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/common/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/common/registry_imports.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/common/registry_imports.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,20 +17,24 @@
 # pylint: disable=unused-import
 # pylint: disable=g-bad-import-order
 from official.vision import registry_imports
 
 # import configs
 from official.projects.yolo.configs import darknet_classification
 from official.projects.yolo.configs import yolo as yolo_config
+from official.projects.yolo.configs import yolov7 as yolov7_config
 
 # import modeling components
 from official.projects.yolo.modeling.backbones import darknet
 from official.projects.yolo.modeling.decoders import yolo_decoder
+from official.projects.yolo.modeling.backbones import yolov7 as yolov7_backbone
+from official.projects.yolo.modeling.decoders import yolov7 as yolov7_decoder
 
 # import tasks
 from official.projects.yolo.tasks import image_classification
 from official.projects.yolo.tasks import yolo as yolo_task
+from official.projects.yolo.tasks import yolov7 as yolov7_task
 
 # import optimization packages
 from official.projects.yolo.optimization import optimizer_factory
 from official.projects.yolo.optimization.configs import optimizer_config
 from official.projects.yolo.optimization.configs import optimization_config
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/layers/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/configs/backbones.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/configs/backbones.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -28,9 +28,17 @@
   min_level: int = 3
   max_level: int = 5
   use_separable_conv: bool = False
   use_reorg_input: bool = False
 
 
 @dataclasses.dataclass
+class YoloV7(hyperparams.Config):
+  model_id: str = 'yolov7'
+  min_level: int = 3
+  max_level: int = 5
+
+
+@dataclasses.dataclass
 class Backbone(backbones.Backbone):
-  darknet: Darknet = Darknet()
+  darknet: Darknet = dataclasses.field(default_factory=Darknet)
+  yolov7: YoloV7 = dataclasses.field(default_factory=YoloV7)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/configs/darknet_classification.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/configs/darknet_classification.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,55 +16,88 @@
 
 import dataclasses
 from typing import List, Optional
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling import hyperparams
+from official.modeling import optimization
 from official.projects.yolo.configs import backbones
 from official.vision.configs import common
 from official.vision.configs import image_classification as imc
 
 
 @dataclasses.dataclass
 class ImageClassificationModel(hyperparams.Config):
   """Image classification model config."""
   num_classes: int = 0
   input_size: List[int] = dataclasses.field(default_factory=lambda: [224, 224])
-  backbone: backbones.Backbone = backbones.Backbone(
-      type='darknet', darknet=backbones.Darknet())
+  backbone: backbones.Backbone = dataclasses.field(
+      # pylint: disable=g-long-lambda
+      default_factory=lambda: backbones.Backbone(
+          type='darknet', darknet=backbones.Darknet()
+      )
+      # pylint: enable=g-long-lambda
+  )
   dropout_rate: float = 0.0
-  norm_activation: common.NormActivation = common.NormActivation()
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=common.NormActivation
+  )
   # Adds a Batch Normalization layer pre-GlobalAveragePooling in classification.
   add_head_batch_norm: bool = False
   kernel_initializer: str = 'VarianceScaling'
 
 
 @dataclasses.dataclass
 class Losses(hyperparams.Config):
   one_hot: bool = True
   label_smoothing: float = 0.0
   l2_weight_decay: float = 0.0
+  loss_weight: float = 1.0
+  soft_labels: bool = False
+  use_binary_cross_entropy: bool = False
 
 
 @dataclasses.dataclass
 class ImageClassificationTask(cfg.TaskConfig):
   """The model config."""
-  model: ImageClassificationModel = ImageClassificationModel()
-  train_data: imc.DataConfig = imc.DataConfig(is_training=True)
-  validation_data: imc.DataConfig = imc.DataConfig(is_training=False)
-  evaluation: imc.Evaluation = imc.Evaluation()
-  losses: Losses = Losses()
+  model: ImageClassificationModel = dataclasses.field(
+      default_factory=ImageClassificationModel
+  )
+  train_data: imc.DataConfig = dataclasses.field(
+      default_factory=lambda: imc.DataConfig(is_training=True)
+  )
+  validation_data: imc.DataConfig = dataclasses.field(
+      default_factory=lambda: imc.DataConfig(is_training=False)
+  )
+  evaluation: imc.Evaluation = dataclasses.field(default_factory=imc.Evaluation)
+  losses: Losses = dataclasses.field(default_factory=Losses)
   gradient_clip_norm: float = 0.0
   logging_dir: Optional[str] = None
+  freeze_backbone: bool = False
 
 
 @exp_factory.register_config_factory('darknet_classification')
 def darknet_classification() -> cfg.ExperimentConfig:
   """Image classification general."""
   return cfg.ExperimentConfig(
       task=ImageClassificationTask(),
-      trainer=cfg.TrainerConfig(),
+      trainer=cfg.TrainerConfig(
+          optimizer_config=optimization.OptimizationConfig({
+              'optimizer': {'type': 'sgd', 'sgd': {'momentum': 0.9}},
+              'learning_rate': {
+                  'type': 'polynomial',
+                  'initial_learning_rate': 0.1,
+              },
+              'warmup': {
+                  'type': 'linear',
+                  'linear': {
+                      'warmup_learning_rate': 0,
+                  },
+              },
+          })
+      ),
       restrictions=[
           'task.train_data.is_training != None',
-          'task.validation_data.is_training != None'
-      ])
+          'task.validation_data.is_training != None',
+      ],
+  )
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/configs/decoders.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/configs/decoders.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -39,10 +39,17 @@
   path_process_len: Optional[int] = None
   max_level_process_len: Optional[int] = None
   embed_spp: Optional[bool] = None
   activation: Optional[str] = 'same'
 
 
 @dataclasses.dataclass
+class YoloV7(hyperparams.Config):
+  model_id: str = 'yolov7'
+  use_separable_conv: bool = False
+
+
+@dataclasses.dataclass
 class Decoder(decoders.Decoder):
   type: Optional[str] = 'yolo_decoder'
-  yolo_decoder: YoloDecoder = YoloDecoder()
+  yolo_decoder: YoloDecoder = dataclasses.field(default_factory=YoloDecoder)
+  yolov7: YoloV7 = dataclasses.field(default_factory=YoloV7)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/configs/yolo.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/configs/yolo.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -72,23 +72,29 @@
   regenerate_source_id: bool = False
   label_map: str = ''
 
 
 @dataclasses.dataclass
 class DataDecoder(hyperparams.OneOfConfig):
   type: Optional[str] = 'simple_decoder'
-  simple_decoder: TfExampleDecoder = TfExampleDecoder()
-  label_map_decoder: TfExampleDecoderLabelMap = TfExampleDecoderLabelMap()
+  simple_decoder: TfExampleDecoder = dataclasses.field(
+      default_factory=TfExampleDecoder
+  )
+  label_map_decoder: TfExampleDecoderLabelMap = dataclasses.field(
+      default_factory=TfExampleDecoderLabelMap
+  )
 
 
 @dataclasses.dataclass
 class Mosaic(hyperparams.Config):
   mosaic_frequency: float = 0.0
+  mosaic9_frequency: float = 0.0
   mixup_frequency: float = 0.0
   mosaic_center: float = 0.2
+  mosaic9_center: float = 0.33
   mosaic_crop_mode: Optional[str] = None
   aug_scale_min: float = 1.0
   aug_scale_max: float = 1.0
   jitter: float = 0.0
 
 
 @dataclasses.dataclass
@@ -106,29 +112,28 @@
   aug_rand_angle: float = 0.0
   aug_rand_translate: float = 0.0
   aug_rand_perspective: float = 0.0
   use_tie_breaker: bool = True
   best_match_only: bool = False
   anchor_thresh: float = -0.01
   area_thresh: float = 0.1
-  mosaic: Mosaic = Mosaic()
+  mosaic: Mosaic = dataclasses.field(default_factory=Mosaic)
 
 
 @dataclasses.dataclass
 class DataConfig(cfg.DataConfig):
   """Input config for training."""
   global_batch_size: int = 64
   input_path: str = ''
   tfds_name: str = ''
   tfds_split: str = ''
-  global_batch_size: int = 1
   is_training: bool = True
   dtype: str = 'float16'
-  decoder: DataDecoder = DataDecoder()
-  parser: Parser = Parser()
+  decoder: DataDecoder = dataclasses.field(default_factory=DataDecoder)
+  parser: Parser = dataclasses.field(default_factory=Parser)
   shuffle_buffer_size: int = 10000
   tfds_download: bool = True
   cache: bool = False
   drop_remainder: bool = True
   file_type: str = 'tfrecord'
 
 
@@ -136,25 +141,29 @@
 class YoloHead(hyperparams.Config):
   """Parameterization for the YOLO Head."""
   smart_bias: bool = True
 
 
 @dataclasses.dataclass
 class YoloDetectionGenerator(hyperparams.Config):
+  apply_nms: bool = True
   box_type: FPNConfig = dataclasses.field(
       default_factory=_build_dict(MIN_LEVEL, MAX_LEVEL, 'original'))
   scale_xy: FPNConfig = dataclasses.field(
       default_factory=_build_dict(MIN_LEVEL, MAX_LEVEL, 1.0))
   path_scales: FPNConfig = dataclasses.field(
       default_factory=_build_path_scales(MIN_LEVEL, MAX_LEVEL))
-  nms_type: str = 'greedy'
+  # Choose from v1, v2, iou and greedy.
+  nms_version: str = 'greedy'
   iou_thresh: float = 0.001
   nms_thresh: float = 0.6
   max_boxes: int = 200
   pre_nms_points: int = 5000
+  # Only works when nms_version='v2'.
+  use_class_agnostic_nms: Optional[bool] = False
 
 
 @dataclasses.dataclass
 class YoloLoss(hyperparams.Config):
   ignore_thresh: FPNConfig = dataclasses.field(
       default_factory=_build_dict(MIN_LEVEL, MAX_LEVEL, 0.0))
   truth_thresh: FPNConfig = dataclasses.field(
@@ -174,15 +183,15 @@
   label_smoothing: float = 0.0
   use_scaled_loss: bool = True
   update_on_repeat: bool = True
 
 
 @dataclasses.dataclass
 class Box(hyperparams.Config):
-  box: List[int] = dataclasses.field(default=list)
+  box: List[int] = dataclasses.field(default_factory=list)
 
 
 @dataclasses.dataclass
 class AnchorBoxes(hyperparams.Config):
   boxes: Optional[List[Box]] = None
   level_limits: Optional[List[int]] = None
   anchors_per_scale: int = 3
@@ -220,46 +229,63 @@
     self.boxes = [Box(box=box) for box in boxes]
 
 
 @dataclasses.dataclass
 class Yolo(hyperparams.Config):
   input_size: Optional[List[int]] = dataclasses.field(
       default_factory=lambda: [512, 512, 3])
-  backbone: backbones.Backbone = backbones.Backbone(
-      type='darknet', darknet=backbones.Darknet(model_id='cspdarknet53'))
-  decoder: decoders.Decoder = decoders.Decoder(
-      type='yolo_decoder',
-      yolo_decoder=decoders.YoloDecoder(version='v4', type='regular'))
-  head: YoloHead = YoloHead()
-  detection_generator: YoloDetectionGenerator = YoloDetectionGenerator()
-  loss: YoloLoss = YoloLoss()
-  norm_activation: common.NormActivation = common.NormActivation(
-      activation='mish',
-      use_sync_bn=True,
-      norm_momentum=0.99,
-      norm_epsilon=0.001)
+  backbone: backbones.Backbone = dataclasses.field(
+      default_factory=lambda: backbones.Backbone(  # pylint: disable=g-long-lambda
+          type='darknet', darknet=backbones.Darknet(model_id='cspdarknet53')
+      )
+  )
+  decoder: decoders.Decoder = dataclasses.field(
+      default_factory=lambda: decoders.Decoder(  # pylint: disable=g-long-lambda
+          type='yolo_decoder',
+          yolo_decoder=decoders.YoloDecoder(version='v4', type='regular'),
+      )
+  )
+  head: YoloHead = dataclasses.field(default_factory=YoloHead)
+  detection_generator: YoloDetectionGenerator = dataclasses.field(
+      default_factory=YoloDetectionGenerator
+  )
+  loss: YoloLoss = dataclasses.field(default_factory=YoloLoss)
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=lambda: common.NormActivation(  # pylint: disable=g-long-lambda
+          activation='mish',
+          use_sync_bn=True,
+          norm_momentum=0.99,
+          norm_epsilon=0.001,
+      )
+  )
   num_classes: int = 80
-  anchor_boxes: AnchorBoxes = AnchorBoxes()
+  anchor_boxes: AnchorBoxes = dataclasses.field(default_factory=AnchorBoxes)
   darknet_based_model: bool = False
 
 
 @dataclasses.dataclass
 class YoloTask(cfg.TaskConfig):
   per_category_metrics: bool = False
   smart_bias_lr: float = 0.0
-  model: Yolo = Yolo()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(is_training=False)
+  model: Yolo = dataclasses.field(default_factory=Yolo)
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=False)
+  )
   weight_decay: float = 0.0
   annotation_file: Optional[str] = None
   init_checkpoint: Optional[str] = None
   init_checkpoint_modules: Union[
       str, List[str]] = 'all'  # all, backbone, and/or decoder
   gradient_clip_norm: float = 0.0
   seed = GLOBAL_SEED
+  # Sets maximum number of boxes to be evaluated by coco eval api.
+  max_num_eval_detections: int = 100
 
 
 COCO_INPUT_PATH_BASE = 'coco'
 COCO_TRAIN_EXAMPLES = 118287
 COCO_VAL_EXAMPLES = 5000
 
 
@@ -395,30 +421,30 @@
   return config
 
 
 @exp_factory.register_config_factory('scaled_yolo')
 def scaled_yolo() -> cfg.ExperimentConfig:
   """COCO object detection with YOLOv4-csp and v4."""
   train_batch_size = 256
-  eval_batch_size = 8
+  eval_batch_size = 256
   train_epochs = 300
   warmup_epochs = 3
 
   validation_interval = 5
   steps_per_epoch = COCO_TRAIN_EXAMPLES // train_batch_size
 
   max_num_instances = 300
 
   config = cfg.ExperimentConfig(
       runtime=cfg.RuntimeConfig(mixed_precision_dtype='bfloat16'),
       task=YoloTask(
           smart_bias_lr=0.1,
           init_checkpoint_modules='',
-          annotation_file=None,
           weight_decay=0.0,
+          annotation_file=None,
           model=Yolo(
               darknet_based_model=False,
               norm_activation=common.NormActivation(
                   activation='mish',
                   use_sync_bn=True,
                   norm_epsilon=0.001,
                   norm_momentum=0.97),
@@ -458,27 +484,27 @@
                       mosaic_frequency=1.0,
                       mixup_frequency=0.0,
                   ))),
           validation_data=DataConfig(
               input_path=os.path.join(COCO_INPUT_PATH_BASE, 'val*'),
               is_training=False,
               global_batch_size=eval_batch_size,
-              drop_remainder=True,
+              drop_remainder=False,
               dtype='float32',
               parser=Parser(
                   letter_box=True,
                   use_tie_breaker=True,
                   best_match_only=True,
                   anchor_thresh=4.0,
                   area_thresh=0.1,
                   max_num_instances=max_num_instances,
               ))),
       trainer=cfg.TrainerConfig(
           train_steps=train_epochs * steps_per_epoch,
-          validation_steps=COCO_VAL_EXAMPLES // eval_batch_size,
+          validation_steps=20,
           validation_interval=validation_interval * steps_per_epoch,
           steps_per_loop=steps_per_epoch,
           summary_interval=steps_per_epoch,
           checkpoint_interval=5 * steps_per_epoch,
           optimizer_config=optimization.OptimizationConfig({
               'ema': {
                   'average_decay': 0.9999,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/models/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/classification_input.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/classification_input.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,23 +1,25 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Classification decoder and parser."""
-import tensorflow as tf
+from typing import List
+
+import tensorflow as tf, tf_keras
 from official.vision.dataloaders import classification_input
 from official.vision.ops import preprocess_ops
 
 
 class Parser(classification_input.Parser):
   """Parser to parse an image and its annotations into a dictionary of tensors."""
 
@@ -86,7 +88,23 @@
         image, self._output_size, method=tf.image.ResizeMethod.BILINEAR)
     image.set_shape([self._output_size[0], self._output_size[1], 3])
 
     # Convert image to self._dtype.
     image = tf.image.convert_image_dtype(image, self._dtype)
     image = image / 255.0
     return image
+
+  @classmethod
+  def inference_fn(
+      cls, image: tf.Tensor, input_image_size: List[int], num_channels: int = 3
+  ) -> tf.Tensor:
+    """Builds image model inputs for serving."""
+
+    image = tf.cast(image, dtype=tf.float32)
+    image = preprocess_ops.center_crop_image(image)
+    image = tf.image.resize(
+        image, input_image_size, method=tf.image.ResizeMethod.BILINEAR
+    )
+
+    image.set_shape(input_image_size + [num_channels])
+    image = image / 255.0
+    return image
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/tf_example_decoder.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/tf_example_decoder.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tensorflow Example proto decoder for object detection.
 
 A decoder to decode string tensors containing serialized tensorflow.Example
 protos for object detection.
 """
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.dataloaders import tf_example_decoder
 
 
 def _coco91_to_80(classif, box, areas, iscrowds):
   """Function used to reduce COCO 91 to COCO 80 (2017 to 2014 format)."""
   # Vector where index i coralates to the class at index[i].
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/dataloaders/yolo_input.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/yolo_input.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Detection Data parser and processing for YOLO."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import anchor
 from official.projects.yolo.ops import preprocessing_ops
 from official.vision.dataloaders import parser
 from official.vision.dataloaders import utils
 from official.vision.ops import box_ops as bbox_ops
 from official.vision.ops import preprocess_ops
@@ -335,40 +335,34 @@
     classes = self.set_shape(gt_classes, pad_axis=0, pad_value=-1)
 
     # Build the dictionary set.
     labels.update({
         'source_id': utils.process_source_id(data['source_id']),
         'bbox': tf.cast(boxes, dtype=self._dtype),
         'classes': tf.cast(classes, dtype=self._dtype),
+        # For OTA loss.
+        'image_info': info,
     })
 
     # Update the labels dictionary.
     if not is_training:
       # Sets up groundtruth data for evaluation.
       groundtruths = {
-          'source_id':
-              labels['source_id'],
-          'height':
-              data['height'],
-          'width':
-              data['width'],
-          'num_detections':
-              tf.shape(data['groundtruth_boxes'])[0],
-          'image_info':
-              info,
-          'boxes':
-              bbox_ops.denormalize_boxes(
-                  data['groundtruth_boxes'],
-                  tf.cast([data['height'], data['width']], gt_boxes.dtype)),
-          'classes':
-              data['groundtruth_classes'],
-          'areas':
-              data['groundtruth_area'],
-          'is_crowds':
-              tf.cast(tf.gather(data['groundtruth_is_crowd'], inds), tf.int32),
+          'source_id': labels['source_id'],
+          'height': data['height'],
+          'width': data['width'],
+          'num_detections': tf.shape(data['groundtruth_boxes'])[0],
+          'image_info': info,
+          'boxes': bbox_ops.denormalize_boxes(
+              data['groundtruth_boxes'],
+              tf.cast([data['height'], data['width']], gt_boxes.dtype)),
+          'classes': data['groundtruth_classes'],
+          'areas': data['groundtruth_area'],
+          'is_crowds': tf.cast(
+              tf.gather(data['groundtruth_is_crowd'], inds), tf.int32),
       }
       groundtruths['source_id'] = utils.process_source_id(
           groundtruths['source_id'])
       groundtruths = utils.pad_groundtruths_to_fixed_size(
           groundtruths, self._max_num_instances)
       labels['groundtruths'] = groundtruths
     return image, labels
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/losses/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/nlp/modeling/networks/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/losses/yolo_loss.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/losses/yolo_loss.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Yolo Loss function."""
 import abc
 import collections
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import box_ops
 from official.projects.yolo.ops import loss_utils
 from official.projects.yolo.ops import math_ops
 
 
 class YoloLossBase(object, metaclass=abc.ABCMeta):
@@ -407,15 +407,15 @@
           tf.reduce_sum(class_loss, axis=(1, 2, 3)), dtype=y_pred.dtype)
     else:
       # Computes the loss while keeping the structure as a list in
       # order to ensure all objects are considered. In some cases can
       # make training more unstable but may also return higher APs.
       pred_class = loss_utils.apply_mask(
           ind_mask, tf.gather_nd(pred_class, inds, batch_dims=1))
-      class_loss = tf.keras.losses.binary_crossentropy(
+      class_loss = tf_keras.losses.binary_crossentropy(
           tf.expand_dims(true_class, axis=-1),
           tf.expand_dims(pred_class, axis=-1),
           label_smoothing=self._label_smoothing,
           from_logits=True)
       class_loss = loss_utils.apply_mask(ind_mask, class_loss)
       class_loss = math_ops.divide_no_nan(class_loss,
                                           tf.expand_dims(reps, axis=-1))
@@ -552,24 +552,24 @@
                     self._objectness_smooth * tf.expand_dims(iou, axis=-1))
     smoothed_iou = loss_utils.apply_mask(ind_mask, smoothed_iou)
     true_conf = loss_utils.build_grid(
         inds, smoothed_iou, pred_conf, ind_mask, update=self._update_on_repeat)
     true_conf = tf.squeeze(true_conf, axis=-1)
 
     # Compute the cross entropy loss for the confidence map.
-    bce = tf.keras.losses.binary_crossentropy(
+    bce = tf_keras.losses.binary_crossentropy(
         tf.expand_dims(true_conf, axis=-1), pred_conf, from_logits=True)
     if self._ignore_thresh != 0.0:
       bce = loss_utils.apply_mask(obj_mask, bce)
       conf_loss = tf.reduce_sum(bce) / tf.reduce_sum(obj_mask)
     else:
       conf_loss = tf.reduce_mean(bce)
 
     # Compute the cross entropy loss for the class maps.
-    class_loss = tf.keras.losses.binary_crossentropy(
+    class_loss = tf_keras.losses.binary_crossentropy(
         true_class,
         pred_class,
         label_smoothing=self._label_smoothing,
         from_logits=True)
     class_loss = loss_utils.apply_mask(
         tf.squeeze(ind_mask, axis=-1), class_loss)
     class_loss = math_ops.divide_no_nan(tf.reduce_sum(class_loss), num_objs)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/losses/yolo_loss_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/losses/yolo_loss_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for yolo heads."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.losses import yolo_loss
 
 
 class YoloDecoderTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
@@ -31,15 +31,15 @@
 
     def inpdict(input_shape, dtype=tf.float32):
       inputs = {}
       for key in input_shape:
         inputs[key] = tf.ones(input_shape[key], dtype=dtype)
       return inputs
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     input_shape = {
         '3': [1, 52, 52, 255],
         '4': [1, 26, 26, 255],
         '5': [1, 13, 13, 255]
     }
     classes = 80
     anchors = {
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/nlp/quantization/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/backbones/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/nlp/tasks/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/backbones/darknet.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/backbones/darknet.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -33,15 +33,15 @@
 
 [2] Alexey Bochkovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao
     YOLOv4: Optimal Speed and Accuracy of Object Detection. arXiv:2004.10934
 """
 
 import collections
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.projects.yolo.modeling.layers import nn_blocks
 from official.vision.modeling.backbones import factory
 
 
 class BlockConfig:
@@ -100,15 +100,15 @@
   connect, introduce or exit a level. Used in place of an if condition
   or switch to make adding new layers easier and to reduce redundant code.
   """
 
   def __init__(self):
     self._layer_dict = {
         'ConvBN': (nn_blocks.ConvBN, self.conv_bn_config_todict),
-        'MaxPool': (tf.keras.layers.MaxPool2D, self.maxpool_config_todict)
+        'MaxPool': (tf_keras.layers.MaxPool2D, self.maxpool_config_todict)
     }
 
   def conv_bn_config_todict(self, config, kwargs):
     dictvals = {
         'filters': config.filters,
         'kernel_size': config.kernel_size,
         'strides': config.strides,
@@ -368,21 +368,21 @@
     'cspdarknet53': CSPDARKNET53,
     'altered_cspdarknet53': CSPADARKNET53,
     'cspdarknettiny': CSPDARKNETTINY,
     'csp-large': LARGECSP53,
 }
 
 
-class Darknet(tf.keras.Model):
+class Darknet(tf_keras.Model):
   """The Darknet backbone architecture."""
 
   def __init__(
       self,
       model_id='darknet53',
-      input_specs=tf.keras.layers.InputSpec(shape=[None, None, None, 3]),
+      input_specs=tf_keras.layers.InputSpec(shape=[None, None, None, 3]),
       min_level=None,
       max_level=5,
       width_scale=1.0,
       depth_scale=1.0,
       use_reorg_input=False,
       csp_level_mod=(),
       activation=None,
@@ -396,15 +396,15 @@
       bias_regularizer=None,
       **kwargs):
 
     layer_specs, splits = Darknet.get_model_config(model_id)
 
     self._model_name = model_id
     self._splits = splits
-    self._input_shape = input_specs
+    self._input_specs = input_specs
     self._registry = LayerBuilder()
 
     # default layer look up
     self._min_size = min_level
     self._max_size = max_level
     self._output_specs = None
     self._csp_level_mod = set(csp_level_mod)
@@ -431,21 +431,19 @@
         'use_sync_bn': self._use_sync_bn,
         'activation': self._activation,
         'use_separable_conv': self._use_separable_conv,
         'dilation_rate': 1,
         'name': None
     }
 
-    inputs = tf.keras.layers.Input(shape=self._input_shape.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
     output = self._build_struct(layer_specs, inputs)
-    super().__init__(inputs=inputs, outputs=output, name=self._model_name)
-
-  @property
-  def input_specs(self):
-    return self._input_shape
+    super().__init__(
+        inputs=inputs, outputs=output, name=self._model_name, **kwargs
+    )
 
   @property
   def output_specs(self):
     return self._output_specs
 
   @property
   def splits(self):
@@ -532,33 +530,36 @@
 
     dilated_reps = config.repetitions - degrid
     for i in range(dilated_reps):
       self._default_dict['name'] = f'{name}_{i}'
       x = nn_blocks.DarkResidual(
           filters=config.filters // scale_filters,
           filter_scale=residual_filter_scale,
-          **self._default_dict)(
-              x)
+          **self._default_dict,
+      )(x)
 
     for i in range(dilated_reps, config.repetitions):
       self._default_dict['dilation_rate'] = max(
-          1, self._default_dict['dilation_rate'] // 2)
-      self._default_dict[
-          'name'] = f"{name}_{i}_degridded_{self._default_dict['dilation_rate']}"
+          1, self._default_dict['dilation_rate'] // 2
+      )
+      self._default_dict['name'] = (
+          f"{name}_{i}_degridded_{self._default_dict['dilation_rate']}"
+      )
       x = nn_blocks.DarkResidual(
           filters=config.filters // scale_filters,
           filter_scale=residual_filter_scale,
-          **self._default_dict)(
-              x)
+          **self._default_dict,
+      )(x)
 
     self._default_dict['name'] = f'{name}_csp_connect'
     output = nn_blocks.CSPConnect(
         filters=config.filters,
         filter_scale=csp_filter_scale,
-        **self._default_dict)([x, x_route])
+        **self._default_dict,
+    )([x, x_route])
     self._default_dict['activation'] = self._activation
     self._default_dict['name'] = None
     return output
 
   def _csp_tiny_stack(self, inputs, config, name):
     self._default_dict['activation'] = self._get_activation(config.activation)
     self._default_dict['name'] = f'{name}_csp_tiny'
@@ -566,15 +567,15 @@
         filters=config.filters, **self._default_dict)(
             inputs)
     self._default_dict['activation'] = self._activation
     self._default_dict['name'] = None
     return x, x_route
 
   def _tiny_stack(self, inputs, config, name):
-    x = tf.keras.layers.MaxPool2D(
+    x = tf_keras.layers.MaxPool2D(
         pool_size=2,
         strides=config.strides,
         padding='same',
         data_format=None,
         name=f'{name}_tiny/pool')(
             inputs)
     self._default_dict['activation'] = self._get_activation(config.activation)
@@ -597,33 +598,36 @@
       self._default_dict['dilation_rate'] = config.dilation_rate
       if config.repetitions < 8:
         config.repetitions += 2
     else:
       self._default_dict['dilation_rate'] = 1
 
     x = nn_blocks.DarkResidual(
-        filters=config.filters, downsample=True, **self._default_dict)(
-            inputs)
+        filters=config.filters, downsample=True, **self._default_dict
+    )(inputs)
 
-    dilated_reps = config.repetitions - self._default_dict[
-        'dilation_rate'] // 2 - 1
+    dilated_reps = (
+        config.repetitions - self._default_dict['dilation_rate'] // 2 - 1
+    )
     for i in range(dilated_reps):
       self._default_dict['name'] = f'{name}_{i}'
-      x = nn_blocks.DarkResidual(
-          filters=config.filters, **self._default_dict)(
-              x)
+      x = nn_blocks.DarkResidual(filters=config.filters, **self._default_dict)(
+          x
+      )
 
     for i in range(dilated_reps, config.repetitions - 1):
-      self._default_dict[
-          'dilation_rate'] = self._default_dict['dilation_rate'] // 2
-      self._default_dict[
-          'name'] = f"{name}_{i}_degridded_{self._default_dict['dilation_rate']}"
-      x = nn_blocks.DarkResidual(
-          filters=config.filters, **self._default_dict)(
-              x)
+      self._default_dict['dilation_rate'] = (
+          self._default_dict['dilation_rate'] // 2
+      )
+      self._default_dict['name'] = (
+          f"{name}_{i}_degridded_{self._default_dict['dilation_rate']}"
+      )
+      x = nn_blocks.DarkResidual(filters=config.filters, **self._default_dict)(
+          x
+      )
 
     self._default_dict['activation'] = self._activation
     self._default_dict['name'] = None
     self._default_dict['dilation_rate'] = 1
     return x
 
   def _build_block(self, inputs, config, name):
@@ -668,19 +672,19 @@
         'activation': self._activation,
     }
     return layer_config
 
 
 @factory.register_backbone_builder('darknet')
 def build_darknet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None
-) -> tf.keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
+    l2_regularizer: tf_keras.regularizers.Regularizer = None
+) -> tf_keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds darknet."""
 
   backbone_config = backbone_config.get()
   model = Darknet(
       model_id=backbone_config.model_id,
       min_level=backbone_config.min_level,
       max_level=backbone_config.max_level,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/backbones/darknet_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/backbones/darknet_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for yolo."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.projects.yolo.modeling.backbones import darknet
 
 
 class DarknetTest(parameterized.TestCase, tf.test.TestCase):
@@ -30,21 +30,21 @@
       (224, 'darknettiny', 1, 2, False),
       (224, 'cspdarknettiny', 1, 1, False),
       (224, 'cspdarknet53', 2, 1, True),
   )
   def test_network_creation(self, input_size, model_id, endpoint_filter_scale,
                             scale_final, dilate):
     """Test creation of ResNet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     network = darknet.Darknet(
         model_id=model_id, min_level=3, max_level=5, dilate=dilate)
     self.assertEqual(network.model_id, model_id)
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
 
     if dilate:
       self.assertAllEqual([
           1, input_size / 2**3, input_size / 2**3, 128 * endpoint_filter_scale
       ], endpoints['3'].shape.as_list())
       self.assertAllEqual([
@@ -74,30 +74,35 @@
           ],
           use_sync_bn=[False, True],
       ))
   def test_sync_bn_multiple_devices(self, strategy, use_sync_bn):
     """Test for sync bn on TPU and GPU devices."""
     inputs = np.random.rand(1, 224, 224, 3)
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     with strategy.scope():
-      network = darknet.Darknet(model_id='darknet53', min_size=3, max_size=5)
+      network = darknet.Darknet(
+          model_id='darknet53',
+          min_level=3,
+          max_level=5,
+          use_sync_bn=use_sync_bn,
+      )
       _ = network(inputs)
 
   @parameterized.parameters(1, 3, 4)
   def test_input_specs(self, input_dim):
     """Test different input feature dimensions."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, input_dim])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, input_dim])
     network = darknet.Darknet(
         model_id='darknet53', min_level=3, max_level=5, input_specs=input_specs)
 
-    inputs = tf.keras.Input(shape=(224, 224, input_dim), batch_size=1)
+    inputs = tf_keras.Input(shape=(224, 224, input_dim), batch_size=1)
     _ = network(inputs)
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     kwargs = dict(
         model_id='darknet53',
         min_level=3,
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/decoders/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/vision/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/decoders/yolo_decoder.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/decoders/yolo_decoder.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Feature Pyramid Network and Path Aggregation variants used in YOLO."""
 from typing import Mapping, Optional, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.projects.yolo.modeling.layers import nn_blocks
 from official.vision.modeling.decoders import factory
 
 # model configurations
 # the structure is as follows. model version, {v3, v4, v#, ... etc}
@@ -80,21 +80,21 @@
                 use_fpn=False,
                 max_level_process_len=2,
                 path_process_len=1),
         ),
 }
 
 
-class _IdentityRoute(tf.keras.layers.Layer):
+class _IdentityRoute(tf_keras.layers.Layer):
 
   def call(self, inputs):  # pylint: disable=arguments-differ
     return None, inputs
 
 
-class YoloFPN(tf.keras.layers.Layer):
+class YoloFPN(tf_keras.layers.Layer):
   """YOLO Feature pyramid network."""
 
   def __init__(self,
                fpn_depth=4,
                max_fpn_depth=None,
                max_csp_stack=None,
                use_spatial_attention=False,
@@ -124,16 +124,16 @@
       fpn_filter_scale: `int`, scaling factor for the FPN filters.
       use_sync_bn: if True, use synchronized batch normalization.
       use_separable_conv: `bool` whether to use separable convs.
       norm_momentum: `float`, normalization momentum for the moving average.
       norm_epsilon: `float`, small float added to variance to avoid dividing by
         zero.
       kernel_initializer: kernel_initializer for convolutional layers.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
-      bias_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
+      kernel_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
+      bias_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
       **kwargs: keyword arguments to be passed.
     """
 
     super().__init__(**kwargs)
     self._fpn_depth = fpn_depth
     self._max_fpn_depth = max_fpn_depth or self._fpn_depth
 
@@ -242,15 +242,15 @@
       outputs[str(level)] = x
       if level > self._min_level:
         x_next = inputs[str(level - 1)]
         _, layer_in = self.resamples[str(level - 1)]([x_next, x])
     return outputs
 
 
-class YoloPAN(tf.keras.layers.Layer):
+class YoloPAN(tf_keras.layers.Layer):
   """YOLO Path Aggregation Network."""
 
   def __init__(self,
                path_process_len=6,
                max_level_process_len=None,
                embed_spp=False,
                use_spatial_attention=False,
@@ -278,16 +278,16 @@
       activation: `str`, the activation function to use typically leaky or mish.
       use_sync_bn: if True, use synchronized batch normalization.
       use_separable_conv: `bool` whether to use separable convs.
       norm_momentum: `float`, normalization omentum for the moving average.
       norm_epsilon: `float`, small float added to variance to avoid dividing
         by zero.
       kernel_initializer: kernel_initializer for convolutional layers.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
-      bias_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
+      kernel_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
+      bias_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
       fpn_input: `bool`, for whether the input into this fucntion is an FPN or
         a backbone.
       fpn_filter_scale: `int`, scaling factor for the FPN filters.
       **kwargs: keyword arguments to be passed.
     """
 
     super().__init__(**kwargs)
@@ -434,15 +434,15 @@
       if self._check(level):
         x_next = inputs[str(self._key_shift(level))]
         _, layer_in = self.resamples[str(
             self._key_shift(level))]([x_route, x_next])
     return outputs
 
 
-class YoloDecoder(tf.keras.Model):
+class YoloDecoder(tf_keras.Model):
   """Darknet Backbone Decoder."""
 
   def __init__(self,
                input_specs,
                use_fpn=False,
                use_spatial_attention=False,
                csp_stack=False,
@@ -485,16 +485,16 @@
       activation: `str`, the activation function to use typically leaky or mish.
       use_sync_bn: if True, use synchronized batch normalization.
       use_separable_conv: `bool` wether to use separable convs.
       norm_momentum: `float`, normalization omentum for the moving average.
       norm_epsilon: `float`, small float added to variance to avoid dividing by
         zero.
       kernel_initializer: kernel_initializer for convolutional layers.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
-      bias_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
+      kernel_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
+      bias_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
       **kwargs: keyword arguments to be passed.
     """
 
     self._input_specs = input_specs
     self._use_fpn = use_fpn
     self._fpn_depth = fpn_depth
     self._max_fpn_depth = max_fpn_depth
@@ -529,15 +529,15 @@
         path_process_len=self._path_process_len,
         max_level_process_len=self._max_level_process_len,
         embed_spp=self._embed_spp,
         fpn_input=self._use_fpn,
         **self._base_config)
 
     inputs = {
-        key: tf.keras.layers.Input(shape=value[1:])
+        key: tf_keras.layers.Input(shape=value[1:])
         for key, value in input_specs.items()
     }
     if self._use_fpn:
       inter_outs = YoloFPN(
           fpn_depth=self._fpn_depth,
           max_fpn_depth=self._max_fpn_depth,
           max_csp_stack=self._max_csp_stack,
@@ -571,28 +571,28 @@
     return cls(**config)
 
 
 @factory.register_decoder_builder('yolo_decoder')
 def build_yolo_decoder(
     input_specs: Mapping[str, tf.TensorShape],
     model_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-    **kwargs) -> Union[None, tf.keras.Model, tf.keras.layers.Layer]:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+    **kwargs) -> Union[None, tf_keras.Model, tf_keras.layers.Layer]:
   """Builds Yolo FPN/PAN decoder from a config.
 
   Args:
     input_specs: A `dict` of input specifications. A dictionary consists of
       {level: TensorShape} from a backbone.
     model_config: A OneOfConfig. Model config.
-    l2_regularizer: A `tf.keras.regularizers.Regularizer` instance. Default to
+    l2_regularizer: A `tf_keras.regularizers.Regularizer` instance. Default to
       None.
     **kwargs: Additional kwargs arguments.
 
   Returns:
-    A `tf.keras.Model` instance of the Yolo FPN/PAN decoder.
+    A `tf_keras.Model` instance of the Yolo FPN/PAN decoder.
   """
   decoder_cfg = model_config.decoder.get()
   norm_activation_config = model_config.norm_activation
 
   activation = (
       decoder_cfg.activation if decoder_cfg.activation != 'same' else
       norm_activation_config.activation)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/decoders/yolo_decoder_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/decoders/yolo_decoder_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for YOLO."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.projects.yolo.modeling.decoders import yolo_decoder as decoders
 
 
 class YoloDecoderTest(parameterized.TestCase, tf.test.TestCase):
@@ -62,15 +62,15 @@
     else:
       raise NotImplementedError(f'YOLO decoder test {type} not implemented.')
     return model
 
   @parameterized.parameters('1', '6spp', '6sppfpn', '6')
   def test_network_creation(self, version):
     """Test creation of ResNet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     input_shape = {
         '3': [1, 52, 52, 256],
         '4': [1, 26, 26, 512],
         '5': [1, 13, 13, 1024]
     }
     decoder = self._build_yolo_decoder(input_shape, version)
 
@@ -90,15 +90,15 @@
               strategy_combinations.one_device_strategy_gpu,
           ],
           use_sync_bn=[False, True],
       ))
   def test_sync_bn_multiple_devices(self, strategy, use_sync_bn):
     """Test for sync bn on TPU and GPU devices."""
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     with strategy.scope():
       input_shape = {
           '3': [1, 52, 52, 256],
           '4': [1, 26, 26, 512],
           '5': [1, 13, 13, 1024]
       }
@@ -109,15 +109,15 @@
         inputs[key] = tf.ones(input_shape[key], dtype=tf.float32)
 
       _ = decoder.call(inputs)
 
   @parameterized.parameters(1, 3, 4)
   def test_input_specs(self, input_dim):
     """Test different input feature dimensions."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     input_shape = {
         '3': [1, 52, 52, 256],
         '4': [1, 26, 26, 512],
         '5': [1, 13, 13, 1024]
     }
     decoder = self._build_yolo_decoder(input_shape, '6')
@@ -125,15 +125,15 @@
     inputs = {}
     for key in input_shape:
       inputs[key] = tf.ones(input_shape[key], dtype=tf.float32)
     _ = decoder(inputs)
 
   def test_serialize_deserialize(self):
     """Create a network object that sets all of its config options."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     input_shape = {
         '3': [1, 52, 52, 256],
         '4': [1, 26, 26, 512],
         '5': [1, 13, 13, 1024]
     }
     decoder = self._build_yolo_decoder(input_shape, '6')
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/heads/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/vision/serving/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/heads/yolo_head.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/heads/yolo_head.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,19 +10,19 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Yolo heads."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.projects.yolo.modeling.layers import nn_blocks
 
 
-class YoloHead(tf.keras.layers.Layer):
+class YoloHead(tf_keras.layers.Layer):
   """YOLO Prediction Head."""
 
   def __init__(self,
                min_level,
                max_level,
                classes=80,
                boxes_per_level=3,
@@ -46,16 +46,16 @@
       output_extras: `int`, number of additional output channels that the head.
         should predict for non-object detection and non-image classification
         tasks.
       norm_momentum: `float`, normalization momentum for the moving average.
       norm_epsilon: `float`, small float added to variance to avoid dividing by
         zero.
       kernel_initializer: kernel_initializer for convolutional layers.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object for Conv2D.
-      bias_regularizer: tf.keras.regularizers.Regularizer object for Conv2d.
+      kernel_regularizer: tf_keras.regularizers.Regularizer object for Conv2D.
+      bias_regularizer: tf_keras.regularizers.Regularizer object for Conv2d.
       activation: `str`, the activation function to use typically leaky or mish.
       smart_bias: `bool`, whether to use smart bias.
       use_separable_conv: `bool` wether to use separable convs.
       **kwargs: keyword arguments to be passed.
     """
 
     super().__init__(**kwargs)
@@ -90,15 +90,15 @@
         use_bn=False,
         use_separable_conv=self._use_separable_conv,
         **self._base_config)
 
   def bias_init(self, scale, inshape, isize=640, no_per_conf=8):
 
     def bias(shape, dtype):
-      init = tf.keras.initializers.Zeros()
+      init = tf_keras.initializers.Zeros()
       base = init(shape, dtype=dtype)
       if self._smart_bias:
         base = tf.reshape(base, [self._boxes_per_level, -1])
         box, conf, classes = tf.split(base, [4, 1, -1], axis=-1)
         conf += tf.math.log(no_per_conf / ((isize / scale)**2))
         classes += tf.math.log(0.6 / (self._classes - 0.99))
         base = tf.concat([box, conf, classes], axis=-1)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/heads/yolo_head_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/heads/yolo_head_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,24 +12,24 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for yolo heads."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.modeling.heads import yolo_head as heads
 
 
 class YoloDecoderTest(parameterized.TestCase, tf.test.TestCase):
 
   def test_network_creation(self):
     """Test creation of YOLO family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     input_shape = {
         '3': [1, 52, 52, 256],
         '4': [1, 26, 26, 512],
         '5': [1, 13, 13, 1024]
     }
     classes = 100
     bps = 3
@@ -45,15 +45,15 @@
     for key in endpoints.keys():
       expected_input_shape = input_shape[key]
       expected_input_shape[-1] = (classes + 5) * bps
       self.assertAllEqual(endpoints[key].shape.as_list(), expected_input_shape)
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     input_shape = {
         '3': [1, 52, 52, 256],
         '4': [1, 26, 26, 512],
         '5': [1, 13, 13, 1024]
     }
     classes = 100
     bps = 3
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/roformer/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,15 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/detection_generator.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/detection_generator.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,79 +1,85 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains common building blocks for yolo layer (detection layer)."""
-import tensorflow as tf
+from typing import Optional
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.losses import yolo_loss
 from official.projects.yolo.ops import box_ops
 from official.projects.yolo.ops import loss_utils
 from official.vision.modeling.layers import detection_generator
 
 
-class YoloLayer(tf.keras.Model):
+class YoloLayer(tf_keras.layers.Layer):
   """Yolo layer (detection generator)."""
 
-  def __init__(self,
-               anchors,
-               classes,
-               iou_thresh=0.0,
-               ignore_thresh=0.7,
-               truth_thresh=1.0,
-               nms_thresh=0.6,
-               max_delta=10.0,
-               loss_type='ciou',
-               iou_normalizer=1.0,
-               cls_normalizer=1.0,
-               object_normalizer=1.0,
-               use_scaled_loss=False,
-               update_on_repeat=False,
-               pre_nms_points=5000,
-               label_smoothing=0.0,
-               max_boxes=200,
-               box_type='original',
-               path_scale=None,
-               scale_xy=None,
-               nms_type='greedy',
-               objectness_smooth=False,
-               **kwargs):
+  def __init__(
+      self,
+      anchors,
+      classes,
+      apply_nms=True,
+      iou_thresh=0.0,
+      ignore_thresh=0.7,
+      truth_thresh=1.0,
+      nms_thresh=0.6,
+      max_delta=10.0,
+      loss_type='ciou',
+      iou_normalizer=1.0,
+      cls_normalizer=1.0,
+      object_normalizer=1.0,
+      use_scaled_loss=False,
+      update_on_repeat=False,
+      pre_nms_points=5000,
+      label_smoothing=0.0,
+      max_boxes=200,
+      box_type='original',
+      path_scale=None,
+      scale_xy=None,
+      nms_version='greedy',
+      objectness_smooth=False,
+      use_class_agnostic_nms: Optional[bool] = False,
+      **kwargs
+  ):
     """Parameters for the loss functions used at each detection head output.
 
     Args:
       anchors: `List[List[int]]` for the anchor boxes that are used in the
         model.
       classes: `int` for the number of classes.
+      apply_nms: A boolean indicating whether to apply NMS.
       iou_thresh: `float` to use many anchors per object if IoU(Obj, Anchor) >
         iou_thresh.
       ignore_thresh: `float` for the IOU value over which the loss is not
         propagated, and a detection is assumed to have been made.
       truth_thresh: `float` for the IOU value over which the loss is propagated
         despite a detection being made'.
       nms_thresh: `float` for the minimum IOU value for an overlap.
       max_delta: gradient clipping to apply to the box loss.
-      loss_type: `str` for the typeof iou loss to use with in {ciou, diou,
-        giou, iou}.
+      loss_type: `str` for the typeof iou loss to use with in {ciou, diou, giou,
+        iou}.
       iou_normalizer: `float` for how much to scale the loss on the IOU or the
         boxes.
       cls_normalizer: `float` for how much to scale the loss on the classes.
       object_normalizer: `float` for how much to scale loss on the detection
         map.
-      use_scaled_loss: `bool` for whether to use the scaled loss
-        or the traditional loss.
+      use_scaled_loss: `bool` for whether to use the scaled loss or the
+        traditional loss.
       update_on_repeat: `bool` indicating how you would like to handle repeated
         indexes in a given [j, i] index. Setting this to True will give more
         consistent MAP, setting it to falls will improve recall by 1-2% but will
         sacrifice some MAP.
       pre_nms_points: `int` number of top candidate detections per class before
         NMS.
       label_smoothing: `float` for how much to smooth the loss on the classes.
@@ -90,50 +96,55 @@
         activation function to the boxes, this is used for some of the newer
         anchor free versions of YOLO.
       path_scale: `dict` for the size of the input tensors. Defaults to
         precalulated values from the `mask`.
       scale_xy: dictionary `float` values inidcating how far each pixel can see
         outside of its containment of 1.0. a value of 1.2 indicates there is a
         20% extended radius around each pixel that this specific pixel can
-        predict values for a center at. the center can range from 0 - value/2
-        to 1 + value/2, this value is set in the yolo filter, and resused here.
+        predict values for a center at. the center can range from 0 - value/2 to
+        1 + value/2, this value is set in the yolo filter, and resused here.
         there should be one value for scale_xy for each level from min_level to
         max_level.
-      nms_type: `str` for which non max suppression to use.
+      nms_version: `str` for which non max suppression to use.
       objectness_smooth: `float` for how much to smooth the loss on the
         detection map.
+      use_class_agnostic_nms: A `bool` of whether non max suppression is
+        operated on all the boxes using max scores across all classes. Only
+        valid when nms_version is v2.
       **kwargs: Addtional keyword arguments.
     """
     super().__init__(**kwargs)
     self._anchors = anchors
+    self._apply_nms = apply_nms
     self._thresh = iou_thresh
     self._ignore_thresh = ignore_thresh
     self._truth_thresh = truth_thresh
     self._iou_normalizer = iou_normalizer
     self._cls_normalizer = cls_normalizer
     self._object_normalizer = object_normalizer
     self._objectness_smooth = objectness_smooth
     self._nms_thresh = nms_thresh
     self._max_boxes = max_boxes
     self._max_delta = max_delta
     self._classes = classes
     self._loss_type = loss_type
+    self._use_class_agnostic_nms = use_class_agnostic_nms
 
     self._use_scaled_loss = use_scaled_loss
     self._update_on_repeat = update_on_repeat
 
     self._pre_nms_points = pre_nms_points
     self._label_smoothing = label_smoothing
 
     self._keys = list(anchors.keys())
     self._len_keys = len(self._keys)
     self._box_type = box_type
     self._path_scale = path_scale or {key: 2**int(key) for key in self._keys}
 
-    self._nms_type = nms_type
+    self._nms_version = nms_version
     self._scale_xy = scale_xy or {key: 1.0 for key, _ in anchors.items()}
 
     self._generator = {}
     self._len_mask = {}
     for key in self._keys:
       anchors = self._anchors[key]
       self._generator[key] = loss_utils.GridGenerator(
@@ -149,124 +160,145 @@
     if height is None or width is None:
       height, width = shape_[1], shape_[2]
 
     generator = self._generator[key]
     len_mask = self._len_mask[key]
     scale_xy = self._scale_xy[key]
 
-    # reshape the yolo output to (batchsize,
+    # Reshape the yolo output to (batchsize,
     #                             width,
     #                             height,
     #                             number_anchors,
     #                             remaining_points)
     data = tf.reshape(inputs, [-1, height, width, len_mask, self._classes + 5])
 
-    # use the grid generator to get the formatted anchor boxes and grid points
-    # in shape [1, height, width, 2]
+    # Use the grid generator to get the formatted anchor boxes and grid points
+    # in shape [1, height, width, 2].
     centers, anchors = generator(height, width, batchsize, dtype=data.dtype)
 
-    # split the yolo detections into boxes, object score map, classes
+    # Split the yolo detections into boxes, object score map, classes.
     boxes, obns_scores, class_scores = tf.split(
         data, [4, 1, self._classes], axis=-1)
 
-    # determine the number of classes
+    # Determine the number of classes.
     classes = class_scores.get_shape().as_list()[-1]
 
-    # configurable to use the new coordinates in scaled Yolo v4 or not
+    # Configurable to use the new coordinates in scaled Yolo v4 or not.
     _, _, boxes = loss_utils.get_predicted_box(
         tf.cast(height, data.dtype),
         tf.cast(width, data.dtype),
         boxes,
         anchors,
         centers,
         scale_xy,
         stride=self._path_scale[key],
         darknet=False,
         box_type=self._box_type[key])
 
-    # convert boxes from yolo(x, y, w. h) to tensorflow(ymin, xmin, ymax, xmax)
+    # Convert boxes from yolo(x, y, w. h) to tensorflow(ymin, xmin, ymax, xmax).
     boxes = box_ops.xcycwh_to_yxyx(boxes)
 
-    # activate and detection map
+    # Activate and detection map
     obns_scores = tf.math.sigmoid(obns_scores)
 
-    # convert detection map to class detection probabailities
+    # Convert detection map to class detection probabilities.
     class_scores = tf.math.sigmoid(class_scores) * obns_scores
 
-    # platten predictions to [batchsize, N, -1] for non max supression
+    # Flatten predictions to [batchsize, N, -1] for non max supression.
     fill = height * width * len_mask
     boxes = tf.reshape(boxes, [-1, fill, 4])
     class_scores = tf.reshape(class_scores, [-1, fill, classes])
     obns_scores = tf.reshape(obns_scores, [-1, fill])
     return obns_scores, boxes, class_scores
 
-  def call(self, inputs):
+  def __call__(self, inputs):
     boxes = []
     class_scores = []
     object_scores = []
     levels = list(inputs.keys())
     min_level = int(min(levels))
     max_level = int(max(levels))
 
-    # aggregare boxes over each scale
+    # Aggregate boxes over each scale.
     for i in range(min_level, max_level + 1):
       key = str(i)
       object_scores_, boxes_, class_scores_ = self.parse_prediction_path(
           key, inputs[key])
       boxes.append(boxes_)
       class_scores.append(class_scores_)
       object_scores.append(object_scores_)
 
-    # colate all predicitons
+    # Collate all predicitons.
     boxes = tf.concat(boxes, axis=1)
     object_scores = tf.concat(object_scores, axis=1)
     class_scores = tf.concat(class_scores, axis=1)
 
-    # get masks to threshold all the predicitons
+    # Get masks to threshold all the predicitons.
     object_mask = tf.cast(object_scores > self._thresh, object_scores.dtype)
     class_mask = tf.cast(class_scores > self._thresh, class_scores.dtype)
 
-    # apply thresholds mask to all the predicitons
+    # Apply thresholds mask to all the predictions.
     object_scores *= object_mask
     class_scores *= (tf.expand_dims(object_mask, axis=-1) * class_mask)
 
-    # apply nms
-    if self._nms_type == 'greedy':
-      # greedy NMS
-      boxes = tf.cast(boxes, dtype=tf.float32)
-      class_scores = tf.cast(class_scores, dtype=tf.float32)
-      boxes, object_scores_, class_scores, num_detections = (
+    # Make a copy of the original dtype.
+    dtype = object_scores.dtype
+
+    if not self._apply_nms:
+      return {
+          'bbox': tf.expand_dims(tf.cast(boxes, dtype=tf.float32), axis=-2),
+          'classes': tf.cast(class_scores, dtype=tf.float32),
+          'confidence': object_scores,
+          'num_detections': self._max_boxes,
+      }
+
+    # Apply nms.
+    if self._nms_version == 'greedy':
+      # Greedy NMS.
+      boxes, object_scores, class_scores, num_detections = (
           tf.image.combined_non_max_suppression(
-              tf.expand_dims(boxes, axis=-2),
-              class_scores,
+              tf.expand_dims(tf.cast(boxes, dtype=tf.float32), axis=-2),
+              tf.cast(class_scores, dtype=tf.float32),
               self._pre_nms_points,
               self._max_boxes,
               iou_threshold=self._nms_thresh,
-              score_threshold=self._thresh))
-      # cast the boxes and predicitons abck to original datatype
-      boxes = tf.cast(boxes, object_scores.dtype)
-      class_scores = tf.cast(class_scores, object_scores.dtype)
-      object_scores = tf.cast(object_scores_, object_scores.dtype)
-    else:
-      # TPU NMS
-      boxes = tf.cast(boxes, dtype=tf.float32)
-      class_scores = tf.cast(class_scores, dtype=tf.float32)
-      (boxes, confidence, classes,
-       num_detections) = detection_generator._generate_detections_v2(  # pylint:disable=protected-access
-           tf.expand_dims(boxes, axis=-2),
-           class_scores,
-           pre_nms_top_k=self._pre_nms_points,
-           max_num_detections=self._max_boxes,
-           nms_iou_threshold=self._nms_thresh,
-           pre_nms_score_threshold=self._thresh)
-      boxes = tf.cast(boxes, object_scores.dtype)
-      class_scores = tf.cast(classes, object_scores.dtype)
-      object_scores = tf.cast(confidence, object_scores.dtype)
+              score_threshold=self._thresh,
+          )
+      )
+    elif self._nms_version == 'v1':
+      (boxes, object_scores, class_scores, num_detections, _) = (
+          detection_generator._generate_detections_v1(  # pylint:disable=protected-access
+              tf.expand_dims(tf.cast(boxes, dtype=tf.float32), axis=-2),
+              tf.cast(class_scores, dtype=tf.float32),
+              pre_nms_top_k=self._pre_nms_points,
+              max_num_detections=self._max_boxes,
+              nms_iou_threshold=self._nms_thresh,
+              pre_nms_score_threshold=self._thresh,
+          )
+      )
+
+    elif self._nms_version == 'v2' or self._nms_version == 'iou':
+      (boxes, object_scores, class_scores, num_detections) = (
+          detection_generator._generate_detections_v2(  # pylint:disable=protected-access
+              tf.expand_dims(tf.cast(boxes, dtype=tf.float32), axis=-2),
+              tf.cast(class_scores, dtype=tf.float32),
+              pre_nms_top_k=self._pre_nms_points,
+              max_num_detections=self._max_boxes,
+              nms_iou_threshold=self._nms_thresh,
+              pre_nms_score_threshold=self._thresh,
+              use_class_agnostic_nms=self._use_class_agnostic_nms,
+          )
+      )
+
+    # Cast the boxes and predicitons back to original datatype.
+    boxes = tf.cast(boxes, dtype)
+    class_scores = tf.cast(class_scores, dtype)
+    object_scores = tf.cast(object_scores, dtype)
 
-    # format and return
+    # Format and return
     return {
         'bbox': boxes,
         'classes': class_scores,
         'confidence': object_scores,
         'num_detections': num_detections,
     }
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/detection_generator_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/detection_generator_test.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,43 +10,52 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for yolo detection generator."""
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from official.projects.yolo.modeling.layers import detection_generator as dg
+from official.projects.yolo.modeling.layers import detection_generator
 
 
 class YoloDecoderTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
-      (True),
-      (False),
+      ('v1', None),
+      ('v2', False),
+      ('v2', True),
+      ('greedy', None),
   )
-  def test_network_creation(self, nms):
+  def test_network_creation(self, nms_version, use_class_agnostic_nms):
     """Test creation of ResNet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     input_shape = {
         '3': [1, 52, 52, 255],
         '4': [1, 26, 26, 255],
         '5': [1, 13, 13, 255]
     }
     classes = 80
     anchors = {
         '3': [[12.0, 19.0], [31.0, 46.0], [96.0, 54.0]],
         '4': [[46.0, 114.0], [133.0, 127.0], [79.0, 225.0]],
         '5': [[301.0, 150.0], [172.0, 286.0], [348.0, 340.0]]
     }
 
     box_type = {key: 'scaled' for key in anchors.keys()}
 
-    layer = dg.YoloLayer(anchors, classes, box_type=box_type, max_boxes=10)
+    layer = detection_generator.YoloLayer(
+        anchors,
+        classes,
+        box_type=box_type,
+        max_boxes=10,
+        use_class_agnostic_nms=use_class_agnostic_nms,
+        nms_version=nms_version,
+    )
 
     inputs = {}
     for key in input_shape:
       inputs[key] = tf.ones(input_shape[key], dtype=tf.float32)
 
     endpoints = layer(inputs)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/nn_blocks.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/nn_blocks.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,37 +1,38 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains common building blocks for yolo neural networks."""
+import functools
 from typing import Callable, List, Tuple
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.vision.ops import spatial_transform_ops
 
 
-class Identity(tf.keras.layers.Layer):
+class Identity(tf_keras.layers.Layer):
 
   def call(self, inputs):
     return inputs
 
 
-class ConvBN(tf.keras.layers.Layer):
+class ConvBN(tf_keras.layers.Layer):
   """ConvBN block.
 
   Modified Convolution layer to match that of the Darknet Library.
   The Layer is a standards combination of Conv BatchNorm Activation,
   however, the use of bias in the conv is determined by the use of batch
   normalization.
   Cross Stage Partial networks (CSPNets) were proposed in:
@@ -97,15 +98,15 @@
     self._kernel_size = kernel_size
     self._strides = strides
     self._padding = padding
     self._dilation_rate = dilation_rate
 
     if kernel_initializer == 'VarianceScaling':
       # to match pytorch initialization method
-      self._kernel_initializer = tf.keras.initializers.VarianceScaling(
+      self._kernel_initializer = tf_keras.initializers.VarianceScaling(
           scale=1 / 3, mode='fan_in', distribution='uniform')
     else:
       self._kernel_initializer = kernel_initializer
 
     self._bias_initializer = bias_initializer
     self._kernel_regularizer = kernel_regularizer
 
@@ -118,24 +119,21 @@
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
 
     ksize = self._kernel_size
     if not isinstance(ksize, List) and not isinstance(ksize, Tuple):
       ksize = [ksize]
     if use_separable_conv and not all([a == 1 for a in ksize]):
-      self._conv_base = tf.keras.layers.SeparableConv2D
+      self._conv_base = tf_keras.layers.SeparableConv2D
     else:
-      self._conv_base = tf.keras.layers.Conv2D
+      self._conv_base = tf_keras.layers.Conv2D
 
-    if use_sync_bn:
-      self._bn_base = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._bn_base = tf.keras.layers.BatchNormalization
+    self._bn_base = tf_keras.layers.BatchNormalization
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       # format: (batch_size, height, width, channels)
       self._bn_axis = -1
     else:
       # format: (batch_size, channels, width, height)
       self._bn_axis = 1
 
     # activation params
@@ -160,20 +158,21 @@
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
 
     if self._use_bn:
       self.bn = self._bn_base(
           momentum=self._norm_momentum,
           epsilon=self._norm_epsilon,
-          axis=self._bn_axis)
+          axis=self._bn_axis,
+          synchronized=self._use_sync_bn)
     else:
       self.bn = None
 
     if self._activation == 'leaky':
-      self._activation_fn = tf.keras.layers.LeakyReLU(alpha=self._leaky_alpha)
+      self._activation_fn = tf_keras.layers.LeakyReLU(alpha=self._leaky_alpha)
     elif self._activation == 'mish':
       self._activation_fn = lambda x: x * tf.math.tanh(tf.math.softplus(x))
     else:
       self._activation_fn = tf_utils.get_activation(self._activation)
 
   def call(self, x):
     x = self.conv(x)
@@ -235,15 +234,15 @@
         'activation': self._activation,
         'leaky_alpha': self._leaky_alpha
     }
     layer_config.update(super().get_config())
     return layer_config
 
 
-class DarkResidual(tf.keras.layers.Layer):
+class DarkResidual(tf_keras.layers.Layer):
   """Darknet block with Residual connection for Yolo v3 Backbone."""
 
   def __init__(self,
                filters=1,
                filter_scale=2,
                dilation_rate=1,
                kernel_initializer='VarianceScaling',
@@ -361,17 +360,17 @@
         filters=self._filters,
         kernel_size=(3, 3),
         strides=(1, 1),
         dilation_rate=self._dilation_rate,
         padding='same',
         **dark_conv_args)
 
-    self._shortcut = tf.keras.layers.Add()
+    self._shortcut = tf_keras.layers.Add()
     if self._sc_activation == 'leaky':
-      self._activation_fn = tf.keras.layers.LeakyReLU(alpha=self._leaky_alpha)
+      self._activation_fn = tf_keras.layers.LeakyReLU(alpha=self._leaky_alpha)
     elif self._sc_activation == 'mish':
       self._activation_fn = lambda x: x * tf.math.tanh(tf.math.softplus(x))
     else:
       self._activation_fn = tf_utils.get_activation(self._sc_activation)
     super().build(input_shape)
 
   def call(self, inputs, training=None):
@@ -399,21 +398,21 @@
         'sc_activation': self._sc_activation,
         'downsample': self._downsample,
     }
     layer_config.update(super().get_config())
     return layer_config
 
 
-class CSPTiny(tf.keras.layers.Layer):
+class CSPTiny(tf_keras.layers.Layer):
   """CSP Tiny layer.
 
   A Small size convolution block proposed in the CSPNet. The layer uses
   shortcuts, routing(concatnation), and feature grouping in order to improve
   gradient variablity and allow for high efficency, low power residual learning
-  for small networtf.keras.
+  for small networtf_keras.
   Cross Stage Partial networks (CSPNets) were proposed in:
   [1] Chien-Yao Wang, Hong-Yuan Mark Liao, I-Hau Yeh, Yueh-Hua Wu,
         Ping-Yang Chen, Jun-Wei Hsieh
       CSPNet: A New Backbone that can Enhance Learning Capability of CNN.
         arXiv:1911.11929
   """
 
@@ -530,15 +529,15 @@
         filters=self._filters,
         kernel_size=(1, 1),
         strides=(1, 1),
         padding='same',
         **dark_conv_args)
 
     if self._downsample:
-      self._maxpool = tf.keras.layers.MaxPool2D(
+      self._maxpool = tf_keras.layers.MaxPool2D(
           pool_size=2, strides=2, padding='same', data_format=None)
 
     super().build(input_shape)
 
   def call(self, inputs, training=None):
     x1 = self._convlayer1(inputs)
     x1_group = tf.split(x1, self._groups, axis=-1)[self._group_id]
@@ -548,15 +547,15 @@
     x5 = self._convlayer4(x4)
     x = tf.concat([x1, x5], axis=-1)  # csp connect
     if self._downsample:
       x = self._maxpool(x)
     return x, x5
 
 
-class CSPRoute(tf.keras.layers.Layer):
+class CSPRoute(tf_keras.layers.Layer):
   """CSPRoute block.
 
   Down sampling layer to take the place of down sampleing done in Residual
   networks. This is the first of 2 layers needed to convert any Residual Network
   model to a CSPNet. At the start of a new level change, this CSPRoute layer
   creates a learned identity that will act as a cross stage connection,
   that is used to inform the inputs to the next stage. It is called cross stage
@@ -687,15 +686,15 @@
     if self._downsample:
       inputs = self._conv1(inputs)
     y = self._conv2(inputs)
     x = self._conv3(inputs)
     return (x, y)
 
 
-class CSPConnect(tf.keras.layers.Layer):
+class CSPConnect(tf_keras.layers.Layer):
   """CSPConnect block.
 
   Sister Layer to the CSPRoute layer. Merges the partial feature stacks
   generated by the CSPDownsampling layer, and the finaly output of the
   residual stack. Suggested in the CSPNet paper.
   Cross Stage Partial networks (CSPNets) were proposed in:
   [1] Chien-Yao Wang, Hong-Yuan Mark Liao, I-Hau Yeh, Yueh-Hua Wu,
@@ -790,15 +789,15 @@
     }
     if not self._drop_first:
       self._conv1 = ConvBN(
           filters=self._filters // self._filter_scale,
           kernel_size=self._kernel_size,
           strides=(1, 1),
           **dark_conv_args)
-    self._concat = tf.keras.layers.Concatenate(axis=-1)
+    self._concat = tf_keras.layers.Concatenate(axis=-1)
 
     if not self._drop_final:
       self._conv2 = ConvBN(
           filters=self._filters,
           kernel_size=(1, 1),
           strides=(1, 1),
           **dark_conv_args)
@@ -811,15 +810,15 @@
 
     # skipped if drop final is true
     if not self._drop_final:
       x = self._conv2(x)
     return x
 
 
-class CSPStack(tf.keras.layers.Layer):
+class CSPStack(tf_keras.layers.Layer):
   """CSP Stack layer.
 
   CSP full stack, combines the route and the connect in case you dont want to
   jsut quickly wrap an existing callable or list of layers to
   make it a cross stage partial. Added for ease of use. you should be able
   to wrap any layer stack with a CSP independent of wether it belongs
   to the Darknet family. if filter_scale = 2, then the blocks in the stack
@@ -931,15 +930,15 @@
     x, x_route = self._route(inputs)
     for layer in self._model_to_wrap:
       x = layer(x)
     x = self._connect([x, x_route])
     return x
 
 
-class PathAggregationBlock(tf.keras.layers.Layer):
+class PathAggregationBlock(tf_keras.layers.Layer):
   """Path Aggregation block."""
 
   def __init__(self,
                filters=1,
                drop_final=True,
                kernel_initializer='VarianceScaling',
                bias_initializer='zeros',
@@ -1085,15 +1084,15 @@
     }
 
     if self._inverted:
       self._build_reversed(input_shape, dark_conv_args)
     else:
       self._build_regular(input_shape, dark_conv_args)
 
-    self._concat = tf.keras.layers.Concatenate()
+    self._concat = tf_keras.layers.Concatenate()
     super().build(input_shape)
 
   def _call_regular(self, inputs, training=None):
     input_to_convolve, input_to_concat = inputs
     x_prev = self._conv(input_to_convolve)
     if self._upsample:
       x_prev = spatial_transform_ops.nearest_upsampling(x_prev,
@@ -1121,53 +1120,53 @@
     # done this way to prevent confusion in the auto graph
     if self._inverted:
       return self._call_reversed(inputs, training=training)
     else:
       return self._call_regular(inputs, training=training)
 
 
-class SPP(tf.keras.layers.Layer):
+class SPP(tf_keras.layers.Layer):
   """Spatial Pyramid Pooling.
 
   A non-agregated SPP layer that uses Pooling.
   """
 
   def __init__(self, sizes, **kwargs):
     self._sizes = list(reversed(sizes))
     if not sizes:
-      raise ValueError('More than one maxpool should be specified in SSP block')
+      raise ValueError('More than one maxpool should be specified in SPP block')
     super().__init__(**kwargs)
 
   def build(self, input_shape):
     maxpools = []
     for size in self._sizes:
       maxpools.append(
-          tf.keras.layers.MaxPool2D(
+          tf_keras.layers.MaxPool2D(
               pool_size=(size, size),
               strides=(1, 1),
               padding='same',
               data_format=None))
     self._maxpools = maxpools
     super().build(input_shape)
 
   def call(self, inputs, training=None):
     outputs = []
     for maxpool in self._maxpools:
       outputs.append(maxpool(inputs))
     outputs.append(inputs)
-    concat_output = tf.keras.layers.concatenate(outputs)
+    concat_output = tf_keras.layers.concatenate(outputs)
     return concat_output
 
   def get_config(self):
     layer_config = {'sizes': self._sizes}
     layer_config.update(super().get_config())
     return layer_config
 
 
-class SAM(tf.keras.layers.Layer):
+class SAM(tf_keras.layers.Layer):
   """Spatial Attention Model.
 
   [1] Sanghyun Woo, Jongchan Park, Joon-Young Lee, In So Kweon
   CBAM: Convolutional Block Attention Module. arXiv:1807.06521
 
   implementation of the Spatial Attention Model (SAM)
   """
@@ -1221,15 +1220,15 @@
     super().__init__(**kwargs)
 
   def build(self, input_shape):
     if self._filters == -1:
       self._filters = input_shape[-1]
     self._conv = ConvBN(filters=self._filters, **self.dark_conv_args)
     if self._output_activation == 'leaky':
-      self._activation_fn = tf.keras.layers.LeakyReLU(alpha=self._leaky_alpha)
+      self._activation_fn = tf_keras.layers.LeakyReLU(alpha=self._leaky_alpha)
     elif self._output_activation == 'mish':
       self._activation_fn = lambda x: x * tf.math.tanh(tf.math.softplus(x))
     else:
       self._activation_fn = tf_utils.get_activation(self._output_activation)
 
   def call(self, inputs, training=None):
     if self._use_pooling:
@@ -1239,15 +1238,15 @@
     else:
       input_maps = inputs
 
     attention_mask = self._conv(input_maps)
     return self._activation_fn(inputs * attention_mask)
 
 
-class CAM(tf.keras.layers.Layer):
+class CAM(tf_keras.layers.Layer):
   """Channel Attention Model.
 
   [1] Sanghyun Woo, Jongchan Park, Joon-Young Lee, In So Kweon
   CBAM: Convolutional Block Attention Module. arXiv:1807.06521
 
   Implementation of the Channel Attention Model (CAM)
   """
@@ -1266,24 +1265,20 @@
                mlp_activation='linear',
                activation='sigmoid',
                leaky_alpha=0.1,
                **kwargs):
 
     self._reduction_ratio = reduction_ratio
 
-    # use_pooling
-    if use_sync_bn:
-      self._bn = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._bn = tf.keras.layers.BatchNormalization
-
     if not use_bn:
       self._bn = Identity
       self._bn_args = {}
     else:
+      self._bn = functools.partial(
+          tf_keras.layers.BatchNormalization, synchronized=use_sync_bn)
       self._bn_args = {
           'momentum': norm_momentum,
           'epsilon': norm_epsilon,
       }
 
     self._mlp_args = {
         'use_bias': use_bias,
@@ -1298,26 +1293,26 @@
     self._activation = activation
 
     super().__init__(**kwargs)
 
   def build(self, input_shape):
     self._filters = input_shape[-1]
 
-    self._mlp = tf.keras.Sequential([
-        tf.keras.layers.Dense(self._filters, **self._mlp_args),
+    self._mlp = tf_keras.Sequential([
+        tf_keras.layers.Dense(self._filters, **self._mlp_args),
         self._bn(**self._bn_args),
-        tf.keras.layers.Dense(
+        tf_keras.layers.Dense(
             int(self._filters * self._reduction_ratio), **self._mlp_args),
         self._bn(**self._bn_args),
-        tf.keras.layers.Dense(self._filters, **self._mlp_args),
+        tf_keras.layers.Dense(self._filters, **self._mlp_args),
         self._bn(**self._bn_args),
     ])
 
     if self._activation == 'leaky':
-      self._activation_fn = tf.keras.layers.LeakyReLU(alpha=self._leaky_alpha)
+      self._activation_fn = tf_keras.layers.LeakyReLU(alpha=self._leaky_alpha)
     elif self._activation == 'mish':
       self._activation_fn = lambda x: x * tf.math.tanh(tf.math.softplus(x))
     else:
       self._activation_fn = tf_utils.get_activation(self._activation)
 
   def call(self, inputs, training=None):
     depth_max = self._mlp(tf.reduce_max(inputs, axis=(1, 2)))
@@ -1326,15 +1321,15 @@
 
     channel_mask = tf.expand_dims(channel_mask, axis=1)
     attention_mask = tf.expand_dims(channel_mask, axis=1)
 
     return inputs * attention_mask
 
 
-class CBAM(tf.keras.layers.Layer):
+class CBAM(tf_keras.layers.Layer):
   """Convolutional Block Attention Module.
 
   [1] Sanghyun Woo, Jongchan Park, Joon-Young Lee, In So Kweon
   CBAM: Convolutional Block Attention Module. arXiv:1807.06521
 
   implementation of the Convolution Block Attention Module (CBAM)
   """
@@ -1399,15 +1394,15 @@
     self._cam = CAM(**self._cam_args)
     self._sam = SAM(**self._sam_args)
 
   def call(self, inputs, training=None):
     return self._sam(self._cam(inputs))
 
 
-class DarkRouteProcess(tf.keras.layers.Layer):
+class DarkRouteProcess(tf_keras.layers.Layer):
   """Dark Route Process block.
 
   Process darknet outputs and connect back bone to head more generalizably
   Abstracts repetition of DarkConv objects that is common in YOLO.
 
   It is used like the following:
 
@@ -1697,22 +1692,264 @@
   def call(self, inputs, training=None):
     if self._csp_stack > 0:
       return self._call_csp(inputs, training=training)
     else:
       return self._call_regular(inputs)
 
 
-class Reorg(tf.keras.layers.Layer):
+class Reorg(tf_keras.layers.Layer):
   """Splits a high resolution image into 4 lower resolution images.
 
   Used in YOLOR to process very high resolution inputs efficiently.
   for example an input image of [1280, 1280, 3] will become [640, 640, 12],
   the images are sampled in such a way that the spatial resoltion is
   retained.
   """
 
   def call(self, x, training=None):
     return tf.concat([
         x[..., ::2, ::2, :], x[..., 1::2, ::2, :], x[..., ::2, 1::2, :],
         x[..., 1::2, 1::2, :]
     ],
                      axis=-1)
+
+
+class SPPCSPC(tf_keras.layers.Layer):
+  """Cross-stage partial network with spatial pyramid pooling.
+
+  This module is used in YOLOv7 to process backbone feature at the highest
+  level. SPPCSPC uses fusion-first CSP block and it uses SPP within
+  the dense block.
+  """
+
+  def __init__(
+      self,
+      filters,
+      pool_sizes=(5, 9, 13),
+      scale=0.5,
+      kernel_initializer='VarianceScaling',
+      bias_initializer='zeros',
+      kernel_regularizer=None,
+      bias_regularizer=None,
+      use_separable_conv=False,
+      use_bn=True,
+      use_sync_bn=False,
+      norm_momentum=0.99,
+      norm_epsilon=0.001,
+      activation='swish',
+      **kwargs):
+    """Initializes SPPCSPC block.
+
+    Args:
+      filters: an `int` for filters used in Conv2D.
+      pool_sizes: a tuple of `int` for maxpool layer used in the dense block.
+      scale: a `float` scale that applies on the filters to determine the
+        internal Conv2D filters within CSP block.
+      kernel_initializer: string to indicate which function to use to initialize
+        weights in Conv2D.
+      bias_initializer: string to indicate which function to use to initialize
+        bias.
+      kernel_regularizer: string to indicate which function to use to
+        regularizer weights in Conv2D.
+      bias_regularizer: string to indicate which function to use to regularizer
+        bias.
+      use_separable_conv: `bool` wether to use separable convs.
+      use_bn: boolean for whether to use batch normalization.
+      use_sync_bn: boolean for whether sync batch normalization statistics
+        of all batch norm layers to the models global statistics
+        (across all input batches).
+      norm_momentum: float for moment to use for batch normalization.
+      norm_epsilon: float for batch normalization epsilon.
+      activation: string to indicate the activation function used after each
+        Conv2D.
+      **kwargs: other keyword arguments.
+    """
+    super().__init__(**kwargs)
+    self._filters = filters
+    self._pool_sizes = pool_sizes
+    self._scale = scale
+    self._kernel_initializer = kernel_initializer
+    self._bias_initializer = bias_initializer
+    self._kernel_regularizer = kernel_regularizer
+    self._bias_regularizer = bias_regularizer
+    self._use_separable_conv = use_separable_conv
+    self._use_bn = use_bn
+    self._use_sync_bn = use_sync_bn
+    self._norm_momentum = norm_momentum
+    self._norm_epsilon = norm_epsilon
+    self._activation = activation
+
+  def build(self, input_shape):
+    filters = self._filters * 2 * self._scale
+    conv_op = functools.partial(
+        ConvBN,
+        activation=self._activation,
+        use_separable_conv=self._use_separable_conv,
+        kernel_initializer=self._kernel_initializer,
+        kernel_regularizer=self._kernel_regularizer,
+        bias_initializer=self._bias_initializer,
+        bias_regularizer=self._bias_regularizer,
+        use_bn=self._use_bn,
+        use_sync_bn=self._use_sync_bn,
+        norm_momentum=self._norm_momentum,
+        norm_epsilon=self._norm_epsilon,
+    )
+    self._conv1_1 = conv_op(filters, kernel_size=1, strides=1)
+    self._conv1_2 = conv_op(filters, kernel_size=3, strides=1)
+    self._conv1_3 = conv_op(filters, kernel_size=1, strides=1)
+    self._poolings = [
+        tf_keras.layers.MaxPooling2D(pool_size, strides=1, padding='same')
+        for pool_size in self._pool_sizes
+    ]
+    self._conv1_4 = conv_op(filters, kernel_size=1, strides=1)
+    self._conv1_5 = conv_op(filters, kernel_size=3, strides=1)
+
+    self._conv2_1 = conv_op(filters, kernel_size=1, strides=1)
+
+    self._merge_conv = conv_op(self._filters, kernel_size=1, strides=1)
+    super().build(input_shape)
+
+  def call(self, inputs, training=None):
+    x = self._conv1_3(self._conv1_2(self._conv1_1(inputs)))
+    x = self._conv1_5(
+        self._conv1_4(
+            tf.concat([x] + [pooling(x) for pooling in self._poolings], -1)
+        )
+    )
+    y = self._conv2_1(inputs)
+    return self._merge_conv(tf.concat([x, y], axis=-1))
+
+  def get_config(self):
+    # used to store/share parameters to reconstruct the model
+    layer_config = {
+        'filters': self._filters,
+        'pool_sizes': self._pool_sizes,
+        'scale': self._scale,
+        'kernel_initializer': self._kernel_initializer,
+        'bias_initializer': self._bias_initializer,
+        'kernel_regularizer': self._kernel_regularizer,
+        'bias_regularizer': self._bias_regularizer,
+        'use_bn': self._use_bn,
+        'use_sync_bn': self._use_sync_bn,
+        'use_separable_conv': self._use_separable_conv,
+        'norm_momentum': self._norm_momentum,
+        'norm_epsilon': self._norm_epsilon,
+        'activation': self._activation,
+    }
+    layer_config.update(super().get_config())
+    return layer_config
+
+
+class RepConv(tf_keras.layers.Layer):
+  """Represented convolution.
+
+  https://arxiv.org/abs/2101.03697
+  """
+
+  def __init__(
+      self,
+      filters,
+      kernel_size=3,
+      strides=1,
+      padding='same',
+      activation='swish',
+      use_separable_conv=False,
+      use_sync_bn=False,
+      norm_momentum=0.99,
+      norm_epsilon=0.001,
+      kernel_initializer='VarianceScaling',
+      kernel_regularizer=None,
+      bias_initializer='zeros',
+      bias_regularizer=None,
+      **kwargs
+  ):
+    """Initializes RepConv layer.
+
+    Args:
+      filters: integer for output depth, or the number of features to learn.
+      kernel_size: integer or tuple for the shape of the weight matrix or kernel
+        to learn.
+      strides: integer of tuple how much to move the kernel after each kernel
+        use.
+      padding: string 'valid' or 'same', if same, then pad the image, else do
+        not.
+      activation: string or None for activation function to use in layer, if
+        None activation is replaced by linear.
+      use_separable_conv: `bool` wether to use separable convs.
+      use_sync_bn: boolean for whether sync batch normalization statistics of
+        all batch norm layers to the models global statistics (across all input
+        batches).
+      norm_momentum: float for moment to use for batch normalization.
+      norm_epsilon: float for batch normalization epsilon.
+      kernel_initializer: string to indicate which function to use to initialize
+        weights.
+      kernel_regularizer: string to indicate which function to use to
+        regularizer weights.
+      bias_initializer: string to indicate which function to use to initialize
+        bias.
+      bias_regularizer: string to indicate which function to use to regularizer
+        bias.
+      **kwargs: other keyword arguments.
+    """
+    super().__init__(**kwargs)
+    self._filters = filters
+    self._kernel_size = kernel_size
+    self._strides = strides
+    self._padding = padding
+    self._activation = activation
+    self._use_separable_conv = use_separable_conv
+    self._use_sync_bn = use_sync_bn
+    self._norm_momentum = norm_momentum
+    self._norm_epsilon = norm_epsilon
+    self._kernel_initializer = kernel_initializer
+    self._kernel_regularizer = kernel_regularizer
+    self._bias_initializer = bias_initializer
+    self._bias_regularizer = bias_regularizer
+    # For deploy.
+    self._fuse = False
+
+  def build(self, input_shape):
+    conv_op = functools.partial(
+        tf_keras.layers.SeparableConv2D
+        if self._use_separable_conv
+        else tf_keras.layers.Conv2D,
+        filters=self._filters,
+        strides=self._strides,
+        padding=self._padding,
+        kernel_initializer=self._kernel_initializer,
+        kernel_regularizer=self._kernel_regularizer,
+        bias_initializer=self._bias_initializer,
+        bias_regularizer=self._bias_regularizer,
+    )
+    bn_op = functools.partial(
+        tf_keras.layers.BatchNormalization,
+        synchronized=self._use_sync_bn,
+        momentum=self._norm_momentum,
+        epsilon=self._norm_epsilon,
+    )
+
+    self._activation_fn = tf_utils.get_activation(self._activation)
+    self._rbr_reparam = conv_op(kernel_size=self._kernel_size, use_bias=True)
+    if input_shape[-1] == self._filters and self._strides == 1:
+      self._rbr_identity = bn_op()
+    self._rbr_dense = conv_op(kernel_size=self._kernel_size, use_bias=False)
+    self._rbr_dense_bn = bn_op()
+    self._rbr_1x1 = conv_op(kernel_size=1, use_bias=False)
+    self._rbr_1x1_bn = bn_op()
+
+  def call(self, inputs, training=None):
+    if self._fuse:
+      return self._activation_fn(self._rbr_reparam(inputs))
+
+    id_out = 0
+    if hasattr(self, '_rbr_identity'):
+      id_out = self._rbr_identity(inputs)
+
+    x = self._rbr_dense_bn(self._rbr_dense(inputs))
+    y = self._rbr_1x1_bn(self._rbr_1x1(inputs))
+    return self._activation_fn(x + y + id_out)
+
+  def fuse(self):
+    if self._fuse:
+      return
+    # TODO(b/264495198): Implement fuse for RepConv.
+    raise NotImplementedError()
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/layers/nn_blocks_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/layers/nn_blocks_test.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,41 +10,41 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.modeling.layers import nn_blocks
 
 
 class CSPConnectTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(('same', 224, 224, 64, 1),
                                   ('downsample', 224, 224, 64, 2))
   def test_pass_through(self, width, height, filters, mod):
-    x = tf.keras.Input(shape=(width, height, filters))
+    x = tf_keras.Input(shape=(width, height, filters))
     test_layer = nn_blocks.CSPRoute(filters=filters, filter_scale=mod)
     test_layer2 = nn_blocks.CSPConnect(filters=filters, filter_scale=mod)
     outx, px = test_layer(x)
     outx = test_layer2([outx, px])
     print(outx)
     print(outx.shape.as_list())
     self.assertAllEqual(
         outx.shape.as_list(),
         [None, np.ceil(width // 2),
          np.ceil(height // 2), (filters)])
 
   @parameterized.named_parameters(('same', 224, 224, 64, 1),
                                   ('downsample', 224, 224, 128, 2))
   def test_gradient_pass_though(self, filters, width, height, mod):
-    loss = tf.keras.losses.MeanSquaredError()
-    optimizer = tf.keras.optimizers.SGD()
+    loss = tf_keras.losses.MeanSquaredError()
+    optimizer = tf_keras.optimizers.SGD()
     test_layer = nn_blocks.CSPRoute(filters, filter_scale=mod)
     path_layer = nn_blocks.CSPConnect(filters, filter_scale=mod)
 
     init = tf.random_normal_initializer()
     x = tf.Variable(
         initial_value=init(shape=(1, width, height, filters), dtype=tf.float32))
     y = tf.Variable(
@@ -64,29 +64,29 @@
 
 
 class CSPRouteTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(('same', 224, 224, 64, 1),
                                   ('downsample', 224, 224, 64, 2))
   def test_pass_through(self, width, height, filters, mod):
-    x = tf.keras.Input(shape=(width, height, filters))
+    x = tf_keras.Input(shape=(width, height, filters))
     test_layer = nn_blocks.CSPRoute(filters=filters, filter_scale=mod)
     outx, _ = test_layer(x)
     print(outx)
     print(outx.shape.as_list())
     self.assertAllEqual(
         outx.shape.as_list(),
         [None, np.ceil(width // 2),
          np.ceil(height // 2), (filters / mod)])
 
   @parameterized.named_parameters(('same', 224, 224, 64, 1),
                                   ('downsample', 224, 224, 128, 2))
   def test_gradient_pass_though(self, filters, width, height, mod):
-    loss = tf.keras.losses.MeanSquaredError()
-    optimizer = tf.keras.optimizers.SGD()
+    loss = tf_keras.losses.MeanSquaredError()
+    optimizer = tf_keras.optimizers.SGD()
     test_layer = nn_blocks.CSPRoute(filters, filter_scale=mod)
     path_layer = nn_blocks.CSPConnect(filters, filter_scale=mod)
 
     init = tf.random_normal_initializer()
     x = tf.Variable(
         initial_value=init(shape=(1, width, height, filters), dtype=tf.float32))
     y = tf.Variable(
@@ -111,15 +111,15 @@
       ('valid', (3, 3), 'valid', (1, 1)), ('same', (3, 3), 'same', (1, 1)),
       ('downsample', (3, 3), 'same', (2, 2)), ('test', (1, 1), 'valid', (1, 1)))
   def test_pass_through(self, kernel_size, padding, strides):
     if padding == 'same':
       pad_const = 1
     else:
       pad_const = 0
-    x = tf.keras.Input(shape=(224, 224, 3))
+    x = tf_keras.Input(shape=(224, 224, 3))
     test_layer = nn_blocks.ConvBN(
         filters=64,
         kernel_size=kernel_size,
         padding=padding,
         strides=strides,
         trainable=False)
     outx = test_layer(x)
@@ -130,16 +130,16 @@
         int((224 - kernel_size[1] + (2 * pad_const)) / strides[1] + 1), 64
     ]
     print(test)
     self.assertAllEqual(outx.shape.as_list(), test)
 
   @parameterized.named_parameters(('filters', 3))
   def test_gradient_pass_though(self, filters):
-    loss = tf.keras.losses.MeanSquaredError()
-    optimizer = tf.keras.optimizers.SGD()
+    loss = tf_keras.losses.MeanSquaredError()
+    optimizer = tf_keras.optimizers.SGD()
     with tf.device('/CPU:0'):
       test_layer = nn_blocks.ConvBN(filters, kernel_size=(3, 3), padding='same')
 
     init = tf.random_normal_initializer()
     x = tf.Variable(
         initial_value=init(shape=(1, 224, 224, 3), dtype=tf.float32))
     y = tf.Variable(
@@ -158,30 +158,30 @@
   @parameterized.named_parameters(('same', 224, 224, 64, False),
                                   ('downsample', 223, 223, 32, True),
                                   ('oddball', 223, 223, 32, False))
   def test_pass_through(self, width, height, filters, downsample):
     mod = 1
     if downsample:
       mod = 2
-    x = tf.keras.Input(shape=(width, height, filters))
+    x = tf_keras.Input(shape=(width, height, filters))
     test_layer = nn_blocks.DarkResidual(filters=filters, downsample=downsample)
     outx = test_layer(x)
     print(outx)
     print(outx.shape.as_list())
     self.assertAllEqual(
         outx.shape.as_list(),
         [None, np.ceil(width / mod),
          np.ceil(height / mod), filters])
 
   @parameterized.named_parameters(('same', 64, 224, 224, False),
                                   ('downsample', 32, 223, 223, True),
                                   ('oddball', 32, 223, 223, False))
   def test_gradient_pass_though(self, filters, width, height, downsample):
-    loss = tf.keras.losses.MeanSquaredError()
-    optimizer = tf.keras.optimizers.SGD()
+    loss = tf_keras.losses.MeanSquaredError()
+    optimizer = tf_keras.optimizers.SGD()
     test_layer = nn_blocks.DarkResidual(filters, downsample=downsample)
 
     if downsample:
       mod = 2
     else:
       mod = 1
 
@@ -205,27 +205,27 @@
 
 class DarkSppTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(('RouteProcessSpp', 224, 224, 3, [5, 9, 13]),
                                   ('test1', 300, 300, 10, [2, 3, 4, 5]),
                                   ('test2', 256, 256, 5, [10]))
   def test_pass_through(self, width, height, channels, sizes):
-    x = tf.keras.Input(shape=(width, height, channels))
+    x = tf_keras.Input(shape=(width, height, channels))
     test_layer = nn_blocks.SPP(sizes=sizes)
     outx = test_layer(x)
     self.assertAllEqual(outx.shape.as_list(),
                         [None, width, height, channels * (len(sizes) + 1)])
     return
 
   @parameterized.named_parameters(('RouteProcessSpp', 224, 224, 3, [5, 9, 13]),
                                   ('test1', 300, 300, 10, [2, 3, 4, 5]),
                                   ('test2', 256, 256, 5, [10]))
   def test_gradient_pass_though(self, width, height, channels, sizes):
-    loss = tf.keras.losses.MeanSquaredError()
-    optimizer = tf.keras.optimizers.SGD()
+    loss = tf_keras.losses.MeanSquaredError()
+    optimizer = tf_keras.optimizers.SGD()
     test_layer = nn_blocks.SPP(sizes=sizes)
 
     init = tf.random_normal_initializer()
     x = tf.Variable(
         initial_value=init(
             shape=(1, width, height, channels), dtype=tf.float32))
     y = tf.Variable(
@@ -245,15 +245,15 @@
 
 class DarkRouteProcessTest(tf.test.TestCase, parameterized.TestCase):
 
   @parameterized.named_parameters(
       ('test1', 224, 224, 64, 7, False), ('test2', 223, 223, 32, 3, False),
       ('tiny', 223, 223, 16, 1, False), ('spp', 224, 224, 64, 7, False))
   def test_pass_through(self, width, height, filters, repetitions, spp):
-    x = tf.keras.Input(shape=(width, height, filters))
+    x = tf_keras.Input(shape=(width, height, filters))
     test_layer = nn_blocks.DarkRouteProcess(
         filters=filters, repetitions=repetitions, insert_spp=spp)
     outx = test_layer(x)
     self.assertLen(outx, 2, msg='len(outx) != 2')
     if repetitions == 1:
       filter_y1 = filters
     else:
@@ -266,16 +266,16 @@
         msg='Output of a DarkRouteProcess layer has an odd number of filters')
     self.assertAllEqual(outx[0].shape.as_list(), [None, width, height, filters])
 
   @parameterized.named_parameters(
       ('test1', 224, 224, 64, 7, False), ('test2', 223, 223, 32, 3, False),
       ('tiny', 223, 223, 16, 1, False), ('spp', 224, 224, 64, 7, False))
   def test_gradient_pass_though(self, width, height, filters, repetitions, spp):
-    loss = tf.keras.losses.MeanSquaredError()
-    optimizer = tf.keras.optimizers.SGD()
+    loss = tf_keras.losses.MeanSquaredError()
+    optimizer = tf_keras.optimizers.SGD()
     test_layer = nn_blocks.DarkRouteProcess(
         filters=filters, repetitions=repetitions, insert_spp=spp)
 
     if repetitions == 1:
       filter_y1 = filters
     else:
       filter_y1 = filters // 2
@@ -297,9 +297,84 @@
                          test_layer.trainable_variables)
     optimizer.apply_gradients(zip(grad, test_layer.trainable_variables))
 
     self.assertNotIn(None, grad)
     return
 
 
+class SPPCSPCTest(tf.test.TestCase, parameterized.TestCase):
+
+  @parameterized.named_parameters(('SPPCSPC', 224, 224, 8, [5, 9, 13], 0.5),
+                                  ('test1', 300, 300, 32, [2, 3, 4, 5], 1.0),
+                                  ('test2', 256, 256, 16, [10], 2.0))
+  def test_pass_through(self, width, height, filters, pool_sizes, scale):
+    x = tf_keras.Input(shape=(width, height, filters))
+    test_layer = nn_blocks.SPPCSPC(filters, pool_sizes, scale)
+    out = test_layer(x)
+    self.assertAllEqual(out.shape.as_list(), [None, width, height, filters])
+
+  @parameterized.named_parameters(('SPPCSPC', 224, 224, 8, [5, 9, 13], 0.5),
+                                  ('test1', 300, 300, 32, [2, 3, 4, 5], 1.0),
+                                  ('test2', 256, 256, 16, [10], 2.0))
+  def test_gradient_pass_though(
+      self, width, height, filters, pool_sizes, scale):
+    loss = tf_keras.losses.MeanSquaredError()
+    optimizer = tf_keras.optimizers.SGD()
+    test_layer = nn_blocks.SPPCSPC(filters, pool_sizes, scale)
+
+    init = tf.random_normal_initializer()
+    x = tf.Variable(
+        initial_value=init(shape=(1, width, height, filters), dtype=tf.float32))
+    y = tf.Variable(
+        initial_value=init(shape=(1, width, height, filters), dtype=tf.float32))
+
+    with tf.GradientTape() as tape:
+      x_hat = test_layer(x)
+      grad_loss = loss(x_hat, y)
+    grad = tape.gradient(grad_loss, test_layer.trainable_variables)
+    optimizer.apply_gradients(zip(grad, test_layer.trainable_variables))
+
+    self.assertNotIn(None, grad)
+    return
+
+
+class RepConvTest(tf.test.TestCase, parameterized.TestCase):
+
+  @parameterized.named_parameters(('RepConv', 224, 224, 8, 1),
+                                  ('test1', 300, 300, 32, 2),
+                                  ('test2', 256, 256, 16, 4))
+  def test_pass_through(self, width, height, filters, strides):
+    x = tf_keras.Input(shape=(width, height, filters))
+    test_layer = nn_blocks.RepConv(filters, strides=strides)
+    out = test_layer(x)
+    self.assertAllEqual(out.shape.as_list(),
+                        [None, width // strides, height // strides, filters])
+
+  @parameterized.named_parameters(('RepConv', 224, 224, 8, 1),
+                                  ('test1', 300, 300, 32, 2),
+                                  ('test2', 256, 256, 16, 4))
+  def test_gradient_pass_though(self, width, height, filters, strides):
+    loss = tf_keras.losses.MeanSquaredError()
+    optimizer = tf_keras.optimizers.SGD()
+    test_layer = nn_blocks.RepConv(filters, strides=strides)
+
+    init = tf.random_normal_initializer()
+    x = tf.Variable(
+        initial_value=init(shape=(1, width, height, filters), dtype=tf.float32))
+    y = tf.Variable(
+        initial_value=init(
+            shape=(1, width // strides, height // strides, filters),
+            dtype=tf.float32,
+        )
+    )
+
+    with tf.GradientTape() as tape:
+      x_hat = test_layer(x)
+      grad_loss = loss(x_hat, y)
+    grad = tape.gradient(grad_loss, test_layer.trainable_variables)
+    optimizer.apply_gradients(zip(grad, test_layer.trainable_variables))
+
+    self.assertNotIn(None, grad)
+    return
+
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/modeling/yolo_model.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/modeling/yolo_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,33 +10,33 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Yolo models."""
 
-from typing import Mapping, Union
-import tensorflow as tf
+from typing import Mapping, Union, Any, Dict
+import tensorflow as tf, tf_keras
 from official.projects.yolo.modeling.layers import nn_blocks
 
 
-class Yolo(tf.keras.Model):
+class Yolo(tf_keras.Model):
   """The YOLO model class."""
 
   def __init__(self,
                backbone,
                decoder,
                head,
                detection_generator,
                **kwargs):
     """Detection initialization function.
 
     Args:
-      backbone: `tf.keras.Model` a backbone network.
-      decoder: `tf.keras.Model` a decoder network.
+      backbone: `tf_keras.Model` a backbone network.
+      decoder: `tf_keras.Model` a decoder network.
       head: `RetinaNetHead`, the RetinaNet head.
       detection_generator: the detection generator.
       **kwargs: keyword arguments to be passed.
     """
     super(Yolo, self).__init__(**kwargs)
 
     self._config_dict = {
@@ -48,17 +48,19 @@
 
     # model components
     self._backbone = backbone
     self._decoder = decoder
     self._head = head
     self._detection_generator = detection_generator
     self._fused = False
-    return
 
-  def call(self, inputs, training=False):
+  def call(self,
+           inputs: tf.Tensor,
+           training: bool = None,
+           mask: Any = None) -> Dict[str, tf.Tensor]:
     maps = self.backbone(inputs)
     decoded_maps = self.decoder(maps)
     raw_predictions = self.head(decoded_maps)
     if training:
       return {'raw_output': raw_predictions}
     else:
       # Post-processing.
@@ -87,15 +89,15 @@
 
   @classmethod
   def from_config(cls, config):
     return cls(**config)
 
   @property
   def checkpoint_items(
-      self) -> Mapping[str, Union[tf.keras.Model, tf.keras.layers.Layer]]:
+      self) -> Mapping[str, Union[tf_keras.Model, tf_keras.layers.Layer]]:
     """Returns a dictionary of items to be additionally checkpointed."""
     items = dict(backbone=self.backbone, head=self.head)
     if self.decoder is not None:
       items.update(decoder=self.decoder)
     return items
 
   def fuse(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/teams/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/anchor.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/anchor.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Yolo Anchor labler."""
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import box_ops
 from official.projects.yolo.ops import loss_utils
 from official.projects.yolo.ops import preprocessing_ops
 
 INF = 10000000
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/box_ops.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/box_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Yolo box ops."""
 import math
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.projects.yolo.ops import math_ops
 
 
 def yxyx_to_xcycwh(box: tf.Tensor):
   """Converts boxes from yxyx to x_center, y_center, width, height.
 
   Args:
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/box_ops_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/box_ops_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """box_ops tests."""
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import box_ops
 
 
 class InputUtilsTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters((1), (4))
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/kmeans_anchors.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/kmeans_anchors.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """K-means for generation of anchor boxes for YOLO."""
 import logging
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import input_reader
 from official.projects.yolo.ops import box_ops
 
 
 def _iou(x, centroids_x, iou_type="iou"):
   """Compute the WH IOU between the ground truths and the centroids."""
@@ -286,15 +286,15 @@
         to get an even distribution of anchor boxes across FPN levels.
       box_generation_mode: `str` for the type of kmeans to use when generating
         anchor boxes. Must be in the set {across_level, per_level}.
       image_resolution: `List[int]` for the resolution of the boxes to run
         k-means for.
       num_samples: `Optional[int]` for the number of samples to use for kmeans,
         typically about 5000 samples are all that are needed, but for the best
-        results use None to run the entire dataset.
+        results use -1 to run the entire dataset.
 
     Returns:
       boxes: `List[List[int]]` of shape [k, 2] for the anchor boxes to use for
         box predicitons.
     """
     self._is_training = False
     dataset = super().read()
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/kmeans_anchors_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/kmeans_anchors_test.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """kmeans_test tests."""
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import kmeans_anchors
 
 
 class KMeansTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters((9, 3, 100))
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/loss_utils.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/loss_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Yolo loss utility functions."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import box_ops
 from official.projects.yolo.ops import math_ops
 
 
 @tf.custom_gradient
 def sigmoid_bce(y, x_prime, label_smoothing):
@@ -39,15 +39,15 @@
     dx = dloss * dsigmoid
 
   This derivative can be reduced simply to:
     dx = (-y + x)
 
   This simplification is used by the darknet library in order to improve
   training stability. The gradient is almost the same
-  as tf.keras.losses.binary_crossentropy but varies slightly and
+  as tf_keras.losses.binary_crossentropy but varies slightly and
   yields different performance.
 
   Args:
     y: `Tensor` holding ground truth data.
     x_prime: `Tensor` holding the predictions prior to application of the
       sigmoid operation.
     label_smoothing: float value between 0.0 and 1.0 indicating the amount of
@@ -167,15 +167,15 @@
 
     Args:
       anchors: A `List[List[int]]` for the anchor boxes that are used in the
         model at all levels.
       scale_anchors: An `int` for how much to scale this level to get the
         original input shape.
     """
-    self.dtype = tf.keras.backend.floatx()
+    self.dtype = tf_keras.backend.floatx()
     self._scale_anchors = scale_anchors
     self._anchors = tf.convert_to_tensor(anchors)
     return
 
   def _build_grid_points(self, lheight, lwidth, anchors, dtype):
     """Generate a grid of fixed grid edges for box center decoding."""
     with tf.name_scope('center_grid'):
@@ -202,15 +202,15 @@
     return anchors
 
   def _extend_batch(self, grid, batch_size):
     return tf.tile(grid, [batch_size, 1, 1, 1, 1])
 
   def __call__(self, height, width, batch_size, dtype=None):
     if dtype is None:
-      self.dtype = tf.keras.backend.floatx()
+      self.dtype = tf_keras.backend.floatx()
     else:
       self.dtype = dtype
     grid_points = self._build_grid_points(height, width, self._anchors,
                                           self.dtype)
     anchor_grid = self._build_anchor_grid(
         height, width,
         tf.cast(self._anchors, self.dtype) /
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/math_ops.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/math_ops.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """A set of private math operations used to safely implement the YOLO loss."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def rm_nan_inf(x, val=0.0):
   """Remove nan and infinity.
 
   Args:
     x: any `Tensor` of any type.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/mosaic.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/mosaic.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,61 +11,69 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Mosaic op."""
 import random
 
-import tensorflow as tf
-import tensorflow_addons as tfa
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import preprocessing_ops
+from official.vision.ops import augment
 from official.vision.ops import box_ops
 from official.vision.ops import preprocess_ops
 
 
 class Mosaic:
-  """Stitch together sets of 4 images to generate samples with more boxes."""
+  """Stitch together sets of 4 (2x2) or 9 (3x3) images to generate samples with more boxes."""
 
-  def __init__(self,
-               output_size,
-               mosaic_frequency=1.0,
-               mixup_frequency=0.0,
-               letter_box=True,
-               jitter=0.0,
-               mosaic_crop_mode='scale',
-               mosaic_center=0.25,
-               aug_scale_min=1.0,
-               aug_scale_max=1.0,
-               aug_rand_angle=0.0,
-               aug_rand_perspective=0.0,
-               aug_rand_translate=0.0,
-               random_pad=False,
-               random_flip=False,
-               area_thresh=0.1,
-               pad_value=preprocessing_ops.PAD_VALUE,
-               seed=None):
+  def __init__(
+      self,
+      output_size,
+      mosaic_frequency=1.0,
+      mosaic9_frequency=0.0,
+      mixup_frequency=0.0,
+      letter_box=True,
+      jitter=0.0,
+      mosaic_crop_mode='scale',
+      mosaic_center=0.25,
+      mosaic9_center=0.33,
+      aug_scale_min=1.0,
+      aug_scale_max=1.0,
+      aug_rand_angle=0.0,
+      aug_rand_perspective=0.0,
+      aug_rand_translate=0.0,
+      random_pad=False,
+      random_flip=False,
+      area_thresh=0.1,
+      pad_value=preprocessing_ops.PAD_VALUE,
+      seed=None,
+  ):
     """Initializes parameters for mosaic.
 
     Args:
       output_size: `Tensor` or `List` for [height, width] of output image.
       mosaic_frequency: `float` indicating how often to apply mosaic.
+      mosaic9_frequency: `float` indicating how often to apply a 3x3 mosaic
+        instead of 2x2.
       mixup_frequency: `float` indicating how often to apply mixup.
       letter_box: `boolean` indicating whether upon start of the datapipeline
         regardless of the preprocessing ops that are used, the aspect ratio of
         the images should be preserved.
       jitter: `float` for the maximum change in aspect ratio expected in each
         preprocessing step.
       mosaic_crop_mode: `str` the type of mosaic to apply. The options are
         {crop, scale, None}, crop will construct a mosaic by slicing images
         togther, scale will create a mosaic by concatnating and shifting the
         image, and None will default to scale and apply no post processing to
         the created mosaic.
       mosaic_center: `float` indicating how much to randomly deviate from the
-        from the center of the image when creating a mosaic.
+        center of the image when creating a mosaic.
+      mosaic9_center: `float` indicating how much to randomly deviate from the
+        center of the image when creating a mosaic9.
       aug_scale_min: `float` indicating the minimum scaling value for image
         scale jitter.
       aug_scale_max: `float` indicating the maximum scaling value for image
         scale jitter.
       aug_rand_angle: `float` indicating the maximum angle value for angle.
         angle will be changes between 0 and value.
       aug_rand_perspective: `float` ranging from 0.000 to 0.001 indicating how
@@ -81,131 +89,144 @@
       seed: `int` the seed for random number generation.
     """
 
     self._output_size = output_size
     self._area_thresh = area_thresh
 
     self._mosaic_frequency = mosaic_frequency
+    self._mosaic9_frequency = mosaic9_frequency
     self._mixup_frequency = mixup_frequency
 
     self._letter_box = letter_box
     self._random_crop = jitter
 
     self._mosaic_crop_mode = mosaic_crop_mode
     self._mosaic_center = mosaic_center
+    self._mosaic9_center = mosaic9_center
 
     self._aug_scale_min = aug_scale_min
     self._aug_scale_max = aug_scale_max
     self._random_pad = random_pad
     self._aug_rand_translate = aug_rand_translate
     self._aug_rand_angle = aug_rand_angle
     self._aug_rand_perspective = aug_rand_perspective
     self._random_flip = random_flip
     self._pad_value = pad_value
 
     self._deterministic = seed is not None
     self._seed = seed if seed is not None else random.randint(0, 2**30)
 
-  def _generate_cut(self):
+  def _generate_cut(self, num_tiles, mosaic_center):
     """Generate a random center to use for slicing and patching the images."""
     if self._mosaic_crop_mode == 'crop':
-      min_offset = self._mosaic_center
+      min_offset = mosaic_center
       cut_x = preprocessing_ops.random_uniform_strong(
           self._output_size[1] * min_offset,
           self._output_size[1] * (1 - min_offset),
           seed=self._seed)
       cut_y = preprocessing_ops.random_uniform_strong(
           self._output_size[0] * min_offset,
           self._output_size[0] * (1 - min_offset),
           seed=self._seed)
       cut = [cut_y, cut_x]
       ishape = tf.convert_to_tensor(
           [self._output_size[0], self._output_size[1], 3])
     else:
       cut = None
-      ishape = tf.convert_to_tensor(
-          [self._output_size[0] * 2, self._output_size[1] * 2, 3])
+      ishape = tf.convert_to_tensor([
+          self._output_size[0] * num_tiles,
+          self._output_size[1] * num_tiles,
+          3,
+      ])
     return cut, ishape
 
-  def scale_boxes(self, patch, ishape, boxes, classes, xs, ys):
+  def scale_boxes(self, patch, ishape, boxes, x_offset, y_offset):
     """Scale and translate the boxes for each image prior to patching."""
-    xs = tf.cast(xs, boxes.dtype)
-    ys = tf.cast(ys, boxes.dtype)
+    x_offset = tf.cast(x_offset, boxes.dtype)
+    y_offset = tf.cast(y_offset, boxes.dtype)
     pshape = tf.cast(tf.shape(patch), boxes.dtype)
     ishape = tf.cast(ishape, boxes.dtype)
-    translate = tf.cast((ishape - pshape), boxes.dtype)
+    y_offset = ishape[0] * y_offset
+    x_offset = ishape[1] * x_offset
 
     boxes = box_ops.denormalize_boxes(boxes, pshape[:2])
-    boxes = boxes + tf.cast([
-        translate[0] * ys, translate[1] * xs, translate[0] * ys,
-        translate[1] * xs
-    ], boxes.dtype)
+    boxes = boxes + tf.cast(
+        [y_offset, x_offset, y_offset, x_offset], boxes.dtype
+    )
     boxes = box_ops.normalize_boxes(boxes, ishape[:2])
-    return boxes, classes
+    return boxes
 
   def _select_ind(self, inds, *args):
     items = []
     for item in args:
       items.append(tf.gather(item, inds))
     return items
 
-  def _augment_image(self,
-                     image,
-                     boxes,
-                     classes,
-                     is_crowd,
-                     area,
-                     xs=0.0,
-                     ys=0.0,
-                     cut=None):
+  def _augment_image(
+      self,
+      image,
+      boxes,
+      classes,
+      is_crowd,
+      area,
+      xs=0.0,
+      ys=0.0,
+      cut=None,
+      letter_box=False,
+  ):
     """Process a single image prior to the application of patching."""
     if self._random_flip:
       # Randomly flip the image horizontally.
       image, boxes, _ = preprocess_ops.random_horizontal_flip(
           image, boxes, seed=self._seed)
 
     # Augment the image without resizing
     image, infos, crop_points = preprocessing_ops.resize_and_jitter_image(
-        image, [self._output_size[0], self._output_size[1]],
+        image,
+        [self._output_size[0], self._output_size[1]],
         random_pad=False,
-        letter_box=self._letter_box,
+        letter_box=letter_box,
         jitter=self._random_crop,
         shiftx=xs,
         shifty=ys,
         cut=cut,
-        seed=self._seed)
+        seed=self._seed,
+    )
 
     # Clip and clean boxes.
     boxes, inds = preprocessing_ops.transform_and_clip_boxes(
         boxes,
         infos,
         area_thresh=self._area_thresh,
         shuffle_boxes=False,
         filter_and_clip_boxes=True,
         seed=self._seed)
     classes, is_crowd, area = self._select_ind(inds, classes, is_crowd, area)  # pylint:disable=unbalanced-tuple-unpacking
     return image, boxes, classes, is_crowd, area, crop_points
 
-  def _mosaic_crop_image(self, image, boxes, classes, is_crowd, area):
+  def _mosaic_crop_image(
+      self, image, boxes, classes, is_crowd, area, mosaic_center):
     """Process a patched image in preperation for final output."""
     if self._mosaic_crop_mode != 'crop':
       shape = tf.cast(preprocessing_ops.get_image_shape(image), tf.float32)
-      center = shape * self._mosaic_center
+      center = shape * mosaic_center
 
       # shift the center of the image by applying a translation to the whole
       # image
       ch = tf.math.round(
           preprocessing_ops.random_uniform_strong(
               -center[0], center[0], seed=self._seed))
       cw = tf.math.round(
           preprocessing_ops.random_uniform_strong(
               -center[1], center[1], seed=self._seed))
 
-      # clip the boxes to those with in the image
-      image = tfa.image.translate(image, [cw, ch], fill_value=self._pad_value)
+      # clip the boxes to fit within the image
+      image = augment.translate(
+          image, [cw, ch], fill_value=self._pad_value, fill_mode='constant'
+      )
       boxes = box_ops.denormalize_boxes(boxes, shape[:2])
       boxes = boxes + tf.cast([ch, cw, ch, cw], boxes.dtype)
       boxes = box_ops.clip_boxes(boxes, shape[:2])
       inds = box_ops.get_non_empty_box_indices(boxes)
 
       boxes = box_ops.normalize_boxes(boxes, shape[:2])
       boxes, classes, is_crowd, area = self._select_ind(inds, boxes, classes,  # pylint:disable=unbalanced-tuple-unpacking
@@ -231,103 +252,179 @@
         affine=affine,
         area_thresh=self._area_thresh,
         seed=self._seed)
     classes, is_crowd, area = self._select_ind(inds, classes, is_crowd, area)  # pylint:disable=unbalanced-tuple-unpacking
     return image, boxes, classes, is_crowd, area, area
 
   # mosaic full frequency doubles model speed
-  def _process_image(self, sample, shiftx, shifty, cut, ishape):
-    """Process and augment each image."""
+  def _process_image(self, sample, shiftx, shifty, cut, letter_box):
+    """Process and augment an image."""
     (image, boxes, classes, is_crowd, area, crop_points) = self._augment_image(
-        sample['image'], sample['groundtruth_boxes'],
-        sample['groundtruth_classes'], sample['groundtruth_is_crowd'],
-        sample['groundtruth_area'], shiftx, shifty, cut)
-
-    (boxes, classes) = self.scale_boxes(image, ishape, boxes, classes,
-                                        1 - shiftx, 1 - shifty)
+        sample['image'],
+        sample['groundtruth_boxes'],
+        sample['groundtruth_classes'],
+        sample['groundtruth_is_crowd'],
+        sample['groundtruth_area'],
+        shiftx,
+        shifty,
+        cut,
+        letter_box,
+    )
 
+    # Make a copy so this method is functional.
+    sample = sample.copy()
     sample['image'] = image
     sample['groundtruth_boxes'] = boxes
     sample['groundtruth_classes'] = classes
     sample['groundtruth_is_crowd'] = is_crowd
     sample['groundtruth_area'] = area
     sample['shiftx'] = shiftx
     sample['shifty'] = shifty
     sample['crop_points'] = crop_points
     return sample
 
-  def _patch2(self, one, two):
-    """Stitch together 2 images in totality."""
-    sample = one
-    sample['image'] = tf.concat([one['image'], two['image']], axis=-2)
-
-    sample['groundtruth_boxes'] = tf.concat(
-        [one['groundtruth_boxes'], two['groundtruth_boxes']], axis=0)
-    sample['groundtruth_classes'] = tf.concat(
-        [one['groundtruth_classes'], two['groundtruth_classes']], axis=0)
-    sample['groundtruth_is_crowd'] = tf.concat(
-        [one['groundtruth_is_crowd'], two['groundtruth_is_crowd']], axis=0)
-    sample['groundtruth_area'] = tf.concat(
-        [one['groundtruth_area'], two['groundtruth_area']], axis=0)
-    return sample
-
-  def _patch(self, one, two):
-    """Build the full 4 patch of images from sets of 2 images."""
-    image = tf.concat([one['image'], two['image']], axis=-3)
-    boxes = tf.concat([one['groundtruth_boxes'], two['groundtruth_boxes']],
-                      axis=0)
-    classes = tf.concat(
-        [one['groundtruth_classes'], two['groundtruth_classes']], axis=0)
-    is_crowd = tf.concat(
-        [one['groundtruth_is_crowd'], two['groundtruth_is_crowd']], axis=0)
-    area = tf.concat([one['groundtruth_area'], two['groundtruth_area']], axis=0)
+  def _update_patched_sample(
+      self, sample, image, boxes, classes, is_crowds, areas, mosaic_center
+  ):
+    """Returns a shallow copy of sample with updated values."""
+    boxes = tf.concat(boxes, axis=0)
+    classes = tf.concat(classes, axis=0)
+    is_crowds = tf.concat(is_crowds, axis=0)
+    areas = tf.concat(areas, axis=0)
 
     if self._mosaic_crop_mode is not None:
-      image, boxes, classes, is_crowd, area, _ = self._mosaic_crop_image(
-          image, boxes, classes, is_crowd, area)
+      image, boxes, classes, is_crowds, areas, _ = self._mosaic_crop_image(
+          image, boxes, classes, is_crowds, areas, mosaic_center
+      )
 
-    sample = one
     height, width = preprocessing_ops.get_image_shape(image)
+    # Shallow copy of dict is needed to keep this method functional and
+    # AutoGraph happy.
+    sample = sample.copy()
     sample['image'] = tf.cast(image, tf.uint8)
     sample['groundtruth_boxes'] = boxes
-    sample['groundtruth_area'] = area
-    sample['groundtruth_classes'] = tf.cast(classes,
-                                            sample['groundtruth_classes'].dtype)
-    sample['groundtruth_is_crowd'] = tf.cast(is_crowd, tf.bool)
+    sample['groundtruth_area'] = areas
+    sample['groundtruth_classes'] = tf.cast(
+        classes, sample['groundtruth_classes'].dtype
+    )
+    sample['groundtruth_is_crowd'] = tf.cast(is_crowds, tf.bool)
     sample['width'] = tf.cast(width, sample['width'].dtype)
     sample['height'] = tf.cast(height, sample['height'].dtype)
     sample['num_detections'] = tf.shape(sample['groundtruth_boxes'])[1]
     sample['is_mosaic'] = tf.cast(1.0, tf.bool)
 
     del sample['shiftx']
     del sample['shifty']
     del sample['crop_points']
+
     return sample
 
-  def _mosaic(self, one, two, three, four):
-    """Stitch together 4 images to build a mosaic."""
+  def _patch(self, patches, ishape, num_rows, num_cols, mosaic_center):
+    """Combines patches into a num_patches x num_patches mosaic and translates the bounding boxes."""
+    rows = []
+    for row_idx in range(num_rows):
+      row_patches = [
+          patches[row_idx * num_cols + col_idx]['image']
+          for col_idx in range(num_cols)
+      ]
+      rows.append(tf.concat(row_patches, axis=-2))
+    image = tf.concat(rows, axis=-3)
+
+    boxes = []
+    classes = []
+    is_crowds = []
+    areas = []
+    # Shift boxes to their new coordinates in the mosaic.
+    for row_idx in range(num_rows):
+      for col_idx in range(num_cols):
+        patch = patches[row_idx * num_cols + col_idx]
+        transformed_boxes = self.scale_boxes(
+            patch['image'],
+            ishape,
+            patch['groundtruth_boxes'],
+            col_idx / num_cols,
+            row_idx / num_rows,
+        )
+        boxes.append(transformed_boxes)
+        classes.append(patch['groundtruth_classes'])
+        is_crowds.append(patch['groundtruth_is_crowd'])
+        areas.append(patch['groundtruth_area'])
+
+    return self._update_patched_sample(
+        patches[0], image, boxes, classes, is_crowds, areas, mosaic_center
+    )
+
+  def _mosaic(self, *patch_samples):
+    """Builds a 2x2 or 3x3 mosaic."""
     if self._mosaic_frequency >= 1.0:
-      domo = 1.0
+      mosaic_prob = 1.0
     else:
-      domo = preprocessing_ops.random_uniform_strong(
-          0.0, 1.0, dtype=tf.float32, seed=self._seed)
-      noop = one.copy()
-
-    if domo >= (1 - self._mosaic_frequency):
-      cut, ishape = self._generate_cut()
-      one = self._process_image(one, 1.0, 1.0, cut, ishape)
-      two = self._process_image(two, 0.0, 1.0, cut, ishape)
-      three = self._process_image(three, 1.0, 0.0, cut, ishape)
-      four = self._process_image(four, 0.0, 0.0, cut, ishape)
-      patch1 = self._patch2(one, two)
-      patch2 = self._patch2(three, four)
-      stitched = self._patch(patch1, patch2)
-      return stitched
+      mosaic_prob = preprocessing_ops.random_uniform_strong(
+          0.0, 1.0, dtype=tf.float32, seed=self._seed
+      )
+      sample = patch_samples[0].copy()
+
+    if mosaic_prob >= (1 - self._mosaic_frequency):
+      mosaic9_prob = preprocessing_ops.random_uniform_strong(
+          0.0, 1.0, dtype=tf.float32, seed=self._seed + 1
+      )
+      if self._mosaic9_frequency > 0 and mosaic9_prob >= (
+          1 - self._mosaic9_frequency
+      ):
+        return self._mosaic9(*patch_samples)
+      else:
+        return self._mosaic4(*patch_samples)
     else:
-      return self._add_param(noop)
+      return self._add_param(sample)
+
+  def _mosaic4(self, *samples):
+    """Stitches together 4 images to build a 2x2 mosaic."""
+    cut, ishape = self._generate_cut(2, self._mosaic_center)
+    samples = [
+        self._process_image(
+            samples[0], 1.0, 1.0, cut, letter_box=self._letter_box
+        ),
+        self._process_image(
+            samples[1], 0.0, 1.0, cut, letter_box=self._letter_box
+        ),
+        self._process_image(
+            samples[2], 1.0, 0.0, cut, letter_box=self._letter_box
+        ),
+        self._process_image(
+            samples[3], 0.0, 0.0, cut, letter_box=self._letter_box
+        ),
+    ]
+    stitched = self._patch(samples, ishape, 2, 2, self._mosaic_center)
+    return stitched
+
+  def _mosaic9(self, *samples):
+    """Stitches together 9 images to build a 3x3 mosaic."""
+    cut, ishape = self._generate_cut(3, self._mosaic9_center)
+    # Only corner images can be letterboxed to prevent gaps in the image.
+    samples = [
+        self._process_image(
+            samples[0], 1.0, 1.0, cut, letter_box=self._letter_box
+        ),
+        self._process_image(samples[1], 0.0, 0.0, cut, letter_box=False),
+        self._process_image(
+            samples[2], 0.0, 1.0, cut, letter_box=self._letter_box
+        ),
+        self._process_image(samples[3], 0.0, 0.0, cut, letter_box=False),
+        self._process_image(samples[4], 0.0, 0.0, cut, letter_box=False),
+        self._process_image(samples[5], 0.0, 0.0, cut, letter_box=False),
+        self._process_image(
+            samples[6], 1.0, 0.0, cut, letter_box=self._letter_box
+        ),
+        self._process_image(samples[7], 0.0, 0.0, cut, letter_box=False),
+        self._process_image(
+            samples[8], 0.0, 0.0, cut, letter_box=self._letter_box
+        ),
+    ]
+    stitched = self._patch(samples, ishape, 3, 3, self._mosaic9_center)
+    return stitched
 
   def _beta(self, alpha, beta):
     """Generates a random number using the beta distribution."""
     a = tf.random.gamma([], alpha)
     b = tf.random.gamma([], beta)
     return b / (a + b)
 
@@ -360,39 +457,46 @@
           [one['groundtruth_area'], two['groundtruth_area']], axis=0)
       return sample
     else:
       return self._add_param(noop)
 
   def _add_param(self, sample):
     """Add parameters to handle skipped images."""
-    sample['is_mosaic'] = tf.cast(0.0, tf.bool)
+    if 'is_mosaic' not in sample:
+      sample['is_mosaic'] = tf.cast(0.0, tf.bool)
     sample['num_detections'] = tf.shape(sample['groundtruth_boxes'])[0]
     return sample
 
   def _apply(self, dataset):
     """Apply mosaic to an input dataset."""
     determ = self._deterministic
     dataset = dataset.prefetch(tf.data.AUTOTUNE)
-    one = dataset.shuffle(100, seed=self._seed, reshuffle_each_iteration=True)
-    two = dataset.shuffle(
-        100, seed=self._seed + 1, reshuffle_each_iteration=True)
-    three = dataset.shuffle(
-        100, seed=self._seed + 2, reshuffle_each_iteration=True)
-    four = dataset.shuffle(
-        100, seed=self._seed + 3, reshuffle_each_iteration=True)
 
-    dataset = tf.data.Dataset.zip((one, two, three, four))
+    patch_datasets = []
+    num_patches = 9 if self._mosaic9_frequency > 0.0 else 4
+    for i in range(num_patches):
+      patch_datasets.append(
+          dataset.shuffle(
+              100, seed=self._seed + i, reshuffle_each_iteration=True
+          )
+      )
+
+    dataset = tf.data.Dataset.zip(tuple(patch_datasets))
     dataset = dataset.map(
         self._mosaic, num_parallel_calls=tf.data.AUTOTUNE, deterministic=determ)
 
     if self._mixup_frequency > 0:
       one = dataset.shuffle(
-          100, seed=self._seed + 4, reshuffle_each_iteration=True)
+          100, seed=self._seed + num_patches, reshuffle_each_iteration=True
+      )
       two = dataset.shuffle(
-          100, seed=self._seed + 5, reshuffle_each_iteration=True)
+          100,
+          seed=self._seed + num_patches + 1,
+          reshuffle_each_iteration=True,
+      )
       dataset = tf.data.Dataset.zip((one, two))
       dataset = dataset.map(
           self._mixup,
           num_parallel_calls=tf.data.AUTOTUNE,
           deterministic=determ)
     return dataset
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/preprocessing_ops.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/preprocessing_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,17 +12,17 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Preprocessing ops for yolo."""
 import random
 
 import numpy as np
-import tensorflow as tf
-import tensorflow_addons as tfa
+import tensorflow as tf, tf_keras
 
+from official.vision.ops import augment
 from official.vision.ops import box_ops as bbox_ops
 
 PAD_VALUE = 114
 GLOBAL_SEED_SET = False
 
 
 def set_random_seeds(seed=0):
@@ -665,20 +665,22 @@
       random_pad=random_pad,
       desired_size=desired_size,
       seed=seed)
   affine = tf.reshape(affine_matrix, [-1])
   affine = tf.cast(affine[:-1], tf.float32)
 
   # Apply the transformation to image.
-  image = tfa.image.transform(
+  image = augment.transform(
       image,
       affine,
       fill_value=PAD_VALUE,
       output_shape=desired_size,
-      interpolation='bilinear')
+      interpolation='bilinear',
+      fill_mode='constant',
+  )
 
   desired_size = tf.cast(desired_size, tf.float32)
   affine_info = [image_size, desired_size, affine_boxes]
   return image, affine_matrix, affine_info
 
 
 def affine_warp_boxes(affine, boxes, output_size, box_history):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/ops/preprocessing_ops_test.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/ops/preprocessing_ops_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for preprocessing_ops.py."""
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import preprocessing_ops
 from official.vision.ops import box_ops as bbox_ops
 
 
 class InputUtilsTest(parameterized.TestCase, tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/optimization/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/optimization/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/optimization/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/triviaqa/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/optimization/configs/optimization_config.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/optimization/configs/optimization_config.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -34,23 +34,27 @@
     sgd: sgd optimizer config.
     adam: adam optimizer config.
     adamw: adam with weight decay.
     lamb: lamb optimizer.
     rmsprop: rmsprop optimizer.
   """
   type: Optional[str] = None
-  sgd_torch: opt_cfg.SGDTorchConfig = opt_cfg.SGDTorchConfig()
+  sgd_torch: opt_cfg.SGDTorchConfig = dataclasses.field(
+      default_factory=opt_cfg.SGDTorchConfig
+  )
 
 
 @dataclasses.dataclass
 class OptimizationConfig(optimization_cfg.OptimizationConfig):
   """Configuration for optimizer and learning rate schedule.
 
   Attributes:
     optimizer: optimizer oneof config.
     ema: optional exponential moving average optimizer config, if specified, ema
       optimizer will be used.
     learning_rate: learning rate oneof config.
     warmup: warmup oneof config.
   """
   type: Optional[str] = None
-  optimizer: OptimizerConfig = OptimizerConfig()
+  optimizer: OptimizerConfig = dataclasses.field(
+      default_factory=OptimizerConfig
+  )
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/optimization/configs/optimizer_config.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/optimization/configs/optimizer_config.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -37,15 +37,15 @@
   global_clipnorm: Optional[float] = None
 
 
 @dataclasses.dataclass
 class SGDTorchConfig(optimizer_config.BaseOptimizerConfig):
   """Configuration for SGD optimizer.
 
-  The attributes for this class matches the arguments of tf.keras.optimizer.SGD.
+  The attributes for this class matches the arguments of tf_keras.optimizer.SGD.
 
   Attributes:
     name: name of the optimizer.
     decay: decay rate for SGD optimizer.
     nesterov: nesterov for SGD optimizer.
     momentum_start: momentum starting point for SGD optimizer.
     momentum: momentum for SGD optimizer.
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/optimization/optimizer_factory.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/optimization/optimizer_factory.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,19 +16,19 @@
 
 import gin
 
 from official.modeling.optimization import ema_optimizer
 from official.modeling.optimization import optimizer_factory
 from official.projects.yolo.optimization import sgd_torch
 
-optimizer_factory.OPTIMIZERS_CLS.update({
+optimizer_factory.LEGACY_OPTIMIZERS_CLS.update({
     'sgd_torch': sgd_torch.SGDTorch,
 })
 
-OPTIMIZERS_CLS = optimizer_factory.OPTIMIZERS_CLS
+OPTIMIZERS_CLS = optimizer_factory.LEGACY_OPTIMIZERS_CLS
 LR_CLS = optimizer_factory.LR_CLS
 WARMUP_CLS = optimizer_factory.WARMUP_CLS
 
 
 class OptimizerFactory(optimizer_factory.OptimizerFactory):
   """Optimizer factory class.
 
@@ -69,15 +69,15 @@
     to the learning rate config. If learning rate type is consant,
     lr_config.learning_rate is returned.
 
     Args:
       bias_lr: learning rate config.
 
     Returns:
-      tf.keras.optimizers.schedules.LearningRateSchedule instance. If
+      tf_keras.optimizers.schedules.LearningRateSchedule instance. If
       learning rate type is consant, lr_config.learning_rate is returned.
     """
     if self._lr_type == 'constant':
       lr = self._lr_config.learning_rate
     else:
       lr = LR_CLS[self._lr_type](**self._lr_config.as_dict())
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/optimization/sgd_torch.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/optimization/sgd_torch.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,17 +12,17 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """SGD PyTorch optimizer."""
 import re
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-LearningRateSchedule = tf.keras.optimizers.schedules.LearningRateSchedule
+LearningRateSchedule = tf_keras.optimizers.schedules.LearningRateSchedule
 
 
 def _var_key(var):
   """Key for representing a primary variable, for looking up slots.
 
   In graph mode the name is derived from the var shared name.
   In eager mode the name is derived from the var unique id.
@@ -39,15 +39,15 @@
   if hasattr(var, "_distributed_container"):
     var = var._distributed_container()
   if var._in_graph_mode:
     return var._shared_name
   return var._unique_id
 
 
-class SGDTorch(tf.keras.optimizers.legacy.Optimizer):
+class SGDTorch(tf_keras.optimizers.legacy.Optimizer):
   """Optimizer that simulates the SGD module used in pytorch.
 
 
   For details on the differences between the original SGD implemention and the
   one in pytorch:
   https://pytorch.org/docs/stable/generated/torch.optim.SGD.html.
   This optimizer also allow for the usage of a momentum warmup along side a
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/serving/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/video_ssl/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/serving/export_module_factory.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/serving/export_module_factory.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,52 +12,53 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Factory for YOLO export modules."""
 
 from typing import Any, Callable, Dict, List, Optional, Text, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.core import export_base
-from official.projects.yolo.configs.yolo import YoloTask
+from official.projects.yolo.configs import darknet_classification
+from official.projects.yolo.configs import yolo
+from official.projects.yolo.configs import yolov7
+from official.projects.yolo.dataloaders import classification_input
 from official.projects.yolo.modeling import factory as yolo_factory
 from official.projects.yolo.modeling.backbones import darknet  # pylint: disable=unused-import
 from official.projects.yolo.modeling.decoders import yolo_decoder  # pylint: disable=unused-import
 from official.projects.yolo.serving import model_fn as yolo_model_fn
-from official.vision import configs
-from official.vision.dataloaders import classification_input
 from official.vision.modeling import factory
 from official.vision.serving import export_utils
 
 
 class ExportModule(export_base.ExportModule):
   """Base Export Module."""
 
   def __init__(self,
                params: cfg.ExperimentConfig,
-               model: tf.keras.Model,
+               model: tf_keras.Model,
                input_signature: Union[tf.TensorSpec, Dict[str, tf.TensorSpec]],
                preprocessor: Optional[Callable[..., Any]] = None,
                inference_step: Optional[Callable[..., Any]] = None,
                postprocessor: Optional[Callable[..., Any]] = None,
                eval_postprocessor: Optional[Callable[..., Any]] = None):
     """Initializes a module for export.
 
     Args:
       params: A dataclass for parameters to the module.
-      model: A tf.keras.Model instance to be exported.
-      input_signature: tf.TensorSpec, e.g.
-        tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.uint8)
+      model: A tf_keras.Model instance to be exported.
+      input_signature: tf.TensorSpec, e.g. tf.TensorSpec(shape=[None, 224, 224,
+        3], dtype=tf.uint8)
       preprocessor: An optional callable to preprocess the inputs.
       inference_step: An optional callable to forward-pass the model.
       postprocessor: An optional callable to postprocess the model outputs.
-      eval_postprocessor: An optional callable to postprocess model outputs
-      used for model evaluation.
+      eval_postprocessor: An optional callable to postprocess model outputs used
+        for model evaluation.
     """
     super().__init__(
         params,
         model=model,
         preprocessor=preprocessor,
         inference_step=inference_step,
         postprocessor=postprocessor)
@@ -102,19 +103,20 @@
 
 
 def create_classification_export_module(
     params: cfg.ExperimentConfig,
     input_type: str,
     batch_size: int,
     input_image_size: List[int],
-    num_channels: int = 3) -> ExportModule:
+    num_channels: int = 3,
+    input_name: Optional[str] = None) -> ExportModule:
   """Creates classification export module."""
   input_signature = export_utils.get_image_input_signatures(
-      input_type, batch_size, input_image_size, num_channels)
-  input_specs = tf.keras.layers.InputSpec(shape=[batch_size] +
+      input_type, batch_size, input_image_size, num_channels, input_name)
+  input_specs = tf_keras.layers.InputSpec(shape=[batch_size] +
                                           input_image_size + [num_channels])
 
   model = factory.build_classification_model(
       input_specs=input_specs,
       model_config=params.task.model,
       l2_regularizer=None)
 
@@ -151,35 +153,47 @@
 
 
 def create_yolo_export_module(
     params: cfg.ExperimentConfig,
     input_type: str,
     batch_size: int,
     input_image_size: List[int],
-    num_channels: int = 3) -> ExportModule:
+    num_channels: int = 3,
+    input_name: Optional[str] = None) -> ExportModule:
   """Creates YOLO export module."""
   input_signature = export_utils.get_image_input_signatures(
-      input_type, batch_size, input_image_size, num_channels)
-  input_specs = tf.keras.layers.InputSpec(shape=[batch_size] +
+      input_type, batch_size, input_image_size, num_channels, input_name)
+  input_specs = tf_keras.layers.InputSpec(shape=[batch_size] +
                                           input_image_size + [num_channels])
-  model, _ = yolo_factory.build_yolo(
-      input_specs=input_specs,
-      model_config=params.task.model,
-      l2_regularization=None)
+  if isinstance(params.task, yolo.YoloTask):
+    model, _ = yolo_factory.build_yolo(
+        input_specs=input_specs,
+        model_config=params.task.model,
+        l2_regularization=None)
+  elif isinstance(params.task, yolov7.YoloV7Task):
+    model = yolo_factory.build_yolov7(
+        input_specs=input_specs,
+        model_config=params.task.model,
+        l2_regularization=None)
 
   def preprocess_fn(inputs):
     image_tensor = export_utils.parse_image(inputs, input_type,
                                             input_image_size, num_channels)
-    # If input_type is `tflite`, do not apply image preprocessing.
+
+    def normalize_image_fn(inputs):
+      image = tf.cast(inputs, dtype=tf.float32)
+      return image / 255.0
+
+    # If input_type is `tflite`, do not apply image preprocessing. Only apply
+    # normalization.
     if input_type == 'tflite':
-      return image_tensor
+      return normalize_image_fn(image_tensor), None
 
     def preprocess_image_fn(inputs):
-      image = tf.cast(inputs, dtype=tf.float32)
-      image = image / 255.
+      image = normalize_image_fn(inputs)
       (image, image_info) = yolo_model_fn.letterbox(
           image,
           input_image_size,
           letter_box=params.task.validation_data.parser.letter_box)
       return image, image_info
 
     images_spec = tf.TensorSpec(shape=input_image_size + [3], dtype=tf.float32)
@@ -194,20 +208,22 @@
             fn_output_signature=(images_spec, image_info_spec),
             parallel_iterations=32))
 
     return images, image_info
 
   def inference_steps(inputs, model):
     images, image_info = inputs
-    detection = model(images, training=False)
-    detection['bbox'] = yolo_model_fn.undo_info(
-        detection['bbox'],
-        detection['num_detections'],
-        image_info,
-        expand=False)
+    detection = model.call(images, training=False)
+    if input_type != 'tflite':
+      detection['bbox'] = yolo_model_fn.undo_info(
+          detection['bbox'],
+          detection['num_detections'],
+          image_info,
+          expand=False,
+      )
 
     final_outputs = {
         'detection_boxes': detection['bbox'],
         'detection_scores': detection['confidence'],
         'detection_classes': detection['classes'],
         'num_detections': detection['num_detections']
     }
@@ -224,22 +240,25 @@
   return export_module
 
 
 def get_export_module(params: cfg.ExperimentConfig,
                       input_type: str,
                       batch_size: Optional[int],
                       input_image_size: List[int],
-                      num_channels: int = 3) -> ExportModule:
+                      num_channels: int = 3,
+                      input_name: Optional[str] = None) -> ExportModule:
   """Factory for export modules."""
   if isinstance(params.task,
-                configs.image_classification.ImageClassificationTask):
+                darknet_classification.ImageClassificationTask):
     export_module = create_classification_export_module(params, input_type,
                                                         batch_size,
                                                         input_image_size,
-                                                        num_channels)
-  elif isinstance(params.task, YoloTask):
+                                                        num_channels,
+                                                        input_name)
+  elif isinstance(params.task, (yolo.YoloTask, yolov7.YoloV7Task)):
     export_module = create_yolo_export_module(params, input_type, batch_size,
-                                              input_image_size, num_channels)
+                                              input_image_size, num_channels,
+                                              input_name)
   else:
     raise ValueError('Export module not implemented for {} task.'.format(
         type(params.task)))
   return export_module
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/serving/export_saved_model.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/serving/export_saved_model.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -34,17 +34,16 @@
 """
 
 from absl import app
 from absl import flags
 
 from official.core import exp_factory
 from official.modeling import hyperparams
-from official.projects.yolo.configs import yolo as cfg  # pylint: disable=unused-import
+from official.projects.yolo.common import registry_imports  # pylint: disable=unused-import
 from official.projects.yolo.serving import export_module_factory
-from official.projects.yolo.tasks import yolo as task  # pylint: disable=unused-import
 from official.vision.serving import export_saved_model_lib
 
 FLAGS = flags.FLAGS
 
 flags.DEFINE_string('experiment', 'scaled_yolo',
                     'experiment type, e.g. scaled_yolo')
 flags.DEFINE_string('export_dir', None, 'The export directory.')
@@ -65,43 +64,63 @@
 flags.DEFINE_integer('batch_size', 1, 'The batch size.')
 flags.DEFINE_string('input_type', 'image_tensor',
                     'One of `image_tensor`, `image_bytes`, `tf_example`.')
 flags.DEFINE_string(
     'input_image_size', '224,224',
     'The comma-separated string of two integers representing the height,width '
     'of the input to the model.')
+_EXPORT_SAVED_MODEL_SUBDIR = flags.DEFINE_string(
+    'export_saved_model_subdir', 'saved_model',
+    'The subdirectory for saved model.')
+_INPUT_NAME = flags.DEFINE_string(
+    'input_name', None,
+    'Input tensor name in signature def. Default at None which'
+    'produces input tensor name `inputs`.')
 
 
 def main(_):
 
   params = exp_factory.get_exp_config(FLAGS.experiment)
   for config_file in FLAGS.config_file or []:
-    params = hyperparams.override_params_dict(
-        params, config_file, is_strict=True)
+    try:
+      params = hyperparams.override_params_dict(
+          params, config_file, is_strict=True
+      )
+    except KeyError:
+      params = hyperparams.override_params_dict(
+          params, config_file, is_strict=False
+      )
   if FLAGS.params_override:
-    params = hyperparams.override_params_dict(
-        params, FLAGS.params_override, is_strict=True)
-
+    try:
+      params = hyperparams.override_params_dict(
+          params, FLAGS.params_override, is_strict=True
+      )
+    except KeyError:
+      params = hyperparams.override_params_dict(
+          params, FLAGS.params_override, is_strict=False
+      )
   params.validate()
   params.lock()
 
   input_image_size = [int(x) for x in FLAGS.input_image_size.split(',')]
 
   export_module = export_module_factory.get_export_module(
       params=params,
       input_type=FLAGS.input_type,
       batch_size=FLAGS.batch_size,
       input_image_size=[int(x) for x in FLAGS.input_image_size.split(',')],
-      num_channels=3)
+      num_channels=3,
+      input_name=_INPUT_NAME.value)
 
   export_saved_model_lib.export_inference_graph(
       input_type=FLAGS.input_type,
       batch_size=FLAGS.batch_size,
       input_image_size=input_image_size,
       params=params,
       checkpoint_path=FLAGS.checkpoint_path,
       export_dir=FLAGS.export_dir,
-      export_module=export_module)
+      export_module=export_module,
+      export_saved_model_subdir=_EXPORT_SAVED_MODEL_SUBDIR.value)
 
 
 if __name__ == '__main__':
   app.run(main)
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/serving/model_fn.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/serving/model_fn.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """YOLO input and model functions for serving/inference."""
 
 from typing import List, Tuple
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yolo.ops import preprocessing_ops
 from official.vision.ops import box_ops
 
 
 def letterbox(image: tf.Tensor,
               desired_size: List[int],
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/tasks/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/video_ssl/dataloaders/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/tasks/image_classification.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/tasks/image_classification.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/tasks/task_utils.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/tasks/task_utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Utils for yolo task."""
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class ListMetrics:
   """Private class used to cleanly place the matric values for each level."""
 
   def __init__(self, metric_names, name="ListMetrics"):
     self.name = name
@@ -25,15 +25,15 @@
     self._metrics = self.build_metric()
     return
 
   def build_metric(self):
     metric_names = self._metric_names
     metrics = []
     for name in metric_names:
-      metrics.append(tf.keras.metrics.Mean(name, dtype=tf.float32))
+      metrics.append(tf_keras.metrics.Mean(name, dtype=tf.float32))
     return metrics
 
   def update_state(self, loss_metrics):
     metrics = self._metrics
     for m in metrics:
       m.update_state(loss_metrics[m.name])
     return
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/tasks/yolo.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/tasks/yolo.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Contains classes used to train Yolo."""
 
 import collections
 from typing import Optional
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import dataset_fn
 from official.core import base_task
 from official.core import config_definitions
 from official.core import input_reader
 from official.core import task_factory
 from official.modeling import performance
@@ -80,15 +80,16 @@
     num_anchors = backbone.max_level - backbone.min_level + 1
     num_anchors *= anchor_cfg.anchors_per_scale
 
     gbs = dataset.global_batch_size
     dataset.global_batch_size = 1
     box_reader = kmeans_anchors.BoxGenInputReader(
         dataset,
-        dataset_fn=tf.data.TFRecordDataset,
+        dataset_fn=dataset_fn.pick_dataset_fn(
+            self.task_config.train_data.file_type),
         decoder_fn=decoder.decode)
 
     boxes = box_reader.read(
         k=num_anchors,
         anchors_per_scale=anchor_cfg.anchors_per_scale,
         image_resolution=input_size,
         scaling_mode=anchor_cfg.scaling_mode,
@@ -108,19 +109,21 @@
   def build_model(self):
     """Build an instance of Yolo."""
 
     model_base_cfg = self.task_config.model
     l2_weight_decay = self.task_config.weight_decay / 2.0
 
     input_size = model_base_cfg.input_size.copy()
-    input_specs = tf.keras.layers.InputSpec(shape=[None] + input_size)
+    input_specs = tf_keras.layers.InputSpec(shape=[None] + input_size)
     l2_regularizer = (
-        tf.keras.regularizers.l2(l2_weight_decay) if l2_weight_decay else None)
+        tf_keras.regularizers.l2(l2_weight_decay) if l2_weight_decay else None)
     model, losses = factory.build_yolo(
         input_specs, model_base_cfg, l2_regularizer)
+    model.build(input_specs.shape)
+    model.summary(print_fn=logging.info)
 
     # save for later usage within the task.
     self._loss_fn = losses
     self._model = model
     return model
 
   def _get_data_decoder(self, params):
@@ -235,15 +238,16 @@
       annotation_file = self.task_config.annotation_file
       if self._coco_91_to_80:
         annotation_file = None
       self.coco_metric = coco_evaluator.COCOEvaluator(
           annotation_file=annotation_file,
           include_mask=False,
           need_rescale_bboxes=False,
-          per_category_metrics=self._task_config.per_category_metrics)
+          per_category_metrics=self._task_config.per_category_metrics,
+          max_num_eval_detections=self.task_config.max_num_eval_detections)
 
     return metrics
 
   def build_losses(self, outputs, labels, aux_losses=None):
     """Build YOLO losses."""
     return self._loss_fn(labels, outputs)
 
@@ -271,23 +275,23 @@
       y_pred = tf.nest.map_structure(lambda x: tf.cast(x, tf.float32), y_pred)
 
       # Get the total loss
       (scaled_loss, metric_loss,
        loss_metrics) = self.build_losses(y_pred['raw_output'], label)
 
       # Scale the loss for numerical stability
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     # Compute the gradient
     train_vars = model.trainable_variables
     gradients = tape.gradient(scaled_loss, train_vars)
 
     # Get unscaled loss if we are using the loss scale optimizer on fp16
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       gradients = optimizer.get_unscaled_gradients(gradients)
 
     # Apply gradients to the model
     optimizer.apply_gradients(zip(gradients, train_vars))
     logs = {self.loss: metric_loss}
 
     # Compute all metrics
@@ -372,15 +376,15 @@
     return state
 
   def reduce_aggregated_logs(self, aggregated_logs, global_step=None):
     """Reduce logs and remove unneeded items. Update with COCO results."""
     res = self.coco_metric.result()
     return res
 
-  def initialize(self, model: tf.keras.Model):
+  def initialize(self, model: tf_keras.Model):
     """Loading pretrained checkpoint."""
 
     if not self.task_config.init_checkpoint:
       logging.info('Training from Scratch.')
       return
 
     ckpt_dir_or_file = self.task_config.init_checkpoint
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yolo/train.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/train.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/video_ssl/losses/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/yt8m/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/configs/yt8m.py` & `tf-models-no-deps-2.16.0/official/projects/yt8m/configs/yt8m.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,23 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Video classification configuration definition."""
 import dataclasses
 from typing import Optional, Tuple
-from absl import flags
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.modeling import optimization
 from official.vision.configs import common
 
-FLAGS = flags.FLAGS
 
 YT8M_TRAIN_EXAMPLES = 3888919
 YT8M_VAL_EXAMPLES = 1112356
 # 2/frame -> frame level
 # 3/frame -> segment level
 YT8M_TRAIN_PATH = 'gs://youtube8m-ml/2/frame/train/train*.tfrecord'
 YT8M_VAL_PATH = 'gs://youtube8m-ml/3/frame/validate/validate*.tfrecord'
@@ -44,20 +42,22 @@
     feature_names: names of the features in the tf.SequenceExample.
     feature_sources: if the feature from 'context' or 'features'.
     feature_dtypes: dtype of decoded feature.
     feature_from_bytes: decode feature from bytes or as dtype list.
     label_fields: name of field to read from tf.SequenceExample.
     segment_size: Number of frames in each segment.
     segment_labels: Use segment level label. Default: False, video level label.
-    include_video_id: `True` means include video id (string) in the input to
-      the model.
+    include_video_id: `True` means include video id (string) in the input to the
+      model.
     temporal_stride: Not used. Need to deprecated.
     max_frames: Maxim Number of frames in a input example. It is used to crop
       the input in the temporal dimension.
-    num_frames: Number of frames in a single input example.
+    sample_random_frames: If sample random frames or random sequence.
+    num_sample_frames: Number of frames to sample for each input example. No
+      frame sampling if None.
     num_classes: Number of classes to classify. Assuming it is a classification
       task.
     num_devices: Not used. To be deprecated.
     input_path: The path to the input.
     is_training: Whether this data is used for training or not.
     num_examples: Number of examples in the dataset. It is used to compute the
       steps for train or eval. set the value to `-1` to make the experiment run
@@ -72,96 +72,162 @@
   feature_dtypes: Tuple[str, ...] = ('uint8', 'uint8')
   feature_from_bytes: Tuple[bool, ...] = (True, True)
   label_field: str = 'labels'
   segment_size: int = 1
   segment_labels: bool = False
   include_video_id: bool = False
   temporal_stride: int = 1
-  max_frames: int = 300
-  num_frames: int = 300  # set smaller to allow random sample (Parser)
+  max_frames: int = 300  # Cap input frames.
+  sample_random_frames: bool = True
+  # Sample random frames if not None. No sampling in inference.
+  num_sample_frames: Optional[int] = 300
+  input_per_feature_l2_norm: bool = False
+  prefetch_buffer_size: int = 100
+  shuffle_buffer_size: int = 100
   num_classes: int = 3862
   num_devices: int = 1
   input_path: str = ''
   is_training: bool = True
   num_examples: int = -1
   file_type: str = 'tfrecord'
 
 
 def yt8m(is_training):
   """YT8M dataset configs."""
   # pylint: disable=unexpected-keyword-arg
   return DataConfig(
-      num_frames=30,
       temporal_stride=1,
       segment_labels=False,
       segment_size=5,
       is_training=is_training,
       split='train' if is_training else 'valid',
       drop_remainder=is_training,  # pytype: disable=wrong-keyword-args
       num_examples=YT8M_TRAIN_EXAMPLES if is_training else YT8M_VAL_EXAMPLES,
       input_path=YT8M_TRAIN_PATH if is_training else YT8M_VAL_PATH)
   # pylint: enable=unexpected-keyword-arg
 
 
 @dataclasses.dataclass
-class MoeModel(hyperparams.Config):
-  """The model config."""
-  num_mixtures: int = 5
-  l2_penalty: float = 1e-5
-  use_input_context_gate: bool = False
-  use_output_context_gate: bool = False
-
-
-@dataclasses.dataclass
 class DbofModel(hyperparams.Config):
   """The model config."""
   cluster_size: int = 3000
   hidden_size: int = 2000
   add_batch_norm: bool = True
-  sample_random_frames: bool = True
+  pooling_method: str = 'average'
   use_context_gate_cluster_layer: bool = False
   context_gate_cluster_bottleneck_size: int = 0
-  pooling_method: str = 'average'
-  yt8m_agg_classifier_model: str = 'MoeModel'
-  agg_model: hyperparams.Config = MoeModel()
-  norm_activation: common.NormActivation = common.NormActivation(
-      activation='relu', use_sync_bn=False)
+
+
+@dataclasses.dataclass
+class Backbone(hyperparams.OneOfConfig):
+  """Configuration for backbones.
+
+  Attributes:
+    type: 'str', type of backbone be used, one of the fields below.
+    dbof: dbof backbone config.
+  """
+  type: Optional[str] = None
+  dbof: DbofModel = dataclasses.field(default_factory=DbofModel)
+
+
+@dataclasses.dataclass
+class MoeModel(hyperparams.Config):
+  """The MoE model config."""
+
+  num_mixtures: int = 5
+  vocab_as_last_dim: bool = False
+  use_input_context_gate: bool = False
+  use_output_context_gate: bool = False
+
+
+@dataclasses.dataclass
+class LogisticModel(hyperparams.Config):
+  """The logistic model config."""
+  return_logits: bool = False
+
+
+@dataclasses.dataclass
+class Head(hyperparams.OneOfConfig):
+  """Configuration for aggreagation heads.
+
+  Attributes:
+    type: 'str', type of head be used, one of the fields below.
+    moe: MoE head config.
+    logistic: Logistic head config.
+  """
+  type: Optional[str] = None
+  moe: MoeModel = dataclasses.field(default_factory=MoeModel)
+  logistic: LogisticModel = dataclasses.field(default_factory=LogisticModel)
+
+
+@dataclasses.dataclass
+class VideoClassificationModel(hyperparams.Config):
+  """The classifier model config."""
+  backbone: Backbone = dataclasses.field(
+      default_factory=lambda: Backbone(type='dbof')
+  )
+  head: Head = dataclasses.field(default_factory=lambda: Head(type='moe'))
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=lambda: common.NormActivation(  # pylint: disable=g-long-lambda
+          activation='relu', use_sync_bn=False
+      )
+  )
 
 
 @dataclasses.dataclass
 class Losses(hyperparams.Config):
   name: str = 'binary_crossentropy'
   from_logits: bool = False
   label_smoothing: float = 0.0
   l2_weight_decay: float = 1e-5
 
 
 @dataclasses.dataclass
+class AveragePrecisionConfig(hyperparams.Config):
+  top_k: int = 20
+  top_n: Optional[int] = None
+  return_per_class_ap: bool = False
+
+
+@dataclasses.dataclass
+class Evaluation(hyperparams.Config):
+  average_precision: Optional[AveragePrecisionConfig] = None
+
+
+@dataclasses.dataclass
 class YT8MTask(cfg.TaskConfig):
   """The task config."""
-  model: DbofModel = DbofModel()
-  train_data: DataConfig = yt8m(is_training=True)
-  validation_data: DataConfig = yt8m(is_training=False)
-  losses: Losses = Losses()
+  model: VideoClassificationModel = dataclasses.field(
+      default_factory=VideoClassificationModel
+  )
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: yt8m(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: yt8m(is_training=False)
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
+  evaluation: Evaluation = dataclasses.field(
+      default_factory=lambda: Evaluation(  # pylint: disable=g-long-lambda
+          average_precision=AveragePrecisionConfig()
+      )
+  )
   gradient_clip_norm: float = 1.0
-  num_readers: int = 8
-  top_k: int = 20
-  top_n: Optional[int] = None
 
 
 def add_trainer(
     experiment: cfg.ExperimentConfig,
     train_batch_size: int,
     eval_batch_size: int,
     learning_rate: float = 0.0001,
     train_epochs: int = 50,
     num_train_examples: int = YT8M_TRAIN_EXAMPLES,
     num_val_examples: int = YT8M_VAL_EXAMPLES,
-):
-  """Add and config a trainer to the experiment config."""
+) -> cfg.ExperimentConfig:
+  """Adds and config a trainer to the experiment config."""
   if num_train_examples <= 0:
     raise ValueError('Wrong train dataset size {!r}'.format(
         experiment.task.train_data))
   if num_val_examples <= 0:
     raise ValueError('Wrong validation dataset size {!r}'.format(
         experiment.task.validation_data))
   experiment.task.train_data.global_batch_size = train_batch_size
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/configs/yt8m_test.py` & `tf-models-no-deps-2.16.0/official/projects/yt8m/configs/yt8m_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.projects.yt8m.configs import yt8m  # pylint: disable=unused-import
 from official.projects.yt8m.configs.yt8m import yt8m as exp_cfg
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/video_ssl/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/yt8m_model.py` & `tf-models-no-deps-2.16.0/official/vision/serving/video_classification.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,196 +1,187 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""YT8M model definition."""
-from typing import Optional
+"""Video classification input and model functions for serving/inference."""
+from typing import Mapping, Dict, Text
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from official.modeling import tf_utils
-from official.projects.yt8m.configs import yt8m as yt8m_cfg
-from official.projects.yt8m.modeling import nn_layers
-from official.projects.yt8m.modeling import yt8m_model_utils as utils
-
-layers = tf.keras.layers
-
-
-class DbofModel(tf.keras.Model):
-  """A YT8M model class builder.
-
-  Creates a Deep Bag of Frames model.
-  The model projects the features for each frame into a higher dimensional
-  'clustering' space, pools across frames in that space, and then
-  uses a configurable video-level model to classify the now aggregated features.
-  The model will randomly sample either frames or sequences of frames during
-  training to speed up convergence.
-  """
-
-  def __init__(
-      self,
-      params: yt8m_cfg.DbofModel,
-      num_frames: int = 30,
-      num_classes: int = 3862,
-      input_specs: layers.InputSpec = layers.InputSpec(
-          shape=[None, None, 1152]),
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      activation: str = "relu",
-      use_sync_bn: bool = False,
-      norm_momentum: float = 0.99,
-      norm_epsilon: float = 0.001,
-      **kwargs):
-    """YT8M initialization function.
+from official.vision.dataloaders import video_input
+from official.vision.serving import export_base
+from official.vision.tasks import video_classification
+
+
+class VideoClassificationModule(export_base.ExportModule):
+  """Video classification Module."""
+
+  def _build_model(self):
+    input_params = self.params.task.train_data
+    self._num_frames = input_params.feature_shape[0]
+    self._stride = input_params.temporal_stride
+    self._min_resize = input_params.min_image_size
+    self._crop_size = input_params.feature_shape[1]
+
+    self._output_audio = input_params.output_audio
+    task = video_classification.VideoClassificationTask(self.params.task)
+    return task.build_model()
+
+  def _decode_tf_example(self, encoded_inputs: tf.Tensor):
+    sequence_description = {
+        # Each image is a string encoding JPEG.
+        video_input.IMAGE_KEY:
+            tf.io.FixedLenSequenceFeature((), tf.string),
+    }
+    if self._output_audio:
+      sequence_description[self._params.task.validation_data.audio_feature] = (
+          tf.io.VarLenFeature(dtype=tf.float32))
+    _, decoded_tensors = tf.io.parse_single_sequence_example(
+        encoded_inputs, {}, sequence_description)
+    for key, value in decoded_tensors.items():
+      if isinstance(value, tf.SparseTensor):
+        decoded_tensors[key] = tf.sparse.to_dense(value)
+    return decoded_tensors
+
+  def _preprocess_image(self, image):
+    image = video_input.process_image(
+        image=image,
+        is_training=False,
+        num_frames=self._num_frames,
+        stride=self._stride,
+        num_test_clips=1,
+        min_resize=self._min_resize,
+        crop_size=self._crop_size,
+        num_crops=1)
+    image = tf.cast(image, tf.float32)  # Use config.
+    features = {'image': image}
+    return features
+
+  def _preprocess_audio(self, audio):
+    features = {}
+    audio = tf.cast(audio, dtype=tf.float32)  # Use config.
+    audio = video_input.preprocess_ops_3d.sample_sequence(
+        audio, 20, random=False, stride=1)
+    audio = tf.ensure_shape(
+        audio, self._params.task.validation_data.audio_feature_shape)
+    features['audio'] = audio
+    return features
+
+  @tf.function
+  def inference_from_tf_example(
+      self, encoded_inputs: tf.Tensor) -> Mapping[str, tf.Tensor]:
+    with tf.device('cpu:0'):
+      if self._output_audio:
+        inputs = tf.map_fn(
+            self._decode_tf_example, (encoded_inputs),
+            fn_output_signature={
+                video_input.IMAGE_KEY: tf.string,
+                self._params.task.validation_data.audio_feature: tf.float32
+            })
+        return self.serve(inputs['image'], inputs['audio'])
+      else:
+        inputs = tf.map_fn(
+            self._decode_tf_example, (encoded_inputs),
+            fn_output_signature={
+                video_input.IMAGE_KEY: tf.string,
+            })
+        return self.serve(inputs[video_input.IMAGE_KEY], tf.zeros([1, 1]))
+
+  @tf.function
+  def inference_from_image_tensors(
+      self, input_frames: tf.Tensor) -> Mapping[str, tf.Tensor]:
+    return self.serve(input_frames, tf.zeros([1, 1]))
+
+  @tf.function
+  def inference_from_image_audio_tensors(
+      self, input_frames: tf.Tensor,
+      input_audio: tf.Tensor) -> Mapping[str, tf.Tensor]:
+    return self.serve(input_frames, input_audio)
+
+  @tf.function
+  def inference_from_image_bytes(self, inputs: tf.Tensor):
+    raise NotImplementedError(
+        'Video classification do not support image bytes input.')
+
+  def serve(self, input_frames: tf.Tensor, input_audio: tf.Tensor):
+    """Cast image to float and run inference.
 
     Args:
-      params: model configuration parameters
-      num_frames: `int` number of frames in a single input.
-      num_classes: `int` number of classes in dataset.
-      input_specs: `tf.keras.layers.InputSpec` specs of the input tensor.
-        [batch_size x num_frames x num_features]
-      kernel_regularizer: tf.keras.regularizers.Regularizer object. Default to
-        None.
-      activation: A `str` of name of the activation function.
-      use_sync_bn: If True, use synchronized batch normalization.
-      norm_momentum: A `float` of normalization momentum for the moving average.
-      norm_epsilon: A `float` added to variance to avoid dividing by zero.
-      **kwargs: keyword arguments to be passed.
+      input_frames: uint8 Tensor of shape [batch_size, None, None, 3]
+      input_audio: float32
+
+    Returns:
+      Tensor holding classification output logits.
     """
-    del num_frames
-    self._self_setattr_tracking = False
-    self._config_dict = {
-        "input_specs": input_specs,
-        "num_classes": num_classes,
-        "params": params
-    }
-    self._num_classes = num_classes
-    self._input_specs = input_specs
-    self._act_fn = tf_utils.get_activation(activation)
-    if use_sync_bn:
-      self._norm = layers.experimental.SyncBatchNormalization
+    with tf.device('cpu:0'):
+      inputs = tf.map_fn(
+          self._preprocess_image, (input_frames),
+          fn_output_signature={
+              'image': tf.float32,
+          })
+      if self._output_audio:
+        inputs.update(
+            tf.map_fn(
+                self._preprocess_audio, (input_audio),
+                fn_output_signature={'audio': tf.float32}))
+    logits = self.inference_step(inputs)
+    if self.params.task.train_data.is_multilabel:
+      probs = tf.math.sigmoid(logits)
     else:
-      self._norm = layers.BatchNormalization
+      probs = tf.nn.softmax(logits)
+    return {'logits': logits, 'probs': probs}
 
-    bn_axis = -1
-    # [batch_size x num_frames x num_features]
-    feature_size = input_specs.shape[-1]
-    # shape 'excluding' batch_size
-    model_input = tf.keras.Input(shape=self._input_specs.shape[1:])
-    # normalize input features
-    input_data = tf.nn.l2_normalize(model_input, -1)
-    tf.summary.histogram("input_hist", input_data)
-
-    # configure model
-    if params.add_batch_norm:
-      input_data = self._norm(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          name="input_bn")(
-              input_data)
-
-    # activation = reshaped input * cluster weights
-    if params.cluster_size > 0:
-      activation = layers.Dense(
-          params.cluster_size,
-          kernel_regularizer=kernel_regularizer,
-          kernel_initializer=tf.random_normal_initializer(
-              stddev=1 / tf.sqrt(tf.cast(feature_size, tf.float32))))(
-                  input_data)
-
-    if params.add_batch_norm:
-      activation = self._norm(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          name="cluster_bn")(
-              activation)
-    else:
-      cluster_biases = tf.Variable(
-          tf.random_normal_initializer(stddev=1 / tf.math.sqrt(feature_size))(
-              shape=[params.cluster_size]),
-          name="cluster_biases")
-      tf.summary.histogram("cluster_biases", cluster_biases)
-      activation += cluster_biases
-
-    activation = self._act_fn(activation)
-    tf.summary.histogram("cluster_output", activation)
-
-    if params.use_context_gate_cluster_layer:
-      pooling_method = None
-      norm_args = dict(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          name="context_gate_bn")
-      activation = utils.context_gate(
-          activation,
-          normalizer_fn=self._norm,
-          normalizer_params=norm_args,
-          pooling_method=pooling_method,
-          hidden_layer_size=params.context_gate_cluster_bottleneck_size,
-          kernel_regularizer=kernel_regularizer)
-
-    activation = utils.frame_pooling(activation, params.pooling_method)
-
-    # activation = activation * hidden1_weights
-    activation = layers.Dense(
-        params.hidden_size,
-        kernel_regularizer=kernel_regularizer,
-        kernel_initializer=tf.random_normal_initializer(
-            stddev=1 / tf.sqrt(tf.cast(params.cluster_size, tf.float32))))(
-                activation)
-
-    if params.add_batch_norm:
-      activation = self._norm(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          name="hidden1_bn")(
-              activation)
+  def get_inference_signatures(self, function_keys: Dict[Text, Text]):
+    """Gets defined function signatures.
 
-    else:
-      hidden1_biases = tf.Variable(
-          tf.random_normal_initializer(stddev=0.01)(shape=[params.hidden_size]),
-          name="hidden1_biases")
-
-      tf.summary.histogram("hidden1_biases", hidden1_biases)
-      activation += hidden1_biases
-
-    activation = self._act_fn(activation)
-    tf.summary.histogram("hidden1_output", activation)
-
-    aggregated_model = getattr(nn_layers,
-                               params.yt8m_agg_classifier_model)
-    norm_args = dict(axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)
-    output = aggregated_model().create_model(
-        model_input=activation,
-        vocab_size=self._num_classes,
-        num_mixtures=params.agg_model.num_mixtures,
-        normalizer_fn=self._norm,
-        normalizer_params=norm_args,
-        l2_penalty=params.agg_model.l2_penalty)
-
-    super().__init__(
-        inputs=model_input, outputs=output.get("predictions"), **kwargs)
-
-  @property
-  def checkpoint_items(self):
-    """Returns a dictionary of items to be additionally checkpointed."""
-    return dict()
-
-  def get_config(self):
-    return self._config_dict
-
-  @classmethod
-  def from_config(cls, config):
-    return cls(**config)
+    Args:
+      function_keys: A dictionary with keys as the function to create signature
+        for and values as the signature keys when returns.
+
+    Returns:
+      A dictionary with key as signature key and value as concrete functions
+        that can be used for tf.saved_model.save.
+    """
+    signatures = {}
+    for key, def_name in function_keys.items():
+      if key == 'image_tensor':
+        input_signature = tf.TensorSpec(
+            shape=[self._batch_size] + self._input_image_size + [3],
+            dtype=tf.uint8,
+            name='INPUT_FRAMES')
+        signatures[
+            def_name] = self.inference_from_image_tensors.get_concrete_function(
+                input_signature)
+      elif key == 'frames_audio':
+        input_signature = [
+            tf.TensorSpec(
+                shape=[self._batch_size] + self._input_image_size + [3],
+                dtype=tf.uint8,
+                name='INPUT_FRAMES'),
+            tf.TensorSpec(
+                shape=[self._batch_size] +
+                self.params.task.train_data.audio_feature_shape,
+                dtype=tf.float32,
+                name='INPUT_AUDIO')
+        ]
+        signatures[
+            def_name] = self.inference_from_image_audio_tensors.get_concrete_function(
+                input_signature)
+      elif key == 'serve_examples' or key == 'tf_example':
+        input_signature = tf.TensorSpec(
+            shape=[self._batch_size], dtype=tf.string)
+        signatures[
+            def_name] = self.inference_from_tf_example.get_concrete_function(
+                input_signature)
+      else:
+        raise ValueError('Unrecognized `input_type`')
+    return signatures
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/modeling/yt8m_model_test.py` & `tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/yt8m_model_test.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,51 +12,69 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for yt8m network."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.projects.yt8m.configs import yt8m as yt8m_cfg
 from official.projects.yt8m.modeling import yt8m_model
 
 
 class YT8MNetworkTest(parameterized.TestCase, tf.test.TestCase):
   """Class for testing yt8m network."""
 
   # test_yt8m_network_creation arbitrary params
-  @parameterized.parameters((32, 1152))  # 1152 = 1024 + 128
-  def test_yt8m_network_creation(self, num_frames, feature_dims):
+  @parameterized.product(
+      num_sample_frames=(None, 16, 32),
+      pooling_method=('average', 'max', 'swap'),
+  )
+  def test_yt8m_network_creation(
+      self, num_sample_frames, pooling_method
+  ):
     """Test for creation of a YT8M Model.
 
     Args:
-      num_frames: number of frames.
-      feature_dims: indicates total dimension size of the features.
+      num_sample_frames: indicates number of frames to sample.
+      pooling_method: str of frame pooling method.
     """
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, feature_dims])
-
-    num_classes = 3862
-    model = yt8m_model.DbofModel(
-        params=yt8m_cfg.YT8MTask.model,
-        num_frames=num_frames,
+    num_frames = 24
+    feature_dims = 52
+    num_classes = 45
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, feature_dims])
+
+    params = yt8m_cfg.YT8MTask().model
+    params.backbone.dbof.pooling_method = pooling_method
+    model = yt8m_model.VideoClassificationModel(
+        params=params,
         num_classes=num_classes,
-        input_specs=input_specs)
+        input_specs=input_specs,
+    )
+
+    # batch = 2 -> arbitrary value for test.
+    if num_sample_frames:
+      inputs = np.random.rand(2, num_sample_frames, feature_dims)
+      num_frames = tf.constant([num_sample_frames, num_sample_frames])
+    else:
+      # Add padding frames.
+      inputs = np.random.rand(2, num_frames + 4, feature_dims)
+      num_frames = tf.constant([num_frames, num_frames + 1])
 
-    # batch = 2 -> arbitrary value for test
-    inputs = np.random.rand(2, num_frames, feature_dims)
-    logits = model(inputs)
-    self.assertAllEqual([2, num_classes], logits.numpy().shape)
+    predictions = model(inputs, num_frames=num_frames)['predictions']
+    self.assertAllEqual([2, num_classes], predictions.numpy().shape)
 
   def test_serialize_deserialize(self):
-    model = yt8m_model.DbofModel(params=yt8m_cfg.YT8MTask.model)
+    model = yt8m_model.VideoClassificationModel(
+        params=yt8m_cfg.YT8MTask().model
+    )
 
     config = model.get_config()
-    new_model = yt8m_model.DbofModel.from_config(config)
+    new_model = yt8m_model.VideoClassificationModel.from_config(config)
 
     # If the serialization was successful,
     # the new config should match the old.
     self.assertAllEqual(model.get_config(), new_model.get_config())
 
 
 if __name__ == '__main__':
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/tasks/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/yt8m/modeling/heads/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,18 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Tasks package definition."""
-from official.projects.yt8m.tasks import yt8m_task
+"""Aggregation heads package definition."""
+
+from official.projects.yt8m.modeling.heads.logistic import LogisticModel
+from official.projects.yt8m.modeling.heads.moe import MoeModel
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/tasks/yt8m_task.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/tasks/semantic_segmentation_3d.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,348 +1,349 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Video classification task definition."""
-from typing import Dict, List, Optional, Tuple
+"""Image segmentation task definition."""
+from typing import Any, Dict, Mapping, Optional, Sequence, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
+from official.common import dataset_fn
 from official.core import base_task
 from official.core import input_reader
 from official.core import task_factory
-from official.modeling import tf_utils
-from official.projects.yt8m.configs import yt8m as yt8m_cfg
-from official.projects.yt8m.dataloaders import yt8m_input
-from official.projects.yt8m.eval_utils import eval_util
-from official.projects.yt8m.modeling import yt8m_model_utils as utils
-from official.projects.yt8m.modeling.yt8m_model import DbofModel
-
-
-@task_factory.register_task_cls(yt8m_cfg.YT8MTask)
-class YT8MTask(base_task.Task):
-  """A task for video classification."""
-
-  def build_model(self):
-    """Builds model for YT8M Task."""
-    train_cfg = self.task_config.train_data
-    common_input_shape = [None, sum(train_cfg.feature_sizes)]
-
-    # [batch_size x num_frames x num_features]
-    input_specs = tf.keras.layers.InputSpec(shape=[None] + common_input_shape)
-    logging.info('Build model input %r', common_input_shape)
+from official.projects.volumetric_models.configs import semantic_segmentation_3d as exp_cfg
+from official.projects.volumetric_models.dataloaders import segmentation_input_3d
+from official.projects.volumetric_models.evaluation import segmentation_metrics
+from official.projects.volumetric_models.losses import segmentation_losses
+from official.projects.volumetric_models.modeling import factory
+
+
+@task_factory.register_task_cls(exp_cfg.SemanticSegmentation3DTask)
+class SemanticSegmentation3DTask(base_task.Task):
+  """A task for semantic segmentation."""
+
+  def build_model(self) -> tf_keras.Model:
+    """Builds segmentation model."""
+    input_specs = tf_keras.layers.InputSpec(
+        shape=[None] + self.task_config.model.input_size +
+        [self.task_config.model.num_channels],
+        dtype=self.task_config.train_data.dtype)
 
     l2_weight_decay = self.task_config.losses.l2_weight_decay
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
     l2_regularizer = (
-        tf.keras.regularizers.l2(l2_weight_decay /
+        tf_keras.regularizers.l2(l2_weight_decay /
                                  2.0) if l2_weight_decay else None)
-    # Model configuration.
-    model_config = self.task_config.model
-    norm_activation_config = model_config.norm_activation
-    model = DbofModel(
-        params=model_config,
-        input_specs=input_specs,
-        num_frames=train_cfg.num_frames,
-        num_classes=train_cfg.num_classes,
-        activation=norm_activation_config.activation,
-        use_sync_bn=norm_activation_config.use_sync_bn,
-        norm_momentum=norm_activation_config.norm_momentum,
-        norm_epsilon=norm_activation_config.norm_epsilon,
-        kernel_regularizer=l2_regularizer)
-    return model
 
-  def build_inputs(self, params: yt8m_cfg.DataConfig, input_context=None):
-    """Builds input.
+    model = factory.build_segmentation_model_3d(
+        input_specs=input_specs,
+        model_config=self.task_config.model,
+        l2_regularizer=l2_regularizer)
 
-    Args:
-      params: configuration for input data
-      input_context: indicates information about the compute replicas and input
-        pipelines
+    # Create a dummy input and call model instance to initialize the model. This
+    # is needed when launching multiple experiments using the same model
+    # directory. Since there is already a trained model, forward pass will not
+    # run and the model will never be built. This is only done when spatial
+    # partitioning is not enabled; otherwise it will fail with OOM due to
+    # extremely large input.
+    if (not self.task_config.train_input_partition_dims) and (
+        not self.task_config.eval_input_partition_dims):
+      dummy_input = tf.random.uniform(shape=[1] + list(input_specs.shape[1:]))
+      _ = model(dummy_input)
 
-    Returns:
-      dataset: dataset fetched from reader
-    """
+    return model
 
-    decoder = yt8m_input.Decoder(input_params=params)
-    decoder_fn = decoder.decode
-    parser = yt8m_input.Parser(input_params=params)
-    parser_fn = parser.parse_fn(params.is_training)
-    postprocess = yt8m_input.PostBatchProcessor(input_params=params)
-    postprocess_fn = postprocess.post_fn
-    transform_batch = yt8m_input.TransformBatcher(input_params=params)
-    batch_fn = transform_batch.batch_fn
+  def initialize(self, model: tf_keras.Model):
+    """Loads pretrained checkpoint."""
+    if not self.task_config.init_checkpoint:
+      return
+
+    ckpt_dir_or_file = self.task_config.init_checkpoint
+    if tf.io.gfile.isdir(ckpt_dir_or_file):
+      ckpt_dir_or_file = tf.train.latest_checkpoint(ckpt_dir_or_file)
+
+    # Restoring checkpoint.
+    if 'all' in self.task_config.init_checkpoint_modules:
+      ckpt = tf.train.Checkpoint(**model.checkpoint_items)
+      status = ckpt.read(ckpt_dir_or_file)
+      status.expect_partial().assert_existing_objects_matched()
+    else:
+      ckpt_items = {}
+      if 'backbone' in self.task_config.init_checkpoint_modules:
+        ckpt_items.update(backbone=model.backbone)
+      if 'decoder' in self.task_config.init_checkpoint_modules:
+        ckpt_items.update(decoder=model.decoder)
+
+      ckpt = tf.train.Checkpoint(**ckpt_items)
+      status = ckpt.read(ckpt_dir_or_file)
+      status.expect_partial().assert_existing_objects_matched()
+
+    logging.info('Finished loading pretrained checkpoint from %s',
+                 ckpt_dir_or_file)
+
+  def build_inputs(self, params, input_context=None) -> tf.data.Dataset:
+    """Builds classification input."""
+    decoder = segmentation_input_3d.Decoder(
+        image_field_key=params.image_field_key,
+        label_field_key=params.label_field_key)
+    parser = segmentation_input_3d.Parser(
+        input_size=params.input_size,
+        num_classes=params.num_classes,
+        num_channels=params.num_channels,
+        image_field_key=params.image_field_key,
+        label_field_key=params.label_field_key,
+        dtype=params.dtype,
+        label_dtype=params.label_dtype)
 
     reader = input_reader.InputReader(
         params,
-        dataset_fn=tf.data.TFRecordDataset,
-        decoder_fn=decoder_fn,
-        parser_fn=parser_fn,
-        postprocess_fn=postprocess_fn,
-        transform_and_batch_fn=batch_fn)
+        dataset_fn=dataset_fn.pick_dataset_fn(params.file_type),
+        decoder_fn=decoder.decode,
+        parser_fn=parser.parse_fn(params.is_training))
 
     dataset = reader.read(input_context=input_context)
 
     return dataset
 
   def build_losses(self,
-                   labels,
-                   model_outputs,
-                   label_weights=None,
-                   aux_losses=None):
-    """Sigmoid Cross Entropy.
+                   labels: tf.Tensor,
+                   model_outputs: tf.Tensor,
+                   aux_losses=None) -> tf.Tensor:
+    """Segmentation loss.
 
     Args:
-      labels: tensor containing truth labels.
-      model_outputs: output logits of the classifier.
-      label_weights: optional tensor of label weights.
-      aux_losses: tensor containing auxiliarly loss tensors, i.e. `losses` in
-        keras.Model.
+      labels: labels.
+      model_outputs: Output logits of the classifier.
+      aux_losses: auxiliarly loss tensors, i.e. `losses` in keras.Model.
 
     Returns:
-      A dict of tensors contains total loss, model loss tensors.
+      The total loss tensor.
     """
-    losses_config = self.task_config.losses
-    model_loss = tf.keras.losses.binary_crossentropy(
-        labels,
-        model_outputs,
-        from_logits=losses_config.from_logits,
-        label_smoothing=losses_config.label_smoothing,
-        axis=None)
+    segmentation_loss_fn = segmentation_losses.SegmentationLossDiceScore(
+        metric_type='adaptive')
 
-    if label_weights is None:
-      model_loss = tf_utils.safe_mean(model_loss)
-    else:
-      model_loss = model_loss * label_weights
-      # Manutally compute weighted mean loss.
-      total_loss = tf.reduce_sum(model_loss)
-      total_weight = tf.cast(
-          tf.reduce_sum(label_weights), dtype=total_loss.dtype)
-      model_loss = tf.math.divide_no_nan(total_loss, total_weight)
+    total_loss = segmentation_loss_fn(model_outputs, labels)
 
-    total_loss = model_loss
     if aux_losses:
       total_loss += tf.add_n(aux_losses)
 
-    return {'total_loss': total_loss, 'model_loss': model_loss}
-
-  def build_metrics(self, training=True):
-    """Gets streaming metrics for training/validation.
-
-       metric: mAP/gAP
-       top_k: A positive integer specifying how many predictions are considered
-        per video.
-       top_n: A positive Integer specifying the average precision at n, or None
-        to use all provided data points.
-    Args:
-      training: Bool value, true for training mode, false for eval/validation.
+    return total_loss
 
-    Returns:
-      A list of strings that indicate metrics to be used.
-    """
+  def build_metrics(self,
+                    training: bool = True) -> Sequence[tf_keras.metrics.Metric]:
+    """Gets streaming metrics for training/validation."""
     metrics = []
-    metric_names = ['total_loss', 'model_loss']
-    for name in metric_names:
-      metrics.append(tf.keras.metrics.Mean(name, dtype=tf.float32))
-
-    if not training:  # Cannot run in train step.
-      num_classes = self.task_config.validation_data.num_classes
-      top_k = self.task_config.top_k
-      top_n = self.task_config.top_n
-      self.avg_prec_metric = eval_util.EvaluationMetrics(
-          num_classes, top_k=top_k, top_n=top_n)
+    num_classes = self.task_config.model.num_classes
+    if training:
+      metrics.extend([
+          tf_keras.metrics.CategoricalAccuracy(
+              name='train_categorical_accuracy', dtype=tf.float32)
+      ])
+    else:
+      self.metrics = [
+          segmentation_metrics.DiceScore(
+              num_classes=num_classes,
+              metric_type='generalized',
+              per_class_metric=self.task_config.evaluation
+              .report_per_class_metric,
+              name='val_generalized_dice',
+              dtype=tf.float32)
+      ]
 
     return metrics
 
-  def process_metrics(self,
-                      metrics: List[tf.keras.metrics.Metric],
-                      labels: tf.Tensor,
-                      outputs: tf.Tensor,
-                      model_losses: Optional[Dict[str, tf.Tensor]] = None,
-                      label_weights: Optional[tf.Tensor] = None,
-                      training: bool = True,
-                      **kwargs) -> Dict[str, Tuple[tf.Tensor, ...]]:
-    """Updates metrics.
-
-    Args:
-      metrics: Evaluation metrics to be updated.
-      labels: A tensor containing truth labels.
-      outputs: Model output logits of the classifier.
-      model_losses: An optional dict of model losses.
-      label_weights: Optional label weights, can be broadcast into shape of
-        outputs/labels.
-      training: Bool indicates if in training mode.
-      **kwargs: Additional input arguments.
-
-    Returns:
-      Updated dict of metrics log.
-    """
-    if model_losses is None:
-      model_losses = {}
-
-    logs = {}
-    if not training:
-      logs.update({self.avg_prec_metric.name: (labels, outputs)})
-
-    for m in metrics:
-      m.update_state(model_losses[m.name])
-      logs[m.name] = m.result()
-    return logs
-
-  def train_step(self, inputs, model, optimizer, metrics=None):
+  def train_step(
+      self,
+      inputs,
+      model: tf_keras.Model,
+      optimizer: tf_keras.optimizers.Optimizer,
+      metrics: Optional[Sequence[tf_keras.metrics.Metric]] = None
+  ) -> Dict[Any, Any]:
     """Does forward and backward.
 
     Args:
-      inputs: a dictionary of input tensors. output_dict = { "video_ids":
-        batch_video_ids, "video_matrix": batch_video_matrix, "labels":
-        batch_labels, "num_frames": batch_frames, }
+      inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
       metrics: a nested structure of metrics objects.
 
     Returns:
-      a dictionary of logs.
+      A dictionary of logs.
     """
-    features, labels = inputs['video_matrix'], inputs['labels']
-    num_frames = inputs['num_frames']
-    label_weights = inputs.get('label_weights', None)
-
-    # sample random frames / random sequence
-    num_frames = tf.cast(num_frames, tf.float32)
-    sample_frames = self.task_config.train_data.num_frames
-    if self.task_config.model.sample_random_frames:
-      features = utils.sample_random_frames(features, num_frames, sample_frames)
-    else:
-      features = utils.sample_random_sequence(features, num_frames,
-                                              sample_frames)
+    features, labels = inputs
+
+    input_partition_dims = self.task_config.train_input_partition_dims
+    if input_partition_dims:
+      strategy = tf.distribute.get_strategy()
+      features = strategy.experimental_split_to_logical_devices(
+          features, input_partition_dims)
 
     num_replicas = tf.distribute.get_strategy().num_replicas_in_sync
     with tf.GradientTape() as tape:
       outputs = model(features, training=True)
       # Casting output layer as float32 is necessary when mixed_precision is
       # mixed_float16 or mixed_bfloat16 to ensure output is casted as float32.
       outputs = tf.nest.map_structure(lambda x: tf.cast(x, tf.float32), outputs)
-      # Computes per-replica loss
-      all_losses = self.build_losses(
-          model_outputs=outputs,
-          labels=labels,
-          label_weights=label_weights,
-          aux_losses=model.losses)
 
-      loss = all_losses['total_loss']
+      outputs = outputs['logits']
+      if self.task_config.model.head.output_logits:
+        outputs = tf.nn.softmax(outputs)
+
+      # Computes per-replica loss.
+      loss = self.build_losses(
+          labels=labels, model_outputs=outputs, aux_losses=model.losses)
       # Scales loss as the default gradients allreduce performs sum inside the
       # optimizer.
       scaled_loss = loss / num_replicas
 
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     # Scales back gradient before apply_gradients when LossScaleOptimizer is
     # used.
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
-
-    # Apply gradient clipping.
-    if self.task_config.gradient_clip_norm > 0:
-      grads, _ = tf.clip_by_global_norm(grads,
-                                        self.task_config.gradient_clip_norm)
     optimizer.apply_gradients(list(zip(grads, tvars)))
 
     logs = {self.loss: loss}
 
-    logs.update(
-        self.process_metrics(
-            metrics,
-            labels=labels,
-            outputs=outputs,
-            model_losses=all_losses,
-            label_weights=label_weights,
-            training=True))
+    # Compute all metrics within strategy scope for training.
+    if metrics:
+      labels = tf.cast(labels, tf.float32)
+      outputs = tf.cast(outputs, tf.float32)
+      self.process_metrics(metrics, labels, outputs)
+      logs.update({m.name: m.result() for m in metrics})
 
     return logs
 
-  def validation_step(self, inputs, model, metrics=None):
+  def validation_step(
+      self,
+      inputs,
+      model: tf_keras.Model,
+      metrics: Optional[Sequence[tf_keras.metrics.Metric]] = None
+  ) -> Dict[Any, Any]:
     """Validatation step.
 
     Args:
-      inputs: a dictionary of input tensors. output_dict = { "video_ids":
-        batch_video_ids, "video_matrix": batch_video_matrix, "labels":
-        batch_labels, "num_frames": batch_frames, }
-      model: the model, forward definition
+      inputs: a dictionary of input tensors.
+      model: the keras.Model.
       metrics: a nested structure of metrics objects.
 
     Returns:
-      a dictionary of logs.
+      A dictionary of logs.
     """
-    features, labels = inputs['video_matrix'], inputs['labels']
-    num_frames = inputs['num_frames']
-    label_weights = inputs.get('label_weights', None)
-
-    # sample random frames (None, 5, 1152) -> (None, 30, 1152)
-    sample_frames = self.task_config.validation_data.num_frames
-    if self.task_config.model.sample_random_frames:
-      features = utils.sample_random_frames(features, num_frames, sample_frames)
-    else:
-      features = utils.sample_random_sequence(features, num_frames,
-                                              sample_frames)
+    features, labels = inputs
+
+    input_partition_dims = self.task_config.eval_input_partition_dims
+    if input_partition_dims:
+      strategy = tf.distribute.get_strategy()
+      features = strategy.experimental_split_to_logical_devices(
+          features, input_partition_dims)
 
     outputs = self.inference_step(features, model)
     outputs = tf.nest.map_structure(lambda x: tf.cast(x, tf.float32), outputs)
-    if self.task_config.validation_data.segment_labels:
-      # workaround to ignore the unrated labels.
-      outputs *= label_weights
-      # remove padding
-      outputs = outputs[~tf.reduce_all(labels == -1, axis=1)]
-      labels = labels[~tf.reduce_all(labels == -1, axis=1)]
-
-    all_losses = self.build_losses(
-        labels=labels,
-        model_outputs=outputs,
-        label_weights=label_weights,
-        aux_losses=model.losses)
-
-    logs = {self.loss: all_losses['total_loss']}
-
-    logs.update(
-        self.process_metrics(
-            metrics,
-            labels=labels,
-            outputs=outputs,
-            model_losses=all_losses,
-            label_weights=inputs.get('label_weights', None),
-            training=False))
+    outputs = outputs['logits']
+    if self.task_config.model.head.output_logits:
+      outputs = tf.nn.softmax(outputs)
+
+    loss = self.build_losses(
+        model_outputs=outputs, labels=labels, aux_losses=model.losses)
+    logs = {self.loss: loss}
+
+    # Compute dice score metrics on CPU.
+    for metric in self.metrics:
+      labels = tf.cast(labels, tf.float32)
+      logits = tf.cast(outputs, tf.float32)
+      logs.update({metric.name: (labels, logits)})
 
     return logs
 
-  def inference_step(self, inputs, model):
+  def inference_step(self, inputs, model: tf_keras.Model) -> tf.Tensor:
     """Performs the forward step."""
     return model(inputs, training=False)
 
-  def aggregate_logs(self, state=None, step_logs=None):
+  def aggregate_logs(
+      self,
+      state: Optional[Sequence[Union[segmentation_metrics.DiceScore,
+                                     tf_keras.metrics.Metric]]] = None,
+      step_outputs: Optional[Mapping[str, Any]] = None
+  ) -> Sequence[tf_keras.metrics.Metric]:
+    """Aggregates statistics to compute metrics over training.
+
+    Args:
+      state: A sequence of tf_keras.metrics.Metric objects. Each element records
+        a metric.
+      step_outputs: A dictionary of [metric_name, (labels, output)] from a step.
+
+    Returns:
+      An updated sequence of tf_keras.metrics.Metric objects.
+    """
     if state is None:
-      state = self.avg_prec_metric
-    self.avg_prec_metric.accumulate(
-        labels=step_logs[self.avg_prec_metric.name][0],
-        predictions=step_logs[self.avg_prec_metric.name][1])
+      for metric in self.metrics:
+        metric.reset_states()
+      state = self.metrics
+
+    for metric in self.metrics:
+      labels = step_outputs[metric.name][0]
+      predictions = step_outputs[metric.name][1]
+
+      # If `step_output` is distributed, it contains a tuple of Tensors instead
+      # of a single Tensor, so we need to concatenate them along the batch
+      # dimension in this case to have a single Tensor.
+      if isinstance(labels, tuple):
+        labels = tf.concat(list(labels), axis=0)
+      if isinstance(predictions, tuple):
+        predictions = tf.concat(list(predictions), axis=0)
+
+      labels = tf.cast(labels, tf.float32)
+      predictions = tf.cast(predictions, tf.float32)
+      metric.update_state(labels, predictions)
     return state
 
-  def reduce_aggregated_logs(self, aggregated_logs, global_step=None):
-    avg_prec_metrics = self.avg_prec_metric.get()
-    self.avg_prec_metric.clear()
-    return avg_prec_metrics
+  def reduce_aggregated_logs(
+      self,
+      aggregated_logs: Optional[Mapping[str, Any]] = None,
+      global_step: Optional[tf.Tensor] = None) -> Mapping[str, float]:
+    """Reduces logs to obtain per-class metrics if needed.
+
+    Args:
+      aggregated_logs: An optional dictionary containing aggregated logs.
+      global_step: An optional `tf.Tensor` of current global training steps.
+
+    Returns:
+      The reduced logs containing per-class metrics and overall metrics.
+
+    Raises:
+      ValueError: If `self.metrics` does not contain exactly 1 metric object.
+    """
+    result = {}
+    if len(self.metrics) != 1:
+      raise ValueError('Exact one metric must be present, but {0} are '
+                       'present.'.format(len(self.metrics)))
+
+    metric = self.metrics[0].result().numpy()
+    if self.task_config.evaluation.report_per_class_metric:
+      for i, metric_val in enumerate(metric):
+        metric_name = self.metrics[0].name + '/class_{0}'.format(
+            i - 1) if i > 0 else self.metrics[0].name
+        result.update({metric_name: metric_val})
+    else:
+      result.update({self.metrics[0].name: metric})
+    return result
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/train.py` & `tf-models-no-deps-2.16.0/official/projects/yt8m/train.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/projects/yt8m/train_test.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/train_test.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,98 +1,102 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+"""Tests for train."""
 import json
 import os
 
 from absl import flags
+from absl import logging
 from absl.testing import flagsaver
-from absl.testing import parameterized
-import tensorflow as tf
-from official.projects.yt8m import train as train_lib
-from official.projects.yt8m.dataloaders import utils
+import tensorflow as tf, tf_keras
+from official.projects.volumetric_models import train as train_lib
 from official.vision.dataloaders import tfexample_utils
 
 FLAGS = flags.FLAGS
 
 
-class TrainTest(parameterized.TestCase, tf.test.TestCase):
+class TrainTest(tf.test.TestCase):
 
   def setUp(self):
     super().setUp()
     self._model_dir = os.path.join(self.get_temp_dir(), 'model_dir')
     tf.io.gfile.makedirs(self._model_dir)
 
     data_dir = os.path.join(self.get_temp_dir(), 'data')
     tf.io.gfile.makedirs(data_dir)
     self._data_path = os.path.join(data_dir, 'data.tfrecord')
-    examples = [utils.make_yt8m_example() for _ in range(8)]
+    # pylint: disable=g-complex-comprehension
+    examples = [
+        tfexample_utils.create_3d_image_test_example(
+            image_height=32, image_width=32, image_volume=32, image_channel=2)
+        for _ in range(2)
+    ]
+    # pylint: enable=g-complex-comprehension
     tfexample_utils.dump_to_tfrecord(self._data_path, tf_examples=examples)
 
-  @parameterized.named_parameters(
-      dict(testcase_name='segment', use_segment_level_labels=True),
-      dict(testcase_name='video', use_segment_level_labels=False))
-  def test_train_and_eval(self, use_segment_level_labels):
+  def test_run(self):
     saved_flag_values = flagsaver.save_flag_values()
     train_lib.tfm_flags.define_flags()
     FLAGS.mode = 'train'
     FLAGS.model_dir = self._model_dir
-    FLAGS.experiment = 'yt8m_experiment'
-    FLAGS.tpu = ''
+    FLAGS.experiment = 'seg_unet3d_test'
+    logging.info('Test pipeline correctness.')
 
     params_override = json.dumps({
         'runtime': {
-            'distribution_strategy': 'mirrored',
             'mixed_precision_dtype': 'float32',
         },
         'trainer': {
             'train_steps': 1,
             'validation_steps': 1,
         },
         'task': {
             'model': {
-                'cluster_size': 16,
-                'hidden_size': 16,
-                'use_context_gate_cluster_layer': True,
-                'agg_model': {
-                    'use_input_context_gate': True,
-                    'use_output_context_gate': True,
+                'backbone': {
+                    'unet_3d': {
+                        'model_id': 4,
+                    },
+                },
+                'decoder': {
+                    'unet_3d_decoder': {
+                        'model_id': 4,
+                    },
                 },
             },
             'train_data': {
                 'input_path': self._data_path,
-                'global_batch_size': 4,
+                'file_type': 'tfrecord',
+                'global_batch_size': 2,
             },
             'validation_data': {
                 'input_path': self._data_path,
-                'segment_labels': use_segment_level_labels,
-                'global_batch_size': 4,
+                'file_type': 'tfrecord',
+                'global_batch_size': 2,
             }
         }
     })
     FLAGS.params_override = params_override
 
-    with train_lib.train.gin.unlock_config():
-      train_lib.train.main('unused_args')
+    train_lib.main('unused_args')
 
     FLAGS.mode = 'eval'
 
-    with train_lib.train.gin.unlock_config():
-      train_lib.train.main('unused_args')
+    with train_lib.gin.unlock_config():
+      train_lib.main('unused_args')
 
     flagsaver.restore_flag_values(saved_flag_values)
 
 
 if __name__ == '__main__':
-  tf.config.set_soft_device_placement(True)
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/video_ssl/ops/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/constants.py` & `tf-models-no-deps-2.16.0/official/recommendation/constants.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/create_ncf_data.py` & `tf-models-no-deps-2.16.0/official/recommendation/create_ncf_data.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import json
 
 # pylint: disable=g-bad-import-order
 # Import libraries
 from absl import app
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 # pylint: enable=g-bad-import-order
 
 from official.recommendation import movielens
 from official.recommendation import data_preprocessing
 
 flags.DEFINE_string(
     "data_dir", None,
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/data_pipeline.py` & `tf-models-no-deps-2.16.0/official/recommendation/data_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -28,15 +28,15 @@
 import timeit
 import traceback
 import typing
 
 from absl import logging
 import numpy as np
 from six.moves import queue
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.tpu.datasets import StreamingFilesDataset
 from official.recommendation import constants as rconst
 from official.recommendation import movielens
 from official.recommendation import popen_helper
 from official.recommendation import stat_utils
 
@@ -313,22 +313,22 @@
       }
       shapes = {
           movielens.USER_COLUMN: tf.TensorShape([batch_size, 1]),
           movielens.ITEM_COLUMN: tf.TensorShape([batch_size, 1])
       }
 
       if self._is_training:
-        types[rconst.VALID_POINT_MASK] = np.bool
+        types[rconst.VALID_POINT_MASK] = bool
         shapes[rconst.VALID_POINT_MASK] = tf.TensorShape([batch_size, 1])
 
-        types = (types, np.bool)
+        types = (types, bool)
         shapes = (shapes, tf.TensorShape([batch_size, 1]))
 
       else:
-        types[rconst.DUPLICATE_MASK] = np.bool
+        types[rconst.DUPLICATE_MASK] = bool
         shapes[rconst.DUPLICATE_MASK] = tf.TensorShape([batch_size, 1])
 
       data_generator = functools.partial(
           self.data_generator, epochs_between_evals=epochs_between_evals)
       dataset = tf.data.Dataset.from_generator(
           generator=data_generator, output_types=types, output_shapes=shapes)
 
@@ -633,15 +633,15 @@
     # except the positive being marked as duplicate to mask out padded points.
     if users.shape[0] < users_per_batch:
       pad_rows = users_per_batch - users.shape[0]
       padding = np.zeros(shape=(pad_rows, users.shape[1]), dtype=np.int32)
       users = np.concatenate([users, padding.astype(users.dtype)], axis=0)
       items = np.concatenate([items, padding.astype(items.dtype)], axis=0)
 
-    duplicate_mask = stat_utils.mask_duplicates(items, axis=1).astype(np.bool)
+    duplicate_mask = stat_utils.mask_duplicates(items, axis=1).astype(bool)
 
     items[:, (0, -1)] = items[:, (-1, 0)]
     duplicate_mask[:, (0, -1)] = duplicate_mask[:, (-1, 0)]
 
     assert users.shape == items.shape == duplicate_mask.shape
     return users, items, duplicate_mask
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/data_preprocessing.py` & `tf-models-no-deps-2.16.0/official/recommendation/data_preprocessing.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -24,15 +24,15 @@
 import timeit
 import typing
 from typing import Dict, Text, Tuple
 
 from absl import logging
 import numpy as np
 import pandas as pd
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.recommendation import constants as rconst
 from official.recommendation import data_pipeline
 from official.recommendation import movielens
 
 
 _EXPECTED_CACHE_KEYS = (rconst.TRAIN_USER_KEY, rconst.TRAIN_ITEM_KEY,
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/data_test.py` & `tf-models-no-deps-2.16.0/official/recommendation/data_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,15 +22,15 @@
 import hashlib
 import os
 
 import mock
 
 import numpy as np
 import scipy.stats
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.recommendation import constants as rconst
 from official.recommendation import data_preprocessing
 from official.recommendation import movielens
 from official.recommendation import popen_helper
 
 DATASET = "ml-test"
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/movielens.py` & `tf-models-no-deps-2.16.0/official/recommendation/movielens.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -31,15 +31,15 @@
 import numpy as np
 import pandas as pd
 import six
 from six.moves import urllib  # pylint: disable=redefined-builtin
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 # pylint: enable=g-bad-import-order
 
 from official.utils.flags import core as flags_core
 
 
 ML_1M = "ml-1m"
 ML_20M = "ml-20m"
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ncf_common.py` & `tf-models-no-deps-2.16.0/official/recommendation/ncf_common.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,15 +20,15 @@
 
 import json
 import os
 
 from absl import flags
 from absl import logging
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import distribute_utils
 from official.recommendation import constants as rconst
 from official.recommendation import data_pipeline
 from official.recommendation import data_preprocessing
 from official.recommendation import movielens
 from official.utils.flags import core as flags_core
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ncf_input_pipeline.py` & `tf-models-no-deps-2.16.0/official/recommendation/ncf_input_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """NCF model input pipeline."""
 
 import functools
 
 # pylint: disable=g-bad-import-order
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 # pylint: enable=g-bad-import-order
 
 from official.recommendation import constants as rconst
 from official.recommendation import data_pipeline
 from official.recommendation import movielens
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ncf_keras_main.py` & `tf-models-no-deps-2.16.0/official/recommendation/ncf_keras_main.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,15 +22,15 @@
 import os
 
 # pylint: disable=g-bad-import-order
 
 from absl import app
 from absl import flags
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 # pylint: enable=g-bad-import-order
 
 from official.common import distribute_utils
 from official.recommendation import constants as rconst
 from official.recommendation import movielens
 from official.recommendation import ncf_common
 from official.recommendation import ncf_input_pipeline
@@ -47,15 +47,15 @@
   logits = tf.slice(logits, [0, 1], [-1, -1])
   in_top_k, _, metric_weights, _ = neumf_model.compute_top_k_and_ndcg(
       logits, dup_mask, match_mlperf)
   metric_weights = tf.cast(metric_weights, tf.float32)
   return in_top_k, metric_weights
 
 
-class MetricLayer(tf.keras.layers.Layer):
+class MetricLayer(tf_keras.layers.Layer):
   """Custom layer of metrics for NCF model."""
 
   def __init__(self, match_mlperf):
     super(MetricLayer, self).__init__()
     self.match_mlperf = match_mlperf
 
   def get_config(self):
@@ -77,22 +77,22 @@
       hr_count = tf.reduce_sum(metric_weights)
 
     self.add_metric(hr_sum, name="hr_sum", aggregation="mean")
     self.add_metric(hr_count, name="hr_count", aggregation="mean")
     return logits
 
 
-class LossLayer(tf.keras.layers.Layer):
+class LossLayer(tf_keras.layers.Layer):
   """Pass-through loss layer for NCF model."""
 
   def __init__(self, loss_normalization_factor):
     # The loss may overflow in float16, so we use float32 instead.
     super(LossLayer, self).__init__(dtype="float32")
     self.loss_normalization_factor = loss_normalization_factor
-    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(
+    self.loss = tf_keras.losses.SparseCategoricalCrossentropy(
         from_logits=True, reduction="sum")
 
   def get_config(self):
     return {"loss_normalization_factor": self.loss_normalization_factor}
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
@@ -103,30 +103,30 @@
     loss = self.loss(
         y_true=labels, y_pred=logits, sample_weight=valid_pt_mask_input)
     loss = loss * (1.0 / self.loss_normalization_factor)
     self.add_loss(loss)
     return logits
 
 
-class IncrementEpochCallback(tf.keras.callbacks.Callback):
+class IncrementEpochCallback(tf_keras.callbacks.Callback):
   """A callback to increase the requested epoch for the data producer.
 
   The reason why we need this is because we can only buffer a limited amount of
   data. So we keep a moving window to represent the buffer. This is to move the
   one of the window's boundaries for each epoch.
   """
 
   def __init__(self, producer):
     self._producer = producer
 
   def on_epoch_begin(self, epoch, logs=None):
     self._producer.increment_request_epoch()
 
 
-class CustomEarlyStopping(tf.keras.callbacks.Callback):
+class CustomEarlyStopping(tf_keras.callbacks.Callback):
   """Stop training has reached a desired hit rate."""
 
   def __init__(self, monitor, desired_value):
     super(CustomEarlyStopping, self).__init__()
 
     self.monitor = monitor
     self.desired = desired_value
@@ -153,48 +153,48 @@
     return monitor_value
 
 
 def _get_keras_model(params):
   """Constructs and returns the model."""
   batch_size = params["batch_size"]
 
-  user_input = tf.keras.layers.Input(
+  user_input = tf_keras.layers.Input(
       shape=(1,), name=movielens.USER_COLUMN, dtype=tf.int32)
 
-  item_input = tf.keras.layers.Input(
+  item_input = tf_keras.layers.Input(
       shape=(1,), name=movielens.ITEM_COLUMN, dtype=tf.int32)
 
-  valid_pt_mask_input = tf.keras.layers.Input(
+  valid_pt_mask_input = tf_keras.layers.Input(
       shape=(1,), name=rconst.VALID_POINT_MASK, dtype=tf.bool)
 
-  dup_mask_input = tf.keras.layers.Input(
+  dup_mask_input = tf_keras.layers.Input(
       shape=(1,), name=rconst.DUPLICATE_MASK, dtype=tf.int32)
 
-  label_input = tf.keras.layers.Input(
+  label_input = tf_keras.layers.Input(
       shape=(1,), name=rconst.TRAIN_LABEL_KEY, dtype=tf.bool)
 
   base_model = neumf_model.construct_model(user_input, item_input, params)
 
   logits = base_model.output
 
-  zeros = tf.keras.layers.Lambda(lambda x: x * 0)(logits)
+  zeros = tf_keras.layers.Lambda(lambda x: x * 0)(logits)
 
-  softmax_logits = tf.keras.layers.concatenate([zeros, logits], axis=-1)
+  softmax_logits = tf_keras.layers.concatenate([zeros, logits], axis=-1)
 
   # Custom training loop calculates loss and metric as a part of
   # training/evaluation step function.
   if not params["keras_use_ctl"]:
     softmax_logits = MetricLayer(
         params["match_mlperf"])([softmax_logits, dup_mask_input])
     # TODO(b/134744680): Use model.add_loss() instead once the API is well
     # supported.
     softmax_logits = LossLayer(batch_size)(
         [softmax_logits, label_input, valid_pt_mask_input])
 
-  keras_model = tf.keras.Model(
+  keras_model = tf_keras.Model(
       inputs={
           movielens.USER_COLUMN: user_input,
           movielens.ITEM_COLUMN: item_input,
           rconst.VALID_POINT_MASK: valid_pt_mask_input,
           rconst.DUPLICATE_MASK: dup_mask_input,
           rconst.TRAIN_LABEL_KEY: label_input
       },
@@ -212,15 +212,15 @@
   if FLAGS.seed is not None:
     print("Setting tf seed")
     tf.random.set_seed(FLAGS.seed)
 
   model_helpers.apply_clean(FLAGS)
 
   if FLAGS.dtype == "fp16" and FLAGS.fp16_implementation == "keras":
-    tf.keras.mixed_precision.set_global_policy("mixed_float16")
+    tf_keras.mixed_precision.set_global_policy("mixed_float16")
 
   strategy = distribute_utils.get_distribution_strategy(
       distribution_strategy=FLAGS.distribution_strategy,
       num_gpus=FLAGS.num_gpus,
       tpu_address=FLAGS.tpu)
 
   params = ncf_common.parse_flags(FLAGS)
@@ -261,15 +261,15 @@
   (train_input_dataset, eval_input_dataset, num_train_steps,
    num_eval_steps) = ncf_input_pipeline.create_ncf_input_data(
        params, producer, input_meta_data, strategy)
   steps_per_epoch = None if generate_input_online else num_train_steps
 
   with distribute_utils.get_strategy_scope(strategy):
     keras_model = _get_keras_model(params)
-    optimizer = tf.keras.optimizers.Adam(
+    optimizer = tf_keras.optimizers.Adam(
         learning_rate=params["learning_rate"],
         beta_1=params["beta1"],
         beta_2=params["beta2"],
         epsilon=params["epsilon"])
     if FLAGS.fp16_implementation == "graph_rewrite":
       optimizer = \
         tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite(
@@ -279,17 +279,17 @@
     elif FLAGS.dtype == "fp16":
       loss_scale = flags_core.get_loss_scale(FLAGS, default_for_fp16="dynamic")
       # Note Model.compile automatically wraps the optimizer with a
       # LossScaleOptimizer using dynamic loss scaling. We explicitly wrap it
       # here for the case where a custom training loop or fixed loss scale is
       # used.
       if loss_scale == "dynamic":
-        optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)
+        optimizer = tf_keras.mixed_precision.LossScaleOptimizer(optimizer)
       else:
-        optimizer = tf.keras.mixed_precision.LossScaleOptimizer(
+        optimizer = tf_keras.mixed_precision.LossScaleOptimizer(
             optimizer, dynamic=False, initial_scale=loss_scale)
 
     if params["keras_use_ctl"]:
       train_loss, eval_results = run_ncf_custom_training(
           params,
           strategy,
           keras_model,
@@ -302,18 +302,18 @@
           generate_input_online=generate_input_online)
     else:
       keras_model.compile(optimizer=optimizer, run_eagerly=FLAGS.run_eagerly)
 
       if not FLAGS.ml_perf:
         # Create Tensorboard summary and checkpoint callbacks.
         summary_dir = os.path.join(FLAGS.model_dir, "summaries")
-        summary_callback = tf.keras.callbacks.TensorBoard(
+        summary_callback = tf_keras.callbacks.TensorBoard(
             summary_dir, profile_batch=0)
         checkpoint_path = os.path.join(FLAGS.model_dir, "checkpoint")
-        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
+        checkpoint_callback = tf_keras.callbacks.ModelCheckpoint(
             checkpoint_path, save_weights_only=True)
 
         callbacks += [summary_callback, checkpoint_callback]
 
       history = keras_model.fit(
           train_input_dataset,
           epochs=FLAGS.train_epochs,
@@ -371,15 +371,15 @@
     generate_input_online: Whether input data was generated by data producer.
       When data is generated by data producer, then train dataset must be
       re-initialized after every epoch.
 
   Returns:
     A tuple of train loss and a list of training and evaluation results.
   """
-  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
+  loss_object = tf_keras.losses.SparseCategoricalCrossentropy(
       reduction="sum", from_logits=True)
   train_input_iterator = iter(
       strategy.experimental_distribute_dataset(train_input_dataset))
 
   def train_step(train_iterator):
     """Called once per step to train the model."""
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ncf_test.py` & `tf-models-no-deps-2.16.0/official/recommendation/ncf_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import unittest
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow.python.eager import context  # pylint: disable=ungrouped-imports
 from official.recommendation import constants as rconst
 from official.recommendation import ncf_common
 from official.recommendation import ncf_keras_main
 from official.utils.testing import integration
 
 NUM_TRAIN_NEG = 4
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/neumf_model.py` & `tf-models-no-deps-2.16.0/official/recommendation/neumf_model.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -32,15 +32,15 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import sys
 
 from six.moves import xrange  # pylint: disable=redefined-builtin
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow import estimator as tf_estimator
 from typing import Any, Dict, Text
 
 from official.recommendation import constants as rconst
 from official.recommendation import movielens
 from official.recommendation import ncf_common
 from official.recommendation import stat_utils
@@ -75,16 +75,16 @@
   """Model Function for NeuMF estimator."""
   if params.get("use_seed"):
     tf.set_random_seed(stat_utils.random_int32())
 
   users = features[movielens.USER_COLUMN]
   items = features[movielens.ITEM_COLUMN]
 
-  user_input = tf.keras.layers.Input(tensor=users)
-  item_input = tf.keras.layers.Input(tensor=items)
+  user_input = tf_keras.layers.Input(tensor=users)
+  item_input = tf_keras.layers.Input(tensor=items)
   logits = construct_model(user_input, item_input, params).output
 
   # Softmax with the first column of zeros is equivalent to sigmoid.
   softmax_logits = ncf_common.convert_to_softmax_logits(logits)
 
   if mode == tf_estimator.ModeKeys.EVAL:
     duplicate_mask = tf.cast(features[rconst.DUPLICATE_MASK], tf.float32)
@@ -132,15 +132,15 @@
 
 
 def _strip_first_and_last_dimension(x, batch_size):
   return tf.reshape(x[0, :], (batch_size,))
 
 
 def construct_model(user_input: tf.Tensor, item_input: tf.Tensor,
-                    params: Dict[Text, Any]) -> tf.keras.Model:
+                    params: Dict[Text, Any]) -> tf_keras.Model:
   """Initialize NeuMF model.
 
   Args:
     user_input: keras input layer for users
     item_input: keras input layer for items
     params: Dict of hyperparameters.
 
@@ -171,75 +171,75 @@
 
   def mlp_slice_fn(x):
     x = tf.squeeze(x, [1])
     return x[:, mf_dim:]
 
   # It turns out to be significantly more effecient to store the MF and MLP
   # embedding portions in the same table, and then slice as needed.
-  embedding_user = tf.keras.layers.Embedding(
+  embedding_user = tf_keras.layers.Embedding(
       num_users,
       mf_dim + model_layers[0] // 2,
       embeddings_initializer=embedding_initializer,
-      embeddings_regularizer=tf.keras.regularizers.l2(mf_regularization),
+      embeddings_regularizer=tf_keras.regularizers.l2(mf_regularization),
       input_length=1,
       name="embedding_user")(
           user_input)
 
-  embedding_item = tf.keras.layers.Embedding(
+  embedding_item = tf_keras.layers.Embedding(
       num_items,
       mf_dim + model_layers[0] // 2,
       embeddings_initializer=embedding_initializer,
-      embeddings_regularizer=tf.keras.regularizers.l2(mf_regularization),
+      embeddings_regularizer=tf_keras.regularizers.l2(mf_regularization),
       input_length=1,
       name="embedding_item")(
           item_input)
 
   # GMF part
-  mf_user_latent = tf.keras.layers.Lambda(
+  mf_user_latent = tf_keras.layers.Lambda(
       mf_slice_fn, name="embedding_user_mf")(
           embedding_user)
-  mf_item_latent = tf.keras.layers.Lambda(
+  mf_item_latent = tf_keras.layers.Lambda(
       mf_slice_fn, name="embedding_item_mf")(
           embedding_item)
 
   # MLP part
-  mlp_user_latent = tf.keras.layers.Lambda(
+  mlp_user_latent = tf_keras.layers.Lambda(
       mlp_slice_fn, name="embedding_user_mlp")(
           embedding_user)
-  mlp_item_latent = tf.keras.layers.Lambda(
+  mlp_item_latent = tf_keras.layers.Lambda(
       mlp_slice_fn, name="embedding_item_mlp")(
           embedding_item)
 
   # Element-wise multiply
-  mf_vector = tf.keras.layers.multiply([mf_user_latent, mf_item_latent])
+  mf_vector = tf_keras.layers.multiply([mf_user_latent, mf_item_latent])
 
   # Concatenation of two latent features
-  mlp_vector = tf.keras.layers.concatenate([mlp_user_latent, mlp_item_latent])
+  mlp_vector = tf_keras.layers.concatenate([mlp_user_latent, mlp_item_latent])
 
   num_layer = len(model_layers)  # Number of layers in the MLP
   for layer in xrange(1, num_layer):
-    model_layer = tf.keras.layers.Dense(
+    model_layer = tf_keras.layers.Dense(
         model_layers[layer],
-        kernel_regularizer=tf.keras.regularizers.l2(mlp_reg_layers[layer]),
+        kernel_regularizer=tf_keras.regularizers.l2(mlp_reg_layers[layer]),
         activation="relu")
     mlp_vector = model_layer(mlp_vector)
 
   # Concatenate GMF and MLP parts
-  predict_vector = tf.keras.layers.concatenate([mf_vector, mlp_vector])
+  predict_vector = tf_keras.layers.concatenate([mf_vector, mlp_vector])
 
   # Final prediction layer
-  logits = tf.keras.layers.Dense(
+  logits = tf_keras.layers.Dense(
       1,
       activation=None,
       kernel_initializer="lecun_uniform",
       name=movielens.RATING_COLUMN)(
           predict_vector)
 
   # Print model topology.
-  model = tf.keras.models.Model([user_input, item_input], logits)
+  model = tf_keras.models.Model([user_input, item_input], logits)
   model.summary()
   sys.stdout.flush()
 
   return model
 
 
 def _get_estimator_spec_with_metrics(logits: tf.Tensor,
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/popen_helper.py` & `tf-models-no-deps-2.16.0/official/recommendation/popen_helper.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/common.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/common.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Flags and common definitions for Ranking Models."""
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import flags as tfm_flags
 
 FLAGS = flags.FLAGS
 
 
 def define_flags() -> None:
@@ -40,16 +40,16 @@
       'The value must be a comma separated pair of positive integers, '
       'specifying the first and last step to profile. For example, '
       '"--profile_steps=2,4" triggers the profiler to process 3 steps, starting'
       ' from the 2nd step. Note that profiler has a non-trivial performance '
       'overhead, and the output file can be gigantic if profiling many steps.')
 
 
-@tf.keras.utils.register_keras_serializable(package='RANKING')
-class WarmUpAndPolyDecay(tf.keras.optimizers.schedules.LearningRateSchedule):
+@tf_keras.utils.register_keras_serializable(package='RANKING')
+class WarmUpAndPolyDecay(tf_keras.optimizers.schedules.LearningRateSchedule):
   """Learning rate callable for the embeddings.
 
   Linear warmup on [0, warmup_steps] then
   Constant on [warmup_steps, decay_start_steps]
   And polynomial decay on [decay_start_steps, decay_start_steps + decay_steps].
   """
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/configs/config.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/configs/config.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -48,17 +48,23 @@
   decay_steps: int = 30000
   decay_start_steps: int = 70000
   decay_exp: float = 2
 
 
 @dataclasses.dataclass
 class OptimizationConfig(hyperparams.Config):
-  """Embedding Optimizer config."""
-  lr_config: LearningRateConfig = LearningRateConfig()
+  """Embedding and dense optimizer configs."""
+  lr_config: LearningRateConfig = dataclasses.field(
+      default_factory=LearningRateConfig
+  )
+  dense_sgd_config: LearningRateConfig = dataclasses.field(
+      default_factory=lambda: LearningRateConfig(warmup_steps=0)
+  )
   embedding_optimizer: str = 'SGD'
+  dense_optimizer: str = 'Adam'
 
 
 @dataclasses.dataclass
 class DataConfig(hyperparams.Config):
   """Dataset config for training and evaluation."""
   input_path: str = ''
   global_batch_size: int = 0
@@ -111,18 +117,22 @@
   label_smoothing: float = 0.0
 
 
 @dataclasses.dataclass
 class Task(hyperparams.Config):
   """The model config."""
   init_checkpoint: str = ''
-  model: ModelConfig = ModelConfig()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(is_training=False)
-  loss: Loss = Loss()
+  model: ModelConfig = dataclasses.field(default_factory=ModelConfig)
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=False)
+  )
+  loss: Loss = dataclasses.field(default_factory=Loss)
   use_synthetic_data: bool = False
 
 
 @dataclasses.dataclass
 class TimeHistoryConfig(hyperparams.Config):
   """Configuration for the TimeHistory callback.
 
@@ -144,24 +154,33 @@
     callbacks: An instance of CallbacksConfig.
     use_orbit: Whether to use orbit library with custom training loop or
       compile/fit API.
     enable_metrics_in_training: Whether to enable metrics during training.
     time_history: Config of TimeHistory callback.
     optimizer_config: An `OptimizerConfig` instance for embedding optimizer.
        Defaults to None.
+    pipeline_sparse_and_dense_exeuction: Whether to pipeline embedding and
+      dense execution. This is a performance optimization.
   """
   train_steps: int = 0
   # Sets validation steps to be -1 to evaluate the entire dataset.
   validation_steps: int = -1
   validation_interval: int = 70000
-  callbacks: CallbacksConfig = CallbacksConfig()
+  callbacks: CallbacksConfig = dataclasses.field(
+      default_factory=CallbacksConfig
+  )
   use_orbit: bool = False
   enable_metrics_in_training: bool = True
-  time_history: TimeHistoryConfig = TimeHistoryConfig(log_steps=5000)
-  optimizer_config: OptimizationConfig = OptimizationConfig()
+  time_history: TimeHistoryConfig = dataclasses.field(
+      default_factory=lambda: TimeHistoryConfig(log_steps=5000)
+  )
+  optimizer_config: OptimizationConfig = dataclasses.field(
+      default_factory=OptimizationConfig
+  )
+  pipeline_sparse_and_dense_execution: bool = False
 
 
 NUM_TRAIN_EXAMPLES = 4195197692
 NUM_EVAL_EXAMPLES = 89137318
 
 train_batch_size = 16384
 eval_batch_size = 16384
@@ -180,34 +199,43 @@
   By default it configures DLRM model on criteo dataset.
 
   Attributes:
     runtime: A `RuntimeConfig` instance.
     task: `Task` instance.
     trainer: A `TrainerConfig` instance.
   """
-  runtime: cfg.RuntimeConfig = cfg.RuntimeConfig()
-  task: Task = Task(
-      model=ModelConfig(
-          embedding_dim=8,
-          vocab_sizes=vocab_sizes,
-          bottom_mlp=[64, 32, 8],
-          top_mlp=[64, 32, 1]),
-      loss=Loss(label_smoothing=0.0),
-      train_data=DataConfig(
-          is_training=True,
-          global_batch_size=train_batch_size),
-      validation_data=DataConfig(
-          is_training=False,
-          global_batch_size=eval_batch_size))
-  trainer: TrainerConfig = TrainerConfig(
-      train_steps=2 * steps_per_epoch,
-      validation_interval=steps_per_epoch,
-      validation_steps=NUM_EVAL_EXAMPLES // eval_batch_size,
-      enable_metrics_in_training=True,
-      optimizer_config=OptimizationConfig())
+  runtime: cfg.RuntimeConfig = dataclasses.field(
+      default_factory=cfg.RuntimeConfig
+  )
+  task: Task = dataclasses.field(
+      default_factory=lambda: Task(  # pylint: disable=g-long-lambda
+          model=ModelConfig(
+              embedding_dim=8,
+              vocab_sizes=vocab_sizes,
+              bottom_mlp=[64, 32, 8],
+              top_mlp=[64, 32, 1],
+          ),
+          loss=Loss(label_smoothing=0.0),
+          train_data=DataConfig(
+              is_training=True, global_batch_size=train_batch_size
+          ),
+          validation_data=DataConfig(
+              is_training=False, global_batch_size=eval_batch_size
+          ),
+      )
+  )
+  trainer: TrainerConfig = dataclasses.field(
+      default_factory=lambda: TrainerConfig(  # pylint: disable=g-long-lambda
+          train_steps=2 * steps_per_epoch,
+          validation_interval=steps_per_epoch,
+          validation_steps=NUM_EVAL_EXAMPLES // eval_batch_size,
+          enable_metrics_in_training=True,
+          optimizer_config=OptimizationConfig(),
+      )
+  )
   restrictions: dataclasses.InitVar[Optional[List[str]]] = None
 
 
 def default_config() -> Config:
   return Config(
       runtime=cfg.RuntimeConfig(),
       task=Task(
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/configs/config_test.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/configs/config_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Unit tests for DLRM config."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.recommendation.ranking.configs import config
 
 
 class ConfigTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_configs(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/data/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/dataloaders/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/data/data_pipeline.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/data/data_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Data pipeline for the Ranking model.
 
 This module defines various input datasets for the Ranking model.
 """
 
 from typing import List
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.recommendation.ranking.configs import config
 
 
 class CriteoTsvReader:
   """Input reader callable for pre-processed Criteo data.
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/data/data_pipeline_test.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/data/data_pipeline_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Unit tests for data_pipeline."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.recommendation.ranking.configs import config
 from official.recommendation.ranking.data import data_pipeline
 
 
 class DataPipelineTest(parameterized.TestCase, tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/task.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/task.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,40 +13,42 @@
 # limitations under the License.
 
 """Task for the Ranking model."""
 
 import math
 from typing import Dict, List, Optional, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_recommenders as tfrs
 
 from official.core import base_task
 from official.core import config_definitions
 from official.recommendation.ranking import common
 from official.recommendation.ranking.configs import config
 from official.recommendation.ranking.data import data_pipeline
 
 RuntimeConfig = config_definitions.RuntimeConfig
 
 
 def _get_tpu_embedding_feature_config(
     vocab_sizes: List[int],
     embedding_dim: Union[int, List[int]],
-    table_name_prefix: str = 'embedding_table'
+    table_name_prefix: str = 'embedding_table',
+    batch_size: Optional[int] = None
 ) -> Dict[str, tf.tpu.experimental.embedding.FeatureConfig]:
   """Returns TPU embedding feature config.
 
   i'th table config will have vocab size of vocab_sizes[i] and embedding
   dimension of embedding_dim if embedding_dim is an int or embedding_dim[i] if
   embedding_dim is a list).
   Args:
     vocab_sizes: List of sizes of categories/id's in the table.
     embedding_dim: An integer or a list of embedding table dimensions.
     table_name_prefix: a prefix for embedding tables.
+    batch_size: Per-replica batch size.
   Returns:
     A dictionary of feature_name, FeatureConfig pairs.
   """
   if isinstance(embedding_dim, List):
     if len(vocab_sizes) != len(embedding_dim):
       raise ValueError(
           f'length of vocab_sizes: {len(vocab_sizes)} is not equal to the '
@@ -62,43 +64,47 @@
   for i, vocab_size in enumerate(vocab_sizes):
     table_config = tf.tpu.experimental.embedding.TableConfig(
         vocabulary_size=vocab_size,
         dim=embedding_dim[i],
         combiner='mean',
         initializer=tf.initializers.TruncatedNormal(
             mean=0.0, stddev=1 / math.sqrt(embedding_dim[i])),
-        name=table_name_prefix + '_%s' % i)
+        name=table_name_prefix + '_%02d' % i)
     feature_config[str(i)] = tf.tpu.experimental.embedding.FeatureConfig(
-        table=table_config)
+        name=str(i),
+        table=table_config,
+        output_shape=[batch_size] if batch_size else None,
+    )
 
   return feature_config
 
 
 class RankingTask(base_task.Task):
   """A task for Ranking Model."""
 
   def __init__(self,
                params: config.Task,
-               optimizer_config: config.OptimizationConfig,
+               trainer_config: config.TrainerConfig,
                logging_dir: Optional[str] = None,
                steps_per_execution: int = 1,
                name: Optional[str] = None):
     """Task initialization.
 
     Args:
       params: the RankingModel task configuration instance.
-      optimizer_config: Optimizer configuration instance.
+      trainer_config: Trainer configuration instance.
       logging_dir: a string pointing to where the model, summaries etc. will be
         saved.
       steps_per_execution: Int. Defaults to 1. The number of batches to run
         during each `tf.function` call. It's used for compile/fit API.
       name: the task name.
     """
     super().__init__(params, logging_dir, name=name)
-    self._optimizer_config = optimizer_config
+    self._trainer_config = trainer_config
+    self._optimizer_config = trainer_config.optimizer_config
     self._steps_per_execution = steps_per_execution
 
   def build_inputs(self, params, input_context=None):
     """Builds classification input."""
 
     dataset = data_pipeline.CriteoTsvReader(
         file_pattern=params.input_path,
@@ -111,15 +117,15 @@
 
   @classmethod
   def create_optimizer(cls, optimizer_config: config.OptimizationConfig,
                        runtime_config: Optional[RuntimeConfig] = None) -> None:
     """See base class. Return None, optimizer is set in `build_model`."""
     return None
 
-  def build_model(self) -> tf.keras.Model:
+  def build_model(self) -> tf_keras.Model:
     """Creates Ranking model architecture and Optimizers.
 
     The RankingModel uses different optimizers/learning rates for embedding
     variables and dense variables.
 
     Returns:
       A Ranking model instance.
@@ -128,35 +134,51 @@
     lr_callable = common.WarmUpAndPolyDecay(
         batch_size=self.task_config.train_data.global_batch_size,
         decay_exp=lr_config.decay_exp,
         learning_rate=lr_config.learning_rate,
         warmup_steps=lr_config.warmup_steps,
         decay_steps=lr_config.decay_steps,
         decay_start_steps=lr_config.decay_start_steps)
-
-    dense_optimizer = tf.keras.optimizers.legacy.Adam()
-    embedding_optimizer = tf.keras.optimizers.get(
+    embedding_optimizer = tf_keras.optimizers.get(
         self.optimizer_config.embedding_optimizer, use_legacy_optimizer=True)
     embedding_optimizer.learning_rate = lr_callable
 
+    dense_optimizer = tf_keras.optimizers.get(
+        self.optimizer_config.dense_optimizer, use_legacy_optimizer=True)
+    if self.optimizer_config.dense_optimizer == 'SGD':
+      dense_lr_config = self.optimizer_config.dense_sgd_config
+      dense_lr_callable = common.WarmUpAndPolyDecay(
+          batch_size=self.task_config.train_data.global_batch_size,
+          decay_exp=dense_lr_config.decay_exp,
+          learning_rate=dense_lr_config.learning_rate,
+          warmup_steps=dense_lr_config.warmup_steps,
+          decay_steps=dense_lr_config.decay_steps,
+          decay_start_steps=dense_lr_config.decay_start_steps)
+      dense_optimizer.learning_rate = dense_lr_callable
+
     feature_config = _get_tpu_embedding_feature_config(
         embedding_dim=self.task_config.model.embedding_dim,
-        vocab_sizes=self.task_config.model.vocab_sizes)
+        vocab_sizes=self.task_config.model.vocab_sizes,
+        batch_size=self.task_config.train_data.global_batch_size
+        // tf.distribute.get_strategy().num_replicas_in_sync,
+    )
 
     embedding_layer = tfrs.experimental.layers.embedding.PartialTPUEmbedding(
         feature_config=feature_config,
         optimizer=embedding_optimizer,
-        size_threshold=self.task_config.model.size_threshold)
+        pipeline_execution_with_tensor_core=self.trainer_config.pipeline_sparse_and_dense_execution,
+        size_threshold=self.task_config.model.size_threshold,
+    )
 
     if self.task_config.model.interaction == 'dot':
       feature_interaction = tfrs.layers.feature_interaction.DotInteraction(
           skip_gather=True)
     elif self.task_config.model.interaction == 'cross':
-      feature_interaction = tf.keras.Sequential([
-          tf.keras.layers.Concatenate(),
+      feature_interaction = tf_keras.Sequential([
+          tf_keras.layers.Concatenate(),
           tfrs.layers.feature_interaction.Cross()
       ])
     else:
       raise ValueError(
           f'params.task.model.interaction {self.task_config.model.interaction} '
           f'is not supported it must be either \'dot\' or \'cross\'.')
 
@@ -175,30 +197,32 @@
 
     model.compile(optimizer, steps_per_execution=self._steps_per_execution)
     return model
 
   def train_step(
       self,
       inputs: Dict[str, tf.Tensor],
-      model: tf.keras.Model,
-      optimizer: tf.keras.optimizers.Optimizer,
-      metrics: Optional[List[tf.keras.metrics.Metric]] = None) -> tf.Tensor:
+      model: tf_keras.Model,
+      optimizer: tf_keras.optimizers.Optimizer,
+      metrics: Optional[List[tf_keras.metrics.Metric]] = None) -> tf.Tensor:
     """See base class."""
     # All metrics need to be passed through the RankingModel.
     assert metrics == model.metrics
     return model.train_step(inputs)
 
   def validation_step(
       self,
       inputs: Dict[str, tf.Tensor],
-      model: tf.keras.Model,
-      metrics: Optional[List[tf.keras.metrics.Metric]] = None) -> tf.Tensor:
+      model: tf_keras.Model,
+      metrics: Optional[List[tf_keras.metrics.Metric]] = None) -> tf.Tensor:
     """See base class."""
     # All metrics need to be passed through the RankingModel.
     assert metrics == model.metrics
     return model.test_step(inputs)
 
   @property
+  def trainer_config(self) -> config.TrainerConfig:
+    return self._trainer_config
+
+  @property
   def optimizer_config(self) -> config.OptimizationConfig:
     return self._optimizer_config
-
-
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/task_test.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/task_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Unit tests for task."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import exp_factory
 from official.recommendation.ranking import task
 from official.recommendation.ranking.data import data_pipeline
 
 
 class TaskTest(parameterized.TestCase, tf.test.TestCase):
@@ -36,15 +36,15 @@
     params.task.model.vocab_sizes = [40, 12, 11, 13, 2, 5]
     params.task.model.embedding_dim = 8
     params.task.model.bottom_mlp = [64, 32, 8]
     params.task.use_synthetic_data = True
     params.task.model.num_dense_features = 5
 
     ranking_task = task.RankingTask(params.task,
-                                    params.trainer.optimizer_config)
+                                    params.trainer)
 
     if is_training:
       dataset = data_pipeline.train_input_fn(params.task)
     else:
       dataset = data_pipeline.eval_input_fn(params.task)
 
     iterator = iter(dataset(ctx=None))
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/train.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/train.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 from typing import Dict
 
 from absl import app
 from absl import flags
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import distribute_utils
 from official.core import base_trainer
 from official.core import train_lib
 from official.core import train_utils
 from official.recommendation.ranking import common
 from official.recommendation.ranking.task import RankingTask
@@ -69,15 +69,15 @@
 
   if FLAGS.seed is not None:
     logging.info('Setting tf seed.')
     tf.random.set_seed(FLAGS.seed)
 
   task = RankingTask(
       params=params.task,
-      optimizer_config=params.trainer.optimizer_config,
+      trainer_config=params.trainer,
       logging_dir=model_dir,
       steps_per_execution=params.trainer.steps_per_loop,
       name='RankingTask')
 
   enable_tensorboard = params.trainer.callbacks.enable_tensorboard
 
   strategy = distribute_utils.get_distribution_strategy(
@@ -146,15 +146,15 @@
     time_callback = keras_utils.TimeHistory(
         params.task.train_data.global_batch_size,
         params.trainer.time_history.log_steps,
         logdir=model_dir if enable_tensorboard else None)
     callbacks = [checkpoint_callback, time_callback]
 
     if enable_tensorboard:
-      tensorboard_callback = tf.keras.callbacks.TensorBoard(
+      tensorboard_callback = tf_keras.callbacks.TensorBoard(
           log_dir=model_dir,
           update_freq=min(1000, params.trainer.validation_interval),
           profile_batch=FLAGS.profile_steps)
       callbacks.append(tensorboard_callback)
 
     num_epochs = (params.trainer.train_steps //
                   params.trainer.validation_interval)
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/ranking/train_test.py` & `tf-models-no-deps-2.16.0/official/recommendation/ranking/train_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Unit tests for ranking model and associated functionality."""
 
 import json
 import os
 from absl import flags
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.recommendation.ranking import common
 from official.recommendation.ranking import train
 
 FLAGS = flags.FLAGS
```

### Comparing `tf-models-no-deps-2.11.2/official/recommendation/stat_utils.py` & `tf-models-no-deps-2.16.0/official/recommendation/stat_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/evaluation/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/docs/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/losses/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/docs/build_orbit_api_docs.py` & `tf-models-no-deps-2.16.0/official/utils/docs/build_orbit_api_docs.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,15 +21,15 @@
 """
 from absl import app
 from absl import flags
 from absl import logging
 
 import orbit
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow_docs.api_generator import doc_controls
 from tensorflow_docs.api_generator import generate_lib
 from tensorflow_docs.api_generator import public_api
 
 FLAGS = flags.FLAGS
 
 flags.DEFINE_string('output_dir', None, 'Where to write the resulting docs to.')
@@ -53,16 +53,16 @@
 
   We hide all methods and properties of the base classes, except:
   - `__init__` is always documented.
   - `call` is always documented, as it can carry important information for
     complex layers.
   """
   module_contents = list(tf.Module.__dict__.items())
-  model_contents = list(tf.keras.Model.__dict__.items())
-  layer_contents = list(tf.keras.layers.Layer.__dict__.items())
+  model_contents = list(tf_keras.Model.__dict__.items())
+  layer_contents = list(tf_keras.layers.Layer.__dict__.items())
 
   for name, obj in module_contents + layer_contents + model_contents:
     if name == '__init__':
       # Always document __init__.
       continue
 
     if name == 'call':
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/docs/build_tfm_api_docs.py` & `tf-models-no-deps-2.16.0/official/utils/docs/build_tfm_api_docs.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,15 +22,15 @@
 
 import pathlib
 
 from absl import app
 from absl import flags
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from tensorflow_docs.api_generator import doc_controls
 from tensorflow_docs.api_generator import generate_lib
 from tensorflow_docs.api_generator import parser
 from tensorflow_docs.api_generator import public_api
 from tensorflow_docs.api_generator.pretty_docs import base_page
 from tensorflow_docs.api_generator.pretty_docs import function_page
 
@@ -98,16 +98,16 @@
 
   We hide all methods and properties of the base classes, except:
   - `__init__` is always documented.
   - `call` is always documented, as it can carry important information for
     complex layers.
   """
   module_contents = list(tf.Module.__dict__.items())
-  model_contents = list(tf.keras.Model.__dict__.items())
-  layer_contents = list(tf.keras.layers.Layer.__dict__.items())
+  model_contents = list(tf_keras.Model.__dict__.items())
+  layer_contents = list(tf_keras.layers.Layer.__dict__.items())
 
   for name, obj in module_contents + layer_contents + model_contents:
     if name == '__init__':
       # Always document __init__.
       continue
 
     if name == 'call':
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/_base.py` & `tf-models-no-deps-2.16.0/official/utils/flags/_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Flags which will be nearly universal across models."""
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.utils.flags._conventions import help_wrap
 
 
 def define_base(data_dir=True,
                 model_dir=True,
                 clean=False,
                 train_epochs=False,
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/_benchmark.py` & `tf-models-no-deps-2.16.0/official/utils/flags/_benchmark.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/_conventions.py` & `tf-models-no-deps-2.16.0/official/utils/flags/_conventions.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/_device.py` & `tf-models-no-deps-2.16.0/official/utils/flags/_device.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/_distribution.py` & `tf-models-no-deps-2.16.0/official/utils/flags/_distribution.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Flags related to distributed execution."""
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.utils.flags._conventions import help_wrap
 
 
 def define_distribution(worker_hosts=True, task_index=True):
   """Register distributed execution flags.
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/_misc.py` & `tf-models-no-deps-2.16.0/official/utils/flags/_misc.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/_performance.py` & `tf-models-no-deps-2.16.0/official/utils/flags/_performance.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Register flags for optimizing performance."""
 
 import multiprocessing
 
 from absl import flags  # pylint: disable=g-bad-import-order
-import tensorflow as tf  # pylint: disable=g-bad-import-order
+import tensorflow as tf, tf_keras  # pylint: disable=g-bad-import-order
 
 from official.utils.flags._conventions import help_wrap
 
 # Map string to TensorFlow dtype
 DTYPE_MAP = {
     "fp16": tf.float16,
     "bf16": tf.bfloat16,
@@ -194,19 +194,19 @@
         return loss_scale > 0
       # pylint: enable=unused-variable
 
     if fp16_implementation:
       flags.DEFINE_enum(
           name="fp16_implementation",
           default="keras",
-          enum_values=("keras', 'graph_rewrite"),
+          enum_values=("keras", "graph_rewrite"),
           help=help_wrap(
               "When --dtype=fp16, how fp16 should be implemented. This has no "
               "impact on correctness. 'keras' uses the "
-              "tf.keras.mixed_precision API. 'graph_rewrite' uses the "
+              "tf_keras.mixed_precision API. 'graph_rewrite' uses the "
               "tf.compat.v1.mixed_precision."
               "enable_mixed_precision_graph_rewrite API."))
 
       @flags.multi_flags_validator(
           ["fp16_implementation", "dtype", "loss_scale"])
       def _check_fp16_implementation(flags_dict):
         """Validator to check fp16_implementation flag is valid."""
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/core.py` & `tf-models-no-deps-2.16.0/official/utils/flags/core.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/flags/flags_test.py` & `tf-models-no-deps-2.16.0/official/utils/flags/flags_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import unittest
 
 from absl import flags
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.utils.flags import core as flags_core  # pylint: disable=g-bad-import-order
 
 
 def define_flags():
   flags_core.define_base(
       clean=True,
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/hyperparams_flags.py` & `tf-models-no-deps-2.16.0/official/utils/hyperparams_flags.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/misc/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/modeling/heads/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/misc/keras_utils.py` & `tf-models-no-deps-2.16.0/official/utils/misc/keras_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Helper functions for the Keras implementations of models."""
 
 import multiprocessing
 import os
 import time
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.eager import monitoring
 
 global_batch_size_gauge = monitoring.IntGauge(
     '/tensorflow/training/global_batch_size', 'TF training global batch size')
 
 first_batch_time_gauge = monitoring.IntGauge(
@@ -43,15 +43,15 @@
     self.timestamp = timestamp
 
   def __repr__(self):
     return "'BatchTimestamp<batch_index: {}, timestamp: {}>'".format(
         self.batch_index, self.timestamp)
 
 
-class TimeHistory(tf.keras.callbacks.Callback):
+class TimeHistory(tf_keras.callbacks.Callback):
   """Callback for Keras models."""
 
   def __init__(self, batch_size, log_steps, initial_step=0, logdir=None):
     """Callback for logging performance.
 
     Args:
       batch_size: Total batch size.
@@ -161,15 +161,15 @@
     epoch_run_time = time.time() - self.epoch_start
     self.epoch_runtime_log.append(epoch_run_time)
 
     self.steps_before_epoch += self.steps_in_epoch
     self.steps_in_epoch = 0
 
 
-class SimpleCheckpoint(tf.keras.callbacks.Callback):
+class SimpleCheckpoint(tf_keras.callbacks.Callback):
   """Keras callback to save tf.train.Checkpoints."""
 
   def __init__(self, checkpoint_manager):
     super(SimpleCheckpoint, self).__init__()
     self.checkpoint_manager = checkpoint_manager
 
   def on_epoch_end(self, epoch, logs=None):
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/misc/model_helpers.py` & `tf-models-no-deps-2.16.0/official/utils/misc/model_helpers.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Miscellaneous functions that can be called by models."""
 
 import numbers
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.util import nest
 # pylint:disable=logging-format-interpolation
 
 
 def past_stop_threshold(stop_threshold, eval_metric):
   """Return a boolean representing whether a model should be stopped.
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/misc/model_helpers_test.py` & `tf-models-no-deps-2.16.0/official/utils/misc/model_helpers_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for Model Helper functions."""
 
-import tensorflow as tf  # pylint: disable=g-bad-import-order
+import tensorflow as tf, tf_keras  # pylint: disable=g-bad-import-order
 
 from official.utils.misc import model_helpers
 
 
 class PastStopThresholdTest(tf.test.TestCase):
   """Tests for past_stop_threshold."""
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/testing/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/serving/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/testing/integration.py` & `tf-models-no-deps-2.16.0/official/utils/testing/integration.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/utils/testing/mock_task.py` & `tf-models-no-deps-2.16.0/official/utils/testing/mock_task.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,29 +13,29 @@
 # limitations under the License.
 
 """Mock task for testing."""
 
 import dataclasses
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling.hyperparams import base_config
 
 
-class MockModel(tf.keras.Model):
+class MockModel(tf_keras.Model):
 
   def __init__(self, network):
     super().__init__()
     self.network = network
 
-  def call(self, inputs):
+  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
     outputs = self.network(inputs)
     self.add_loss(tf.reduce_mean(outputs))
     return outputs
 
 
 @dataclasses.dataclass
 class MockTaskConfig(cfg.TaskConfig):
@@ -46,26 +46,26 @@
 class MockTask(base_task.Task):
   """Mock task object for testing."""
 
   def __init__(self, params=None, logging_dir=None, name=None):
     super().__init__(params=params, logging_dir=logging_dir, name=name)
 
   def build_model(self, *arg, **kwargs):
-    inputs = tf.keras.layers.Input(shape=(2,), name="random", dtype=tf.float32)
-    outputs = tf.keras.layers.Dense(
-        1, bias_initializer=tf.keras.initializers.Ones(), name="dense_0")(
+    inputs = tf_keras.layers.Input(shape=(2,), name="random", dtype=tf.float32)
+    outputs = tf_keras.layers.Dense(
+        1, bias_initializer=tf_keras.initializers.Ones(), name="dense_0")(
             inputs)
-    network = tf.keras.Model(inputs=inputs, outputs=outputs)
+    network = tf_keras.Model(inputs=inputs, outputs=outputs)
     return MockModel(network)
 
   def build_metrics(self, training: bool = True):
     del training
-    return [tf.keras.metrics.Accuracy(name="acc")]
+    return [tf_keras.metrics.Accuracy(name="acc")]
 
-  def validation_step(self, inputs, model: tf.keras.Model, metrics=None):
+  def validation_step(self, inputs, model: tf_keras.Model, metrics=None):
     logs = super().validation_step(inputs, model, metrics)
     logs["counter"] = tf.constant(1, dtype=tf.float32)
     return logs
 
   def build_inputs(self, params):
 
     def generate_data(_):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/configs/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/backbones.py` & `tf-models-no-deps-2.16.0/official/vision/configs/backbones.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,31 +22,40 @@
 @dataclasses.dataclass
 class Transformer(hyperparams.Config):
   """Transformer config."""
   mlp_dim: int = 1
   num_heads: int = 1
   num_layers: int = 1
   attention_dropout_rate: float = 0.0
-  dropout_rate: float = 0.1
+  dropout_rate: float = 0.0
 
 
 @dataclasses.dataclass
 class VisionTransformer(hyperparams.Config):
   """VisionTransformer config."""
   model_name: str = 'vit-b16'
   # pylint: disable=line-too-long
   pooler: str = 'token'  # 'token', 'gap' or 'none'. If set to 'token', an extra classification token is added to sequence.
   # pylint: enable=line-too-long
   representation_size: int = 0
   hidden_size: int = 1
   patch_size: int = 16
-  transformer: Transformer = Transformer()
+  transformer: Transformer = dataclasses.field(default_factory=Transformer)
   init_stochastic_depth_rate: float = 0.0
   original_init: bool = True
   pos_embed_shape: Optional[Tuple[int, int]] = None
+  # If output encoded tokens sequence when pooler is `none`.
+  output_encoded_tokens: bool = True
+  # If output encoded tokens 2D feature map.
+  output_2d_feature_maps: bool = False
+
+  # Adding Layerscale to each Encoder block https://arxiv.org/abs/2204.07118
+  layer_scale_init_value: float = 0.0
+  # Transformer encoder spatial partition dimensions.
+  transformer_partition_dims: Optional[Tuple[int, int, int, int]] = None
 
 
 @dataclasses.dataclass
 class ResNet(hyperparams.Config):
   """ResNet config."""
   model_id: int = 50
   depth_multiplier: float = 1.0
@@ -143,16 +152,20 @@
     spinenet: spinenet backbone config.
     spinenet_mobile: mobile spinenet backbone config.
     mobilenet: mobilenet backbone config.
     mobiledet: mobiledet backbone config.
     vit: vision transformer backbone config.
   """
   type: Optional[str] = None
-  resnet: ResNet = ResNet()
-  dilated_resnet: DilatedResNet = DilatedResNet()
-  revnet: RevNet = RevNet()
-  efficientnet: EfficientNet = EfficientNet()
-  spinenet: SpineNet = SpineNet()
-  spinenet_mobile: SpineNetMobile = SpineNetMobile()
-  mobilenet: MobileNet = MobileNet()
-  mobiledet: MobileDet = MobileDet()
-  vit: VisionTransformer = VisionTransformer()
+  resnet: ResNet = dataclasses.field(default_factory=ResNet)
+  dilated_resnet: DilatedResNet = dataclasses.field(
+      default_factory=DilatedResNet
+  )
+  revnet: RevNet = dataclasses.field(default_factory=RevNet)
+  efficientnet: EfficientNet = dataclasses.field(default_factory=EfficientNet)
+  spinenet: SpineNet = dataclasses.field(default_factory=SpineNet)
+  spinenet_mobile: SpineNetMobile = dataclasses.field(
+      default_factory=SpineNetMobile
+  )
+  mobilenet: MobileNet = dataclasses.field(default_factory=MobileNet)
+  mobiledet: MobileDet = dataclasses.field(default_factory=MobileDet)
+  vit: VisionTransformer = dataclasses.field(default_factory=VisionTransformer)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/backbones_3d.py` & `tf-models-no-deps-2.16.0/official/vision/configs/backbones_3d.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -84,23 +84,19 @@
                         temporal_kernel_sizes=(3,),
                         use_self_gating=True),
           ResNet3DBlock(temporal_strides=1,
                         temporal_kernel_sizes=(3,),
                         use_self_gating=True))
 
 
-_RESNET3D50_DEFAULT_CFG = ResNet3D50()
-_RESNET3DRS_DEFAULT_CFG = ResNet3DRS()
-
-
 @dataclasses.dataclass
 class Backbone3D(hyperparams.OneOfConfig):
   """Configuration for backbones.
 
   Attributes:
     type: 'str', type of backbone be used, one of the fields below.
     resnet_3d: resnet3d backbone config.
     resnet_3d_rs: resnet3d-rs backbone config.
   """
   type: Optional[str] = None
-  resnet_3d: ResNet3D = _RESNET3D50_DEFAULT_CFG
-  resnet_3d_rs: ResNet3D = _RESNET3DRS_DEFAULT_CFG
+  resnet_3d: ResNet3D = dataclasses.field(default_factory=ResNet3D50)
+  resnet_3d_rs: ResNet3D = dataclasses.field(default_factory=ResNet3DRS)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/common.py` & `tf-models-no-deps-2.16.0/official/vision/configs/common.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -24,14 +24,15 @@
 
 
 @dataclasses.dataclass
 class TfExampleDecoder(hyperparams.Config):
   """A simple TF Example decoder config."""
   regenerate_source_id: bool = False
   mask_binarize_threshold: Optional[float] = None
+  attribute_names: List[str] = dataclasses.field(default_factory=list)
 
 
 @dataclasses.dataclass
 class TfExampleDecoderLabelMap(hyperparams.Config):
   """TF Example decoder with label map config."""
   regenerate_source_id: bool = False
   mask_binarize_threshold: Optional[float] = None
@@ -44,16 +45,20 @@
 
   Attributes:
     type: 'str', type of data decoder be used, one of the fields below.
     simple_decoder: simple TF Example decoder config.
     label_map_decoder: TF Example decoder with label map config.
   """
   type: Optional[str] = 'simple_decoder'
-  simple_decoder: TfExampleDecoder = TfExampleDecoder()
-  label_map_decoder: TfExampleDecoderLabelMap = TfExampleDecoderLabelMap()
+  simple_decoder: TfExampleDecoder = dataclasses.field(
+      default_factory=TfExampleDecoder
+  )
+  label_map_decoder: TfExampleDecoderLabelMap = dataclasses.field(
+      default_factory=TfExampleDecoderLabelMap
+  )
 
 
 @dataclasses.dataclass
 class RandAugment(hyperparams.Config):
   """Configuration for RandAugment."""
   num_layers: int = 2
   magnitude: float = 10
@@ -101,16 +106,16 @@
 
   Attributes:
     type: 'str', type of augmentation be used, one of the fields below.
     randaug: RandAugment config.
     autoaug: AutoAugment config.
   """
   type: Optional[str] = None
-  randaug: RandAugment = RandAugment()
-  autoaug: AutoAugment = AutoAugment()
+  randaug: RandAugment = dataclasses.field(default_factory=RandAugment)
+  autoaug: AutoAugment = dataclasses.field(default_factory=AutoAugment)
 
 
 @dataclasses.dataclass
 class NormActivation(hyperparams.Config):
   activation: str = 'relu'
   use_sync_bn: bool = True
   norm_momentum: float = 0.99
@@ -134,14 +139,29 @@
   # Keep for backward compatibility.
   aug_policy: Optional[str] = None  # None, 'autoaug', or 'randaug'.
   randaug_magnitude: Optional[int] = 10
 
 
 @dataclasses.dataclass
 class TFLitePostProcessingConfig(hyperparams.Config):
+  """TFLite Post Processing config for inference."""
   max_detections: int = 200
   max_classes_per_detection: int = 5
   # Regular NMS run in a multi-class fashion and is slow. Setting it to False
   # uses class-agnostic NMS, which is faster.
   use_regular_nms: bool = False
   nms_score_threshold: float = 0.1
   nms_iou_threshold: float = 0.5
+  # Whether to normalize coordinates of anchors to [0, 1]. If setting to True,
+  # coordinates of output boxes is also normalized but latency increases.
+  normalize_anchor_coordinates: Optional[bool] = False
+  # Whether to omit the final nms placeholder op. If set to True, the output
+  # will be a tuple of boxes, scores result right before the NMS operation.
+  omit_nms: Optional[bool] = False
+  # The number of detections per class when using regular NMS.
+  detections_per_class: Optional[int] = 5
+  # Box scaling factors. It should agree with `box_coder_weights` defined in
+  # `DetectionGenerator`, which is in the format of [y, x, w, h].
+  y_scale: float = 1.0
+  x_scale: float = 1.0
+  w_scale: float = 1.0
+  h_scale: float = 1.0
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/decoders.py` & `tf-models-no-deps-2.16.0/official/vision/configs/decoders.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -62,11 +62,11 @@
   """Configuration for decoders.
 
   Attributes:
     type: 'str', type of decoder be used, one of the fields below.
     fpn: fpn config.
   """
   type: Optional[str] = None
-  fpn: FPN = FPN()
-  nasfpn: NASFPN = NASFPN()
-  identity: Identity = Identity()
-  aspp: ASPP = ASPP()
+  fpn: FPN = dataclasses.field(default_factory=FPN)
+  nasfpn: NASFPN = dataclasses.field(default_factory=NASFPN)
+  identity: Identity = dataclasses.field(default_factory=Identity)
+  aspp: ASPP = dataclasses.field(default_factory=ASPP)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/image_classification.py` & `tf-models-no-deps-2.16.0/official/vision/configs/image_classification.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,94 +11,123 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Image classification configuration definition."""
 import dataclasses
 import os
-from typing import List, Optional, Tuple
+from typing import List, Optional, Tuple, Union, Sequence
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.modeling import optimization
 from official.vision.configs import common
 from official.vision.configs import backbones
 
 
 @dataclasses.dataclass
 class DataConfig(cfg.DataConfig):
   """Input config for training."""
-  input_path: str = ''
+  input_path: Union[Sequence[str], str, hyperparams.Config] = ''
+  weights: Optional[hyperparams.base_config.Config] = None
   global_batch_size: int = 0
   is_training: bool = True
   dtype: str = 'float32'
   shuffle_buffer_size: int = 10000
   cycle_length: int = 10
   is_multilabel: bool = False
   aug_rand_hflip: bool = True
   aug_crop: Optional[bool] = True
   crop_area_range: Optional[Tuple[float, float]] = (0.08, 1.0)
   aug_type: Optional[
       common.Augmentation] = None  # Choose from AutoAugment and RandAugment.
+  three_augment: bool = False
   color_jitter: float = 0.
   random_erasing: Optional[common.RandomErasing] = None
   file_type: str = 'tfrecord'
   image_field_key: str = 'image/encoded'
   label_field_key: str = 'image/class/label'
   decode_jpeg_only: bool = True
   mixup_and_cutmix: Optional[common.MixupAndCutmix] = None
-  decoder: Optional[common.DataDecoder] = common.DataDecoder()
+  decoder: Optional[common.DataDecoder] = dataclasses.field(
+      default_factory=common.DataDecoder
+  )
 
   # Keep for backward compatibility.
   aug_policy: Optional[str] = None  # None, 'autoaug', or 'randaug'.
   randaug_magnitude: Optional[int] = 10
+  # Determines ratio between the side of the cropped image and the short side of
+  # the original image.
+  center_crop_fraction: Optional[float] = 0.875
+  # Interpolation method for resizing image in Parser for both training and eval
+  tf_resize_method: str = 'bilinear'
+  # Repeat augmentation puts multiple augmentations of the same image in a batch
+  # https://arxiv.org/abs/1902.05509
+  repeated_augment: Optional[int] = None
 
 
 @dataclasses.dataclass
 class ImageClassificationModel(hyperparams.Config):
   """The model config."""
   num_classes: int = 0
   input_size: List[int] = dataclasses.field(default_factory=list)
-  backbone: backbones.Backbone = backbones.Backbone(
-      type='resnet', resnet=backbones.ResNet())
+  backbone: backbones.Backbone = dataclasses.field(
+      default_factory=lambda: backbones.Backbone(  # pylint: disable=g-long-lambda
+          type='resnet', resnet=backbones.ResNet()
+      )
+  )
   dropout_rate: float = 0.0
-  norm_activation: common.NormActivation = common.NormActivation(
-      use_sync_bn=False)
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=lambda: common.NormActivation(use_sync_bn=False)
+  )
   # Adds a BatchNormalization layer pre-GlobalAveragePooling in classification
   add_head_batch_norm: bool = False
   kernel_initializer: str = 'random_uniform'
   # Whether to output softmax results instead of logits.
   output_softmax: bool = False
 
 
 @dataclasses.dataclass
 class Losses(hyperparams.Config):
   loss_weight: float = 1.0
   one_hot: bool = True
   label_smoothing: float = 0.0
   l2_weight_decay: float = 0.0
   soft_labels: bool = False
+  # Converts multi-class classification to multi-label classification. Weights
+  # each object class equally in the loss function, ignoring their size.
+  use_binary_cross_entropy: bool = False
 
 
 @dataclasses.dataclass
 class Evaluation(hyperparams.Config):
   top_k: int = 5
   precision_and_recall_thresholds: Optional[List[float]] = None
   report_per_class_precision_and_recall: bool = False
 
 
 @dataclasses.dataclass
 class ImageClassificationTask(cfg.TaskConfig):
   """The task config."""
-  model: ImageClassificationModel = ImageClassificationModel()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(is_training=False)
-  losses: Losses = Losses()
-  evaluation: Evaluation = Evaluation()
+  model: ImageClassificationModel = dataclasses.field(
+      default_factory=ImageClassificationModel
+  )
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=False)
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
+  evaluation: Evaluation = dataclasses.field(default_factory=Evaluation)
+  train_input_partition_dims: Optional[List[int]] = dataclasses.field(
+      default_factory=list)
+  eval_input_partition_dims: Optional[List[int]] = dataclasses.field(
+      default_factory=list)
   init_checkpoint: Optional[str] = None
   init_checkpoint_modules: str = 'all'  # all or backbone
   model_output_keys: Optional[List[int]] = dataclasses.field(
       default_factory=list)
   freeze_backbone: bool = False
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/image_classification_test.py` & `tf-models-no-deps-2.16.0/official/vision/configs/image_classification_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for image_classification."""
 # pylint: disable=unused-import
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official import vision
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.vision.configs import image_classification as exp_cfg
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/maskrcnn.py` & `tf-models-no-deps-2.16.0/official/vision/configs/maskrcnn.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """R-CNN(-RS) configuration definition."""
 
 import dataclasses
 import os
-from typing import List, Optional, Union
+from typing import List, Optional, Sequence, Union
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.modeling import optimization
 from official.vision.configs import common
 from official.vision.configs import decoders
@@ -30,36 +30,52 @@
 # pylint: disable=missing-class-docstring
 @dataclasses.dataclass
 class Parser(hyperparams.Config):
   num_channels: int = 3
   match_threshold: float = 0.5
   unmatched_threshold: float = 0.5
   aug_rand_hflip: bool = False
+  aug_rand_vflip: bool = False
   aug_scale_min: float = 1.0
   aug_scale_max: float = 1.0
   aug_type: Optional[
       common.Augmentation] = None  # Choose from AutoAugment and RandAugment.
   skip_crowd_during_training: bool = True
   max_num_instances: int = 100
   rpn_match_threshold: float = 0.7
   rpn_unmatched_threshold: float = 0.3
   rpn_batch_size_per_im: int = 256
   rpn_fg_fraction: float = 0.5
   mask_crop_size: int = 112
+  pad: bool = True  # Only support `pad = True`.
+  keep_aspect_ratio: bool = True  # Only support `keep_aspect_ratio = True`.
+
+  def __post_init__(self, *args, **kwargs):
+    """Validates the configuration."""
+    if not self.pad:
+      raise ValueError('`maskrcnn.Parser` only supports `pad = True`.')
+    if not self.keep_aspect_ratio:
+      raise ValueError(
+          '`maskrcnn.Parser` only supports `keep_aspect_ratio = True`.'
+      )
+    super().__post_init__(*args, **kwargs)
 
 
 @dataclasses.dataclass
 class DataConfig(cfg.DataConfig):
   """Input config for training."""
-  input_path: str = ''
+  input_path: Union[Sequence[str], str, hyperparams.Config] = ''
+  weights: Optional[hyperparams.Config] = None
   global_batch_size: int = 0
   is_training: bool = False
   dtype: str = 'bfloat16'
-  decoder: common.DataDecoder = common.DataDecoder()
-  parser: Parser = Parser()
+  decoder: common.DataDecoder = dataclasses.field(
+      default_factory=common.DataDecoder
+  )
+  parser: Parser = dataclasses.field(default_factory=Parser)
   shuffle_buffer_size: int = 10000
   file_type: str = 'tfrecord'
   drop_remainder: bool = True
   # Number of examples in the data set, it's used to create the annotation file.
   num_examples: int = -1
 
 
@@ -131,14 +147,15 @@
   pre_nms_top_k: int = 5000
   pre_nms_score_threshold: float = 0.05
   nms_iou_threshold: float = 0.5
   max_num_detections: int = 100
   nms_version: str = 'v2'  # `v2`, `v1`, `batched`
   use_cpu_nms: bool = False
   soft_nms_sigma: Optional[float] = None  # Only works when nms_version='v1'.
+  use_sigmoid_probability: bool = False
 
 
 @dataclasses.dataclass
 class MaskHead(hyperparams.Config):
   upsample_factor: int = 2
   num_convs: int = 4
   num_filters: int = 256
@@ -159,66 +176,91 @@
 
 @dataclasses.dataclass
 class MaskRCNN(hyperparams.Config):
   num_classes: int = 0
   input_size: List[int] = dataclasses.field(default_factory=list)
   min_level: int = 2
   max_level: int = 6
-  anchor: Anchor = Anchor()
+  anchor: Anchor = dataclasses.field(default_factory=Anchor)
   include_mask: bool = True
-  backbone: backbones.Backbone = backbones.Backbone(
-      type='resnet', resnet=backbones.ResNet())
-  decoder: decoders.Decoder = decoders.Decoder(
-      type='fpn', fpn=decoders.FPN())
-  rpn_head: RPNHead = RPNHead()
-  detection_head: DetectionHead = DetectionHead()
-  roi_generator: ROIGenerator = ROIGenerator()
-  roi_sampler: ROISampler = ROISampler()
-  roi_aligner: ROIAligner = ROIAligner()
-  detection_generator: DetectionGenerator = DetectionGenerator()
-  mask_head: Optional[MaskHead] = MaskHead()
-  mask_sampler: Optional[MaskSampler] = MaskSampler()
-  mask_roi_aligner: Optional[MaskROIAligner] = MaskROIAligner()
-  norm_activation: common.NormActivation = common.NormActivation(
-      norm_momentum=0.997,
-      norm_epsilon=0.0001,
-      use_sync_bn=True)
+  outer_boxes_scale: float = 1.0
+  backbone: backbones.Backbone = dataclasses.field(
+      default_factory=lambda: backbones.Backbone(
+          type='resnet', resnet=backbones.ResNet()
+      )
+  )
+  decoder: decoders.Decoder = dataclasses.field(
+      default_factory=lambda: decoders.Decoder(type='fpn', fpn=decoders.FPN())
+  )
+  rpn_head: RPNHead = dataclasses.field(default_factory=RPNHead)
+  detection_head: DetectionHead = dataclasses.field(
+      default_factory=DetectionHead
+  )
+  roi_generator: ROIGenerator = dataclasses.field(default_factory=ROIGenerator)
+  roi_sampler: ROISampler = dataclasses.field(default_factory=ROISampler)
+  roi_aligner: ROIAligner = dataclasses.field(default_factory=ROIAligner)
+  detection_generator: DetectionGenerator = dataclasses.field(
+      default_factory=DetectionGenerator
+  )
+  mask_head: Optional[MaskHead] = dataclasses.field(default_factory=MaskHead)
+  mask_sampler: Optional[MaskSampler] = dataclasses.field(
+      default_factory=MaskSampler
+  )
+  mask_roi_aligner: Optional[MaskROIAligner] = dataclasses.field(
+      default_factory=MaskROIAligner
+  )
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=lambda: common.NormActivation(  # pylint: disable=g-long-lambda
+          norm_momentum=0.997, norm_epsilon=0.0001, use_sync_bn=True
+      )
+  )
 
 
 @dataclasses.dataclass
 class Losses(hyperparams.Config):
   loss_weight: float = 1.0
   rpn_huber_loss_delta: float = 1. / 9.
   frcnn_huber_loss_delta: float = 1.
+  frcnn_class_use_binary_cross_entropy: bool = False
+  frcnn_class_loss_top_k_percent: float = 1.
   l2_weight_decay: float = 0.0
   rpn_score_weight: float = 1.0
   rpn_box_weight: float = 1.0
   frcnn_class_weight: float = 1.0
   frcnn_box_weight: float = 1.0
   mask_weight: float = 1.0
+  class_weights: Optional[List[float]] = None
 
 
 @dataclasses.dataclass
 class MaskRCNNTask(cfg.TaskConfig):
-  model: MaskRCNN = MaskRCNN()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(is_training=False,
-                                           drop_remainder=False)
-  losses: Losses = Losses()
+  model: MaskRCNN = dataclasses.field(default_factory=MaskRCNN)
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(  # pylint: disable=g-long-lambda
+          is_training=False, drop_remainder=False
+      )
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
   init_checkpoint: Optional[str] = None
   init_checkpoint_modules: Union[
       str, List[str]] = 'all'  # all, backbone, and/or decoder
   annotation_file: Optional[str] = None
   per_category_metrics: bool = False
   # If set, we only use masks for the specified class IDs.
   allowed_mask_class_ids: Optional[List[int]] = None
   # If set, the COCO metrics will be computed.
   use_coco_metrics: bool = True
   # If set, the Waymo Open Dataset evaluator would be used.
   use_wod_metrics: bool = False
+  # If set, use instance metrics (AP, mask AP, etc.) computed by an efficient
+  # approximation algorithm with TPU compatible operations.
+  use_approx_instance_metrics: bool = False
 
   # If set, freezes the backbone during training.
   # TODO(crisnv) Add paper link when available.
   freeze_backbone: bool = False
 
 
 COCO_INPUT_PATH_BASE = 'coco'
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/maskrcnn_test.py` & `tf-models-no-deps-2.16.0/official/vision/configs/maskrcnn_test.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for maskrcnn."""
 # pylint: disable=unused-import
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official import vision
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.vision.configs import maskrcnn as exp_cfg
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/retinanet.py` & `tf-models-no-deps-2.16.0/official/vision/configs/retinanet.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,20 +12,21 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """RetinaNet configuration definition."""
 
 import dataclasses
 import os
-from typing import List, Optional, Union
+from typing import Optional, List, Sequence, Union
 
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.modeling import optimization
+from official.modeling.hyperparams import base_config
 from official.vision.configs import common
 from official.vision.configs import decoders
 from official.vision.configs import backbones
 
 
 # pylint: disable=missing-class-docstring
 # Keep for backward compatibility.
@@ -54,28 +55,38 @@
   aug_rand_hflip: bool = False
   aug_scale_min: float = 1.0
   aug_scale_max: float = 1.0
   skip_crowd_during_training: bool = True
   max_num_instances: int = 100
   # Can choose AutoAugment and RandAugment.
   aug_type: Optional[common.Augmentation] = None
+  pad: bool = True
+  keep_aspect_ratio: bool = True
 
   # Keep for backward compatibility. Not used.
   aug_policy: Optional[str] = None
 
 
 @dataclasses.dataclass
 class DataConfig(cfg.DataConfig):
-  """Input config for training."""
-  input_path: str = ''
+  """Input config for training.
+
+  Attributes:
+    weights: Sampling weights for each corresponding input_path. If used, then
+      input_path must be a config with matching keys.
+  """
+  input_path: Union[Sequence[str], str, base_config.Config] = ''
+  weights: Optional[base_config.Config] = None
   global_batch_size: int = 0
   is_training: bool = False
   dtype: str = 'bfloat16'
-  decoder: common.DataDecoder = common.DataDecoder()
-  parser: Parser = Parser()
+  decoder: common.DataDecoder = dataclasses.field(
+      default_factory=common.DataDecoder
+  )
+  parser: Parser = dataclasses.field(default_factory=Parser)
   shuffle_buffer_size: int = 10000
   file_type: str = 'tfrecord'
 
 
 @dataclasses.dataclass
 class Anchor(hyperparams.Config):
   num_scales: int = 3
@@ -95,23 +106,35 @@
 
 
 @dataclasses.dataclass
 class AttributeHead(hyperparams.Config):
   name: str = ''
   type: str = 'regression'
   size: int = 1
+  # Attribute heads of the same "prediction_tower_name" will share the same
+  # prediction tower. If unspecified, they will use their individual prediction
+  # tower.
+  prediction_tower_name: str = ''
+  # If `num_convs` or `num_filters` are not provided, it will use the parameters
+  # from RetinaNetHead. When several attributes share the head through setting
+  # the same `prediction_tower_name`, we only respect `num_convs` and
+  # `num_filters` from the first attribute that use the shared prediction tower
+  # name.
+  num_convs: Optional[int] = None
+  num_filters: Optional[int] = None
 
 
 @dataclasses.dataclass
 class RetinaNetHead(hyperparams.Config):
   num_convs: int = 4
   num_filters: int = 256
   use_separable_conv: bool = False
   attribute_heads: List[AttributeHead] = dataclasses.field(default_factory=list)
   share_classification_heads: bool = False
+  share_level_convs: Optional[bool] = True
 
 
 @dataclasses.dataclass
 class DetectionGenerator(hyperparams.Config):
   apply_nms: bool = True
   pre_nms_top_k: int = 5000
   pre_nms_score_threshold: float = 0.05
@@ -120,62 +143,86 @@
   nms_version: str = 'v2'  # `v2`, `v1`, `batched`, or `tflite`.
   use_cpu_nms: bool = False
   soft_nms_sigma: Optional[float] = None  # Only works when nms_version='v1'.
 
   # When nms_version = `tflite`, values from tflite_post_processing need to be
   # specified. They are compatible with the input arguments used by TFLite
   # custom NMS op and override above parameters.
-  tflite_post_processing: common.TFLitePostProcessingConfig = common.TFLitePostProcessingConfig(
+  tflite_post_processing: common.TFLitePostProcessingConfig = dataclasses.field(
+      default_factory=common.TFLitePostProcessingConfig
   )
+  # Return decoded boxes/scores even if apply_nms is set `True`.
+  return_decoded: Optional[bool] = None
+  # Only works when nms_version='v2'.
+  use_class_agnostic_nms: Optional[bool] = False
+  # Weights or scales when encode and decode boxes coordinates. For Faster RCNN,
+  # the open-source implementation recommends using [10.0, 10.0, 5.0, 5.0].
+  box_coder_weights: Optional[List[float]] = None
 
 
 @dataclasses.dataclass
 class RetinaNet(hyperparams.Config):
   num_classes: int = 0
   input_size: List[int] = dataclasses.field(default_factory=list)
   min_level: int = 3
   max_level: int = 7
-  anchor: Anchor = Anchor()
-  backbone: backbones.Backbone = backbones.Backbone(
-      type='resnet', resnet=backbones.ResNet())
-  decoder: decoders.Decoder = decoders.Decoder(
-      type='fpn', fpn=decoders.FPN())
-  head: RetinaNetHead = RetinaNetHead()
-  detection_generator: DetectionGenerator = DetectionGenerator()
-  norm_activation: common.NormActivation = common.NormActivation()
+  anchor: Anchor = dataclasses.field(default_factory=Anchor)
+  backbone: backbones.Backbone = dataclasses.field(
+      default_factory=lambda: backbones.Backbone(  # pylint: disable=g-long-lambda
+          type='resnet', resnet=backbones.ResNet()
+      )
+  )
+  decoder: decoders.Decoder = dataclasses.field(
+      default_factory=lambda: decoders.Decoder(type='fpn', fpn=decoders.FPN())
+  )
+  head: RetinaNetHead = dataclasses.field(default_factory=RetinaNetHead)
+  detection_generator: DetectionGenerator = dataclasses.field(
+      default_factory=DetectionGenerator
+  )
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=common.NormActivation
+  )
 
 
 @dataclasses.dataclass
 class ExportConfig(hyperparams.Config):
   output_normalized_coordinates: bool = False
   cast_num_detections_to_float: bool = False
   cast_detection_classes_to_float: bool = False
+  output_intermediate_features: bool = False
 
 
 @dataclasses.dataclass
 class RetinaNetTask(cfg.TaskConfig):
-  model: RetinaNet = RetinaNet()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(is_training=False)
-  losses: Losses = Losses()
+  model: RetinaNet = dataclasses.field(default_factory=RetinaNet)
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=False)
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
   init_checkpoint: Optional[str] = None
   init_checkpoint_modules: Union[
       str, List[str]] = 'all'  # all, backbone, and/or decoder
   annotation_file: Optional[str] = None
   per_category_metrics: bool = False
-  export_config: ExportConfig = ExportConfig()
+  export_config: ExportConfig = dataclasses.field(default_factory=ExportConfig)
   # If set, the COCO metrics will be computed.
   use_coco_metrics: bool = True
   # If set, the Waymo Open Dataset evaluator would be used.
   use_wod_metrics: bool = False
 
   # If set, freezes the backbone during training.
   # TODO(crisnv) Add paper link when available.
   freeze_backbone: bool = False
 
+  # Sets maximum number of boxes to be evaluated by coco eval api.
+  max_num_eval_detections: int = 100
+
 
 @exp_factory.register_config_factory('retinanet')
 def retinanet() -> cfg.ExperimentConfig:
   """RetinaNet general config."""
   return cfg.ExperimentConfig(
       task=RetinaNetTask(),
       restrictions=[
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/retinanet_test.py` & `tf-models-no-deps-2.16.0/official/vision/configs/retinanet_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for retinanet."""
 # pylint: disable=unused-import
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official import vision
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.vision.configs import retinanet as exp_cfg
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/semantic_segmentation.py` & `tf-models-no-deps-2.16.0/official/vision/configs/semantic_segmentation.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,34 +11,68 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Semantic segmentation configuration definition."""
 import dataclasses
 import os
-from typing import List, Optional, Union
+from typing import List, Optional, Sequence, Union
 
 import numpy as np
+
 from official.core import config_definitions as cfg
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.modeling import optimization
 from official.vision.configs import common
 from official.vision.configs import decoders
 from official.vision.configs import backbones
+from official.vision.ops import preprocess_ops
+
+
+@dataclasses.dataclass
+class DenseFeatureConfig(hyperparams.Config):
+  """Config for dense features, such as RGB pixels, masks, heatmaps.
+
+  The dense features are encoded images in TF examples. Thus they are
+  1-, 3- or 4-channel. For features with another channel number (e.g.
+  optical flow), they could be encoded in multiple 1-channel features.
+  The default config is for RGB input, with mean and stddev from ImageNet
+  datasets. Only supports 8-bit encoded features with the maximum value = 255.
+
+  Attributes:
+    feature_name: The key of the feature in TF examples.
+    num_channels: An `int` specifying the number of channels of the feature.
+    mean: A list of floats in the range of [0, 255] representing the mean value
+      of each channel. The length of the list should match num_channels.
+    stddev: A list of floats in the range of [0, 255] representing the standard
+      deviation of each channel. The length should match num_channels.
+  """
+  feature_name: str = 'image/encoded'
+  num_channels: int = 3
+  mean: List[float] = dataclasses.field(
+      default_factory=lambda: preprocess_ops.MEAN_RGB
+  )
+  stddev: List[float] = dataclasses.field(
+      default_factory=lambda: preprocess_ops.STDDEV_RGB
+  )
 
 
 @dataclasses.dataclass
 class DataConfig(cfg.DataConfig):
   """Input config for training."""
+  image_feature: DenseFeatureConfig = dataclasses.field(
+      default_factory=DenseFeatureConfig
+  )
   output_size: List[int] = dataclasses.field(default_factory=list)
   # If crop_size is specified, image will be resized first to
   # output_size, then crop of size crop_size will be cropped.
   crop_size: List[int] = dataclasses.field(default_factory=list)
-  input_path: str = ''
+  input_path: Union[Sequence[str], str, hyperparams.Config] = None
+  weights: Optional[hyperparams.Config] = None
   global_batch_size: int = 0
   is_training: bool = True
   dtype: str = 'float32'
   shuffle_buffer_size: int = 1000
   cycle_length: int = 10
   # If resize_eval_groundtruth is set to False, original image sizes are used
   # for eval. In that case, groundtruth_padded_size has to be specified too to
@@ -48,26 +82,31 @@
   aug_scale_min: float = 1.0
   aug_scale_max: float = 1.0
   aug_rand_hflip: bool = True
   preserve_aspect_ratio: bool = True
   aug_policy: Optional[str] = None
   drop_remainder: bool = True
   file_type: str = 'tfrecord'
-  decoder: Optional[common.DataDecoder] = common.DataDecoder()
+  decoder: Optional[common.DataDecoder] = dataclasses.field(
+      default_factory=common.DataDecoder
+  )
+  additional_dense_features: List[DenseFeatureConfig] = dataclasses.field(
+      default_factory=list)
 
 
 @dataclasses.dataclass
 class SegmentationHead(hyperparams.Config):
   """Segmentation head config."""
   level: int = 3
   num_convs: int = 2
   num_filters: int = 256
   use_depthwise_convolution: bool = False
   prediction_kernel_size: int = 1
   upsample_factor: int = 1
+  logit_activation: Optional[str] = None  # None, 'sigmoid', or 'softmax'.
   feature_fusion: Optional[
       str] = None  # None, deeplabv3plus, panoptic_fpn_fusion or pyramid_fusion
   # deeplabv3plus feature fusion params
   low_level: Union[int, str] = 2
   low_level_num_filters: int = 48
   # panoptic_fpn_fusion params
   decoder_min_level: Optional[Union[int, str]] = None
@@ -78,70 +117,92 @@
 class MaskScoringHead(hyperparams.Config):
   """Mask Scoring head config."""
   num_convs: int = 4
   num_filters: int = 128
   fc_input_size: List[int] = dataclasses.field(default_factory=list)
   num_fcs: int = 2
   fc_dims: int = 1024
+  use_depthwise_convolution: bool = False
 
 
 @dataclasses.dataclass
 class SemanticSegmentationModel(hyperparams.Config):
   """Semantic segmentation model config."""
   num_classes: int = 0
   input_size: List[int] = dataclasses.field(default_factory=list)
   min_level: int = 3
   max_level: int = 6
-  head: SegmentationHead = SegmentationHead()
-  backbone: backbones.Backbone = backbones.Backbone(
-      type='resnet', resnet=backbones.ResNet())
-  decoder: decoders.Decoder = decoders.Decoder(type='identity')
+  head: SegmentationHead = dataclasses.field(default_factory=SegmentationHead)
+  backbone: backbones.Backbone = dataclasses.field(
+      default_factory=lambda: backbones.Backbone(  # pylint: disable=g-long-lambda
+          type='resnet', resnet=backbones.ResNet()
+      )
+  )
+  decoder: decoders.Decoder = dataclasses.field(
+      default_factory=lambda: decoders.Decoder(type='identity')
+  )
   mask_scoring_head: Optional[MaskScoringHead] = None
-  norm_activation: common.NormActivation = common.NormActivation()
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=common.NormActivation
+  )
 
 
 @dataclasses.dataclass
 class Losses(hyperparams.Config):
+  """Loss function config."""
   loss_weight: float = 1.0
   label_smoothing: float = 0.0
   ignore_label: int = 255
   gt_is_matting_map: bool = False
   class_weights: List[float] = dataclasses.field(default_factory=list)
   l2_weight_decay: float = 0.0
   use_groundtruth_dimension: bool = True
+  # If true, use binary cross entropy (sigmoid) in loss, otherwise, use
+  # categorical cross entropy (softmax).
+  use_binary_cross_entropy: bool = False
   top_k_percent_pixels: float = 1.0
+  mask_scoring_weight: float = 1.0
 
 
 @dataclasses.dataclass
 class Evaluation(hyperparams.Config):
+  """Evaluation config."""
   report_per_class_iou: bool = True
   report_train_mean_iou: bool = True  # Turning this off can speed up training.
 
 
 @dataclasses.dataclass
 class ExportConfig(hyperparams.Config):
+  """Model export config."""
   # Whether to rescale the predicted mask to the original image size.
   rescale_output: bool = False
 
 
 @dataclasses.dataclass
 class SemanticSegmentationTask(cfg.TaskConfig):
   """The model config."""
-  model: SemanticSegmentationModel = SemanticSegmentationModel()
-  train_data: DataConfig = DataConfig(is_training=True)
-  validation_data: DataConfig = DataConfig(is_training=False)
-  losses: Losses = Losses()
-  evaluation: Evaluation = Evaluation()
+  model: SemanticSegmentationModel = dataclasses.field(
+      default_factory=SemanticSegmentationModel
+  )
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=False)
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
+  evaluation: Evaluation = dataclasses.field(default_factory=Evaluation)
   train_input_partition_dims: List[int] = dataclasses.field(
       default_factory=list)
   eval_input_partition_dims: List[int] = dataclasses.field(default_factory=list)
   init_checkpoint: Optional[str] = None
   init_checkpoint_modules: Union[
       str, List[str]] = 'all'  # all, backbone, and/or decoder
-  export_config: ExportConfig = ExportConfig()
+  export_config: ExportConfig = dataclasses.field(default_factory=ExportConfig)
+  allow_image_summary: bool = True
 
 
 @exp_factory.register_config_factory('semantic_segmentation')
 def semantic_segmentation() -> cfg.ExperimentConfig:
   """Semantic segmentation general."""
   return cfg.ExperimentConfig(
       task=SemanticSegmentationTask(),
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/semantic_segmentation_test.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/configs/semantic_segmentation_3d_test.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,34 +12,32 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for semantic_segmentation."""
 
 # pylint: disable=unused-import
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-from official import vision
 from official.core import config_definitions as cfg
 from official.core import exp_factory
-from official.vision.configs import semantic_segmentation as exp_cfg
+from official.projects.volumetric_models.configs import semantic_segmentation_3d as exp_cfg
 
 
 class ImageSegmentationConfigTest(tf.test.TestCase, parameterized.TestCase):
 
-  @parameterized.parameters(('seg_deeplabv3_pascal',),
-                            ('seg_deeplabv3plus_pascal',))
+  @parameterized.parameters(
+      ('seg_unet3d_test',),)
   def test_semantic_segmentation_configs(self, config_name):
     config = exp_factory.get_exp_config(config_name)
     self.assertIsInstance(config, cfg.ExperimentConfig)
-    self.assertIsInstance(config.task, exp_cfg.SemanticSegmentationTask)
+    self.assertIsInstance(config.task, exp_cfg.SemanticSegmentation3DTask)
     self.assertIsInstance(config.task.model,
-                          exp_cfg.SemanticSegmentationModel)
+                          exp_cfg.SemanticSegmentationModel3D)
     self.assertIsInstance(config.task.train_data, exp_cfg.DataConfig)
-    config.validate()
     config.task.train_data.is_training = None
     with self.assertRaises(KeyError):
       config.validate()
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/video_classification.py` & `tf-models-no-deps-2.16.0/official/vision/configs/video_classification.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -60,72 +60,77 @@
   aug_min_area_ratio: float = 0.49
   aug_max_area_ratio: float = 1.0
   aug_type: Optional[
       common.Augmentation] = None  # AutoAugment and RandAugment.
   mixup_and_cutmix: Optional[common.MixupAndCutmix] = None
   image_field_key: str = 'image/encoded'
   label_field_key: str = 'clip/label/index'
+  input_image_format: str = 'jpeg'
 
 
 def kinetics400(is_training):
-  """Generated Kinectics 400 dataset configs."""
+  """Generated Kinetics 400 dataset configs."""
   return DataConfig(
       name='kinetics400',
       num_classes=400,
       is_training=is_training,
       split='train' if is_training else 'valid',
       drop_remainder=is_training,
       num_examples=215570 if is_training else 17706,
       feature_shape=(64, 224, 224, 3) if is_training else (250, 224, 224, 3))
 
 
 def kinetics600(is_training):
-  """Generated Kinectics 600 dataset configs."""
+  """Generated Kinetics 600 dataset configs."""
   return DataConfig(
       name='kinetics600',
       num_classes=600,
       is_training=is_training,
       split='train' if is_training else 'valid',
       drop_remainder=is_training,
       num_examples=366016 if is_training else 27780,
       feature_shape=(64, 224, 224, 3) if is_training else (250, 224, 224, 3))
 
 
 def kinetics700(is_training):
-  """Generated Kinectics 600 dataset configs."""
+  """Generated Kinetics 600 dataset configs."""
   return DataConfig(
       name='kinetics700',
       num_classes=700,
       is_training=is_training,
       split='train' if is_training else 'valid',
       drop_remainder=is_training,
       num_examples=522883 if is_training else 33441,
       feature_shape=(64, 224, 224, 3) if is_training else (250, 224, 224, 3))
 
 
 def kinetics700_2020(is_training):
-  """Generated Kinectics 600 dataset configs."""
+  """Generated Kinetics 600 dataset configs."""
   return DataConfig(
       name='kinetics700',
       num_classes=700,
       is_training=is_training,
       split='train' if is_training else 'valid',
       drop_remainder=is_training,
       num_examples=535982 if is_training else 33640,
       feature_shape=(64, 224, 224, 3) if is_training else (250, 224, 224, 3))
 
 
 @dataclasses.dataclass
 class VideoClassificationModel(hyperparams.Config):
   """The model config."""
   model_type: str = 'video_classification'
-  backbone: backbones_3d.Backbone3D = backbones_3d.Backbone3D(
-      type='resnet_3d', resnet_3d=backbones_3d.ResNet3D50())
-  norm_activation: common.NormActivation = common.NormActivation(
-      use_sync_bn=False)
+  backbone: backbones_3d.Backbone3D = dataclasses.field(
+      default_factory=lambda: backbones_3d.Backbone3D(  # pylint: disable=g-long-lambda
+          type='resnet_3d', resnet_3d=backbones_3d.ResNet3D50()
+      )
+  )
+  norm_activation: common.NormActivation = dataclasses.field(
+      default_factory=lambda: common.NormActivation(use_sync_bn=False)
+  )
   dropout_rate: float = 0.2
   aggregate_endpoints: bool = False
   require_endpoints: Optional[Tuple[str, ...]] = None
 
 
 @dataclasses.dataclass
 class Losses(hyperparams.Config):
@@ -138,20 +143,27 @@
 class Metrics(hyperparams.Config):
   use_per_class_recall: bool = False
 
 
 @dataclasses.dataclass
 class VideoClassificationTask(cfg.TaskConfig):
   """The task config."""
-  model: VideoClassificationModel = VideoClassificationModel()
-  train_data: DataConfig = DataConfig(is_training=True, drop_remainder=True)
-  validation_data: DataConfig = DataConfig(
-      is_training=False, drop_remainder=False)
-  losses: Losses = Losses()
-  metrics: Metrics = Metrics()
+  model: VideoClassificationModel = dataclasses.field(
+      default_factory=VideoClassificationModel
+  )
+  train_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(is_training=True, drop_remainder=True)
+  )
+  validation_data: DataConfig = dataclasses.field(
+      default_factory=lambda: DataConfig(  # pylint: disable=g-long-lambda
+          is_training=False, drop_remainder=False
+      )
+  )
+  losses: Losses = dataclasses.field(default_factory=Losses)
+  metrics: Metrics = dataclasses.field(default_factory=Metrics)
   init_checkpoint: Optional[str] = None
   init_checkpoint_modules: str = 'all'  # all or backbone
   freeze_backbone: bool = False
   # Spatial Partitioning fields.
   train_input_partition_dims: Optional[Tuple[int, ...]] = None
   eval_input_partition_dims: Optional[Tuple[int, ...]] = None
 
@@ -269,15 +281,15 @@
       learning_rate=0.8,
       train_epochs=100)
   return config
 
 
 @exp_factory.register_config_factory('video_classification_kinetics400')
 def video_classification_kinetics400() -> cfg.ExperimentConfig:
-  """Video classification on Kinectics 400 with resnet."""
+  """Video classification on Kinetics 400 with resnet."""
   train_dataset = kinetics400(is_training=True)
   validation_dataset = kinetics400(is_training=False)
   task = VideoClassificationTask(
       model=VideoClassificationModel(
           backbone=backbones_3d.Backbone3D(
               type='resnet_3d', resnet_3d=backbones_3d.ResNet3D50()),
           norm_activation=common.NormActivation(
@@ -295,15 +307,15 @@
       ])
   add_trainer(config, train_batch_size=1024, eval_batch_size=64)
   return config
 
 
 @exp_factory.register_config_factory('video_classification_kinetics600')
 def video_classification_kinetics600() -> cfg.ExperimentConfig:
-  """Video classification on Kinectics 600 with resnet."""
+  """Video classification on Kinetics 600 with resnet."""
   train_dataset = kinetics600(is_training=True)
   validation_dataset = kinetics600(is_training=False)
   task = VideoClassificationTask(
       model=VideoClassificationModel(
           backbone=backbones_3d.Backbone3D(
               type='resnet_3d', resnet_3d=backbones_3d.ResNet3D50()),
           norm_activation=common.NormActivation(
@@ -321,15 +333,15 @@
       ])
   add_trainer(config, train_batch_size=1024, eval_batch_size=64)
   return config
 
 
 @exp_factory.register_config_factory('video_classification_kinetics700')
 def video_classification_kinetics700() -> cfg.ExperimentConfig:
-  """Video classification on Kinectics 700 with resnet."""
+  """Video classification on Kinetics 700 with resnet."""
   train_dataset = kinetics700(is_training=True)
   validation_dataset = kinetics700(is_training=False)
   task = VideoClassificationTask(
       model=VideoClassificationModel(
           backbone=backbones_3d.Backbone3D(
               type='resnet_3d', resnet_3d=backbones_3d.ResNet3D50()),
           norm_activation=common.NormActivation(
@@ -347,15 +359,15 @@
       ])
   add_trainer(config, train_batch_size=1024, eval_batch_size=64)
   return config
 
 
 @exp_factory.register_config_factory('video_classification_kinetics700_2020')
 def video_classification_kinetics700_2020() -> cfg.ExperimentConfig:
-  """Video classification on Kinectics 700 2020 with resnet."""
+  """Video classification on Kinetics 700 2020 with resnet."""
   train_dataset = kinetics700_2020(is_training=True)
   validation_dataset = kinetics700_2020(is_training=False)
   task = VideoClassificationTask(
       model=VideoClassificationModel(
           backbone=backbones_3d.Backbone3D(
               type='resnet_3d', resnet_3d=backbones_3d.ResNet3D50()),
           norm_activation=common.NormActivation(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/configs/video_classification_test.py` & `tf-models-no-deps-2.16.0/official/projects/qat/vision/configs/image_classification_test.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,44 +1,48 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Tests for video_classification."""
-
+"""Tests for image_classification."""
 # pylint: disable=unused-import
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official import vision
 from official.core import config_definitions as cfg
 from official.core import exp_factory
-from official.vision.configs import video_classification as exp_cfg
-
+from official.projects.qat.vision.configs import common
+from official.projects.qat.vision.configs import image_classification as qat_exp_cfg
+from official.vision.configs import image_classification as exp_cfg
 
-class VideoClassificationConfigTest(tf.test.TestCase, parameterized.TestCase):
 
-  @parameterized.parameters(('video_classification',),
-                            ('video_classification_kinetics600',))
-  def test_video_classification_configs(self, config_name):
+class ImageClassificationConfigTest(tf.test.TestCase, parameterized.TestCase):
+
+  @parameterized.parameters(
+      ('resnet_imagenet_qat',),
+      ('mobilenet_imagenet_qat',),
+  )
+  def test_image_classification_configs(self, config_name):
     config = exp_factory.get_exp_config(config_name)
     self.assertIsInstance(config, cfg.ExperimentConfig)
-    self.assertIsInstance(config.task, exp_cfg.VideoClassificationTask)
-    self.assertIsInstance(config.task.model, exp_cfg.VideoClassificationModel)
+    self.assertIsInstance(config.task, qat_exp_cfg.ImageClassificationTask)
+    self.assertIsInstance(config.task.model,
+                          exp_cfg.ImageClassificationModel)
+    self.assertIsInstance(config.task.quantization, common.Quantization)
     self.assertIsInstance(config.task.train_data, exp_cfg.DataConfig)
-    config.validate()
     config.task.train_data.is_training = None
-    with self.assertRaises(KeyError):
+    with self.assertRaisesRegex(KeyError, 'Found inconsistency between key'):
       config.validate()
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/tasks/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/create_coco_tf_record.py` & `tf-models-no-deps-2.16.0/official/vision/data/create_coco_tf_record.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -33,15 +33,15 @@
 import os
 
 from absl import app  # pylint:disable=unused-import
 from absl import flags
 import numpy as np
 
 from pycocotools import mask
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 import multiprocessing as mp
 from official.vision.data import tfrecord_lib
 
 
 flags.DEFINE_boolean(
     'include_masks', False, 'Whether to include instance segmentations masks '
@@ -62,14 +62,17 @@
                     'annotations.')
 flags.DEFINE_string('panoptic_masks_dir', '',
                     'Directory containing panoptic masks annotations.')
 flags.DEFINE_boolean(
     'include_panoptic_masks', False, 'Whether to include category and '
     'instance masks in the result. These are required to run the PQ evaluator '
     'default: False.')
+flags.DEFINE_boolean(
+    'panoptic_skip_crowd', False, 'Whether to skip crowd or not for panoptic '
+    'annotations. default: False.')
 flags.DEFINE_string('output_file_prefix', '/tmp/train', 'Path to output file')
 flags.DEFINE_integer('num_shards', 32, 'Number of shards for output file.')
 _NUM_PROCESSES = flags.DEFINE_integer(
     'num_processes', None,
     ('Number of parallel processes to use. '
      'If set to 0, disables multi-processing.'))
 
@@ -130,15 +133,17 @@
         segments_encoded_mask, dtype=np.uint8) * _VOID_LABEL
     instance_mask = np.ones_like(
         segments_encoded_mask, dtype=np.uint8) * _VOID_INSTANCE_ID
 
   for idx, segment in enumerate(segments_info):
     segment_id = segment['id']
     category_id = segment['category_id']
-
+    is_crowd = segment['iscrowd']
+    if FLAGS.panoptic_skip_crowd and is_crowd:
+      continue
     if is_category_thing[category_id]:
       encoded_category_id = _THING_CLASS_ID
       instance_id = idx + 1
     else:
       encoded_category_id = category_id - _STUFF_CLASSES_OFFSET
       instance_id = _VOID_INSTANCE_ID
 
@@ -206,35 +211,38 @@
 def bbox_annotations_to_feature_dict(
     bbox_annotations, image_height, image_width, id_to_name_map, include_masks):
   """Convert COCO annotations to an encoded feature dict."""
 
   data, num_skipped = coco_annotations_to_lists(
       bbox_annotations, id_to_name_map, image_height, image_width,
       include_masks)
-  feature_dict = {
-      'image/object/bbox/xmin':
-          tfrecord_lib.convert_to_feature(data['xmin']),
-      'image/object/bbox/xmax':
-          tfrecord_lib.convert_to_feature(data['xmax']),
-      'image/object/bbox/ymin':
-          tfrecord_lib.convert_to_feature(data['ymin']),
-      'image/object/bbox/ymax':
-          tfrecord_lib.convert_to_feature(data['ymax']),
-      'image/object/class/text':
-          tfrecord_lib.convert_to_feature(data['category_names']),
-      'image/object/class/label':
-          tfrecord_lib.convert_to_feature(data['category_id']),
-      'image/object/is_crowd':
-          tfrecord_lib.convert_to_feature(data['is_crowd']),
-      'image/object/area':
-          tfrecord_lib.convert_to_feature(data['area'], 'float_list')
-  }
-  if include_masks:
-    feature_dict['image/object/mask'] = (
-        tfrecord_lib.convert_to_feature(data['encoded_mask_png']))
+  feature_dict = {}
+  if len(bbox_annotations) != num_skipped:
+    feature_dict = {
+        'image/object/bbox/xmin': tfrecord_lib.convert_to_feature(data['xmin']),
+        'image/object/bbox/xmax': tfrecord_lib.convert_to_feature(data['xmax']),
+        'image/object/bbox/ymin': tfrecord_lib.convert_to_feature(data['ymin']),
+        'image/object/bbox/ymax': tfrecord_lib.convert_to_feature(data['ymax']),
+        'image/object/class/text': tfrecord_lib.convert_to_feature(
+            data['category_names']
+        ),
+        'image/object/class/label': tfrecord_lib.convert_to_feature(
+            data['category_id']
+        ),
+        'image/object/is_crowd': tfrecord_lib.convert_to_feature(
+            data['is_crowd']
+        ),
+        'image/object/area': tfrecord_lib.convert_to_feature(
+            data['area'], 'float_list'
+        ),
+    }
+    if include_masks:
+      feature_dict['image/object/mask'] = tfrecord_lib.convert_to_feature(
+          data['encoded_mask_png']
+      )
 
   return feature_dict, num_skipped
 
 
 def encode_caption_annotations(caption_annotations):
   captions = []
   for caption_annotation in caption_annotations:
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/fake_feature_generator.py` & `tf-models-no-deps-2.16.0/official/vision/data/fake_feature_generator.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/image_utils.py` & `tf-models-no-deps-2.16.0/official/vision/data/image_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/image_utils_test.py` & `tf-models-no-deps-2.16.0/official/vision/data/image_utils_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for image_utils."""
 import imghdr
 from unittest import mock
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.data import fake_feature_generator
 from official.vision.data import image_utils
 
 
 class ImageUtilsTest(parameterized.TestCase, tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/process_coco_few_shot_json_files.py` & `tf-models-no-deps-2.16.0/official/vision/data/process_coco_few_shot_json_files.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -25,15 +25,15 @@
 import json
 import logging
 import os
 
 from absl import app
 from absl import flags
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 logger = tf.get_logger()
 logger.setLevel(logging.INFO)
 
 flags.DEFINE_string('workdir', None, 'Working directory.')
 
 FLAGS = flags.FLAGS
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/tf_example_builder.py` & `tf-models-no-deps-2.16.0/official/vision/data/tf_example_builder.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -136,15 +136,15 @@
     feature_key = tf_example_feature_key.EncodedImageFeatureKey(feature_prefix)
 
     # If source ID is not provided, we use hashed encoded image as the source
     # ID. Note that we only keep 24 bits to be consistent with the Model Garden
     # requirement, which will transform the source ID into float32.
     if not image_source_id:
       hashed_image = int(hashlib.blake2s(encoded_image).hexdigest(), 16)
-      image_source_id = _to_bytes(str(hash(hashed_image) % ((1 << 24) + 1)))
+      image_source_id = _to_bytes(str(hashed_image % ((1 << 24) + 1)))
 
     if label is not None:
       self.add_ints_feature(feature_key.label, label)
 
     return (
         self.add_bytes_feature(feature_key.encoded, encoded_image)
         .add_bytes_feature(feature_key.format, image_format)
@@ -201,15 +201,15 @@
       self.add_floats_feature(feature_key.confidence, confidences)
     return self
 
   def _compute_mask_areas(
       self, instance_mask_matrices: np.ndarray) -> Sequence[float]:
     return np.sum(
         instance_mask_matrices, axis=(1, 2, 3),
-        dtype=np.float).flatten().tolist()
+        dtype=float).flatten().tolist()
 
   def add_instance_mask_matrices_feature(
       self,
       instance_mask_matrices: np.ndarray,
       feature_prefix: Optional[str] = None) -> 'TfExampleBuilder':
     """Encodes and adds instance mask features to the example.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/tf_example_builder_test.py` & `tf-models-no-deps-2.16.0/official/vision/data/tf_example_builder_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,38 +11,37 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for tf_example_builder."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.vision.data import fake_feature_generator
 from official.vision.data import image_utils
 from official.vision.data import tf_example_builder
 
 
 class TfExampleBuilderTest(tf.test.TestCase, parameterized.TestCase):
 
-  @parameterized.named_parameters(
-      ('RGB_PNG', 128, 64, 3, 'PNG', '15125990', 3),
-      ('RGB_RAW', 128, 128, 3, 'RAW', '5607919', 0),
-      ('RGB_JPEG', 64, 128, 3, 'JPEG', '3107796', [2, 5]))
+  @parameterized.named_parameters(('RGB_PNG', 128, 64, 3, 'PNG', 3),
+                                  ('RGB_RAW', 128, 128, 3, 'RAW', 0),
+                                  ('RGB_JPEG', 64, 128, 3, 'JPEG', [2, 5]))
   def test_add_image_matrix_feature_success(self, height, width, num_channels,
-                                            image_format, hashed_image, label):
+                                            image_format, label):
     # Prepare test data.
     image_np = fake_feature_generator.generate_image_np(height, width,
                                                         num_channels)
     expected_image_bytes = image_utils.encode_image(image_np, image_format)
-    hashed_image = bytes(hashed_image, 'ascii')
+    hashed_image = bytes('10242048', 'ascii')
 
     # Run code logic.
     example_builder = tf_example_builder.TfExampleBuilder()
-    example_builder.add_image_matrix_feature(image_np, image_format,
-                                             label=label)
+    example_builder.add_image_matrix_feature(
+        image_np, image_format, hashed_image, label=label)
     example = example_builder.example
 
     # Verify outputs.
     # Prefer to use string literal for feature keys to directly display the
     # structure of the expected tf.train.Example.
     if isinstance(label, int):
       expected_labels = [label]
@@ -86,19 +85,23 @@
     num_channels = 1
     image_format = 'PNG'
     feature_prefix = 'depth'
     label = 8
     image_np = fake_feature_generator.generate_image_np(height, width,
                                                         num_channels)
     expected_image_bytes = image_utils.encode_image(image_np, image_format)
-    hashed_image = bytes('11981843', 'ascii')
+    hashed_image = bytes('10242048', 'ascii')
 
     example_builder = tf_example_builder.TfExampleBuilder()
     example_builder.add_image_matrix_feature(
-        image_np, image_format, feature_prefix=feature_prefix, label=label)
+        image_np,
+        image_format,
+        hashed_image,
+        feature_prefix=feature_prefix,
+        label=label)
     example = example_builder.example
 
     self.assertProtoEquals(
         tf.train.Example(
             features=tf.train.Features(
                 feature={
                     'depth/image/encoded':
@@ -129,20 +132,16 @@
                 })), example)
 
   def test_add_encoded_raw_image_feature_success(self):
     height = 128
     width = 128
     num_channels = 3
     image_format = 'RAW'
-    image_bytes = tf.bfloat16.as_numpy_dtype
-    image_np = fake_feature_generator.generate_image_np(height, width,
-                                                        num_channels)
-    image_np = image_np.astype(image_bytes)
-    expected_image_bytes = image_utils.encode_image(image_np, image_format)
-    hashed_image = bytes('3572575', 'ascii')
+    expected_image_bytes = bytes('image', 'ascii')
+    hashed_image = bytes('16188651', 'ascii')
 
     example_builder = tf_example_builder.TfExampleBuilder()
     example_builder.add_encoded_image_feature(expected_image_bytes, 'RAW',
                                               height, width, num_channels)
     example = example_builder.example
 
     self.assertProtoEquals(
@@ -180,54 +179,50 @@
     expected_image_bytes = image_utils.encode_image(image_np, image_format)
 
     example_builder = tf_example_builder.TfExampleBuilder()
     with self.assertRaises(ValueError):
       example_builder.add_encoded_image_feature(expected_image_bytes,
                                                 image_format)
 
-  @parameterized.parameters(
-      (True, True, True, True, True, True),
-      (False, False, False, False, False, False),
-      (True, False, False, False, False, False),
-      (False, True, False, False, False, False),
-      (False, False, True, False, False, False),
-      (False, False, False, True, False, False),
-      (False, False, False, False, True, False),
-      (False, False, False, False, False, True),
-  )
+  @parameterized.product(
+      miss_image_format=(True, False),
+      miss_height=(True, False),
+      miss_width=(True, False),
+      miss_num_channels=(True, False),
+      miss_label=(True, False))
   def test_add_encoded_image_feature_success(self, miss_image_format,
                                              miss_height, miss_width,
                                              miss_num_channels,
-                                             miss_image_source_id,
                                              miss_label):
     height = 64
     width = 64
     num_channels = 3
     image_format = 'PNG'
     image_np = fake_feature_generator.generate_image_np(height, width,
                                                         num_channels)
     image_bytes = image_utils.encode_image(image_np, image_format)
-    hashed_image = bytes('2968688', 'ascii')
+    # We don't test on image_source_id because encoding process becomes
+    # non-deterministic.
+    hashed_image = bytes('10242048', 'ascii')
     label = 5
 
     image_format = None if miss_image_format else image_format
     height = None if miss_height else height
     width = None if miss_width else width
     num_channels = None if miss_num_channels else num_channels
-    image_source_id = None if miss_image_source_id else hashed_image
     label = None if miss_label else label
 
     example_builder = tf_example_builder.TfExampleBuilder()
     example_builder.add_encoded_image_feature(
         image_bytes,
         image_format=image_format,
         height=height,
         width=width,
         num_channels=num_channels,
-        image_source_id=image_source_id,
+        image_source_id=hashed_image,
         label=label)
     example = example_builder.example
 
     expected_features = {
         'image/encoded':
             tf.train.Feature(
                 bytes_list=tf.train.BytesList(value=[image_bytes])),
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/tf_example_feature_key.py` & `tf-models-no-deps-2.16.0/official/vision/data/tf_example_feature_key.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/data/tfrecord_lib.py` & `tf-models-no-deps-2.16.0/official/vision/data/tfrecord_lib.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,15 @@
 import hashlib
 import io
 import itertools
 
 from absl import logging
 import numpy as np
 from PIL import Image
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 import multiprocessing as mp
 
 
 LOG_EVERY = 100
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/waste_identification_ml/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/classification_input.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/classification_input.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Classification decoder and parser."""
 from typing import Any, Dict, List, Optional, Tuple
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.configs import common
 from official.vision.dataloaders import decoder
 from official.vision.dataloaders import parser
 from official.vision.ops import augment
 from official.vision.ops import preprocess_ops
 
@@ -67,22 +67,27 @@
                aug_rand_hflip: bool = True,
                aug_crop: Optional[bool] = True,
                aug_type: Optional[common.Augmentation] = None,
                color_jitter: float = 0.,
                random_erasing: Optional[common.RandomErasing] = None,
                is_multilabel: bool = False,
                dtype: str = 'float32',
-               crop_area_range: Optional[Tuple[float, float]] = (0.08, 1.0)):
+               crop_area_range: Optional[Tuple[float, float]] = (0.08, 1.0),
+               center_crop_fraction: Optional[
+                   float] = preprocess_ops.CENTER_CROP_FRACTION,
+               tf_resize_method: str = 'bilinear',
+               three_augment: bool = False):
     """Initializes parameters for parsing annotations in the dataset.
 
     Args:
       output_size: `Tensor` or `list` for [height, width] of output image. The
         output_size should be divided by the largest feature stride 2^max_level.
       num_classes: `float`, number of classes.
-      image_field_key: `str`, the key name to encoded image in tf.Example.
+      image_field_key: `str`, the key name to encoded image or decoded image
+        matrix in tf.Example.
       label_field_key: `str`, the key name to label in tf.Example.
       decode_jpeg_only: `bool`, if True, only JPEG format is decoded, this is
         faster than decoding other types. Default is True.
       aug_rand_hflip: `bool`, if True, augment training with random horizontal
         flip.
       aug_crop: `bool`, if True, perform random cropping during training and
         center crop during validation.
@@ -96,14 +101,18 @@
       is_multilabel: A `bool`, whether or not each example has multiple labels.
       dtype: `str`, cast output image in dtype. It can be 'float32', 'float16',
         or 'bfloat16'.
       crop_area_range: An optional `tuple` of (min_area, max_area) for image
         random crop function to constraint crop operation. The cropped areas
         of the image must contain a fraction of the input image within this
         range. The default area range is (0.08, 1.0).
+      https://arxiv.org/abs/2204.07118.
+      center_crop_fraction: center_crop_fraction.
+      tf_resize_method: A `str`, interpolation method for resizing image.
+      three_augment: A bool, whether to apply three augmentations.
     """
     self._output_size = output_size
     self._aug_rand_hflip = aug_rand_hflip
     self._aug_crop = aug_crop
     self._num_classes = num_classes
     self._image_field_key = image_field_key
     if dtype == 'float32':
@@ -146,14 +155,17 @@
           max_count=random_erasing.max_count,
           trials=random_erasing.trials)
     else:
       self._random_erasing = None
     self._is_multilabel = is_multilabel
     self._decode_jpeg_only = decode_jpeg_only
     self._crop_area_range = crop_area_range
+    self._center_crop_fraction = center_crop_fraction
+    self._tf_resize_method = tf_resize_method
+    self._three_augment = three_augment
 
   def _parse_train_data(self, decoded_tensors):
     """Parses data for training."""
     image = self._parse_train_image(decoded_tensors)
     label = tf.cast(decoded_tensors[self._label_field_key], dtype=tf.int32)
     if self._is_multilabel:
       if isinstance(label, tf.sparse.SparseTensor):
@@ -170,29 +182,40 @@
         label = tf.sparse.to_dense(label)
       label = tf.reduce_sum(tf.one_hot(label, self._num_classes), axis=0)
     return image, label
 
   def _parse_train_image(self, decoded_tensors):
     """Parses image data for training."""
     image_bytes = decoded_tensors[self._image_field_key]
-
-    if self._decode_jpeg_only and self._aug_crop:
+    require_decoding = (
+        not tf.is_tensor(image_bytes) or image_bytes.dtype == tf.dtypes.string
+    )
+
+    if (
+        require_decoding
+        and self._decode_jpeg_only
+        and self._aug_crop
+    ):
       image_shape = tf.image.extract_jpeg_shape(image_bytes)
 
       # Crops image.
       cropped_image = preprocess_ops.random_crop_image_v2(
           image_bytes, image_shape, area_range=self._crop_area_range)
       image = tf.cond(
           tf.reduce_all(tf.equal(tf.shape(cropped_image), image_shape)),
           lambda: preprocess_ops.center_crop_image_v2(image_bytes, image_shape),
           lambda: cropped_image)
     else:
-      # Decodes image.
-      image = tf.io.decode_image(image_bytes, channels=3)
-      image.set_shape([None, None, 3])
+      if require_decoding:
+        # Decodes image.
+        image = tf.io.decode_image(image_bytes, channels=3)
+        image.set_shape([None, None, 3])
+      else:
+        # Already decoded image matrix
+        image = image_bytes
 
       # Crops image.
       if self._aug_crop:
         cropped_image = preprocess_ops.random_crop_image(
             image, area_range=self._crop_area_range)
 
         image = tf.cond(
@@ -207,21 +230,28 @@
     if self._color_jitter > 0:
       image = preprocess_ops.color_jitter(image, self._color_jitter,
                                           self._color_jitter,
                                           self._color_jitter)
 
     # Resizes image.
     image = tf.image.resize(
-        image, self._output_size, method=tf.image.ResizeMethod.BILINEAR)
+        image, self._output_size, method=self._tf_resize_method)
     image.set_shape([self._output_size[0], self._output_size[1], 3])
 
     # Apply autoaug or randaug.
     if self._augmenter is not None:
       image = self._augmenter.distort(image)
 
+    # Three augmentation
+    if self._three_augment:
+      image = augment.AutoAugment(
+          augmentation_name='deit3_three_augment',
+          translate_const=20,
+      ).distort(image)
+
     # Normalizes image with mean and std pixel values.
     image = preprocess_ops.normalize_image(
         image, offset=preprocess_ops.MEAN_RGB, scale=preprocess_ops.STDDEV_RGB)
 
     # Random erasing after the image has been normalized
     if self._random_erasing is not None:
       image = self._random_erasing.distort(image)
@@ -230,31 +260,44 @@
     image = tf.image.convert_image_dtype(image, self._dtype)
 
     return image
 
   def _parse_eval_image(self, decoded_tensors):
     """Parses image data for evaluation."""
     image_bytes = decoded_tensors[self._image_field_key]
-
-    if self._decode_jpeg_only and self._aug_crop:
+    require_decoding = (
+        not tf.is_tensor(image_bytes) or image_bytes.dtype == tf.dtypes.string
+    )
+
+    if (
+        require_decoding
+        and self._decode_jpeg_only
+        and self._aug_crop
+    ):
       image_shape = tf.image.extract_jpeg_shape(image_bytes)
 
       # Center crops.
-      image = preprocess_ops.center_crop_image_v2(image_bytes, image_shape)
+      image = preprocess_ops.center_crop_image_v2(
+          image_bytes, image_shape, self._center_crop_fraction)
     else:
-      # Decodes image.
-      image = tf.io.decode_image(image_bytes, channels=3)
-      image.set_shape([None, None, 3])
+      if require_decoding:
+        # Decodes image.
+        image = tf.io.decode_image(image_bytes, channels=3)
+        image.set_shape([None, None, 3])
+      else:
+        # Already decoded image matrix
+        image = image_bytes
 
       # Center crops.
       if self._aug_crop:
-        image = preprocess_ops.center_crop_image(image)
+        image = preprocess_ops.center_crop_image(
+            image, self._center_crop_fraction)
 
     image = tf.image.resize(
-        image, self._output_size, method=tf.image.ResizeMethod.BILINEAR)
+        image, self._output_size, method=self._tf_resize_method)
     image.set_shape([self._output_size[0], self._output_size[1], 3])
 
     # Normalizes image with mean and std pixel values.
     image = preprocess_ops.normalize_image(
         image, offset=preprocess_ops.MEAN_RGB, scale=preprocess_ops.STDDEV_RGB)
 
     # Convert image to self._dtype.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/decoder.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/decoder.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,19 +13,17 @@
 # limitations under the License.
 
 """The generic decoder interface."""
 
 import abc
 
 
-class Decoder(object):
+class Decoder(metaclass=abc.ABCMeta):
   """Decodes the raw data into tensors."""
 
-  __metaclass__ = abc.ABCMeta
-
   @abc.abstractmethod
   def decode(self, serialized_example):
     """Decodes the serialized example into tensors.
 
     Args:
       serialized_example: a serialized string tensor that encodes the data.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/input_reader.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/input_reader.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,61 +10,130 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Dataset reader for vision model garden."""
 
-from typing import Any, Callable, Optional, Tuple
+from typing import Any, Callable, Mapping, Optional, Tuple, Union
 
-import tensorflow as tf
+from absl import logging
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.core import input_reader
 
 
+InputReader = input_reader.InputReader
+
+
+def build_weighted_sampling_combine_fn(
+    weights: Mapping[Any, Any], stop_on_empty_dataset=True
+) -> Callable[[tf.data.Dataset], tf.data.Dataset]:
+  """Builds a combine_fn using weighted sampling."""
+
+  def combine_fn(datasets: Mapping[Any, tf.data.Dataset]) -> tf.data.Dataset:
+    """Combines multiple datasets using weighted sampling."""
+    ds = []
+    ws = []
+    for k, dataset in datasets.items():
+      ds.append(dataset)
+      ws.append(weights[k])
+    return tf.data.Dataset.sample_from_datasets(
+        ds, ws, stop_on_empty_dataset=stop_on_empty_dataset)
+
+  return combine_fn
+
+
+def create_combine_fn(
+    params: cfg.DataConfig
+) -> Union[None, Callable[[tf.data.Dataset], tf.data.Dataset]]:
+  """Creates and returns a combine_fn for dataset mixing."""
+  if (
+      hasattr(params, 'stop_on_empty_dataset')
+      and params.stop_on_empty_dataset is not None
+  ):
+    stop_on_empty_dataset = params.stop_on_empty_dataset
+  else:
+    stop_on_empty_dataset = True
+
+  if params.weights:
+    # Combine multiple datasets using weighted sampling.
+    if (not isinstance(params.input_path, cfg.base_config.Config) or
+        not isinstance(params.weights, cfg.base_config.Config)):
+      raise ValueError(
+          'input_path and weights must both be a Config to use weighted '
+          'sampling.')
+    input_paths = params.input_path.as_dict()
+    weights = params.weights.as_dict()
+    if len(input_paths) != len(weights):
+      raise ValueError(
+          'The number of input_path and weights must be the same, but got %d '
+          'input_paths and %d weights.' % (len(input_paths), len(weights)))
+
+    for k in input_paths.keys():
+      if k not in weights:
+        raise ValueError(
+            'input_path key \'%s\' does not have a corresponding weight.' % k)
+
+    return build_weighted_sampling_combine_fn(weights, stop_on_empty_dataset)
+  return None
+
+
 def calculate_batch_sizes(total_batch_size: int,
-                          pseudo_label_ratio: float) -> Tuple[int, int]:
+                          pseudo_label_ratio: float,
+                          pseudo_label_batch_size: int = 0) -> Tuple[int, int]:
   """Calculates labeled and pseudo-labeled dataset batch sizes.
 
   Returns (labeled_batch_size, pseudo_labeled_batch_size) given a
   total batch size and pseudo-label data ratio.
 
   Args:
    total_batch_size: The total batch size for all data.
-   pseudo_label_ratio: A non-negative float ratio of pseudo-labeled
-     to labeled data in a batch.
+   pseudo_label_ratio: A float ratio of pseudo-labeled to labeled data in a
+     batch. If it is negative, use `pseudo_label_batch_size` instead.
+   pseudo_label_batch_size: The batch size of pseudo-labeled data. It is ignored
+     if `pseudo_label_ratio` is valid. If not, it will be used and it cannot be
+     larger than total global batch size or less than 0 if pseudo_label_ratio is
+     also less than 0.
 
   Returns:
     (labeled_batch_size, pseudo_labeled_batch_size) as ints.
 
   Raises:
-    ValueError: If total_batch_size is negative.
-    ValueError: If pseudo_label_ratio is negative.
+    ValueError: If total_batch_size is negative, or both If pseudo_label_ratio
+      is negative and pseudo-label global_batch_size is negative or larger than
+      total batch size.
   """
   if total_batch_size < 0:
     raise ValueError('Invalid total_batch_size: {}'.format(total_batch_size))
-  if pseudo_label_ratio < 0.0:
-    raise ValueError(
-        'Invalid pseudo_label_ratio: {}'.format(pseudo_label_ratio))
-
-  ratio_factor = pseudo_label_ratio / (1.0 + pseudo_label_ratio)
-  pseudo_labeled_batch_size = int(round(total_batch_size * ratio_factor))
-  labeled_batch_size = total_batch_size - pseudo_labeled_batch_size
-  return labeled_batch_size, pseudo_labeled_batch_size
+  if pseudo_label_ratio >= 0.0:
+    ratio_factor = pseudo_label_ratio / (1.0 + pseudo_label_ratio)
+    pseudo_label_batch_size = int(total_batch_size * ratio_factor)
+    label_batch_size = total_batch_size - pseudo_label_batch_size
+  else:
+    if pseudo_label_batch_size > total_batch_size or pseudo_label_batch_size < 0:
+      raise ValueError(
+          'The batch size of pseudo-label dataset should not be larger than '
+          'total global batch size.')
+    logging.info('data_ratio for pseudo-label dataset is less than 0. '
+                 'Use global_batch_size from pseudo_label data config instead.')
+    label_batch_size = total_batch_size - pseudo_label_batch_size
+  return label_batch_size, pseudo_label_batch_size
 
 
 class CombinationDatasetInputReader(input_reader.InputReader):
   """Combination dataset input reader."""
 
   def __init__(self,
                params: cfg.DataConfig,
                dataset_fn=tf.data.TFRecordDataset,
                pseudo_label_dataset_fn=tf.data.TFRecordDataset,
                decoder_fn: Optional[Callable[..., Any]] = None,
+               combine_fn: Optional[Callable[..., Any]] = None,
                sample_fn: Optional[Callable[..., Any]] = None,
                parser_fn: Optional[Callable[..., Any]] = None,
                transform_and_batch_fn: Optional[Callable[
                    [tf.data.Dataset, Optional[tf.distribute.InputContext]],
                    tf.data.Dataset]] = None,
                postprocess_fn: Optional[Callable[..., Any]] = None):
     """Initializes an CombinationDatasetInputReader instance.
@@ -79,14 +148,17 @@
       params: A config_definitions.DataConfig object.
       dataset_fn: A `tf.data.Dataset` that consumes the input files. For
         example, it can be `tf.data.TFRecordDataset`.
       pseudo_label_dataset_fn: A `tf.data.Dataset` that consumes the input
         files. For example, it can be `tf.data.TFRecordDataset`.
       decoder_fn: An optional `callable` that takes the serialized data string
         and decodes them into the raw tensor dictionary.
+      combine_fn: An optional `callable` that takes a dictionarty of
+        `tf.data.Dataset` objects as input and outputs a combined dataset. It
+        will be executed after the decoder_fn and before the sample_fn.
       sample_fn: An optional `callable` that takes a `tf.data.Dataset` object as
         input and outputs the transformed dataset. It performs sampling on the
         decoded raw tensors dict before the parser_fn.
       parser_fn: An optional `callable` that takes the decoded raw tensors dict
         and parse them into a dictionary of tensors that can be consumed by the
         model. It will be executed after decoder_fn.
       transform_and_batch_fn: An optional `callable` that takes a
@@ -97,65 +169,66 @@
         batch size.
       postprocess_fn: A optional `callable` that processes batched tensors. It
         will be executed after batching.
 
     Raises:
       ValueError: If drop_remainder is False.
     """
-    super().__init__(params=params,
-                     dataset_fn=dataset_fn,
-                     decoder_fn=decoder_fn,
-                     sample_fn=sample_fn,
-                     parser_fn=parser_fn,
-                     transform_and_batch_fn=transform_and_batch_fn,
-                     postprocess_fn=postprocess_fn)
+    super().__init__(
+        params=params,
+        dataset_fn=dataset_fn,
+        decoder_fn=decoder_fn,
+        combine_fn=combine_fn,
+        sample_fn=sample_fn,
+        parser_fn=parser_fn,
+        transform_and_batch_fn=transform_and_batch_fn,
+        postprocess_fn=postprocess_fn)
 
     self._pseudo_label_file_pattern = params.pseudo_label_data.input_path
     self._pseudo_label_dataset_fn = pseudo_label_dataset_fn
     self._pseudo_label_data_ratio = params.pseudo_label_data.data_ratio
+    self._pseudo_label_batch_size = params.pseudo_label_data.global_batch_size
     self._pseudo_label_matched_files = input_reader.match_files(
         self._pseudo_label_file_pattern)
     if not self._drop_remainder:
       raise ValueError(
           'Must use drop_remainder=True with CombinationDatasetInputReader')
 
   def read(
       self,
       input_context: Optional[tf.distribute.InputContext] = None
   ) -> tf.data.Dataset:
     """Generates a tf.data.Dataset object."""
 
     labeled_batch_size, pl_batch_size = calculate_batch_sizes(
-        self._global_batch_size, self._pseudo_label_data_ratio)
+        self._global_batch_size, self._pseudo_label_data_ratio,
+        self._pseudo_label_batch_size)
 
     if not labeled_batch_size and pl_batch_size:
       raise ValueError(
           'Invalid batch_size: {} and pseudo_label_data_ratio: {}, '
           'resulting in a 0 batch size for one of the datasets.'.format(
               self._global_batch_size, self._pseudo_label_data_ratio))
 
     def _read_decode_and_parse_dataset(matched_files, dataset_fn, batch_size,
-                                       input_context, tfds_builder):
-      dataset = self._read_data_source(matched_files, dataset_fn, input_context,
-                                       tfds_builder)
+                                       input_context):
+      dataset = self._read_data_source(matched_files, dataset_fn, input_context)
       return self._decode_and_parse_dataset(dataset, batch_size, input_context)
 
     labeled_dataset = _read_decode_and_parse_dataset(
         matched_files=self._matched_files,
         dataset_fn=self._dataset_fn,
         batch_size=labeled_batch_size,
-        input_context=input_context,
-        tfds_builder=self._tfds_builder)
+        input_context=input_context)
 
     pseudo_labeled_dataset = _read_decode_and_parse_dataset(
         matched_files=self._pseudo_label_matched_files,
         dataset_fn=self._pseudo_label_dataset_fn,
         batch_size=pl_batch_size,
-        input_context=input_context,
-        tfds_builder=False)
+        input_context=input_context)
 
     def concat_fn(d1, d2):
       return tf.nest.map_structure(
           lambda x1, x2: tf.concat([x1, x2], axis=0), d1, d2)
 
     dataset_concat = tf.data.Dataset.zip(
         (labeled_dataset, pseudo_labeled_dataset))
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/input_reader_factory.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/input_reader_factory.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/maskrcnn_input.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/maskrcnn_input.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Data parser and processing for Mask R-CNN."""
 
 from typing import Optional
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.configs import common
 from official.vision.dataloaders import parser
 from official.vision.dataloaders import utils
 from official.vision.ops import anchor
 from official.vision.ops import augment
 from official.vision.ops import box_ops
@@ -39,57 +39,63 @@
                aspect_ratios,
                anchor_size,
                rpn_match_threshold=0.7,
                rpn_unmatched_threshold=0.3,
                rpn_batch_size_per_im=256,
                rpn_fg_fraction=0.5,
                aug_rand_hflip=False,
+               aug_rand_vflip=False,
                aug_scale_min=1.0,
                aug_scale_max=1.0,
                aug_type: Optional[common.Augmentation] = None,
                skip_crowd_during_training=True,
                max_num_instances=100,
                include_mask=False,
+               outer_boxes_scale=1.0,
                mask_crop_size=112,
                dtype='float32'):
     """Initializes parameters for parsing annotations in the dataset.
 
     Args:
       output_size: `Tensor` or `list` for [height, width] of output image. The
         output_size should be divided by the largest feature stride 2^max_level.
       min_level: `int` number of minimum level of the output feature pyramid.
       max_level: `int` number of maximum level of the output feature pyramid.
       num_scales: `int` number representing intermediate scales added
         on each level. For instances, num_scales=2 adds one additional
         intermediate anchor scales [2^0, 2^0.5] on each level.
-      aspect_ratios: `list` of float numbers representing the aspect raito
+      aspect_ratios: `list` of float numbers representing the aspect ratio
         anchors added on each level. The number indicates the ratio of width to
         height. For instances, aspect_ratios=[1.0, 2.0, 0.5] adds three anchors
         on each scale level.
       anchor_size: `float` number representing the scale of size of the base
         anchor to the feature stride 2^level.
       rpn_match_threshold:
       rpn_unmatched_threshold:
       rpn_batch_size_per_im:
       rpn_fg_fraction:
-      aug_rand_hflip: `bool`, if True, augment training with random
-        horizontal flip.
+      aug_rand_hflip: `bool`, if True, augment training with random horizontal
+        flip.
+      aug_rand_vflip: `bool`, if True, augment training with random vertical
+        flip.
       aug_scale_min: `float`, the minimum scale applied to `output_size` for
         data augmentation during training.
       aug_scale_max: `float`, the maximum scale applied to `output_size` for
         data augmentation during training.
       aug_type: An optional Augmentation object with params for AutoAugment.
         The AutoAug policy should not use rotation/translation/shear.
         Only in-place augmentations can be used.
       skip_crowd_during_training: `bool`, if True, skip annotations labeled with
         `is_crowd` equals to 1.
       max_num_instances: `int` number of maximum number of instances in an
-        image. The groundtruth data will be padded to `max_num_instances`.
-      include_mask: a bool to indicate whether parse mask groundtruth.
-      mask_crop_size: the size which groundtruth mask is cropped to.
+        image. The ground-truth data will be padded to `max_num_instances`.
+      include_mask: a bool to indicate whether parse mask ground-truth.
+      outer_boxes_scale: a float to scale up the bounding boxes to generate
+        more inclusive masks. The scale is expected to be >=1.0.
+      mask_crop_size: the size which ground-truth mask is cropped to.
       dtype: `str`, data type. One of {`bfloat16`, `float32`, `float16`}.
     """
 
     self._max_num_instances = max_num_instances
     self._skip_crowd_during_training = skip_crowd_during_training
 
     # Anchor.
@@ -104,14 +110,15 @@
     self._rpn_match_threshold = rpn_match_threshold
     self._rpn_unmatched_threshold = rpn_unmatched_threshold
     self._rpn_batch_size_per_im = rpn_batch_size_per_im
     self._rpn_fg_fraction = rpn_fg_fraction
 
     # Data augmentation.
     self._aug_rand_hflip = aug_rand_hflip
+    self._aug_rand_vflip = aug_rand_vflip
     self._aug_scale_min = aug_scale_min
     self._aug_scale_max = aug_scale_max
 
     if aug_type and aug_type.type:
       if aug_type.type == 'autoaug':
         self._augmenter = augment.AutoAugment(
             augmentation_name=aug_type.autoaug.augmentation_name,
@@ -129,14 +136,15 @@
         raise ValueError('Augmentation policy {} not supported.'.format(
             aug_type.type))
     else:
       self._augmenter = None
 
     # Mask.
     self._include_mask = include_mask
+    self._outer_boxes_scale = outer_boxes_scale
     self._mask_crop_size = mask_crop_size
 
     # Image output dtype.
     self._dtype = dtype
 
   def _parse_train_data(self, data):
     """Parses data for training.
@@ -160,19 +168,19 @@
           shape [height_l, width_l, anchors_per_location]. The height_l and
           width_l represent the dimension of class logits at l-th level.
         rpn_box_targets: ordered dictionary with keys
           [min_level, min_level+1, ..., max_level]. The values are tensor with
           shape [height_l, width_l, anchors_per_location * 4]. The height_l and
           width_l represent the dimension of bounding box regression output at
           l-th level.
-        gt_boxes: Groundtruth bounding box annotations. The box is represented
+        gt_boxes: Ground-truth bounding box annotations. The box is represented
            in [y1, x1, y2, x2] format. The coordinates are w.r.t the scaled
            image that is fed to the network. The tennsor is padded with -1 to
            the fixed dimension [self._max_num_instances, 4].
-        gt_classes: Groundtruth classes annotations. The tennsor is padded
+        gt_classes: Ground-truth classes annotations. The tennsor is padded
           with -1 to the fixed dimension [self._max_num_instances].
         gt_masks: groundtrugh masks cropped by the bounding box and
           resized to a fixed size determined by mask_crop_size.
     """
     classes = data['groundtruth_classes']
     boxes = data['groundtruth_boxes']
     if self._include_mask:
@@ -199,21 +207,26 @@
 
     image_shape = tf.shape(image)[0:2]
 
     # Normalizes image with mean and std pixel values.
     image = preprocess_ops.normalize_image(image)
 
     # Flips image randomly during training.
-    if self._aug_rand_hflip:
-      if self._include_mask:
-        image, boxes, masks = preprocess_ops.random_horizontal_flip(
-            image, boxes, masks)
-      else:
-        image, boxes, _ = preprocess_ops.random_horizontal_flip(
-            image, boxes)
+    image, boxes, masks = preprocess_ops.random_horizontal_flip(
+        image,
+        boxes,
+        masks=None if not self._include_mask else masks,
+        prob=tf.where(self._aug_rand_hflip, 0.5, 0.0),
+    )
+    image, boxes, masks = preprocess_ops.random_vertical_flip(
+        image,
+        boxes,
+        masks=None if not self._include_mask else masks,
+        prob=tf.where(self._aug_rand_vflip, 0.5, 0.0),
+    )
 
     # Converts boxes from normalized coordinates to pixel coordinates.
     # Now the coordinates of boxes are w.r.t. the original image.
     boxes = box_ops.denormalize_boxes(boxes, image_shape)
 
     # Resizes and crops image.
     image, image_info = preprocess_ops.resize_and_crop_image(
@@ -228,22 +241,25 @@
     # Resizes and crops boxes.
     # Now the coordinates of boxes are w.r.t the scaled image.
     image_scale = image_info[2, :]
     offset = image_info[3, :]
     boxes = preprocess_ops.resize_and_crop_boxes(
         boxes, image_scale, image_info[1, :], offset)
 
-    # Filters out ground truth boxes that are all zeros.
+    # Filters out ground-truth boxes that are all zeros.
     indices = box_ops.get_non_empty_box_indices(boxes)
     boxes = tf.gather(boxes, indices)
     classes = tf.gather(classes, indices)
     if self._include_mask:
+      outer_boxes = box_ops.compute_outer_boxes(boxes, image_info[1, :],
+                                                self._outer_boxes_scale)
       masks = tf.gather(masks, indices)
       # Transfer boxes to the original image space and do normalization.
-      cropped_boxes = boxes + tf.tile(tf.expand_dims(offset, axis=0), [1, 2])
+      cropped_boxes = outer_boxes + tf.tile(
+          tf.expand_dims(offset, axis=0), [1, 2])
       cropped_boxes /= tf.tile(tf.expand_dims(image_scale, axis=0), [1, 2])
       cropped_boxes = box_ops.normalize_boxes(cropped_boxes, image_shape)
       num_masks = tf.shape(masks)[0]
       masks = tf.image.crop_and_resize(
           tf.expand_dims(masks, axis=-1),
           cropped_boxes,
           box_indices=tf.range(num_masks, dtype=tf.int32),
@@ -268,54 +284,54 @@
         self._rpn_fg_fraction)
     rpn_score_targets, rpn_box_targets = anchor_labeler.label_anchors(
         anchor_boxes, boxes,
         tf.cast(tf.expand_dims(classes, axis=-1), dtype=tf.float32))
 
     # Casts input image to self._dtype
     image = tf.cast(image, dtype=self._dtype)
+    boxes = preprocess_ops.clip_or_pad_to_fixed_size(
+        boxes, self._max_num_instances, -1)
+    classes = preprocess_ops.clip_or_pad_to_fixed_size(
+        classes, self._max_num_instances, -1)
 
     # Packs labels for model_fn outputs.
     labels = {
-        'anchor_boxes':
-            anchor_boxes,
-        'image_info':
-            image_info,
-        'rpn_score_targets':
-            rpn_score_targets,
-        'rpn_box_targets':
-            rpn_box_targets,
-        'gt_boxes':
-            preprocess_ops.clip_or_pad_to_fixed_size(boxes,
-                                                     self._max_num_instances,
-                                                     -1),
-        'gt_classes':
-            preprocess_ops.clip_or_pad_to_fixed_size(classes,
-                                                     self._max_num_instances,
-                                                     -1),
+        'anchor_boxes': anchor_boxes,
+        'image_info': image_info,
+        'rpn_score_targets': rpn_score_targets,
+        'rpn_box_targets': rpn_box_targets,
+        'gt_boxes': boxes,
+        'gt_classes': classes,
     }
     if self._include_mask:
-      labels['gt_masks'] = preprocess_ops.clip_or_pad_to_fixed_size(
+      outer_boxes = preprocess_ops.clip_or_pad_to_fixed_size(
+          outer_boxes, self._max_num_instances, -1)
+      masks = preprocess_ops.clip_or_pad_to_fixed_size(
           masks, self._max_num_instances, -1)
+      labels.update({
+          'gt_outer_boxes': outer_boxes,
+          'gt_masks': masks,
+      })
 
     return image, labels
 
   def _parse_eval_data(self, data):
     """Parses data for evaluation.
 
     Args:
       data: the decoded tensor dictionary from TfExampleDecoder.
 
     Returns:
-      A dictionary of {'images': image, 'labels': labels} where
+      A tuple of (image, labels) where
         image: image tensor that is preproessed to have normalized value and
           dimension [output_size[0], output_size[1], 3]
         labels: a dictionary of tensors used for training. The following
           describes {key: value} pairs in the dictionary.
           source_ids: Source image id. Default value -1 if the source id is
-            empty in the groundtruth annotation.
+            empty in the ground-truth annotation.
           image_info: a 2D `Tensor` that encodes the information of the image
             and the applied preprocessing. It is in the format of
             [[original_height, original_width], [scaled_height, scaled_width],
           anchor_boxes: ordered dictionary with keys
             [min_level, min_level+1, ..., max_level]. The values are tensor with
             shape [height_l, width_l, 4] representing anchor boxes at each
             level.
@@ -367,9 +383,23 @@
         'areas': data['groundtruth_area'],
         'is_crowds': tf.cast(data['groundtruth_is_crowd'], tf.int32),
     }
     groundtruths['source_id'] = utils.process_source_id(
         groundtruths['source_id'])
     groundtruths = utils.pad_groundtruths_to_fixed_size(
         groundtruths, self._max_num_instances)
+    if self._include_mask:
+      masks = data['groundtruth_instance_masks']
+      masks = tf.image.crop_and_resize(
+          tf.expand_dims(masks, axis=-1),
+          boxes=data['groundtruth_boxes'],
+          box_indices=tf.range(tf.shape(masks)[0], dtype=tf.int32),
+          crop_size=[self._mask_crop_size, self._mask_crop_size],
+          method='bilinear',
+      )
+      masks = tf.squeeze(masks, axis=-1)
+      groundtruths['masks'] = preprocess_ops.clip_or_pad_to_fixed_size(
+          masks, self._max_num_instances, -1
+      )
+
     labels['groundtruths'] = groundtruths
     return image, labels
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/parser.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/parser.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/retinanet_input.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/retinanet_input.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,21 +10,24 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Data parser and processing for RetinaNet.
 
-Parse image and ground truths in a dataset to training targets and package them
+Parse image and ground-truths in a dataset to training targets and package them
 into (image, labels) tuple for RetinaNet.
 """
 
+from typing import Optional
+
 # Import libraries
+
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.dataloaders import parser
 from official.vision.dataloaders import utils
 from official.vision.ops import anchor
 from official.vision.ops import augment
 from official.vision.ops import box_ops
 from official.vision.ops import preprocess_ops
@@ -38,46 +41,54 @@
                min_level,
                max_level,
                num_scales,
                aspect_ratios,
                anchor_size,
                match_threshold=0.5,
                unmatched_threshold=0.5,
+               box_coder_weights=None,
                aug_type=None,
                aug_rand_hflip=False,
                aug_scale_min=1.0,
                aug_scale_max=1.0,
                use_autoaugment=False,
                autoaugment_policy_name='v0',
                skip_crowd_during_training=True,
                max_num_instances=100,
                dtype='bfloat16',
-               mode=None):
+               resize_first: Optional[bool] = None,
+               mode=None,
+               pad=True,
+               keep_aspect_ratio=True):
     """Initializes parameters for parsing annotations in the dataset.
 
     Args:
       output_size: `Tensor` or `list` for [height, width] of output image. The
         output_size should be divided by the largest feature stride 2^max_level.
       min_level: `int` number of minimum level of the output feature pyramid.
       max_level: `int` number of maximum level of the output feature pyramid.
       num_scales: `int` number representing intermediate scales added on each
         level. For instances, num_scales=2 adds one additional intermediate
         anchor scales [2^0, 2^0.5] on each level.
-      aspect_ratios: `list` of float numbers representing the aspect raito
+      aspect_ratios: `list` of float numbers representing the aspect ratio
         anchors added on each level. The number indicates the ratio of width to
         height. For instances, aspect_ratios=[1.0, 2.0, 0.5] adds three anchors
         on each scale level.
       anchor_size: `float` number representing the scale of size of the base
         anchor to the feature stride 2^level.
       match_threshold: `float` number between 0 and 1 representing the
         lower-bound threshold to assign positive labels for anchors. An anchor
         with a score over the threshold is labeled positive.
       unmatched_threshold: `float` number between 0 and 1 representing the
         upper-bound threshold to assign negative labels for anchors. An anchor
         with a score below the threshold is labeled negative.
+      box_coder_weights: Optional `list` of 4 positive floats to scale y, x, h,
+        and w when encoding box coordinates. If set to None, does not perform
+        scaling. For Faster RCNN, the open-source implementation recommends
+        using [10.0, 10.0, 5.0, 5.0].
       aug_type: An optional Augmentation object to choose from AutoAugment and
         RandAugment.
       aug_rand_hflip: `bool`, if True, augment training with random horizontal
         flip.
       aug_scale_min: `float`, the minimum scale applied to `output_size` for
         data augmentation during training.
       aug_scale_max: `float`, the maximum scale applied to `output_size` for
@@ -87,30 +98,43 @@
       autoaugment_policy_name: `string` that specifies the name of the
         AutoAugment policy that will be used during training.
       skip_crowd_during_training: `bool`, if True, skip annotations labeled with
         `is_crowd` equals to 1.
       max_num_instances: `int` number of maximum number of instances in an
         image. The groundtruth data will be padded to `max_num_instances`.
       dtype: `str`, data type. One of {`bfloat16`, `float32`, `float16`}.
+      resize_first: Optional `bool`, if True, resize the image before the
+        augmentations; computationally more efficient.
       mode: a ModeKeys. Specifies if this is training, evaluation, prediction or
-        prediction with groundtruths in the outputs.
+        prediction with ground-truths in the outputs.
+      pad: A bool indicating whether to pad the input image to make it
+        size a factor of 2**max_level. The padded size will be the smallest
+        rectangle, such that each dimension is the smallest multiple of 
+        2**max_level which is larger than the desired output size. For example,
+        if desired output size = (320, 320) and max_level = 7, the output padded
+        size = (384, 384). This is necessary when using FPN as it assumes each
+        lower feature map is 2x size of its higher neighbor. Without padding,
+        such relationship may be invalidated. The backbone may produce 5x5 and
+        2x2 consecutive feature maps, which does not work with FPN.
+      keep_aspect_ratio: `bool`, if True, keep the aspect ratio when resizing.
     """
     self._mode = mode
     self._max_num_instances = max_num_instances
     self._skip_crowd_during_training = skip_crowd_during_training
 
     # Anchor.
     self._output_size = output_size
     self._min_level = min_level
     self._max_level = max_level
     self._num_scales = num_scales
     self._aspect_ratios = aspect_ratios
     self._anchor_size = anchor_size
     self._match_threshold = match_threshold
     self._unmatched_threshold = unmatched_threshold
+    self._box_coder_weights = box_coder_weights
 
     # Data augmentation.
     self._aug_rand_hflip = aug_rand_hflip
     self._aug_scale_min = aug_scale_min
     self._aug_scale_max = aug_scale_max
 
     # Data augmentation with AutoAugment or RandAugment.
@@ -137,39 +161,87 @@
     # Deprecated. Data Augmentation with AutoAugment.
     self._use_autoaugment = use_autoaugment
     self._autoaugment_policy_name = autoaugment_policy_name
 
     # Data type.
     self._dtype = dtype
 
-  def _parse_train_data(self, data):
+    # Input pipeline optimization.
+    self._resize_first = resize_first
+
+    # Whether to pad image to make its size the smallest factor of 2*max_level.
+    # This is needed when using FPN decoder.
+    self._pad = pad
+
+    self._keep_aspect_ratio = keep_aspect_ratio
+
+  def _resize_and_crop_image_and_boxes(self, image, boxes, pad=True):
+    """Resizes and crops image and boxes, optionally with padding."""
+    # Resizes and crops image.
+    padded_size = None
+    if pad:
+      padded_size = preprocess_ops.compute_padded_size(self._output_size,
+                                                       2**self._max_level)
+    image, image_info = preprocess_ops.resize_and_crop_image(
+        image,
+        self._output_size,
+        padded_size=padded_size,
+        aug_scale_min=self._aug_scale_min,
+        aug_scale_max=self._aug_scale_max,
+        keep_aspect_ratio=self._keep_aspect_ratio,
+    )
+
+    # Resizes and crops boxes.
+    image_scale = image_info[2, :]
+    offset = image_info[3, :]
+    boxes = preprocess_ops.resize_and_crop_boxes(boxes, image_scale,
+                                                 image_info[1, :], offset)
+    return image, boxes, image_info
+
+  def _parse_train_data(self, data, anchor_labeler=None, input_anchor=None):
     """Parses data for training and evaluation."""
     classes = data['groundtruth_classes']
     boxes = data['groundtruth_boxes']
     # If not empty, `attributes` is a dict of (name, ground_truth) pairs.
-    # `ground_gruth` of attributes is assumed in shape [N, attribute_size].
-    # TODO(xianzhi): support parsing attributes weights.
+    # `ground_truth` of attributes is assumed in shape [N, attribute_size].
     attributes = data.get('groundtruth_attributes', {})
     is_crowds = data['groundtruth_is_crowd']
 
     # Skips annotations with `is_crowd` = True.
     if self._skip_crowd_during_training:
-      num_groundtrtuhs = tf.shape(input=classes)[0]
-      with tf.control_dependencies([num_groundtrtuhs, is_crowds]):
+      num_groundtruths = tf.shape(input=classes)[0]
+      with tf.control_dependencies([num_groundtruths, is_crowds]):
         indices = tf.cond(
             pred=tf.greater(tf.size(input=is_crowds), 0),
             true_fn=lambda: tf.where(tf.logical_not(is_crowds))[:, 0],
-            false_fn=lambda: tf.cast(tf.range(num_groundtrtuhs), tf.int64))
+            false_fn=lambda: tf.cast(tf.range(num_groundtruths), tf.int64))
       classes = tf.gather(classes, indices)
       boxes = tf.gather(boxes, indices)
       for k, v in attributes.items():
         attributes[k] = tf.gather(v, indices)
 
     # Gets original image.
     image = data['image']
+    image_size = tf.cast(tf.shape(image)[0:2], tf.float32)
+
+    less_output_pixels = (
+        self._output_size[0] * self._output_size[1]
+    ) < image_size[0] * image_size[1]
+
+    # Resizing first can reduce augmentation computation if the original image
+    # has more pixels than the desired output image.
+    # There might be a smarter threshold to compute less_output_pixels as
+    # we keep the padding to the very end, i.e., a resized image likely has less
+    # pixels than self._output_size[0] * self._output_size[1].
+    resize_first = self._resize_first and less_output_pixels
+    if resize_first:
+      image, boxes, image_info = self._resize_and_crop_image_and_boxes(
+          image, boxes, pad=False
+      )
+      image = tf.cast(image, dtype=tf.uint8)
 
     # Apply autoaug or randaug.
     if self._augmenter is not None:
       image, boxes = self._augmenter.distort_with_boxes(image, boxes)
     image_shape = tf.shape(input=image)[0:2]
 
     # Normalizes image with mean and std pixel values.
@@ -178,46 +250,57 @@
     # Flips image randomly during training.
     if self._aug_rand_hflip:
       image, boxes, _ = preprocess_ops.random_horizontal_flip(image, boxes)
 
     # Converts boxes from normalized coordinates to pixel coordinates.
     boxes = box_ops.denormalize_boxes(boxes, image_shape)
 
-    # Resizes and crops image.
-    image, image_info = preprocess_ops.resize_and_crop_image(
-        image,
-        self._output_size,
-        padded_size=preprocess_ops.compute_padded_size(self._output_size,
-                                                       2**self._max_level),
-        aug_scale_min=self._aug_scale_min,
-        aug_scale_max=self._aug_scale_max)
+    if self._pad:
+      padded_size = preprocess_ops.compute_padded_size(
+          self._output_size, 2**self._max_level
+      )
+    else:
+      padded_size = self._output_size
+
+    if not resize_first:
+      image, boxes, image_info = (
+          self._resize_and_crop_image_and_boxes(image, boxes, pad=self._pad)
+      )
+
+    image = tf.image.pad_to_bounding_box(
+        image, 0, 0, padded_size[0], padded_size[1]
+    )
+    image = tf.ensure_shape(image, padded_size + [3])
+
     image_height, image_width, _ = image.get_shape().as_list()
 
-    # Resizes and crops boxes.
-    image_scale = image_info[2, :]
-    offset = image_info[3, :]
-    boxes = preprocess_ops.resize_and_crop_boxes(boxes, image_scale,
-                                                 image_info[1, :], offset)
-    # Filters out ground truth boxes that are all zeros.
+    # Filters out ground-truth boxes that are all zeros.
     indices = box_ops.get_non_empty_box_indices(boxes)
     boxes = tf.gather(boxes, indices)
     classes = tf.gather(classes, indices)
     for k, v in attributes.items():
       attributes[k] = tf.gather(v, indices)
 
     # Assigns anchors.
-    input_anchor = anchor.build_anchor_generator(
-        min_level=self._min_level,
-        max_level=self._max_level,
-        num_scales=self._num_scales,
-        aspect_ratios=self._aspect_ratios,
-        anchor_size=self._anchor_size)
+    if input_anchor is None:
+      input_anchor = anchor.build_anchor_generator(
+          min_level=self._min_level,
+          max_level=self._max_level,
+          num_scales=self._num_scales,
+          aspect_ratios=self._aspect_ratios,
+          anchor_size=self._anchor_size,
+      )
+
     anchor_boxes = input_anchor(image_size=(image_height, image_width))
-    anchor_labeler = anchor.AnchorLabeler(self._match_threshold,
-                                          self._unmatched_threshold)
+    if anchor_labeler is None:
+      anchor_labeler = anchor.AnchorLabeler(
+          match_threshold=self._match_threshold,
+          unmatched_threshold=self._unmatched_threshold,
+          box_coder_weights=self._box_coder_weights,
+      )
     (cls_targets, box_targets, att_targets, cls_weights,
      box_weights) = anchor_labeler.label_anchors(
          anchor_boxes, boxes, tf.expand_dims(classes, axis=1), attributes)
 
     # Casts input image to desired data type.
     image = tf.cast(image, dtype=self._dtype)
 
@@ -230,74 +313,89 @@
         'box_weights': box_weights,
         'image_info': image_info,
     }
     if att_targets:
       labels['attribute_targets'] = att_targets
     return image, labels
 
-  def _parse_eval_data(self, data):
+  def _parse_eval_data(self, data, anchor_labeler=None, input_anchor=None):
     """Parses data for training and evaluation."""
-    groundtruths = {}
+
     classes = data['groundtruth_classes']
     boxes = data['groundtruth_boxes']
     # If not empty, `attributes` is a dict of (name, ground_truth) pairs.
-    # `ground_gruth` of attributes is assumed in shape [N, attribute_size].
-    # TODO(xianzhi): support parsing attributes weights.
+    # `ground_truth` of attributes is assumed in shape [N, attribute_size].
     attributes = data.get('groundtruth_attributes', {})
 
     # Gets original image and its size.
     image = data['image']
     image_shape = tf.shape(input=image)[0:2]
 
     # Normalizes image with mean and std pixel values.
     image = preprocess_ops.normalize_image(image)
 
     # Converts boxes from normalized coordinates to pixel coordinates.
     boxes = box_ops.denormalize_boxes(boxes, image_shape)
 
     # Resizes and crops image.
+    if self._pad:
+      padded_size = preprocess_ops.compute_padded_size(
+          self._output_size, 2**self._max_level
+      )
+    else:
+      padded_size = self._output_size
+
     image, image_info = preprocess_ops.resize_and_crop_image(
         image,
         self._output_size,
-        padded_size=preprocess_ops.compute_padded_size(self._output_size,
-                                                       2**self._max_level),
+        padded_size=padded_size,
         aug_scale_min=1.0,
-        aug_scale_max=1.0)
+        aug_scale_max=1.0,
+        keep_aspect_ratio=self._keep_aspect_ratio,
+    )
+    image = tf.ensure_shape(image, padded_size + [3])
     image_height, image_width, _ = image.get_shape().as_list()
 
     # Resizes and crops boxes.
     image_scale = image_info[2, :]
     offset = image_info[3, :]
     boxes = preprocess_ops.resize_and_crop_boxes(boxes, image_scale,
                                                  image_info[1, :], offset)
-    # Filters out ground truth boxes that are all zeros.
+    # Filters out ground-truth boxes that are all zeros.
     indices = box_ops.get_non_empty_box_indices(boxes)
     boxes = tf.gather(boxes, indices)
     classes = tf.gather(classes, indices)
     for k, v in attributes.items():
       attributes[k] = tf.gather(v, indices)
 
     # Assigns anchors.
-    input_anchor = anchor.build_anchor_generator(
-        min_level=self._min_level,
-        max_level=self._max_level,
-        num_scales=self._num_scales,
-        aspect_ratios=self._aspect_ratios,
-        anchor_size=self._anchor_size)
+    if input_anchor is None:
+      input_anchor = anchor.build_anchor_generator(
+          min_level=self._min_level,
+          max_level=self._max_level,
+          num_scales=self._num_scales,
+          aspect_ratios=self._aspect_ratios,
+          anchor_size=self._anchor_size,
+      )
+
     anchor_boxes = input_anchor(image_size=(image_height, image_width))
-    anchor_labeler = anchor.AnchorLabeler(self._match_threshold,
-                                          self._unmatched_threshold)
+    if anchor_labeler is None:
+      anchor_labeler = anchor.AnchorLabeler(
+          match_threshold=self._match_threshold,
+          unmatched_threshold=self._unmatched_threshold,
+          box_coder_weights=self._box_coder_weights,
+      )
     (cls_targets, box_targets, att_targets, cls_weights,
      box_weights) = anchor_labeler.label_anchors(
          anchor_boxes, boxes, tf.expand_dims(classes, axis=1), attributes)
 
     # Casts input image to desired data type.
     image = tf.cast(image, dtype=self._dtype)
 
-    # Sets up groundtruth data for evaluation.
+    # Sets up ground-truth data for evaluation.
     groundtruths = {
         'source_id': data['source_id'],
         'height': data['height'],
         'width': data['width'],
         'num_detections': tf.shape(data['groundtruth_classes']),
         'image_info': image_info,
         'boxes': box_ops.denormalize_boxes(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/segmentation_input.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/segmentation_input.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,35 +10,44 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Data parser and processing for segmentation datasets."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
+from official.vision.configs import semantic_segmentation as config_lib
 from official.vision.dataloaders import decoder
 from official.vision.dataloaders import parser
 from official.vision.dataloaders import utils
 from official.vision.ops import preprocess_ops
 
 
 class Decoder(decoder.Decoder):
   """A tf.Example decoder for segmentation task."""
 
-  def __init__(self):
+  def __init__(self,
+               image_feature=config_lib.DenseFeatureConfig(),
+               additional_dense_features=None):
     self._keys_to_features = {
         'image/encoded':
             tf.io.FixedLenFeature((), tf.string, default_value=''),
         'image/height':
             tf.io.FixedLenFeature((), tf.int64, default_value=0),
         'image/width':
             tf.io.FixedLenFeature((), tf.int64, default_value=0),
         'image/segmentation/class/encoded':
+            tf.io.FixedLenFeature((), tf.string, default_value=''),
+        image_feature.feature_name:
             tf.io.FixedLenFeature((), tf.string, default_value='')
     }
+    if additional_dense_features:
+      for feature in additional_dense_features:
+        self._keys_to_features[feature.feature_name] = tf.io.FixedLenFeature(
+            (), tf.string, default_value='')
 
   def decode(self, serialized_example):
     return tf.io.parse_single_example(serialized_example,
                                       self._keys_to_features)
 
 
 class Parser(parser.Parser):
@@ -51,43 +60,50 @@
                gt_is_matting_map=False,
                groundtruth_padded_size=None,
                ignore_label=255,
                aug_rand_hflip=False,
                preserve_aspect_ratio=True,
                aug_scale_min=1.0,
                aug_scale_max=1.0,
-               dtype='float32'):
+               dtype='float32',
+               image_feature=config_lib.DenseFeatureConfig(),
+               additional_dense_features=None):
     """Initializes parameters for parsing annotations in the dataset.
 
     Args:
       output_size: `Tensor` or `list` for [height, width] of output image. The
         output_size should be divided by the largest feature stride 2^max_level.
       crop_size: `Tensor` or `list` for [height, width] of the crop. If
         specified a training crop of size crop_size is returned. This is useful
         for cropping original images during training while evaluating on
         original image sizes.
-      resize_eval_groundtruth: `bool`, if True, eval groundtruth masks are
+      resize_eval_groundtruth: `bool`, if True, eval ground-truth masks are
         resized to output_size.
       gt_is_matting_map: `bool`, if True, the expected mask is in the range
         between 0 and 255. The parser will normalize the value of the mask into
         the range between 0 and 1.
       groundtruth_padded_size: `Tensor` or `list` for [height, width]. When
-        resize_eval_groundtruth is set to False, the groundtruth masks are
+        resize_eval_groundtruth is set to False, the ground-truth masks are
         padded to this size.
       ignore_label: `int` the pixel with ignore label will not used for training
         and evaluation.
       aug_rand_hflip: `bool`, if True, augment training with random horizontal
         flip.
       preserve_aspect_ratio: `bool`, if True, the aspect ratio is preserved,
         otherwise, the image is resized to output_size.
       aug_scale_min: `float`, the minimum scale applied to `output_size` for
         data augmentation during training.
       aug_scale_max: `float`, the maximum scale applied to `output_size` for
         data augmentation during training.
       dtype: `str`, data type. One of {`bfloat16`, `float32`, `float16`}.
+      image_feature: the config for the image input (usually RGB). Defaults to
+        the config for a 3-channel image with key = `image/encoded` and ImageNet
+        dataset mean/stddev.
+      additional_dense_features: `list` of DenseFeatureConfig for additional
+        dense features.
     """
     self._output_size = output_size
     self._crop_size = crop_size
     self._resize_eval_groundtruth = resize_eval_groundtruth
     if (not resize_eval_groundtruth) and (groundtruth_padded_size is None):
       raise ValueError('groundtruth_padded_size ([height, width]) needs to be'
                        'specified when resize_eval_groundtruth is False.')
@@ -100,42 +116,70 @@
     self._aug_rand_hflip = aug_rand_hflip
     self._aug_scale_min = aug_scale_min
     self._aug_scale_max = aug_scale_max
 
     # dtype.
     self._dtype = dtype
 
+    self._image_feature = image_feature
+    self._additional_dense_features = additional_dense_features
+
   def _prepare_image_and_label(self, data):
     """Prepare normalized image and label."""
-    image = tf.io.decode_image(data['image/encoded'], channels=3)
-    label = tf.io.decode_image(
-        data['image/segmentation/class/encoded'], channels=1)
     height = data['image/height']
     width = data['image/width']
-    image = tf.reshape(image, (height, width, 3))
 
+    label = tf.io.decode_image(
+        data['image/segmentation/class/encoded'], channels=1)
     label = tf.reshape(label, (1, height, width))
     label = tf.cast(label, tf.float32)
-    # Normalizes image with mean and std pixel values.
-    image = preprocess_ops.normalize_image(image)
+
+    image = tf.io.decode_image(
+        data[self._image_feature.feature_name],
+        channels=self._image_feature.num_channels,
+        dtype=tf.uint8)
+    image = tf.reshape(image, (height, width, self._image_feature.num_channels))
+    # Normalizes the image feature with mean and std values, which are divided
+    # by 255 because an uint8 image are re-scaled automatically. Images other
+    # than uint8 type will be wrongly normalized.
+    image = preprocess_ops.normalize_image(
+        image, [mean / 255.0 for mean in self._image_feature.mean],
+        [stddev / 255.0 for stddev in self._image_feature.stddev])
+
+    if self._additional_dense_features:
+      input_list = [image]
+      for feature_cfg in self._additional_dense_features:
+        feature = tf.io.decode_image(
+            data[feature_cfg.feature_name],
+            channels=feature_cfg.num_channels,
+            dtype=tf.uint8)
+        feature = tf.reshape(feature, (height, width, feature_cfg.num_channels))
+        feature = preprocess_ops.normalize_image(
+            feature, [mean / 255.0 for mean in feature_cfg.mean],
+            [stddev / 255.0 for stddev in feature_cfg.stddev])
+        input_list.append(feature)
+      concat_input = tf.concat(input_list, axis=2)
+    else:
+      concat_input = image
 
     if not self._preserve_aspect_ratio:
       label = tf.reshape(label, [data['image/height'], data['image/width'], 1])
-      image = tf.image.resize(image, self._output_size, method='bilinear')
+      concat_input = tf.image.resize(
+          concat_input, self._output_size, method='bilinear')
       label = tf.image.resize(label, self._output_size, method='nearest')
       label = tf.reshape(label[:, :, -1], [1] + self._output_size)
 
-    return image, label
+    return concat_input, label
 
   def _parse_train_data(self, data):
     """Parses data for training and evaluation."""
     image, label = self._prepare_image_and_label(data)
 
-    # Normalize the label into the range of 0 and 1 for matting groundtruth.
-    # Note that the input groundtruth labels must be 0 to 255, and do not
+    # Normalize the label into the range of 0 and 1 for matting ground-truth.
+    # Note that the input ground-truth labels must be 0 to 255, and do not
     # contain ignore_label. For gt_is_matting_map case, ignore_label is only
     # used for padding the labels.
     if self._gt_is_matting_map:
       scale = tf.constant(255.0, dtype=tf.float32)
       scale = tf.expand_dims(scale, axis=0)
       scale = tf.expand_dims(scale, axis=0)
       label = tf.cast(label, tf.float32) / scale
@@ -146,15 +190,16 @@
       # If output_size is specified, resize image, and label to desired
       # output_size.
       if self._output_size:
         image = tf.image.resize(image, self._output_size, method='bilinear')
         label = tf.image.resize(label, self._output_size, method='nearest')
 
       image_mask = tf.concat([image, label], axis=2)
-      image_mask_crop = tf.image.random_crop(image_mask, self._crop_size + [4])
+      image_mask_crop = tf.image.random_crop(
+          image_mask, self._crop_size + [tf.shape(image_mask)[-1]])
       image = image_mask_crop[:, :, :-1]
       label = tf.reshape(image_mask_crop[:, :, -1], [1] + self._crop_size)
 
     # Flips image randomly during training.
     if self._aug_rand_hflip:
       image, _, label = preprocess_ops.random_horizontal_flip(
           image, masks=label)
@@ -195,15 +240,15 @@
 
     return image, labels
 
   def _parse_eval_data(self, data):
     """Parses data for training and evaluation."""
     image, label = self._prepare_image_and_label(data)
 
-    # Binarize mask if groundtruth is a matting map
+    # Binarize mask if ground-truth is a matting map
     if self._gt_is_matting_map:
       label = tf.divide(tf.cast(label, dtype=tf.float32), 255.0)
       label = utils.binarize_matting_map(label)
 
     # The label is first offset by +1 and then padded with 0.
     label += 1
     label = tf.expand_dims(label, axis=3)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tf_example_decoder.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tf_example_decoder.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,46 +13,56 @@
 # limitations under the License.
 
 """Tensorflow Example proto decoder for object detection.
 
 A decoder to decode string tensors containing serialized tensorflow.Example
 protos for object detection.
 """
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.dataloaders import decoder
 
 
 def _generate_source_id(image_bytes):
   # Hashing using 22 bits since float32 has only 23 mantissa bits.
   return tf.strings.as_string(
       tf.strings.to_hash_bucket_fast(image_bytes, 2 ** 22 - 1))
 
 
 class TfExampleDecoder(decoder.Decoder):
   """Tensorflow Example proto decoder."""
 
-  def __init__(self,
-               include_mask=False,
-               regenerate_source_id=False,
-               mask_binarize_threshold=None):
+  def __init__(
+      self,
+      include_mask=False,
+      regenerate_source_id=False,
+      mask_binarize_threshold=None,
+      attribute_names=None,
+  ):
     self._include_mask = include_mask
     self._regenerate_source_id = regenerate_source_id
     self._keys_to_features = {
         'image/encoded': tf.io.FixedLenFeature((), tf.string),
         'image/height': tf.io.FixedLenFeature((), tf.int64, -1),
         'image/width': tf.io.FixedLenFeature((), tf.int64, -1),
         'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),
         'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),
         'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),
         'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),
         'image/object/class/label': tf.io.VarLenFeature(tf.int64),
         'image/object/area': tf.io.VarLenFeature(tf.float32),
         'image/object/is_crowd': tf.io.VarLenFeature(tf.int64),
     }
+    attribute_names = attribute_names or []
+    for attr_name in attribute_names:
+      self._keys_to_features[f'image/object/attribute/{attr_name}'] = (
+          tf.io.VarLenFeature(tf.int64)
+      )
+    self._attribute_names = attribute_names
+
     self._mask_binarize_threshold = mask_binarize_threshold
     if include_mask:
       self._keys_to_features.update({
           'image/object/mask': tf.io.VarLenFeature(tf.string),
       })
     if not regenerate_source_id:
       self._keys_to_features.update({
@@ -72,14 +82,22 @@
     ymin = parsed_tensors['image/object/bbox/ymin']
     ymax = parsed_tensors['image/object/bbox/ymax']
     return tf.stack([ymin, xmin, ymax, xmax], axis=-1)
 
   def _decode_classes(self, parsed_tensors):
     return parsed_tensors['image/object/class/label']
 
+  def _decode_attributes(self, parsed_tensors):
+    attribute_dict = dict()
+    for attr_name in self._attribute_names:
+      attr_array = parsed_tensors[f'image/object/attribute/{attr_name}']
+      # TODO(b/269654135): Support decoding of fully 2D attributes.
+      attribute_dict[attr_name] = tf.expand_dims(attr_array, -1)
+    return attribute_dict
+
   def _decode_areas(self, parsed_tensors):
     xmin = parsed_tensors['image/object/bbox/xmin']
     xmax = parsed_tensors['image/object/bbox/xmax']
     ymin = parsed_tensors['image/object/bbox/ymin']
     ymax = parsed_tensors['image/object/bbox/ymax']
     height = tf.cast(parsed_tensors['image/height'], dtype=tf.float32)
     width = tf.cast(parsed_tensors['image/width'], dtype=tf.float32)
@@ -145,14 +163,16 @@
           lambda: parsed_tensors['image/source_id'],
           lambda: _generate_source_id(parsed_tensors['image/encoded']))
     image = self._decode_image(parsed_tensors)
     boxes = self._decode_boxes(parsed_tensors)
     classes = self._decode_classes(parsed_tensors)
     areas = self._decode_areas(parsed_tensors)
 
+    attributes = self._decode_attributes(parsed_tensors)
+
     decode_image_shape = tf.logical_or(
         tf.equal(parsed_tensors['image/height'], -1),
         tf.equal(parsed_tensors['image/width'], -1))
     image_shape = tf.cast(tf.shape(image), dtype=tf.int64)
 
     parsed_tensors['image/height'] = tf.where(decode_image_shape,
                                               image_shape[0],
@@ -176,13 +196,15 @@
         'height': parsed_tensors['image/height'],
         'width': parsed_tensors['image/width'],
         'groundtruth_classes': classes,
         'groundtruth_is_crowd': is_crowds,
         'groundtruth_area': areas,
         'groundtruth_boxes': boxes,
     }
+    if self._attribute_names:
+      decoded_tensors.update({'groundtruth_attributes': attributes})
     if self._include_mask:
       decoded_tensors.update({
           'groundtruth_instance_masks': masks,
           'groundtruth_instance_masks_png': parsed_tensors['image/object/mask'],
       })
     return decoded_tensors
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tf_example_decoder_test.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tf_example_decoder_test.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for tf_example_decoder.py."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.dataloaders import tf_example_decoder
 from official.vision.dataloaders import tfexample_utils
 
 
 class TfExampleDecoderTest(tf.test.TestCase, parameterized.TestCase):
 
@@ -73,29 +73,33 @@
     self.assertAllEqual(
         (num_instances, image_height, image_width),
         results['groundtruth_instance_masks'].shape)
     self.assertAllEqual(
         (num_instances,), results['groundtruth_instance_masks_png'].shape)
 
   def test_result_content(self):
-    decoder = tf_example_decoder.TfExampleDecoder(include_mask=True)
+    decoder = tf_example_decoder.TfExampleDecoder(
+        include_mask=True, attribute_names=['attr1', 'attr2']
+    )
 
     image_content = [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]],
                      [[0, 0, 0], [255, 255, 255], [255, 255, 255], [0, 0, 0]],
                      [[0, 0, 0], [255, 255, 255], [255, 255, 255], [0, 0, 0]],
                      [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]]]
     image = tfexample_utils.encode_image(np.uint8(image_content), fmt='PNG')
     image_height = 4
     image_width = 4
     num_instances = 2
     xmins = [0, 0.25]
     xmaxs = [0.5, 1.0]
     ymins = [0, 0]
     ymaxs = [0.5, 1.0]
     labels = [3, 1]
+    attr1 = np.array([[0], [2]])
+    attr2 = np.array([[1], [3]])
     areas = [
         0.25 * image_height * image_width, 0.75 * image_height * image_width
     ]
     is_crowds = [1, 0]
     mask_content = [[[255, 255, 0, 0],
                      [255, 255, 0, 0],
                      [0, 0, 0, 0],
@@ -107,40 +111,61 @@
     masks = [
         tfexample_utils.encode_image(np.uint8(m), fmt='PNG')
         for m in list(mask_content)
     ]
     serialized_example = tf.train.Example(
         features=tf.train.Features(
             feature={
-                'image/encoded': (tf.train.Feature(
-                    bytes_list=tf.train.BytesList(value=[image]))),
-                'image/source_id': (tf.train.Feature(
+                'image/encoded': tf.train.Feature(
+                    bytes_list=tf.train.BytesList(value=[image])
+                ),
+                'image/source_id': tf.train.Feature(
                     bytes_list=tf.train.BytesList(
-                        value=[tfexample_utils.DUMP_SOURCE_ID]))),
-                'image/height': (tf.train.Feature(
-                    int64_list=tf.train.Int64List(value=[image_height]))),
-                'image/width': (tf.train.Feature(
-                    int64_list=tf.train.Int64List(value=[image_width]))),
-                'image/object/bbox/xmin': (tf.train.Feature(
-                    float_list=tf.train.FloatList(value=xmins))),
-                'image/object/bbox/xmax': (tf.train.Feature(
-                    float_list=tf.train.FloatList(value=xmaxs))),
-                'image/object/bbox/ymin': (tf.train.Feature(
-                    float_list=tf.train.FloatList(value=ymins))),
-                'image/object/bbox/ymax': (tf.train.Feature(
-                    float_list=tf.train.FloatList(value=ymaxs))),
-                'image/object/class/label': (tf.train.Feature(
-                    int64_list=tf.train.Int64List(value=labels))),
-                'image/object/is_crowd': (tf.train.Feature(
-                    int64_list=tf.train.Int64List(value=is_crowds))),
-                'image/object/area': (tf.train.Feature(
-                    float_list=tf.train.FloatList(value=areas))),
-                'image/object/mask': (tf.train.Feature(
-                    bytes_list=tf.train.BytesList(value=masks))),
-            })).SerializeToString()
+                        value=[tfexample_utils.DUMP_SOURCE_ID]
+                    )
+                ),
+                'image/height': tf.train.Feature(
+                    int64_list=tf.train.Int64List(value=[image_height])
+                ),
+                'image/width': tf.train.Feature(
+                    int64_list=tf.train.Int64List(value=[image_width])
+                ),
+                'image/object/bbox/xmin': tf.train.Feature(
+                    float_list=tf.train.FloatList(value=xmins)
+                ),
+                'image/object/bbox/xmax': tf.train.Feature(
+                    float_list=tf.train.FloatList(value=xmaxs)
+                ),
+                'image/object/bbox/ymin': tf.train.Feature(
+                    float_list=tf.train.FloatList(value=ymins)
+                ),
+                'image/object/bbox/ymax': tf.train.Feature(
+                    float_list=tf.train.FloatList(value=ymaxs)
+                ),
+                'image/object/class/label': tf.train.Feature(
+                    int64_list=tf.train.Int64List(value=labels)
+                ),
+                'image/object/is_crowd': tf.train.Feature(
+                    int64_list=tf.train.Int64List(value=is_crowds)
+                ),
+                'image/object/area': tf.train.Feature(
+                    float_list=tf.train.FloatList(value=areas)
+                ),
+                'image/object/mask': tf.train.Feature(
+                    bytes_list=tf.train.BytesList(value=masks)
+                ),
+                'image/object/attribute/attr1': tf.train.Feature(
+                    int64_list=tf.train.Int64List(value=attr1.flatten())
+                ),
+                'image/object/attribute/attr2': tf.train.Feature(
+                    int64_list=tf.train.Int64List(value=attr2.flatten())
+                ),
+            }
+        )
+    ).SerializeToString()
     decoded_tensors = decoder.decode(
         tf.convert_to_tensor(value=serialized_example))
 
     results = tf.nest.map_structure(lambda x: x.numpy(), decoded_tensors)
 
     self.assertAllEqual(
         (image_height, image_width, 3), results['image'].shape)
@@ -159,16 +184,21 @@
     self.assertAllEqual(
         (num_instances, image_height, image_width),
         results['groundtruth_instance_masks'].shape)
     self.assertAllEqual(
         (num_instances,), results['groundtruth_instance_masks_png'].shape)
     self.assertAllEqual(
         [3, 1], results['groundtruth_classes'])
-    self.assertAllEqual(
-        [True, False], results['groundtruth_is_crowd'])
+    np.testing.assert_array_equal(
+        attr1, results['groundtruth_attributes']['attr1']
+    )
+    np.testing.assert_array_equal(
+        attr2, results['groundtruth_attributes']['attr2']
+    )
+    self.assertAllEqual([True, False], results['groundtruth_is_crowd'])
     self.assertNDArrayNear(
         [0.25 * image_height * image_width, 0.75 * image_height * image_width],
         results['groundtruth_area'], 1e-4)
     self.assertNDArrayNear(
         [[0, 0, 0.5, 0.5], [0, 0.25, 1.0, 1.0]],
         results['groundtruth_boxes'], 1e-4)
     self.assertNDArrayNear(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tf_example_label_map_decoder.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tf_example_label_map_decoder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Tensorflow Example proto decoder for object detection.
 
 A decoder to decode string tensors containing serialized tensorflow.Example
 protos for object detection.
 """
 import csv
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.dataloaders import tf_example_decoder
 
 
 class TfExampleDecoderLabelMap(tf_example_decoder.TfExampleDecoder):
   """Tensorflow Example proto decoder."""
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tf_example_label_map_decoder_test.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tf_example_label_map_decoder_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for tf_example_label_map_decoder.py."""
 
 import os
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.dataloaders import tf_example_label_map_decoder
 from official.vision.dataloaders import tfexample_utils
 
 
 LABEL_MAP_CSV_CONTENT = '0,class_0\n1,class_1\n2,class_2'
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_classification_decoders.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_classification_decoders.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """TFDS Classification decoders."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.vision.dataloaders import decoder
 
 
 class ClassificationDecorder(decoder.Decoder):
   """A tf.Example decoder for tfds classification datasets."""
 
   def decode(self, serialized_example):
@@ -31,8 +31,9 @@
     return sample_dict
 
 
 TFDS_ID_TO_DECODER_MAP = {
     'cifar10': ClassificationDecorder,
     'cifar100': ClassificationDecorder,
     'imagenet2012': ClassificationDecorder,
+    'imagenet2012_fewshot/10shot': ClassificationDecorder,
 }
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_detection_decoders.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_detection_decoders.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,26 +10,26 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """TFDS detection decoders."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.vision.dataloaders import decoder
 
 
 class MSCOCODecoder(decoder.Decoder):
   """A tf.Example decoder for tfds coco datasets."""
 
   def decode(self, serialized_example):
     """Decode the serialized example.
 
     Args:
-      serialized_example: a dictonary example produced by tfds.
+      serialized_example: a dictionary example produced by tfds.
 
     Returns:
       decoded_tensors: a dictionary of tensors with the following fields:
         - source_id: a string scalar tensor.
         - image: a uint8 tensor of shape [None, None, 3].
         - height: an integer scalar tensor.
         - width: an integer scalar tensor.
@@ -52,9 +52,10 @@
     }
     return decoded_tensors
 
 
 TFDS_ID_TO_DECODER_MAP = {
     'coco/2017': MSCOCODecoder,
     'coco/2014': MSCOCODecoder,
-    'coco': MSCOCODecoder
+    'coco': MSCOCODecoder,
+    'scenic:objects365': MSCOCODecoder,
 }
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_factory.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_factory.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_factory_test.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_factory_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for tfds factory functions."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.dataloaders import decoder as base_decoder
 from official.vision.dataloaders import tfds_factory
 
 
 class TFDSFactoryTest(tf.test.TestCase, parameterized.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tfds_segmentation_decoders.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tfds_segmentation_decoders.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """TFDS Semantic Segmentation decoders."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.vision.dataloaders import decoder
 
 
 class CityScapesDecorder(decoder.Decoder):
   """A tf.Example decoder for tfds cityscapes datasets."""
 
   def __init__(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/tfexample_utils.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/tfexample_utils.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -38,18 +38,18 @@
   def test_foo(self):
     dataset = tf.data.TFRecordDataset(self._data_path)
     ...
 
 ```
 
 """
-from typing import Sequence, Union
+from typing import Mapping, Optional, Sequence, Union
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import file_writers
 from official.vision.data import fake_feature_generator
 from official.vision.data import image_utils
 from official.vision.data import tf_example_builder
 
 IMAGE_KEY = 'image/encoded'
@@ -107,26 +107,30 @@
   put_bytes_list_to_feature(
       seq_example, raw_image_bytes, key=IMAGE_KEY, repeat_num=4)
 
   put_float_list_to_feature(seq_example, value=random_audio, key=AUDIO_KEY)
   return seq_example
 
 
-def dump_to_tfrecord(record_file: str,
-                     tf_examples: Sequence[Union[tf.train.Example,
-                                                 tf.train.SequenceExample]]):
+def dump_to_tfrecord(
+    record_file: str,
+    tf_examples: Sequence[Union[tf.train.Example, tf.train.SequenceExample]],
+    file_type: str = 'tfrecord'):
   """Writes serialized Example to TFRecord file with path.
 
   Note that examples are expected to be not seriazlied.
 
   Args:
     record_file: The name of the output file.
     tf_examples: A list of examples to be stored.
+    file_type: A string indicating the file format, could be: 'tfrecord',
+      'tfrecords', 'tfrecord_compressed', 'tfrecords_gzip', 'riegeli'. The
+      string is case insensitive.
   """
-  file_writers.write_small_dataset(tf_examples, record_file, 'tfrecord')
+  file_writers.write_small_dataset(tf_examples, record_file, file_type)
 
 
 def create_classification_example(
     image_height: int,
     image_width: int,
     image_format: str = 'JPEG',
     is_multilabel: bool = False,
@@ -146,16 +150,16 @@
     A tf.train.Example for testing.
   """
   image = fake_feature_generator.generate_image_np(image_height, image_width)
   labels = fake_feature_generator.generate_classes_np(2,
                                                       int(is_multilabel) +
                                                       1).tolist()
   builder = tf_example_builder.TfExampleBuilder()
-  example = builder.add_image_matrix_feature(image,
-                                             image_format).add_ints_feature(
+  example = builder.add_image_matrix_feature(image, image_format,
+                                             DUMP_SOURCE_ID).add_ints_feature(
                                                  CLASSIFICATION_LABEL_KEY,
                                                  labels).example
   if output_serialized_example:
     return example.SerializeToString()
   return example
 
 
@@ -179,52 +183,59 @@
     A tf.train.Example for testing.
   """
   image = fake_feature_generator.generate_image_np(image_height, image_width)
   labels = fake_feature_generator.generate_classes_np(2, 1).tolist()
   soft_labels = (fake_feature_generator.generate_classes_np(1, num_labels) +
                  0.6).tolist()
   builder = tf_example_builder.TfExampleBuilder()
-  example = builder.add_image_matrix_feature(image,
-                                             image_format).add_ints_feature(
+  example = builder.add_image_matrix_feature(image, image_format,
+                                             DUMP_SOURCE_ID).add_ints_feature(
                                                  CLASSIFICATION_LABEL_KEY,
                                                  labels).add_floats_feature(
                                                      DISTILLATION_LABEL_KEY,
                                                      soft_labels).example
   if output_serialized_example:
     return example.SerializeToString()
   return example
 
 
 def create_3d_image_test_example(
     image_height: int,
     image_width: int,
     image_volume: int,
     image_channel: int,
+    num_classes: int = 2,
     output_serialized_example: bool = False) -> tf.train.Example:
   """Creates 3D image and label.
 
   Args:
     image_height: The height of test 3D image.
     image_width: The width of test 3D image.
     image_volume: The volume of test 3D image.
     image_channel: The channel of test 3D image.
+    num_classes: The number of classes of the test 3D label.
     output_serialized_example: A boolean flag represents whether to return a
       serialized example.
 
   Returns:
     A tf.train.Example for testing.
   """
   image = fake_feature_generator.generate_image_np(image_height, image_width,
                                                    image_channel)
   images = image[:, :, np.newaxis, :]
   images = np.tile(images, [1, 1, image_volume, 1]).astype(np.float32)
 
-  shape = [image_height, image_width, image_volume, image_channel]
-  labels = fake_feature_generator.generate_classes_np(
-      2, np.prod(shape)).reshape(shape).astype(np.float32)
+  label_shape = [image_height, image_width, image_volume, num_classes]
+  labels = (
+      fake_feature_generator.generate_classes_np(
+          num_classes, np.prod(label_shape)
+      )
+      .reshape(label_shape)
+      .astype(np.float32)
+  )
 
   builder = tf_example_builder.TfExampleBuilder()
   example = builder.add_bytes_feature(IMAGE_KEY,
                                       images.tobytes()).add_bytes_feature(
                                           CLASSIFICATION_LABEL_KEY,
                                           labels.tobytes()).example
   if output_serialized_example:
@@ -262,49 +273,64 @@
       2, size=num_instances).tolist()
   labels_text = [b'class_1'] * num_instances
   masks = fake_feature_generator.generate_instance_masks_np(
       image_height, image_width, boxes)
 
   builder = tf_example_builder.TfExampleBuilder()
 
-  example = builder.add_image_matrix_feature(image).add_boxes_feature(
-      xmins, xmaxs, ymins, ymaxs,
-      labels).add_instance_mask_matrices_feature(masks).add_ints_feature(
-          'image/object/is_crowd',
-          is_crowds).add_bytes_feature('image/object/class/text',
-                                       labels_text).example
+  example = builder.add_image_matrix_feature(
+      image, image_source_id=DUMP_SOURCE_ID).add_boxes_feature(
+          xmins, xmaxs, ymins, ymaxs,
+          labels).add_instance_mask_matrices_feature(masks).add_ints_feature(
+              'image/object/is_crowd',
+              is_crowds).add_bytes_feature('image/object/class/text',
+                                           labels_text).example
   if not fill_image_size:
     del example.features.feature['image/height']
     del example.features.feature['image/width']
 
   if output_serialized_example:
     return example.SerializeToString()
   return example
 
 
 def create_segmentation_test_example(
     image_height: int,
     image_width: int,
     image_channel: int,
-    output_serialized_example: bool = False) -> tf.train.Example:
+    output_serialized_example: bool = False,
+    dense_features: Optional[Mapping[str, int]] = None) -> tf.train.Example:
   """Creates and returns a test example containing mask annotations.
 
   Args:
     image_height: The height of test image.
     image_width: The width of test image.
     image_channel: The channel of test image.
     output_serialized_example: A boolean flag represents whether to return a
       serialized example.
-
+    dense_features: An optional dictionary of additional dense features, where
+      the key is the prefix of the feature key in tf.Example and the value is
+      the number of the channels of this feature.
   Returns:
     A tf.train.Example for testing.
   """
   image = fake_feature_generator.generate_image_np(image_height, image_width,
                                                    image_channel)
   mask = fake_feature_generator.generate_semantic_mask_np(
       image_height, image_width, 3)
   builder = tf_example_builder.TfExampleBuilder()
-  example = builder.add_image_matrix_feature(
-      image).add_semantic_mask_matrix_feature(mask).example
+  builder.add_image_matrix_feature(
+      image,
+      image_source_id=DUMP_SOURCE_ID).add_semantic_mask_matrix_feature(mask)
+
+  if dense_features:
+    for prefix, channel in dense_features.items():
+      dense_feature = fake_feature_generator.generate_semantic_mask_np(
+          image_height, image_width, channel)
+      builder.add_semantic_mask_matrix_feature(
+          dense_feature, feature_prefix=prefix)
+
+  example = builder.example
+
   if output_serialized_example:
     return example.SerializeToString()
   return example
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/utils.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Data loader utils."""
 from typing import Dict
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import preprocess_ops
 
 
 def process_source_id(source_id: tf.Tensor) -> tf.Tensor:
   """Processes source_id to the right format.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/utils_test.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/utils_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for dataloader utils functions."""
 
 # Import libraries
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.dataloaders import utils
 
 
 class UtilsTest(tf.test.TestCase, parameterized.TestCase):
 
   def test_process_empty_source_id(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/video_input.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/video_input.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Parser for video and label datasets."""
 
 from typing import Dict, Optional, Tuple, Union
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.configs import video_classification as exp_cfg
 from official.vision.dataloaders import decoder
 from official.vision.dataloaders import parser
 from official.vision.ops import augment
 from official.vision.ops import preprocess_ops_3d
 
@@ -41,47 +41,50 @@
                   num_crops: int = 1,
                   zero_centering_image: bool = False,
                   min_aspect_ratio: float = 0.5,
                   max_aspect_ratio: float = 2,
                   min_area_ratio: float = 0.49,
                   max_area_ratio: float = 1.0,
                   augmenter: Optional[augment.ImageAugment] = None,
-                  seed: Optional[int] = None) -> tf.Tensor:
+                  seed: Optional[int] = None,
+                  input_image_format: Optional[str] = 'jpeg') -> tf.Tensor:
   """Processes a serialized image tensor.
 
   Args:
-    image: Input Tensor of shape [timesteps] and type tf.string of serialized
+    image: Input Tensor of shape [time-steps] and type tf.string of serialized
       frames.
     is_training: Whether or not in training mode. If True, random sample, crop
       and left right flip is used.
-    num_frames: Number of frames per subclip.
+    num_frames: Number of frames per sub clip.
     stride: Temporal stride to sample frames.
     random_stride_range: An int indicating the min and max bounds to uniformly
       sample different strides from the video. E.g., a value of 1 with stride=2
       will uniformly sample a stride in {1, 2, 3} for each video in a batch.
       Only used enabled training for the purposes of frame-rate augmentation.
       Defaults to 0, which disables random sampling.
     num_test_clips: Number of test clips (1 by default). If more than 1, this
       will sample multiple linearly spaced clips within each video at test time.
       If 1, then a single clip in the middle of the video is sampled. The clips
-      are aggreagated in the batch dimension.
+      are aggregated in the batch dimension.
     min_resize: Frames are resized so that min(height, width) is min_resize.
     crop_size: Final size of the frame after cropping the resized frames.
       Optionally, specify a tuple of (crop_height, crop_width) if
       crop_height != crop_width.
     num_channels: Number of channels of the clip.
     num_crops: Number of crops to perform on the resized frames.
     zero_centering_image: If True, frames are normalized to values in [-1, 1].
       If False, values in [0, 1].
     min_aspect_ratio: The minimum aspect range for cropping.
     max_aspect_ratio: The maximum aspect range for cropping.
     min_area_ratio: The minimum area range for cropping.
     max_area_ratio: The maximum area range for cropping.
     augmenter: Image augmenter to distort each image.
     seed: A deterministic seed to use when sampling.
+    input_image_format: The format of input image which could be jpeg, png or
+          none for unknown or mixed datasets.
 
   Returns:
     Processed frames. Tensor of shape
       [num_frames * num_test_clips, crop_height, crop_width, num_channels].
   """
   # Validate parameters.
   if is_training and num_test_clips != 1:
@@ -89,14 +92,18 @@
         '`num_test_clips` %d is ignored since `is_training` is `True`.',
         num_test_clips)
 
   if random_stride_range < 0:
     raise ValueError('Random stride range should be >= 0, got {}'.format(
         random_stride_range))
 
+  if input_image_format not in ('jpeg', 'png', 'none'):
+    raise ValueError('Unknown input image format: {}'.format(
+        input_image_format))
+
   if isinstance(crop_size, int):
     crop_size = (crop_size, crop_size)
   crop_height, crop_width = crop_size
 
   # Temporal sampler.
   if is_training:
     if random_stride_range > 0:
@@ -116,15 +123,15 @@
                                                        num_frames, stride)
   else:
     # Sample middle clip.
     image = preprocess_ops_3d.sample_sequence(image, num_frames, False, stride)
 
   # Decode JPEG string to tf.uint8.
   if image.dtype == tf.string:
-    image = preprocess_ops_3d.decode_jpeg(image, num_channels)
+    image = preprocess_ops_3d.decode_image(image, num_channels)
 
   if is_training:
     # Standard image data augmentation: random resized crop and random flip.
     image = preprocess_ops_3d.random_crop_resize(
         image, crop_height, crop_width, num_frames, num_channels,
         (min_aspect_ratio, max_aspect_ratio),
         (min_area_ratio, max_area_ratio))
@@ -149,33 +156,33 @@
                       num_test_clips: int = 1,
                       num_test_crops: int = 1) -> tf.Tensor:
   """Processes a batched Tensor of frames.
 
   The same parameters used in process should be used here.
 
   Args:
-    image: Input Tensor of shape [batch, timesteps, height, width, 3].
+    image: Input Tensor of shape [batch, time-steps, height, width, 3].
     is_training: Whether or not in training mode. If True, random sample, crop
       and left right flip is used.
-    num_frames: Number of frames per subclip.
+    num_frames: Number of frames per sub clip.
     num_test_clips: Number of test clips (1 by default). If more than 1, this
       will sample multiple linearly spaced clips within each video at test time.
       If 1, then a single clip in the middle of the video is sampled. The clips
-      are aggreagated in the batch dimension.
+      are aggregated in the batch dimension.
     num_test_crops: Number of test crops (1 by default). If more than 1, there
       are multiple crops for each clip at test time. If 1, there is a single
-      central crop. The crops are aggreagated in the batch dimension.
+      central crop. The crops are aggregated in the batch dimension.
 
   Returns:
     Processed frames. Tensor of shape
       [batch * num_test_clips * num_test_crops, num_frames, height, width, 3].
   """
   num_views = num_test_clips * num_test_crops
   if num_views > 1 and not is_training:
-    # In this case, multiple views are merged together in batch dimenstion which
+    # In this case, multiple views are merged together in batch dimension which
     # will be batch * num_views.
     image = tf.reshape(image, [-1, num_frames] + image.shape[2:].as_list())
 
   return image
 
 
 def process_label(label: tf.Tensor,
@@ -291,14 +298,15 @@
     self._dtype = tf.dtypes.as_dtype(input_params.dtype)
     self._label_dtype = tf.dtypes.as_dtype(input_params.label_dtype)
     self._output_audio = input_params.output_audio
     self._min_aspect_ratio = input_params.aug_min_aspect_ratio
     self._max_aspect_ratio = input_params.aug_max_aspect_ratio
     self._min_area_ratio = input_params.aug_min_area_ratio
     self._max_area_ratio = input_params.aug_max_area_ratio
+    self._input_image_format = input_params.input_image_format
     if self._output_audio:
       self._audio_feature = input_params.audio_feature
       self._audio_shape = input_params.audio_feature_shape
 
     aug_type = input_params.aug_type
     if aug_type is not None:
       if aug_type.type == 'autoaug':
@@ -339,15 +347,16 @@
         crop_size=self._crop_size,
         num_channels=self._num_channels,
         min_aspect_ratio=self._min_aspect_ratio,
         max_aspect_ratio=self._max_aspect_ratio,
         min_area_ratio=self._min_area_ratio,
         max_area_ratio=self._max_area_ratio,
         augmenter=self._augmenter,
-        zero_centering_image=self._zero_centering_image)
+        zero_centering_image=self._zero_centering_image,
+        input_image_format=self._input_image_format)
     image = tf.cast(image, dtype=self._dtype)
 
     features = {'image': image}
 
     label = decoded_tensors[self._label_key]
     label = process_label(label, self._one_hot_label, self._num_classes,
                           self._label_dtype)
@@ -374,15 +383,16 @@
         num_frames=self._num_frames,
         stride=self._stride,
         num_test_clips=self._num_test_clips,
         min_resize=self._min_resize,
         crop_size=self._crop_size,
         num_channels=self._num_channels,
         num_crops=self._num_crops,
-        zero_centering_image=self._zero_centering_image)
+        zero_centering_image=self._zero_centering_image,
+        input_image_format=self._input_image_format)
     image = tf.cast(image, dtype=self._dtype)
     features = {'image': image}
 
     label = decoded_tensors[self._label_key]
     label = process_label(label, self._one_hot_label, self._num_classes,
                           self._label_dtype)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/dataloaders/video_input_test.py` & `tf-models-no-deps-2.16.0/official/vision/dataloaders/video_input_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 
 import io
 
 # Import libraries
 import numpy as np
 from PIL import Image
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 from official.vision.configs import common
 from official.vision.configs import video_classification as exp_cfg
 from official.vision.dataloaders import video_input
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/evaluation/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/waste_identification_ml/data_generation/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/evaluation/coco_evaluator.py` & `tf-models-no-deps-2.16.0/official/vision/evaluation/coco_evaluator.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -29,43 +29,58 @@
 import atexit
 import tempfile
 # Import libraries
 from absl import logging
 import numpy as np
 from pycocotools import cocoeval
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.evaluation import coco_utils
 
 
 class COCOEvaluator(object):
   """COCO evaluation metric class."""
 
   def __init__(self,
                annotation_file,
                include_mask,
+               include_keypoint=False,
                need_rescale_bboxes=True,
-               per_category_metrics=False):
+               need_rescale_keypoints=False,
+               per_category_metrics=False,
+               max_num_eval_detections=100,
+               kpt_oks_sigmas=None):
     """Constructs COCO evaluation class.
 
     The class provides the interface to COCO metrics_fn. The
     _update_op() takes detections from each image and push them to
     self.detections. The _evaluate() loads a JSON file in COCO annotation format
-    as the groundtruths and runs COCO evaluation.
+    as the ground-truths and runs COCO evaluation.
 
     Args:
       annotation_file: a JSON file that stores annotations of the eval dataset.
-        If `annotation_file` is None, groundtruth annotations will be loaded
+        If `annotation_file` is None, ground-truth annotations will be loaded
         from the dataloader.
       include_mask: a boolean to indicate whether or not to include the mask
         eval.
+      include_keypoint: a boolean to indicate whether or not to include the
+        keypoint eval.
       need_rescale_bboxes: If true bboxes in `predictions` will be rescaled back
         to absolute values (`image_info` is needed in this case).
+      need_rescale_keypoints: If true keypoints in `predictions` will be
+        rescaled back to absolute values (`image_info` is needed in this case).
       per_category_metrics: Whether to return per category metrics.
+      max_num_eval_detections: Maximum number of detections to evaluate in coco
+        eval api. Default at 100.
+      kpt_oks_sigmas: The sigmas used to calculate keypoint OKS. See
+        http://cocodataset.org/#keypoints-eval. When None, it will use the
+        defaults in COCO.
+    Raises:
+      ValueError: if max_num_eval_detections is not an integer.
     """
     if annotation_file:
       if annotation_file.startswith('gs://'):
         _, local_val_json = tempfile.mkstemp(suffix='.json')
         tf.io.gfile.remove(local_val_json)
 
         tf.io.gfile.copy(annotation_file, local_val_json)
@@ -73,34 +88,50 @@
       else:
         local_val_json = annotation_file
       self._coco_gt = coco_utils.COCOWrapper(
           eval_type=('mask' if include_mask else 'box'),
           annotation_file=local_val_json)
     self._annotation_file = annotation_file
     self._include_mask = include_mask
+    self._include_keypoint = include_keypoint
     self._per_category_metrics = per_category_metrics
+    if max_num_eval_detections is None or not isinstance(
+        max_num_eval_detections, int):
+      raise ValueError('max_num_eval_detections must be an integer.')
     self._metric_names = [
         'AP', 'AP50', 'AP75', 'APs', 'APm', 'APl', 'ARmax1', 'ARmax10',
-        'ARmax100', 'ARs', 'ARm', 'ARl'
+        f'ARmax{max_num_eval_detections}', 'ARs', 'ARm', 'ARl'
     ]
+    self.max_num_eval_detections = max_num_eval_detections
     self._required_prediction_fields = [
         'source_id', 'num_detections', 'detection_classes', 'detection_scores',
         'detection_boxes'
     ]
     self._need_rescale_bboxes = need_rescale_bboxes
-    if self._need_rescale_bboxes:
+    self._need_rescale_keypoints = need_rescale_keypoints
+    if self._need_rescale_bboxes or self._need_rescale_keypoints:
       self._required_prediction_fields.append('image_info')
     self._required_groundtruth_fields = [
         'source_id', 'height', 'width', 'classes', 'boxes'
     ]
     if self._include_mask:
       mask_metric_names = ['mask_' + x for x in self._metric_names]
       self._metric_names.extend(mask_metric_names)
       self._required_prediction_fields.extend(['detection_masks'])
       self._required_groundtruth_fields.extend(['masks'])
+    if self._include_keypoint:
+      keypoint_metric_names = [
+          'AP', 'AP50', 'AP75', 'APm', 'APl', 'ARmax1', 'ARmax10',
+          f'ARmax{max_num_eval_detections}', 'ARm', 'ARl'
+      ]
+      keypoint_metric_names = ['keypoint_' + x for x in keypoint_metric_names]
+      self._metric_names.extend(keypoint_metric_names)
+      self._required_prediction_fields.extend(['detection_keypoints'])
+      self._required_groundtruth_fields.extend(['keypoints'])
+      self._kpt_oks_sigmas = kpt_oks_sigmas
 
     self.reset_states()
 
   @property
   def name(self):
     return 'coco_metric'
 
@@ -137,44 +168,56 @@
     coco_predictions = coco_utils.convert_predictions_to_coco_annotations(
         self._predictions)
     coco_dt = coco_gt.loadRes(predictions=coco_predictions)
     image_ids = [ann['image_id'] for ann in coco_predictions]
 
     coco_eval = cocoeval.COCOeval(coco_gt, coco_dt, iouType='bbox')
     coco_eval.params.imgIds = image_ids
+    coco_eval.params.maxDets[2] = self.max_num_eval_detections
     coco_eval.evaluate()
     coco_eval.accumulate()
     coco_eval.summarize()
     coco_metrics = coco_eval.stats
+    metrics = coco_metrics
 
     if self._include_mask:
       mcoco_eval = cocoeval.COCOeval(coco_gt, coco_dt, iouType='segm')
       mcoco_eval.params.imgIds = image_ids
       mcoco_eval.evaluate()
       mcoco_eval.accumulate()
       mcoco_eval.summarize()
       mask_coco_metrics = mcoco_eval.stats
+      metrics = np.hstack((metrics, mask_coco_metrics))
 
-    if self._include_mask:
-      metrics = np.hstack((coco_metrics, mask_coco_metrics))
-    else:
-      metrics = coco_metrics
+    if self._include_keypoint:
+      kcoco_eval = cocoeval.COCOeval(coco_gt, coco_dt, iouType='keypoints',
+                                     kpt_oks_sigmas=self._kpt_oks_sigmas)
+      kcoco_eval.params.imgIds = image_ids
+      kcoco_eval.evaluate()
+      kcoco_eval.accumulate()
+      kcoco_eval.summarize()
+      keypoint_coco_metrics = kcoco_eval.stats
+      metrics = np.hstack((metrics, keypoint_coco_metrics))
 
     metrics_dict = {}
     for i, name in enumerate(self._metric_names):
       metrics_dict[name] = metrics[i].astype(np.float32)
 
     # Adds metrics per category.
     if self._per_category_metrics:
       metrics_dict.update(self._retrieve_per_category_metrics(coco_eval))
 
       if self._include_mask:
         metrics_dict.update(self._retrieve_per_category_metrics(
             mcoco_eval, prefix='mask'))
 
+      if self._include_keypoint:
+        metrics_dict.update(self._retrieve_per_category_metrics(
+            mcoco_eval, prefix='keypoints'))
+
     return metrics_dict
 
   def _retrieve_per_category_metrics(self, coco_eval, prefix=''):
     """Retrieves and per-category metrics and retuns them in a dict.
 
     Args:
       coco_eval: a cocoeval.COCOeval object containing evaluation data.
@@ -193,63 +236,67 @@
         if self._annotation_file:
           coco_category = self._coco_gt.cats[category_id]
           # if 'name' is available use it, otherwise use `id`
           category_display_name = coco_category.get('name', category_id)
         else:
           category_display_name = category_id
 
-        metrics_dict[prefix + 'Precision mAP ByCategory/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[0][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Precision mAP ByCategory@50IoU/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[1][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Precision mAP ByCategory@75IoU/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[2][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Precision mAP ByCategory (small) /{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[3][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Precision mAP ByCategory (medium) /{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[4][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Precision mAP ByCategory (large) /{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[5][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Recall AR@1 ByCategory/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[6][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Recall AR@10 ByCategory/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[7][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Recall AR@100 ByCategory/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[8][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Recall AR (small) ByCategory/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[9][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Recall AR (medium) ByCategory/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[10][category_index].astype(np.float32)
-        metrics_dict[prefix + 'Recall AR (large) ByCategory/{}'.format(
-            category_display_name
-        )] = coco_eval.category_stats[11][category_index].astype(np.float32)
+        if 'keypoints' in prefix:
+          metrics_dict_keys = [
+              'Precision mAP ByCategory',
+              'Precision mAP ByCategory@50IoU',
+              'Precision mAP ByCategory@75IoU',
+              'Precision mAP ByCategory (medium)',
+              'Precision mAP ByCategory (large)',
+              'Recall AR@1 ByCategory',
+              'Recall AR@10 ByCategory',
+              'Recall AR@100 ByCategory',
+              'Recall AR (medium) ByCategory',
+              'Recall AR (large) ByCategory',
+          ]
+        else:
+          metrics_dict_keys = [
+              'Precision mAP ByCategory',
+              'Precision mAP ByCategory@50IoU',
+              'Precision mAP ByCategory@75IoU',
+              'Precision mAP ByCategory (small)',
+              'Precision mAP ByCategory (medium)',
+              'Precision mAP ByCategory (large)',
+              'Recall AR@1 ByCategory',
+              'Recall AR@10 ByCategory',
+              'Recall AR@100 ByCategory',
+              'Recall AR (small) ByCategory',
+              'Recall AR (medium) ByCategory',
+              'Recall AR (large) ByCategory',
+          ]
+
+        for idx, key in enumerate(metrics_dict_keys):
+          metrics_dict[prefix + key + '/{}'.format(
+              category_display_name)] = coco_eval.category_stats[idx][
+                  category_index].astype(np.float32)
 
     return metrics_dict
 
-  def _process_predictions(self, predictions):
+  def _process_bbox_predictions(self, predictions):
     image_scale = np.tile(predictions['image_info'][:, 2:3, :], (1, 1, 2))
     predictions['detection_boxes'] = (
         predictions['detection_boxes'].astype(np.float32))
     predictions['detection_boxes'] /= image_scale
     if 'detection_outer_boxes' in predictions:
       predictions['detection_outer_boxes'] = (
           predictions['detection_outer_boxes'].astype(np.float32))
       predictions['detection_outer_boxes'] /= image_scale
 
+  def _process_keypoints_predictions(self, predictions):
+    image_scale = tf.reshape(predictions['image_info'][:, 2:3, :],
+                             [-1, 1, 1, 2])
+    predictions['detection_keypoints'] = (
+        predictions['detection_keypoints'].astype(np.float32))
+    predictions['detection_keypoints'] /= image_scale
+
   def _convert_to_numpy(self, groundtruths, predictions):
     """Converts tesnors to numpy arrays."""
     if groundtruths:
       labels = tf.nest.map_structure(lambda x: x.numpy(), groundtruths)
       numpy_groundtruths = {}
       for key, val in labels.items():
         if isinstance(val, tuple):
@@ -267,15 +314,15 @@
         numpy_predictions[key] = val
     else:
       numpy_predictions = predictions
 
     return numpy_groundtruths, numpy_predictions
 
   def update_state(self, groundtruths, predictions):
-    """Update and aggregate detection results and groundtruth data.
+    """Update and aggregate detection results and ground-truth data.
 
     Args:
       groundtruths: a dictionary of Tensors including the fields below.
         See also different parsers under `../dataloader` for more details.
         Required fields:
           - source_id: a numpy array of int or string of shape [batch_size].
           - height: a numpy array of int of shape [batch_size].
@@ -302,25 +349,27 @@
           - detection_boxes: a numpy array of float of shape [batch_size, K, 4].
           - detection_classes: a numpy array of int of shape [batch_size, K].
           - detection_scores: a numpy array of float of shape [batch_size, K].
         Optional fields:
           - detection_masks: a numpy array of float of shape
               [batch_size, K, mask_height, mask_width].
     Raises:
-      ValueError: if the required prediction or groundtruth fields are not
+      ValueError: if the required prediction or ground-truth fields are not
         present in the incoming `predictions` or `groundtruths`.
     """
     groundtruths, predictions = self._convert_to_numpy(groundtruths,
                                                        predictions)
     for k in self._required_prediction_fields:
       if k not in predictions:
         raise ValueError(
             'Missing the required key `{}` in predictions!'.format(k))
     if self._need_rescale_bboxes:
-      self._process_predictions(predictions)
+      self._process_bbox_predictions(predictions)
+    if self._need_rescale_keypoints:
+      self._process_keypoints_predictions(predictions)
     for k, v in six.iteritems(predictions):
       if k not in self._predictions:
         self._predictions[k] = [v]
       else:
         self._predictions[k].append(v)
 
     if not self._annotation_file:
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/evaluation/coco_utils.py` & `tf-models-no-deps-2.16.0/official/vision/evaluation/coco_utils.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,42 +21,42 @@
 
 from absl import logging
 import numpy as np
 from PIL import Image
 from pycocotools import coco
 from pycocotools import mask as mask_api
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import dataset_fn
 from official.vision.dataloaders import tf_example_decoder
 from official.vision.ops import box_ops
 from official.vision.ops import mask_ops
 
 
 class COCOWrapper(coco.COCO):
   """COCO wrapper class.
 
   This class wraps COCO API object, which provides the following additional
   functionalities:
     1. Support string type image id.
-    2. Support loading the groundtruth dataset using the external annotation
+    2. Support loading the ground-truth dataset using the external annotation
        dictionary.
     3. Support loading the prediction results using the external annotation
        dictionary.
   """
 
   def __init__(self, eval_type='box', annotation_file=None, gt_dataset=None):
     """Instantiates a COCO-style API object.
 
     Args:
       eval_type: either 'box' or 'mask'.
       annotation_file: a JSON file that stores annotations of the eval dataset.
         This is required if `gt_dataset` is not provided.
-      gt_dataset: the groundtruth eval datatset in COCO API format.
+      gt_dataset: the ground-truth eval datatset in COCO API format.
     """
     if ((annotation_file and gt_dataset) or
         ((not annotation_file) and (not gt_dataset))):
       raise ValueError('One and only one of `annotation_file` and `gt_dataset` '
                        'needs to be specified.')
 
     if eval_type not in ['box', 'mask']:
@@ -77,15 +77,15 @@
         `bbox`, `segmentation`.
 
     Returns:
       res: result COCO api object.
 
     Raises:
       ValueError: if the set of image id from predctions is not the subset of
-        the set of image id of the groundtruth dataset.
+        the set of image id of the ground-truth dataset.
     """
     res = coco.COCO()
     res.dataset['images'] = copy.deepcopy(self.dataset['images'])
     res.dataset['categories'] = copy.deepcopy(self.dataset['categories'])
 
     image_ids = [ann['image_id'] for ann in predictions]
     if set(image_ids) != (set(image_ids) & set(self.getImgIds())):
@@ -106,29 +106,30 @@
 
 
 def convert_predictions_to_coco_annotations(predictions):
   """Converts a batch of predictions to annotations in COCO format.
 
   Args:
     predictions: a dictionary of lists of numpy arrays including the following
-      fields. K below denotes the maximum number of instances per image.
+      fields. 'K' below denotes the maximum number of instances per image.
       Required fields:
         - source_id: a list of numpy arrays of int or string of shape
             [batch_size].
-        - num_detections: a list of numpy arrays of int of shape [batch_size].
         - detection_boxes: a list of numpy arrays of float of shape
             [batch_size, K, 4], where coordinates are in the original image
             space (not the scaled image space).
         - detection_classes: a list of numpy arrays of int of shape
             [batch_size, K].
         - detection_scores: a list of numpy arrays of float of shape
             [batch_size, K].
       Optional fields:
         - detection_masks: a list of numpy arrays of float of shape
             [batch_size, K, mask_height, mask_width].
+        - detection_keypoints: a list of numpy arrays of float of shape
+            [batch_size, K, num_keypoints, 2]
 
   Returns:
     coco_predictions: prediction in COCO annotation format.
   """
   coco_predictions = []
   num_batches = len(predictions['source_id'])
   max_num_detections = predictions['detection_classes'][0].shape[1]
@@ -140,48 +141,65 @@
       predictions['detection_outer_boxes'][i] = box_ops.yxyx_to_xywh(
           predictions['detection_outer_boxes'][i])
       mask_boxes = predictions['detection_outer_boxes']
     else:
       mask_boxes = predictions['detection_boxes']
 
     batch_size = predictions['source_id'][i].shape[0]
+    if 'detection_keypoints' in predictions:
+      # Adds extra ones to indicate the visibility for each keypoint as is
+      # recommended by MSCOCO. Also, convert keypoint from [y, x] to [x, y]
+      # as mandated by COCO.
+      num_keypoints = predictions['detection_keypoints'][i].shape[2]
+      coco_keypoints = np.concatenate(
+          [
+              predictions['detection_keypoints'][i][..., 1:],
+              predictions['detection_keypoints'][i][..., :1],
+              np.ones([batch_size, max_num_detections, num_keypoints, 1]),
+          ],
+          axis=-1,
+      ).astype(int)
     for j in range(batch_size):
       if 'detection_masks' in predictions:
         image_masks = mask_ops.paste_instance_masks(
             predictions['detection_masks'][i][j],
             mask_boxes[i][j],
             int(predictions['image_info'][i][j, 0, 0]),
-            int(predictions['image_info'][i][j, 0, 1]))
+            int(predictions['image_info'][i][j, 0, 1]),
+        )
         binary_masks = (image_masks > 0.0).astype(np.uint8)
         encoded_masks = [
             mask_api.encode(np.asfortranarray(binary_mask))
-            for binary_mask in list(binary_masks)]
+            for binary_mask in list(binary_masks)
+        ]
       for k in range(max_num_detections):
         ann = {}
         ann['image_id'] = predictions['source_id'][i][j]
         ann['category_id'] = predictions['detection_classes'][i][j, k]
         ann['bbox'] = predictions['detection_boxes'][i][j, k]
         ann['score'] = predictions['detection_scores'][i][j, k]
         if 'detection_masks' in predictions:
           ann['segmentation'] = encoded_masks[k]
+        if 'detection_keypoints' in predictions:
+          ann['keypoints'] = coco_keypoints[j, k].flatten().tolist()
         coco_predictions.append(ann)
 
   for i, ann in enumerate(coco_predictions):
     ann['id'] = i + 1
 
   return coco_predictions
 
 
 def convert_groundtruths_to_coco_dataset(groundtruths, label_map=None):
-  """Converts groundtruths to the dataset in COCO format.
+  """Converts ground-truths to the dataset in COCO format.
 
   Args:
     groundtruths: a dictionary of numpy arrays including the fields below.
       Note that each element in the list represent the number for a single
-      example without batch dimension. K below denotes the actual number of
+      example without batch dimension. 'K' below denotes the actual number of
       instances for each image.
       Required fields:
         - source_id: a list of numpy arrays of int or string of shape
           [batch_size].
         - height: a list of numpy arrays of int of shape [batch_size].
         - width: a list of numpy arrays of int of shape [batch_size].
         - num_detections: a list of numpy arrays of int of shape [batch_size].
@@ -193,31 +211,33 @@
         - is_crowds: a list of numpy arrays of int of shape [batch_size, K]. If
             th field is absent, it is assumed that this instance is not crowd.
         - areas: a list of numy arrays of float of shape [batch_size, K]. If the
             field is absent, the area is calculated using either boxes or
             masks depending on which one is available.
         - masks: a list of numpy arrays of string of shape [batch_size, K],
     label_map: (optional) a dictionary that defines items from the category id
-      to the category name. If `None`, collect the category mappping from the
+      to the category name. If `None`, collect the category mapping from the
       `groundtruths`.
 
   Returns:
-    coco_groundtruths: the groundtruth dataset in COCO format.
+    coco_groundtruths: the ground-truth dataset in COCO format.
   """
   source_ids = np.concatenate(groundtruths['source_id'], axis=0)
   heights = np.concatenate(groundtruths['height'], axis=0)
   widths = np.concatenate(groundtruths['width'], axis=0)
   gt_images = [{'id': int(i), 'height': int(h), 'width': int(w)} for i, h, w
                in zip(source_ids, heights, widths)]
 
   gt_annotations = []
   num_batches = len(groundtruths['source_id'])
   for i in range(num_batches):
-    logging.info(
-        'convert_groundtruths_to_coco_dataset: Processing annotation %d', i)
+    logging.log_every_n(
+        logging.INFO,
+        'convert_groundtruths_to_coco_dataset: Processing annotation %d', 100,
+        i)
     max_num_instances = groundtruths['classes'][i].shape[1]
     batch_size = groundtruths['source_id'][i].shape[0]
     for j in range(batch_size):
       num_instances = groundtruths['num_detections'][i][j]
       if num_instances > max_num_instances:
         logging.warning(
             'num_groundtruths is larger than max_num_instances, %d v.s. %d',
@@ -243,34 +263,46 @@
           ann['area'] = float(
               (boxes[j, k, 3] - boxes[j, k, 1]) *
               (boxes[j, k, 2] - boxes[j, k, 0]))
         if 'masks' in groundtruths:
           if isinstance(groundtruths['masks'][i][j, k], tf.Tensor):
             mask = Image.open(
                 six.BytesIO(groundtruths['masks'][i][j, k].numpy()))
-            width, height = mask.size
-            np_mask = (
-                np.array(mask.getdata()).reshape(height,
-                                                 width).astype(np.uint8))
           else:
             mask = Image.open(
                 six.BytesIO(groundtruths['masks'][i][j, k]))
-            width, height = mask.size
-            np_mask = (
-                np.array(mask.getdata()).reshape(height,
-                                                 width).astype(np.uint8))
+          np_mask = np.array(mask, dtype=np.uint8)
           np_mask[np_mask > 0] = 255
           encoded_mask = mask_api.encode(np.asfortranarray(np_mask))
           ann['segmentation'] = encoded_mask
           # Ensure the content of `counts` is JSON serializable string.
           if 'counts' in ann['segmentation']:
             ann['segmentation']['counts'] = six.ensure_str(
                 ann['segmentation']['counts'])
           if 'areas' not in groundtruths:
             ann['area'] = mask_api.area(encoded_mask)
+        if 'keypoints' in groundtruths:
+          keypoints = groundtruths['keypoints'][i]
+          coco_keypoints = []
+          num_valid_keypoints = 0
+          for z in range(len(keypoints[j, k, :, 1])):
+            # Convert from [y, x] to [x, y] as mandated by COCO.
+            x = float(keypoints[j, k, z, 1])
+            y = float(keypoints[j, k, z, 0])
+            coco_keypoints.append(x)
+            coco_keypoints.append(y)
+            if tf.math.is_nan(x) or tf.math.is_nan(y) or (
+                x == 0 and y == 0):
+              visibility = 0
+            else:
+              visibility = 2
+              num_valid_keypoints = num_valid_keypoints + 1
+            coco_keypoints.append(visibility)
+          ann['keypoints'] = coco_keypoints
+          ann['num_keypoints'] = num_valid_keypoints
         gt_annotations.append(ann)
 
   for i, ann in enumerate(gt_annotations):
     ann['id'] = i + 1
 
   if label_map:
     gt_categories = [{'id': i, 'name': label_map[i]} for i in label_map]
@@ -283,15 +315,15 @@
       'categories': gt_categories,
       'annotations': copy.deepcopy(gt_annotations),
   }
   return gt_dataset
 
 
 class COCOGroundtruthGenerator:
-  """Generates the groundtruth annotations from a single example."""
+  """Generates the ground-truth annotations from a single example."""
 
   def __init__(self, file_pattern, file_type, num_examples, include_mask,
                regenerate_source_id=False):
     self._file_pattern = file_pattern
     self._num_examples = num_examples
     self._include_mask = include_mask
     self._dataset_fn = dataset_fn.pick_dataset_fn(file_type)
@@ -300,19 +332,19 @@
   def _parse_single_example(self, example):
     """Parses a single serialized tf.Example proto.
 
     Args:
       example: a serialized tf.Example proto string.
 
     Returns:
-      A dictionary of groundtruth with the following fields:
+      A dictionary of ground-truth with the following fields:
         source_id: a scalar tensor of int64 representing the image source_id.
         height: a scalar tensor of int64 representing the image height.
         width: a scalar tensor of int64 representing the image width.
-        boxes: a float tensor of shape [K, 4], representing the groundtruth
+        boxes: a float tensor of shape [K, 4], representing the ground-truth
           boxes in absolute coordinates with respect to the original image size.
         classes: a int64 tensor of shape [K], representing the class labels of
           each instances.
         is_crowds: a bool tensor of shape [K], indicating whether the instance
           is crowd.
         areas: a float tensor of shape [K], indicating the area of each
           instance.
@@ -346,15 +378,15 @@
     if self._include_mask:
       groundtruths.update({
           'masks': decoded_tensors['groundtruth_instance_masks_png'],
       })
     return groundtruths
 
   def _build_pipeline(self):
-    """Builds data pipeline to generate groundtruth annotations."""
+    """Builds data pipeline to generate ground-truth annotations."""
     dataset = tf.data.Dataset.list_files(self._file_pattern, shuffle=False)
     dataset = dataset.interleave(
         map_func=lambda filename: self._dataset_fn(filename).prefetch(1),
         cycle_length=None,
         num_parallel_calls=tf.data.experimental.AUTOTUNE)
 
     dataset = dataset.take(self._num_examples)
@@ -378,19 +410,21 @@
   groundtruth_generator = COCOGroundtruthGenerator(
       file_pattern, file_type, num_samples, include_mask, regenerate_source_id)
   generate_annotation_file(groundtruth_generator, annotation_file)
 
 
 def generate_annotation_file(groundtruth_generator,
                              annotation_file):
-  """Generates COCO-style annotation JSON file given a groundtruth generator."""
+  """Generates COCO-style annotation JSON file given a ground-truth generator."""
   groundtruths = {}
   logging.info('Loading groundtruth annotations from dataset to memory...')
   for i, groundtruth in enumerate(groundtruth_generator()):
-    logging.info('generate_annotation_file: Processing annotation %d', i)
+    logging.log_every_n(logging.INFO,
+                        'generate_annotation_file: Processing annotation %d',
+                        100, i)
     for k, v in six.iteritems(groundtruth):
       if k not in groundtruths:
         groundtruths[k] = [v]
       else:
         groundtruths[k].append(v)
   gt_dataset = convert_groundtruths_to_coco_dataset(groundtruths)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/evaluation/coco_utils_test.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/dataloaders/segmentation_input_3d_test.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,49 +1,62 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Tests for coco_utils."""
+"""Tests for segmentation_input_3d.py."""
 
 import os
 
-import tensorflow as tf
+from absl.testing import parameterized
+import tensorflow as tf, tf_keras
 
+from official.projects.volumetric_models.dataloaders import segmentation_input_3d
 from official.vision.dataloaders import tfexample_utils
-from official.vision.evaluation import coco_utils
 
 
-class CocoUtilsTest(tf.test.TestCase):
+class InputReaderTest(parameterized.TestCase, tf.test.TestCase):
 
-  def test_scan_and_generator_annotation_file(self):
-    num_samples = 10
-    example = tfexample_utils.create_detection_test_example(
-        image_height=512, image_width=512, image_channel=3, num_instances=10)
-    tf_examples = [example] * num_samples
-    data_file = os.path.join(self.create_tempdir(), 'test.tfrecord')
-    tfexample_utils.dump_to_tfrecord(
-        record_file=data_file, tf_examples=tf_examples)
-    annotation_file = os.path.join(self.create_tempdir(), 'annotation.json')
-
-    coco_utils.scan_and_generator_annotation_file(
-        file_pattern=data_file,
-        file_type='tfrecord',
-        num_samples=num_samples,
-        include_mask=True,
-        annotation_file=annotation_file)
-    self.assertTrue(
-        tf.io.gfile.exists(annotation_file),
-        msg='Annotation file {annotation_file} does not exists.')
+  def setUp(self):
+    super().setUp()
+    data_dir = os.path.join(self.get_temp_dir(), 'data')
+    tf.io.gfile.makedirs(data_dir)
+    self._data_path = os.path.join(data_dir, 'data.tfrecord')
+    self._example = tfexample_utils.create_3d_image_test_example(
+        image_height=32, image_width=32, image_volume=32, image_channel=2)
+
+  @parameterized.parameters(
+      ([32, 32, 32], 2, 2, False),
+      ([32, 32, 32], 2, 2, True),
+  )
+  def testSegmentationInputReader(self, input_size, num_classes, num_channels,
+                                  is_training):
+
+    decoder = segmentation_input_3d.Decoder()
+    parser = segmentation_input_3d.Parser(
+        input_size=input_size,
+        num_classes=num_classes,
+        num_channels=num_channels)
+
+    decoded_tensor = decoder.decode(self._example.SerializeToString())
+    image, labels = parser.parse_fn(is_training=is_training)(decoded_tensor)
+
+    # Checks image shape.
+    self.assertEqual(
+        list(image.numpy().shape),
+        [input_size[0], input_size[1], input_size[2], num_channels])
+    self.assertEqual(
+        list(labels.numpy().shape),
+        [input_size[0], input_size[1], input_size[2], num_classes])
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/evaluation/panoptic_quality_evaluator.py` & `tf-models-no-deps-2.16.0/official/vision/evaluation/panoptic_quality_evaluator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -23,15 +23,15 @@
       evaluator.update_state(groundtruths, predictions)
     evaluator.result()  # finish one full eval and reset states.
 
 See also: https://github.com/cocodataset/cocoapi/
 """
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.evaluation import panoptic_quality
 
 
 def _crop_padding(mask, image_info):
   """Crops padded masks to match original image shape.
 
@@ -56,22 +56,22 @@
                offset, is_thing=None, rescale_predictions=False):
     """Constructs Panoptic Quality evaluation class.
 
     The class provides the interface to Panoptic Quality metrics_fn.
 
     Args:
       num_categories: The number of segmentation categories (or "classes" in the
-        dataset.
+        dataset).
       ignored_label: A category id that is ignored in evaluation, e.g. the void
         label as defined in COCO panoptic segmentation dataset.
       max_instances_per_category: The maximum number of instances for each
         category. Used in ensuring unique instance labels.
       offset: The maximum number of unique labels. This is used, by multiplying
         the ground-truth labels, to generate unique ids for individual regions
-        of overlap between groundtruth and predicted segments.
+        of overlap between ground-truth and predicted segments.
       is_thing: A boolean array of length `num_categories`. The entry
         `is_thing[category_id]` is True iff that category is a "thing" category
         instead of "stuff." Default to `None`, and it means categories are not
         classified into these two categories.
       rescale_predictions: `bool`, whether to scale back prediction to original
         image sizes. If True, groundtruths['image_info'] is used to rescale
         predictions.
@@ -119,15 +119,15 @@
         numpy_predictions[key] = val
     else:
       numpy_predictions = predictions
 
     return numpy_groundtruths, numpy_predictions
 
   def update_state(self, groundtruths, predictions):
-    """Update and aggregate detection results and groundtruth data.
+    """Update and aggregate detection results and ground-truth data.
 
     Args:
       groundtruths: a dictionary of Tensors including the fields below. See also
         different parsers under `../dataloader` for more details.
         Required fields:
           - category_mask: a numpy array of uint16 of shape [batch_size, H, W].
           - instance_mask: a numpy array of uint16 of shape [batch_size, H, W].
@@ -141,15 +141,15 @@
       predictions: a dictionary of tensors including the fields below. See
         different parsers under `../dataloader` for more details.
         Required fields:
           - category_mask: a numpy array of uint16 of shape [batch_size, H, W].
           - instance_mask: a numpy array of uint16 of shape [batch_size, H, W].
 
     Raises:
-      ValueError: if the required prediction or groundtruth fields are not
+      ValueError: if the required prediction or ground-truth fields are not
         present in the incoming `predictions` or `groundtruths`.
     """
     groundtruths, predictions = self._convert_to_numpy(groundtruths,
                                                        predictions)
     for k in self._required_prediction_fields:
       if k not in predictions:
         raise ValueError(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/evaluation/panoptic_quality_evaluator_test.py` & `tf-models-no-deps-2.16.0/official/vision/evaluation/panoptic_quality_evaluator_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for panoptic_quality_evaluator."""
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.evaluation import panoptic_quality_evaluator
 
 
 class PanopticQualityEvaluatorTest(tf.test.TestCase):
 
   def test_multiple_batches(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/evaluation/segmentation_metrics_test.py` & `tf-models-no-deps-2.16.0/official/vision/evaluation/segmentation_metrics_test.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for segmentation_metrics."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.evaluation import segmentation_metrics
 
 
 class SegmentationMetricsTest(parameterized.TestCase, tf.test.TestCase):
 
   def _create_test_data(self):
@@ -39,35 +39,57 @@
             tf.ones([1, 6, 6, 1], dtype=tf.bool),
         'image_info':
             tf.constant([[[6, 6], [3, 3], [0.5, 0.5], [0, 0]]],
                         dtype=tf.float32)
     }
     return y_pred, y_true
 
-  @parameterized.parameters(True, False)
-  def test_mean_iou_metric(self, rescale_predictions):
+  @parameterized.parameters((True, True), (False, False), (True, False),
+                            (False, True))
+  def test_mean_iou_metric(self, rescale_predictions, use_v2):
     tf.config.experimental_run_functions_eagerly(True)
-    mean_iou_metric = segmentation_metrics.MeanIoU(
-        num_classes=2, rescale_predictions=rescale_predictions)
+    if use_v2:
+      mean_iou_metric = segmentation_metrics.MeanIoUV2(
+          num_classes=2, rescale_predictions=rescale_predictions)
+    else:
+      mean_iou_metric = segmentation_metrics.MeanIoU(
+          num_classes=2, rescale_predictions=rescale_predictions)
     y_pred, y_true = self._create_test_data()
     # Disable autograph for correct coverage statistics.
     update_fn = tf.autograph.experimental.do_not_convert(
         mean_iou_metric.update_state)
     update_fn(y_true=y_true, y_pred=y_pred)
     miou = mean_iou_metric.result()
     self.assertAlmostEqual(miou.numpy(), 0.762, places=3)
 
-  @parameterized.parameters(True, False)
-  def test_per_class_mean_iou_metric(self, rescale_predictions):
-    per_class_iou_metric = segmentation_metrics.PerClassIoU(
-        num_classes=2, rescale_predictions=rescale_predictions)
+  @parameterized.parameters((True, True), (False, False), (True, False),
+                            (False, True))
+  def test_per_class_mean_iou_metric(self, rescale_predictions, use_v2):
+    if use_v2:
+      per_class_iou_metric = segmentation_metrics.PerClassIoUV2(
+          num_classes=2, rescale_predictions=rescale_predictions)
+    else:
+      per_class_iou_metric = segmentation_metrics.PerClassIoU(
+          num_classes=2, rescale_predictions=rescale_predictions)
     y_pred, y_true = self._create_test_data()
     # Disable autograph for correct coverage statistics.
     update_fn = tf.autograph.experimental.do_not_convert(
         per_class_iou_metric.update_state)
     update_fn(y_true=y_true, y_pred=y_pred)
     per_class_miou = per_class_iou_metric.result()
     self.assertAllClose(per_class_miou.numpy(), [0.857, 0.667], atol=1e-3)
 
+  def test_mean_iou_metric_v2_target_class_ids(self):
+    tf.config.experimental_run_functions_eagerly(True)
+    mean_iou_metric = segmentation_metrics.MeanIoUV2(
+        num_classes=2, target_class_ids=[0])
+    y_pred, y_true = self._create_test_data()
+    # Disable autograph for correct coverage statistics.
+    update_fn = tf.autograph.experimental.do_not_convert(
+        mean_iou_metric.update_state)
+    update_fn(y_true=y_true, y_pred=y_pred)
+    miou = mean_iou_metric.result()
+    self.assertAlmostEqual(miou.numpy(), 0.857, places=3)
+
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/evaluation/wod_detection_evaluator.py` & `tf-models-no-deps-2.16.0/official/vision/evaluation/wod_detection_evaluator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """2D detection evaluator for the Waymo Open Dataset."""
 import pprint
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.vision.ops import box_ops
 from waymo_open_dataset import label_pb2
 from waymo_open_dataset.metrics.python import wod_detection_evaluator
 from waymo_open_dataset.protos import breakdown_pb2
 from waymo_open_dataset.protos import metrics_pb2
 
 
@@ -67,15 +67,15 @@
       if 'frame_id' in k:
         result_tensor_dict[k] = tf.tile([v], [num_valid])
       else:
         result_tensor_dict[k] = tf.gather(v, gather_indices)
     return result_tensor_dict
 
   def update_state(self, groundtruths, predictions):
-    """Update the metrics state with prediction and groundtruth data.
+    """Update the metrics state with prediction and ground-truth data.
 
     Args:
       groundtruths: a dictionary of Tensors including the fields below.
         Required fields:
           - source_id: a numpy array of int or string of shape [batch_size].
           - num_detections: a numpy array of int of shape [batch_size].
           - boxes: a numpy array of float of shape [batch_size, K, 4].
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/losses/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/losses/focal_loss.py` & `tf-models-no-deps-2.16.0/official/vision/losses/focal_loss.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,35 +10,35 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Losses used for detection models."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
-class FocalLoss(tf.keras.losses.Loss):
+class FocalLoss(tf_keras.losses.Loss):
   """Implements a Focal loss for classification problems.
 
   Reference:
     [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002).
   """
 
   def __init__(self,
                alpha,
                gamma,
-               reduction=tf.keras.losses.Reduction.AUTO,
+               reduction=tf_keras.losses.Reduction.AUTO,
                name=None):
     """Initializes `FocalLoss`.
 
     Args:
       alpha: The `alpha` weight factor for binary class imbalance.
       gamma: The `gamma` focusing parameter to re-weight loss.
-      reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to
+      reduction: (Optional) Type of `tf_keras.losses.Reduction` to apply to
         loss. Default value is `AUTO`. `AUTO` indicates that the reduction
         option will be determined by the usage context. For almost all cases
         this defaults to `SUM_OVER_BATCH_SIZE`. When used with
         `tf.distribute.Strategy`, outside of built-in training loops such as
         `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE`
         will raise an error. Please see this custom training [tutorial](
           https://www.tensorflow.org/tutorials/distribute/custom_training) for
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/losses/loss_utils.py` & `tf-models-no-deps-2.16.0/official/vision/losses/loss_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Losses utilities for detection models."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def multi_level_flatten(multi_level_inputs, last_dim=None):
   """Flattens a multi-level input.
 
   Args:
     multi_level_inputs: Ordered Dict with level to [batch, d1, ..., dm].
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/losses/maskrcnn_losses.py` & `tf-models-no-deps-2.16.0/official/vision/losses/maskrcnn_losses.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,45 +1,45 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Losses for maskrcn model."""
+"""Losses for maskrcnn model."""
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class RpnScoreLoss(object):
   """Region Proposal Network score loss function."""
 
   def __init__(self, rpn_batch_size_per_im):
     self._rpn_batch_size_per_im = rpn_batch_size_per_im
-    self._binary_crossentropy = tf.keras.losses.BinaryCrossentropy(
-        reduction=tf.keras.losses.Reduction.SUM, from_logits=True)
+    self._binary_crossentropy = tf_keras.losses.BinaryCrossentropy(
+        reduction=tf_keras.losses.Reduction.SUM, from_logits=True)
 
   def __call__(self, score_outputs, labels):
     """Computes total RPN detection loss.
 
     Computes total RPN detection loss including box and score from all levels.
 
     Args:
       score_outputs: an OrderDict with keys representing levels and values
         representing scores in [batch_size, height, width, num_anchors].
       labels: the dictionary that returned from dataloader that includes
-        groundturth targets.
+        ground-truth targets.
 
     Returns:
       rpn_score_loss: a scalar tensor representing total score loss.
     """
     with tf.name_scope('rpn_loss'):
       levels = sorted(score_outputs.keys())
 
@@ -48,15 +48,15 @@
         score_losses.append(
             self._rpn_score_loss(
                 score_outputs[level],
                 labels[level],
                 normalizer=tf.cast(
                     tf.shape(score_outputs[level])[0] *
                     self._rpn_batch_size_per_im,
-                    dtype=tf.float32)))
+                    dtype=score_outputs[level].dtype)))
 
       # Sums per level losses to total loss.
       return tf.math.add_n(score_losses)
 
   def _rpn_score_loss(self, score_outputs, score_targets, normalizer=1.0):
     """Computes score loss."""
     # score_targets has three values:
@@ -82,28 +82,28 @@
 class RpnBoxLoss(object):
   """Region Proposal Network box regression loss function."""
 
   def __init__(self, huber_loss_delta: float):
     # The delta is typically around the mean value of regression target.
     # for instances, the regression targets of 512x512 input with 6 anchors on
     # P2-P6 pyramid is about [0.1, 0.1, 0.2, 0.2].
-    self._huber_loss = tf.keras.losses.Huber(
-        delta=huber_loss_delta, reduction=tf.keras.losses.Reduction.SUM)
+    self._huber_loss = tf_keras.losses.Huber(
+        delta=huber_loss_delta, reduction=tf_keras.losses.Reduction.SUM)
 
   def __call__(self, box_outputs, labels):
     """Computes total RPN detection loss.
 
     Computes total RPN detection loss including box and score from all levels.
 
     Args:
       box_outputs: an OrderDict with keys representing levels and values
-        representing box regression targets in
-        [batch_size, height, width, num_anchors * 4].
+        representing box regression targets in [batch_size, height, width,
+        num_anchors * 4].
       labels: the dictionary that returned from dataloader that includes
-        groundturth targets.
+        ground-truth targets.
 
     Returns:
       rpn_box_loss: a scalar tensor representing total box regression loss.
     """
     with tf.name_scope('rpn_loss'):
       levels = sorted(box_outputs.keys())
 
@@ -113,84 +113,160 @@
 
       # Sum per level losses to total loss.
       return tf.add_n(box_losses)
 
   def _rpn_box_loss(self, box_outputs, box_targets, normalizer=1.0):
     """Computes box regression loss."""
     with tf.name_scope('rpn_box_loss'):
-      mask = tf.cast(tf.not_equal(box_targets, 0.0), dtype=tf.float32)
+      _, height, width, num_anchors_vertices = box_targets.get_shape().as_list()
+      # (batch_size, height, width, num_anchors, 4)
+      reshaped_box_targets = tf.reshape(
+          box_targets, [-1, height, width, num_anchors_vertices // 4, 4])
+      # The box is valid if at least one of the ymin, xmin, ymax, ymax is not 0.
+      # (batch_size, height, width, num_anchors)
+      valid_mask = tf.reduce_any(
+          tf.math.abs(reshaped_box_targets) > 1e-6, axis=-1)
+      # (batch_size, height, width, num_anchors * 4)
+      valid_mask = tf.cast(
+          tf.repeat(valid_mask, 4, axis=-1), dtype=box_outputs.dtype)
+      # (batch_size, height, width, num_anchors * 4, 1)
       box_targets = tf.expand_dims(box_targets, axis=-1)
+      # (batch_size, height, width, num_anchors * 4, 1)
       box_outputs = tf.expand_dims(box_outputs, axis=-1)
-      box_loss = self._huber_loss(box_targets, box_outputs, sample_weight=mask)
+      box_loss = self._huber_loss(
+          box_targets, box_outputs, sample_weight=valid_mask)
       # The loss is normalized by the sum of non-zero weights and additional
       # normalizer provided by the function caller. Using + 0.01 here to avoid
-      # division by zero.
-      box_loss /= normalizer * (tf.reduce_sum(mask) + 0.01)
+      # division by zero. For each replica, get the sum of non-zero masks. Then
+      # get the mean of sums from all replicas. Note there is an extra division
+      # by `num_replicas` in train_step(). So it is equivalent to normalizing
+      # the box loss by the global sum of non-zero masks.
+      replica_context = tf.distribute.get_replica_context()
+      valid_mask = tf.reduce_sum(valid_mask)
+      valid_mask_mean = replica_context.all_reduce(
+          tf.distribute.ReduceOp.MEAN, valid_mask
+      )
+      box_loss /= normalizer * (valid_mask_mean + 0.01)
       return box_loss
 
 
 class FastrcnnClassLoss(object):
   """Fast R-CNN classification loss function."""
 
-  def __init__(self):
-    self._categorical_crossentropy = tf.keras.losses.CategoricalCrossentropy(
-        reduction=tf.keras.losses.Reduction.SUM, from_logits=True)
+  def __init__(self,
+               use_binary_cross_entropy: bool = False,
+               top_k_percent: float = 1.0):
+    """Initializes loss computation.
+
+    Args:
+      use_binary_cross_entropy: If true, uses binary cross entropy loss,
+        otherwise uses categorical cross entropy loss.
+      top_k_percent: a float, the value lies in [0.0, 1.0]. When its value < 1.,
+        only aggregate the top k percent of losses. This is useful for hard
+        example mining.
+    """
+    self._use_binary_cross_entropy = use_binary_cross_entropy
+    self._top_k_percent = top_k_percent
 
-  def __call__(self, class_outputs, class_targets):
+  def __call__(self, class_outputs, class_targets, class_weights=None):
     """Computes the class loss (Fast-RCNN branch) of Mask-RCNN.
 
     This function implements the classification loss of the Fast-RCNN.
 
-    The classification loss is softmax on all RoIs.
-    Reference: https://github.com/facebookresearch/Detectron/blob/master/detectron/modeling/fast_rcnn_heads.py  # pylint: disable=line-too-long
+    The classification loss is categorical (or binary) cross entropy on all
+    RoIs.
+    Reference:
+    https://github.com/facebookresearch/Detectron/blob/master/detectron/modeling/fast_rcnn_heads.py
+    # pylint: disable=line-too-long
 
     Args:
-      class_outputs: a float tensor representing the class prediction for each box
-        with a shape of [batch_size, num_boxes, num_classes].
+      class_outputs: a float tensor representing the class prediction for each
+        box with a shape of [batch_size, num_boxes, num_classes].
       class_targets: a float tensor representing the class label for each box
         with a shape of [batch_size, num_boxes].
+      class_weights: A float list containing the weight of each class.
 
     Returns:
       a scalar tensor representing total class loss.
     """
     with tf.name_scope('fast_rcnn_loss'):
-      batch_size, num_boxes, num_classes = class_outputs.get_shape().as_list()
-      class_targets = tf.cast(class_targets, dtype=tf.int32)
-      class_targets_one_hot = tf.one_hot(class_targets, num_classes)
-      return self._fast_rcnn_class_loss(class_outputs, class_targets_one_hot,
-                                        normalizer=batch_size * num_boxes)
-
-  def _fast_rcnn_class_loss(self, class_outputs, class_targets_one_hot,
-                            normalizer=1.0):
-    """Computes classification loss."""
-    with tf.name_scope('fast_rcnn_class_loss'):
-      class_loss = self._categorical_crossentropy(class_targets_one_hot,
-                                                  class_outputs)
+      output_dtype = class_outputs.dtype
+      num_classes = class_outputs.get_shape().as_list()[-1]
+      class_weights = (
+          class_weights if class_weights is not None else [1.0] * num_classes
+      )
+      if num_classes != len(class_weights):
+        raise ValueError(
+            'Length of class_weights should be {}'.format(num_classes)
+        )
+
+      class_weights = tf.constant(class_weights, dtype=output_dtype)
+
+      class_targets_one_hot = tf.one_hot(
+          tf.cast(class_targets, dtype=tf.int32),
+          num_classes,
+          dtype=class_outputs.dtype)
+      if self._use_binary_cross_entropy:
+        # (batch_size, num_boxes, num_classes)
+        cross_entropy_loss = tf.nn.sigmoid_cross_entropy_with_logits(
+            labels=class_targets_one_hot, logits=class_outputs)
+        cross_entropy_loss *= class_weights
+      else:
+        # (batch_size, num_boxes)
+        cross_entropy_loss = tf.nn.softmax_cross_entropy_with_logits(
+            labels=class_targets_one_hot, logits=class_outputs)
+        class_weight_mask = tf.einsum(
+            '...y,y->...', class_targets_one_hot, class_weights
+        )
+        cross_entropy_loss *= class_weight_mask
+
+      if self._top_k_percent < 1.0:
+        return self.aggregate_loss_top_k(cross_entropy_loss)
+      else:
+        return tf.reduce_mean(cross_entropy_loss)
 
-      class_loss /= normalizer
-      return class_loss
+  def aggregate_loss_top_k(self, loss, num_valid_values=None):
+    """Aggregate the top-k the greatest loss values.
+
+    Args:
+      loss: a float tensor in shape (batch_size, num_boxes) or (batch_size,
+        num_boxes, num_classes) which stores the loss values.
+      num_valid_values: the number of loss values which are not ignored. The
+        default value is None, which means all the loss values are valid.
+
+    Returns:
+      A 0-D float which stores the overall loss of the batch.
+    """
+    loss = tf.reshape(loss, shape=[-1])
+    top_k_num = tf.cast(
+        self._top_k_percent * tf.size(loss, out_type=tf.float32), tf.int32)
+    top_k_losses, _ = tf.math.top_k(loss, k=top_k_num)
+    normalizer = tf.cast(top_k_num, loss.dtype)
+    if num_valid_values is not None:
+      normalizer = tf.minimum(normalizer, tf.cast(num_valid_values, loss.dtype))
+    return tf.reduce_sum(top_k_losses) / (normalizer + 1e-5)
 
 
 class FastrcnnBoxLoss(object):
   """Fast R-CNN box regression loss function."""
 
   def __init__(self,
                huber_loss_delta: float,
                class_agnostic_bbox_pred: bool = False):
     """Initiate Faster RCNN box loss.
 
     Args:
       huber_loss_delta: the delta is typically around the mean value of
-        regression target. for instances, the regression targets of 512x512
+        regression target. For instances, the regression targets of 512x512
         input with 6 anchors on P2-P6 pyramid is about [0.1, 0.1, 0.2, 0.2].
       class_agnostic_bbox_pred: if True, class agnostic bounding box prediction
         is performed.
     """
-    self._huber_loss = tf.keras.losses.Huber(
-        delta=huber_loss_delta, reduction=tf.keras.losses.Reduction.SUM)
+    self._huber_loss = tf_keras.losses.Huber(
+        delta=huber_loss_delta, reduction=tf_keras.losses.Reduction.SUM)
     self._class_agnostic_bbox_pred = class_agnostic_bbox_pred
 
   def __call__(self, box_outputs, class_targets, box_targets):
     """Computes the box loss (Fast-RCNN branch) of Mask-RCNN.
 
     This function implements the box regression loss of the Fast-RCNN. As the
     `box_outputs` produces `num_classes` boxes for each RoI, the reference model
@@ -218,70 +294,65 @@
       if not self._class_agnostic_bbox_pred:
         box_outputs = self._assign_class_targets(box_outputs, class_targets)
 
       return self._fast_rcnn_box_loss(box_outputs, box_targets, class_targets)
 
   def _assign_class_targets(self, box_outputs, class_targets):
     """Selects the box from `box_outputs` based on `class_targets`, with which the box has the maximum overlap."""
-    (batch_size, num_rois,
-     num_class_specific_boxes) = box_outputs.get_shape().as_list()
+    _, num_rois, num_class_specific_boxes = box_outputs.get_shape().as_list()
     num_classes = num_class_specific_boxes // 4
-    box_outputs = tf.reshape(box_outputs,
-                             [batch_size, num_rois, num_classes, 4])
-
-    box_indices = tf.reshape(
-        class_targets + tf.tile(
-            tf.expand_dims(tf.range(batch_size) * num_rois * num_classes, 1),
-            [1, num_rois]) + tf.tile(
-                tf.expand_dims(tf.range(num_rois) * num_classes, 0),
-                [batch_size, 1]), [-1])
-
-    box_outputs = tf.matmul(
-        tf.one_hot(
-            box_indices,
-            batch_size * num_rois * num_classes,
-            dtype=box_outputs.dtype), tf.reshape(box_outputs, [-1, 4]))
-    box_outputs = tf.reshape(box_outputs, [batch_size, -1, 4])
-
-    return box_outputs
+    box_outputs = tf.reshape(box_outputs, [-1, num_rois, num_classes, 4])
+    class_targets_ont_hot = tf.one_hot(
+        class_targets, num_classes, dtype=box_outputs.dtype
+    )
+    return tf.einsum('bnij,bni->bnj', box_outputs, class_targets_ont_hot)
 
   def _fast_rcnn_box_loss(self, box_outputs, box_targets, class_targets,
                           normalizer=1.0):
     """Computes box regression loss."""
     with tf.name_scope('fast_rcnn_box_loss'):
-      mask = tf.tile(tf.expand_dims(tf.greater(class_targets, 0), axis=2),
-                     [1, 1, 4])
-      mask = tf.cast(mask, dtype=tf.float32)
+      mask = tf.tile(
+          tf.expand_dims(tf.greater(class_targets, 0), axis=2), [1, 1, 4])
+      mask = tf.cast(mask, dtype=box_outputs.dtype)
       box_targets = tf.expand_dims(box_targets, axis=-1)
       box_outputs = tf.expand_dims(box_outputs, axis=-1)
       box_loss = self._huber_loss(box_targets, box_outputs, sample_weight=mask)
       # The loss is normalized by the number of ones in mask,
-      # additianal normalizer provided by the user and using 0.01 here to avoid
-      # division by 0.
-      box_loss /= normalizer * (tf.reduce_sum(mask) + 0.01)
+      # additional normalizer provided by the user and using 0.01 here to avoid
+      # division by 0. For each replica, get the sum of non-zero masks. Then
+      # get the mean of sums from all replicas. Note there is an extra division
+      # by `num_replicas` in train_step(). So it is equivalent to normalizing
+      # the box loss by the global sum of non-zero masks.
+      replica_context = tf.distribute.get_replica_context()
+      mask = tf.reduce_sum(mask)
+      mask_mean = replica_context.all_reduce(
+          tf.distribute.ReduceOp.MEAN, mask
+      )
+      box_loss /= normalizer * (mask_mean + 0.01)
       return box_loss
 
 
 class MaskrcnnLoss(object):
   """Mask R-CNN instance segmentation mask loss function."""
 
   def __init__(self):
-    self._binary_crossentropy = tf.keras.losses.BinaryCrossentropy(
-        reduction=tf.keras.losses.Reduction.SUM, from_logits=True)
+    self._binary_crossentropy = tf_keras.losses.BinaryCrossentropy(
+        reduction=tf_keras.losses.Reduction.SUM, from_logits=True)
 
   def __call__(self, mask_outputs, mask_targets, select_class_targets):
     """Computes the mask loss of Mask-RCNN.
 
     This function implements the mask loss of Mask-RCNN. As the `mask_outputs`
     produces `num_classes` masks for each RoI, the reference model expands
     `mask_targets` to match the shape of `mask_outputs` and selects only the
     target that the RoI has a maximum overlap. (Reference: https://github.com/facebookresearch/Detectron/blob/master/detectron/roi_data/mask_rcnn.py)  # pylint: disable=line-too-long
-    Instead, this implementation selects the `mask_outputs` by the `class_targets`
-    so that it doesn't expand `mask_targets`. Note that the selection logic is
-    done in the post-processing of mask_rcnn_fn in mask_rcnn_architecture.py.
+    Instead, this implementation selects the `mask_outputs` by the
+    `class_targets` so that it doesn't expand `mask_targets`. Note that the
+    selection logic is done in the post-processing of mask_rcnn_fn in
+    mask_rcnn_architecture.py.
 
     Args:
       mask_outputs: a float tensor representing the prediction for each mask,
         with a shape of
         [batch_size, num_masks, mask_height, mask_width].
       mask_targets: a float tensor representing the binary mask of ground truth
         labels for each mask with a shape of
@@ -289,24 +360,31 @@
       select_class_targets: a tensor with a shape of [batch_size, num_masks],
         representing the foreground mask targets.
 
     Returns:
       mask_loss: a float tensor representing total mask loss.
     """
     with tf.name_scope('mask_rcnn_loss'):
-      (batch_size, num_masks, mask_height,
-       mask_width) = mask_outputs.get_shape().as_list()
+      _, _, mask_height, mask_width = mask_outputs.get_shape().as_list()
 
       weights = tf.tile(
-          tf.reshape(tf.greater(select_class_targets, 0),
-                     [batch_size, num_masks, 1, 1]),
-          [1, 1, mask_height, mask_width])
-      weights = tf.cast(weights, dtype=tf.float32)
+          tf.greater(select_class_targets, 0)[:, :, tf.newaxis, tf.newaxis],
+          [1, 1, mask_height, mask_width],
+      )
+      weights = tf.cast(weights, dtype=mask_outputs.dtype)
 
       mask_targets = tf.expand_dims(mask_targets, axis=-1)
       mask_outputs = tf.expand_dims(mask_outputs, axis=-1)
       mask_loss = self._binary_crossentropy(mask_targets, mask_outputs,
                                             sample_weight=weights)
-
+      # For each replica, get the sum of non-zero weights. Then get the mean of
+      # sums from all replicas. Note there is an extra division by
+      # `num_replicas` in train_step(). So it is equivalent to normalizing the
+      # mask loss by the global sum of non-zero weights.
+      replica_context = tf.distribute.get_replica_context()
+      weights = tf.reduce_sum(weights)
+      weights_mean = replica_context.all_reduce(
+          tf.distribute.ReduceOp.MEAN, weights
+      )
       # The loss is normalized by the number of 1's in weights and
       # + 0.01 is used to avoid division by zero.
-      return mask_loss / (tf.reduce_sum(weights) + 0.01)
+      return mask_loss / (weights_mean + 0.01)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/losses/retinanet_losses.py` & `tf-models-no-deps-2.16.0/official/vision/losses/retinanet_losses.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Losses used for detection models."""
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def focal_loss(logits, targets, alpha, gamma):
   """Compute the focal loss between `logits` and the golden `target` values.
 
   Focal loss = -(1-pt)^gamma * log(pt)
   where pt is the probability of being classified to the true class.
@@ -49,34 +49,34 @@
     loss = modulator * cross_entropy
     weighted_loss = tf.where(positive_label_mask, alpha * loss,
                              (1.0 - alpha) * loss)
 
   return weighted_loss
 
 
-class FocalLoss(tf.keras.losses.Loss):
+class FocalLoss(tf_keras.losses.Loss):
   """Implements a Focal loss for classification problems.
 
   Reference:
     [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002).
   """
 
   def __init__(self,
                alpha,
                gamma,
                num_classes,
-               reduction=tf.keras.losses.Reduction.AUTO,
+               reduction=tf_keras.losses.Reduction.AUTO,
                name=None):
     """Initializes `FocalLoss`.
 
     Args:
       alpha: The `alpha` weight factor for binary class imbalance.
       gamma: The `gamma` focusing parameter to re-weight loss.
       num_classes: Number of foreground classes.
-      reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to
+      reduction: (Optional) Type of `tf_keras.losses.Reduction` to apply to
         loss. Default value is `AUTO`. `AUTO` indicates that the reduction
         option will be determined by the usage context. For almost all cases
         this defaults to `SUM_OVER_BATCH_SIZE`. When used with
         `tf.distribute.Strategy`, outside of built-in training loops such as
         `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE`
         will raise an error. Please see this custom training [tutorial](
           https://www.tensorflow.org/tutorials/distribute/custom_training) for
@@ -130,39 +130,39 @@
         'gamma': self._gamma,
         'num_classes': self._num_classes,
     }
     base_config = super(FocalLoss, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
 
-class RetinanetBoxLoss(tf.keras.losses.Loss):
+class RetinanetBoxLoss(tf_keras.losses.Loss):
   """RetinaNet box Huber loss."""
 
   def __init__(self,
                delta,
-               reduction=tf.keras.losses.Reduction.AUTO,
+               reduction=tf_keras.losses.Reduction.AUTO,
                name=None):
     """Initializes `RetinanetBoxLoss`.
 
     Args:
       delta: A float, the point where the Huber loss function changes from a
         quadratic to linear.
-      reduction: (Optional) Type of `tf.keras.losses.Reduction` to apply to
+      reduction: (Optional) Type of `tf_keras.losses.Reduction` to apply to
         loss. Default value is `AUTO`. `AUTO` indicates that the reduction
         option will be determined by the usage context. For almost all cases
         this defaults to `SUM_OVER_BATCH_SIZE`. When used with
         `tf.distribute.Strategy`, outside of built-in training loops such as
         `tf.keras` `compile` and `fit`, using `AUTO` or `SUM_OVER_BATCH_SIZE`
         will raise an error. Please see this custom training [tutorial](
           https://www.tensorflow.org/tutorials/distribute/custom_training) for
             more details.
       name: Optional name for the op. Defaults to 'retinanet_class_loss'.
     """
-    self._huber_loss = tf.keras.losses.Huber(
-        delta=delta, reduction=tf.keras.losses.Reduction.NONE)
+    self._huber_loss = tf_keras.losses.Huber(
+        delta=delta, reduction=tf_keras.losses.Reduction.NONE)
     self._delta = delta
     super(RetinanetBoxLoss, self).__init__(reduction=reduction, name=name)
 
   def call(self, y_true, y_pred):
     """Computes box detection loss.
 
     Computes total detection loss including box and class loss from all levels.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/efficientnet.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/efficientnet.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,23 +15,23 @@
 """Contains definitions of EfficientNet Networks."""
 
 import math
 from typing import Any, List, Tuple
 
 # Import libraries
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.layers import nn_blocks
 from official.vision.modeling.layers import nn_layers
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 # The fixed EfficientNet-B0 architecture discovered by NAS.
 # Each element represents a specification of a building block:
 # (block_fn, block_repeats, kernel_size, strides, expand_ratio, in_filters,
 # out_filters, is_output)
 EN_B0_BLOCK_SPECS = [
     ('mbconv', 1, 3, 1, 1, 32, 16, False),
@@ -88,81 +88,82 @@
         width_scale,
         depth_scale,
     )
     decoded_specs.append(BlockSpec(*s))
   return decoded_specs
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class EfficientNet(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class EfficientNet(tf_keras.Model):
   """Creates an EfficientNet family model.
 
   This implements the EfficientNet model from:
     Mingxing Tan, Quoc V. Le.
     EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.
     (https://arxiv.org/pdf/1905.11946)
   """
 
   def __init__(self,
                model_id: str,
-               input_specs: tf.keras.layers.InputSpec = layers.InputSpec(
+               input_specs: tf_keras.layers.InputSpec = layers.InputSpec(
                    shape=[None, None, None, 3]),
                se_ratio: float = 0.0,
                stochastic_depth_drop_rate: float = 0.0,
                kernel_initializer: str = 'VarianceScaling',
-               kernel_regularizer: tf.keras.regularizers.Regularizer = None,
-               bias_regularizer: tf.keras.regularizers.Regularizer = None,
+               kernel_regularizer: tf_keras.regularizers.Regularizer = None,
+               bias_regularizer: tf_keras.regularizers.Regularizer = None,
                activation: str = 'relu',
+               se_inner_activation: str = 'relu',
                use_sync_bn: bool = False,
                norm_momentum: float = 0.99,
                norm_epsilon: float = 0.001,  # pytype: disable=annotation-type-mismatch  # typed-keras
                **kwargs):
     """Initializes an EfficientNet model.
 
     Args:
       model_id: A `str` of model ID of EfficientNet.
-      input_specs: A `tf.keras.layers.InputSpec` of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of the input tensor.
       se_ratio: A `float` of squeeze and excitation ratio for inverted
         bottleneck blocks.
       stochastic_depth_drop_rate: A `float` of drop rate for drop connect layer.
       kernel_initializer: A `str` for kernel initializer of convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       activation: A `str` of name of the activation function.
+      se_inner_activation: A `str` of name of the activation function used in
+        Sequeeze and Excitation layer.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._model_id = model_id
     self._input_specs = input_specs
     self._se_ratio = se_ratio
     self._stochastic_depth_drop_rate = stochastic_depth_drop_rate
     self._use_sync_bn = use_sync_bn
     self._activation = activation
+    self._se_inner_activation = se_inner_activation
     self._kernel_initializer = kernel_initializer
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
-    if use_sync_bn:
-      self._norm = layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = layers.BatchNormalization
+    self._norm = layers.BatchNormalization
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       bn_axis = -1
     else:
       bn_axis = 1
 
     # Build EfficientNet.
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
     width_scale = SCALING_MAP[model_id]['width_scale']
     depth_scale = SCALING_MAP[model_id]['depth_scale']
 
     # Build stem.
     x = layers.Conv2D(
         filters=nn_layers.round_filters(32, width_scale),
         kernel_size=3,
@@ -170,15 +171,18 @@
         use_bias=False,
         padding='same',
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)(
             inputs)
     x = self._norm(
-        axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)(
+        axis=bn_axis,
+        momentum=norm_momentum,
+        epsilon=norm_epsilon,
+        synchronized=use_sync_bn)(
             x)
     x = tf_utils.get_activation(activation)(x)
 
     # Build intermediate blocks.
     endpoints = {}
     endpoint_level = 2
     decoded_specs = block_spec_decoder(EN_B0_BLOCK_SPECS, width_scale,
@@ -202,15 +206,18 @@
         use_bias=False,
         padding='same',
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)(
             x)
     x = self._norm(
-        axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)(
+        axis=bn_axis,
+        momentum=norm_momentum,
+        epsilon=norm_epsilon,
+        synchronized=use_sync_bn)(
             x)
     endpoints[str(endpoint_level)] = tf_utils.get_activation(activation)(x)
 
     super(EfficientNet, self).__init__(
         inputs=inputs, outputs=endpoints, **kwargs)
 
   def _block_group(self,
@@ -240,14 +247,15 @@
         kernel_size=specs.kernel_size,
         se_ratio=self._se_ratio,
         stochastic_depth_drop_rate=self._stochastic_depth_drop_rate,
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer,
         activation=self._activation,
+        se_inner_activation=self._se_inner_activation,
         use_sync_bn=self._use_sync_bn,
         norm_momentum=self._norm_momentum,
         norm_epsilon=self._norm_epsilon)(
             inputs)
 
     for _ in range(1, specs.block_repeats):
       x = block_fn(
@@ -258,14 +266,15 @@
           kernel_size=specs.kernel_size,
           se_ratio=self._se_ratio,
           stochastic_depth_drop_rate=self._stochastic_depth_drop_rate,
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer,
           activation=self._activation,
+          se_inner_activation=self._se_inner_activation,
           use_sync_bn=self._use_sync_bn,
           norm_momentum=self._norm_momentum,
           norm_epsilon=self._norm_epsilon)(
               x)
 
     return tf.identity(x, name=name)
 
@@ -292,18 +301,19 @@
   def output_specs(self):
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
 @factory.register_backbone_builder('efficientnet')
 def build_efficientnet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
+    l2_regularizer: tf_keras.regularizers.Regularizer = None,
+    se_inner_activation: str = 'relu') -> tf_keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds EfficientNet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'efficientnet', (f'Inconsistent backbone type '
                                            f'{backbone_type}')
 
   return EfficientNet(
@@ -311,8 +321,9 @@
       input_specs=input_specs,
       stochastic_depth_drop_rate=backbone_cfg.stochastic_depth_drop_rate,
       se_ratio=backbone_cfg.se_ratio,
       activation=norm_activation_config.activation,
       use_sync_bn=norm_activation_config.use_sync_bn,
       norm_momentum=norm_activation_config.norm_momentum,
       norm_epsilon=norm_activation_config.norm_epsilon,
-      kernel_regularizer=l2_regularizer)
+      kernel_regularizer=l2_regularizer,
+      se_inner_activation=se_inner_activation)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/efficientnet_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/efficientnet_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,29 +12,29 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for EfficientNet."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import efficientnet
 
 
 class EfficientNetTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(32, 224)
   def test_network_creation(self, input_size):
     """Test creation of EfficientNet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     network = efficientnet.EfficientNet(model_id='b0')
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
 
     self.assertAllEqual([1, input_size / 2**2, input_size / 2**2, 24],
                         endpoints['2'].shape.as_list())
     self.assertAllEqual([1, input_size / 2**3, input_size / 2**3, 40],
                         endpoints['3'].shape.as_list())
     self.assertAllEqual([1, input_size / 2**4, input_size / 2**4, 112],
@@ -46,32 +46,32 @@
   def test_network_scaling(self, model_id):
     """Test compound scaling."""
     efficientnet_params = {
         'b0': 4049564,
         'b3': 10783528,
         'b6': 40960136,
     }
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     input_size = 32
     network = efficientnet.EfficientNet(model_id=model_id, se_ratio=0.25)
     self.assertEqual(network.count_params(), efficientnet_params[model_id])
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     _ = network(inputs)
 
   @parameterized.parameters(1, 3)
   def test_input_specs(self, input_dim):
     """Test different input feature dimensions."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, input_dim])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, input_dim])
     network = efficientnet.EfficientNet(model_id='b0', input_specs=input_specs)
 
-    inputs = tf.keras.Input(shape=(128, 128, input_dim), batch_size=1)
+    inputs = tf_keras.Input(shape=(128, 128, input_dim), batch_size=1)
     _ = network(inputs)
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     kwargs = dict(
         model_id='b0',
         se_ratio=0.25,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/factory.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/factory.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -41,15 +41,15 @@
 
 
 """
 from typing import Sequence, Union
 
 # Import libraries
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import registry
 from official.modeling import hyperparams
 
 
 _REGISTERED_BACKBONE_CLS = {}
 
@@ -57,15 +57,15 @@
 def register_backbone_builder(key: str):
   """Decorates a builder of backbone class.
 
   The builder should be a Callable (a class or a function).
   This decorator supports registration of backbone builder as follows:
 
   ```
-  class MyBackbone(tf.keras.Model):
+  class MyBackbone(tf_keras.Model):
     pass
 
   @register_backbone_builder('mybackbone')
   def builder(input_specs, config, l2_reg):
     return MyBackbone(...)
 
   # Builds a MyBackbone object.
@@ -78,32 +78,32 @@
   Returns:
     A callable for using as class decorator that registers the decorated class
     for creation from an instance of task_config_cls.
   """
   return registry.register(_REGISTERED_BACKBONE_CLS, key)
 
 
-def build_backbone(input_specs: Union[tf.keras.layers.InputSpec,
-                                      Sequence[tf.keras.layers.InputSpec]],
+def build_backbone(input_specs: Union[tf_keras.layers.InputSpec,
+                                      Sequence[tf_keras.layers.InputSpec]],
                    backbone_config: hyperparams.Config,
                    norm_activation_config: hyperparams.Config,
-                   l2_regularizer: tf.keras.regularizers.Regularizer = None,
-                   **kwargs) -> tf.keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
+                   l2_regularizer: tf_keras.regularizers.Regularizer = None,
+                   **kwargs) -> tf_keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds backbone from a config.
 
   Args:
-    input_specs: A (sequence of) `tf.keras.layers.InputSpec` of input.
+    input_specs: A (sequence of) `tf_keras.layers.InputSpec` of input.
     backbone_config: A `OneOfConfig` of backbone config.
     norm_activation_config: A config for normalization/activation layer.
-    l2_regularizer: A `tf.keras.regularizers.Regularizer` object. Default to
+    l2_regularizer: A `tf_keras.regularizers.Regularizer` object. Default to
       None.
     **kwargs: Additional keyword args to be passed to backbone builder.
 
   Returns:
-    A `tf.keras.Model` instance of the backbone.
+    A `tf_keras.Model` instance of the backbone.
   """
   backbone_builder = registry.lookup(_REGISTERED_BACKBONE_CLS,
                                      backbone_config.type)
 
   return backbone_builder(
       input_specs=input_specs,
       backbone_config=backbone_config,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/factory_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/factory_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for factory functions."""
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from official.vision.configs import backbones as backbones_cfg
 from official.vision.configs import backbones_3d as backbones_3d_cfg
 from official.vision.configs import common as common_cfg
 from official.vision.modeling import backbones
 from official.vision.modeling.backbones import factory
@@ -38,15 +38,15 @@
     backbone_config = backbones_cfg.Backbone(
         type='resnet',
         resnet=backbones_cfg.ResNet(model_id=model_id, se_ratio=0.0))
     norm_activation_config = common_cfg.NormActivation(
         norm_momentum=0.99, norm_epsilon=1e-5, use_sync_bn=False)
 
     factory_network = factory.build_backbone(
-        input_specs=tf.keras.layers.InputSpec(shape=[None, None, None, 3]),
+        input_specs=tf_keras.layers.InputSpec(shape=[None, None, None, 3]),
         backbone_config=backbone_config,
         norm_activation_config=norm_activation_config)
 
     network_config = network.get_config()
     factory_network_config = factory_network.get_config()
 
     self.assertEqual(network_config, factory_network_config)
@@ -69,15 +69,15 @@
         type='efficientnet',
         efficientnet=backbones_cfg.EfficientNet(
             model_id=model_id, se_ratio=se_ratio))
     norm_activation_config = common_cfg.NormActivation(
         norm_momentum=0.99, norm_epsilon=1e-5, use_sync_bn=False)
 
     factory_network = factory.build_backbone(
-        input_specs=tf.keras.layers.InputSpec(shape=[None, None, None, 3]),
+        input_specs=tf_keras.layers.InputSpec(shape=[None, None, None, 3]),
         backbone_config=backbone_config,
         norm_activation_config=norm_activation_config)
 
     network_config = network.get_config()
     factory_network_config = factory_network.get_config()
 
     self.assertEqual(network_config, factory_network_config)
@@ -102,15 +102,15 @@
         type='mobilenet',
         mobilenet=backbones_cfg.MobileNet(
             model_id=model_id, filter_size_scale=filter_size_scale))
     norm_activation_config = common_cfg.NormActivation(
         norm_momentum=0.99, norm_epsilon=1e-5, use_sync_bn=False)
 
     factory_network = factory.build_backbone(
-        input_specs=tf.keras.layers.InputSpec(shape=[None, None, None, 3]),
+        input_specs=tf_keras.layers.InputSpec(shape=[None, None, None, 3]),
         backbone_config=backbone_config,
         norm_activation_config=norm_activation_config)
 
     network_config = network.get_config()
     factory_network_config = factory_network.get_config()
 
     self.assertEqual(network_config, factory_network_config)
@@ -118,15 +118,15 @@
   @combinations.generate(combinations.combine(model_id=['49'],))
   def test_spinenet_creation(self, model_id):
     """Test creation of SpineNet models."""
     input_size = 128
     min_level = 3
     max_level = 7
 
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, input_size, input_size, 3])
     network = backbones.SpineNet(
         input_specs=input_specs,
         min_level=min_level,
         max_level=max_level,
         norm_momentum=0.99,
         norm_epsilon=1e-5)
@@ -134,15 +134,15 @@
     backbone_config = backbones_cfg.Backbone(
         type='spinenet',
         spinenet=backbones_cfg.SpineNet(model_id=model_id))
     norm_activation_config = common_cfg.NormActivation(
         norm_momentum=0.99, norm_epsilon=1e-5, use_sync_bn=False)
 
     factory_network = factory.build_backbone(
-        input_specs=tf.keras.layers.InputSpec(
+        input_specs=tf_keras.layers.InputSpec(
             shape=[None, input_size, input_size, 3]),
         backbone_config=backbone_config,
         norm_activation_config=norm_activation_config)
 
     network_config = network.get_config()
     factory_network_config = factory_network.get_config()
 
@@ -158,15 +158,15 @@
     backbone_config = backbones_cfg.Backbone(
         type='revnet',
         revnet=backbones_cfg.RevNet(model_id=model_id))
     norm_activation_config = common_cfg.NormActivation(
         norm_momentum=0.99, norm_epsilon=1e-5, use_sync_bn=False)
 
     factory_network = factory.build_backbone(
-        input_specs=tf.keras.layers.InputSpec(shape=[None, None, None, 3]),
+        input_specs=tf_keras.layers.InputSpec(shape=[None, None, None, 3]),
         backbone_config=backbone_config,
         norm_activation_config=norm_activation_config)
 
     network_config = network.get_config()
     factory_network_config = factory_network.get_config()
 
     self.assertEqual(network_config, factory_network_config)
@@ -210,15 +210,15 @@
         type='mobiledet',
         mobiledet=backbones_cfg.MobileDet(
             model_id=model_id, filter_size_scale=filter_size_scale))
     norm_activation_config = common_cfg.NormActivation(
         norm_momentum=0.99, norm_epsilon=1e-5, use_sync_bn=False)
 
     factory_network = factory.build_backbone(
-        input_specs=tf.keras.layers.InputSpec(shape=[None, None, None, 3]),
+        input_specs=tf_keras.layers.InputSpec(shape=[None, None, None, 3]),
         backbone_config=backbone_config,
         norm_activation_config=norm_activation_config)
 
     network_config = network.get_config()
     factory_network_config = factory_network.get_config()
 
     self.assertEqual(network_config, factory_network_config)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/mobiledet.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/mobiledet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,30 +13,30 @@
 # limitations under the License.
 
 """Definitions of MobileDet Networks."""
 
 import dataclasses
 from typing import Any, Dict, Optional, Tuple, List
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.backbones import mobilenet
 from official.vision.modeling.layers import nn_blocks
 from official.vision.modeling.layers import nn_layers
 
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 
 #  pylint: disable=pointless-string-statement
 
 """
-Architecture: https://arxiv.org/abs/1704.04861.
+Architecture: https://arxiv.org/abs/2004.14525.
 
 "MobileDets: Searching for Object Detection Architectures for
 Mobile Accelerators" Yunyang Xiong, Hanxiao Liu, Suyog Gupta, Berkin Akin,
 Gabriel Bender, Yongzhe Wang, Pieter-Jan Kindermans, Mingxing Tan, Vikas Singh,
 Bo Chen
 
 Note that `round_down_protection` flag should be set to false for scaling
@@ -340,30 +340,30 @@
                                            divisor=divisible_by,
                                            round_down_protect=False,
                                            min_depth=8)
 
   return decoded_specs
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MobileDet(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MobileDet(tf_keras.Model):
   """Creates a MobileDet family model."""
 
   def __init__(
       self,
       model_id: str = 'MobileDetCPU',
       filter_size_scale: float = 1.0,
-      input_specs: tf.keras.layers.InputSpec = layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = layers.InputSpec(
           shape=[None, None, None, 3]),
       # The followings are for hyper-parameter tuning.
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       # The followings should be kept the same most of the times.
       min_depth: int = 8,
       divisible_by: int = 8,
       regularize_depthwise: bool = False,
       use_sync_bn: bool = False,
       **kwargs):
     """Initializes a MobileDet model.
@@ -371,22 +371,22 @@
     Args:
       model_id: A `str` of MobileDet version. The supported values are
         `MobileDetCPU`, `MobileDetDSP`, `MobileDetEdgeTPU`, `MobileDetGPU`.
       filter_size_scale: A `float` of multiplier for the filters (number of
         channels) for all convolution ops. The value must be greater than zero.
         Typical usage will be to set this value in (0, 1) to reduce the number
         of parameters or computation cost of the model.
-      input_specs: A `tf.keras.layers.InputSpec` of specs of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of specs of the input tensor.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       kernel_initializer: A `str` for kernel initializer of convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       min_depth: An `int` of minimum depth (number of channels) for all
         convolution ops. Enforced when filter_size_scale < 1, and not an active
         constraint when filter_size_scale >= 1.
       divisible_by: An `int` that ensures all inner dimensions are divisible by
         this number.
       regularize_depthwise: If Ture, apply regularization on depthwise.
@@ -409,15 +409,15 @@
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     self._use_sync_bn = use_sync_bn
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
 
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
 
     block_specs = SUPPORTED_SPECS_MAP.get(model_id)
     self._decoded_specs = block_spec_decoder(
         specs=block_specs,
         filter_size_scale=self._filter_size_scale,
         divisible_by=self._get_divisible_by())
 
@@ -518,15 +518,15 @@
             divisible_by=self._get_divisible_by()
         )(net)
 
       else:
         raise ValueError('Unknown block type {} for layer {}'.format(
             block_def.block_fn, i))
 
-      net = tf.keras.layers.Activation('linear', name=block_name)(net)
+      net = tf_keras.layers.Activation('linear', name=block_name)(net)
 
       if block_def.is_output:
         endpoints[str(endpoint_level)] = net
         endpoint_level += 1
 
     return net, endpoints, endpoint_level
 
@@ -554,19 +554,19 @@
   def output_specs(self):
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
 @factory.register_backbone_builder('mobiledet')
 def build_mobiledet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None
+) -> tf_keras.Model:
   """Builds MobileDet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'mobiledet', (f'Inconsistent backbone type '
                                         f'{backbone_type}')
 
   return MobileDet(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/mobiledet_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/mobiledet_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for Mobiledet."""
 
 import itertools
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import mobiledet
 
 
 class MobileDetTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
@@ -67,48 +67,48 @@
               'MobileDetDSP',
               'MobileDetEdgeTPU',
               'MobileDetGPU',
           ],
       ))
   def test_input_specs(self, input_dim, model_id):
     """Test different input feature dimensions."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, input_dim])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, input_dim])
     network = mobiledet.MobileDet(model_id=model_id, input_specs=input_specs)
 
-    inputs = tf.keras.Input(shape=(128, 128, input_dim), batch_size=1)
+    inputs = tf_keras.Input(shape=(128, 128, input_dim), batch_size=1)
     _ = network(inputs)
 
   @parameterized.parameters(
       itertools.product(
           [
               'MobileDetCPU',
               'MobileDetDSP',
               'MobileDetEdgeTPU',
               'MobileDetGPU',
           ],
           [32, 224],
       ))
   def test_mobiledet_creation(self, model_id, input_size):
     """Test creation of MobileDet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     mobiledet_layers = {
         # The number of filters of layers having outputs been collected
         # for filter_size_scale = 1.0
         'MobileDetCPU': [8, 16, 32, 72, 144],
         'MobileDetDSP': [24, 32, 64, 144, 240],
         'MobileDetEdgeTPU': [16, 16, 40, 96, 384],
         'MobileDetGPU': [16, 32, 64, 128, 384],
     }
 
     network = mobiledet.MobileDet(model_id=model_id,
                                   filter_size_scale=1.0)
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
 
     for idx, num_filter in enumerate(mobiledet_layers[model_id]):
       self.assertAllEqual(
           [1, input_size / 2 ** (idx+1), input_size / 2 ** (idx+1), num_filter],
           endpoints[str(idx+1)].shape.as_list())
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/mobilenet.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/mobilenet.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,42 +14,42 @@
 
 """Contains definitions of MobileNet Networks."""
 
 import dataclasses
 from typing import Optional, Dict, Any, Tuple
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.layers import nn_blocks
 from official.vision.modeling.layers import nn_layers
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 
 #  pylint: disable=pointless-string-statement
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class Conv2DBNBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class Conv2DBNBlock(tf_keras.layers.Layer):
   """A convolution block with batch normalization."""
 
   def __init__(
       self,
       filters: int,
       kernel_size: int = 3,
       strides: int = 1,
       use_bias: bool = False,
       use_explicit_padding: bool = False,
       activation: str = 'relu6',
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       use_normalization: bool = True,
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       **kwargs):
     """A convolution block with batch normalization.
 
@@ -63,17 +63,17 @@
       use_bias: If True, use bias in the convolution layer.
       use_explicit_padding: Use 'VALID' padding for convolutions, but prepad
         inputs so that the output dimensions are the same as if 'SAME' padding
         were used.
       activation: A `str` name of the activation function.
       kernel_initializer: A `str` for kernel initializer of convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       use_normalization: If True, use batch normalization.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       **kwargs: Additional keyword arguments to be passed.
     """
@@ -87,24 +87,21 @@
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     self._use_normalization = use_normalization
     self._use_sync_bn = use_sync_bn
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
+    self._norm = tf_keras.layers.BatchNormalization
 
     if use_explicit_padding and kernel_size > 1:
       self._padding = 'valid'
     else:
       self._padding = 'same'
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
 
   def get_config(self):
     config = {
         'filters': self._filters,
@@ -123,29 +120,30 @@
     }
     base_config = super(Conv2DBNBlock, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def build(self, input_shape):
     if self._use_explicit_padding and self._kernel_size > 1:
       padding_size = nn_layers.get_padding_for_kernel_size(self._kernel_size)
-      self._pad = tf.keras.layers.ZeroPadding2D(padding_size)
-    self._conv0 = tf.keras.layers.Conv2D(
+      self._pad = tf_keras.layers.ZeroPadding2D(padding_size)
+    self._conv0 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=self._kernel_size,
         strides=self._strides,
         padding=self._padding,
         use_bias=self._use_bias,
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     if self._use_normalization:
       self._norm0 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn)
     self._activation_layer = tf_utils.get_activation(
         self._activation, use_keras_layer=True)
 
     super(Conv2DBNBlock, self).build(input_shape)
 
   def call(self, inputs, training=None):
     if self._use_explicit_padding and self._kernel_size > 1:
@@ -612,30 +610,30 @@
                                            multiplier=filter_size_scale,
                                            divisor=divisible_by,
                                            min_depth=8)
 
   return decoded_specs
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MobileNet(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MobileNet(tf_keras.Model):
   """Creates a MobileNet family model."""
 
   def __init__(
       self,
       model_id: str = 'MobileNetV2',
       filter_size_scale: float = 1.0,
-      input_specs: tf.keras.layers.InputSpec = layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = layers.InputSpec(
           shape=[None, None, None, 3]),
       # The followings are for hyper-parameter tuning.
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       # The followings should be kept the same most of the times.
       output_stride: Optional[int] = None,
       min_depth: int = 8,
       # divisible is not used in MobileNetV1.
       divisible_by: int = 8,
       stochastic_depth_drop_rate: float = 0.0,
       regularize_depthwise: bool = False,
@@ -650,22 +648,22 @@
       model_id: A `str` of MobileNet version. The supported values are
         `MobileNetV1`, `MobileNetV2`, `MobileNetV3Large`, `MobileNetV3Small`,
         `MobileNetV3EdgeTPU`, `MobileNetMultiMAX` and `MobileNetMultiAVG`.
       filter_size_scale: A `float` of multiplier for the filters (number of
         channels) for all convolution ops. The value must be greater than zero.
         Typical usage will be to set this value in (0, 1) to reduce the number
         of parameters or computation cost of the model.
-      input_specs: A `tf.keras.layers.InputSpec` of specs of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of specs of the input tensor.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       kernel_initializer: A `str` for kernel initializer of convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       output_stride: An `int` that specifies the requested ratio of input to
         output spatial resolution. If not None, then we invoke atrous
         convolution if necessary to prevent the network from reducing the
         spatial resolution of activation maps. Allowed values are 8 (accurate
         fully convolutional mode), 16 (fast fully convolutional mode), 32
         (classification mode).
@@ -712,15 +710,15 @@
     self._bias_regularizer = bias_regularizer
     self._use_sync_bn = use_sync_bn
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._finegrain_classification_mode = finegrain_classification_mode
     self._output_intermediate_endpoints = output_intermediate_endpoints
 
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
 
     block_specs = SUPPORTED_SPECS_MAP.get(model_id)
     self._decoded_specs = block_spec_decoder(
         specs=block_specs,
         filter_size_scale=self._filter_size_scale,
         divisible_by=self._get_divisible_by(),
         finegrain_classification_mode=self._finegrain_classification_mode)
@@ -863,15 +861,15 @@
       elif block_def.block_fn == 'gpooling':
         net = layers.GlobalAveragePooling2D(keepdims=True)(net)
 
       else:
         raise ValueError('Unknown block type {} for layer {}'.format(
             block_def.block_fn, i))
 
-      net = tf.keras.layers.Activation('linear', name=block_name)(net)
+      net = tf_keras.layers.Activation('linear', name=block_name)(net)
 
       if block_def.is_output:
         endpoints[str(endpoint_level)] = net
         for key, tensor in intermediate_endpoints.items():
           endpoints[str(endpoint_level) + '/' + key] = tensor
         if current_stride != self._output_stride:
           endpoint_level += 1
@@ -907,19 +905,19 @@
   def output_specs(self):
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
 @factory.register_backbone_builder('mobilenet')
 def build_mobilenet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None
+) -> tf_keras.Model:
   """Builds MobileNet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'mobilenet', (f'Inconsistent backbone type '
                                         f'{backbone_type}')
 
   return MobileNet(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/mobilenet_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/mobilenet_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import itertools
 import math
 
 # Import libraries
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import mobilenet
 
 
 class MobileNetTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
@@ -85,20 +85,20 @@
               'MobileNetMultiAVGSeg',
               'MobileNetMultiMAXSeg',
               'MobileNetV3SmallReducedFilters',
           ],
       ))
   def test_input_specs(self, input_dim, model_id):
     """Test different input feature dimensions."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, input_dim])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, input_dim])
     network = mobilenet.MobileNet(model_id=model_id, input_specs=input_specs)
 
-    inputs = tf.keras.Input(shape=(128, 128, input_dim), batch_size=1)
+    inputs = tf_keras.Input(shape=(128, 128, input_dim), batch_size=1)
     _ = network(inputs)
 
   @parameterized.parameters(
       itertools.product(
           [
               'MobileNetV1',
               'MobileNetV2',
@@ -111,15 +111,15 @@
               'MobileNetV3SmallReducedFilters',
           ],
           [32, 224],
       ))
   def test_mobilenet_creation(self, model_id,
                               input_size):
     """Test creation of MobileNet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     mobilenet_layers = {
         # The number of filters of layers having outputs been collected
         # for filter_size_scale = 1.0
         'MobileNetV1': [128, 256, 512, 1024],
         'MobileNetV2': [24, 32, 96, 320],
         'MobileNetV3Small': [16, 24, 48, 96],
@@ -131,15 +131,15 @@
         'MobileNetMultiMAXSeg': [32, 64, 128, 96],
         'MobileNetV3SmallReducedFilters': [16, 24, 48, 48],
     }
 
     network = mobilenet.MobileNet(model_id=model_id,
                                   filter_size_scale=1.0)
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
 
     for idx, num_filter in enumerate(mobilenet_layers[model_id]):
       self.assertAllEqual(
           [1, input_size / 2 ** (idx+2), input_size / 2 ** (idx+2), num_filter],
           endpoints[str(idx+2)].shape.as_list())
 
@@ -156,15 +156,15 @@
               'MobileNetMultiAVGSeg',
               'MobileNetMultiMAXSeg',
               'MobileNetV3SmallReducedFilters',
           ],
           [32, 224],
       ))
   def test_mobilenet_intermediate_layers(self, model_id, input_size):
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     # Tests the mobilenet intermediate depthwise layers.
     mobilenet_depthwise_layers = {
         # The number of filters of depthwise layers having outputs been
         # collected for filter_size_scale = 1.0. Only tests the mobilenet
         # model with inverted bottleneck block using depthwise which excludes
         # MobileNetV1.
         'MobileNetV1': [],
@@ -178,15 +178,15 @@
         'MobileNetMultiMAXSeg': [96, 128, 384, 320],
         'MobileNetV3SmallReducedFilters': [16, 88, 144, 288],
     }
     network = mobilenet.MobileNet(model_id=model_id,
                                   filter_size_scale=1.0,
                                   output_intermediate_endpoints=True)
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
 
     for idx, num_filter in enumerate(mobilenet_depthwise_layers[model_id]):
       # Not using depthwise conv in this layer.
       if num_filter is None:
         continue
 
@@ -239,15 +239,15 @@
 
     input_size = 224
     network = mobilenet.MobileNet(model_id=model_id,
                                   filter_size_scale=filter_size_scale)
     self.assertEqual(network.count_params(),
                      mobilenet_params[(model_id, filter_size_scale)])
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     _ = network(inputs)
 
   @parameterized.parameters(
       itertools.product(
           [
               'MobileNetV1',
               'MobileNetV2',
@@ -260,15 +260,15 @@
               'MobileNetMultiMAXSeg',
               'MobileNetV3SmallReducedFilters',
           ],
           [8, 16, 32],
       ))
   def test_mobilenet_output_stride(self, model_id, output_stride):
     """Test for creation of a MobileNet with different output strides."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     mobilenet_layers = {
         # The number of filters of the layers outputs been collected
         # for filter_size_scale = 1.0.
         'MobileNetV1': 1024,
         'MobileNetV2': 320,
         'MobileNetV3Small': 96,
@@ -282,15 +282,15 @@
     }
 
     network = mobilenet.MobileNet(
         model_id=model_id, filter_size_scale=1.0, output_stride=output_stride)
     level = int(math.log2(output_stride))
     input_size = 224
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
     num_filter = mobilenet_layers[model_id]
     self.assertAllEqual(
         [1, input_size / output_stride, input_size / output_stride, num_filter],
         endpoints[str(level)].shape.as_list())
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,23 +13,23 @@
 # limitations under the License.
 
 """Contains definitions of ResNet and ResNet-RS models."""
 
 from typing import Callable, Optional
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.layers import nn_blocks
 from official.vision.modeling.layers import nn_layers
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 # Specifications for different ResNet variants.
 # Each entry specifies block configurations of the particular ResNet variant.
 # Each element in the block configuration is in the following format:
 # (block_fn, num_filters, block_repeats)
 RESNET_SPECS = {
     10: [
@@ -40,14 +40,20 @@
     ],
     18: [
         ('residual', 64, 2),
         ('residual', 128, 2),
         ('residual', 256, 2),
         ('residual', 512, 2),
     ],
+    26: [
+        ('residual', 64, 3),
+        ('residual', 128, 3),
+        ('residual', 256, 3),
+        ('residual', 512, 3),
+    ],
     34: [
         ('residual', 64, 3),
         ('residual', 128, 4),
         ('residual', 256, 6),
         ('residual', 512, 3),
     ],
     50: [
@@ -91,16 +97,16 @@
         ('bottleneck', 128, 44),
         ('bottleneck', 256, 87),
         ('bottleneck', 512, 4),
     ],
 }
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ResNet(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ResNet(tf_keras.Model):
   """Creates ResNet and ResNet-RS family models.
 
   This implements the Deep Residual Network from:
     Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.
     Deep Residual Learning for Image Recognition.
     (https://arxiv.org/pdf/1512.03385) and
     Irwan Bello, William Fedus, Xianzhi Du, Ekin D. Cubuk, Aravind Srinivas,
@@ -108,37 +114,37 @@
     Revisiting ResNets: Improved Training and Scaling Strategies.
     (https://arxiv.org/abs/2103.07579).
   """
 
   def __init__(
       self,
       model_id: int,
-      input_specs: tf.keras.layers.InputSpec = layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = layers.InputSpec(
           shape=[None, None, None, 3]),
       depth_multiplier: float = 1.0,
       stem_type: str = 'v0',
       resnetd_shortcut: bool = False,
       replace_stem_max_pool: bool = False,
       se_ratio: Optional[float] = None,
       init_stochastic_depth_rate: float = 0.0,
       scale_stem: bool = True,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       bn_trainable: bool = True,
       **kwargs):
     """Initializes a ResNet model.
 
     Args:
       model_id: An `int` of the depth of ResNet backbone model.
-      input_specs: A `tf.keras.layers.InputSpec` of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of the input tensor.
       depth_multiplier: A `float` of the depth multiplier to uniformaly scale up
         all layers in channel size. This argument is also referred to as
         `width_multiplier` in (https://arxiv.org/abs/2103.07579).
       stem_type: A `str` of stem type of ResNet. Default to `v0`. If set to
         `v1`, use ResNet-D type stem (https://arxiv.org/abs/1812.01187).
       resnetd_shortcut: A `bool` of whether to use ResNet-D shortcut in
         downsampling blocks.
@@ -148,17 +154,17 @@
       init_stochastic_depth_rate: A `float` of initial stochastic depth rate.
       scale_stem: A `bool` of whether to scale stem layers.
       activation: A `str` name of the activation function.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A small `float` added to variance to avoid dividing by zero.
       kernel_initializer: A str for kernel initializer of convolutional layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       bn_trainable: A `bool` that indicates whether batch norm layers should be
         trainable. Default to True.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._model_id = model_id
     self._input_specs = input_specs
@@ -169,154 +175,160 @@
     self._se_ratio = se_ratio
     self._init_stochastic_depth_rate = init_stochastic_depth_rate
     self._scale_stem = scale_stem
     self._use_sync_bn = use_sync_bn
     self._activation = activation
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
-    if use_sync_bn:
-      self._norm = layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = layers.BatchNormalization
+    self._norm = layers.BatchNormalization
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     self._bn_trainable = bn_trainable
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
-      bn_axis = -1
+    if tf_keras.backend.image_data_format() == 'channels_last':
+      self._bn_axis = -1
     else:
-      bn_axis = 1
+      self._bn_axis = 1
 
     # Build ResNet.
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
+    x = self._stem(inputs)
 
-    stem_depth_multiplier = self._depth_multiplier if scale_stem else 1.0
-    if stem_type == 'v0':
+    endpoints = {}
+    for i, spec in enumerate(RESNET_SPECS[model_id]):
+      if spec[0] == 'residual':
+        block_fn = nn_blocks.ResidualBlock
+      elif spec[0] == 'bottleneck':
+        block_fn = nn_blocks.BottleneckBlock
+      else:
+        raise ValueError('Block fn `{}` is not supported.'.format(spec[0]))
+      x = self._block_group(
+          inputs=x,
+          filters=int(spec[1] * self._depth_multiplier),
+          strides=(1 if i == 0 else 2),
+          block_fn=block_fn,
+          block_repeats=spec[2],
+          stochastic_depth_drop_rate=nn_layers.get_stochastic_depth_rate(
+              self._init_stochastic_depth_rate, i + 2, 5),
+          name='block_group_l{}'.format(i + 2))
+      endpoints[str(i + 2)] = x
+
+    self._output_specs = {l: endpoints[l].get_shape() for l in endpoints}
+
+    super(ResNet, self).__init__(inputs=inputs, outputs=endpoints, **kwargs)
+
+  def _stem(self, inputs):
+    stem_depth_multiplier = self._depth_multiplier if self._scale_stem else 1.0
+    if self._stem_type == 'v0':
       x = layers.Conv2D(
           filters=int(64 * stem_depth_multiplier),
           kernel_size=7,
           strides=2,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
-          bias_regularizer=self._bias_regularizer)(
-              inputs)
+          bias_regularizer=self._bias_regularizer,
+      )(inputs)
       x = self._norm(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          trainable=bn_trainable)(
-              x)
-      x = tf_utils.get_activation(activation, use_keras_layer=True)(x)
-    elif stem_type == 'v1':
+          axis=self._bn_axis,
+          momentum=self._norm_momentum,
+          epsilon=self._norm_epsilon,
+          trainable=self._bn_trainable,
+          synchronized=self._use_sync_bn,
+      )(x)
+      x = tf_utils.get_activation(self._activation, use_keras_layer=True)(x)
+    elif self._stem_type == 'v1':
       x = layers.Conv2D(
           filters=int(32 * stem_depth_multiplier),
           kernel_size=3,
           strides=2,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
-          bias_regularizer=self._bias_regularizer)(
-              inputs)
+          bias_regularizer=self._bias_regularizer,
+      )(inputs)
       x = self._norm(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          trainable=bn_trainable)(
-              x)
-      x = tf_utils.get_activation(activation, use_keras_layer=True)(x)
+          axis=self._bn_axis,
+          momentum=self._norm_momentum,
+          epsilon=self._norm_epsilon,
+          trainable=self._bn_trainable,
+          synchronized=self._use_sync_bn,
+      )(x)
+      x = tf_utils.get_activation(self._activation, use_keras_layer=True)(x)
       x = layers.Conv2D(
           filters=int(32 * stem_depth_multiplier),
           kernel_size=3,
           strides=1,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
-          bias_regularizer=self._bias_regularizer)(
-              x)
+          bias_regularizer=self._bias_regularizer,
+      )(x)
       x = self._norm(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          trainable=bn_trainable)(
-              x)
-      x = tf_utils.get_activation(activation, use_keras_layer=True)(x)
+          axis=self._bn_axis,
+          momentum=self._norm_momentum,
+          epsilon=self._norm_epsilon,
+          trainable=self._bn_trainable,
+          synchronized=self._use_sync_bn,
+      )(x)
+      x = tf_utils.get_activation(self._activation, use_keras_layer=True)(x)
       x = layers.Conv2D(
           filters=int(64 * stem_depth_multiplier),
           kernel_size=3,
           strides=1,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
-          bias_regularizer=self._bias_regularizer)(
-              x)
+          bias_regularizer=self._bias_regularizer,
+      )(x)
       x = self._norm(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          trainable=bn_trainable)(
-              x)
-      x = tf_utils.get_activation(activation, use_keras_layer=True)(x)
+          axis=self._bn_axis,
+          momentum=self._norm_momentum,
+          epsilon=self._norm_epsilon,
+          trainable=self._bn_trainable,
+          synchronized=self._use_sync_bn,
+      )(x)
+      x = tf_utils.get_activation(self._activation, use_keras_layer=True)(x)
     else:
-      raise ValueError('Stem type {} not supported.'.format(stem_type))
+      raise ValueError('Stem type {} not supported.'.format(self._stem_type))
 
-    if replace_stem_max_pool:
+    if self._replace_stem_max_pool:
       x = layers.Conv2D(
           filters=int(64 * self._depth_multiplier),
           kernel_size=3,
           strides=2,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
-          bias_regularizer=self._bias_regularizer)(
-              x)
+          bias_regularizer=self._bias_regularizer,
+      )(x)
       x = self._norm(
-          axis=bn_axis,
-          momentum=norm_momentum,
-          epsilon=norm_epsilon,
-          trainable=bn_trainable)(
-              x)
-      x = tf_utils.get_activation(activation, use_keras_layer=True)(x)
+          axis=self._bn_axis,
+          momentum=self._norm_momentum,
+          epsilon=self._norm_epsilon,
+          trainable=self._bn_trainable,
+          synchronized=self._use_sync_bn,
+      )(x)
+      x = tf_utils.get_activation(self._activation, use_keras_layer=True)(x)
     else:
       x = layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
 
-    endpoints = {}
-    for i, spec in enumerate(RESNET_SPECS[model_id]):
-      if spec[0] == 'residual':
-        block_fn = nn_blocks.ResidualBlock
-      elif spec[0] == 'bottleneck':
-        block_fn = nn_blocks.BottleneckBlock
-      else:
-        raise ValueError('Block fn `{}` is not supported.'.format(spec[0]))
-      x = self._block_group(
-          inputs=x,
-          filters=int(spec[1] * self._depth_multiplier),
-          strides=(1 if i == 0 else 2),
-          block_fn=block_fn,
-          block_repeats=spec[2],
-          stochastic_depth_drop_rate=nn_layers.get_stochastic_depth_rate(
-              self._init_stochastic_depth_rate, i + 2, 5),
-          name='block_group_l{}'.format(i + 2))
-      endpoints[str(i + 2)] = x
-
-    self._output_specs = {l: endpoints[l].get_shape() for l in endpoints}
-
-    super(ResNet, self).__init__(inputs=inputs, outputs=endpoints, **kwargs)
+    return x
 
   def _block_group(self,
                    inputs: tf.Tensor,
                    filters: int,
                    strides: int,
-                   block_fn: Callable[..., tf.keras.layers.Layer],
+                   block_fn: Callable[..., tf_keras.layers.Layer],
                    block_repeats: int = 1,
                    stochastic_depth_drop_rate: float = 0.0,
                    name: str = 'block_group'):
     """Creates one group of blocks for the ResNet model.
 
     Args:
       inputs: A `tf.Tensor` of size `[batch, channels, height, width]`.
@@ -365,15 +377,15 @@
           activation=self._activation,
           use_sync_bn=self._use_sync_bn,
           norm_momentum=self._norm_momentum,
           norm_epsilon=self._norm_epsilon,
           bn_trainable=self._bn_trainable)(
               x)
 
-    return tf.keras.layers.Activation('linear', name=name)(x)
+    return tf_keras.layers.Activation('linear', name=name)(x)
 
   def get_config(self):
     config_dict = {
         'model_id': self._model_id,
         'depth_multiplier': self._depth_multiplier,
         'stem_type': self._stem_type,
         'resnetd_shortcut': self._resnetd_shortcut,
@@ -400,18 +412,18 @@
   def output_specs(self):
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
 @factory.register_backbone_builder('resnet')
 def build_resnet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
+    l2_regularizer: tf_keras.regularizers.Regularizer = None) -> tf_keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds ResNet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'resnet', (f'Inconsistent backbone type '
                                      f'{backbone_type}')
 
   return ResNet(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_3d.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_3d.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,23 +12,23 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains definitions of 3D Residual Networks."""
 from typing import Callable, List, Tuple, Optional
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.layers import nn_blocks_3d
 from official.vision.modeling.layers import nn_layers
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 RESNET_SPECS = {
     50: [
         ('bottleneck3d', 64, 3),
         ('bottleneck3d', 128, 4),
         ('bottleneck3d', 256, 6),
         ('bottleneck3d', 512, 3),
@@ -68,51 +68,51 @@
         ('bottleneck3d', 128, 36),
         ('bottleneck3d', 256, 72),
         ('bottleneck3d', 512, 4),
     ],
 }
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ResNet3D(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ResNet3D(tf_keras.Model):
   """Creates a 3D ResNet family model."""
 
   def __init__(
       self,
       model_id: int,
       temporal_strides: List[int],
       temporal_kernel_sizes: List[Tuple[int]],
       use_self_gating: Optional[List[int]] = None,
-      input_specs: tf.keras.layers.InputSpec = layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = layers.InputSpec(
           shape=[None, None, None, None, 3]),
       stem_type: str = 'v0',
       stem_conv_temporal_kernel_size: int = 5,
       stem_conv_temporal_stride: int = 2,
       stem_pool_temporal_stride: int = 2,
       init_stochastic_depth_rate: float = 0.0,
       activation: str = 'relu',
       se_ratio: Optional[float] = None,
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
     """Initializes a 3D ResNet model.
 
     Args:
       model_id: An `int` of depth of ResNet backbone model.
       temporal_strides: A list of integers that specifies the temporal strides
         for all 3d blocks.
       temporal_kernel_sizes: A list of tuples that specifies the temporal kernel
         sizes for all 3d blocks in different block groups.
       use_self_gating: A list of booleans to specify applying self-gating module
         or not in each block group. If None, self-gating is not applied.
-      input_specs: A `tf.keras.layers.InputSpec` of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of the input tensor.
       stem_type: A `str` of stem type of ResNet. Default to `v0`. If set to
         `v1`, use ResNet-D type stem (https://arxiv.org/abs/1812.01187).
       stem_conv_temporal_kernel_size: An `int` of temporal kernel size for the
         first conv layer.
       stem_conv_temporal_stride: An `int` of temporal stride for the first conv
         layer.
       stem_pool_temporal_stride: An `int` of temporal stride for the first pool
@@ -120,17 +120,17 @@
       init_stochastic_depth_rate: A `float` of initial stochastic depth rate.
       activation: A `str` of name of the activation function.
       se_ratio: A `float` or None. Ratio of the Squeeze-and-Excitation layer.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       kernel_initializer: A str for kernel initializer of convolutional layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._model_id = model_id
     self._temporal_strides = temporal_strides
     self._temporal_kernel_sizes = temporal_kernel_sizes
     self._input_specs = input_specs
@@ -141,28 +141,25 @@
     self._use_self_gating = use_self_gating
     self._se_ratio = se_ratio
     self._init_stochastic_depth_rate = init_stochastic_depth_rate
     self._use_sync_bn = use_sync_bn
     self._activation = activation
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
-    if use_sync_bn:
-      self._norm = layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = layers.BatchNormalization
+    self._norm = layers.BatchNormalization
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
 
     # Build ResNet3D backbone.
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
     endpoints = self._build_model(inputs)
     self._output_specs = {l: endpoints[l].get_shape() for l in endpoints}
 
     super(ResNet3D, self).__init__(inputs=inputs, outputs=endpoints, **kwargs)
 
   def _build_model(self, inputs):
     """Builds model architecture.
@@ -228,15 +225,16 @@
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               inputs)
       x = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)(x)
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn)(x)
       x = tf_utils.get_activation(self._activation)(x)
     elif stem_type == 'v1':
       x = layers.Conv3D(
           filters=32,
           kernel_size=[self._stem_conv_temporal_kernel_size, 3, 3],
           strides=[self._stem_conv_temporal_stride, 2, 2],
           use_bias=False,
@@ -244,60 +242,63 @@
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               inputs)
       x = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)(x)
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn)(x)
       x = tf_utils.get_activation(self._activation)(x)
       x = layers.Conv3D(
           filters=32,
           kernel_size=[1, 3, 3],
           strides=[1, 1, 1],
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               x)
       x = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)(x)
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn)(x)
       x = tf_utils.get_activation(self._activation)(x)
       x = layers.Conv3D(
           filters=64,
           kernel_size=[1, 3, 3],
           strides=[1, 1, 1],
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               x)
       x = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)(x)
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn)(x)
       x = tf_utils.get_activation(self._activation)(x)
     else:
       raise ValueError(f'Stem type {stem_type} not supported.')
 
     return x
 
   def _block_group(self,
                    inputs: tf.Tensor,
                    filters: int,
                    temporal_kernel_sizes: Tuple[int],
                    temporal_strides: int,
                    spatial_strides: int,
                    block_fn: Callable[
                        ...,
-                       tf.keras.layers.Layer] = nn_blocks_3d.BottleneckBlock3D,
+                       tf_keras.layers.Layer] = nn_blocks_3d.BottleneckBlock3D,
                    block_repeats: int = 1,
                    stochastic_depth_drop_rate: float = 0.0,
                    use_self_gating: bool = False,
                    name: str = 'block_group'):
     """Creates one group of blocks for the ResNet3D model.
 
     Args:
@@ -396,19 +397,19 @@
   def output_specs(self):
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
 @factory.register_backbone_builder('resnet_3d')
 def build_resnet3d(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None
+) -> tf_keras.Model:
   """Builds ResNet 3d backbone from a config."""
   backbone_cfg = backbone_config.get()
 
   # Flatten configs before passing to the backbone.
   temporal_strides = []
   temporal_kernel_sizes = []
   use_self_gating = []
@@ -435,19 +436,19 @@
       norm_momentum=norm_activation_config.norm_momentum,
       norm_epsilon=norm_activation_config.norm_epsilon,
       kernel_regularizer=l2_regularizer)
 
 
 @factory.register_backbone_builder('resnet_3d_rs')
 def build_resnet3d_rs(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None
+) -> tf_keras.Model:
   """Builds ResNet-3D-RS backbone from a config."""
   backbone_cfg = backbone_config.get()
 
   # Flatten configs before passing to the backbone.
   temporal_strides = []
   temporal_kernel_sizes = []
   use_self_gating = []
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_3d_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_3d_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,44 +12,44 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for resnet."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import resnet_3d
 
 
 class ResNet3DTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
       (128, 50, 4, 'v0', False, 0.0),
       (128, 50, 4, 'v1', False, 0.2),
       (256, 50, 4, 'v1', True, 0.2),
   )
   def test_network_creation(self, input_size, model_id, endpoint_filter_scale,
                             stem_type, se_ratio, init_stochastic_depth_rate):
     """Test creation of ResNet3D family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     temporal_strides = [1, 1, 1, 1]
     temporal_kernel_sizes = [(3, 3, 3), (3, 1, 3, 1), (3, 1, 3, 1, 3, 1),
                              (1, 3, 1)]
     use_self_gating = [True, False, True, False]
 
     network = resnet_3d.ResNet3D(
         model_id=model_id,
         temporal_strides=temporal_strides,
         temporal_kernel_sizes=temporal_kernel_sizes,
         use_self_gating=use_self_gating,
         stem_type=stem_type,
         se_ratio=se_ratio,
         init_stochastic_depth_rate=init_stochastic_depth_rate)
-    inputs = tf.keras.Input(shape=(8, input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(8, input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
 
     self.assertAllEqual([
         1, 2, input_size / 2**2, input_size / 2**2, 64 * endpoint_filter_scale
     ], endpoints['2'].shape.as_list())
     self.assertAllEqual([
         1, 2, input_size / 2**3, input_size / 2**3, 128 * endpoint_filter_scale
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_deeplab.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_deeplab.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,22 +13,22 @@
 # limitations under the License.
 
 """Contains definitions of Residual Networks with Deeplab modifications."""
 
 from typing import Callable, Optional, Tuple, List
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.layers import nn_blocks
 from official.vision.modeling.layers import nn_layers
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 # Specifications for different ResNet variants.
 # Each entry specifies block configurations of the particular ResNet variant.
 # Each element in the block configuration is in the following format:
 # (block_fn, num_filters, block_repeats)
 RESNET_SPECS = {
     50: [
@@ -54,52 +54,52 @@
         ('bottleneck', 128, 24),
         ('bottleneck', 256, 36),
         ('bottleneck', 512, 3),
     ],
 }
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class DilatedResNet(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class DilatedResNet(tf_keras.Model):
   """Creates a ResNet model with Deeplabv3 modifications.
 
   This backbone is suitable for semantic segmentation. This implements
     Liang-Chieh Chen, George Papandreou, Florian Schroff, Hartwig Adam.
     Rethinking Atrous Convolution for Semantic Image Segmentation.
     (https://arxiv.org/pdf/1706.05587)
   """
 
   def __init__(
       self,
       model_id: int,
       output_stride: int,
-      input_specs: tf.keras.layers.InputSpec = layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = layers.InputSpec(
           shape=[None, None, None, 3]),
       stem_type: str = 'v0',
       resnetd_shortcut: bool = False,
       replace_stem_max_pool: bool = False,
       se_ratio: Optional[float] = None,
       init_stochastic_depth_rate: float = 0.0,
       multigrid: Optional[Tuple[int]] = None,
       last_stage_repeats: int = 1,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
     """Initializes a ResNet model with DeepLab modification.
 
     Args:
       model_id: An `int` specifies depth of ResNet backbone model.
       output_stride: An `int` of output stride, ratio of input to output
         resolution.
-      input_specs: A `tf.keras.layers.InputSpec` of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of the input tensor.
       stem_type: A `str` of stem type. Can be `v0` or `v1`. `v1` replaces 7x7
         conv by 3 3x3 convs.
       resnetd_shortcut: A `bool` of whether to use ResNet-D shortcut in
         downsampling blocks.
       replace_stem_max_pool: A `bool` of whether to replace the max pool in stem
         with a stride-2 conv,
       se_ratio: A `float` or None. Ratio of the Squeeze-and-Excitation layer.
@@ -109,104 +109,113 @@
       last_stage_repeats: An `int` that specifies how many times last stage is
         repeated.
       activation: A `str` name of the activation function.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       kernel_initializer: A str for kernel initializer of convolutional layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._model_id = model_id
     self._output_stride = output_stride
     self._input_specs = input_specs
     self._use_sync_bn = use_sync_bn
     self._activation = activation
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
-    if use_sync_bn:
-      self._norm = layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = layers.BatchNormalization
+    self._norm = layers.BatchNormalization
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     self._stem_type = stem_type
     self._resnetd_shortcut = resnetd_shortcut
     self._replace_stem_max_pool = replace_stem_max_pool
     self._se_ratio = se_ratio
     self._init_stochastic_depth_rate = init_stochastic_depth_rate
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       bn_axis = -1
     else:
       bn_axis = 1
 
     # Build ResNet.
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
 
     if stem_type == 'v0':
       x = layers.Conv2D(
           filters=64,
           kernel_size=7,
           strides=2,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               inputs)
       x = self._norm(
-          axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)(
+          axis=bn_axis,
+          momentum=norm_momentum,
+          epsilon=norm_epsilon,
+          synchronized=use_sync_bn)(
               x)
       x = tf_utils.get_activation(activation)(x)
     elif stem_type == 'v1':
       x = layers.Conv2D(
           filters=64,
           kernel_size=3,
           strides=2,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               inputs)
       x = self._norm(
-          axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)(
+          axis=bn_axis,
+          momentum=norm_momentum,
+          epsilon=norm_epsilon,
+          synchronized=use_sync_bn)(
               x)
       x = tf_utils.get_activation(activation)(x)
       x = layers.Conv2D(
           filters=64,
           kernel_size=3,
           strides=1,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               x)
       x = self._norm(
-          axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)(
+          axis=bn_axis,
+          momentum=norm_momentum,
+          epsilon=norm_epsilon,
+          synchronized=use_sync_bn)(
               x)
       x = tf_utils.get_activation(activation)(x)
       x = layers.Conv2D(
           filters=128,
           kernel_size=3,
           strides=1,
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               x)
       x = self._norm(
-          axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)(
+          axis=bn_axis,
+          momentum=norm_momentum,
+          epsilon=norm_epsilon,
+          synchronized=use_sync_bn)(
               x)
       x = tf_utils.get_activation(activation)(x)
     else:
       raise ValueError('Stem type {} not supported.'.format(stem_type))
 
     if replace_stem_max_pool:
       x = layers.Conv2D(
@@ -216,15 +225,18 @@
           use_bias=False,
           padding='same',
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               x)
       x = self._norm(
-          axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)(
+          axis=bn_axis,
+          momentum=norm_momentum,
+          epsilon=norm_epsilon,
+          synchronized=use_sync_bn)(
               x)
       x = tf_utils.get_activation(activation, use_keras_layer=True)(x)
     else:
       x = layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
 
     normal_resnet_stage = int(np.math.log2(self._output_stride)) - 2
 
@@ -275,15 +287,15 @@
         inputs=inputs, outputs=endpoints, **kwargs)
 
   def _block_group(self,
                    inputs: tf.Tensor,
                    filters: int,
                    strides: int,
                    dilation_rate: int,
-                   block_fn: Callable[..., tf.keras.layers.Layer],
+                   block_fn: Callable[..., tf_keras.layers.Layer],
                    block_repeats: int = 1,
                    stochastic_depth_drop_rate: float = 0.0,
                    multigrid: Optional[List[int]] = None,
                    name: str = 'block_group'):
     """Creates one group of blocks for the ResNet model.
 
     Deeplab applies strides at the last block.
@@ -376,18 +388,18 @@
   def output_specs(self):
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
 @factory.register_backbone_builder('dilated_resnet')
 def build_dilated_resnet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
+    l2_regularizer: tf_keras.regularizers.Regularizer = None) -> tf_keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds ResNet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'dilated_resnet', (f'Inconsistent backbone type '
                                              f'{backbone_type}')
 
   return DilatedResNet(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_deeplab_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_deeplab_test.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for resnet_deeplab models."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.vision.modeling.backbones import resnet_deeplab
 
 
 class ResNetTest(parameterized.TestCase, tf.test.TestCase):
@@ -35,19 +35,19 @@
       (128, 101, 4, 16),
       (128, 152, 4, 16),
       (128, 200, 4, 16),
   )
   def test_network_creation(self, input_size, model_id,
                             endpoint_filter_scale, output_stride):
     """Test creation of ResNet models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     network = resnet_deeplab.DilatedResNet(model_id=model_id,
                                            output_stride=output_stride)
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
     print(endpoints)
     self.assertAllEqual([
         1, input_size / output_stride, input_size / output_stride,
         512 * endpoint_filter_scale
     ], endpoints[str(int(np.math.log2(output_stride)))].shape.as_list())
 
@@ -65,25 +65,25 @@
                             replace_stem_max_pool):
     """Test additional features of ResNet models."""
     input_size = 128
     model_id = 50
     endpoint_filter_scale = 4
     output_stride = 8
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     network = resnet_deeplab.DilatedResNet(
         model_id=model_id,
         output_stride=output_stride,
         stem_type=stem_type,
         resnetd_shortcut=resnetd_shortcut,
         replace_stem_max_pool=replace_stem_max_pool,
         se_ratio=se_ratio,
         init_stochastic_depth_rate=init_stochastic_depth_rate)
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
     print(endpoints)
     self.assertAllEqual([
         1, input_size / output_stride, input_size / output_stride,
         512 * endpoint_filter_scale
     ], endpoints[str(int(np.math.log2(output_stride)))].shape.as_list())
 
@@ -95,31 +95,31 @@
           ],
           use_sync_bn=[False, True],
       ))
   def test_sync_bn_multiple_devices(self, strategy, use_sync_bn):
     """Test for sync bn on TPU and GPU devices."""
     inputs = np.random.rand(64, 128, 128, 3)
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     with strategy.scope():
       network = resnet_deeplab.DilatedResNet(
           model_id=50, output_stride=8, use_sync_bn=use_sync_bn)
       _ = network(inputs)
 
   @parameterized.parameters(1, 3, 4)
   def test_input_specs(self, input_dim):
     """Test different input feature dimensions."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, input_dim])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, input_dim])
     network = resnet_deeplab.DilatedResNet(
         model_id=50, output_stride=8, input_specs=input_specs)
 
-    inputs = tf.keras.Input(shape=(128, 128, input_dim), batch_size=1)
+    inputs = tf_keras.Input(shape=(128, 128, input_dim), batch_size=1)
     _ = network(inputs)
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     kwargs = dict(
         model_id=50,
         output_stride=8,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/resnet_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/resnet_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,48 +13,50 @@
 # limitations under the License.
 
 """Tests for resnet."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.vision.modeling.backbones import resnet
 
 
 class ResNetTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
       (128, 10, 1),
       (128, 18, 1),
+      (128, 26, 1),
       (128, 34, 1),
       (128, 50, 4),
       (128, 101, 4),
       (128, 152, 4),
   )
   def test_network_creation(self, input_size, model_id,
                             endpoint_filter_scale):
     """Test creation of ResNet family models."""
     resnet_params = {
         10: 4915904,
         18: 11190464,
+        26: 17465024,
         34: 21306048,
         50: 23561152,
         101: 42605504,
         152: 58295232,
     }
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     network = resnet.ResNet(model_id=model_id)
     self.assertEqual(network.count_params(), resnet_params[model_id])
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
 
     self.assertAllEqual(
         [1, input_size / 2**2, input_size / 2**2, 64 * endpoint_filter_scale],
         endpoints['2'].shape.as_list())
     self.assertAllEqual(
         [1, input_size / 2**3, input_size / 2**3, 128 * endpoint_filter_scale],
@@ -74,15 +76,15 @@
           ],
           use_sync_bn=[False, True],
       ))
   def test_sync_bn_multiple_devices(self, strategy, use_sync_bn):
     """Test for sync bn on TPU and GPU devices."""
     inputs = np.random.rand(64, 128, 128, 3)
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     with strategy.scope():
       network = resnet.ResNet(model_id=50, use_sync_bn=use_sync_bn)
       _ = network(inputs)
 
   @parameterized.parameters(
       (128, 34, 1, 'v0', None, 0.0, 1.0, False, False),
@@ -90,35 +92,35 @@
       (128, 50, 4, 'v0', None, 0.0, 1.5, False, False),
       (128, 50, 4, 'v1', 0.25, 0.2, 2.0, True, True),
   )
   def test_resnet_rs(self, input_size, model_id, endpoint_filter_scale,
                      stem_type, se_ratio, init_stochastic_depth_rate,
                      depth_multiplier, resnetd_shortcut, replace_stem_max_pool):
     """Test creation of ResNet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     network = resnet.ResNet(
         model_id=model_id,
         depth_multiplier=depth_multiplier,
         stem_type=stem_type,
         resnetd_shortcut=resnetd_shortcut,
         replace_stem_max_pool=replace_stem_max_pool,
         se_ratio=se_ratio,
         init_stochastic_depth_rate=init_stochastic_depth_rate)
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     _ = network(inputs)
 
   @parameterized.parameters(1, 3, 4)
   def test_input_specs(self, input_dim):
     """Test different input feature dimensions."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, input_dim])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, input_dim])
     network = resnet.ResNet(model_id=50, input_specs=input_specs)
 
-    inputs = tf.keras.Input(shape=(128, 128, input_dim), batch_size=1)
+    inputs = tf_keras.Input(shape=(128, 128, input_dim), batch_size=1)
     _ = network(inputs)
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     kwargs = dict(
         model_id=50,
         depth_multiplier=1.0,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/revnet.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/revnet.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains definitions of RevNet."""
 
 from typing import Any, Callable, Dict, Optional
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.layers import nn_blocks
 
 
 # Specifications for different RevNet variants.
@@ -44,78 +44,78 @@
         ('bottleneck', 256, 2),
         ('bottleneck', 512, 11),
         ('bottleneck', 832, 2),
     ],
 }
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class RevNet(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class RevNet(tf_keras.Model):
   """Creates a Reversible ResNet (RevNet) family model.
 
   This implements:
     Aidan N. Gomez, Mengye Ren, Raquel Urtasun, Roger B. Grosse.
     The Reversible Residual Network: Backpropagation Without Storing
     Activations.
     (https://arxiv.org/pdf/1707.04585.pdf)
   """
 
   def __init__(
       self,
       model_id: int,
-      input_specs: tf.keras.layers.InputSpec = tf.keras.layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = tf_keras.layers.InputSpec(
           shape=[None, None, None, 3]),
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
     """Initializes a RevNet model.
 
     Args:
       model_id: An `int` of depth/id of ResNet backbone model.
-      input_specs: A `tf.keras.layers.InputSpec` of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of the input tensor.
       activation: A `str` name of the activation function.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       kernel_initializer: A str for kernel initializer of convolutional layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._model_id = model_id
     self._input_specs = input_specs
     self._use_sync_bn = use_sync_bn
     self._activation = activation
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
+    self._norm = tf_keras.layers.BatchNormalization
 
-    axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1
+    axis = -1 if tf_keras.backend.image_data_format() == 'channels_last' else 1
 
     # Build RevNet.
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
 
-    x = tf.keras.layers.Conv2D(
+    x = tf_keras.layers.Conv2D(
         filters=REVNET_SPECS[model_id][0][1],
         kernel_size=7, strides=2, use_bias=False, padding='same',
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer)(inputs)
     x = self._norm(
-        axis=axis, momentum=norm_momentum, epsilon=norm_epsilon)(x)
+        axis=axis,
+        momentum=norm_momentum,
+        epsilon=norm_epsilon,
+        synchronized=use_sync_bn)(x)
     x = tf_utils.get_activation(activation)(x)
-    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
+    x = tf_keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
 
     endpoints = {}
     for i, spec in enumerate(REVNET_SPECS[model_id]):
       if spec[0] == 'residual':
         inner_block_fn = nn_blocks.ResidualInner
       elif spec[0] == 'bottleneck':
         inner_block_fn = nn_blocks.BottleneckResidualInner
@@ -140,15 +140,15 @@
 
     super(RevNet, self).__init__(inputs=inputs, outputs=endpoints, **kwargs)
 
   def _block_group(self,
                    inputs: tf.Tensor,
                    filters: int,
                    strides: int,
-                   inner_block_fn: Callable[..., tf.keras.layers.Layer],
+                   inner_block_fn: Callable[..., tf_keras.layers.Layer],
                    block_repeats: int,
                    batch_norm_first: bool,
                    name: str = 'revblock_group') -> tf.Tensor:
     """Creates one reversible block for RevNet model.
 
     Args:
       inputs: A `tf.Tensor` of size `[batch, channels, height, width]`.
@@ -197,29 +197,29 @@
         'kernel_regularizer': self._kernel_regularizer,
     }
     return config_dict
 
   @classmethod
   def from_config(cls,
                   config: Dict[str, Any],
-                  custom_objects: Optional[Any] = None) -> tf.keras.Model:
+                  custom_objects: Optional[Any] = None) -> tf_keras.Model:
     return cls(**config)
 
   @property
   def output_specs(self) -> Dict[int, tf.TensorShape]:
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs  # pytype: disable=bad-return-type  # trace-all-classes
 
 
 @factory.register_backbone_builder('revnet')
 def build_revnet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
+    l2_regularizer: tf_keras.regularizers.Regularizer = None) -> tf_keras.Model:  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds RevNet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'revnet', (f'Inconsistent backbone type '
                                      f'{backbone_type}')
 
   return RevNet(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/revnet_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/revnet_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,32 +12,32 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for RevNet."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import revnet
 
 
 class RevNetTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
       (128, 56, 4),
       (128, 104, 4),
   )
   def test_network_creation(self, input_size, model_id,
                             endpoint_filter_scale):
     """Test creation of RevNet family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     network = revnet.RevNet(model_id=model_id)
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = network(inputs)
     network.summary()
 
     self.assertAllEqual(
         [1, input_size / 2**2, input_size / 2**2, 128 * endpoint_filter_scale],
         endpoints['2'].shape.as_list())
     self.assertAllEqual(
@@ -49,20 +49,20 @@
     self.assertAllEqual(
         [1, input_size / 2**5, input_size / 2**5, 832 * endpoint_filter_scale],
         endpoints['5'].shape.as_list())
 
   @parameterized.parameters(1, 3, 4)
   def test_input_specs(self, input_dim):
     """Test different input feature dimensions."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, input_dim])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, input_dim])
     network = revnet.RevNet(model_id=56, input_specs=input_specs)
 
-    inputs = tf.keras.Input(shape=(128, 128, input_dim), batch_size=1)
+    inputs = tf_keras.Input(shape=(128, 128, input_dim), batch_size=1)
     _ = network(inputs)
 
   def test_serialize_deserialize(self):
     # Create a network object that sets all of its config options.
     kwargs = dict(
         model_id=56,
         activation='relu',
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/spinenet.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/spinenet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,24 +16,24 @@
 
 import math
 from typing import Any, List, Optional, Tuple
 
 # Import libraries
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.layers import nn_blocks
 from official.vision.modeling.layers import nn_layers
 from official.vision.ops import spatial_transform_ops
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 FILTER_SIZE_MAP = {
     1: 32,
     2: 64,
     3: 128,
     4: 256,
     5: 256,
@@ -120,77 +120,79 @@
   """Builds the list of BlockSpec objects for SpineNet."""
   if not block_specs:
     block_specs = SPINENET_BLOCK_SPECS
   logging.info('Building SpineNet block specs: %s', block_specs)
   return [BlockSpec(*b) for b in block_specs]
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class SpineNet(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SpineNet(tf_keras.Model):
   """Creates a SpineNet family model.
 
   This implements:
     Xianzhi Du, Tsung-Yi Lin, Pengchong Jin, Golnaz Ghiasi, Mingxing Tan,
     Yin Cui, Quoc V. Le, Xiaodan Song.
     SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization.
     (https://arxiv.org/abs/1912.05027)
   """
 
   def __init__(
       self,
-      input_specs: tf.keras.layers.InputSpec = tf.keras.layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = tf_keras.layers.InputSpec(
           shape=[None, None, None, 3]),
       min_level: int = 3,
       max_level: int = 7,
-      block_specs: List[BlockSpec] = build_block_specs(),
+      block_specs: Optional[List[BlockSpec]] = None,
       endpoints_num_filters: int = 256,
       resample_alpha: float = 0.5,
       block_repeats: int = 1,
       filter_size_scale: float = 1.0,
       init_stochastic_depth_rate: float = 0.0,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       **kwargs):
     """Initializes a SpineNet model.
 
     Args:
-      input_specs: A `tf.keras.layers.InputSpec` of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of the input tensor.
       min_level: An `int` of min level for output mutiscale features.
       max_level: An `int` of max level for output mutiscale features.
       block_specs: A list of block specifications for the SpineNet model
         discovered by NAS.
       endpoints_num_filters: An `int` of feature dimension for the output
         endpoints.
       resample_alpha: A `float` of resampling factor in cross-scale connections.
       block_repeats: An `int` of number of blocks contained in the layer.
       filter_size_scale: A `float` of multiplier for the filters (number of
         channels) for all convolution ops. The value must be greater than zero.
         Typical usage will be to set this value in (0, 1) to reduce the number
         of parameters or computation cost of the model.
       init_stochastic_depth_rate: A `float` of initial stochastic depth rate.
       kernel_initializer: A str for kernel initializer of convolutional layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       activation: A `str` name of the activation function.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A small `float` added to variance to avoid dividing by zero.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._input_specs = input_specs
     self._min_level = min_level
     self._max_level = max_level
-    self._block_specs = block_specs
+    self._block_specs = (
+        build_block_specs() if block_specs is None else block_specs
+    )
     self._endpoints_num_filters = endpoints_num_filters
     self._resample_alpha = resample_alpha
     self._block_repeats = block_repeats
     self._filter_size_scale = filter_size_scale
     self._init_stochastic_depth_rate = init_stochastic_depth_rate
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
@@ -199,32 +201,28 @@
     self._use_sync_bn = use_sync_bn
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._init_block_fn = 'bottleneck'
     self._num_init_blocks = 2
 
     self._set_activation_fn(activation)
+    self._norm = layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = layers.BatchNormalization
-
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
 
     # Build SpineNet.
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
 
     net = self._build_stem(inputs=inputs)
     input_width = input_specs.shape[2]
     if input_width is None:
-      max_stride = max(map(lambda b: b.level, block_specs))
+      max_stride = max(map(lambda b: b.level, self._block_specs))
       input_width = 2 ** max_stride
     net = self._build_scale_permuted_network(net=net, input_width=input_width)
     endpoints = self._build_endpoints(net=net)
 
     self._output_specs = {l: endpoints[l].get_shape() for l in endpoints}
     super(SpineNet, self).__init__(inputs=inputs, outputs=endpoints)
 
@@ -297,15 +295,16 @@
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)(
             inputs)
     x = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)(
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)(
             x)
     x = tf_utils.get_activation(self._activation_fn)(x)
     x = layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)
 
     net = []
     # Build the initial level 2 blocks.
     for i in range(self._num_init_blocks):
@@ -428,15 +427,16 @@
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               net[str(level)])
       x = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)(
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn)(
               x)
       x = tf_utils.get_activation(self._activation_fn)(x)
       endpoints[str(level)] = x
     return endpoints
 
   def _resample_with_alpha(self,
                            inputs,
@@ -460,15 +460,16 @@
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)(
             inputs)
     x = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)(
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)(
             x)
     x = tf_utils.get_activation(self._activation_fn)(x)
 
     # Spatial resampling.
     if input_width > target_width:
       x = layers.Conv2D(
           filters=new_num_filters,
@@ -479,15 +480,16 @@
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               x)
       x = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)(
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn)(
               x)
       x = tf_utils.get_activation(self._activation_fn)(x)
       input_width /= 2
       while input_width > target_width:
         x = layers.MaxPool2D(pool_size=3, strides=2, padding='SAME')(x)
         input_width /= 2
     elif input_width < target_width:
@@ -505,15 +507,16 @@
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)(
             x)
     x = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)(
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)(
             x)
     return x
 
   def get_config(self):
     config_dict = {
         'min_level': self._min_level,
         'max_level': self._max_level,
@@ -540,18 +543,18 @@
   def output_specs(self):
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
 @factory.register_backbone_builder('spinenet')
 def build_spinenet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:
+    l2_regularizer: tf_keras.regularizers.Regularizer = None) -> tf_keras.Model:
   """Builds SpineNet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'spinenet', (f'Inconsistent backbone type '
                                        f'{backbone_type}')
 
   model_id = str(backbone_cfg.model_id)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/spinenet_mobile.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/spinenet_mobile.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -29,24 +29,24 @@
 """Contains definitions of Mobile SpineNet Networks."""
 import math
 from typing import Any, List, Optional, Tuple
 
 # Import libraries
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.layers import nn_blocks
 from official.vision.modeling.layers import nn_layers
 from official.vision.ops import spatial_transform_ops
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 FILTER_SIZE_MAP = {
     0: 8,
     1: 16,
     2: 24,
     3: 40,
     4: 80,
@@ -112,16 +112,16 @@
   """Builds the list of BlockSpec objects for SpineNet."""
   if not block_specs:
     block_specs = SPINENET_BLOCK_SPECS
   logging.info('Building SpineNet block specs: %s', block_specs)
   return [BlockSpec(*b) for b in block_specs]
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class SpineNetMobile(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SpineNetMobile(tf_keras.Model):
   """Creates a Mobile SpineNet family model.
 
   This implements:
     [1] Xianzhi Du, Tsung-Yi Lin, Pengchong Jin, Golnaz Ghiasi, Mingxing Tan,
     Yin Cui, Quoc V. Le, Xiaodan Song.
     SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization.
     (https://arxiv.org/abs/1912.05027).
@@ -129,38 +129,38 @@
     Quoc Le, Xiaodan Song.
     Efficient Scale-Permuted Backbone with Learned Resource Distribution.
     (https://arxiv.org/abs/2010.11426).
   """
 
   def __init__(
       self,
-      input_specs: tf.keras.layers.InputSpec = tf.keras.layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = tf_keras.layers.InputSpec(
           shape=[None, None, None, 3]),
       min_level: int = 3,
       max_level: int = 7,
-      block_specs: List[BlockSpec] = build_block_specs(),
+      block_specs: Optional[List[BlockSpec]] = None,
       endpoints_num_filters: int = 256,
       se_ratio: float = 0.2,
       block_repeats: int = 1,
       filter_size_scale: float = 1.0,
       expand_ratio: int = 6,
       init_stochastic_depth_rate=0.0,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       use_keras_upsampling_2d: bool = False,
       **kwargs):
     """Initializes a Mobile SpineNet model.
 
     Args:
-      input_specs: A `tf.keras.layers.InputSpec` of the input tensor.
+      input_specs: A `tf_keras.layers.InputSpec` of the input tensor.
       min_level: An `int` of min level for output mutiscale features.
       max_level: An `int` of max level for output mutiscale features.
       block_specs: The block specifications for the SpineNet model discovered by
         NAS.
       endpoints_num_filters: An `int` of feature dimension for the output
         endpoints.
       se_ratio: A `float` of Squeeze-and-Excitation ratio.
@@ -169,29 +169,31 @@
         channels) for all convolution ops. The value must be greater than zero.
         Typical usage will be to set this value in (0, 1) to reduce the number
         of parameters or computation cost of the model.
       expand_ratio: An `integer` of expansion ratios for inverted bottleneck
         blocks.
       init_stochastic_depth_rate: A `float` of initial stochastic depth rate.
       kernel_initializer: A str for kernel initializer of convolutional layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
         Default to None.
       activation: A `str` name of the activation function.
       use_sync_bn: If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A small `float` added to variance to avoid dividing by zero.
       use_keras_upsampling_2d: If True, use keras UpSampling2D layer.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._input_specs = input_specs
     self._min_level = min_level
     self._max_level = max_level
-    self._block_specs = block_specs
+    self._block_specs = (
+        build_block_specs() if block_specs is None else block_specs
+    )
     self._endpoints_num_filters = endpoints_num_filters
     self._se_ratio = se_ratio
     self._block_repeats = block_repeats
     self._filter_size_scale = filter_size_scale
     self._expand_ratio = expand_ratio
     self._init_stochastic_depth_rate = init_stochastic_depth_rate
     self._kernel_initializer = kernel_initializer
@@ -199,32 +201,28 @@
     self._bias_regularizer = bias_regularizer
     self._activation = activation
     self._use_sync_bn = use_sync_bn
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._use_keras_upsampling_2d = use_keras_upsampling_2d
     self._num_init_blocks = 2
+    self._norm = layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = layers.BatchNormalization
-
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
 
     # Build SpineNet.
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
 
     net = self._build_stem(inputs=inputs)
     input_width = input_specs.shape[2]
     if input_width is None:
-      max_stride = max(map(lambda b: b.level, block_specs))
+      max_stride = max(map(lambda b: b.level, self._block_specs))
       input_width = 2 ** max_stride
     net = self._build_scale_permuted_network(net=net, input_width=input_width)
     endpoints = self._build_endpoints(net=net)
 
     self._output_specs = {l: endpoints[l].get_shape() for l in endpoints}
     super().__init__(inputs=inputs, outputs=endpoints)
 
@@ -267,15 +265,15 @@
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer,
           activation=self._activation,
           use_sync_bn=self._use_sync_bn,
           norm_momentum=self._norm_momentum,
           norm_epsilon=self._norm_epsilon)(
               inputs)
-    return tf.keras.layers.Activation('linear', name=name)(x)
+    return tf_keras.layers.Activation('linear', name=name)(x)
 
   def _build_stem(self, inputs):
     """Builds SpineNet stem."""
     x = layers.Conv2D(
         filters=int(FILTER_SIZE_MAP[0] * self._filter_size_scale),
         kernel_size=3,
         strides=2,
@@ -284,15 +282,16 @@
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)(
             inputs)
     x = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)(
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)(
             x)
     x = tf_utils.get_activation(self._activation, use_keras_layer=True)(x)
 
     net = []
     stem_strides = [1, 2]
     # Build the initial level 2 blocks.
     for i in range(self._num_init_blocks):
@@ -422,15 +421,16 @@
           kernel_initializer=self._kernel_initializer,
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)(
               net[str(level)])
       x = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)(
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn)(
               x)
       x = tf_utils.get_activation(self._activation, use_keras_layer=True)(x)
       endpoints[str(level)] = x
     return endpoints
 
   def _resample_with_sepconv(self, inputs, input_width, target_width,
                              target_num_filters):
@@ -447,15 +447,16 @@
             kernel_initializer=self._kernel_initializer,
             kernel_regularizer=self._kernel_regularizer,
             bias_regularizer=self._bias_regularizer)(
                 x)
         x = self._norm(
             axis=self._bn_axis,
             momentum=self._norm_momentum,
-            epsilon=self._norm_epsilon)(
+            epsilon=self._norm_epsilon,
+            synchronized=self._use_sync_bn)(
                 x)
         x = tf_utils.get_activation(
             self._activation, use_keras_layer=True)(x)
         input_width /= 2
     elif input_width < target_width:
       scale = target_width // input_width
       x = spatial_transform_ops.nearest_upsampling(
@@ -470,15 +471,16 @@
         kernel_initializer=self._kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)(
             x)
     x = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)(
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)(
             x)
     return x
 
   def get_config(self):
     config_dict = {
         'min_level': self._min_level,
         'max_level': self._max_level,
@@ -507,18 +509,18 @@
   def output_specs(self):
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
 @factory.register_backbone_builder('spinenet_mobile')
 def build_spinenet_mobile(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     backbone_config: hyperparams.Config,
     norm_activation_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:
+    l2_regularizer: tf_keras.regularizers.Regularizer = None) -> tf_keras.Model:
   """Builds Mobile SpineNet backbone from a config."""
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'spinenet_mobile', (f'Inconsistent backbone type '
                                               f'{backbone_type}')
 
   model_id = backbone_cfg.model_id
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/spinenet_mobile_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/spinenet_mobile_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -25,15 +25,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 """Tests for SpineNet."""
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import spinenet_mobile
 
 
 class SpineNetMobileTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
@@ -43,30 +43,30 @@
   )
   def test_network_creation(self, input_size, filter_size_scale, block_repeats,
                             se_ratio, endpoints_num_filters):
     """Test creation of SpineNet models."""
     min_level = 3
     max_level = 7
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, input_size, input_size, 3])
     model = spinenet_mobile.SpineNetMobile(
         input_specs=input_specs,
         min_level=min_level,
         max_level=max_level,
         endpoints_num_filters=endpoints_num_filters,
         resample_alpha=se_ratio,
         block_repeats=block_repeats,
         filter_size_scale=filter_size_scale,
         init_stochastic_depth_rate=0.2,
     )
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = model(inputs)
 
     for l in range(min_level, max_level + 1):
       self.assertIn(str(l), endpoints.keys())
       self.assertAllEqual(
           [1, input_size / 2**l, input_size / 2**l, endpoints_num_filters],
           endpoints[str(l)].shape.as_list())
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/spinenet_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/spinenet_test.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for SpineNet."""
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import spinenet
 
 
 class SpineNetTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
@@ -30,30 +30,30 @@
       (640, 1.3, 4, 1.0, 384, 3, 7),
   )
   def test_network_creation(self, input_size, filter_size_scale, block_repeats,
                             resample_alpha, endpoints_num_filters, min_level,
                             max_level):
     """Test creation of SpineNet models."""
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, input_size, input_size, 3])
     model = spinenet.SpineNet(
         input_specs=input_specs,
         min_level=min_level,
         max_level=max_level,
         endpoints_num_filters=endpoints_num_filters,
         resample_alpha=resample_alpha,
         block_repeats=block_repeats,
         filter_size_scale=filter_size_scale,
         init_stochastic_depth_rate=0.2,
     )
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     endpoints = model(inputs)
 
     for l in range(min_level, max_level + 1):
       self.assertIn(str(l), endpoints.keys())
       self.assertAllEqual(
           [1, input_size / 2**l, input_size / 2**l, endpoints_num_filters],
           endpoints[str(l)].shape.as_list())
@@ -63,16 +63,16 @@
       ((128, 128), (256, 256)),
       ((640, 640), (896, 1664)),
   )
   def test_load_from_different_input_specs(self, input_size_1, input_size_2):
     """Test loading checkpoints with different input size."""
 
     def build_spinenet(input_size):
-      tf.keras.backend.set_image_data_format('channels_last')
-      input_specs = tf.keras.layers.InputSpec(
+      tf_keras.backend.set_image_data_format('channels_last')
+      input_specs = tf_keras.layers.InputSpec(
           shape=[None, input_size[0], input_size[1], 3])
       model = spinenet.SpineNet(
           input_specs=input_specs,
           min_level=3,
           max_level=7,
           endpoints_num_filters=384,
           resample_alpha=1.0,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/vit.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/vit.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,37 +10,39 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """VisionTransformer models."""
 
+import math
 from typing import Optional, Tuple
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import activations
 from official.vision.modeling.backbones import factory
 from official.vision.modeling.backbones.vit_specs import VIT_SPECS
 from official.vision.modeling.layers import nn_blocks
 from official.vision.modeling.layers import nn_layers
 
-layers = tf.keras.layers
 
+layers = tf_keras.layers
 
-class AddPositionEmbs(tf.keras.layers.Layer):
+
+class AddPositionEmbs(layers.Layer):
   """Adds (optionally learned) positional embeddings to the inputs."""
 
   def __init__(self,
-               posemb_init: Optional[tf.keras.initializers.Initializer] = None,
+               posemb_init: Optional[tf_keras.initializers.Initializer] = None,
                posemb_origin_shape: Optional[Tuple[int, int]] = None,
                posemb_target_shape: Optional[Tuple[int, int]] = None,
                **kwargs):
-    """Constructs Postional Embedding module.
+    """Constructs Positional Embedding module.
 
     The logic of this module is: the learnable positional embeddings length will
     be determined by the inputs_shape or posemb_origin_shape (if provided)
     during the construction. If the posemb_target_shape is provided and is
     different from the positional embeddings length, the embeddings will be
     interpolated during the forward call.
 
@@ -64,15 +66,15 @@
     pos_emb_shape = (1, pos_emb_length, inputs_shape[2])
     self.pos_embedding = self.add_weight(
         'pos_embedding', pos_emb_shape, initializer=self.posemb_init)
 
   def _interpolate(self, pos_embedding: tf.Tensor, from_shape: Tuple[int, int],
                    to_shape: Tuple[int, int]) -> tf.Tensor:
     """Interpolates the positional embeddings."""
-    logging.info('Interpolating postional embedding from length: %d to %d',
+    logging.info('Interpolating postional embedding from length: %s to %s',
                  from_shape, to_shape)
     grid_emb = tf.reshape(pos_embedding, [1] + list(from_shape) + [-1])
     # NOTE: Using BILINEAR interpolation by default.
     grid_emb = tf.image.resize(grid_emb, to_shape)
     return tf.reshape(grid_emb, [1, to_shape[0] * to_shape[1], -1])
 
   def call(self, inputs, inputs_positions=None):
@@ -85,29 +87,29 @@
           from_shape=self.posemb_origin_shape,
           to_shape=self.posemb_target_shape)
     pos_embedding = tf.cast(pos_embedding, inputs.dtype)
 
     return inputs + pos_embedding
 
 
-class TokenLayer(tf.keras.layers.Layer):
+class TokenLayer(layers.Layer):
   """A simple layer to wrap token parameters."""
 
   def build(self, inputs_shape):
     self.cls = self.add_weight(
         'cls', (1, 1, inputs_shape[-1]), initializer='zeros')
 
   def call(self, inputs):
     cls = tf.cast(self.cls, inputs.dtype)
     cls = cls + tf.zeros_like(inputs[:, 0:1])  # A hacky way to tile.
     x = tf.concat([cls, inputs], axis=1)
     return x
 
 
-class Encoder(tf.keras.layers.Layer):
+class Encoder(layers.Layer):
   """Transformer Encoder."""
 
   def __init__(self,
                num_layers,
                mlp_dim,
                num_heads,
                dropout_rate=0.1,
@@ -115,33 +117,37 @@
                kernel_regularizer=None,
                inputs_positions=None,
                init_stochastic_depth_rate=0.0,
                kernel_initializer='glorot_uniform',
                add_pos_embed=True,
                pos_embed_origin_shape=None,
                pos_embed_target_shape=None,
+               layer_scale_init_value=0.0,
+               transformer_partition_dims=None,
                **kwargs):
     super().__init__(**kwargs)
     self._num_layers = num_layers
     self._mlp_dim = mlp_dim
     self._num_heads = num_heads
     self._dropout_rate = dropout_rate
     self._attention_dropout_rate = attention_dropout_rate
     self._kernel_regularizer = kernel_regularizer
     self._inputs_positions = inputs_positions
     self._init_stochastic_depth_rate = init_stochastic_depth_rate
     self._kernel_initializer = kernel_initializer
     self._add_pos_embed = add_pos_embed
     self._pos_embed_origin_shape = pos_embed_origin_shape
     self._pos_embed_target_shape = pos_embed_target_shape
+    self._layer_scale_init_value = layer_scale_init_value
+    self._transformer_partition_dims = transformer_partition_dims
 
   def build(self, input_shape):
     if self._add_pos_embed:
       self._pos_embed = AddPositionEmbs(
-          posemb_init=tf.keras.initializers.RandomNormal(stddev=0.02),
+          posemb_init=tf_keras.initializers.RandomNormal(stddev=0.02),
           posemb_origin_shape=self._pos_embed_origin_shape,
           posemb_target_shape=self._pos_embed_target_shape,
           name='posembed_input')
     self._dropout = layers.Dropout(rate=self._dropout_rate)
 
     self._encoder_layers = []
     # Set layer norm epsilons to 1e-6 to be consistent with JAX implementation.
@@ -154,15 +160,17 @@
           output_dropout=self._dropout_rate,
           attention_dropout=self._attention_dropout_rate,
           kernel_regularizer=self._kernel_regularizer,
           kernel_initializer=self._kernel_initializer,
           norm_first=True,
           stochastic_depth_drop_rate=nn_layers.get_stochastic_depth_rate(
               self._init_stochastic_depth_rate, i + 1, self._num_layers),
-          norm_epsilon=1e-6)
+          norm_epsilon=1e-6,
+          layer_scale_init_value=self._layer_scale_init_value,
+          transformer_partition_dims=self._transformer_partition_dims)
       self._encoder_layers.append(encoder_layer)
     self._norm = layers.LayerNormalization(epsilon=1e-6)
     super().build(input_shape)
 
   def call(self, inputs, training=None):
     x = inputs
     if self._add_pos_embed:
@@ -185,67 +193,76 @@
         'kernel_regularizer': self._kernel_regularizer,
         'inputs_positions': self._inputs_positions,
         'init_stochastic_depth_rate': self._init_stochastic_depth_rate,
         'kernel_initializer': self._kernel_initializer,
         'add_pos_embed': self._add_pos_embed,
         'pos_embed_origin_shape': self._pos_embed_origin_shape,
         'pos_embed_target_shape': self._pos_embed_target_shape,
+        'layer_scale_init_value': self._layer_scale_init_value,
+        'transformer_partition_dims': self._transformer_partition_dims,
     }
     config.update(updates)
     return config
 
 
-class VisionTransformer(tf.keras.Model):
+class VisionTransformer(tf_keras.Model):
   """Class to build VisionTransformer family model."""
 
-  def __init__(self,
-               mlp_dim=3072,
-               num_heads=12,
-               num_layers=12,
-               attention_dropout_rate=0.0,
-               dropout_rate=0.1,
-               init_stochastic_depth_rate=0.0,
-               input_specs=layers.InputSpec(shape=[None, None, None, 3]),
-               patch_size=16,
-               hidden_size=768,
-               representation_size=0,
-               pooler='token',
-               kernel_regularizer=None,
-               original_init: bool = True,
-               pos_embed_shape: Optional[Tuple[int, int]] = None):
+  def __init__(
+      self,
+      mlp_dim=3072,
+      num_heads=12,
+      num_layers=12,
+      attention_dropout_rate=0.0,
+      dropout_rate=0.1,
+      init_stochastic_depth_rate=0.0,
+      input_specs=layers.InputSpec(shape=[None, None, None, 3]),
+      patch_size=16,
+      hidden_size=768,
+      representation_size=0,
+      pooler='token',
+      kernel_regularizer=None,
+      original_init: bool = True,
+      output_encoded_tokens: bool = True,
+      output_2d_feature_maps: bool = False,
+      pos_embed_shape: Optional[Tuple[int, int]] = None,
+      layer_scale_init_value: float = 0.0,
+      transformer_partition_dims: Optional[Tuple[int, int, int, int]] = None,
+  ):
     """VisionTransformer initialization function."""
     self._mlp_dim = mlp_dim
     self._num_heads = num_heads
     self._num_layers = num_layers
     self._hidden_size = hidden_size
     self._patch_size = patch_size
 
-    inputs = tf.keras.Input(shape=input_specs.shape[1:])
+    inputs = tf_keras.Input(shape=input_specs.shape[1:])
 
     x = layers.Conv2D(
         filters=hidden_size,
         kernel_size=patch_size,
         strides=patch_size,
         padding='valid',
         kernel_regularizer=kernel_regularizer,
         kernel_initializer='lecun_normal' if original_init else 'he_uniform')(
             inputs)
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       rows_axis, cols_axis = (1, 2)
     else:
       rows_axis, cols_axis = (2, 3)
       # The reshape below assumes the data_format is 'channels_last,' so
       # transpose to that. Once the data is flattened by the reshape, the
       # data_format is irrelevant, so no need to update
-      # tf.keras.backend.image_data_format.
+      # tf_keras.backend.image_data_format.
       x = tf.transpose(x, perm=[0, 2, 3, 1])
 
     pos_embed_target_shape = (x.shape[rows_axis], x.shape[cols_axis])
-    seq_len = (input_specs.shape[rows_axis] // patch_size) * (
-        input_specs.shape[cols_axis] // patch_size)
+    feat_h = input_specs.shape[rows_axis] // patch_size
+    feat_w = input_specs.shape[cols_axis] // patch_size
+    seq_len = feat_h * feat_w
     x = tf.reshape(x, [-1, seq_len, hidden_size])
 
     # If we want to add a class token, add it here.
     if pooler == 'token':
       x = TokenLayer(name='cls')(x)
 
     x = Encoder(
@@ -255,59 +272,95 @@
         dropout_rate=dropout_rate,
         attention_dropout_rate=attention_dropout_rate,
         kernel_regularizer=kernel_regularizer,
         kernel_initializer='glorot_uniform' if original_init else dict(
             class_name='TruncatedNormal', config=dict(stddev=.02)),
         init_stochastic_depth_rate=init_stochastic_depth_rate,
         pos_embed_origin_shape=pos_embed_shape,
-        pos_embed_target_shape=pos_embed_target_shape)(
+        pos_embed_target_shape=pos_embed_target_shape,
+        layer_scale_init_value=layer_scale_init_value)(
             x)
 
     if pooler == 'token':
+      output_feature = x[:, 1:]
       x = x[:, 0]
     elif pooler == 'gap':
+      output_feature = x
       x = tf.reduce_mean(x, axis=1)
     elif pooler == 'none':
+      output_feature = x
       x = tf.identity(x, name='encoded_tokens')
     else:
       raise ValueError(f'unrecognized pooler type: {pooler}')
 
+    endpoints = {}
+    if output_2d_feature_maps:
+      # Use the closest feature level.
+      feat_level = round(math.log2(patch_size))
+      logging.info(
+          'VisionTransformer patch size %d and feature level: %d',
+          patch_size,
+          feat_level,
+      )
+      endpoints[str(feat_level)] = tf.reshape(
+          output_feature, [-1, feat_h, feat_w, x.shape.as_list()[-1]])
+
+      # Don"t include `pre_logits` or `encoded_tokens` to support decoders.
+      self._output_specs = {k: v.shape for k, v in endpoints.items()}
+
     if representation_size:
-      x = tf.keras.layers.Dense(
+      x = layers.Dense(
           representation_size,
           kernel_regularizer=kernel_regularizer,
           name='pre_logits',
-          kernel_initializer='lecun_normal' if original_init else 'he_uniform')(
-              x)
+          kernel_initializer='lecun_normal' if original_init else 'he_uniform',
+      )(x)
       x = tf.nn.tanh(x)
     else:
       x = tf.identity(x, name='pre_logits')
 
     if pooler == 'none':
-      endpoints = {'encoded_tokens': x}
+      if output_encoded_tokens:
+        endpoints['encoded_tokens'] = x
     else:
-      endpoints = {
-          'pre_logits':
-              tf.reshape(x, [-1, 1, 1, representation_size or hidden_size])
-      }
-    super(VisionTransformer, self).__init__(inputs=inputs, outputs=endpoints)
+      endpoints['pre_logits'] = tf.reshape(
+          x, [-1, 1, 1, representation_size or hidden_size])
+
+    super().__init__(inputs=inputs, outputs=endpoints)
+
+  @property
+  def output_specs(self):
+    """A dict of {level: TensorShape} pairs for the model output."""
+    return self._output_specs
 
 
 @factory.register_backbone_builder('vit')
 def build_vit(input_specs,
               backbone_config,
               norm_activation_config,
               l2_regularizer=None):
   """Build ViT model."""
   del norm_activation_config
   backbone_type = backbone_config.type
   backbone_cfg = backbone_config.get()
   assert backbone_type == 'vit', (f'Inconsistent backbone type '
                                   f'{backbone_type}')
   backbone_cfg.override(VIT_SPECS[backbone_cfg.model_name])
+  logging.info(
+      (
+          'ViT specs: mlp_dim=%d, num_heads=%d, num_layers=%d,'
+          'patch_size=%d, hidden_size=%d, representation_size=%d.'
+      ),
+      backbone_cfg.transformer.mlp_dim,
+      backbone_cfg.transformer.num_heads,
+      backbone_cfg.transformer.num_layers,
+      backbone_cfg.patch_size,
+      backbone_cfg.hidden_size,
+      backbone_cfg.representation_size,
+  )
 
   return VisionTransformer(
       mlp_dim=backbone_cfg.transformer.mlp_dim,
       num_heads=backbone_cfg.transformer.num_heads,
       num_layers=backbone_cfg.transformer.num_layers,
       attention_dropout_rate=backbone_cfg.transformer.attention_dropout_rate,
       dropout_rate=backbone_cfg.transformer.dropout_rate,
@@ -315,8 +368,12 @@
       input_specs=input_specs,
       patch_size=backbone_cfg.patch_size,
       hidden_size=backbone_cfg.hidden_size,
       representation_size=backbone_cfg.representation_size,
       pooler=backbone_cfg.pooler,
       kernel_regularizer=l2_regularizer,
       original_init=backbone_cfg.original_init,
-      pos_embed_shape=backbone_cfg.pos_embed_shape)
+      output_encoded_tokens=backbone_cfg.output_encoded_tokens,
+      output_2d_feature_maps=backbone_cfg.output_2d_feature_maps,
+      layer_scale_init_value=backbone_cfg.layer_scale_init_value,
+      pos_embed_shape=backbone_cfg.pos_embed_shape,
+      transformer_partition_dims=backbone_cfg.transformer_partition_dims)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/vit_specs.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/vit_specs.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -57,12 +57,24 @@
         dict(
             hidden_size=1280,
             patch_size=14,
             transformer=dict(mlp_dim=5120, num_heads=16, num_layers=32),
         ),
     'vit-g14':
         dict(
+            hidden_size=1408,
+            patch_size=14,
+            transformer=dict(mlp_dim=5632, num_heads=16, num_layers=40),
+        ),
+    'vit-G14':
+        dict(
             hidden_size=1664,
             patch_size=14,
             transformer=dict(mlp_dim=8192, num_heads=16, num_layers=48),
         ),
+    'vit-e14':
+        dict(
+            hidden_size=1792,
+            patch_size=14,
+            transformer=dict(mlp_dim=15360, num_heads=16, num_layers=56),
+        ),
 })
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/backbones/vit_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/backbones/vit_test.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,64 +10,91 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for VIT."""
 
+import math
+
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import vit
 
 
 class VisionTransformerTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
       (224, 85798656),
       (256, 85844736),
   )
   def test_network_creation(self, input_size, params_count):
     """Test creation of VisionTransformer family models."""
-    tf.keras.backend.set_image_data_format('channels_last')
-    input_specs = tf.keras.layers.InputSpec(
+    tf_keras.backend.set_image_data_format('channels_last')
+    input_specs = tf_keras.layers.InputSpec(
         shape=[2, input_size, input_size, 3])
     network = vit.VisionTransformer(input_specs=input_specs)
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     _ = network(inputs)
     self.assertEqual(network.count_params(), params_count)
 
-  def test_network_none_pooler(self):
-    tf.keras.backend.set_image_data_format('channels_last')
-    input_size = 256
-    input_specs = tf.keras.layers.InputSpec(
+  @parameterized.product(
+      patch_size=[6, 4],
+      output_2d_feature_maps=[True, False],
+      pooler=['none', 'gap', 'token'],
+  )
+  def test_network_with_diferent_configs(
+      self, patch_size, output_2d_feature_maps, pooler):
+    tf_keras.backend.set_image_data_format('channels_last')
+    input_size = 24
+    expected_feat_level = str(round(math.log2(patch_size)))
+    num_patch_rows = input_size // patch_size
+    input_specs = tf_keras.layers.InputSpec(
         shape=[2, input_size, input_size, 3])
     network = vit.VisionTransformer(
         input_specs=input_specs,
-        patch_size=16,
-        pooler='none',
-        representation_size=128,
-        pos_embed_shape=(14, 14))  # (224 // 16)
-
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
-    output = network(inputs)['encoded_tokens']
-    self.assertEqual(output.shape, [1, 256, 128])
+        patch_size=patch_size,
+        pooler=pooler,
+        hidden_size=8,
+        mlp_dim=8,
+        num_layers=1,
+        num_heads=2,
+        representation_size=16,
+        output_2d_feature_maps=output_2d_feature_maps)
+
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    output = network(inputs)
+    if pooler == 'none':
+      self.assertEqual(
+          output['encoded_tokens'].shape, [1, num_patch_rows**2, 16])
+    else:
+      self.assertEqual(output['pre_logits'].shape, [1, 1, 1, 16])
+
+    if output_2d_feature_maps:
+      self.assertIn(expected_feat_level, output)
+      self.assertIn(expected_feat_level, network.output_specs)
+      self.assertEqual(
+          network.output_specs[expected_feat_level][1:],
+          [num_patch_rows, num_patch_rows, 8])
+    else:
+      self.assertNotIn(expected_feat_level, output)
 
   def test_posembedding_interpolation(self):
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     input_size = 256
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[2, input_size, input_size, 3])
     network = vit.VisionTransformer(
         input_specs=input_specs,
         patch_size=16,
         pooler='gap',
         pos_embed_shape=(14, 14))  # (224 // 16)
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
     output = network(inputs)['pre_logits']
     self.assertEqual(output.shape, [1, 1, 1, 768])
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/classification_model.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/classification_model.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,76 +12,86 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Build classification models."""
 
 from typing import Any, Mapping, Optional
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ClassificationModel(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ClassificationModel(tf_keras.Model):
   """A classification class builder."""
 
   def __init__(
       self,
-      backbone: tf.keras.Model,
+      backbone: tf_keras.Model,
       num_classes: int,
-      input_specs: tf.keras.layers.InputSpec = layers.InputSpec(
+      input_specs: tf_keras.layers.InputSpec = layers.InputSpec(
           shape=[None, None, None, 3]),
       dropout_rate: float = 0.0,
       kernel_initializer: str = 'random_uniform',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       add_head_batch_norm: bool = False,
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       skip_logits_layer: bool = False,
       **kwargs):
     """Classification initialization function.
 
     Args:
       backbone: a backbone network.
       num_classes: `int` number of classes in classification task.
-      input_specs: `tf.keras.layers.InputSpec` specs of the input tensor.
+      input_specs: `tf_keras.layers.InputSpec` specs of the input tensor.
       dropout_rate: `float` rate for dropout regularization.
       kernel_initializer: kernel initializer for the dense layer.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object. Default to
+      kernel_regularizer: tf_keras.regularizers.Regularizer object. Default to
                           None.
-      bias_regularizer: tf.keras.regularizers.Regularizer object. Default to
+      bias_regularizer: tf_keras.regularizers.Regularizer object. Default to
                           None.
       add_head_batch_norm: `bool` whether to add a batch normalization layer
         before pool.
       use_sync_bn: `bool` if True, use synchronized batch normalization.
       norm_momentum: `float` normalization momentum for the moving average.
       norm_epsilon: `float` small float added to variance to avoid dividing by
         zero.
       skip_logits_layer: `bool`, whether to skip the prediction layer.
       **kwargs: keyword arguments to be passed.
     """
-    if use_sync_bn:
-      norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      norm = tf.keras.layers.BatchNormalization
-    axis = -1 if tf.keras.backend.image_data_format() == 'channels_last' else 1
+    norm = tf_keras.layers.BatchNormalization
+    axis = -1 if tf_keras.backend.image_data_format() == 'channels_last' else 1
 
-    inputs = tf.keras.Input(shape=input_specs.shape[1:], name=input_specs.name)
+    inputs = tf_keras.Input(shape=input_specs.shape[1:], name=input_specs.name)
     endpoints = backbone(inputs)
     x = endpoints[max(endpoints.keys())]
 
     if add_head_batch_norm:
-      x = norm(axis=axis, momentum=norm_momentum, epsilon=norm_epsilon)(x)
-    x = tf.keras.layers.GlobalAveragePooling2D()(x)
+      x = norm(
+          axis=axis,
+          momentum=norm_momentum,
+          epsilon=norm_epsilon,
+          synchronized=use_sync_bn,
+      )(x)
+
+    # Depending on the backbone type, backbone's output can be
+    # [batch_size, height, weight, channel_size] or
+    # [batch_size, token_size, hidden_size].
+    if len(x.shape) == 4:
+      x = tf_keras.layers.GlobalAveragePooling2D()(x)
+    elif len(x.shape) == 3:
+      x = tf_keras.layers.GlobalAveragePooling1D()(x)
+
     if not skip_logits_layer:
-      x = tf.keras.layers.Dropout(dropout_rate)(x)
-      x = tf.keras.layers.Dense(
+      x = tf_keras.layers.Dropout(dropout_rate)(x)
+      x = tf_keras.layers.Dense(
           num_classes,
           kernel_initializer=kernel_initializer,
           kernel_regularizer=kernel_regularizer,
           bias_regularizer=bias_regularizer)(
               x)
 
     super(ClassificationModel, self).__init__(
@@ -102,20 +112,20 @@
     self._input_specs = input_specs
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     self._backbone = backbone
     self._norm = norm
 
   @property
-  def checkpoint_items(self) -> Mapping[str, tf.keras.Model]:
+  def checkpoint_items(self) -> Mapping[str, tf_keras.Model]:
     """Returns a dictionary of items to be additionally checkpointed."""
     return dict(backbone=self.backbone)
 
   @property
-  def backbone(self) -> tf.keras.Model:
+  def backbone(self) -> tf_keras.Model:
     return self._backbone
 
   def get_config(self) -> Mapping[str, Any]:
     return self._config_dict
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/classification_model_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/classification_model_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for classification network."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.vision.modeling import backbones
 from official.vision.modeling import classification_model
 
 
@@ -32,22 +32,22 @@
       (384 * 4, 6, 12, 384, 21665664),
   )
   def test_vision_transformer_creation(self, mlp_dim, num_heads, num_layers,
                                        hidden_size, num_params):
     """Test for creation of a Vision Transformer classifier."""
     inputs = np.random.rand(2, 224, 224, 3)
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = backbones.VisionTransformer(
         mlp_dim=mlp_dim,
         num_heads=num_heads,
         num_layers=num_layers,
         hidden_size=hidden_size,
-        input_specs=tf.keras.layers.InputSpec(shape=[None, 224, 224, 3]),
+        input_specs=tf_keras.layers.InputSpec(shape=[None, 224, 224, 3]),
     )
     self.assertEqual(backbone.count_params(), num_params)
 
     num_classes = 1000
     model = classification_model.ClassificationModel(
         backbone=backbone,
         num_classes=num_classes,
@@ -63,15 +63,15 @@
       (128, 50, 'swish'),
   )
   def test_resnet_network_creation(self, input_size, resnet_model_id,
                                    activation):
     """Test for creation of a ResNet-50 classifier."""
     inputs = np.random.rand(2, input_size, input_size, 3)
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = backbones.ResNet(model_id=resnet_model_id, activation=activation)
     self.assertEqual(backbone.count_params(), 23561152)
 
     num_classes = 1000
     model = classification_model.ClassificationModel(
         backbone=backbone,
@@ -84,15 +84,15 @@
     self.assertAllEqual([2, num_classes], logits.numpy().shape)
 
   def test_revnet_network_creation(self):
     """Test for creation of a RevNet-56 classifier."""
     revnet_model_id = 56
     inputs = np.random.rand(2, 224, 224, 3)
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = backbones.RevNet(model_id=revnet_model_id)
     self.assertEqual(backbone.count_params(), 19473792)
 
     num_classes = 1000
     model = classification_model.ClassificationModel(
         backbone=backbone,
@@ -119,15 +119,15 @@
           filter_size_scale=[1.0, 0.75],
       ))
   def test_mobilenet_network_creation(self, mobilenet_model_id,
                                       filter_size_scale):
     """Test for creation of a MobileNet classifier."""
     inputs = np.random.rand(2, 224, 224, 3)
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = backbones.MobileNet(
         model_id=mobilenet_model_id, filter_size_scale=filter_size_scale)
 
     num_classes = 1001
     model = classification_model.ClassificationModel(
         backbone=backbone,
@@ -146,15 +146,15 @@
           ],
           use_sync_bn=[False, True],
       ))
   def test_sync_bn_multiple_devices(self, strategy, use_sync_bn):
     """Test for sync bn on TPU and GPU devices."""
     inputs = np.random.rand(64, 128, 128, 3)
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     with strategy.scope():
       backbone = backbones.ResNet(model_id=50, use_sync_bn=use_sync_bn)
 
       model = classification_model.ClassificationModel(
           backbone=backbone,
           num_classes=1000,
@@ -171,32 +171,32 @@
           input_dim=[1, 3, 4]))
   def test_data_format_gpu(self, strategy, data_format, input_dim):
     """Test for different data formats on GPU devices."""
     if data_format == 'channels_last':
       inputs = np.random.rand(2, 128, 128, input_dim)
     else:
       inputs = np.random.rand(2, input_dim, 128, 128)
-    input_specs = tf.keras.layers.InputSpec(shape=inputs.shape)
+    input_specs = tf_keras.layers.InputSpec(shape=inputs.shape)
 
-    tf.keras.backend.set_image_data_format(data_format)
+    tf_keras.backend.set_image_data_format(data_format)
 
     with strategy.scope():
       backbone = backbones.ResNet(model_id=50, input_specs=input_specs)
 
       model = classification_model.ClassificationModel(
           backbone=backbone,
           num_classes=1000,
           input_specs=input_specs,
       )
       _ = model(inputs)
 
   def test_serialize_deserialize(self):
     """Validate the classification net can be serialized and deserialized."""
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     backbone = backbones.ResNet(model_id=50)
 
     model = classification_model.ClassificationModel(
         backbone=backbone, num_classes=1000)
 
     config = model.get_config()
     new_model = classification_model.ClassificationModel.from_config(config)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/aspp.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/aspp.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,41 +13,41 @@
 # limitations under the License.
 
 """Contains definitions of Atrous Spatial Pyramid Pooling (ASPP) decoder."""
 from typing import Any, List, Mapping, Optional, Union
 
 # Import libraries
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.vision.modeling.decoders import factory
 from official.vision.modeling.layers import deeplab
 from official.vision.modeling.layers import nn_layers
 
 TensorMapUnion = Union[tf.Tensor, Mapping[str, tf.Tensor]]
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ASPP(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ASPP(tf_keras.layers.Layer):
   """Creates an Atrous Spatial Pyramid Pooling (ASPP) layer."""
 
   def __init__(
       self,
       level: int,
       dilation_rates: List[int],
       num_filters: int = 256,
       pool_kernel_size: Optional[int] = None,
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       activation: str = 'relu',
       dropout_rate: float = 0.0,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       interpolation: str = 'bilinear',
       use_depthwise_convolution: bool = False,
       spp_layer_version: str = 'v1',
       output_tensor: bool = False,
       **kwargs):
     """Initializes an Atrous Spatial Pyramid Pooling (ASPP) layer.
 
@@ -61,15 +61,15 @@
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       activation: A `str` activation to be used in ASPP.
       dropout_rate: A `float` rate for dropout regularization.
       kernel_initializer: A `str` name of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
       interpolation: A `str` of interpolation method. It should be one of
         `bilinear`, `nearest`, `bicubic`, `area`, `lanczos3`, `lanczos5`,
         `gaussian`, or `mitchellcubic`.
       use_depthwise_convolution: If True depthwise separable convolutions will
         be added to the Atrous spatial pyramid pooling.
      spp_layer_version: A `str` of spatial pyramid pooling layer version.
@@ -157,28 +157,28 @@
     return cls(**config)
 
 
 @factory.register_decoder_builder('aspp')
 def build_aspp_decoder(
     input_specs: Mapping[str, tf.TensorShape],
     model_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None
+) -> tf_keras.Model:
   """Builds ASPP decoder from a config.
 
   Args:
     input_specs: A `dict` of input specifications. A dictionary consists of
       {level: TensorShape} from a backbone. Note this is for consistent
         interface, and is not used by ASPP decoder.
     model_config: A OneOfConfig. Model config.
-    l2_regularizer: A `tf.keras.regularizers.Regularizer` instance. Default to
+    l2_regularizer: A `tf_keras.regularizers.Regularizer` instance. Default to
       None.
 
   Returns:
-    A `tf.keras.Model` instance of the ASPP decoder.
+    A `tf_keras.Model` instance of the ASPP decoder.
 
   Raises:
     ValueError: If the model_config.decoder.type is not `aspp`.
   """
   del input_specs  # input_specs is not used by ASPP decoder.
   decoder_type = model_config.decoder.type
   decoder_cfg = model_config.decoder.get()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/aspp_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/aspp_test.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for aspp."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import resnet
 from official.vision.modeling.decoders import aspp
 
 
 class ASPPTest(parameterized.TestCase, tf.test.TestCase):
 
@@ -33,17 +33,17 @@
       (4, [6, 12], 256, 'v2'),
   )
   def test_network_creation(self, level, dilation_rates, num_filters,
                             spp_layer_version):
     """Test creation of ASPP."""
 
     input_size = 256
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
 
     backbone = resnet.ResNet(model_id=50)
     network = aspp.ASPP(
         level=level,
         dilation_rates=dilation_rates,
         num_filters=num_filters,
         spp_layer_version=spp_layer_version)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/factory.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/factory.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -39,30 +39,30 @@
 then don't imported the decoder module in decoders/__init__.py, but import it
 in place that uses it.
 """
 from typing import Any, Callable, Mapping, Optional, Union
 
 # Import libraries
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import registry
 from official.modeling import hyperparams
 
 _REGISTERED_DECODER_CLS = {}
 
 
 def register_decoder_builder(key: str) -> Callable[..., Any]:
   """Decorates a builder of decoder class.
 
   The builder should be a Callable (a class or a function).
   This decorator supports registration of decoder builder as follows:
 
   ```
-  class MyDecoder(tf.keras.Model):
+  class MyDecoder(tf_keras.Model):
     pass
 
   @register_decoder_builder('mydecoder')
   def builder(input_specs, config, l2_reg):
     return MyDecoder(...)
 
   # Builds a MyDecoder object.
@@ -79,50 +79,50 @@
   return registry.register(_REGISTERED_DECODER_CLS, key)
 
 
 @register_decoder_builder('identity')
 def build_identity(
     input_specs: Optional[Mapping[str, tf.TensorShape]] = None,
     model_config: Optional[hyperparams.Config] = None,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None) -> None:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None) -> None:
   """Builds identity decoder from a config.
 
   All the input arguments are not used by identity decoder but kept here to
   ensure the interface is consistent.
 
   Args:
     input_specs: A `dict` of input specifications. A dictionary consists of
       {level: TensorShape} from a backbone.
     model_config: A `OneOfConfig` of model config.
-    l2_regularizer: A `tf.keras.regularizers.Regularizer` object. Default to
+    l2_regularizer: A `tf_keras.regularizers.Regularizer` object. Default to
       None.
 
   Returns:
     An instance of the identity decoder.
   """
   del input_specs, model_config, l2_regularizer  # Unused by identity decoder.
 
 
 def build_decoder(
     input_specs: Mapping[str, tf.TensorShape],
     model_config: hyperparams.Config,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None,
-    **kwargs) -> Union[None, tf.keras.Model, tf.keras.layers.Layer]:  # pytype: disable=annotation-type-mismatch  # typed-keras
+    l2_regularizer: tf_keras.regularizers.Regularizer = None,
+    **kwargs) -> Union[None, tf_keras.Model, tf_keras.layers.Layer]:  # pytype: disable=annotation-type-mismatch  # typed-keras
   """Builds decoder from a config.
 
   A decoder can be a keras.Model, a keras.layers.Layer, or None. If it is not
   None, the decoder will take features from the backbone as input and generate
   decoded feature maps. If it is None, such as an identity decoder, the decoder
   is skipped and features from the backbone are regarded as model output.
 
   Args:
     input_specs: A `dict` of input specifications. A dictionary consists of
       {level: TensorShape} from a backbone.
     model_config: A `OneOfConfig` of model config.
-    l2_regularizer: A `tf.keras.regularizers.Regularizer` object. Default to
+    l2_regularizer: A `tf_keras.regularizers.Regularizer` object. Default to
       None.
     **kwargs: Additional keyword args to be passed to decoder builder.
 
   Returns:
     An instance of the decoder.
   """
   decoder_builder = registry.lookup(_REGISTERED_DECODER_CLS,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/factory_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/factory_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for decoder factory functions."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from official.vision import configs
 from official.vision.configs import decoders as decoders_cfg
 from official.vision.modeling import decoders
 from official.vision.modeling.decoders import factory
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/fpn.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/fpn.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,27 +13,27 @@
 # limitations under the License.
 
 """Contains the definitions of Feature Pyramid Networks (FPN)."""
 from typing import Any, Mapping, Optional
 
 # Import libraries
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.decoders import factory
 from official.vision.ops import spatial_transform_ops
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class FPN(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class FPN(tf_keras.Model):
   """Creates a Feature Pyramid Network (FPN).
 
-  This implemets the paper:
+  This implements the paper:
   Tsung-Yi Lin, Piotr Dollar, Ross Girshick, Kaiming He, Bharath Hariharan, and
   Serge Belongie.
   Feature Pyramid Networks for Object Detection.
   (https://arxiv.org/pdf/1612.03144)
   """
 
   def __init__(
@@ -46,16 +46,16 @@
       use_separable_conv: bool = False,
       use_keras_layer: bool = False,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
     """Initializes a Feature Pyramid Network (FPN).
 
     Args:
       input_specs: A `dict` of input specifications. A dictionary consists of
         {level: TensorShape} from a backbone.
       min_level: An `int` of minimum level in FPN output feature maps.
@@ -68,17 +68,17 @@
       use_keras_layer: A `bool`. If Ture use keras layers as many as possible.
       activation: A `str` name of the activation function.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       kernel_initializer: A `str` name of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._config_dict = {
         'input_specs': input_specs,
         'min_level': min_level,
         'max_level': max_level,
         'num_filters': num_filters,
@@ -89,29 +89,26 @@
         'use_sync_bn': use_sync_bn,
         'norm_momentum': norm_momentum,
         'norm_epsilon': norm_epsilon,
         'kernel_initializer': kernel_initializer,
         'kernel_regularizer': kernel_regularizer,
         'bias_regularizer': bias_regularizer,
     }
-    if use_separable_conv:
-      conv2d = tf.keras.layers.SeparableConv2D
-    else:
-      conv2d = tf.keras.layers.Conv2D
-    if use_sync_bn:
-      norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      norm = tf.keras.layers.BatchNormalization
+    conv2d = (
+        tf_keras.layers.SeparableConv2D
+        if use_separable_conv
+        else tf_keras.layers.Conv2D
+    )
+    norm = tf_keras.layers.BatchNormalization
     activation_fn = tf_utils.get_activation(activation, use_keras_layer=True)
 
     # Build input feature pyramid.
-    if tf.keras.backend.image_data_format() == 'channels_last':
-      bn_axis = -1
-    else:
-      bn_axis = 1
+    bn_axis = (
+        -1 if tf_keras.backend.image_data_format() == 'channels_last' else 1
+    )
 
     # Get input feature pyramid from backbone.
     logging.info('FPN input_specs: %s', input_specs)
     inputs = self._build_input_pyramid(input_specs, min_level)
     backbone_max_level = min(int(max(inputs.keys())), max_level)
 
     # Build lateral connections.
@@ -119,90 +116,97 @@
     for level in range(min_level, backbone_max_level + 1):
       feats_lateral[str(level)] = conv2d(
           filters=num_filters,
           kernel_size=1,
           padding='same',
           kernel_initializer=kernel_initializer,
           kernel_regularizer=kernel_regularizer,
-          bias_regularizer=bias_regularizer)(
+          bias_regularizer=bias_regularizer,
+          name=f'lateral_{level}')(
               inputs[str(level)])
 
     # Build top-down path.
     feats = {str(backbone_max_level): feats_lateral[str(backbone_max_level)]}
     for level in range(backbone_max_level - 1, min_level - 1, -1):
       feat_a = spatial_transform_ops.nearest_upsampling(
           feats[str(level + 1)], 2, use_keras_layer=use_keras_layer)
       feat_b = feats_lateral[str(level)]
 
       if fusion_type == 'sum':
         if use_keras_layer:
-          feats[str(level)] = tf.keras.layers.Add()([feat_a, feat_b])
+          feats[str(level)] = tf_keras.layers.Add()([feat_a, feat_b])
         else:
           feats[str(level)] = feat_a + feat_b
       elif fusion_type == 'concat':
         if use_keras_layer:
-          feats[str(level)] = tf.keras.layers.Concatenate(axis=-1)(
+          feats[str(level)] = tf_keras.layers.Concatenate(axis=-1)(
               [feat_a, feat_b])
         else:
           feats[str(level)] = tf.concat([feat_a, feat_b], axis=-1)
       else:
         raise ValueError('Fusion type {} not supported.'.format(fusion_type))
 
-    # TODO(xianzhi): consider to remove bias in conv2d.
+    # TODO(fyangf): experiment with removing bias in conv2d.
     # Build post-hoc 3x3 convolution kernel.
     for level in range(min_level, backbone_max_level + 1):
       feats[str(level)] = conv2d(
           filters=num_filters,
           strides=1,
           kernel_size=3,
           padding='same',
           kernel_initializer=kernel_initializer,
           kernel_regularizer=kernel_regularizer,
-          bias_regularizer=bias_regularizer)(
+          bias_regularizer=bias_regularizer,
+          name=f'post_hoc_{level}')(
               feats[str(level)])
 
-    # TODO(xianzhi): consider to remove bias in conv2d.
+    # TODO(fyangf): experiment with removing bias in conv2d.
     # Build coarser FPN levels introduced for RetinaNet.
     for level in range(backbone_max_level + 1, max_level + 1):
       feats_in = feats[str(level - 1)]
       if level > backbone_max_level + 1:
         feats_in = activation_fn(feats_in)
       feats[str(level)] = conv2d(
           filters=num_filters,
           strides=2,
           kernel_size=3,
           padding='same',
           kernel_initializer=kernel_initializer,
           kernel_regularizer=kernel_regularizer,
-          bias_regularizer=bias_regularizer)(
+          bias_regularizer=bias_regularizer,
+          name=f'coarser_{level}')(
               feats_in)
 
     # Apply batch norm layers.
     for level in range(min_level, max_level + 1):
       feats[str(level)] = norm(
-          axis=bn_axis, momentum=norm_momentum, epsilon=norm_epsilon)(
+          axis=bn_axis,
+          momentum=norm_momentum,
+          epsilon=norm_epsilon,
+          synchronized=use_sync_bn,
+          name=f'norm_{level}')(
               feats[str(level)])
 
     self._output_specs = {
         str(level): feats[str(level)].get_shape()
         for level in range(min_level, max_level + 1)
     }
 
-    super(FPN, self).__init__(inputs=inputs, outputs=feats, **kwargs)
+    super().__init__(inputs=inputs, outputs=feats, **kwargs)
 
   def _build_input_pyramid(self, input_specs: Mapping[str, tf.TensorShape],
                            min_level: int):
     assert isinstance(input_specs, dict)
     if min(input_specs.keys()) > str(min_level):
       raise ValueError(
           'Backbone min level should be less or equal to FPN min level')
 
     inputs = {}
     for level, spec in input_specs.items():
-      inputs[level] = tf.keras.Input(shape=spec[1:])
+      inputs[level] = tf_keras.Input(shape=spec[1:])
     return inputs
 
   def get_config(self) -> Mapping[str, Any]:
     return self._config_dict
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
@@ -214,27 +218,27 @@
     return self._output_specs
 
 
 @factory.register_decoder_builder('fpn')
 def build_fpn_decoder(
     input_specs: Mapping[str, tf.TensorShape],
     model_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None
+) -> tf_keras.Model:
   """Builds FPN decoder from a config.
 
   Args:
     input_specs: A `dict` of input specifications. A dictionary consists of
       {level: TensorShape} from a backbone.
     model_config: A OneOfConfig. Model config.
-    l2_regularizer: A `tf.keras.regularizers.Regularizer` instance. Default to
+    l2_regularizer: A `tf_keras.regularizers.Regularizer` instance. Default to
       None.
 
   Returns:
-    A `tf.keras.Model` instance of the FPN decoder.
+    A `tf_keras.Model` instance of the FPN decoder.
 
   Raises:
     ValueError: If the model_config.decoder.type is not `fpn`.
   """
   decoder_type = model_config.decoder.type
   decoder_cfg = model_config.decoder.get()
   if decoder_type != 'fpn':
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/fpn_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/fpn_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for FPN."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import mobilenet
 from official.vision.modeling.backbones import resnet
 from official.vision.modeling.decoders import fpn
 
 
 class FPNTest(parameterized.TestCase, tf.test.TestCase):
@@ -30,17 +30,17 @@
       (256, 3, 7, False, True, 'sum'),
       (256, 3, 7, True, False, 'concat'),
       (256, 3, 7, True, True, 'concat'),
   )
   def test_network_creation(self, input_size, min_level, max_level,
                             use_separable_conv, use_keras_layer, fusion_type):
     """Test creation of FPN."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
 
     backbone = resnet.ResNet(model_id=50)
     network = fpn.FPN(
         input_specs=backbone.output_specs,
         min_level=min_level,
         max_level=max_level,
         fusion_type=fusion_type,
@@ -62,17 +62,17 @@
       (256, 3, 7, True, False),
       (256, 3, 7, True, True),
   )
   def test_network_creation_with_mobilenet(self, input_size, min_level,
                                            max_level, use_separable_conv,
                                            use_keras_layer):
     """Test creation of FPN with mobilenet backbone."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
 
     backbone = mobilenet.MobileNet(model_id='MobileNetV2')
     network = fpn.FPN(
         input_specs=backbone.output_specs,
         min_level=min_level,
         max_level=max_level,
         use_separable_conv=use_separable_conv,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/nasfpn.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/nasfpn.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Contains definitions of NAS-FPN."""
 
 from typing import Any, List, Mapping, Optional, Tuple
 
 # Import libraries
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import hyperparams
 from official.modeling import tf_utils
 from official.vision.modeling.decoders import factory
 from official.vision.ops import spatial_transform_ops
 
 
@@ -57,40 +57,40 @@
   """Builds the list of BlockSpec objects for NAS-FPN."""
   if not block_specs:
     block_specs = NASFPN_BLOCK_SPECS
   logging.info('Building NAS-FPN block specs: %s', block_specs)
   return [BlockSpec(*b) for b in block_specs]
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class NASFPN(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class NASFPN(tf_keras.Model):
   """Creates a NAS-FPN model.
 
   This implements the paper:
   Golnaz Ghiasi, Tsung-Yi Lin, Ruoming Pang, Quoc V. Le.
   NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection.
   (https://arxiv.org/abs/1904.07392)
   """
 
   def __init__(
       self,
       input_specs: Mapping[str, tf.TensorShape],
       min_level: int = 3,
       max_level: int = 7,
-      block_specs: List[BlockSpec] = build_block_specs(),
+      block_specs: Optional[List[BlockSpec]] = None,
       num_filters: int = 256,
       num_repeats: int = 5,
       use_separable_conv: bool = False,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       kernel_initializer: str = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
     """Initializes a NAS-FPN model.
 
     Args:
       input_specs: A `dict` of input specifications. A dictionary consists of
         {level: TensorShape} from a backbone.
       min_level: An `int` of minimum level in FPN output feature maps.
@@ -104,17 +104,17 @@
         convolution in FPN layers.
       activation: A `str` name of the activation function.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       kernel_initializer: A `str` name of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
       **kwargs: Additional keyword arguments to be passed.
     """
     self._config_dict = {
         'input_specs': input_specs,
         'min_level': min_level,
         'max_level': max_level,
         'num_filters': num_filters,
@@ -126,30 +126,31 @@
         'norm_epsilon': norm_epsilon,
         'kernel_initializer': kernel_initializer,
         'kernel_regularizer': kernel_regularizer,
         'bias_regularizer': bias_regularizer,
     }
     self._min_level = min_level
     self._max_level = max_level
-    self._block_specs = block_specs
+    self._block_specs = (
+        build_block_specs() if block_specs is None else block_specs
+    )
     self._num_repeats = num_repeats
-    self._conv_op = (tf.keras.layers.SeparableConv2D
+    self._conv_op = (tf_keras.layers.SeparableConv2D
                      if self._config_dict['use_separable_conv']
-                     else tf.keras.layers.Conv2D)
-    self._norm_op = (tf.keras.layers.experimental.SyncBatchNormalization
-                     if self._config_dict['use_sync_bn']
-                     else tf.keras.layers.BatchNormalization)
-    if tf.keras.backend.image_data_format() == 'channels_last':
+                     else tf_keras.layers.Conv2D)
+    self._norm_op = tf_keras.layers.BatchNormalization
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._norm_kwargs = {
         'axis': self._bn_axis,
         'momentum': self._config_dict['norm_momentum'],
         'epsilon': self._config_dict['norm_epsilon'],
+        'synchronized': self._config_dict['use_sync_bn'],
     }
     self._activation = tf_utils.get_activation(activation)
 
     # Gets input feature pyramid from backbone.
     inputs = self._build_input_pyramid(input_specs, min_level)
 
     # Projects the input features.
@@ -181,15 +182,15 @@
     assert isinstance(input_specs, dict)
     if min(input_specs.keys()) > str(min_level):
       raise ValueError(
           'Backbone min level should be less or equal to FPN min level')
 
     inputs = {}
     for level, spec in input_specs.items():
-      inputs[level] = tf.keras.Input(shape=spec[1:])
+      inputs[level] = tf_keras.Input(shape=spec[1:])
     return inputs
 
   def _resample_feature_map(self,
                             inputs,
                             input_level,
                             target_level,
                             target_num_filters=256):
@@ -201,46 +202,46 @@
           kernel_size=1,
           padding='same',
           **self._conv_kwargs)(x)
       x = self._norm_op(**self._norm_kwargs)(x)
 
     if input_level < target_level:
       stride = int(2 ** (target_level - input_level))
-      return tf.keras.layers.MaxPool2D(
+      return tf_keras.layers.MaxPool2D(
           pool_size=stride, strides=stride, padding='same')(x)
     if input_level > target_level:
       scale = int(2 ** (input_level - target_level))
       return spatial_transform_ops.nearest_upsampling(x, scale=scale)
 
     # Force output x to be the same dtype as mixed precision policy. This avoids
     # dtype mismatch when one input (by default float32 dtype) does not meet all
     # the above conditions and is output unchanged, while other inputs are
     # processed to have different dtype, e.g., using bfloat16 on TPU.
-    compute_dtype = tf.keras.layers.Layer().dtype_policy.compute_dtype
+    compute_dtype = tf_keras.layers.Layer().dtype_policy.compute_dtype
     if (compute_dtype is not None) and (x.dtype != compute_dtype):
       return tf.cast(x, dtype=compute_dtype)
     else:
       return x
 
   @property
   def _conv_kwargs(self):
     if self._config_dict['use_separable_conv']:
       return {
-          'depthwise_initializer': tf.keras.initializers.VarianceScaling(
+          'depthwise_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'pointwise_initializer': tf.keras.initializers.VarianceScaling(
+          'pointwise_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           'bias_initializer': tf.zeros_initializer(),
           'depthwise_regularizer': self._config_dict['kernel_regularizer'],
           'pointwise_regularizer': self._config_dict['kernel_regularizer'],
           'bias_regularizer': self._config_dict['bias_regularizer'],
       }
     else:
       return {
-          'kernel_initializer': tf.keras.initializers.VarianceScaling(
+          'kernel_initializer': tf_keras.initializers.VarianceScaling(
               scale=2, mode='fan_out', distribution='untruncated_normal'),
           'bias_initializer': tf.zeros_initializer(),
           'kernel_regularizer': self._config_dict['kernel_regularizer'],
           'bias_regularizer': self._config_dict['bias_regularizer'],
       }
 
   def _global_attention(self, feat0, feat1):
@@ -329,27 +330,27 @@
     return self._output_specs
 
 
 @factory.register_decoder_builder('nasfpn')
 def build_nasfpn_decoder(
     input_specs: Mapping[str, tf.TensorShape],
     model_config: hyperparams.Config,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None
+) -> tf_keras.Model:
   """Builds NASFPN decoder from a config.
 
   Args:
     input_specs: A `dict` of input specifications. A dictionary consists of
       {level: TensorShape} from a backbone.
     model_config: A OneOfConfig. Model config.
-    l2_regularizer: A `tf.keras.regularizers.Regularizer` instance. Default to
+    l2_regularizer: A `tf_keras.regularizers.Regularizer` instance. Default to
       None.
 
   Returns:
-    A `tf.keras.Model` instance of the NASFPN decoder.
+    A `tf_keras.Model` instance of the NASFPN decoder.
 
   Raises:
     ValueError: If the model_config.decoder.type is not `nasfpn`.
   """
   decoder_type = model_config.decoder.type
   decoder_cfg = model_config.decoder.get()
   if decoder_type != 'nasfpn':
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/decoders/nasfpn_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/decoders/nasfpn_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,32 +12,32 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for NAS-FPN."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.backbones import resnet
 from official.vision.modeling.decoders import nasfpn
 
 
 class NASFPNTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
       (256, 3, 7, False),
       (256, 3, 7, True),
   )
   def test_network_creation(self, input_size, min_level, max_level,
                             use_separable_conv):
     """Test creation of NAS-FPN."""
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
-    inputs = tf.keras.Input(shape=(input_size, input_size, 3), batch_size=1)
+    inputs = tf_keras.Input(shape=(input_size, input_size, 3), batch_size=1)
 
     num_filters = 256
     backbone = resnet.ResNet(model_id=50)
     network = nasfpn.NASFPN(
         input_specs=backbone.output_specs,
         min_level=min_level,
         max_level=max_level,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/factory.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/factory.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Factory methods to build models."""
 
 from typing import Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.configs import image_classification as classification_cfg
 from official.vision.configs import maskrcnn as maskrcnn_cfg
 from official.vision.configs import retinanet as retinanet_cfg
 from official.vision.configs import semantic_segmentation as segmentation_cfg
 from official.vision.modeling import backbones
 from official.vision.modeling import classification_model
@@ -35,19 +35,19 @@
 from official.vision.modeling.layers import mask_sampler
 from official.vision.modeling.layers import roi_aligner
 from official.vision.modeling.layers import roi_generator
 from official.vision.modeling.layers import roi_sampler
 
 
 def build_classification_model(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     model_config: classification_cfg.ImageClassificationModel,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
     skip_logits_layer: bool = False,
-    backbone: Optional[tf.keras.Model] = None) -> tf.keras.Model:
+    backbone: Optional[tf_keras.Model] = None) -> tf_keras.Model:
   """Builds the classification model."""
   norm_activation_config = model_config.norm_activation
   if not backbone:
     backbone = backbones.factory.build_backbone(
         input_specs=input_specs,
         backbone_config=model_config.backbone,
         norm_activation_config=norm_activation_config,
@@ -64,29 +64,29 @@
       use_sync_bn=norm_activation_config.use_sync_bn,
       norm_momentum=norm_activation_config.norm_momentum,
       norm_epsilon=norm_activation_config.norm_epsilon,
       skip_logits_layer=skip_logits_layer)
   return model
 
 
-def build_maskrcnn(input_specs: tf.keras.layers.InputSpec,
+def build_maskrcnn(input_specs: tf_keras.layers.InputSpec,
                    model_config: maskrcnn_cfg.MaskRCNN,
                    l2_regularizer: Optional[
-                       tf.keras.regularizers.Regularizer] = None,
-                   backbone: Optional[tf.keras.Model] = None,
-                   decoder: Optional[tf.keras.Model] = None) -> tf.keras.Model:
+                       tf_keras.regularizers.Regularizer] = None,
+                   backbone: Optional[tf_keras.Model] = None,
+                   decoder: Optional[tf_keras.Model] = None) -> tf_keras.Model:
   """Builds Mask R-CNN model."""
   norm_activation_config = model_config.norm_activation
   if not backbone:
     backbone = backbones.factory.build_backbone(
         input_specs=input_specs,
         backbone_config=model_config.backbone,
         norm_activation_config=norm_activation_config,
         l2_regularizer=l2_regularizer)
-  backbone_features = backbone(tf.keras.Input(input_specs.shape[1:]))
+  backbone_features = backbone(tf_keras.Input(input_specs.shape[1:]))
 
   if not decoder:
     decoder = decoders.factory.build_decoder(
         input_specs=backbone.output_specs,
         model_config=model_config,
         l2_regularizer=l2_regularizer)
 
@@ -200,15 +200,16 @@
       apply_nms=generator_config.apply_nms,
       pre_nms_top_k=generator_config.pre_nms_top_k,
       pre_nms_score_threshold=generator_config.pre_nms_score_threshold,
       nms_iou_threshold=generator_config.nms_iou_threshold,
       max_num_detections=generator_config.max_num_detections,
       nms_version=generator_config.nms_version,
       use_cpu_nms=generator_config.use_cpu_nms,
-      soft_nms_sigma=generator_config.soft_nms_sigma)
+      soft_nms_sigma=generator_config.soft_nms_sigma,
+      use_sigmoid_probability=generator_config.use_sigmoid_probability)
 
   if model_config.include_mask:
     mask_head = instance_heads.MaskHead(
         num_classes=model_config.num_classes,
         upsample_factor=model_config.mask_head.upsample_factor,
         num_convs=model_config.mask_head.num_convs,
         num_filters=model_config.mask_head.num_filters,
@@ -247,34 +248,35 @@
       mask_roi_aligner=mask_roi_aligner_obj,
       class_agnostic_bbox_pred=detection_head_config.class_agnostic_bbox_pred,
       cascade_class_ensemble=detection_head_config.cascade_class_ensemble,
       min_level=model_config.min_level,
       max_level=model_config.max_level,
       num_scales=model_config.anchor.num_scales,
       aspect_ratios=model_config.anchor.aspect_ratios,
-      anchor_size=model_config.anchor.anchor_size)
+      anchor_size=model_config.anchor.anchor_size,
+      outer_boxes_scale=model_config.outer_boxes_scale)
   return model
 
 
 def build_retinanet(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     model_config: retinanet_cfg.RetinaNet,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-    backbone: Optional[tf.keras.Model] = None,
-    decoder: Optional[tf.keras.Model] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+    backbone: Optional[tf_keras.Model] = None,
+    decoder: Optional[tf_keras.Model] = None
+) -> tf_keras.Model:
   """Builds RetinaNet model."""
   norm_activation_config = model_config.norm_activation
   if not backbone:
     backbone = backbones.factory.build_backbone(
         input_specs=input_specs,
         backbone_config=model_config.backbone,
         norm_activation_config=norm_activation_config,
         l2_regularizer=l2_regularizer)
-  backbone_features = backbone(tf.keras.Input(input_specs.shape[1:]))
+  backbone_features = backbone(tf_keras.Input(input_specs.shape[1:]))
 
   if not decoder:
     decoder = decoders.factory.build_decoder(
         input_specs=backbone.output_specs,
         model_config=model_config,
         l2_regularizer=l2_regularizer)
 
@@ -295,32 +297,45 @@
       ],
       share_classification_heads=head_config.share_classification_heads,
       use_separable_conv=head_config.use_separable_conv,
       activation=norm_activation_config.activation,
       use_sync_bn=norm_activation_config.use_sync_bn,
       norm_momentum=norm_activation_config.norm_momentum,
       norm_epsilon=norm_activation_config.norm_epsilon,
-      kernel_regularizer=l2_regularizer)
+      kernel_regularizer=l2_regularizer,
+      share_level_convs=head_config.share_level_convs,
+  )
 
   # Builds decoder and head so that their trainable weights are initialized
   if decoder:
     decoder_features = decoder(backbone_features)
     _ = head(decoder_features)
 
+  # Add `input_image_size` into `tflite_post_processing_config`.
+  tflite_post_processing_config = (
+      generator_config.tflite_post_processing.as_dict()
+  )
+  tflite_post_processing_config['input_image_size'] = (
+      input_specs.shape[1],
+      input_specs.shape[2],
+  )
   detection_generator_obj = detection_generator.MultilevelDetectionGenerator(
       apply_nms=generator_config.apply_nms,
       pre_nms_top_k=generator_config.pre_nms_top_k,
       pre_nms_score_threshold=generator_config.pre_nms_score_threshold,
       nms_iou_threshold=generator_config.nms_iou_threshold,
       max_num_detections=generator_config.max_num_detections,
       nms_version=generator_config.nms_version,
       use_cpu_nms=generator_config.use_cpu_nms,
       soft_nms_sigma=generator_config.soft_nms_sigma,
-      tflite_post_processing_config=generator_config.tflite_post_processing
-      .as_dict())
+      tflite_post_processing_config=tflite_post_processing_config,
+      return_decoded=generator_config.return_decoded,
+      use_class_agnostic_nms=generator_config.use_class_agnostic_nms,
+      box_coder_weights=generator_config.box_coder_weights,
+  )
 
   model = retinanet_model.RetinaNetModel(
       backbone,
       decoder,
       head,
       detection_generator_obj,
       min_level=model_config.min_level,
@@ -328,20 +343,20 @@
       num_scales=model_config.anchor.num_scales,
       aspect_ratios=model_config.anchor.aspect_ratios,
       anchor_size=model_config.anchor.anchor_size)
   return model
 
 
 def build_segmentation_model(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     model_config: segmentation_cfg.SemanticSegmentationModel,
-    l2_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-    backbone: Optional[tf.keras.Model] = None,
-    decoder: Optional[tf.keras.Model] = None
-) -> tf.keras.Model:
+    l2_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+    backbone: Optional[tf_keras.Model] = None,
+    decoder: Optional[tf_keras.Model] = None
+) -> tf_keras.Model:
   """Builds Segmentation model."""
   norm_activation_config = model_config.norm_activation
   if not backbone:
     backbone = backbones.factory.build_backbone(
         input_specs=input_specs,
         backbone_config=model_config.backbone,
         norm_activation_config=norm_activation_config,
@@ -363,14 +378,15 @@
       num_filters=head_config.num_filters,
       use_depthwise_convolution=head_config.use_depthwise_convolution,
       upsample_factor=head_config.upsample_factor,
       feature_fusion=head_config.feature_fusion,
       low_level=head_config.low_level,
       low_level_num_filters=head_config.low_level_num_filters,
       activation=norm_activation_config.activation,
+      logit_activation=head_config.logit_activation,
       use_sync_bn=norm_activation_config.use_sync_bn,
       norm_momentum=norm_activation_config.norm_momentum,
       norm_epsilon=norm_activation_config.norm_epsilon,
       kernel_regularizer=l2_regularizer)
 
   mask_scoring_head = None
   if model_config.mask_scoring_head:
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/factory_3d.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/factory_3d.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Factory methods to build models."""
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import registry
 from official.vision.configs import video_classification as video_classification_cfg
 from official.vision.modeling import video_classification_model
 from official.vision.modeling import backbones
 
 _REGISTERED_MODEL_CLS = {}
@@ -28,15 +28,15 @@
 def register_model_builder(key: str):
   """Decorates a builder of model class.
 
   The builder should be a Callable (a class or a function).
   This decorator supports registration of backbone builder as follows:
 
   ```
-  class MyModel(tf.keras.Model):
+  class MyModel(tf_keras.Model):
     pass
 
   @register_backbone_builder('mybackbone')
   def builder(input_specs, config, l2_reg):
     return MyModel(...)
 
   # Builds a MyModel object.
@@ -51,42 +51,42 @@
     for creation from an instance of model class.
   """
   return registry.register(_REGISTERED_MODEL_CLS, key)
 
 
 def build_model(
     model_type: str,
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     model_config: video_classification_cfg.hyperparams.Config,
     num_classes: int,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:
+    l2_regularizer: tf_keras.regularizers.Regularizer = None) -> tf_keras.Model:
   """Builds backbone from a config.
 
   Args:
     model_type: string name of model type. It should be consistent with
       ModelConfig.model_type.
-    input_specs: tf.keras.layers.InputSpec.
+    input_specs: tf_keras.layers.InputSpec.
     model_config: a OneOfConfig. Model config.
     num_classes: number of classes.
-    l2_regularizer: tf.keras.regularizers.Regularizer instance. Default to None.
+    l2_regularizer: tf_keras.regularizers.Regularizer instance. Default to None.
 
   Returns:
-    tf.keras.Model instance of the backbone.
+    tf_keras.Model instance of the backbone.
   """
   model_builder = registry.lookup(_REGISTERED_MODEL_CLS, model_type)
 
   return model_builder(input_specs, model_config, num_classes, l2_regularizer)
 
 
 @register_model_builder('video_classification')
 def build_video_classification_model(
-    input_specs: tf.keras.layers.InputSpec,
+    input_specs: tf_keras.layers.InputSpec,
     model_config: video_classification_cfg.VideoClassificationModel,
     num_classes: int,
-    l2_regularizer: tf.keras.regularizers.Regularizer = None) -> tf.keras.Model:
+    l2_regularizer: tf_keras.regularizers.Regularizer = None) -> tf_keras.Model:
   """Builds the video classification model."""
   input_specs_dict = {'image': input_specs}
   norm_activation_config = model_config.norm_activation
   backbone = backbones.factory.build_backbone(
       input_specs=input_specs,
       backbone_config=model_config.backbone,
       norm_activation_config=norm_activation_config,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/factory_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/factory_test.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for factory.py."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.configs import backbones
 from official.vision.configs import backbones_3d
 from official.vision.configs import image_classification as classification_cfg
 from official.vision.configs import maskrcnn as maskrcnn_cfg
 from official.vision.configs import retinanet as retinanet_cfg
 from official.vision.configs import video_classification as video_classification_cfg
@@ -34,96 +34,114 @@
       ('resnet', (224, 224), 5e-5),
       ('resnet', (224, 224), None),
       ('resnet', (None, None), 5e-5),
       ('resnet', (None, None), None),
   )
   def test_builder(self, backbone_type, input_size, weight_decay):
     num_classes = 2
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, input_size[0], input_size[1], 3])
     model_config = classification_cfg.ImageClassificationModel(
         num_classes=num_classes,
         backbone=backbones.Backbone(type=backbone_type))
     l2_regularizer = (
-        tf.keras.regularizers.l2(weight_decay) if weight_decay else None)
+        tf_keras.regularizers.l2(weight_decay) if weight_decay else None)
     _ = factory.build_classification_model(
         input_specs=input_specs,
         model_config=model_config,
         l2_regularizer=l2_regularizer)
 
 
 class MaskRCNNBuilderTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
       ('resnet', (640, 640)),
       ('resnet', (None, None)),
   )
   def test_builder(self, backbone_type, input_size):
     num_classes = 2
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, input_size[0], input_size[1], 3])
     model_config = maskrcnn_cfg.MaskRCNN(
         num_classes=num_classes,
         backbone=backbones.Backbone(type=backbone_type))
-    l2_regularizer = tf.keras.regularizers.l2(5e-5)
+    l2_regularizer = tf_keras.regularizers.l2(5e-5)
     _ = factory.build_maskrcnn(
         input_specs=input_specs,
         model_config=model_config,
         l2_regularizer=l2_regularizer)
 
 
 class RetinaNetBuilderTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
       ('resnet', (640, 640), False),
       ('resnet', (None, None), True),
   )
   def test_builder(self, backbone_type, input_size, has_att_heads):
     num_classes = 2
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, input_size[0], input_size[1], 3])
     if has_att_heads:
       attribute_heads_config = [
           retinanet_cfg.AttributeHead(name='att1'),
           retinanet_cfg.AttributeHead(
               name='att2', type='classification', size=2),
       ]
     else:
       attribute_heads_config = None
     model_config = retinanet_cfg.RetinaNet(
         num_classes=num_classes,
         backbone=backbones.Backbone(type=backbone_type),
         head=retinanet_cfg.RetinaNetHead(
             attribute_heads=attribute_heads_config))
-    l2_regularizer = tf.keras.regularizers.l2(5e-5)
+    l2_regularizer = tf_keras.regularizers.l2(5e-5)
     _ = factory.build_retinanet(
         input_specs=input_specs,
         model_config=model_config,
         l2_regularizer=l2_regularizer)
     if has_att_heads:
-      self.assertEqual(model_config.head.attribute_heads[0].as_dict(),
-                       dict(name='att1', type='regression', size=1))
-      self.assertEqual(model_config.head.attribute_heads[1].as_dict(),
-                       dict(name='att2', type='classification', size=2))
+      self.assertEqual(
+          model_config.head.attribute_heads[0].as_dict(),
+          dict(
+              name='att1',
+              type='regression',
+              size=1,
+              prediction_tower_name='',
+              num_convs=None,
+              num_filters=None,
+          ),
+      )
+      self.assertEqual(
+          model_config.head.attribute_heads[1].as_dict(),
+          dict(
+              name='att2',
+              type='classification',
+              size=2,
+              prediction_tower_name='',
+              num_convs=None,
+              num_filters=None,
+          ),
+      )
 
 
 class VideoClassificationModelBuilderTest(parameterized.TestCase,
                                           tf.test.TestCase):
 
   @parameterized.parameters(
       ('resnet_3d', (8, 224, 224), 5e-5),
       ('resnet_3d', (None, None, None), 5e-5),
   )
   def test_builder(self, backbone_type, input_size, weight_decay):
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, input_size[0], input_size[1], input_size[2], 3])
     model_config = video_classification_cfg.VideoClassificationModel(
         backbone=backbones_3d.Backbone3D(type=backbone_type))
     l2_regularizer = (
-        tf.keras.regularizers.l2(weight_decay) if weight_decay else None)
+        tf_keras.regularizers.l2(weight_decay) if weight_decay else None)
     _ = factory_3d.build_video_classification_model(
         input_specs=input_specs,
         model_config=model_config,
         num_classes=2,
         l2_regularizer=l2_regularizer)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/heads/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/heads/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,8 +14,9 @@
 
 """Heads package definition."""
 
 from official.vision.modeling.heads.dense_prediction_heads import RetinaNetHead
 from official.vision.modeling.heads.dense_prediction_heads import RPNHead
 from official.vision.modeling.heads.instance_heads import DetectionHead
 from official.vision.modeling.heads.instance_heads import MaskHead
+from official.vision.modeling.heads.segmentation_heads import MaskScoring
 from official.vision.modeling.heads.segmentation_heads import SegmentationHead
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/heads/dense_prediction_heads.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/heads/instance_heads.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,540 +1,433 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Contains definitions of dense prediction heads."""
-
-from typing import Any, Dict, List, Mapping, Optional, Union
+"""Contains definitions of instance prediction heads."""
 
+from typing import List, Union, Optional
 # Import libraries
-
-import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class RetinaNetHead(tf.keras.layers.Layer):
-  """Creates a RetinaNet head."""
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class DetectionHead(tf_keras.layers.Layer):
+  """Creates a detection head."""
 
   def __init__(
       self,
-      min_level: int,
-      max_level: int,
       num_classes: int,
-      num_anchors_per_location: int,
-      num_convs: int = 4,
+      num_convs: int = 0,
       num_filters: int = 256,
-      attribute_heads: Optional[List[Dict[str, Any]]] = None,
-      share_classification_heads: bool = False,
       use_separable_conv: bool = False,
+      num_fcs: int = 2,
+      fc_dims: int = 1024,
+      class_agnostic_bbox_pred: bool = False,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      num_params_per_anchor: int = 4,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
-    """Initializes a RetinaNet head.
+    """Initializes a detection head.
 
     Args:
-      min_level: An `int` number of minimum feature level.
-      max_level: An `int` number of maximum feature level.
-      num_classes: An `int` number of classes to predict.
-      num_anchors_per_location: An `int` number of number of anchors per pixel
-        location.
+      num_classes: An `int` for the number of classes.
       num_convs: An `int` number that represents the number of the intermediate
-        conv layers before the prediction.
+        convolution layers before the FC layers.
       num_filters: An `int` number that represents the number of filters of the
-        intermediate conv layers.
-      attribute_heads: If not None, a list that contains a dict for each
-        additional attribute head. Each dict consists of 3 key-value pairs:
-        `name`, `type` ('regression' or 'classification'), and `size` (number
-        of predicted values for each instance).
-      share_classification_heads: A `bool` that indicates whethere
-        sharing weights among the main and attribute classification heads.
+        intermediate convolution layers.
       use_separable_conv: A `bool` that indicates whether the separable
         convolution layers is used.
+      num_fcs: An `int` number that represents the number of FC layers before
+        the predictions.
+      fc_dims: An `int` number that represents the number of dimension of the FC
+        layers.
+      class_agnostic_bbox_pred: `bool`, indicating whether bboxes should be
+        predicted for every class or not.
       activation: A `str` that indicates which activation is used, e.g. 'relu',
         'swish', etc.
       use_sync_bn: A `bool` that indicates whether to use synchronized batch
         normalization across different replicas.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
-      num_params_per_anchor: Number of parameters required to specify an anchor
-        box. For example, `num_params_per_anchor` would be 4 for axis-aligned
-        anchor boxes specified by their y-centers, x-centers, heights, and
-        widths.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
       **kwargs: Additional keyword arguments to be passed.
     """
-    super(RetinaNetHead, self).__init__(**kwargs)
+    super(DetectionHead, self).__init__(**kwargs)
     self._config_dict = {
-        'min_level': min_level,
-        'max_level': max_level,
         'num_classes': num_classes,
-        'num_anchors_per_location': num_anchors_per_location,
         'num_convs': num_convs,
         'num_filters': num_filters,
-        'attribute_heads': attribute_heads,
-        'share_classification_heads': share_classification_heads,
         'use_separable_conv': use_separable_conv,
+        'num_fcs': num_fcs,
+        'fc_dims': fc_dims,
+        'class_agnostic_bbox_pred': class_agnostic_bbox_pred,
         'activation': activation,
         'use_sync_bn': use_sync_bn,
         'norm_momentum': norm_momentum,
         'norm_epsilon': norm_epsilon,
         'kernel_regularizer': kernel_regularizer,
         'bias_regularizer': bias_regularizer,
-        'num_params_per_anchor': num_params_per_anchor,
     }
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation = tf_utils.get_activation(activation)
 
   def build(self, input_shape: Union[tf.TensorShape, List[tf.TensorShape]]):
     """Creates the variables of the head."""
-    conv_op = (tf.keras.layers.SeparableConv2D
+    conv_op = (tf_keras.layers.SeparableConv2D
                if self._config_dict['use_separable_conv']
-               else tf.keras.layers.Conv2D)
+               else tf_keras.layers.Conv2D)
     conv_kwargs = {
         'filters': self._config_dict['num_filters'],
         'kernel_size': 3,
         'padding': 'same',
-        'bias_initializer': tf.zeros_initializer(),
-        'bias_regularizer': self._config_dict['bias_regularizer'],
     }
-    if not self._config_dict['use_separable_conv']:
+    if self._config_dict['use_separable_conv']:
+      conv_kwargs.update({
+          'depthwise_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'pointwise_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'bias_initializer': tf.zeros_initializer(),
+          'depthwise_regularizer': self._config_dict['kernel_regularizer'],
+          'pointwise_regularizer': self._config_dict['kernel_regularizer'],
+          'bias_regularizer': self._config_dict['bias_regularizer'],
+      })
+    else:
       conv_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.RandomNormal(
-              stddev=0.01),
+          'kernel_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'bias_initializer': tf.zeros_initializer(),
           'kernel_regularizer': self._config_dict['kernel_regularizer'],
+          'bias_regularizer': self._config_dict['bias_regularizer'],
       })
-    bn_op = (tf.keras.layers.experimental.SyncBatchNormalization
-             if self._config_dict['use_sync_bn']
-             else tf.keras.layers.BatchNormalization)
+    bn_op = tf_keras.layers.BatchNormalization
     bn_kwargs = {
         'axis': self._bn_axis,
         'momentum': self._config_dict['norm_momentum'],
         'epsilon': self._config_dict['norm_epsilon'],
+        'synchronized': self._config_dict['use_sync_bn'],
     }
 
-    # Class net.
-    self._cls_convs = []
-    self._cls_norms = []
-    for level in range(
-        self._config_dict['min_level'], self._config_dict['max_level'] + 1):
-      this_level_cls_norms = []
-      for i in range(self._config_dict['num_convs']):
-        if level == self._config_dict['min_level']:
-          cls_conv_name = 'classnet-conv_{}'.format(i)
-          if 'kernel_initializer' in conv_kwargs:
-            conv_kwargs['kernel_initializer'] = tf_utils.clone_initializer(
-                conv_kwargs['kernel_initializer'])
-          self._cls_convs.append(conv_op(name=cls_conv_name, **conv_kwargs))
-        cls_norm_name = 'classnet-conv-norm_{}_{}'.format(level, i)
-        this_level_cls_norms.append(bn_op(name=cls_norm_name, **bn_kwargs))
-      self._cls_norms.append(this_level_cls_norms)
-
-    classifier_kwargs = {
-        'filters': (
-            self._config_dict['num_classes'] *
-            self._config_dict['num_anchors_per_location']),
-        'kernel_size': 3,
-        'padding': 'same',
-        'bias_initializer': tf.constant_initializer(-np.log((1 - 0.01) / 0.01)),
-        'bias_regularizer': self._config_dict['bias_regularizer'],
-    }
-    if not self._config_dict['use_separable_conv']:
-      classifier_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.RandomNormal(stddev=1e-5),
-          'kernel_regularizer': self._config_dict['kernel_regularizer'],
-      })
-    self._classifier = conv_op(name='scores', **classifier_kwargs)
-
-    # Box net.
-    self._box_convs = []
-    self._box_norms = []
-    for level in range(
-        self._config_dict['min_level'], self._config_dict['max_level'] + 1):
-      this_level_box_norms = []
-      for i in range(self._config_dict['num_convs']):
-        if level == self._config_dict['min_level']:
-          box_conv_name = 'boxnet-conv_{}'.format(i)
-          if 'kernel_initializer' in conv_kwargs:
-            conv_kwargs['kernel_initializer'] = tf_utils.clone_initializer(
-                conv_kwargs['kernel_initializer'])
-          self._box_convs.append(conv_op(name=box_conv_name, **conv_kwargs))
-        box_norm_name = 'boxnet-conv-norm_{}_{}'.format(level, i)
-        this_level_box_norms.append(bn_op(name=box_norm_name, **bn_kwargs))
-      self._box_norms.append(this_level_box_norms)
-
-    box_regressor_kwargs = {
-        'filters': (self._config_dict['num_params_per_anchor'] *
-                    self._config_dict['num_anchors_per_location']),
-        'kernel_size': 3,
-        'padding': 'same',
-        'bias_initializer': tf.zeros_initializer(),
-        'bias_regularizer': self._config_dict['bias_regularizer'],
-    }
-    if not self._config_dict['use_separable_conv']:
-      box_regressor_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.RandomNormal(
-              stddev=1e-5),
-          'kernel_regularizer': self._config_dict['kernel_regularizer'],
-      })
-    self._box_regressor = conv_op(name='boxes', **box_regressor_kwargs)
-
-    # Attribute learning nets.
-    if self._config_dict['attribute_heads']:
-      self._att_predictors = {}
-      self._att_convs = {}
-      self._att_norms = {}
-
-      for att_config in self._config_dict['attribute_heads']:
-        att_name = att_config['name']
-        att_type = att_config['type']
-        att_size = att_config['size']
-        att_convs_i = []
-        att_norms_i = []
-
-        # Build conv and norm layers.
-        for level in range(self._config_dict['min_level'],
-                           self._config_dict['max_level'] + 1):
-          this_level_att_norms = []
-          for i in range(self._config_dict['num_convs']):
-            if level == self._config_dict['min_level']:
-              att_conv_name = '{}-conv_{}'.format(att_name, i)
-              if 'kernel_initializer' in conv_kwargs:
-                conv_kwargs['kernel_initializer'] = tf_utils.clone_initializer(
-                    conv_kwargs['kernel_initializer'])
-              att_convs_i.append(conv_op(name=att_conv_name, **conv_kwargs))
-            att_norm_name = '{}-conv-norm_{}_{}'.format(att_name, level, i)
-            this_level_att_norms.append(bn_op(name=att_norm_name, **bn_kwargs))
-          att_norms_i.append(this_level_att_norms)
-        self._att_convs[att_name] = att_convs_i
-        self._att_norms[att_name] = att_norms_i
-
-        # Build the final prediction layer.
-        att_predictor_kwargs = {
-            'filters':
-                (att_size * self._config_dict['num_anchors_per_location']),
-            'kernel_size': 3,
-            'padding': 'same',
-            'bias_initializer': tf.zeros_initializer(),
-            'bias_regularizer': self._config_dict['bias_regularizer'],
-        }
-        if att_type == 'regression':
-          att_predictor_kwargs.update(
-              {'bias_initializer': tf.zeros_initializer()})
-        elif att_type == 'classification':
-          att_predictor_kwargs.update({
-              'bias_initializer':
-                  tf.constant_initializer(-np.log((1 - 0.01) / 0.01))
-          })
-        else:
-          raise ValueError(
-              'Attribute head type {} not supported.'.format(att_type))
-
-        if not self._config_dict['use_separable_conv']:
-          att_predictor_kwargs.update({
-              'kernel_initializer':
-                  tf.keras.initializers.RandomNormal(stddev=1e-5),
-              'kernel_regularizer':
-                  self._config_dict['kernel_regularizer'],
-          })
-
-        self._att_predictors[att_name] = conv_op(
-            name='{}_attributes'.format(att_name), **att_predictor_kwargs)
+    self._convs = []
+    self._conv_norms = []
+    for i in range(self._config_dict['num_convs']):
+      conv_name = 'detection-conv_{}'.format(i)
+      if 'kernel_initializer' in conv_kwargs:
+        conv_kwargs['kernel_initializer'] = tf_utils.clone_initializer(
+            conv_kwargs['kernel_initializer'])
+      self._convs.append(conv_op(name=conv_name, **conv_kwargs))
+      bn_name = 'detection-conv-bn_{}'.format(i)
+      self._conv_norms.append(bn_op(name=bn_name, **bn_kwargs))
+
+    self._fcs = []
+    self._fc_norms = []
+    for i in range(self._config_dict['num_fcs']):
+      fc_name = 'detection-fc_{}'.format(i)
+      self._fcs.append(
+          tf_keras.layers.Dense(
+              units=self._config_dict['fc_dims'],
+              kernel_initializer=tf_keras.initializers.VarianceScaling(
+                  scale=1 / 3.0, mode='fan_out', distribution='uniform'),
+              kernel_regularizer=self._config_dict['kernel_regularizer'],
+              bias_regularizer=self._config_dict['bias_regularizer'],
+              name=fc_name))
+      bn_name = 'detection-fc-bn_{}'.format(i)
+      self._fc_norms.append(bn_op(name=bn_name, **bn_kwargs))
+
+    self._classifier = tf_keras.layers.Dense(
+        units=self._config_dict['num_classes'],
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
+        bias_initializer=tf.zeros_initializer(),
+        kernel_regularizer=self._config_dict['kernel_regularizer'],
+        bias_regularizer=self._config_dict['bias_regularizer'],
+        name='detection-scores')
+
+    num_box_outputs = (4 if self._config_dict['class_agnostic_bbox_pred'] else
+                       self._config_dict['num_classes'] * 4)
+    self._box_regressor = tf_keras.layers.Dense(
+        units=num_box_outputs,
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.001),
+        bias_initializer=tf.zeros_initializer(),
+        kernel_regularizer=self._config_dict['kernel_regularizer'],
+        bias_regularizer=self._config_dict['bias_regularizer'],
+        name='detection-boxes')
 
-    super(RetinaNetHead, self).build(input_shape)
+    super(DetectionHead, self).build(input_shape)
 
-  def call(self, features: Mapping[str, tf.Tensor]):
-    """Forward pass of the RetinaNet head.
+  def call(self, inputs: tf.Tensor, training: bool = None):
+    """Forward pass of box and class branches for the Mask-RCNN model.
 
     Args:
-      features: A `dict` of `tf.Tensor` where
-        - key: A `str` of the level of the multilevel features.
-        - values: A `tf.Tensor`, the feature map tensors, whose shape is
-            [batch, height_l, width_l, channels].
+      inputs: A `tf.Tensor` of the shape [batch_size, num_instances, roi_height,
+        roi_width, roi_channels], representing the ROI features.
+      training: a `bool` indicating whether it is in `training` mode.
 
     Returns:
-      scores: A `dict` of `tf.Tensor` which includes scores of the predictions.
-        - key: A `str` of the level of the multilevel predictions.
-        - values: A `tf.Tensor` of the box scores predicted from a particular
-            feature level, whose shape is
-            [batch, height_l, width_l, num_classes * num_anchors_per_location].
-      boxes: A `dict` of `tf.Tensor` which includes coordinates of the
+      class_outputs: A `tf.Tensor` of the shape
+        [batch_size, num_rois, num_classes], representing the class predictions.
+      box_outputs: A `tf.Tensor` of the shape
+        [batch_size, num_rois, num_classes * 4], representing the box
         predictions.
-        - key: A `str` of the level of the multilevel predictions.
-        - values: A `tf.Tensor` of the box scores predicted from a particular
-            feature level, whose shape is
-            [batch, height_l, width_l,
-             num_params_per_anchor * num_anchors_per_location].
-      attributes: a dict of (attribute_name, attribute_prediction). Each
-        `attribute_prediction` is a dict of:
-        - key: `str`, the level of the multilevel predictions.
-        - values: `Tensor`, the box scores predicted from a particular feature
-            level, whose shape is
-            [batch, height_l, width_l,
-            attribute_size * num_anchors_per_location].
-        Can be an empty dictionary if no attribute learning is required.
     """
-    scores = {}
-    boxes = {}
-    if self._config_dict['attribute_heads']:
-      attributes = {
-          att_config['name']: {}
-          for att_config in self._config_dict['attribute_heads']
-      }
-    else:
-      attributes = {}
-
-    for i, level in enumerate(
-        range(self._config_dict['min_level'],
-              self._config_dict['max_level'] + 1)):
-      this_level_features = features[str(level)]
-
-      # class net.
-      x = this_level_features
-      for conv, norm in zip(self._cls_convs, self._cls_norms[i]):
-        x = conv(x)
-        x = norm(x)
-        x = self._activation(x)
-      classnet_x = x
-      scores[str(level)] = self._classifier(classnet_x)
-
-      # box net.
-      x = this_level_features
-      for conv, norm in zip(self._box_convs, self._box_norms[i]):
-        x = conv(x)
-        x = norm(x)
-        x = self._activation(x)
-      boxes[str(level)] = self._box_regressor(x)
-
-      # attribute nets.
-      if self._config_dict['attribute_heads']:
-        for att_config in self._config_dict['attribute_heads']:
-          att_name = att_config['name']
-          att_type = att_config['type']
-          if self._config_dict[
-              'share_classification_heads'] and att_type == 'classification':
-            attributes[att_name][str(level)] = self._att_predictors[att_name](
-                classnet_x)
-          else:
-            x = this_level_features
-            for conv, norm in zip(self._att_convs[att_name],
-                                  self._att_norms[att_name][i]):
-              x = conv(x)
-              x = norm(x)
-              x = self._activation(x)
-            attributes[att_name][str(level)] = self._att_predictors[att_name](x)
+    roi_features = inputs
+    _, num_rois, height, width, filters = roi_features.get_shape().as_list()
 
-    return scores, boxes, attributes
+    x = tf.reshape(roi_features, [-1, height, width, filters])
+    for conv, bn in zip(self._convs, self._conv_norms):
+      x = conv(x)
+      x = bn(x)
+      x = self._activation(x)
+
+    _, _, _, filters = x.get_shape().as_list()
+    x = tf.reshape(x, [-1, num_rois, height * width * filters])
+
+    for fc, bn in zip(self._fcs, self._fc_norms):
+      x = fc(x)
+      x = bn(x)
+      x = self._activation(x)
+
+    classes = self._classifier(x)
+    boxes = self._box_regressor(x)
+    return classes, boxes
 
   def get_config(self):
     return self._config_dict
 
   @classmethod
   def from_config(cls, config):
     return cls(**config)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class RPNHead(tf.keras.layers.Layer):
-  """Creates a Region Proposal Network (RPN) head."""
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MaskHead(tf_keras.layers.Layer):
+  """Creates a mask head."""
 
   def __init__(
       self,
-      min_level: int,
-      max_level: int,
-      num_anchors_per_location: int,
-      num_convs: int = 1,
+      num_classes: int,
+      upsample_factor: int = 2,
+      num_convs: int = 4,
       num_filters: int = 256,
       use_separable_conv: bool = False,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      class_agnostic: bool = False,
       **kwargs):
-    """Initializes a Region Proposal Network head.
+    """Initializes a mask head.
 
     Args:
-      min_level: An `int` number of minimum feature level.
-      max_level: An `int` number of maximum feature level.
-      num_anchors_per_location: An `int` number of number of anchors per pixel
-        location.
+      num_classes: An `int` of the number of classes.
+      upsample_factor: An `int` that indicates the upsample factor to generate
+        the final predicted masks. It should be >= 1.
       num_convs: An `int` number that represents the number of the intermediate
-        convolution layers before the prediction.
+        convolution layers before the mask prediction layers.
       num_filters: An `int` number that represents the number of filters of the
         intermediate convolution layers.
       use_separable_conv: A `bool` that indicates whether the separable
         convolution layers is used.
       activation: A `str` that indicates which activation is used, e.g. 'relu',
         'swish', etc.
       use_sync_bn: A `bool` that indicates whether to use synchronized batch
         normalization across different replicas.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
+      class_agnostic: A `bool`. If set, we use a single channel mask head that
+        is shared between all classes.
       **kwargs: Additional keyword arguments to be passed.
     """
-    super(RPNHead, self).__init__(**kwargs)
+    super(MaskHead, self).__init__(**kwargs)
     self._config_dict = {
-        'min_level': min_level,
-        'max_level': max_level,
-        'num_anchors_per_location': num_anchors_per_location,
+        'num_classes': num_classes,
+        'upsample_factor': upsample_factor,
         'num_convs': num_convs,
         'num_filters': num_filters,
         'use_separable_conv': use_separable_conv,
         'activation': activation,
         'use_sync_bn': use_sync_bn,
         'norm_momentum': norm_momentum,
         'norm_epsilon': norm_epsilon,
         'kernel_regularizer': kernel_regularizer,
         'bias_regularizer': bias_regularizer,
+        'class_agnostic': class_agnostic
     }
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation = tf_utils.get_activation(activation)
 
-  def build(self, input_shape):
+  def build(self, input_shape: Union[tf.TensorShape, List[tf.TensorShape]]):
     """Creates the variables of the head."""
-    conv_op = (tf.keras.layers.SeparableConv2D
+    conv_op = (tf_keras.layers.SeparableConv2D
                if self._config_dict['use_separable_conv']
-               else tf.keras.layers.Conv2D)
+               else tf_keras.layers.Conv2D)
     conv_kwargs = {
         'filters': self._config_dict['num_filters'],
         'kernel_size': 3,
         'padding': 'same',
-        'bias_initializer': tf.zeros_initializer(),
-        'bias_regularizer': self._config_dict['bias_regularizer'],
     }
-    if not self._config_dict['use_separable_conv']:
+    if self._config_dict['use_separable_conv']:
+      conv_kwargs.update({
+          'depthwise_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'pointwise_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'bias_initializer': tf.zeros_initializer(),
+          'depthwise_regularizer': self._config_dict['kernel_regularizer'],
+          'pointwise_regularizer': self._config_dict['kernel_regularizer'],
+          'bias_regularizer': self._config_dict['bias_regularizer'],
+      })
+    else:
       conv_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.RandomNormal(
-              stddev=0.01),
+          'kernel_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'bias_initializer': tf.zeros_initializer(),
           'kernel_regularizer': self._config_dict['kernel_regularizer'],
+          'bias_regularizer': self._config_dict['bias_regularizer'],
       })
-    bn_op = (tf.keras.layers.experimental.SyncBatchNormalization
-             if self._config_dict['use_sync_bn']
-             else tf.keras.layers.BatchNormalization)
+    bn_op = tf_keras.layers.BatchNormalization
     bn_kwargs = {
         'axis': self._bn_axis,
         'momentum': self._config_dict['norm_momentum'],
         'epsilon': self._config_dict['norm_epsilon'],
+        'synchronized': self._config_dict['use_sync_bn'],
     }
 
     self._convs = []
-    self._norms = []
-    for level in range(
-        self._config_dict['min_level'], self._config_dict['max_level'] + 1):
-      this_level_norms = []
-      for i in range(self._config_dict['num_convs']):
-        if level == self._config_dict['min_level']:
-          conv_name = 'rpn-conv_{}'.format(i)
-          if 'kernel_initializer' in conv_kwargs:
-            conv_kwargs['kernel_initializer'] = tf_utils.clone_initializer(
-                conv_kwargs['kernel_initializer'])
-          self._convs.append(conv_op(name=conv_name, **conv_kwargs))
-        norm_name = 'rpn-conv-norm_{}_{}'.format(level, i)
-        this_level_norms.append(bn_op(name=norm_name, **bn_kwargs))
-      self._norms.append(this_level_norms)
+    self._conv_norms = []
+    for i in range(self._config_dict['num_convs']):
+      conv_name = 'mask-conv_{}'.format(i)
+      for initializer_name in ['kernel_initializer', 'depthwise_initializer',
+                               'pointwise_initializer']:
+        if initializer_name in conv_kwargs:
+          conv_kwargs[initializer_name] = tf_utils.clone_initializer(
+              conv_kwargs[initializer_name])
+      self._convs.append(conv_op(name=conv_name, **conv_kwargs))
+      bn_name = 'mask-conv-bn_{}'.format(i)
+      self._conv_norms.append(bn_op(name=bn_name, **bn_kwargs))
+
+    self._deconv = tf_keras.layers.Conv2DTranspose(
+        filters=self._config_dict['num_filters'],
+        kernel_size=self._config_dict['upsample_factor'],
+        strides=self._config_dict['upsample_factor'],
+        padding='valid',
+        kernel_initializer=tf_keras.initializers.VarianceScaling(
+            scale=2, mode='fan_out', distribution='untruncated_normal'),
+        bias_initializer=tf.zeros_initializer(),
+        kernel_regularizer=self._config_dict['kernel_regularizer'],
+        bias_regularizer=self._config_dict['bias_regularizer'],
+        name='mask-upsampling')
+    self._deconv_bn = bn_op(name='mask-deconv-bn', **bn_kwargs)
 
-    classifier_kwargs = {
-        'filters': self._config_dict['num_anchors_per_location'],
-        'kernel_size': 1,
-        'padding': 'valid',
-        'bias_initializer': tf.zeros_initializer(),
-        'bias_regularizer': self._config_dict['bias_regularizer'],
-    }
-    if not self._config_dict['use_separable_conv']:
-      classifier_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.RandomNormal(
-              stddev=1e-5),
-          'kernel_regularizer': self._config_dict['kernel_regularizer'],
-      })
-    self._classifier = conv_op(name='rpn-scores', **classifier_kwargs)
+    if self._config_dict['class_agnostic']:
+      num_filters = 1
+    else:
+      num_filters = self._config_dict['num_classes']
 
-    box_regressor_kwargs = {
-        'filters': 4 * self._config_dict['num_anchors_per_location'],
+    conv_kwargs = {
+        'filters': num_filters,
         'kernel_size': 1,
         'padding': 'valid',
-        'bias_initializer': tf.zeros_initializer(),
-        'bias_regularizer': self._config_dict['bias_regularizer'],
     }
-    if not self._config_dict['use_separable_conv']:
-      box_regressor_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.RandomNormal(
-              stddev=1e-5),
+    if self._config_dict['use_separable_conv']:
+      conv_kwargs.update({
+          'depthwise_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'pointwise_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'bias_initializer': tf.zeros_initializer(),
+          'depthwise_regularizer': self._config_dict['kernel_regularizer'],
+          'pointwise_regularizer': self._config_dict['kernel_regularizer'],
+          'bias_regularizer': self._config_dict['bias_regularizer'],
+      })
+    else:
+      conv_kwargs.update({
+          'kernel_initializer': tf_keras.initializers.VarianceScaling(
+              scale=2, mode='fan_out', distribution='untruncated_normal'),
+          'bias_initializer': tf.zeros_initializer(),
           'kernel_regularizer': self._config_dict['kernel_regularizer'],
+          'bias_regularizer': self._config_dict['bias_regularizer'],
       })
-    self._box_regressor = conv_op(name='rpn-boxes', **box_regressor_kwargs)
+    self._mask_regressor = conv_op(name='mask-logits', **conv_kwargs)
 
-    super(RPNHead, self).build(input_shape)
+    super(MaskHead, self).build(input_shape)
 
-  def call(self, features: Mapping[str, tf.Tensor]):
-    """Forward pass of the RPN head.
+  def call(self, inputs: List[tf.Tensor], training: bool = None):
+    """Forward pass of mask branch for the Mask-RCNN model.
 
     Args:
-      features: A `dict` of `tf.Tensor` where
-        - key: A `str` of the level of the multilevel features.
-        - values: A `tf.Tensor`, the feature map tensors, whose shape is [batch,
-          height_l, width_l, channels].
+      inputs: A `list` of two tensors where
+        inputs[0]: A `tf.Tensor` of shape [batch_size, num_instances,
+          roi_height, roi_width, roi_channels], representing the ROI features.
+        inputs[1]: A `tf.Tensor` of shape [batch_size, num_instances],
+          representing the classes of the ROIs.
+      training: A `bool` indicating whether it is in `training` mode.
 
     Returns:
-      scores: A `dict` of `tf.Tensor` which includes scores of the predictions.
-        - key: A `str` of the level of the multilevel predictions.
-        - values: A `tf.Tensor` of the box scores predicted from a particular
-            feature level, whose shape is
-            [batch, height_l, width_l, num_classes * num_anchors_per_location].
-      boxes: A `dict` of `tf.Tensor` which includes coordinates of the
-        predictions.
-        - key: A `str` of the level of the multilevel predictions.
-        - values: A `tf.Tensor` of the box scores predicted from a particular
-            feature level, whose shape is
-            [batch, height_l, width_l, 4 * num_anchors_per_location].
+      mask_outputs: A `tf.Tensor` of shape
+        [batch_size, num_instances, roi_height * upsample_factor,
+         roi_width * upsample_factor], representing the mask predictions.
     """
-    scores = {}
-    boxes = {}
-    for i, level in enumerate(
-        range(self._config_dict['min_level'],
-              self._config_dict['max_level'] + 1)):
-      x = features[str(level)]
-      for conv, norm in zip(self._convs, self._norms[i]):
-        x = conv(x)
-        x = norm(x)
-        x = self._activation(x)
-      scores[str(level)] = self._classifier(x)
-      boxes[str(level)] = self._box_regressor(x)
-    return scores, boxes
+    roi_features, roi_classes = inputs
+    _, num_rois, height, width, filters = roi_features.get_shape().as_list()
+
+    x = tf.reshape(roi_features, [-1, height, width, filters])
+    for conv, bn in zip(self._convs, self._conv_norms):
+      x = conv(x)
+      x = bn(x)
+      x = self._activation(x)
+
+    x = self._deconv(x)
+    x = self._deconv_bn(x)
+    x = self._activation(x)
+
+    logits = self._mask_regressor(x)
+
+    mask_height = height * self._config_dict['upsample_factor']
+    mask_width = width * self._config_dict['upsample_factor']
+
+    if self._config_dict['class_agnostic']:
+      return tf.reshape(logits, [-1, num_rois, mask_height, mask_width])
+    else:
+      logits = tf.reshape(
+          logits,
+          [-1, num_rois, mask_height, mask_width,
+           self._config_dict['num_classes']])
+      return tf.gather(
+          logits, tf.cast(roi_classes, dtype=tf.int32), axis=-1, batch_dims=2
+      )
 
   def get_config(self):
     return self._config_dict
 
   @classmethod
   def from_config(cls, config):
     return cls(**config)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/heads/dense_prediction_heads_test.py` & `tf-models-no-deps-2.16.0/official/vision/serving/video_classification_test.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,149 +1,113 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Tests for dense_prediction_heads.py."""
 
-# Import libraries
+# import io
+import os
+import random
+
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
-
-from official.vision.modeling.heads import dense_prediction_heads
-
+import tensorflow as tf, tf_keras
 
-class RetinaNetHeadTest(parameterized.TestCase, tf.test.TestCase):
-
-  @parameterized.parameters(
-      (False, False, False, None, False),
-      (False, True, False, None, False),
-      (True, False, True, 'regression', False),
-      (True, True, True, 'classification', True),
-  )
-  def test_forward(self, use_separable_conv, use_sync_bn, has_att_heads,
-                   att_type, share_classification_heads):
-    if has_att_heads:
-      attribute_heads = [dict(name='depth', type=att_type, size=1)]
+from official.core import exp_factory
+from official.vision import registry_imports  # pylint: disable=unused-import
+from official.vision.dataloaders import tfexample_utils
+from official.vision.serving import video_classification
+
+
+class VideoClassificationTest(tf.test.TestCase, parameterized.TestCase):
+
+  def _get_classification_module(self):
+    params = exp_factory.get_exp_config('video_classification_ucf101')
+    params.task.train_data.feature_shape = (8, 64, 64, 3)
+    params.task.validation_data.feature_shape = (8, 64, 64, 3)
+    params.task.model.backbone.resnet_3d.model_id = 50
+    classification_module = video_classification.VideoClassificationModule(
+        params, batch_size=1, input_image_size=[8, 64, 64])
+    return classification_module
+
+  def _export_from_module(self, module, input_type, save_directory):
+    signatures = module.get_inference_signatures(
+        {input_type: 'serving_default'})
+    tf.saved_model.save(module, save_directory, signatures=signatures)
+
+  def _get_dummy_input(self, input_type, module=None):
+    """Get dummy input for the given input type."""
+
+    if input_type == 'image_tensor':
+      images = np.random.randint(
+          low=0, high=255, size=(1, 8, 64, 64, 3), dtype=np.uint8)
+      # images = np.zeros((1, 8, 64, 64, 3), dtype=np.uint8)
+      return images, images
+    elif input_type == 'tf_example':
+      example = tfexample_utils.make_video_test_example(
+          image_shape=(64, 64, 3),
+          audio_shape=(20, 128),
+          label=random.randint(0, 100)).SerializeToString()
+      images = tf.nest.map_structure(
+          tf.stop_gradient,
+          tf.map_fn(
+              module._decode_tf_example,
+              elems=tf.constant([example]),
+              fn_output_signature={
+                  video_classification.video_input.IMAGE_KEY: tf.string,
+              }))
+      images = images[video_classification.video_input.IMAGE_KEY]
+      return [example], images
     else:
-      attribute_heads = None
-
-    retinanet_head = dense_prediction_heads.RetinaNetHead(
-        min_level=3,
-        max_level=4,
-        num_classes=3,
-        num_anchors_per_location=3,
-        num_convs=2,
-        num_filters=256,
-        attribute_heads=attribute_heads,
-        share_classification_heads=share_classification_heads,
-        use_separable_conv=use_separable_conv,
-        activation='relu',
-        use_sync_bn=use_sync_bn,
-        norm_momentum=0.99,
-        norm_epsilon=0.001,
-        kernel_regularizer=None,
-        bias_regularizer=None,
-    )
-    features = {
-        '3': np.random.rand(2, 128, 128, 16),
-        '4': np.random.rand(2, 64, 64, 16),
-    }
-    scores, boxes, attributes = retinanet_head(features)
-    self.assertAllEqual(scores['3'].numpy().shape, [2, 128, 128, 9])
-    self.assertAllEqual(scores['4'].numpy().shape, [2, 64, 64, 9])
-    self.assertAllEqual(boxes['3'].numpy().shape, [2, 128, 128, 12])
-    self.assertAllEqual(boxes['4'].numpy().shape, [2, 64, 64, 12])
-    if has_att_heads:
-      for att in attributes.values():
-        self.assertAllEqual(att['3'].numpy().shape, [2, 128, 128, 3])
-        self.assertAllEqual(att['4'].numpy().shape, [2, 64, 64, 3])
-
-  def test_serialize_deserialize(self):
-    retinanet_head = dense_prediction_heads.RetinaNetHead(
-        min_level=3,
-        max_level=7,
-        num_classes=3,
-        num_anchors_per_location=9,
-        num_convs=2,
-        num_filters=16,
-        attribute_heads=None,
-        use_separable_conv=False,
-        activation='relu',
-        use_sync_bn=False,
-        norm_momentum=0.99,
-        norm_epsilon=0.001,
-        kernel_regularizer=None,
-        bias_regularizer=None,
-    )
-    config = retinanet_head.get_config()
-    new_retinanet_head = (
-        dense_prediction_heads.RetinaNetHead.from_config(config))
-    self.assertAllEqual(
-        retinanet_head.get_config(), new_retinanet_head.get_config())
-
-
-class RpnHeadTest(parameterized.TestCase, tf.test.TestCase):
+      raise ValueError(f'{input_type}')
 
   @parameterized.parameters(
-      (False, False),
-      (False, True),
-      (True, False),
-      (True, True),
+      {'input_type': 'image_tensor'},
+      {'input_type': 'tf_example'},
   )
-  def test_forward(self, use_separable_conv, use_sync_bn):
-    rpn_head = dense_prediction_heads.RPNHead(
-        min_level=3,
-        max_level=4,
-        num_anchors_per_location=3,
-        num_convs=2,
-        num_filters=256,
-        use_separable_conv=use_separable_conv,
-        activation='relu',
-        use_sync_bn=use_sync_bn,
-        norm_momentum=0.99,
-        norm_epsilon=0.001,
-        kernel_regularizer=None,
-        bias_regularizer=None,
-    )
-    features = {
-        '3': np.random.rand(2, 128, 128, 16),
-        '4': np.random.rand(2, 64, 64, 16),
-    }
-    scores, boxes = rpn_head(features)
-    self.assertAllEqual(scores['3'].numpy().shape, [2, 128, 128, 3])
-    self.assertAllEqual(scores['4'].numpy().shape, [2, 64, 64, 3])
-    self.assertAllEqual(boxes['3'].numpy().shape, [2, 128, 128, 12])
-    self.assertAllEqual(boxes['4'].numpy().shape, [2, 64, 64, 12])
-
-  def test_serialize_deserialize(self):
-    rpn_head = dense_prediction_heads.RPNHead(
-        min_level=3,
-        max_level=7,
-        num_anchors_per_location=9,
-        num_convs=2,
-        num_filters=16,
-        use_separable_conv=False,
-        activation='relu',
-        use_sync_bn=False,
-        norm_momentum=0.99,
-        norm_epsilon=0.001,
-        kernel_regularizer=None,
-        bias_regularizer=None,
-    )
-    config = rpn_head.get_config()
-    new_rpn_head = dense_prediction_heads.RPNHead.from_config(config)
-    self.assertAllEqual(rpn_head.get_config(), new_rpn_head.get_config())
+  def test_export(self, input_type):
+    tmp_dir = self.get_temp_dir()
+    module = self._get_classification_module()
+
+    self._export_from_module(module, input_type, tmp_dir)
+
+    self.assertTrue(os.path.exists(os.path.join(tmp_dir, 'saved_model.pb')))
+    self.assertTrue(
+        os.path.exists(os.path.join(tmp_dir, 'variables', 'variables.index')))
+    self.assertTrue(
+        os.path.exists(
+            os.path.join(tmp_dir, 'variables',
+                         'variables.data-00000-of-00001')))
+
+    imported = tf.saved_model.load(tmp_dir)
+    classification_fn = imported.signatures['serving_default']
+
+    images, images_tensor = self._get_dummy_input(input_type, module)
+    processed_images = tf.nest.map_structure(
+        tf.stop_gradient,
+        tf.map_fn(
+            module._preprocess_image,
+            elems=images_tensor,
+            fn_output_signature={
+                'image': tf.float32,
+            }))
+    expected_logits = module.model(processed_images, training=False)
+    expected_prob = tf.nn.softmax(expected_logits)
+    out = classification_fn(tf.constant(images))
+
+    # The imported model should contain any trackable attrs that the original
+    # model had.
+    self.assertAllClose(out['logits'].numpy(), expected_logits.numpy())
+    self.assertAllClose(out['probs'].numpy(), expected_prob.numpy())
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/heads/instance_heads.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/heads/segmentation_heads.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,452 +1,472 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Contains definitions of instance prediction heads."""
-
-from typing import List, Union, Optional
-# Import libraries
-import tensorflow as tf
+"""Contains definitions of segmentation heads."""
+from typing import List, Union, Optional, Mapping, Tuple, Any
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
+from official.vision.modeling.layers import nn_layers
+from official.vision.ops import spatial_transform_ops
+
 
+class MaskScoring(tf_keras.Model):
+  """Creates a mask scoring layer.
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class DetectionHead(tf.keras.layers.Layer):
-  """Creates a detection head."""
+  This implements mask scoring layer from the paper:
+
+  Zhaojin Huang, Lichao Huang, Yongchao Gong, Chang Huang, Xinggang Wang.
+  Mask Scoring R-CNN.
+  (https://arxiv.org/pdf/1903.00241.pdf)
+  """
 
   def __init__(
       self,
       num_classes: int,
-      num_convs: int = 0,
+      fc_input_size: List[int],
+      num_convs: int = 3,
       num_filters: int = 256,
-      use_separable_conv: bool = False,
-      num_fcs: int = 2,
+      use_depthwise_convolution: bool = False,
       fc_dims: int = 1024,
-      class_agnostic_bbox_pred: bool = False,
+      num_fcs: int = 2,
       activation: str = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
-    """Initializes a detection head.
+
+    """Initializes mask scoring layer.
 
     Args:
-      num_classes: An `int` for the number of classes.
-      num_convs: An `int` number that represents the number of the intermediate
-        convolution layers before the FC layers.
-      num_filters: An `int` number that represents the number of filters of the
-        intermediate convolution layers.
-      use_separable_conv: A `bool` that indicates whether the separable
-        convolution layers is used.
-      num_fcs: An `int` number that represents the number of FC layers before
-        the predictions.
-      fc_dims: An `int` number that represents the number of dimension of the FC
-        layers.
-      class_agnostic_bbox_pred: `bool`, indicating whether bboxes should be
-        predicted for every class or not.
-      activation: A `str` that indicates which activation is used, e.g. 'relu',
-        'swish', etc.
-      use_sync_bn: A `bool` that indicates whether to use synchronized batch
-        normalization across different replicas.
-      norm_momentum: A `float` of normalization momentum for the moving average.
-      norm_epsilon: A `float` added to variance to avoid dividing by zero.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      num_classes: An `int` for number of classes.
+      fc_input_size: A List of `int` for the input size of the
+        fully connected layers.
+      num_convs: An`int` for number of conv layers.
+      num_filters: An `int` for the number of filters for conv layers.
+      use_depthwise_convolution: A `bool`, whether or not using depthwise convs.
+      fc_dims: An `int` number of filters for each fully connected layers.
+      num_fcs: An `int` for number of fully connected layers.
+      activation: A `str` name of the activation function.
+      use_sync_bn: A bool, whether or not to use sync batch normalization.
+      norm_momentum: A float for the momentum in BatchNorm. Defaults to 0.99.
+      norm_epsilon: A float for the epsilon value in BatchNorm. Defaults to
+        0.001.
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
       **kwargs: Additional keyword arguments to be passed.
     """
-    super(DetectionHead, self).__init__(**kwargs)
+    super(MaskScoring, self).__init__(**kwargs)
+
     self._config_dict = {
         'num_classes': num_classes,
         'num_convs': num_convs,
         'num_filters': num_filters,
-        'use_separable_conv': use_separable_conv,
-        'num_fcs': num_fcs,
+        'fc_input_size': fc_input_size,
         'fc_dims': fc_dims,
-        'class_agnostic_bbox_pred': class_agnostic_bbox_pred,
-        'activation': activation,
+        'num_fcs': num_fcs,
         'use_sync_bn': use_sync_bn,
+        'use_depthwise_convolution': use_depthwise_convolution,
         'norm_momentum': norm_momentum,
         'norm_epsilon': norm_epsilon,
+        'activation': activation,
         'kernel_regularizer': kernel_regularizer,
         'bias_regularizer': bias_regularizer,
     }
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation = tf_utils.get_activation(activation)
 
   def build(self, input_shape: Union[tf.TensorShape, List[tf.TensorShape]]):
-    """Creates the variables of the head."""
-    conv_op = (tf.keras.layers.SeparableConv2D
-               if self._config_dict['use_separable_conv']
-               else tf.keras.layers.Conv2D)
+    """Creates the variables of the mask scoring head."""
+    conv_op = tf_keras.layers.Conv2D
     conv_kwargs = {
         'filters': self._config_dict['num_filters'],
         'kernel_size': 3,
         'padding': 'same',
     }
-    if self._config_dict['use_separable_conv']:
-      conv_kwargs.update({
-          'depthwise_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'pointwise_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'bias_initializer': tf.zeros_initializer(),
-          'depthwise_regularizer': self._config_dict['kernel_regularizer'],
-          'pointwise_regularizer': self._config_dict['kernel_regularizer'],
-          'bias_regularizer': self._config_dict['bias_regularizer'],
-      })
-    else:
-      conv_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'bias_initializer': tf.zeros_initializer(),
-          'kernel_regularizer': self._config_dict['kernel_regularizer'],
-          'bias_regularizer': self._config_dict['bias_regularizer'],
-      })
-    bn_op = (tf.keras.layers.experimental.SyncBatchNormalization
-             if self._config_dict['use_sync_bn']
-             else tf.keras.layers.BatchNormalization)
+    conv_kwargs.update({
+        'kernel_initializer': tf_keras.initializers.VarianceScaling(
+            scale=2, mode='fan_out', distribution='untruncated_normal'),
+        'bias_initializer': tf.zeros_initializer(),
+        'kernel_regularizer': self._config_dict['kernel_regularizer'],
+        'bias_regularizer': self._config_dict['bias_regularizer'],
+    })
+    bn_op = tf_keras.layers.BatchNormalization
     bn_kwargs = {
         'axis': self._bn_axis,
         'momentum': self._config_dict['norm_momentum'],
         'epsilon': self._config_dict['norm_epsilon'],
+        'synchronized': self._config_dict['use_sync_bn'],
     }
 
     self._convs = []
     self._conv_norms = []
     for i in range(self._config_dict['num_convs']):
-      conv_name = 'detection-conv_{}'.format(i)
+      if self._config_dict['use_depthwise_convolution']:
+        self._convs.append(
+            tf_keras.layers.DepthwiseConv2D(
+                name='mask-scoring-depthwise-conv-{}'.format(i),
+                kernel_size=3,
+                padding='same',
+                use_bias=False,
+                depthwise_initializer=tf_keras.initializers.RandomNormal(
+                    stddev=0.01),
+                depthwise_regularizer=self._config_dict['kernel_regularizer'],
+                depth_multiplier=1))
+        norm_name = 'mask-scoring-depthwise-bn-{}'.format(i)
+        self._conv_norms.append(bn_op(name=norm_name, **bn_kwargs))
+      conv_name = 'mask-scoring-conv-{}'.format(i)
       if 'kernel_initializer' in conv_kwargs:
         conv_kwargs['kernel_initializer'] = tf_utils.clone_initializer(
             conv_kwargs['kernel_initializer'])
+      if self._config_dict['use_depthwise_convolution']:
+        conv_kwargs['kernel_size'] = 1
       self._convs.append(conv_op(name=conv_name, **conv_kwargs))
-      bn_name = 'detection-conv-bn_{}'.format(i)
+      bn_name = 'mask-scoring-bn-{}'.format(i)
       self._conv_norms.append(bn_op(name=bn_name, **bn_kwargs))
 
     self._fcs = []
     self._fc_norms = []
     for i in range(self._config_dict['num_fcs']):
-      fc_name = 'detection-fc_{}'.format(i)
+      fc_name = 'mask-scoring-fc-{}'.format(i)
       self._fcs.append(
-          tf.keras.layers.Dense(
+          tf_keras.layers.Dense(
               units=self._config_dict['fc_dims'],
-              kernel_initializer=tf.keras.initializers.VarianceScaling(
+              kernel_initializer=tf_keras.initializers.VarianceScaling(
                   scale=1 / 3.0, mode='fan_out', distribution='uniform'),
               kernel_regularizer=self._config_dict['kernel_regularizer'],
               bias_regularizer=self._config_dict['bias_regularizer'],
               name=fc_name))
-      bn_name = 'detection-fc-bn_{}'.format(i)
+      bn_name = 'mask-scoring-fc-bn-{}'.format(i)
       self._fc_norms.append(bn_op(name=bn_name, **bn_kwargs))
 
-    self._classifier = tf.keras.layers.Dense(
+    self._classifier = tf_keras.layers.Dense(
         units=self._config_dict['num_classes'],
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),
-        bias_initializer=tf.zeros_initializer(),
-        kernel_regularizer=self._config_dict['kernel_regularizer'],
-        bias_regularizer=self._config_dict['bias_regularizer'],
-        name='detection-scores')
-
-    num_box_outputs = (4 if self._config_dict['class_agnostic_bbox_pred'] else
-                       self._config_dict['num_classes'] * 4)
-    self._box_regressor = tf.keras.layers.Dense(
-        units=num_box_outputs,
-        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.001),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
         bias_initializer=tf.zeros_initializer(),
         kernel_regularizer=self._config_dict['kernel_regularizer'],
         bias_regularizer=self._config_dict['bias_regularizer'],
-        name='detection-boxes')
+        name='iou-scores')
 
-    super(DetectionHead, self).build(input_shape)
+    super(MaskScoring, self).build(input_shape)
 
-  def call(self, inputs: tf.Tensor, training: bool = None):
-    """Forward pass of box and class branches for the Mask-RCNN model.
+  def call(self, inputs: tf.Tensor, training: bool = None):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
+    """Forward pass mask scoring head.
 
     Args:
-      inputs: A `tf.Tensor` of the shape [batch_size, num_instances, roi_height,
-        roi_width, roi_channels], representing the ROI features.
+      inputs: A `tf.Tensor` of the shape [batch_size, width, size, num_classes],
+      representing the segmentation logits.
       training: a `bool` indicating whether it is in `training` mode.
 
     Returns:
-      class_outputs: A `tf.Tensor` of the shape
-        [batch_size, num_rois, num_classes], representing the class predictions.
-      box_outputs: A `tf.Tensor` of the shape
-        [batch_size, num_rois, num_classes * 4], representing the box
-        predictions.
+      mask_scores: A `tf.Tensor` of predicted mask scores
+        [batch_size, num_classes].
     """
-    roi_features = inputs
-    _, num_rois, height, width, filters = roi_features.get_shape().as_list()
-
-    x = tf.reshape(roi_features, [-1, height, width, filters])
+    x = tf.stop_gradient(inputs)
     for conv, bn in zip(self._convs, self._conv_norms):
       x = conv(x)
       x = bn(x)
       x = self._activation(x)
 
-    _, _, _, filters = x.get_shape().as_list()
-    x = tf.reshape(x, [-1, num_rois, height * width * filters])
+    # Casts feat to float32 so the resize op can be run on TPU.
+    x = tf.cast(x, tf.float32)
+    x = tf.image.resize(x, size=self._config_dict['fc_input_size'],
+                        method=tf.image.ResizeMethod.BILINEAR)
+    # Casts it back to be compatible with the rest opetations.
+    x = tf.cast(x, inputs.dtype)
+
+    _, h, w, filters = x.get_shape().as_list()
+    x = tf.reshape(x, [-1, h * w * filters])
 
     for fc, bn in zip(self._fcs, self._fc_norms):
       x = fc(x)
       x = bn(x)
       x = self._activation(x)
 
-    classes = self._classifier(x)
-    boxes = self._box_regressor(x)
-    return classes, boxes
+    ious = self._classifier(x)
+    return ious
 
-  def get_config(self):
+  def get_config(self) -> Mapping[str, Any]:
     return self._config_dict
 
   @classmethod
-  def from_config(cls, config):
+  def from_config(cls, config, custom_objects=None):
     return cls(**config)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MaskHead(tf.keras.layers.Layer):
-  """Creates a mask head."""
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SegmentationHead(tf_keras.layers.Layer):
+  """Creates a segmentation head."""
 
   def __init__(
       self,
       num_classes: int,
-      upsample_factor: int = 2,
-      num_convs: int = 4,
+      level: Union[int, str],
+      num_convs: int = 2,
       num_filters: int = 256,
-      use_separable_conv: bool = False,
+      use_depthwise_convolution: bool = False,
+      prediction_kernel_size: int = 1,
+      upsample_factor: int = 1,
+      feature_fusion: Optional[str] = None,
+      decoder_min_level: Optional[int] = None,
+      decoder_max_level: Optional[int] = None,
+      low_level: int = 2,
+      low_level_num_filters: int = 48,
+      num_decoder_filters: int = 256,
       activation: str = 'relu',
+      logit_activation: Optional[str] = None,
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      class_agnostic: bool = False,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
-    """Initializes a mask head.
+    """Initializes a segmentation head.
 
     Args:
-      num_classes: An `int` of the number of classes.
-      upsample_factor: An `int` that indicates the upsample factor to generate
-        the final predicted masks. It should be >= 1.
-      num_convs: An `int` number that represents the number of the intermediate
-        convolution layers before the mask prediction layers.
-      num_filters: An `int` number that represents the number of filters of the
-        intermediate convolution layers.
-      use_separable_conv: A `bool` that indicates whether the separable
-        convolution layers is used.
+      num_classes: An `int` number of mask classification categories. The number
+        of classes does not include background class.
+      level: An `int` or `str`, level to use to build segmentation head.
+      num_convs: An `int` number of stacked convolution before the last
+        prediction layer.
+      num_filters: An `int` number to specify the number of filters used.
+        Default is 256.
+      use_depthwise_convolution: A bool to specify if use depthwise separable
+        convolutions.
+      prediction_kernel_size: An `int` number to specify the kernel size of the
+      prediction layer.
+      upsample_factor: An `int` number to specify the upsampling factor to
+        generate finer mask. Default 1 means no upsampling is applied.
+      feature_fusion: One of the constants in nn_layers.FeatureFusion, namely
+        `deeplabv3plus`, `pyramid_fusion`, `panoptic_fpn_fusion`,
+        `deeplabv3plus_sum_to_merge`, or None. If `deeplabv3plus`, features from
+        decoder_features[level] will be fused with low level feature maps from
+        backbone. If `pyramid_fusion`, multiscale features will be resized and
+        fused at the target level.
+      decoder_min_level: An `int` of minimum level from decoder to use in
+        feature fusion. It is only used when feature_fusion is set to
+        `panoptic_fpn_fusion`.
+      decoder_max_level: An `int` of maximum level from decoder to use in
+        feature fusion. It is only used when feature_fusion is set to
+        `panoptic_fpn_fusion`.
+      low_level: An `int` of backbone level to be used for feature fusion. It is
+        used when feature_fusion is set to `deeplabv3plus` or
+        `deeplabv3plus_sum_to_merge`.
+      low_level_num_filters: An `int` of reduced number of filters for the low
+        level features before fusing it with higher level features. It is only
+        used when feature_fusion is set to `deeplabv3plus` or
+        `deeplabv3plus_sum_to_merge`.
+      num_decoder_filters: An `int` of number of filters in the decoder outputs.
+        It is only used when feature_fusion is set to `panoptic_fpn_fusion`.
       activation: A `str` that indicates which activation is used, e.g. 'relu',
         'swish', etc.
+      logit_activation: Activation applied to the final classifier layer logits,
+        e.g. 'sigmoid', 'softmax'. Can be useful in cases when the task does not
+        use only cross entropy loss.
       use_sync_bn: A `bool` that indicates whether to use synchronized batch
         normalization across different replicas.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
-      class_agnostic: A `bool`. If set, we use a single channel mask head that
-        is shared between all classes.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
       **kwargs: Additional keyword arguments to be passed.
     """
-    super(MaskHead, self).__init__(**kwargs)
+    super(SegmentationHead, self).__init__(**kwargs)
+
     self._config_dict = {
         'num_classes': num_classes,
-        'upsample_factor': upsample_factor,
+        'level': level,
         'num_convs': num_convs,
         'num_filters': num_filters,
-        'use_separable_conv': use_separable_conv,
+        'use_depthwise_convolution': use_depthwise_convolution,
+        'prediction_kernel_size': prediction_kernel_size,
+        'upsample_factor': upsample_factor,
+        'feature_fusion': feature_fusion,
+        'decoder_min_level': decoder_min_level,
+        'decoder_max_level': decoder_max_level,
+        'low_level': low_level,
+        'low_level_num_filters': low_level_num_filters,
+        'num_decoder_filters': num_decoder_filters,
         'activation': activation,
+        'logit_activation': logit_activation,
         'use_sync_bn': use_sync_bn,
         'norm_momentum': norm_momentum,
         'norm_epsilon': norm_epsilon,
         'kernel_regularizer': kernel_regularizer,
-        'bias_regularizer': bias_regularizer,
-        'class_agnostic': class_agnostic
+        'bias_regularizer': bias_regularizer
     }
-
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation = tf_utils.get_activation(activation)
 
   def build(self, input_shape: Union[tf.TensorShape, List[tf.TensorShape]]):
-    """Creates the variables of the head."""
-    conv_op = (tf.keras.layers.SeparableConv2D
-               if self._config_dict['use_separable_conv']
-               else tf.keras.layers.Conv2D)
-    conv_kwargs = {
-        'filters': self._config_dict['num_filters'],
-        'kernel_size': 3,
-        'padding': 'same',
-    }
-    if self._config_dict['use_separable_conv']:
-      conv_kwargs.update({
-          'depthwise_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'pointwise_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'bias_initializer': tf.zeros_initializer(),
-          'depthwise_regularizer': self._config_dict['kernel_regularizer'],
-          'pointwise_regularizer': self._config_dict['kernel_regularizer'],
-          'bias_regularizer': self._config_dict['bias_regularizer'],
-      })
-    else:
-      conv_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'bias_initializer': tf.zeros_initializer(),
-          'kernel_regularizer': self._config_dict['kernel_regularizer'],
-          'bias_regularizer': self._config_dict['bias_regularizer'],
-      })
-    bn_op = (tf.keras.layers.experimental.SyncBatchNormalization
-             if self._config_dict['use_sync_bn']
-             else tf.keras.layers.BatchNormalization)
+    """Creates the variables of the segmentation head."""
+    use_depthwise_convolution = self._config_dict['use_depthwise_convolution']
+    conv_op = tf_keras.layers.Conv2D
+    bn_op = tf_keras.layers.BatchNormalization
     bn_kwargs = {
         'axis': self._bn_axis,
         'momentum': self._config_dict['norm_momentum'],
         'epsilon': self._config_dict['norm_epsilon'],
+        'synchronized': self._config_dict['use_sync_bn'],
     }
 
+    if self._config_dict['feature_fusion'] in {'deeplabv3plus',
+                                               'deeplabv3plus_sum_to_merge'}:
+      # Deeplabv3+ feature fusion layers.
+      self._dlv3p_conv = conv_op(
+          kernel_size=1,
+          padding='same',
+          use_bias=False,
+          kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
+          kernel_regularizer=self._config_dict['kernel_regularizer'],
+          name='segmentation_head_deeplabv3p_fusion_conv',
+          filters=self._config_dict['low_level_num_filters'])
+
+      self._dlv3p_norm = bn_op(
+          name='segmentation_head_deeplabv3p_fusion_norm', **bn_kwargs)
+
+    elif self._config_dict['feature_fusion'] == 'panoptic_fpn_fusion':
+      self._panoptic_fpn_fusion = nn_layers.PanopticFPNFusion(
+          min_level=self._config_dict['decoder_min_level'],
+          max_level=self._config_dict['decoder_max_level'],
+          target_level=self._config_dict['level'],
+          num_filters=self._config_dict['num_filters'],
+          num_fpn_filters=self._config_dict['num_decoder_filters'],
+          activation=self._config_dict['activation'],
+          kernel_regularizer=self._config_dict['kernel_regularizer'],
+          bias_regularizer=self._config_dict['bias_regularizer'])
+
+    # Segmentation head layers.
     self._convs = []
-    self._conv_norms = []
+    self._norms = []
     for i in range(self._config_dict['num_convs']):
-      conv_name = 'mask-conv_{}'.format(i)
-      for initializer_name in ['kernel_initializer', 'depthwise_initializer',
-                               'pointwise_initializer']:
-        if initializer_name in conv_kwargs:
-          conv_kwargs[initializer_name] = tf_utils.clone_initializer(
-              conv_kwargs[initializer_name])
-      self._convs.append(conv_op(name=conv_name, **conv_kwargs))
-      bn_name = 'mask-conv-bn_{}'.format(i)
-      self._conv_norms.append(bn_op(name=bn_name, **bn_kwargs))
-
-    self._deconv = tf.keras.layers.Conv2DTranspose(
-        filters=self._config_dict['num_filters'],
-        kernel_size=self._config_dict['upsample_factor'],
-        strides=self._config_dict['upsample_factor'],
-        padding='valid',
-        kernel_initializer=tf.keras.initializers.VarianceScaling(
-            scale=2, mode='fan_out', distribution='untruncated_normal'),
+      if use_depthwise_convolution:
+        self._convs.append(
+            tf_keras.layers.DepthwiseConv2D(
+                name='segmentation_head_depthwise_conv_{}'.format(i),
+                kernel_size=3,
+                padding='same',
+                use_bias=False,
+                depthwise_initializer=tf_keras.initializers.RandomNormal(
+                    stddev=0.01),
+                depthwise_regularizer=self._config_dict['kernel_regularizer'],
+                depth_multiplier=1))
+        norm_name = 'segmentation_head_depthwise_norm_{}'.format(i)
+        self._norms.append(bn_op(name=norm_name, **bn_kwargs))
+      conv_name = 'segmentation_head_conv_{}'.format(i)
+      self._convs.append(
+          conv_op(
+              name=conv_name,
+              filters=self._config_dict['num_filters'],
+              kernel_size=3 if not use_depthwise_convolution else 1,
+              padding='same',
+              use_bias=False,
+              kernel_initializer=tf_keras.initializers.RandomNormal(
+                  stddev=0.01),
+              kernel_regularizer=self._config_dict['kernel_regularizer']))
+      norm_name = 'segmentation_head_norm_{}'.format(i)
+      self._norms.append(bn_op(name=norm_name, **bn_kwargs))
+
+    self._classifier = conv_op(
+        name='segmentation_output',
+        filters=self._config_dict['num_classes'],
+        kernel_size=self._config_dict['prediction_kernel_size'],
+        padding='same',
+        activation=self._config_dict['logit_activation'],
         bias_initializer=tf.zeros_initializer(),
+        kernel_initializer=tf_keras.initializers.RandomNormal(stddev=0.01),
         kernel_regularizer=self._config_dict['kernel_regularizer'],
-        bias_regularizer=self._config_dict['bias_regularizer'],
-        name='mask-upsampling')
-    self._deconv_bn = bn_op(name='mask-deconv-bn', **bn_kwargs)
-
-    if self._config_dict['class_agnostic']:
-      num_filters = 1
-    else:
-      num_filters = self._config_dict['num_classes']
-
-    conv_kwargs = {
-        'filters': num_filters,
-        'kernel_size': 1,
-        'padding': 'valid',
-    }
-    if self._config_dict['use_separable_conv']:
-      conv_kwargs.update({
-          'depthwise_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'pointwise_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'bias_initializer': tf.zeros_initializer(),
-          'depthwise_regularizer': self._config_dict['kernel_regularizer'],
-          'pointwise_regularizer': self._config_dict['kernel_regularizer'],
-          'bias_regularizer': self._config_dict['bias_regularizer'],
-      })
-    else:
-      conv_kwargs.update({
-          'kernel_initializer': tf.keras.initializers.VarianceScaling(
-              scale=2, mode='fan_out', distribution='untruncated_normal'),
-          'bias_initializer': tf.zeros_initializer(),
-          'kernel_regularizer': self._config_dict['kernel_regularizer'],
-          'bias_regularizer': self._config_dict['bias_regularizer'],
-      })
-    self._mask_regressor = conv_op(name='mask-logits', **conv_kwargs)
+        bias_regularizer=self._config_dict['bias_regularizer'])
 
-    super(MaskHead, self).build(input_shape)
+    super().build(input_shape)
 
-  def call(self, inputs: List[tf.Tensor], training: bool = None):
-    """Forward pass of mask branch for the Mask-RCNN model.
+  def call(self, inputs: Tuple[Union[tf.Tensor, Mapping[str, tf.Tensor]],
+                               Union[tf.Tensor, Mapping[str, tf.Tensor]]]):
+    """Forward pass of the segmentation head.
+
+    It supports both a tuple of 2 tensors or 2 dictionaries. The first is
+    backbone endpoints, and the second is decoder endpoints. When inputs are
+    tensors, they are from a single level of feature maps. When inputs are
+    dictionaries, they contain multiple levels of feature maps, where the key
+    is the index of feature map.
 
     Args:
-      inputs: A `list` of two tensors where
-        inputs[0]: A `tf.Tensor` of shape [batch_size, num_instances,
-          roi_height, roi_width, roi_channels], representing the ROI features.
-        inputs[1]: A `tf.Tensor` of shape [batch_size, num_instances],
-          representing the classes of the ROIs.
-      training: A `bool` indicating whether it is in `training` mode.
-
+      inputs: A tuple of 2 feature map tensors of shape
+        [batch, height_l, width_l, channels] or 2 dictionaries of tensors:
+        - key: A `str` of the level of the multilevel features.
+        - values: A `tf.Tensor` of the feature map tensors, whose shape is
+            [batch, height_l, width_l, channels].
+        The first is backbone endpoints, and the second is decoder endpoints.
     Returns:
-      mask_outputs: A `tf.Tensor` of shape
-        [batch_size, num_instances, roi_height * upsample_factor,
-         roi_width * upsample_factor], representing the mask predictions.
+      segmentation prediction mask: A `tf.Tensor` of the segmentation mask
+        scores predicted from input features.
     """
-    roi_features, roi_classes = inputs
-    batch_size, num_rois, height, width, filters = (
-        roi_features.get_shape().as_list())
-    if batch_size is None:
-      batch_size = tf.shape(roi_features)[0]
-
-    x = tf.reshape(roi_features, [-1, height, width, filters])
-    for conv, bn in zip(self._convs, self._conv_norms):
-      x = conv(x)
-      x = bn(x)
-      x = self._activation(x)
-
-    x = self._deconv(x)
-    x = self._deconv_bn(x)
-    x = self._activation(x)
-
-    logits = self._mask_regressor(x)
-
-    mask_height = height * self._config_dict['upsample_factor']
-    mask_width = width * self._config_dict['upsample_factor']
 
-    if self._config_dict['class_agnostic']:
-      logits = tf.reshape(logits, [-1, num_rois, mask_height, mask_width, 1])
+    backbone_output = inputs[0]
+    decoder_output = inputs[1]
+    if self._config_dict['feature_fusion'] in {'deeplabv3plus',
+                                               'deeplabv3plus_sum_to_merge'}:
+      # deeplabv3+ feature fusion
+      x = decoder_output[str(self._config_dict['level'])] if isinstance(
+          decoder_output, dict) else decoder_output
+      y = backbone_output[str(self._config_dict['low_level'])] if isinstance(
+          backbone_output, dict) else backbone_output
+      y = self._dlv3p_norm(self._dlv3p_conv(y))
+      y = self._activation(y)
+
+      x = tf.image.resize(
+          x, tf.shape(y)[1:3], method=tf.image.ResizeMethod.BILINEAR)
+      x = tf.cast(x, dtype=y.dtype)
+      if self._config_dict['feature_fusion'] == 'deeplabv3plus':
+        x = tf.concat([x, y], axis=self._bn_axis)
+      else:
+        x = tf_keras.layers.Add()([x, y])
+    elif self._config_dict['feature_fusion'] == 'pyramid_fusion':
+      if not isinstance(decoder_output, dict):
+        raise ValueError('Only support dictionary decoder_output.')
+      x = nn_layers.pyramid_feature_fusion(decoder_output,
+                                           self._config_dict['level'])
+    elif self._config_dict['feature_fusion'] == 'panoptic_fpn_fusion':
+      x = self._panoptic_fpn_fusion(decoder_output)
     else:
-      logits = tf.reshape(
-          logits,
-          [-1, num_rois, mask_height, mask_width,
-           self._config_dict['num_classes']])
-
-    batch_indices = tf.tile(
-        tf.expand_dims(tf.range(batch_size), axis=1), [1, num_rois])
-    mask_indices = tf.tile(
-        tf.expand_dims(tf.range(num_rois), axis=0), [batch_size, 1])
+      x = decoder_output[str(self._config_dict['level'])] if isinstance(
+          decoder_output, dict) else decoder_output
 
-    if self._config_dict['class_agnostic']:
-      class_gather_indices = tf.zeros_like(roi_classes, dtype=tf.int32)
-    else:
-      class_gather_indices = tf.cast(roi_classes, dtype=tf.int32)
+    for conv, norm in zip(self._convs, self._norms):
+      x = conv(x)
+      x = norm(x)
+      x = self._activation(x)
+    if self._config_dict['upsample_factor'] > 1:
+      x = spatial_transform_ops.nearest_upsampling(
+          x, scale=self._config_dict['upsample_factor'])
 
-    gather_indices = tf.stack(
-        [batch_indices, mask_indices, class_gather_indices],
-        axis=2)
-    mask_outputs = tf.gather_nd(
-        tf.transpose(logits, [0, 1, 4, 2, 3]), gather_indices)
-    return mask_outputs
+    return self._classifier(x)
 
   def get_config(self):
-    return self._config_dict
+    base_config = super().get_config()
+    return dict(list(base_config.items()) + list(self._config_dict.items()))
 
   @classmethod
   def from_config(cls, config):
     return cls(**config)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/heads/instance_heads_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/heads/instance_heads_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for instance_heads.py."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.heads import instance_heads
 
 
 class DetectionHeadTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/heads/segmentation_heads_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/heads/segmentation_heads_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for segmentation_heads.py."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.heads import segmentation_heads
 
 
 class SegmentationHeadTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/box_sampler.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/box_sampler.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,21 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains definitions of box sampler."""
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import sampling_ops
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class BoxSampler(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class BoxSampler(tf_keras.layers.Layer):
   """Creates a BoxSampler to sample positive and negative boxes."""
 
   def __init__(self,
                num_samples: int = 512,
                foreground_fraction: float = 0.25,
                **kwargs):
     """Initializes a box sampler.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/deeplab.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/deeplab.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,20 +10,20 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Layers for DeepLabV3."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 
 
-class SpatialPyramidPooling(tf.keras.layers.Layer):
+class SpatialPyramidPooling(tf_keras.layers.Layer):
   """Implements the Atrous Spatial Pyramid Pooling.
 
   References:
     [Rethinking Atrous Convolution for Semantic Image Segmentation](
       https://arxiv.org/pdf/1706.05587.pdf)
     [Encoder-Decoder with Atrous Separable Convolution for Semantic Image
     Segmentation](https://arxiv.org/pdf/1802.02611.pdf)
@@ -75,128 +75,128 @@
     self.output_channels = output_channels
     self.dilation_rates = dilation_rates
     self.use_sync_bn = use_sync_bn
     self.batchnorm_momentum = batchnorm_momentum
     self.batchnorm_epsilon = batchnorm_epsilon
     self.activation = activation
     self.dropout = dropout
-    self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)
-    self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)
+    self.kernel_initializer = tf_keras.initializers.get(kernel_initializer)
+    self.kernel_regularizer = tf_keras.regularizers.get(kernel_regularizer)
     self.interpolation = interpolation
-    self.input_spec = tf.keras.layers.InputSpec(ndim=4)
+    self.input_spec = tf_keras.layers.InputSpec(ndim=4)
     self.pool_kernel_size = pool_kernel_size
     self.use_depthwise_convolution = use_depthwise_convolution
 
   def build(self, input_shape):
     channels = input_shape[3]
 
     self.aspp_layers = []
+    bn_op = tf_keras.layers.BatchNormalization
 
-    if self.use_sync_bn:
-      bn_op = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      bn_op = tf.keras.layers.BatchNormalization
-
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       bn_axis = -1
     else:
       bn_axis = 1
 
-    conv_sequential = tf.keras.Sequential([
-        tf.keras.layers.Conv2D(
+    conv_sequential = tf_keras.Sequential([
+        tf_keras.layers.Conv2D(
             filters=self.output_channels,
             kernel_size=(1, 1),
             kernel_initializer=tf_utils.clone_initializer(
                 self.kernel_initializer),
             kernel_regularizer=self.kernel_regularizer,
             use_bias=False),
         bn_op(
             axis=bn_axis,
             momentum=self.batchnorm_momentum,
-            epsilon=self.batchnorm_epsilon),
-        tf.keras.layers.Activation(self.activation)
+            epsilon=self.batchnorm_epsilon,
+            synchronized=self.use_sync_bn),
+        tf_keras.layers.Activation(self.activation)
     ])
     self.aspp_layers.append(conv_sequential)
 
     for dilation_rate in self.dilation_rates:
       leading_layers = []
       kernel_size = (3, 3)
       if self.use_depthwise_convolution:
         leading_layers += [
-            tf.keras.layers.DepthwiseConv2D(
+            tf_keras.layers.DepthwiseConv2D(
                 depth_multiplier=1,
                 kernel_size=kernel_size,
                 padding='same',
                 dilation_rate=dilation_rate,
                 use_bias=False)
         ]
         kernel_size = (1, 1)
-      conv_sequential = tf.keras.Sequential(leading_layers + [
-          tf.keras.layers.Conv2D(
+      conv_sequential = tf_keras.Sequential(leading_layers + [
+          tf_keras.layers.Conv2D(
               filters=self.output_channels,
               kernel_size=kernel_size,
               padding='same',
               kernel_regularizer=self.kernel_regularizer,
               kernel_initializer=tf_utils.clone_initializer(
                   self.kernel_initializer),
               dilation_rate=dilation_rate,
               use_bias=False),
           bn_op(
               axis=bn_axis,
               momentum=self.batchnorm_momentum,
-              epsilon=self.batchnorm_epsilon),
-          tf.keras.layers.Activation(self.activation)
+              epsilon=self.batchnorm_epsilon,
+              synchronized=self.use_sync_bn),
+          tf_keras.layers.Activation(self.activation)
       ])
       self.aspp_layers.append(conv_sequential)
 
     if self.pool_kernel_size is None:
-      pool_sequential = tf.keras.Sequential([
-          tf.keras.layers.GlobalAveragePooling2D(),
-          tf.keras.layers.Reshape((1, 1, channels))])
+      pool_sequential = tf_keras.Sequential([
+          tf_keras.layers.GlobalAveragePooling2D(),
+          tf_keras.layers.Reshape((1, 1, channels))])
     else:
-      pool_sequential = tf.keras.Sequential([
-          tf.keras.layers.AveragePooling2D(self.pool_kernel_size)])
+      pool_sequential = tf_keras.Sequential([
+          tf_keras.layers.AveragePooling2D(self.pool_kernel_size)])
 
     pool_sequential.add(
-        tf.keras.Sequential([
-            tf.keras.layers.Conv2D(
+        tf_keras.Sequential([
+            tf_keras.layers.Conv2D(
                 filters=self.output_channels,
                 kernel_size=(1, 1),
                 kernel_initializer=tf_utils.clone_initializer(
                     self.kernel_initializer),
                 kernel_regularizer=self.kernel_regularizer,
                 use_bias=False),
             bn_op(
                 axis=bn_axis,
                 momentum=self.batchnorm_momentum,
-                epsilon=self.batchnorm_epsilon),
-            tf.keras.layers.Activation(self.activation)
+                epsilon=self.batchnorm_epsilon,
+                synchronized=self.use_sync_bn),
+            tf_keras.layers.Activation(self.activation)
         ]))
 
     self.aspp_layers.append(pool_sequential)
 
-    self.projection = tf.keras.Sequential([
-        tf.keras.layers.Conv2D(
+    self.projection = tf_keras.Sequential([
+        tf_keras.layers.Conv2D(
             filters=self.output_channels,
             kernel_size=(1, 1),
             kernel_initializer=tf_utils.clone_initializer(
                 self.kernel_initializer),
             kernel_regularizer=self.kernel_regularizer,
             use_bias=False),
         bn_op(
             axis=bn_axis,
             momentum=self.batchnorm_momentum,
-            epsilon=self.batchnorm_epsilon),
-        tf.keras.layers.Activation(self.activation),
-        tf.keras.layers.Dropout(rate=self.dropout)
+            epsilon=self.batchnorm_epsilon,
+            synchronized=self.use_sync_bn),
+        tf_keras.layers.Activation(self.activation),
+        tf_keras.layers.Dropout(rate=self.dropout)
     ])
 
   def call(self, inputs, training=None):
     if training is None:
-      training = tf.keras.backend.learning_phase()
+      training = tf_keras.backend.learning_phase()
     result = []
     for i, layer in enumerate(self.aspp_layers):
       x = layer(inputs, training=training)
       # Apply resize layer to the end of the last set of layers.
       if i == len(self.aspp_layers) - 1:
         x = tf.image.resize(tf.cast(x, tf.float32), tf.shape(inputs)[1:3])
       result.append(tf.cast(x, inputs.dtype))
@@ -210,15 +210,15 @@
         'dilation_rates': self.dilation_rates,
         'pool_kernel_size': self.pool_kernel_size,
         'use_sync_bn': self.use_sync_bn,
         'batchnorm_momentum': self.batchnorm_momentum,
         'batchnorm_epsilon': self.batchnorm_epsilon,
         'activation': self.activation,
         'dropout': self.dropout,
-        'kernel_initializer': tf.keras.initializers.serialize(
+        'kernel_initializer': tf_keras.initializers.serialize(
             self.kernel_initializer),
-        'kernel_regularizer': tf.keras.regularizers.serialize(
+        'kernel_regularizer': tf_keras.regularizers.serialize(
             self.kernel_regularizer),
         'interpolation': self.interpolation,
     }
     base_config = super(SpatialPyramidPooling, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/deeplab_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/deeplab_test.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,37 +10,37 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for ASPP."""
 
-import tensorflow as tf
+from absl.testing import parameterized
+import tensorflow as tf, tf_keras
 
-from tensorflow.python.keras import keras_parameterized
 from official.vision.modeling.layers import deeplab
 
 
-@keras_parameterized.run_all_keras_modes
-class DeeplabTest(keras_parameterized.TestCase):
+class DeeplabTest(tf.test.TestCase, parameterized.TestCase):
 
-  @keras_parameterized.parameterized.parameters(
+  @parameterized.parameters(
       (None,),
       ([32, 32],),
       )
   def test_aspp(self, pool_kernel_size):
-    inputs = tf.keras.Input(shape=(64, 64, 128), dtype=tf.float32)
+    del pool_kernel_size
+    inputs = tf_keras.Input(shape=(64, 64, 128), dtype=tf.float32)
     layer = deeplab.SpatialPyramidPooling(output_channels=256,
                                           dilation_rates=[6, 12, 18],
                                           pool_kernel_size=None)
     output = layer(inputs)
     self.assertAllEqual([None, 64, 64, 256], output.shape)
 
   def test_aspp_invalid_shape(self):
-    inputs = tf.keras.Input(shape=(64, 64), dtype=tf.float32)
+    inputs = tf_keras.Input(shape=(64, 64), dtype=tf.float32)
     layer = deeplab.SpatialPyramidPooling(output_channels=256,
                                           dilation_rates=[6, 12, 18])
     with self.assertRaises(ValueError):
       _ = layer(inputs)
 
   def test_config_with_custom_name(self):
     layer = deeplab.SpatialPyramidPooling(256, [5], name='aspp')
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/detection_generator.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/detection_generator.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,52 +10,56 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains definitions of generators to generate the final detections."""
 import contextlib
-from typing import Any, Dict, List, Optional, Mapping, Sequence
+from typing import Any, Dict, List, Optional, Mapping, Sequence, Tuple
+
 # Import libraries
-import tensorflow as tf
 
+import numpy as np
+import tensorflow as tf, tf_keras
+
+from official.vision.modeling.layers import edgetpu
 from official.vision.ops import box_ops
 from official.vision.ops import nms
 from official.vision.ops import preprocess_ops
 
 
-def _generate_detections_v1(boxes: tf.Tensor,
-                            scores: tf.Tensor,
-                            attributes: Optional[Mapping[str,
-                                                         tf.Tensor]] = None,
-                            pre_nms_top_k: int = 5000,
-                            pre_nms_score_threshold: float = 0.05,
-                            nms_iou_threshold: float = 0.5,
-                            max_num_detections: int = 100,
-                            soft_nms_sigma: Optional[float] = None):
+def _generate_detections_v1(
+    boxes: tf.Tensor,
+    scores: tf.Tensor,
+    attributes: Optional[Mapping[str, tf.Tensor]] = None,
+    pre_nms_top_k: int = 5000,
+    pre_nms_score_threshold: float = 0.05,
+    nms_iou_threshold: float = 0.5,
+    max_num_detections: int = 100,
+    soft_nms_sigma: Optional[float] = None,
+):
   """Generates the final detections given the model outputs.
 
   The implementation unrolls the batch dimension and process images one by one.
   It required the batch dimension to be statically known and it is TPU
   compatible.
 
   Args:
     boxes: A `tf.Tensor` with shape `[batch_size, N, num_classes, 4]` or
-      `[batch_size, N, 1, 4]` for box predictions on all feature levels. The
-      N is the number of total anchors on all levels.
+      `[batch_size, N, 1, 4]` for box predictions on all feature levels. The N
+      is the number of total anchors on all levels.
     scores: A `tf.Tensor` with shape `[batch_size, N, num_classes]`, which
       stacks class probability on all feature levels. The N is the number of
       total anchors on all levels. The num_classes is the number of classes
       predicted by the model. Note that the class_outputs here is the raw score.
     attributes: None or a dict of (attribute_name, attributes) pairs. Each
-      attributes is a `tf.Tensor` with shape
-      `[batch_size, N, num_classes, attribute_size]` or
-      `[batch_size, N, 1, attribute_size]` for attribute predictions on all
-      feature levels. The N is the number of total anchors on all levels. Can
-      be None if no attribute learning is required.
+      attributes is a `tf.Tensor` with shape `[batch_size, N, num_classes,
+      attribute_size]` or `[batch_size, N, 1, attribute_size]` for attribute
+      predictions on all feature levels. The N is the number of total anchors on
+      all levels. Can be None if no attribute learning is required.
     pre_nms_top_k: An `int` number of top candidate detections per class before
       NMS.
     pre_nms_score_threshold: A `float` representing the threshold for deciding
       when to remove boxes based on score.
     nms_iou_threshold: A `float` representing the threshold for deciding whether
       boxes overlap too much with respect to IOU.
     max_num_detections: A scalar representing maximum number of boxes retained
@@ -89,26 +93,32 @@
     valid_detections = []
     if attributes:
       nmsed_attributes = {att_name: [] for att_name in attributes.keys()}
     else:
       nmsed_attributes = {}
 
     for i in range(batch_size):
-      (nmsed_boxes_i, nmsed_scores_i, nmsed_classes_i, valid_detections_i,
-       nmsed_att_i) = _generate_detections_per_image(
-           boxes[i],
-           scores[i],
-           attributes={
-               att_name: att[i] for att_name, att in attributes.items()
-           } if attributes else {},
-           pre_nms_top_k=pre_nms_top_k,
-           pre_nms_score_threshold=pre_nms_score_threshold,
-           nms_iou_threshold=nms_iou_threshold,
-           max_num_detections=max_num_detections,
-           soft_nms_sigma=soft_nms_sigma)
+      (
+          nmsed_boxes_i,
+          nmsed_scores_i,
+          nmsed_classes_i,
+          valid_detections_i,
+          nmsed_att_i,
+      ) = _generate_detections_per_image(
+          boxes[i],
+          scores[i],
+          attributes={att_name: att[i] for att_name, att in attributes.items()}
+          if attributes
+          else {},
+          pre_nms_top_k=pre_nms_top_k,
+          pre_nms_score_threshold=pre_nms_score_threshold,
+          nms_iou_threshold=nms_iou_threshold,
+          max_num_detections=max_num_detections,
+          soft_nms_sigma=soft_nms_sigma,
+      )
       nmsed_boxes.append(nmsed_boxes_i)
       nmsed_scores.append(nmsed_scores_i)
       nmsed_classes.append(nmsed_classes_i)
       valid_detections.append(valid_detections_i)
       if attributes:
         for att_name in attributes.keys():
           nmsed_attributes[att_name].append(nmsed_att_i[att_name])
@@ -117,51 +127,58 @@
   nmsed_scores = tf.stack(nmsed_scores, axis=0)
   nmsed_classes = tf.stack(nmsed_classes, axis=0)
   valid_detections = tf.stack(valid_detections, axis=0)
   if attributes:
     for att_name in attributes.keys():
       nmsed_attributes[att_name] = tf.stack(nmsed_attributes[att_name], axis=0)
 
-  return nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections, nmsed_attributes
+  return (
+      nmsed_boxes,
+      nmsed_scores,
+      nmsed_classes,
+      valid_detections,
+      nmsed_attributes,
+  )
 
 
 def _generate_detections_per_image(
     boxes: tf.Tensor,
     scores: tf.Tensor,
     attributes: Optional[Mapping[str, tf.Tensor]] = None,
     pre_nms_top_k: int = 5000,
     pre_nms_score_threshold: float = 0.05,
     nms_iou_threshold: float = 0.5,
     max_num_detections: int = 100,
-    soft_nms_sigma: Optional[float] = None):
+    soft_nms_sigma: Optional[float] = None,
+):
   """Generates the final detections per image given the model outputs.
 
   Args:
     boxes: A  `tf.Tensor` with shape `[N, num_classes, 4]` or `[N, 1, 4]`, which
       box predictions on all feature levels. The N is the number of total
       anchors on all levels.
     scores: A `tf.Tensor` with shape `[N, num_classes]`, which stacks class
       probability on all feature levels. The N is the number of total anchors on
       all levels. The num_classes is the number of classes predicted by the
       model. Note that the class_outputs here is the raw score.
-    attributes: If not None, a dict of `tf.Tensor`. Each value is in shape
-      `[N, num_classes, attribute_size]` or `[N, 1, attribute_size]` of
-      attribute predictions on all feature levels. The N is the number of total
-      anchors on all levels.
+    attributes: If not None, a dict of `tf.Tensor`. Each value is in shape `[N,
+      num_classes, attribute_size]` or `[N, 1, attribute_size]` of attribute
+      predictions on all feature levels. The N is the number of total anchors on
+      all levels.
     pre_nms_top_k: An `int` number of top candidate detections per class before
       NMS.
     pre_nms_score_threshold: A `float` representing the threshold for deciding
       when to remove boxes based on score.
     nms_iou_threshold: A `float` representing the threshold for deciding whether
       boxes overlap too much with respect to IOU.
     max_num_detections: A `scalar` representing maximum number of boxes retained
       over all classes.
     soft_nms_sigma: A `float` representing the sigma parameter for Soft NMS.
-      When soft_nms_sigma=0.0, we fall back to standard NMS.
-      If set to None, `tf.image.non_max_suppression_padded` is called instead.
+      When soft_nms_sigma=0.0, we fall back to standard NMS. If set to None,
+      `tf.image.non_max_suppression_padded` is called instead.
 
   Returns:
     nms_boxes: A `float` tf.Tensor of shape `[max_num_detections, 4]`
       representing top detected boxes in `[y1, x1, y2, x2]`.
     nms_scores: A `float` tf.Tensor of shape `[max_num_detections]` representing
       sorted confidence scores for detected boxes. The values are between [0,
       1].
@@ -184,80 +201,99 @@
     nmsed_attributes = {}
 
   for i in range(num_classes):
     boxes_i = boxes[:, min(num_classes_for_box - 1, i)]
     scores_i = scores[:, i]
     # Obtains pre_nms_top_k before running NMS.
     scores_i, indices = tf.nn.top_k(
-        scores_i, k=tf.minimum(tf.shape(scores_i)[-1], pre_nms_top_k))
+        scores_i, k=tf.minimum(tf.shape(scores_i)[-1], pre_nms_top_k)
+    )
     boxes_i = tf.gather(boxes_i, indices)
 
     if soft_nms_sigma is not None:
-      (nmsed_indices_i,
-       nmsed_scores_i) = tf.image.non_max_suppression_with_scores(
-           tf.cast(boxes_i, tf.float32),
-           tf.cast(scores_i, tf.float32),
-           max_num_detections,
-           iou_threshold=nms_iou_threshold,
-           score_threshold=pre_nms_score_threshold,
-           soft_nms_sigma=soft_nms_sigma,
-           name='nms_detections_' + str(i))
+      (nmsed_indices_i, nmsed_scores_i) = (
+          tf.image.non_max_suppression_with_scores(
+              tf.cast(boxes_i, tf.float32),
+              tf.cast(scores_i, tf.float32),
+              max_num_detections,
+              iou_threshold=nms_iou_threshold,
+              score_threshold=pre_nms_score_threshold,
+              soft_nms_sigma=soft_nms_sigma,
+              name='nms_detections_' + str(i),
+          )
+      )
       nmsed_boxes_i = tf.gather(boxes_i, nmsed_indices_i)
       nmsed_boxes_i = preprocess_ops.clip_or_pad_to_fixed_size(
-          nmsed_boxes_i, max_num_detections, 0.0)
+          nmsed_boxes_i, max_num_detections, 0.0
+      )
       nmsed_scores_i = preprocess_ops.clip_or_pad_to_fixed_size(
-          nmsed_scores_i, max_num_detections, -1.0)
+          nmsed_scores_i, max_num_detections, -1.0
+      )
     else:
-      (nmsed_indices_i,
-       nmsed_num_valid_i) = tf.image.non_max_suppression_padded(
-           tf.cast(boxes_i, tf.float32),
-           tf.cast(scores_i, tf.float32),
-           max_num_detections,
-           iou_threshold=nms_iou_threshold,
-           score_threshold=pre_nms_score_threshold,
-           pad_to_max_output_size=True,
-           name='nms_detections_' + str(i))
+      (nmsed_indices_i, nmsed_num_valid_i) = (
+          tf.image.non_max_suppression_padded(
+              tf.cast(boxes_i, tf.float32),
+              tf.cast(scores_i, tf.float32),
+              max_num_detections,
+              iou_threshold=nms_iou_threshold,
+              score_threshold=pre_nms_score_threshold,
+              pad_to_max_output_size=True,
+              name='nms_detections_' + str(i),
+          )
+      )
       nmsed_boxes_i = tf.gather(boxes_i, nmsed_indices_i)
       nmsed_scores_i = tf.gather(scores_i, nmsed_indices_i)
       # Sets scores of invalid boxes to -1.
       nmsed_scores_i = tf.where(
           tf.less(tf.range(max_num_detections), [nmsed_num_valid_i]),
-          nmsed_scores_i, -tf.ones_like(nmsed_scores_i))
+          nmsed_scores_i,
+          -tf.ones_like(nmsed_scores_i),
+      )
 
     nmsed_classes_i = tf.fill([max_num_detections], i)
     nmsed_boxes.append(nmsed_boxes_i)
     nmsed_scores.append(nmsed_scores_i)
     nmsed_classes.append(nmsed_classes_i)
     if attributes:
       for att_name, att in attributes.items():
         num_classes_for_attr = att.get_shape().as_list()[1]
         att_i = att[:, min(num_classes_for_attr - 1, i)]
         att_i = tf.gather(att_i, indices)
         nmsed_att_i = tf.gather(att_i, nmsed_indices_i)
         nmsed_att_i = preprocess_ops.clip_or_pad_to_fixed_size(
-            nmsed_att_i, max_num_detections, 0.0)
+            nmsed_att_i, max_num_detections, 0.0
+        )
         nmsed_attributes[att_name].append(nmsed_att_i)
 
   # Concats results from all classes and sort them.
   nmsed_boxes = tf.concat(nmsed_boxes, axis=0)
   nmsed_scores = tf.concat(nmsed_scores, axis=0)
   nmsed_classes = tf.concat(nmsed_classes, axis=0)
   nmsed_scores, indices = tf.nn.top_k(
-      nmsed_scores, k=max_num_detections, sorted=True)
+      nmsed_scores, k=max_num_detections, sorted=True
+  )
   nmsed_boxes = tf.gather(nmsed_boxes, indices)
   nmsed_classes = tf.gather(nmsed_classes, indices)
   valid_detections = tf.reduce_sum(
-      tf.cast(tf.greater(nmsed_scores, -1), tf.int32))
+      tf.cast(tf.greater(nmsed_scores, -1), tf.int32)
+  )
   if attributes:
     for att_name in attributes.keys():
       nmsed_attributes[att_name] = tf.concat(nmsed_attributes[att_name], axis=0)
-      nmsed_attributes[att_name] = tf.gather(nmsed_attributes[att_name],
-                                             indices)
-
-  return nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections, nmsed_attributes
+      nmsed_attributes[att_name] = tf.gather(
+          nmsed_attributes[att_name], indices
+      )
+
+  return (
+      nmsed_boxes,
+      nmsed_scores,
+      nmsed_classes,
+      valid_detections,
+      nmsed_attributes,
+  )
 
 
 def _select_top_k_scores(scores_in: tf.Tensor, pre_nms_num_detections: int):
   """Selects top_k scores and indices for each class.
 
   Args:
     scores_in: A `tf.Tensor` with shape `[batch_size, N, num_classes]`, which
@@ -273,37 +309,153 @@
   batch_size, num_anchors, num_class = scores_in.get_shape().as_list()
   if batch_size is None:
     batch_size = tf.shape(scores_in)[0]
   scores_trans = tf.transpose(scores_in, perm=[0, 2, 1])
   scores_trans = tf.reshape(scores_trans, [-1, num_anchors])
 
   top_k_scores, top_k_indices = tf.nn.top_k(
-      scores_trans, k=pre_nms_num_detections, sorted=True)
+      scores_trans, k=pre_nms_num_detections, sorted=True
+  )
 
-  top_k_scores = tf.reshape(top_k_scores,
-                            [batch_size, num_class, pre_nms_num_detections])
-  top_k_indices = tf.reshape(top_k_indices,
-                             [batch_size, num_class, pre_nms_num_detections])
-
-  return tf.transpose(top_k_scores,
-                      [0, 2, 1]), tf.transpose(top_k_indices, [0, 2, 1])
-
-
-def _generate_detections_v2(boxes: tf.Tensor,
-                            scores: tf.Tensor,
-                            pre_nms_top_k: int = 5000,
-                            pre_nms_score_threshold: float = 0.05,
-                            nms_iou_threshold: float = 0.5,
-                            max_num_detections: int = 100):
-  """Generates the final detections given the model outputs.
+  top_k_scores = tf.reshape(
+      top_k_scores, [batch_size, num_class, pre_nms_num_detections]
+  )
+  top_k_indices = tf.reshape(
+      top_k_indices, [batch_size, num_class, pre_nms_num_detections]
+  )
+
+  return tf.transpose(top_k_scores, [0, 2, 1]), tf.transpose(
+      top_k_indices, [0, 2, 1]
+  )
 
-  This implementation unrolls classes dimension while using the tf.while_loop
-  to implement the batched NMS, so that it can be parallelized at the batch
-  dimension. It should give better performance comparing to v1 implementation.
-  It is TPU compatible.
+
+def _generate_detections_v2_class_agnostic(
+    boxes: tf.Tensor,
+    scores: tf.Tensor,
+    pre_nms_top_k: int = 5000,
+    pre_nms_score_threshold: float = 0.05,
+    nms_iou_threshold: float = 0.5,
+    max_num_detections: int = 100
+):
+  """Generates the final detections by applying class-agnostic NMS.
+
+  Args:
+    boxes: A `tf.Tensor` with shape `[batch_size, N, num_classes, 4]` or
+      `[batch_size, N, 1, 4]`, which box predictions on all feature levels. The
+      N is the number of total anchors on all levels.
+    scores: A `tf.Tensor` with shape `[batch_size, N, num_classes]`, which
+      stacks class probability on all feature levels. The N is the number of
+      total anchors on all levels. The num_classes is the number of classes
+      predicted by the model. Note that the class_outputs here is the raw score.
+    pre_nms_top_k: An `int` number of top candidate detections per class before
+      NMS.
+    pre_nms_score_threshold: A `float` representing the threshold for deciding
+      when to remove boxes based on score.
+    nms_iou_threshold: A `float` representing the threshold for deciding whether
+      boxes overlap too much with respect to IOU.
+    max_num_detections: A `scalar` representing maximum number of boxes retained
+      over all classes.
+
+  Returns:
+    nms_boxes: A `float` tf.Tensor of shape [batch_size, max_num_detections, 4]
+      representing top detected boxes in [y1, x1, y2, x2].
+    nms_scores: A `float` tf.Tensor of shape [batch_size, max_num_detections]
+      representing sorted confidence scores for detected boxes. The values are
+      between [0, 1].
+    nms_classes: An `int` tf.Tensor of shape [batch_size, max_num_detections]
+      representing classes for detected boxes.
+    valid_detections: An `int` tf.Tensor of shape [batch_size] only the top
+      `valid_detections` boxes are valid detections.
+  """
+  with tf.name_scope('generate_detections_class_agnostic'):
+    nmsed_boxes = []
+    nmsed_classes = []
+    nmsed_scores = []
+    valid_detections = []
+    batch_size, _, num_classes_for_box, _ = boxes.get_shape().as_list()
+    if batch_size is None:
+      batch_size = tf.shape(boxes)[0]
+    _, total_anchors, _ = scores.get_shape().as_list()
+
+    # Keeps only the class with highest score for each predicted box.
+    scores_condensed, classes_ids = tf.nn.top_k(
+        scores, k=1, sorted=True
+    )
+    scores_condensed = tf.squeeze(scores_condensed, axis=[2])
+    if num_classes_for_box > 1:
+      boxes = tf.gather(boxes, classes_ids, axis=2, batch_dims=2)
+    boxes_condensed = tf.squeeze(boxes, axis=[2])
+    classes_condensed = tf.squeeze(classes_ids, axis=[2])
+
+    # Selects top pre_nms_num scores and indices before NMS.
+    num_anchors_filtered = min(total_anchors, pre_nms_top_k)
+    scores_filtered, indices_filtered = tf.nn.top_k(
+        scores_condensed, k=num_anchors_filtered, sorted=True
+    )
+    classes_filtered = tf.gather(
+        classes_condensed, indices_filtered, axis=1, batch_dims=1
+    )
+    boxes_filtered = tf.gather(
+        boxes_condensed, indices_filtered, axis=1, batch_dims=1
+    )
+
+    tf.ensure_shape(boxes_filtered, [None, num_anchors_filtered, 4])
+    tf.ensure_shape(classes_filtered, [None, num_anchors_filtered])
+    tf.ensure_shape(scores_filtered, [None, num_anchors_filtered])
+    boxes_filtered = tf.cast(
+        boxes_filtered, tf.float32
+    )
+    scores_filtered = tf.cast(
+        scores_filtered, tf.float32
+    )
+    # Apply class-agnostic NMS on boxes.
+    (nmsed_indices_padded, valid_detections) = (
+        tf.image.non_max_suppression_padded(
+            boxes=boxes_filtered,
+            scores=scores_filtered,
+            max_output_size=max_num_detections,
+            iou_threshold=nms_iou_threshold,
+            pad_to_max_output_size=True,
+            score_threshold=pre_nms_score_threshold,
+            sorted_input=True,
+            name='nms_detections'
+        )
+    )
+    nmsed_boxes = tf.gather(
+        boxes_filtered, nmsed_indices_padded, batch_dims=1, axis=1
+    )
+    nmsed_scores = tf.gather(
+        scores_filtered, nmsed_indices_padded, batch_dims=1, axis=1
+    )
+    nmsed_classes = tf.gather(
+        classes_filtered, nmsed_indices_padded, batch_dims=1, axis=1
+    )
+
+    # Sets the padded boxes, scores, and classes to 0.
+    padding_mask = tf.reshape(
+        tf.range(max_num_detections), [1, -1]
+    ) < tf.reshape(valid_detections, [-1, 1])
+    nmsed_boxes = nmsed_boxes * tf.cast(
+        tf.expand_dims(padding_mask, axis=2), nmsed_boxes.dtype
+    )
+    nmsed_scores = nmsed_scores * tf.cast(padding_mask, nmsed_scores.dtype)
+    nmsed_classes = nmsed_classes * tf.cast(padding_mask, nmsed_classes.dtype)
+
+  return nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections
+
+
+def _generate_detections_v2_class_aware(
+    boxes: tf.Tensor,
+    scores: tf.Tensor,
+    pre_nms_top_k: int = 5000,
+    pre_nms_score_threshold: float = 0.05,
+    nms_iou_threshold: float = 0.5,
+    max_num_detections: int = 100,
+):
+  """Generates the final detections by using class-aware NMS.
 
   Args:
     boxes: A `tf.Tensor` with shape `[batch_size, N, num_classes, 4]` or
       `[batch_size, N, 1, 4]`, which box predictions on all feature levels. The
       N is the number of total anchors on all levels.
     scores: A `tf.Tensor` with shape `[batch_size, N, num_classes]`, which
       stacks class probability on all feature levels. The N is the number of
@@ -336,50 +488,221 @@
     valid_detections = []
     batch_size, _, num_classes_for_box, _ = boxes.get_shape().as_list()
     if batch_size is None:
       batch_size = tf.shape(boxes)[0]
     _, total_anchors, num_classes = scores.get_shape().as_list()
     # Selects top pre_nms_num scores and indices before NMS.
     scores, indices = _select_top_k_scores(
-        scores, min(total_anchors, pre_nms_top_k))
+        scores, min(total_anchors, pre_nms_top_k)
+    )
     for i in range(num_classes):
       boxes_i = boxes[:, :, min(num_classes_for_box - 1, i), :]
       scores_i = scores[:, :, i]
       # Obtains pre_nms_top_k before running NMS.
       boxes_i = tf.gather(boxes_i, indices[:, :, i], batch_dims=1, axis=1)
 
       # Filter out scores.
       boxes_i, scores_i = box_ops.filter_boxes_by_scores(
-          boxes_i, scores_i, min_score_threshold=pre_nms_score_threshold)
+          boxes_i, scores_i, min_score_threshold=pre_nms_score_threshold
+      )
 
       (nmsed_scores_i, nmsed_boxes_i) = nms.sorted_non_max_suppression_padded(
           tf.cast(scores_i, tf.float32),
           tf.cast(boxes_i, tf.float32),
           max_num_detections,
-          iou_threshold=nms_iou_threshold)
+          iou_threshold=nms_iou_threshold,
+      )
       nmsed_classes_i = tf.fill([batch_size, max_num_detections], i)
       nmsed_boxes.append(nmsed_boxes_i)
       nmsed_scores.append(nmsed_scores_i)
       nmsed_classes.append(nmsed_classes_i)
   nmsed_boxes = tf.concat(nmsed_boxes, axis=1)
   nmsed_scores = tf.concat(nmsed_scores, axis=1)
   nmsed_classes = tf.concat(nmsed_classes, axis=1)
   nmsed_scores, indices = tf.nn.top_k(
-      nmsed_scores, k=max_num_detections, sorted=True)
+      nmsed_scores, k=max_num_detections, sorted=True
+  )
   nmsed_boxes = tf.gather(nmsed_boxes, indices, batch_dims=1, axis=1)
   nmsed_classes = tf.gather(nmsed_classes, indices, batch_dims=1)
   valid_detections = tf.reduce_sum(
-      input_tensor=tf.cast(tf.greater(nmsed_scores, 0.0), tf.int32), axis=1)
+      input_tensor=tf.cast(tf.greater(nmsed_scores, 0.0), tf.int32), axis=1
+  )
   return nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections
 
 
-def _generate_detections_batched(boxes: tf.Tensor, scores: tf.Tensor,
-                                 pre_nms_score_threshold: float,
-                                 nms_iou_threshold: float,
-                                 max_num_detections: int):
+def _generate_detections_v2(
+    boxes: tf.Tensor,
+    scores: tf.Tensor,
+    pre_nms_top_k: int = 5000,
+    pre_nms_score_threshold: float = 0.05,
+    nms_iou_threshold: float = 0.5,
+    max_num_detections: int = 100,
+    use_class_agnostic_nms: Optional[bool] = None,
+):
+  """Generates the final detections given the model outputs.
+
+  This implementation unrolls classes dimension while using the tf.while_loop
+  to implement the batched NMS, so that it can be parallelized at the batch
+  dimension. It should give better performance comparing to v1 implementation.
+  It is TPU compatible.
+
+  Args:
+    boxes: A `tf.Tensor` with shape `[batch_size, N, num_classes, 4]` or
+      `[batch_size, N, 1, 4]`, which box predictions on all feature levels. The
+      N is the number of total anchors on all levels.
+    scores: A `tf.Tensor` with shape `[batch_size, N, num_classes]`, which
+      stacks class probability on all feature levels. The N is the number of
+      total anchors on all levels. The num_classes is the number of classes
+      predicted by the model. Note that the class_outputs here is the raw score.
+    pre_nms_top_k: An `int` number of top candidate detections per class before
+      NMS.
+    pre_nms_score_threshold: A `float` representing the threshold for deciding
+      when to remove boxes based on score.
+    nms_iou_threshold: A `float` representing the threshold for deciding whether
+      boxes overlap too much with respect to IOU.
+    max_num_detections: A `scalar` representing maximum number of boxes retained
+      over all classes.
+    use_class_agnostic_nms: A `bool` of whether non max suppression is operated
+      on all the boxes using max scores across all classes.
+
+  Returns:
+    nms_boxes: A `float` tf.Tensor of shape [batch_size, max_num_detections, 4]
+      representing top detected boxes in [y1, x1, y2, x2].
+    nms_scores: A `float` tf.Tensor of shape [batch_size, max_num_detections]
+      representing sorted confidence scores for detected boxes. The values are
+      between [0, 1].
+    nms_classes: An `int` tf.Tensor of shape [batch_size, max_num_detections]
+      representing classes for detected boxes.
+    valid_detections: An `int` tf.Tensor of shape [batch_size] only the top
+      `valid_detections` boxes are valid detections.
+  """
+  if use_class_agnostic_nms:
+    return _generate_detections_v2_class_agnostic(
+        boxes=boxes,
+        scores=scores,
+        pre_nms_top_k=pre_nms_top_k,
+        pre_nms_score_threshold=pre_nms_score_threshold,
+        nms_iou_threshold=nms_iou_threshold,
+        max_num_detections=max_num_detections,
+    )
+
+  return _generate_detections_v2_class_aware(
+      boxes=boxes,
+      scores=scores,
+      pre_nms_top_k=pre_nms_top_k,
+      pre_nms_score_threshold=pre_nms_score_threshold,
+      nms_iou_threshold=nms_iou_threshold,
+      max_num_detections=max_num_detections,
+  )
+
+
+def _generate_detections_v3(
+    boxes: tf.Tensor,
+    scores: tf.Tensor,
+    pre_nms_score_threshold: float = 0.05,
+    nms_iou_threshold: float = 0.5,
+    max_num_detections: int = 100,
+    refinements: int = 2,
+) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:
+  """Generates the detections given the model outputs using NMS for EdgeTPU.
+
+  Args:
+    boxes: A `tf.Tensor` with shape `[batch_size, num_classes, N, 4]` or
+      `[batch_size, 1, N, 4]`, which box predictions on all feature levels. The
+      N is the number of total anchors on all levels.
+    scores: A `tf.Tensor` with shape `[batch_size, num_classes, N]`, which
+      stacks class probability on all feature levels. The N is the number of
+      total anchors on all levels. The num_classes is the number of classes
+      predicted by the model. Note that the class_outputs here is the raw score.
+    pre_nms_score_threshold: A `float` representing the threshold for deciding
+      when to remove boxes based on score.
+    nms_iou_threshold: A `float` representing the threshold for deciding whether
+      boxes overlap too much with respect to IOU.
+    max_num_detections: A `scalar` representing maximum number of boxes retained
+      over all classes.
+    refinements: Quality parameter for NMS algorithm.
+
+  Returns:
+    nms_boxes: A `float` tf.Tensor of shape [batch_size, max_num_detections, 4]
+      representing top detected boxes in [y1, x1, y2, x2].
+    nms_scores: A `float` tf.Tensor of shape [batch_size, max_num_detections]
+      representing sorted confidence scores for detected boxes. The values are
+      between [0, 1].
+    nms_classes: An `int` tf.Tensor of shape [batch_size, max_num_detections]
+      representing classes for detected boxes.
+    valid_detections: An `int` tf.Tensor of shape [batch_size] only the top
+      `valid_detections` boxes are valid detections.
+
+  Raises:
+    ValueError if inputs shapes are not valid.
+  """
+  one = tf.constant(1, dtype=scores.dtype)
+  with tf.name_scope('generate_detections'):
+    batch_size, num_box_classes, box_locations, sides = (
+        boxes.get_shape().as_list()
+    )
+    if batch_size is None:
+      batch_size = tf.shape(boxes)[0]
+    _, num_classes, locations = scores.get_shape().as_list()
+    if num_box_classes != 1 and num_box_classes != num_classes:
+      raise ValueError('Boxes should have either 1 class or same as scores.')
+    if locations != box_locations:
+      raise ValueError('Number of locations is different.')
+    if sides != 4:
+      raise ValueError('Number of sides is incorrect.')
+    # Selects pre_nms_score_threshold scores before NMS.
+    boxes, scores = box_ops.filter_boxes_by_scores(
+        boxes, scores, min_score_threshold=pre_nms_score_threshold
+    )
+
+    # EdgeTPU-friendly class-wise NMS, -1 for invalid.
+    indices = edgetpu.non_max_suppression_padded(
+        boxes,
+        scores,
+        max_num_detections,
+        iou_threshold=nms_iou_threshold,
+        refinements=refinements,
+    )
+    # Gather NMS-ed boxes and scores.
+    safe_indices = tf.nn.relu(indices)  # 0 for invalid
+    invalid_detections = safe_indices - indices  # 1 for invalid, 0 for valid
+    valid_detections = one - invalid_detections  # 0 for invalid, 1 for valid
+    safe_indices = tf.cast(safe_indices, tf.int32)
+    boxes = tf.gather(boxes, safe_indices, axis=2, batch_dims=2)
+    boxes = tf.cast(tf.expand_dims(valid_detections, -1), boxes.dtype) * boxes
+    scores = valid_detections * tf.gather(
+        scores, safe_indices, axis=2, batch_dims=2
+    )
+    # Compliment with class numbers.
+    classes = tf.constant(np.arange(num_classes), dtype=scores.dtype)
+    classes = tf.reshape(classes, [1, num_classes, 1])
+    classes = tf.tile(classes, [batch_size, 1, max_num_detections])
+    # Flatten classes, locations. Class = -1 for invalid detection
+    scores = tf.reshape(scores, [batch_size, num_classes * max_num_detections])
+    boxes = tf.reshape(boxes, [batch_size, num_classes * max_num_detections, 4])
+    classes = tf.reshape(
+        valid_detections * classes - invalid_detections,
+        [batch_size, num_classes * max_num_detections],
+    )
+    # Filter top-k across boxes of all classes
+    scores, indices = tf.nn.top_k(scores, k=max_num_detections, sorted=True)
+    boxes = tf.gather(boxes, indices, batch_dims=1, axis=1)
+    classes = tf.gather(classes, indices, batch_dims=1, axis=1)
+    invalid_detections = tf.nn.relu(classes) - classes
+    valid_detections = tf.reduce_sum(one - invalid_detections, axis=1)
+    return boxes, scores, classes, valid_detections
+
+
+def _generate_detections_batched(
+    boxes: tf.Tensor,
+    scores: tf.Tensor,
+    pre_nms_score_threshold: float,
+    nms_iou_threshold: float,
+    max_num_detections: int,
+):
   """Generates detected boxes with scores and classes for one-stage detector.
 
   The function takes output of multi-level ConvNets and anchor boxes and
   generates detected boxes. Note that this used batched nms, which is not
   supported on TPU currently.
 
   Args:
@@ -414,62 +737,69 @@
             boxes,
             scores,
             max_output_size_per_class=max_num_detections,
             max_total_size=max_num_detections,
             iou_threshold=nms_iou_threshold,
             score_threshold=pre_nms_score_threshold,
             pad_per_class=False,
-            clip_boxes=False))
+            clip_boxes=False,
+        )
+    )
     nmsed_classes = tf.cast(nmsed_classes, tf.int32)
   return nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections
 
 
 def _generate_detections_tflite_implements_signature(
-    config: Dict[str, Any]) -> str:
+    config: Dict[str, Any]
+) -> str:
   """Returns `experimental_implements` signature for TFLite's custom NMS op.
 
   This signature encodes the arguments to correctly initialize TFLite's custom
   post-processing op in the MLIR converter.
   For details on `experimental_implements` see here:
   https://www.tensorflow.org/api_docs/python/tf/function
 
   Args:
     config: A dictionary of configs defining parameters for TFLite NMS op.
 
   Returns:
     An `experimental_implements` signature string.
   """
-  scale_value = 1.0
 
   implements_signature = [
       'name: "%s"' % 'TFLite_Detection_PostProcess',
-      'attr { key: "max_detections" value { i: %d } }' %
-      config['max_detections'],
-      'attr { key: "max_classes_per_detection" value { i: %d } }' %
-      config['max_classes_per_detection'],
-      'attr { key: "use_regular_nms" value { b: %s } }' %
-      str(config['use_regular_nms']).lower(),
-      'attr { key: "nms_score_threshold" value { f: %f } }' %
-      config['nms_score_threshold'],
-      'attr { key: "nms_iou_threshold" value { f: %f } }' %
-      config['nms_iou_threshold'],
-      'attr { key: "y_scale" value { f: %f } }' % scale_value,
-      'attr { key: "x_scale" value { f: %f } }' % scale_value,
-      'attr { key: "h_scale" value { f: %f } }' % scale_value,
-      'attr { key: "w_scale" value { f: %f } }' % scale_value,
-      'attr { key: "num_classes" value { i: %d } }' % config['num_classes']
+      'attr { key: "max_detections" value { i: %d } }'
+      % config['max_detections'],
+      'attr { key: "max_classes_per_detection" value { i: %d } }'
+      % config['max_classes_per_detection'],
+      'attr { key: "detections_per_class" value { i: %d } }'
+      % config.get('detections_per_class', 5),
+      'attr { key: "use_regular_nms" value { b: %s } }'
+      % str(config['use_regular_nms']).lower(),
+      'attr { key: "nms_score_threshold" value { f: %f } }'
+      % config['nms_score_threshold'],
+      'attr { key: "nms_iou_threshold" value { f: %f } }'
+      % config['nms_iou_threshold'],
+      'attr { key: "y_scale" value { f: %f } }' % config.get('y_scale', 1.0),
+      'attr { key: "x_scale" value { f: %f } }' % config.get('x_scale', 1.0),
+      'attr { key: "h_scale" value { f: %f } }' % config.get('h_scale', 1.0),
+      'attr { key: "w_scale" value { f: %f } }' % config.get('w_scale', 1.0),
+      'attr { key: "num_classes" value { i: %d } }' % config['num_classes'],
   ]
   implements_signature = ' '.join(implements_signature)
   return implements_signature
 
 
-def _generate_detections_tflite(raw_boxes: Mapping[str, tf.Tensor],
-                                raw_scores: Mapping[str, tf.Tensor],
-                                anchor_boxes: Mapping[str, tf.Tensor],
-                                config: Dict[str, Any]) -> Sequence[Any]:
+def _generate_detections_tflite(
+    raw_boxes: Mapping[str, tf.Tensor],
+    raw_scores: Mapping[str, tf.Tensor],
+    anchor_boxes: Mapping[str, tf.Tensor],
+    config: Dict[str, Any],
+    box_coder_weights: List[float] | None = None,
+) -> Sequence[Any]:
   """Generate detections for conversion to TFLite.
 
   Mathematically same as class-agnostic NMS, except that the last portion of
   the TF graph constitutes a dummy `tf.function` that contains an annotation
   for conversion to TFLite's custom NMS op. Using this custom op allows
   features like post-training quantization & accelerator support.
   NOTE: This function does NOT return a valid output, and is only meant to
@@ -484,129 +814,169 @@
     raw_scores: A dictionary of tensors for classes. Key is level of features
       and value is a tensor denoting a level of logits with shape [1, H, W,
       num_class * num_anchors].
     anchor_boxes: A dictionary of tensors for anchor boxes. Key is level of
       features and value is a tensor denoting a level of anchors with shape
       [num_anchors, 4].
     config: A dictionary of configs defining parameters for TFLite NMS op.
-
+    box_coder_weights: An optional `list` of 4 positive floats to scale y, x, h,
+      and w when encoding box coordinates. If set to None, does not perform
+      scaling. For Faster RCNN, the open-source implementation recommends using
+      [10.0, 10.0, 5.0, 5.0].
   Returns:
     A (dummy) tuple of (boxes, scores, classess, num_detections).
 
   Raises:
     ValueError: If the last dimension of predicted boxes is not divisible by 4,
       or the last dimension of predicted scores is not divisible by number of
       anchors per location.
   """
   scores, boxes, anchors = [], [], []
   levels = list(raw_scores.keys())
   min_level = int(min(levels))
   max_level = int(max(levels))
   batch_size = tf.shape(raw_scores[str(min_level)])[0]
 
-  num_anchors_per_locations_times_4 = raw_boxes[str(
-      min_level)].get_shape().as_list()[-1]
+  num_anchors_per_locations_times_4 = (
+      raw_boxes[str(min_level)].get_shape().as_list()[-1]
+  )
   if num_anchors_per_locations_times_4 % 4 != 0:
     raise ValueError(
-        'The last dimension of predicted boxes should be divisible by 4.')
+        'The last dimension of predicted boxes should be divisible by 4.'
+    )
+
   num_anchors_per_locations = num_anchors_per_locations_times_4 // 4
-  if num_anchors_per_locations_times_4 % 4 != 0:
+  num_classes_times_anchors_per_location = (
+      raw_scores[str(min_level)].get_shape().as_list()[-1]
+  )
+  if num_classes_times_anchors_per_location % num_anchors_per_locations != 0:
     raise ValueError(
-        f'The last dimension of predicted scores should be divisible by {num_anchors_per_locations}.'
+        'The last dimension of predicted scores should be divisible by'
+        f' {num_anchors_per_locations}.'
     )
-  num_classes = raw_scores[str(
-      min_level)].get_shape().as_list()[-1] // num_anchors_per_locations
+  num_classes = (
+      num_classes_times_anchors_per_location // num_anchors_per_locations
+  )
   config.update({'num_classes': num_classes})
 
   for i in range(min_level, max_level + 1):
-    scores.append(
-        tf.sigmoid(
-            tf.reshape(raw_scores[str(i)], [batch_size, -1, num_classes])))
+    scores.append(tf.reshape(raw_scores[str(i)], [batch_size, -1, num_classes]))
     boxes.append(tf.reshape(raw_boxes[str(i)], [batch_size, -1, 4]))
     anchors.append(tf.reshape(anchor_boxes[str(i)], [-1, 4]))
-  scores = tf.concat(scores, 1)
+  scores = tf.sigmoid(tf.concat(scores, 1))
   boxes = tf.concat(boxes, 1)
   anchors = tf.concat(anchors, 0)
 
   ycenter_a = (anchors[..., 0] + anchors[..., 2]) / 2
   xcenter_a = (anchors[..., 1] + anchors[..., 3]) / 2
   ha = anchors[..., 2] - anchors[..., 0]
   wa = anchors[..., 3] - anchors[..., 1]
   anchors = tf.stack([ycenter_a, xcenter_a, ha, wa], axis=-1)
 
+  if box_coder_weights:
+    config.update({
+        'y_scale': box_coder_weights[0],
+        'x_scale': box_coder_weights[1],
+        'h_scale': box_coder_weights[2],
+        'w_scale': box_coder_weights[3],
+    })
+
+  if config.get('normalize_anchor_coordinates', False):
+    # TFLite's object detection APIs require normalized anchors.
+    height, width = config['input_image_size']
+    normalize_factor = tf.constant(
+        [height, width, height, width], dtype=tf.float32
+    )
+    anchors = anchors / normalize_factor
+
   # There is no TF equivalent for TFLite's custom post-processing op.
   # So we add an 'empty' composite function here, that is legalized to the
   # custom op with MLIR.
   # For details, see: tensorflow/compiler/mlir/lite/utils/nms_utils.cc
   @tf.function(
       experimental_implements=_generate_detections_tflite_implements_signature(
-          config))
+          config
+      )
+  )
   # pylint: disable=g-unused-argument,unused-argument
   def dummy_post_processing(input_boxes, input_scores, input_anchors):
     boxes = tf.constant(0.0, dtype=tf.float32, name='boxes')
     scores = tf.constant(0.0, dtype=tf.float32, name='scores')
     classes = tf.constant(0.0, dtype=tf.float32, name='classes')
     num_detections = tf.constant(0.0, dtype=tf.float32, name='num_detections')
     return boxes, classes, scores, num_detections
 
+  if config.get('omit_nms', False):
+    dummy_classes = tf.constant(0.0, dtype=tf.float32, name='classes')
+    dummy_num_detections = tf.constant(
+        0.0, dtype=tf.float32, name='num_detections')
+    return boxes, dummy_classes, scores, dummy_num_detections
   return dummy_post_processing(boxes, scores, anchors)[::-1]
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class DetectionGenerator(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class DetectionGenerator(tf_keras.layers.Layer):
   """Generates the final detected boxes with scores and classes."""
 
-  def __init__(self,
-               apply_nms: bool = True,
-               pre_nms_top_k: int = 5000,
-               pre_nms_score_threshold: float = 0.05,
-               nms_iou_threshold: float = 0.5,
-               max_num_detections: int = 100,
-               nms_version: str = 'v2',
-               use_cpu_nms: bool = False,
-               soft_nms_sigma: Optional[float] = None,
-               **kwargs):
+  def __init__(
+      self,
+      apply_nms: bool = True,
+      pre_nms_top_k: int = 5000,
+      pre_nms_score_threshold: float = 0.05,
+      nms_iou_threshold: float = 0.5,
+      max_num_detections: int = 100,
+      nms_version: str = 'v2',
+      use_cpu_nms: bool = False,
+      soft_nms_sigma: Optional[float] = None,
+      use_sigmoid_probability: bool = False,
+      **kwargs,
+  ):
     """Initializes a detection generator.
 
     Args:
-      apply_nms: A `bool` of whether or not apply non maximum suppression.
-        If False, the decoded boxes and their scores are returned.
+      apply_nms: A `bool` of whether or not apply non maximum suppression. If
+        False, the decoded boxes and their scores are returned.
       pre_nms_top_k: An `int` of the number of top scores proposals to be kept
         before applying NMS.
       pre_nms_score_threshold: A `float` of the score threshold to apply before
         applying  NMS. Proposals whose scores are below this threshold are
         thrown away.
       nms_iou_threshold: A `float` in [0, 1], the NMS IoU threshold.
       max_num_detections: An `int` of the final number of total detections to
         generate.
       nms_version: A string of `batched`, `v1` or `v2` specifies NMS version.
       use_cpu_nms: A `bool` of whether or not enforce NMS to run on CPU.
       soft_nms_sigma: A `float` representing the sigma parameter for Soft NMS.
         When soft_nms_sigma=0.0, we fall back to standard NMS.
+      use_sigmoid_probability: A `bool`, if true, use sigmoid to get
+        probability, otherwise use softmax.
       **kwargs: Additional keyword arguments passed to Layer.
     """
     self._config_dict = {
         'apply_nms': apply_nms,
         'pre_nms_top_k': pre_nms_top_k,
         'pre_nms_score_threshold': pre_nms_score_threshold,
         'nms_iou_threshold': nms_iou_threshold,
         'max_num_detections': max_num_detections,
         'nms_version': nms_version,
         'use_cpu_nms': use_cpu_nms,
         'soft_nms_sigma': soft_nms_sigma,
+        'use_sigmoid_probability': use_sigmoid_probability,
     }
     super(DetectionGenerator, self).__init__(**kwargs)
 
-  def __call__(self,
-               raw_boxes: tf.Tensor,
-               raw_scores: tf.Tensor,
-               anchor_boxes: tf.Tensor,
-               image_shape: tf.Tensor,
-               regression_weights: Optional[List[float]] = None,
-               bbox_per_class: bool = True):
+  def __call__(
+      self,
+      raw_boxes: tf.Tensor,
+      raw_scores: tf.Tensor,
+      anchor_boxes: tf.Tensor,
+      image_shape: tf.Tensor,
+      regression_weights: Optional[List[float]] = None,
+      bbox_per_class: bool = True,
+  ):
     """Generates final detections.
 
     Args:
       raw_boxes: A `tf.Tensor` of shape of `[batch_size, K, num_classes * 4]`
         representing the class-specific box coordinates relative to anchors.
       raw_scores: A `tf.Tensor` of shape of `[batch_size, K, num_classes]`
         representing the class logits before applying score activiation.
@@ -632,46 +1002,55 @@
           `num_detections` boxes are valid detections
       If `apply_nms` = False, the return is a dictionary with keys:
         `decoded_boxes`: A `float` tf.Tensor of shape [batch, num_raw_boxes, 4]
           representing all the decoded boxes.
         `decoded_box_scores`: A `float` tf.Tensor of shape
           [batch, num_raw_boxes] representing socres of all the decoded boxes.
     """
-    box_scores = tf.nn.softmax(raw_scores, axis=-1)
+    if self._config_dict['use_sigmoid_probability']:
+      box_scores = tf.math.sigmoid(raw_scores)
+    else:
+      box_scores = tf.nn.softmax(raw_scores, axis=-1)
 
     # Removes the background class.
     box_scores_shape = tf.shape(box_scores)
     box_scores_shape_list = box_scores.get_shape().as_list()
     batch_size = box_scores_shape[0]
     num_locations = box_scores_shape_list[1]
     num_classes = box_scores_shape_list[-1]
 
     box_scores = tf.slice(box_scores, [0, 0, 1], [-1, -1, -1])
 
     if bbox_per_class:
       num_detections = num_locations * (num_classes - 1)
-      raw_boxes = tf.reshape(raw_boxes,
-                             [batch_size, num_locations, num_classes, 4])
+      raw_boxes = tf.reshape(
+          raw_boxes, [batch_size, num_locations, num_classes, 4]
+      )
       raw_boxes = tf.slice(raw_boxes, [0, 0, 1, 0], [-1, -1, -1, -1])
       anchor_boxes = tf.tile(
-          tf.expand_dims(anchor_boxes, axis=2), [1, 1, num_classes - 1, 1])
+          tf.expand_dims(anchor_boxes, axis=2), [1, 1, num_classes - 1, 1]
+      )
       raw_boxes = tf.reshape(raw_boxes, [batch_size, num_detections, 4])
       anchor_boxes = tf.reshape(anchor_boxes, [batch_size, num_detections, 4])
 
     # Box decoding.
     decoded_boxes = box_ops.decode_boxes(
-        raw_boxes, anchor_boxes, weights=regression_weights)
+        raw_boxes, anchor_boxes, weights=regression_weights
+    )
 
-    # Box clipping
-    decoded_boxes = box_ops.clip_boxes(
-        decoded_boxes, tf.expand_dims(image_shape, axis=1))
+    # Box clipping.
+    if image_shape is not None:
+      decoded_boxes = box_ops.clip_boxes(
+          decoded_boxes, tf.expand_dims(image_shape, axis=1)
+      )
 
     if bbox_per_class:
       decoded_boxes = tf.reshape(
-          decoded_boxes, [batch_size, num_locations, num_classes - 1, 4])
+          decoded_boxes, [batch_size, num_locations, num_classes - 1, 4]
+      )
     else:
       decoded_boxes = tf.expand_dims(decoded_boxes, axis=2)
 
     if not self._config_dict['apply_nms']:
       return {
           'decoded_boxes': decoded_boxes,
           'decoded_box_scores': box_scores,
@@ -683,42 +1062,54 @@
     else:
       nms_context = contextlib.nullcontext()
 
     with nms_context:
       if self._config_dict['nms_version'] == 'batched':
         (nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections) = (
             _generate_detections_batched(
-                decoded_boxes, box_scores,
+                decoded_boxes,
+                box_scores,
                 self._config_dict['pre_nms_score_threshold'],
                 self._config_dict['nms_iou_threshold'],
-                self._config_dict['max_num_detections']))
+                self._config_dict['max_num_detections'],
+            )
+        )
       elif self._config_dict['nms_version'] == 'v1':
         (nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections, _) = (
             _generate_detections_v1(
                 decoded_boxes,
                 box_scores,
                 pre_nms_top_k=self._config_dict['pre_nms_top_k'],
-                pre_nms_score_threshold=self
-                ._config_dict['pre_nms_score_threshold'],
+                pre_nms_score_threshold=self._config_dict[
+                    'pre_nms_score_threshold'
+                ],
                 nms_iou_threshold=self._config_dict['nms_iou_threshold'],
                 max_num_detections=self._config_dict['max_num_detections'],
-                soft_nms_sigma=self._config_dict['soft_nms_sigma']))
+                soft_nms_sigma=self._config_dict['soft_nms_sigma'],
+            )
+        )
       elif self._config_dict['nms_version'] == 'v2':
         (nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections) = (
             _generate_detections_v2(
                 decoded_boxes,
                 box_scores,
                 pre_nms_top_k=self._config_dict['pre_nms_top_k'],
-                pre_nms_score_threshold=self
-                ._config_dict['pre_nms_score_threshold'],
+                pre_nms_score_threshold=self._config_dict[
+                    'pre_nms_score_threshold'
+                ],
                 nms_iou_threshold=self._config_dict['nms_iou_threshold'],
-                max_num_detections=self._config_dict['max_num_detections']))
+                max_num_detections=self._config_dict['max_num_detections'],
+            )
+        )
       else:
-        raise ValueError('NMS version {} not supported.'.format(
-            self._config_dict['nms_version']))
+        raise ValueError(
+            'NMS version {} not supported.'.format(
+                self._config_dict['nms_version']
+            )
+        )
 
     # Adds 1 to offset the background class which has index 0.
     nmsed_classes += 1
 
     return {
         'num_detections': valid_detections,
         'detection_boxes': nmsed_boxes,
@@ -730,29 +1121,36 @@
     return self._config_dict
 
   @classmethod
   def from_config(cls, config):
     return cls(**config)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MultilevelDetectionGenerator(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MultilevelDetectionGenerator(tf_keras.layers.Layer):
   """Generates detected boxes with scores and classes for one-stage detector."""
 
-  def __init__(self,
-               apply_nms: bool = True,
-               pre_nms_top_k: int = 5000,
-               pre_nms_score_threshold: float = 0.05,
-               nms_iou_threshold: float = 0.5,
-               max_num_detections: int = 100,
-               nms_version: str = 'v1',
-               use_cpu_nms: bool = False,
-               soft_nms_sigma: Optional[float] = None,
-               tflite_post_processing_config: Optional[Dict[str, Any]] = None,
-               **kwargs):
+  def __init__(
+      self,
+      apply_nms: bool = True,
+      pre_nms_top_k: int = 5000,
+      pre_nms_score_threshold: float = 0.05,
+      nms_iou_threshold: float = 0.5,
+      max_num_detections: int = 100,
+      nms_version: str = 'v1',
+      use_cpu_nms: bool = False,
+      soft_nms_sigma: Optional[float] = None,
+      tflite_post_processing_config: Optional[Dict[str, Any]] = None,
+      pre_nms_top_k_sharding_block: Optional[int] = None,
+      nms_v3_refinements: Optional[int] = None,
+      return_decoded: Optional[bool] = None,
+      use_class_agnostic_nms: Optional[bool] = None,
+      box_coder_weights: Optional[List[float]] = None,
+      **kwargs,
+  ):
     """Initializes a multi-level detection generator.
 
     Args:
       apply_nms: A `bool` of whether or not apply non maximum suppression. If
         False, the decoded boxes and their scores are returned.
       pre_nms_top_k: An `int` of the number of top scores proposals to be kept
         before applying NMS.
@@ -764,40 +1162,79 @@
         generate.
       nms_version: A string of `batched`, `v1` or `v2` specifies NMS version
       use_cpu_nms: A `bool` of whether or not enforce NMS to run on CPU.
       soft_nms_sigma: A `float` representing the sigma parameter for Soft NMS.
         When soft_nms_sigma=0.0, we fall back to standard NMS.
       tflite_post_processing_config: An optional dictionary containing
         post-processing parameters used for TFLite custom NMS op.
-
+      pre_nms_top_k_sharding_block: For v3 (edge tpu friendly) NMS, avoids
+        creating long axis for pre_nms_top_k. Will do top_k in shards of size
+        [num_classes, pre_nms_top_k_sharding_block * boxes_per_location]
+      nms_v3_refinements: For v3 (edge tpu friendly) NMS, sets how close result
+        should be to standard NMS. When None, 2 is used. Here is some
+        experimental deviations for different refinement values:
+        if == 0, AP is reduced 1.0%, AR is reduced 5% on COCO
+        if == 1, AP is reduced 0.2%, AR is reduced 2% on COCO
+        if == 2, AP is reduced <0.1%, AR is reduced <1% on COCO
+      return_decoded: A `bool` of whether to return decoded boxes before NMS
+        regardless of whether `apply_nms` is True or not.
+      use_class_agnostic_nms: A `bool` of whether non max suppression is
+        operated on all the boxes using max scores across all classes.
+      box_coder_weights: An optional `list` of 4 positive floats to scale y, x,
+        h, and w when encoding box coordinates. If set to None, does not perform
+        scaling. For Faster RCNN, the open-source implementation recommends
+        using [10.0, 10.0, 5.0, 5.0].
       **kwargs: Additional keyword arguments passed to Layer.
+
+    Raises:
+      ValueError: If `use_class_agnostic_nms` is required by `nms_version` is
+      not specified as `v2`.
     """
+    if use_class_agnostic_nms and nms_version != 'v2':
+      raise ValueError(
+          'If not using TFLite custom NMS, `use_class_agnostic_nms` can only be'
+          ' enabled for NMS v2 for now, but NMS {} is used! If you are using'
+          ' TFLite NMS, please configure TFLite custom NMS for class-agnostic'
+          ' NMS.'.format(nms_version)
+      )
     self._config_dict = {
         'apply_nms': apply_nms,
         'pre_nms_top_k': pre_nms_top_k,
         'pre_nms_score_threshold': pre_nms_score_threshold,
         'nms_iou_threshold': nms_iou_threshold,
         'max_num_detections': max_num_detections,
         'nms_version': nms_version,
         'use_cpu_nms': use_cpu_nms,
-        'soft_nms_sigma': soft_nms_sigma
+        'soft_nms_sigma': soft_nms_sigma,
+        'return_decoded': return_decoded,
+        'use_class_agnostic_nms': use_class_agnostic_nms,
+        'box_coder_weights': box_coder_weights,
     }
+    # Don't store if were not defined
+    if pre_nms_top_k_sharding_block is not None:
+      self._config_dict['pre_nms_top_k_sharding_block'] = (
+          pre_nms_top_k_sharding_block
+      )
+    if nms_v3_refinements is not None:
+      self._config_dict['nms_v3_refinements'] = nms_v3_refinements
 
     if tflite_post_processing_config is not None:
       self._config_dict.update(
-          {'tflite_post_processing_config': tflite_post_processing_config})
-    super(MultilevelDetectionGenerator, self).__init__(**kwargs)
+          {'tflite_post_processing_config': tflite_post_processing_config}
+      )
+    super().__init__(**kwargs)
 
   def _decode_multilevel_outputs(
       self,
       raw_boxes: Mapping[str, tf.Tensor],
       raw_scores: Mapping[str, tf.Tensor],
       anchor_boxes: Mapping[str, tf.Tensor],
       image_shape: tf.Tensor,
-      raw_attributes: Optional[Mapping[str, tf.Tensor]] = None):
+      raw_attributes: Optional[Mapping[str, tf.Tensor]] = None,
+  ):
     """Collects dict of multilevel boxes, scores, attributes into lists."""
     boxes = []
     scores = []
     if raw_attributes:
       attributes = {att_name: [] for att_name in raw_attributes.keys()}
     else:
       attributes = {}
@@ -805,82 +1242,200 @@
     levels = list(raw_boxes.keys())
     min_level = int(min(levels))
     max_level = int(max(levels))
     for i in range(min_level, max_level + 1):
       raw_boxes_i = raw_boxes[str(i)]
       raw_scores_i = raw_scores[str(i)]
       batch_size = tf.shape(raw_boxes_i)[0]
-      (_, feature_h_i, feature_w_i,
-       num_anchors_per_locations_times_4) = raw_boxes_i.get_shape().as_list()
+      (_, feature_h_i, feature_w_i, num_anchors_per_locations_times_4) = (
+          raw_boxes_i.get_shape().as_list()
+      )
       num_locations = feature_h_i * feature_w_i
       num_anchors_per_locations = num_anchors_per_locations_times_4 // 4
-      num_classes = raw_scores_i.get_shape().as_list(
-      )[-1] // num_anchors_per_locations
+      num_classes = (
+          raw_scores_i.get_shape().as_list()[-1] // num_anchors_per_locations
+      )
 
       # Applies score transformation and remove the implicit background class.
       scores_i = tf.sigmoid(
-          tf.reshape(raw_scores_i, [
-              batch_size, num_locations * num_anchors_per_locations, num_classes
-          ]))
+          tf.reshape(
+              raw_scores_i,
+              [
+                  batch_size,
+                  num_locations * num_anchors_per_locations,
+                  num_classes,
+              ],
+          )
+      )
       scores_i = tf.slice(scores_i, [0, 0, 1], [-1, -1, -1])
 
       # Box decoding.
       # The anchor boxes are shared for all data in a batch.
       # One stage detector only supports class agnostic box regression.
       anchor_boxes_i = tf.reshape(
           anchor_boxes[str(i)],
-          [batch_size, num_locations * num_anchors_per_locations, 4])
+          [batch_size, num_locations * num_anchors_per_locations, 4],
+      )
       raw_boxes_i = tf.reshape(
           raw_boxes_i,
-          [batch_size, num_locations * num_anchors_per_locations, 4])
-      boxes_i = box_ops.decode_boxes(raw_boxes_i, anchor_boxes_i)
+          [batch_size, num_locations * num_anchors_per_locations, 4],
+      )
+      boxes_i = box_ops.decode_boxes(
+          raw_boxes_i,
+          anchor_boxes_i,
+          weights=self._config_dict['box_coder_weights'],
+      )
 
       # Box clipping.
-      boxes_i = box_ops.clip_boxes(
-          boxes_i, tf.expand_dims(image_shape, axis=1))
+      if image_shape is not None:
+        boxes_i = box_ops.clip_boxes(
+            boxes_i, tf.expand_dims(image_shape, axis=1)
+        )
 
       boxes.append(boxes_i)
       scores.append(scores_i)
 
       if raw_attributes:
         for att_name, raw_att in raw_attributes.items():
-          attribute_size = raw_att[str(
-              i)].get_shape().as_list()[-1] // num_anchors_per_locations
-          att_i = tf.reshape(raw_att[str(i)], [
-              batch_size, num_locations * num_anchors_per_locations,
-              attribute_size
-          ])
+          attribute_size = (
+              raw_att[str(i)].get_shape().as_list()[-1]
+              // num_anchors_per_locations
+          )
+          att_i = tf.reshape(
+              raw_att[str(i)],
+              [
+                  batch_size,
+                  num_locations * num_anchors_per_locations,
+                  attribute_size,
+              ],
+          )
           attributes[att_name].append(att_i)
 
     boxes = tf.concat(boxes, axis=1)
     boxes = tf.expand_dims(boxes, axis=2)
     scores = tf.concat(scores, axis=1)
 
     if raw_attributes:
       for att_name in raw_attributes.keys():
         attributes[att_name] = tf.concat(attributes[att_name], axis=1)
         attributes[att_name] = tf.expand_dims(attributes[att_name], axis=2)
 
     return boxes, scores, attributes
 
-  def __call__(self,
-               raw_boxes: Mapping[str, tf.Tensor],
-               raw_scores: Mapping[str, tf.Tensor],
-               anchor_boxes: Mapping[str, tf.Tensor],
-               image_shape: tf.Tensor,
-               raw_attributes: Optional[Mapping[str, tf.Tensor]] = None):
+  def _decode_multilevel_outputs_and_pre_nms_top_k(
+      self,
+      raw_boxes: Mapping[str, tf.Tensor],
+      raw_scores: Mapping[str, tf.Tensor],
+      anchor_boxes: Mapping[str, tf.Tensor],
+      image_shape: tf.Tensor,
+  ) -> Tuple[tf.Tensor, tf.Tensor]:
+    """Collects dict of multilevel boxes, scores into lists."""
+    boxes = None
+    scores = None
+
+    pre_nms_top_k = self._config_dict['pre_nms_top_k']
+    # TODO(b/258007436): consider removing when compiler be able to handle
+    # it on its own.
+    pre_nms_top_k_sharding_block = self._config_dict.get(
+        'pre_nms_top_k_sharding_block', 128
+    )
+    levels = list(raw_boxes.keys())
+    min_level = int(min(levels))
+    max_level = int(max(levels))
+    if image_shape is not None:
+      clip_shape = tf.expand_dims(tf.expand_dims(image_shape, axis=1), axis=1)
+    else:
+      clip_shape = None
+    for i in range(max_level, min_level - 1, -1):
+      (
+          batch_size,
+          unsharded_h,
+          unsharded_w,
+          num_anchors_per_locations_times_4,
+      ) = (
+          raw_boxes[str(i)].get_shape().as_list()
+      )
+      num_anchors_per_locations = num_anchors_per_locations_times_4 // 4
+      if batch_size is None:
+        batch_size = tf.shape(raw_boxes[str(i)])[0]
+      block = max(1, pre_nms_top_k_sharding_block // unsharded_w)
+      boxes_shape = [
+          batch_size,
+          unsharded_h,
+          unsharded_w * num_anchors_per_locations,
+          4,
+      ]
+      decoded_boxes = box_ops.decode_boxes(
+          tf.reshape(raw_boxes[str(i)], boxes_shape),
+          tf.reshape(anchor_boxes[str(i)], boxes_shape),
+      )
+      if clip_shape is not None:
+        decoded_boxes = box_ops.clip_boxes(
+            decoded_boxes,
+            clip_shape,
+        )
+      for raw_scores_i, decoded_boxes_i in edgetpu.shard_tensors(
+          1, block, (raw_scores[str(i)], decoded_boxes)
+      ):
+        (_, feature_h_i, feature_w_i, _) = raw_scores_i.get_shape().as_list()
+        num_locations = feature_h_i * feature_w_i
+        num_classes = (
+            raw_scores_i.get_shape().as_list()[-1] // num_anchors_per_locations
+        )
+
+        # Applies score transformation and remove the implicit background class.
+        scores_i = tf.slice(
+            tf.transpose(
+                tf.reshape(
+                    raw_scores_i,
+                    [
+                        batch_size,
+                        num_locations * num_anchors_per_locations,
+                        num_classes,
+                    ],
+                ),
+                [0, 2, 1],
+            ),
+            [0, 1, 0],
+            [-1, -1, -1],
+        )
+
+        # Box decoding.
+        # The anchor boxes are shared for all data in a batch.
+        # One stage detector only supports class agnostic box regression.
+        boxes_i = tf.tile(
+            tf.reshape(
+                decoded_boxes_i,
+                [batch_size, 1, num_locations * num_anchors_per_locations, 4],
+            ),
+            [1, num_classes - 1, 1, 1],
+        )
+        scores, boxes = edgetpu.concat_and_top_k(
+            pre_nms_top_k, (scores, scores_i), (boxes, boxes_i)
+        )
+    boxes: tf.Tensor = boxes  # pytype: disable=annotation-type-mismatch
+    return boxes, tf.sigmoid(scores)
+
+  def __call__(
+      self,
+      raw_boxes: Mapping[str, tf.Tensor],
+      raw_scores: Mapping[str, tf.Tensor],
+      anchor_boxes: Mapping[str, tf.Tensor],
+      image_shape: tf.Tensor,
+      raw_attributes: Optional[Mapping[str, tf.Tensor]] = None,
+  ) -> Mapping[str, Any]:
     """Generates final detections.
 
     Args:
       raw_boxes: A `dict` with keys representing FPN levels and values
         representing box tenors of shape `[batch, feature_h, feature_w,
         num_anchors * 4]`.
       raw_scores: A `dict` with keys representing FPN levels and values
         representing logit tensors of shape `[batch, feature_h, feature_w,
-        num_anchors]`.
+        num_anchors * num_classes]`.
       anchor_boxes: A `dict` with keys representing FPN levels and values
         representing anchor tenors of shape `[batch_size, K, 4]` representing
         the corresponding anchor boxes w.r.t `box_outputs`.
       image_shape: A `tf.Tensor` of shape of [batch_size, 2] storing the image
         height and width w.r.t. the scaled image, i.e. the same image space as
         `box_outputs` and `anchor_boxes`.
       raw_attributes: If not None, a `dict` of (attribute_name,
@@ -899,97 +1454,150 @@
         `detection_classes`: An `int` tf.Tensor of shape
           [batch, max_num_detections] representing classes for detected boxes.
         `num_detections`: An `int` tf.Tensor of shape [batch] only the first
           `num_detections` boxes are valid detections
         `detection_attributes`: A dict. Values of the dict is a `float`
           tf.Tensor of shape [batch, max_num_detections, attribute_size]
           representing attribute predictions for detected boxes.
-      If `apply_nms` = False, the return is a dictionary with keys:
+      If `apply_nms` = False, the return is a dictionary with following keys. If
+      `return_decoded` = True, the following items will also be included even if
+      `apply_nms` = True:
         `decoded_boxes`: A `float` tf.Tensor of shape [batch, num_raw_boxes, 4]
           representing all the decoded boxes.
         `decoded_box_scores`: A `float` tf.Tensor of shape
           [batch, num_raw_boxes] representing socres of all the decoded boxes.
         `decoded_box_attributes`: A dict. Values in the dict is a
           `float` tf.Tensor of shape [batch, num_raw_boxes, attribute_size]
           representing attribute predictions of all the decoded boxes.
     """
-    if self._config_dict['apply_nms'] and self._config_dict[
-        'nms_version'] == 'tflite':
+    if (
+        self._config_dict['apply_nms']
+        and self._config_dict['nms_version'] == 'tflite'
+    ):
       boxes, classes, scores, num_detections = _generate_detections_tflite(
-          raw_boxes, raw_scores, anchor_boxes,
-          self.get_config()['tflite_post_processing_config'])
+          raw_boxes,
+          raw_scores,
+          anchor_boxes,
+          self.get_config()['tflite_post_processing_config'],
+          self._config_dict['box_coder_weights'],
+      )
       return {
           'num_detections': num_detections,
           'detection_boxes': boxes,
           'detection_classes': classes,
-          'detection_scores': scores
+          'detection_scores': scores,
       }
 
-    boxes, scores, attributes = self._decode_multilevel_outputs(
-        raw_boxes, raw_scores, anchor_boxes, image_shape, raw_attributes)
+    if self._config_dict['nms_version'] != 'v3':
+      boxes, scores, attributes = self._decode_multilevel_outputs(
+          raw_boxes, raw_scores, anchor_boxes, image_shape, raw_attributes
+      )
+    else:
+      attributes = None
+      boxes, scores = self._decode_multilevel_outputs_and_pre_nms_top_k(
+          raw_boxes, raw_scores, anchor_boxes, image_shape
+      )
+
+    decoded_results = {
+        'decoded_boxes': boxes,
+        'decoded_box_scores': scores,
+        'decoded_box_attributes': attributes,
+    }
 
     if not self._config_dict['apply_nms']:
-      return {
-          'decoded_boxes': boxes,
-          'decoded_box_scores': scores,
-          'decoded_box_attributes': attributes,
-      }
+      return decoded_results
 
     # Optionally force the NMS to run on CPU.
     if self._config_dict['use_cpu_nms']:
       nms_context = tf.device('cpu:0')
     else:
       nms_context = contextlib.nullcontext()
 
     with nms_context:
       if raw_attributes and (self._config_dict['nms_version'] != 'v1'):
         raise ValueError(
             'Attribute learning is only supported for NMSv1 but NMS {} is used.'
-            .format(self._config_dict['nms_version']))
+            .format(self._config_dict['nms_version'])
+        )
       if self._config_dict['nms_version'] == 'batched':
         (nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections) = (
             _generate_detections_batched(
-                boxes, scores, self._config_dict['pre_nms_score_threshold'],
+                boxes,
+                scores,
+                self._config_dict['pre_nms_score_threshold'],
                 self._config_dict['nms_iou_threshold'],
-                self._config_dict['max_num_detections']))
+                self._config_dict['max_num_detections'],
+            )
+        )
         # Set `nmsed_attributes` to None for batched NMS.
         nmsed_attributes = {}
       elif self._config_dict['nms_version'] == 'v1':
-        (nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections,
-         nmsed_attributes) = (
-             _generate_detections_v1(
-                 boxes,
-                 scores,
-                 attributes=attributes if raw_attributes else None,
-                 pre_nms_top_k=self._config_dict['pre_nms_top_k'],
-                 pre_nms_score_threshold=self
-                 ._config_dict['pre_nms_score_threshold'],
-                 nms_iou_threshold=self._config_dict['nms_iou_threshold'],
-                 max_num_detections=self._config_dict['max_num_detections'],
-                 soft_nms_sigma=self._config_dict['soft_nms_sigma']))
+        (
+            nmsed_boxes,
+            nmsed_scores,
+            nmsed_classes,
+            valid_detections,
+            nmsed_attributes,
+        ) = _generate_detections_v1(
+            boxes,
+            scores,
+            attributes=attributes if raw_attributes else None,
+            pre_nms_top_k=self._config_dict['pre_nms_top_k'],
+            pre_nms_score_threshold=self._config_dict[
+                'pre_nms_score_threshold'
+            ],
+            nms_iou_threshold=self._config_dict['nms_iou_threshold'],
+            max_num_detections=self._config_dict['max_num_detections'],
+            soft_nms_sigma=self._config_dict['soft_nms_sigma'],
+        )
       elif self._config_dict['nms_version'] == 'v2':
         (nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections) = (
             _generate_detections_v2(
                 boxes,
                 scores,
                 pre_nms_top_k=self._config_dict['pre_nms_top_k'],
-                pre_nms_score_threshold=self
-                ._config_dict['pre_nms_score_threshold'],
+                pre_nms_score_threshold=self._config_dict[
+                    'pre_nms_score_threshold'
+                ],
                 nms_iou_threshold=self._config_dict['nms_iou_threshold'],
-                max_num_detections=self._config_dict['max_num_detections']))
+                max_num_detections=self._config_dict['max_num_detections'],
+                use_class_agnostic_nms=self._config_dict[
+                    'use_class_agnostic_nms'
+                ],
+            )
+        )
         # Set `nmsed_attributes` to None for v2.
         nmsed_attributes = {}
+      elif self._config_dict['nms_version'] == 'v3':
+        (nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections) = (
+            _generate_detections_v3(
+                boxes,
+                scores,
+                pre_nms_score_threshold=self._config_dict[
+                    'pre_nms_score_threshold'
+                ],
+                nms_iou_threshold=self._config_dict['nms_iou_threshold'],
+                max_num_detections=self._config_dict['max_num_detections'],
+                refinements=self._config_dict.get('nms_v3_refinements', 2),
+            )
+        )
+        # Set `nmsed_attributes` to None for v3.
+        nmsed_attributes = {}
       else:
-        raise ValueError('NMS version {} not supported.'.format(
-            self._config_dict['nms_version']))
+        raise ValueError(
+            'NMS version {} not supported.'.format(
+                self._config_dict['nms_version']
+            )
+        )
 
     # Adds 1 to offset the background class which has index 0.
     nmsed_classes += 1
 
     return {
+        **(decoded_results if self._config_dict['return_decoded'] else {}),
         'num_detections': valid_detections,
         'detection_boxes': nmsed_boxes,
         'detection_classes': nmsed_classes,
         'detection_scores': nmsed_scores,
         'detection_attributes': nmsed_attributes,
     }
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/detection_generator_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/retinanet_model_test.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,282 +1,322 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Tests for detection_generator.py."""
-# Import libraries
+"""Tests for RetinaNet models."""
 
+# Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
+from tensorflow.python.distribute import combinations
+from tensorflow.python.distribute import strategy_combinations
+from official.vision.modeling import retinanet_model
+from official.vision.modeling.backbones import resnet
+from official.vision.modeling.decoders import fpn
+from official.vision.modeling.heads import dense_prediction_heads
 from official.vision.modeling.layers import detection_generator
 from official.vision.ops import anchor
 
 
-class SelectTopKScoresTest(tf.test.TestCase):
-
-  def testSelectTopKScores(self):
-    pre_nms_num_boxes = 2
-    scores_data = [[[0.2, 0.2], [0.1, 0.9], [0.5, 0.1], [0.3, 0.5]]]
-    scores_in = tf.constant(scores_data, dtype=tf.float32)
-    top_k_scores, top_k_indices = detection_generator._select_top_k_scores(
-        scores_in, pre_nms_num_detections=pre_nms_num_boxes)
-    expected_top_k_scores = np.array([[[0.5, 0.9], [0.3, 0.5]]],
-                                     dtype=np.float32)
-
-    expected_top_k_indices = [[[2, 1], [3, 3]]]
-
-    self.assertAllEqual(top_k_scores.numpy(), expected_top_k_scores)
-    self.assertAllEqual(top_k_indices.numpy(), expected_top_k_indices)
-
-
-class DetectionGeneratorTest(
-    parameterized.TestCase, tf.test.TestCase):
-
-  @parameterized.product(
-      nms_version=['batched', 'v1', 'v2'],
-      use_cpu_nms=[True, False],
-      soft_nms_sigma=[None, 0.1])
-  def testDetectionsOutputShape(self, nms_version, use_cpu_nms, soft_nms_sigma):
-    max_num_detections = 10
-    num_classes = 4
-    pre_nms_top_k = 5000
-    pre_nms_score_threshold = 0.01
-    batch_size = 1
-    kwargs = {
-        'apply_nms': True,
-        'pre_nms_top_k': pre_nms_top_k,
-        'pre_nms_score_threshold': pre_nms_score_threshold,
-        'nms_iou_threshold': 0.5,
-        'max_num_detections': max_num_detections,
-        'nms_version': nms_version,
-        'use_cpu_nms': use_cpu_nms,
-        'soft_nms_sigma': soft_nms_sigma,
-    }
-    generator = detection_generator.DetectionGenerator(**kwargs)
-
-    cls_outputs_all = (
-        np.random.rand(84, num_classes) - 0.5) * 3  # random 84x3 outputs.
-    box_outputs_all = np.random.rand(84, 4 * num_classes)  # random 84 boxes.
-    anchor_boxes_all = np.random.rand(84, 4)  # random 84 boxes.
-    class_outputs = tf.reshape(
-        tf.convert_to_tensor(cls_outputs_all, dtype=tf.float32),
-        [1, 84, num_classes])
-    box_outputs = tf.reshape(
-        tf.convert_to_tensor(box_outputs_all, dtype=tf.float32),
-        [1, 84, 4 * num_classes])
-    anchor_boxes = tf.reshape(
-        tf.convert_to_tensor(anchor_boxes_all, dtype=tf.float32),
-        [1, 84, 4])
-    image_info = tf.constant(
-        [[[1000, 1000], [100, 100], [0.1, 0.1], [0, 0]]],
-        dtype=tf.float32)
-    results = generator(
-        box_outputs, class_outputs, anchor_boxes, image_info[:, 1, :])
-    boxes = results['detection_boxes']
-    classes = results['detection_classes']
-    scores = results['detection_scores']
-    valid_detections = results['num_detections']
-
-    self.assertEqual(boxes.numpy().shape, (batch_size, max_num_detections, 4))
-    self.assertEqual(scores.numpy().shape, (batch_size, max_num_detections,))
-    self.assertEqual(classes.numpy().shape, (batch_size, max_num_detections,))
-    self.assertEqual(valid_detections.numpy().shape, (batch_size,))
-
-  def test_serialize_deserialize(self):
-    kwargs = {
-        'apply_nms': True,
-        'pre_nms_top_k': 1000,
-        'pre_nms_score_threshold': 0.1,
-        'nms_iou_threshold': 0.5,
-        'max_num_detections': 10,
-        'nms_version': 'v2',
-        'use_cpu_nms': False,
-        'soft_nms_sigma': None,
-    }
-    generator = detection_generator.DetectionGenerator(**kwargs)
-
-    expected_config = dict(kwargs)
-    self.assertEqual(generator.get_config(), expected_config)
-
-    new_generator = (
-        detection_generator.DetectionGenerator.from_config(
-            generator.get_config()))
-
-    self.assertAllEqual(generator.get_config(), new_generator.get_config())
-
-
-class MultilevelDetectionGeneratorTest(
-    parameterized.TestCase, tf.test.TestCase):
+class RetinaNetTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
-      ('batched', False, True, None, None),
-      ('batched', False, False, None, None),
-      ('v2', False, True, None, None),
-      ('v2', False, False, None, None),
-      ('v1', True, True, 0.0, None),
-      ('v1', True, False, 0.1, None),
-      ('v1', True, False, None, None),
-      ('tflite', False, False, None, True),
-      ('tflite', False, False, None, False),
+      {
+          'use_separable_conv': True,
+          'build_anchor_boxes': True,
+          'is_training': False,
+          'has_att_heads': False,
+      },
+      {
+          'use_separable_conv': False,
+          'build_anchor_boxes': True,
+          'is_training': False,
+          'has_att_heads': False,
+      },
+      {
+          'use_separable_conv': False,
+          'build_anchor_boxes': False,
+          'is_training': False,
+          'has_att_heads': False,
+      },
+      {
+          'use_separable_conv': False,
+          'build_anchor_boxes': False,
+          'is_training': True,
+          'has_att_heads': False,
+      },
+      {
+          'use_separable_conv': False,
+          'build_anchor_boxes': True,
+          'is_training': True,
+          'has_att_heads': True,
+      },
+      {
+          'use_separable_conv': False,
+          'build_anchor_boxes': True,
+          'is_training': False,
+          'has_att_heads': True,
+      },
   )
-  def testDetectionsOutputShape(self, nms_version, has_att_heads, use_cpu_nms,
-                                soft_nms_sigma, use_regular_nms):
-    min_level = 4
-    max_level = 6
-    num_scales = 2
-    max_num_detections = 10
-    aspect_ratios = [1.0, 2.0]
-    anchor_scale = 2.0
-    output_size = [64, 64]
-    num_classes = 4
-    pre_nms_top_k = 5000
-    pre_nms_score_threshold = 0.01
-    batch_size = 1
-    tflite_post_processing_config = {
-        'max_detections': max_num_detections,
-        'max_classes_per_detection': 1,
-        'use_regular_nms': use_regular_nms,
-        'nms_score_threshold': 0.01,
-        'nms_iou_threshold': 0.5
-    }
-    kwargs = {
-        'apply_nms': True,
-        'pre_nms_top_k': pre_nms_top_k,
-        'pre_nms_score_threshold': pre_nms_score_threshold,
-        'nms_iou_threshold': 0.5,
-        'max_num_detections': max_num_detections,
-        'nms_version': nms_version,
-        'use_cpu_nms': use_cpu_nms,
-        'soft_nms_sigma': soft_nms_sigma,
-        'tflite_post_processing_config': tflite_post_processing_config
-    }
-
-    input_anchor = anchor.build_anchor_generator(min_level, max_level,
-                                                 num_scales, aspect_ratios,
-                                                 anchor_scale)
-    anchor_boxes = input_anchor(output_size)
-    cls_outputs_all = (
-        np.random.rand(84, num_classes) - 0.5) * 3  # random 84x3 outputs.
-    box_outputs_all = np.random.rand(84, 4)  # random 84 boxes.
-    class_outputs = {
-        '4':
-            tf.reshape(
-                tf.convert_to_tensor(cls_outputs_all[0:64], dtype=tf.float32),
-                [1, 8, 8, num_classes]),
-        '5':
-            tf.reshape(
-                tf.convert_to_tensor(cls_outputs_all[64:80], dtype=tf.float32),
-                [1, 4, 4, num_classes]),
-        '6':
-            tf.reshape(
-                tf.convert_to_tensor(cls_outputs_all[80:84], dtype=tf.float32),
-                [1, 2, 2, num_classes]),
-    }
-    box_outputs = {
-        '4': tf.reshape(tf.convert_to_tensor(
-            box_outputs_all[0:64], dtype=tf.float32), [1, 8, 8, 4]),
-        '5': tf.reshape(tf.convert_to_tensor(
-            box_outputs_all[64:80], dtype=tf.float32), [1, 4, 4, 4]),
-        '6': tf.reshape(tf.convert_to_tensor(
-            box_outputs_all[80:84], dtype=tf.float32), [1, 2, 2, 4]),
-    }
-    if has_att_heads:
-      att_outputs_all = np.random.rand(84, 1)  # random attributes.
-      att_outputs = {
-          'depth': {
-              '4':
-                  tf.reshape(
-                      tf.convert_to_tensor(
-                          att_outputs_all[0:64], dtype=tf.float32),
-                      [1, 8, 8, 1]),
-              '5':
-                  tf.reshape(
-                      tf.convert_to_tensor(
-                          att_outputs_all[64:80], dtype=tf.float32),
-                      [1, 4, 4, 1]),
-              '6':
-                  tf.reshape(
-                      tf.convert_to_tensor(
-                          att_outputs_all[80:84], dtype=tf.float32),
-                      [1, 2, 2, 1]),
-          }
-      }
+  def test_build_model(self, use_separable_conv, build_anchor_boxes,
+                       is_training, has_att_heads):
+    num_classes = 3
+    min_level = 3
+    max_level = 7
+    num_scales = 3
+    aspect_ratios = [1.0]
+    anchor_size = 3
+    fpn_num_filters = 256
+    head_num_convs = 4
+    head_num_filters = 256
+    num_anchors_per_location = num_scales * len(aspect_ratios)
+    image_size = 384
+    images = np.random.rand(2, image_size, image_size, 3)
+    image_shape = np.array([[image_size, image_size], [image_size, image_size]])
+
+    if build_anchor_boxes:
+      anchor_boxes = anchor.Anchor(
+          min_level=min_level,
+          max_level=max_level,
+          num_scales=num_scales,
+          aspect_ratios=aspect_ratios,
+          anchor_size=anchor_size,
+          image_size=(image_size, image_size)).multilevel_boxes
+      for l in anchor_boxes:
+        anchor_boxes[l] = tf.tile(
+            tf.expand_dims(anchor_boxes[l], axis=0), [2, 1, 1, 1])
     else:
-      att_outputs = None
-    image_info = tf.constant([[[1000, 1000], [100, 100], [0.1, 0.1], [0, 0]]],
-                             dtype=tf.float32)
-    generator = detection_generator.MultilevelDetectionGenerator(**kwargs)
-    results = generator(box_outputs, class_outputs, anchor_boxes,
-                        image_info[:, 1, :], att_outputs)
-    boxes = results['detection_boxes']
-    classes = results['detection_classes']
-    scores = results['detection_scores']
-    valid_detections = results['num_detections']
-
-    if nms_version == 'tflite':
-      # When nms_version is `tflite`, all output tensors are empty as the actual
-      # post-processing happens in the TFLite model.
-      self.assertEqual(boxes.numpy().shape, ())
-      self.assertEqual(scores.numpy().shape, ())
-      self.assertEqual(classes.numpy().shape, ())
-      self.assertEqual(valid_detections.numpy().shape, ())
+      anchor_boxes = None
+
+    if has_att_heads:
+      attribute_heads = [
+          dict(
+              name='depth', type='regression', size=1, prediction_tower_name='')
+      ]
     else:
-      self.assertEqual(boxes.numpy().shape, (batch_size, max_num_detections, 4))
-      self.assertEqual(scores.numpy().shape, (
-          batch_size,
-          max_num_detections,
-      ))
-      self.assertEqual(classes.numpy().shape, (
-          batch_size,
-          max_num_detections,
+      attribute_heads = None
+
+    backbone = resnet.ResNet(model_id=50)
+    decoder = fpn.FPN(
+        input_specs=backbone.output_specs,
+        min_level=min_level,
+        max_level=max_level,
+        num_filters=fpn_num_filters,
+        use_separable_conv=use_separable_conv)
+    head = dense_prediction_heads.RetinaNetHead(
+        min_level=min_level,
+        max_level=max_level,
+        num_classes=num_classes,
+        attribute_heads=attribute_heads,
+        num_anchors_per_location=num_anchors_per_location,
+        use_separable_conv=use_separable_conv,
+        num_convs=head_num_convs,
+        num_filters=head_num_filters)
+    generator = detection_generator.MultilevelDetectionGenerator(
+        max_num_detections=10)
+    model = retinanet_model.RetinaNetModel(
+        backbone=backbone,
+        decoder=decoder,
+        head=head,
+        detection_generator=generator,
+        min_level=min_level,
+        max_level=max_level,
+        num_scales=num_scales,
+        aspect_ratios=aspect_ratios,
+        anchor_size=anchor_size)
+
+    _ = model(images, image_shape, anchor_boxes, training=is_training)
+
+  @combinations.generate(
+      combinations.combine(
+          strategy=[
+              strategy_combinations.cloud_tpu_strategy,
+              strategy_combinations.one_device_strategy_gpu,
+          ],
+          image_size=[
+              (128, 128),
+          ],
+          training=[True, False],
+          has_att_heads=[True, False],
+          output_intermediate_features=[True, False],
+          soft_nms_sigma=[None, 0.0, 0.1],
       ))
-      self.assertEqual(valid_detections.numpy().shape, (batch_size,))
+  def test_forward(self, strategy, image_size, training, has_att_heads,
+                   output_intermediate_features, soft_nms_sigma):
+    """Test for creation of a R50-FPN RetinaNet."""
+    tf_keras.backend.set_image_data_format('channels_last')
+    num_classes = 3
+    min_level = 3
+    max_level = 7
+    num_scales = 3
+    aspect_ratios = [1.0]
+    num_anchors_per_location = num_scales * len(aspect_ratios)
+
+    images = np.random.rand(2, image_size[0], image_size[1], 3)
+    image_shape = np.array(
+        [[image_size[0], image_size[1]], [image_size[0], image_size[1]]])
+
+    with strategy.scope():
+      anchor_gen = anchor.build_anchor_generator(
+          min_level=min_level,
+          max_level=max_level,
+          num_scales=num_scales,
+          aspect_ratios=aspect_ratios,
+          anchor_size=3)
+      anchor_boxes = anchor_gen(image_size)
+      for l in anchor_boxes:
+        anchor_boxes[l] = tf.tile(
+            tf.expand_dims(anchor_boxes[l], axis=0), [2, 1, 1, 1])
+
+      backbone = resnet.ResNet(model_id=50)
+      decoder = fpn.FPN(
+          input_specs=backbone.output_specs,
+          min_level=min_level,
+          max_level=max_level)
+
       if has_att_heads:
-        for att in results['detection_attributes'].values():
-          self.assertEqual(att.numpy().shape,
-                           (batch_size, max_num_detections, 1))
+        attribute_heads = [
+            dict(
+                name='depth',
+                type='regression',
+                size=1,
+                prediction_tower_name='')
+        ]
+      else:
+        attribute_heads = None
+      head = dense_prediction_heads.RetinaNetHead(
+          min_level=min_level,
+          max_level=max_level,
+          num_classes=num_classes,
+          attribute_heads=attribute_heads,
+          num_anchors_per_location=num_anchors_per_location)
+      generator = detection_generator.MultilevelDetectionGenerator(
+          max_num_detections=10,
+          nms_version='v1',
+          use_cpu_nms=soft_nms_sigma is not None,
+          soft_nms_sigma=soft_nms_sigma)
+      model = retinanet_model.RetinaNetModel(
+          backbone=backbone,
+          decoder=decoder,
+          head=head,
+          detection_generator=generator)
+
+      model_outputs = model(
+          images,
+          image_shape,
+          anchor_boxes,
+          output_intermediate_features=output_intermediate_features,
+          training=training)
+
+    if training:
+      cls_outputs = model_outputs['cls_outputs']
+      box_outputs = model_outputs['box_outputs']
+      for level in range(min_level, max_level + 1):
+        self.assertIn(str(level), cls_outputs)
+        self.assertIn(str(level), box_outputs)
+        self.assertAllEqual([
+            2,
+            image_size[0] // 2**level,
+            image_size[1] // 2**level,
+            num_classes * num_anchors_per_location
+        ], cls_outputs[str(level)].numpy().shape)
+        self.assertAllEqual([
+            2,
+            image_size[0] // 2**level,
+            image_size[1] // 2**level,
+            4 * num_anchors_per_location
+        ], box_outputs[str(level)].numpy().shape)
+        if has_att_heads:
+          att_outputs = model_outputs['attribute_outputs']
+          for att in att_outputs.values():
+            self.assertAllEqual([
+                2, image_size[0] // 2**level, image_size[1] // 2**level,
+                1 * num_anchors_per_location
+            ], att[str(level)].numpy().shape)
+    else:
+      self.assertIn('detection_boxes', model_outputs)
+      self.assertIn('detection_scores', model_outputs)
+      self.assertIn('detection_classes', model_outputs)
+      self.assertIn('num_detections', model_outputs)
+      self.assertAllEqual(
+          [2, 10, 4], model_outputs['detection_boxes'].numpy().shape)
+      self.assertAllEqual(
+          [2, 10], model_outputs['detection_scores'].numpy().shape)
+      self.assertAllEqual(
+          [2, 10], model_outputs['detection_classes'].numpy().shape)
+      self.assertAllEqual(
+          [2,], model_outputs['num_detections'].numpy().shape)
+      if has_att_heads:
+        self.assertIn('detection_attributes', model_outputs)
+        self.assertAllEqual(
+            [2, 10, 1],
+            model_outputs['detection_attributes']['depth'].numpy().shape)
+    if output_intermediate_features:
+      for l in range(2, 6):
+        self.assertIn('backbone_{}'.format(l), model_outputs)
+        self.assertAllEqual([
+            2, image_size[0] // 2**l, image_size[1] // 2**l,
+            backbone.output_specs[str(l)].as_list()[-1]
+        ], model_outputs['backbone_{}'.format(l)].numpy().shape)
+      for l in range(min_level, max_level + 1):
+        self.assertIn('decoder_{}'.format(l), model_outputs)
+        self.assertAllEqual([
+            2, image_size[0] // 2**l, image_size[1] // 2**l,
+            decoder.output_specs[str(l)].as_list()[-1]
+        ], model_outputs['decoder_{}'.format(l)].numpy().shape)
 
   def test_serialize_deserialize(self):
-    tflite_post_processing_config = {
-        'max_detections': 100,
-        'max_classes_per_detection': 1,
-        'use_regular_nms': True,
-        'nms_score_threshold': 0.01,
-        'nms_iou_threshold': 0.5
-    }
-    kwargs = {
-        'apply_nms': True,
-        'pre_nms_top_k': 1000,
-        'pre_nms_score_threshold': 0.1,
-        'nms_iou_threshold': 0.5,
-        'max_num_detections': 10,
-        'nms_version': 'v2',
-        'use_cpu_nms': False,
-        'soft_nms_sigma': None,
-        'tflite_post_processing_config': tflite_post_processing_config
-    }
-    generator = detection_generator.MultilevelDetectionGenerator(**kwargs)
-
-    expected_config = dict(kwargs)
-    self.assertEqual(generator.get_config(), expected_config)
-
-    new_generator = (
-        detection_generator.MultilevelDetectionGenerator.from_config(
-            generator.get_config()))
+    """Validate the network can be serialized and deserialized."""
+    num_classes = 3
+    min_level = 3
+    max_level = 7
+    num_scales = 3
+    aspect_ratios = [1.0]
+    num_anchors_per_location = num_scales * len(aspect_ratios)
+
+    backbone = resnet.ResNet(model_id=50)
+    decoder = fpn.FPN(
+        input_specs=backbone.output_specs,
+        min_level=min_level,
+        max_level=max_level)
+    head = dense_prediction_heads.RetinaNetHead(
+        min_level=min_level,
+        max_level=max_level,
+        num_classes=num_classes,
+        num_anchors_per_location=num_anchors_per_location)
+    generator = detection_generator.MultilevelDetectionGenerator(
+        max_num_detections=10)
+    model = retinanet_model.RetinaNetModel(
+        backbone=backbone,
+        decoder=decoder,
+        head=head,
+        detection_generator=generator,
+        min_level=min_level,
+        max_level=max_level,
+        num_scales=num_scales,
+        aspect_ratios=aspect_ratios,
+        anchor_size=3)
+
+    config = model.get_config()
+    new_model = retinanet_model.RetinaNetModel.from_config(config)
+
+    # Validate that the config can be forced to JSON.
+    _ = new_model.to_json()
 
-    self.assertAllEqual(generator.get_config(), new_generator.get_config())
+    # If the serialization was successful, the new config should match the old.
+    self.assertAllEqual(model.get_config(), new_model.get_config())
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/mask_sampler.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/mask_sampler.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains definitions of mask sampler."""
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import spatial_transform_ops
 
 
 def _sample_and_crop_foreground_masks(candidate_rois: tf.Tensor,
                                       candidate_gt_boxes: tf.Tensor,
                                       candidate_gt_classes: tf.Tensor,
@@ -96,16 +96,16 @@
   cropped_foreground_masks = spatial_transform_ops.crop_mask_in_target_box(
       foreground_masks, foreground_boxes, foreground_rois, mask_target_size,
       sample_offset=0.5)
 
   return foreground_rois, foreground_classes, cropped_foreground_masks
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MaskSampler(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MaskSampler(tf_keras.layers.Layer):
   """Samples and creates mask training targets."""
 
   def __init__(self, mask_target_size: int, num_sampled_masks: int, **kwargs):
     self._config_dict = {
         'mask_target_size': mask_target_size,
         'num_sampled_masks': num_sampled_masks,
     }
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_blocks.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_blocks.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Contains common building blocks for neural networks."""
 
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union, Text
 
 # Import libraries
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.nlp import modeling as nlp_modeling
 from official.vision.modeling.layers import nn_layers
 
 
 def _pad_strides(strides: int, axis: int) -> Tuple[int, int, int, int]:
@@ -49,16 +49,16 @@
       x = tf.pad(x, [[0, 0], pad_size, [0, 0], [0, 0]])
     else:
       x = tf.pad(x, [[0, 0], [0, 0], [0, 0], pad_size])
 
   return x + 0.
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ResidualBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ResidualBlock(tf_keras.layers.Layer):
   """A residual block."""
 
   def __init__(self,
                filters,
                strides,
                use_projection=False,
                se_ratio=None,
@@ -88,17 +88,17 @@
       se_ratio: A `float` or None. Ratio of the Squeeze-and-Excitation layer.
       resnetd_shortcut: A `bool` if True, apply the resnetd style modification
         to the shortcut connection. Not implemented in residual blocks.
       stochastic_depth_drop_rate: A `float` or None. if not None, drop rate for
         the stochastic depth layer.
       kernel_initializer: A `str` of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2d.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2d.
         Default to None.
       activation: A `str` name of the activation function.
       use_explicit_padding: Use 'VALID' padding for convolutions, but prepad
         inputs so that the output dimensions are the same as if 'SAME' padding
         were used.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
@@ -119,78 +119,81 @@
     self._activation = activation
     self._stochastic_depth_drop_rate = stochastic_depth_drop_rate
     self._kernel_initializer = kernel_initializer
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
+    self._norm = tf_keras.layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation_fn = tf_utils.get_activation(activation)
     self._bn_trainable = bn_trainable
 
   def build(self, input_shape):
     if self._use_projection:
-      self._shortcut = tf.keras.layers.Conv2D(
+      self._shortcut = tf_keras.layers.Conv2D(
           filters=self._filters,
           kernel_size=1,
           strides=self._strides,
           use_bias=False,
           kernel_initializer=tf_utils.clone_initializer(
               self._kernel_initializer),
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)
       self._norm0 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
           epsilon=self._norm_epsilon,
-          trainable=self._bn_trainable)
+          trainable=self._bn_trainable,
+          synchronized=self._use_sync_bn,
+      )
 
     conv1_padding = 'same'
     # explicit padding here is added for centernet
     if self._use_explicit_padding:
-      self._pad = tf.keras.layers.ZeroPadding2D(padding=(1, 1))
+      self._pad = tf_keras.layers.ZeroPadding2D(padding=(1, 1))
       conv1_padding = 'valid'
 
-    self._conv1 = tf.keras.layers.Conv2D(
+    self._conv1 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=3,
         strides=self._strides,
         padding=conv1_padding,
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
         epsilon=self._norm_epsilon,
-        trainable=self._bn_trainable)
+        trainable=self._bn_trainable,
+        synchronized=self._use_sync_bn,
+    )
 
-    self._conv2 = tf.keras.layers.Conv2D(
+    self._conv2 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=3,
         strides=1,
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm2 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
         epsilon=self._norm_epsilon,
-        trainable=self._bn_trainable)
+        trainable=self._bn_trainable,
+        synchronized=self._use_sync_bn,
+    )
 
     if self._se_ratio and self._se_ratio > 0 and self._se_ratio <= 1:
       self._squeeze_excitation = nn_layers.SqueezeExcitation(
           in_filters=self._filters,
           out_filters=self._filters,
           se_ratio=self._se_ratio,
           kernel_initializer=tf_utils.clone_initializer(
@@ -249,16 +252,16 @@
 
     if self._stochastic_depth:
       x = self._stochastic_depth(x, training=training)
 
     return self._activation_fn(x + shortcut)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class BottleneckBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class BottleneckBlock(tf_keras.layers.Layer):
   """A standard bottleneck block."""
 
   def __init__(self,
                filters,
                strides,
                dilation_rate=1,
                use_projection=False,
@@ -289,17 +292,17 @@
       se_ratio: A `float` or None. Ratio of the Squeeze-and-Excitation layer.
       resnetd_shortcut: A `bool`. If True, apply the resnetd style modification
         to the shortcut connection.
       stochastic_depth_drop_rate: A `float` or None. If not None, drop rate for
         the stochastic depth layer.
       kernel_initializer: A `str` of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2d.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2d.
         Default to None.
       activation: A `str` name of the activation function.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       bn_trainable: A `bool` that indicates whether batch norm layers should be
         trainable. Default to True.
@@ -317,102 +320,108 @@
     self._activation = activation
     self._stochastic_depth_drop_rate = stochastic_depth_drop_rate
     self._kernel_initializer = kernel_initializer
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    self._norm = tf_keras.layers.BatchNormalization
+
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._bn_trainable = bn_trainable
 
   def build(self, input_shape):
     if self._use_projection:
       if self._resnetd_shortcut:
-        self._shortcut0 = tf.keras.layers.AveragePooling2D(
+        self._shortcut0 = tf_keras.layers.AveragePooling2D(
             pool_size=2, strides=self._strides, padding='same')
-        self._shortcut1 = tf.keras.layers.Conv2D(
+        self._shortcut1 = tf_keras.layers.Conv2D(
             filters=self._filters * 4,
             kernel_size=1,
             strides=1,
             use_bias=False,
             kernel_initializer=tf_utils.clone_initializer(
                 self._kernel_initializer),
             kernel_regularizer=self._kernel_regularizer,
             bias_regularizer=self._bias_regularizer)
       else:
-        self._shortcut = tf.keras.layers.Conv2D(
+        self._shortcut = tf_keras.layers.Conv2D(
             filters=self._filters * 4,
             kernel_size=1,
             strides=self._strides,
             use_bias=False,
             kernel_initializer=tf_utils.clone_initializer(
                 self._kernel_initializer),
             kernel_regularizer=self._kernel_regularizer,
             bias_regularizer=self._bias_regularizer)
 
       self._norm0 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
           epsilon=self._norm_epsilon,
-          trainable=self._bn_trainable)
+          trainable=self._bn_trainable,
+          synchronized=self._use_sync_bn,
+      )
 
-    self._conv1 = tf.keras.layers.Conv2D(
+    self._conv1 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=1,
         strides=1,
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
         epsilon=self._norm_epsilon,
-        trainable=self._bn_trainable)
+        trainable=self._bn_trainable,
+        synchronized=self._use_sync_bn,
+    )
     self._activation1 = tf_utils.get_activation(
         self._activation, use_keras_layer=True)
 
-    self._conv2 = tf.keras.layers.Conv2D(
+    self._conv2 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=3,
         strides=self._strides,
         dilation_rate=self._dilation_rate,
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm2 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
         epsilon=self._norm_epsilon,
-        trainable=self._bn_trainable)
+        trainable=self._bn_trainable,
+        synchronized=self._use_sync_bn,
+    )
     self._activation2 = tf_utils.get_activation(
         self._activation, use_keras_layer=True)
 
-    self._conv3 = tf.keras.layers.Conv2D(
+    self._conv3 = tf_keras.layers.Conv2D(
         filters=self._filters * 4,
         kernel_size=1,
         strides=1,
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm3 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
         epsilon=self._norm_epsilon,
-        trainable=self._bn_trainable)
+        trainable=self._bn_trainable,
+        synchronized=self._use_sync_bn,
+    )
     self._activation3 = tf_utils.get_activation(
         self._activation, use_keras_layer=True)
 
     if self._se_ratio and self._se_ratio > 0 and self._se_ratio <= 1:
       self._squeeze_excitation = nn_layers.SqueezeExcitation(
           in_filters=self._filters * 4,
           out_filters=self._filters * 4,
@@ -425,15 +434,15 @@
       self._squeeze_excitation = None
 
     if self._stochastic_depth_drop_rate:
       self._stochastic_depth = nn_layers.StochasticDepth(
           self._stochastic_depth_drop_rate)
     else:
       self._stochastic_depth = None
-    self._add = tf.keras.layers.Add()
+    self._add = tf_keras.layers.Add()
 
     super(BottleneckBlock, self).build(input_shape)
 
   def get_config(self):
     config = {
         'filters': self._filters,
         'strides': self._strides,
@@ -481,16 +490,16 @@
     if self._stochastic_depth:
       x = self._stochastic_depth(x, training=training)
 
     x = self._add([x, shortcut])
     return self._activation3(x)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class InvertedBottleneckBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class InvertedBottleneckBlock(tf_keras.layers.Layer):
   """An inverted bottleneck block."""
 
   def __init__(self,
                in_filters,
                out_filters,
                expand_ratio,
                strides,
@@ -527,17 +536,17 @@
       kernel_size: An `int` kernel_size of the depthwise conv layer.
       se_ratio: A `float` or None. If not None, se ratio for the squeeze and
         excitation layer.
       stochastic_depth_drop_rate: A `float` or None. if not None, drop rate for
         the stochastic depth layer.
       kernel_initializer: A `str` of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2d.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2d.
         Default to None.
       activation: A `str` name of the activation function.
       se_inner_activation: A `str` name of squeeze-excitation inner activation.
       se_gating_activation: A `str` name of squeeze-excitation gating
         activation.
       se_round_down_protect: A `bool` of whether round down more than 10% will
         be allowed in SE layer.
@@ -585,20 +594,17 @@
     self._kernel_initializer = kernel_initializer
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     self._expand_se_in_filters = expand_se_in_filters
     self._output_intermediate_endpoints = output_intermediate_endpoints
+    self._norm = tf_keras.layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     if not depthwise_activation:
       self._depthwise_activation = activation
     if regularize_depthwise:
       self._depthsize_regularizer = kernel_regularizer
@@ -611,48 +617,52 @@
       # First 1x1 conv for channel expansion.
       expand_filters = nn_layers.make_divisible(
           self._in_filters * self._expand_ratio, self._divisible_by)
 
       expand_kernel = 1 if self._use_depthwise else self._kernel_size
       expand_stride = 1 if self._use_depthwise else self._strides
 
-      self._conv0 = tf.keras.layers.Conv2D(
+      self._conv0 = tf_keras.layers.Conv2D(
           filters=expand_filters,
           kernel_size=expand_kernel,
           strides=expand_stride,
           padding='same',
           use_bias=False,
           kernel_initializer=tf_utils.clone_initializer(
               self._kernel_initializer),
           kernel_regularizer=self._kernel_regularizer,
           bias_regularizer=self._bias_regularizer)
       self._norm0 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn,
+      )
       self._activation_layer = tf_utils.get_activation(
           self._activation, use_keras_layer=True)
 
     if self._use_depthwise:
       # Depthwise conv.
-      self._conv1 = tf.keras.layers.DepthwiseConv2D(
+      self._conv1 = tf_keras.layers.DepthwiseConv2D(
           kernel_size=(self._kernel_size, self._kernel_size),
           strides=self._strides,
           padding='same',
           depth_multiplier=1,
           dilation_rate=self._dilation_rate,
           use_bias=False,
           depthwise_initializer=tf_utils.clone_initializer(
               self._kernel_initializer),
           depthwise_regularizer=self._depthsize_regularizer,
           bias_regularizer=self._bias_regularizer)
       self._norm1 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn,
+      )
       self._depthwise_activation_layer = tf_utils.get_activation(
           self._depthwise_activation, use_keras_layer=True)
 
     # Squeeze and excitation.
     if self._se_ratio and self._se_ratio > 0 and self._se_ratio <= 1:
       logging.info('Use Squeeze and excitation.')
       in_filters = self._in_filters
@@ -670,34 +680,36 @@
           bias_regularizer=self._bias_regularizer,
           activation=self._se_inner_activation,
           gating_activation=self._se_gating_activation)
     else:
       self._squeeze_excitation = None
 
     # Last 1x1 conv.
-    self._conv2 = tf.keras.layers.Conv2D(
+    self._conv2 = tf_keras.layers.Conv2D(
         filters=self._out_filters,
         kernel_size=1,
         strides=1,
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm2 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
 
     if self._stochastic_depth_drop_rate:
       self._stochastic_depth = nn_layers.StochasticDepth(
           self._stochastic_depth_drop_rate)
     else:
       self._stochastic_depth = None
-    self._add = tf.keras.layers.Add()
+    self._add = tf_keras.layers.Add()
 
     super(InvertedBottleneckBlock, self).build(input_shape)
 
   def get_config(self):
     config = {
         'in_filters': self._in_filters,
         'out_filters': self._out_filters,
@@ -758,98 +770,98 @@
       x = self._add([x, shortcut])
 
     if self._output_intermediate_endpoints:
       return x, endpoints
     return x
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ResidualInner(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ResidualInner(tf_keras.layers.Layer):
   """Creates a single inner block of a residual.
 
   This corresponds to `F`/`G` functions in the RevNet paper:
   Aidan N. Gomez, Mengye Ren, Raquel Urtasun, Roger B. Grosse.
   The Reversible Residual Network: Backpropagation Without Storing Activations.
   (https://arxiv.org/pdf/1707.04585.pdf)
   """
 
   def __init__(
       self,
       filters: int,
       strides: int,
       kernel_initializer: Union[str, Callable[
-          ..., tf.keras.initializers.Initializer]] = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+          ..., tf_keras.initializers.Initializer]] = 'VarianceScaling',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       activation: Union[str, Callable[..., tf.Tensor]] = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       batch_norm_first: bool = True,
       **kwargs):
     """Initializes a ResidualInner.
 
     Args:
       filters: An `int` of output filter size.
       strides: An `int` of stride size for convolution for the residual block.
-      kernel_initializer: A `str` or `tf.keras.initializers.Initializer`
+      kernel_initializer: A `str` or `tf_keras.initializers.Initializer`
         instance for convolutional layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` for Conv2D.
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` for Conv2D.
       activation: A `str` or `callable` instance of the activation function.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       batch_norm_first: A `bool` of whether to apply activation and batch norm
         before conv.
       **kwargs: Additional keyword arguments to be passed.
     """
     super(ResidualInner, self).__init__(**kwargs)
 
     self.strides = strides
     self.filters = filters
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
     self._kernel_regularizer = kernel_regularizer
-    self._activation = tf.keras.activations.get(activation)
+    self._activation = tf_keras.activations.get(activation)
     self._use_sync_bn = use_sync_bn
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._batch_norm_first = batch_norm_first
+    self._norm = tf_keras.layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation_fn = tf_utils.get_activation(activation)
 
   def build(self, input_shape: tf.TensorShape):
     if self._batch_norm_first:
       self._batch_norm_0 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn,
+      )
 
-    self._conv2d_1 = tf.keras.layers.Conv2D(
+    self._conv2d_1 = tf_keras.layers.Conv2D(
         filters=self.filters,
         kernel_size=3,
         strides=self.strides,
         use_bias=False,
         padding='same',
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer)
 
     self._batch_norm_1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
 
-    self._conv2d_2 = tf.keras.layers.Conv2D(
+    self._conv2d_2 = tf_keras.layers.Conv2D(
         filters=self.filters,
         kernel_size=3,
         strides=1,
         use_bias=False,
         padding='same',
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer)
@@ -882,109 +894,111 @@
 
     x = self._batch_norm_1(x, training=training)
     x = self._activation_fn(x)
     x = self._conv2d_2(x)
     return x
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class BottleneckResidualInner(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class BottleneckResidualInner(tf_keras.layers.Layer):
   """Creates a single inner block of a bottleneck.
 
   This corresponds to `F`/`G` functions in the RevNet paper:
   Aidan N. Gomez, Mengye Ren, Raquel Urtasun, Roger B. Grosse.
   The Reversible Residual Network: Backpropagation Without Storing Activations.
   (https://arxiv.org/pdf/1707.04585.pdf)
   """
 
   def __init__(
       self,
       filters: int,
       strides: int,
       kernel_initializer: Union[str, Callable[
-          ..., tf.keras.initializers.Initializer]] = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+          ..., tf_keras.initializers.Initializer]] = 'VarianceScaling',
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       activation: Union[str, Callable[..., tf.Tensor]] = 'relu',
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       batch_norm_first: bool = True,
       **kwargs):
     """Initializes a BottleneckResidualInner.
 
     Args:
       filters: An `int` number of filters for first 2 convolutions. Last Last,
         and thus the number of output channels from the bottlneck block is
         `4*filters`
       strides: An `int` of stride size for convolution for the residual block.
-      kernel_initializer: A `str` or `tf.keras.initializers.Initializer`
+      kernel_initializer: A `str` or `tf_keras.initializers.Initializer`
         instance for convolutional layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` for Conv2D.
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` for Conv2D.
       activation: A `str` or `callable` instance of the activation function.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       batch_norm_first: A `bool` of whether to apply activation and batch norm
         before conv.
       **kwargs: Additional keyword arguments to be passed.
     """
     super(BottleneckResidualInner, self).__init__(**kwargs)
 
     self.strides = strides
     self.filters = filters
-    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)
+    self._kernel_initializer = tf_keras.initializers.get(kernel_initializer)
     self._kernel_regularizer = kernel_regularizer
-    self._activation = tf.keras.activations.get(activation)
+    self._activation = tf_keras.activations.get(activation)
     self._use_sync_bn = use_sync_bn
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._batch_norm_first = batch_norm_first
+    self._norm = tf_keras.layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation_fn = tf_utils.get_activation(activation)
 
   def build(self, input_shape: tf.TensorShape):
     if self._batch_norm_first:
       self._batch_norm_0 = self._norm(
           axis=self._bn_axis,
           momentum=self._norm_momentum,
-          epsilon=self._norm_epsilon)
-    self._conv2d_1 = tf.keras.layers.Conv2D(
+          epsilon=self._norm_epsilon,
+          synchronized=self._use_sync_bn,
+      )
+    self._conv2d_1 = tf_keras.layers.Conv2D(
         filters=self.filters,
         kernel_size=1,
         strides=self.strides,
         use_bias=False,
         padding='same',
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer)
     self._batch_norm_1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
-    self._conv2d_2 = tf.keras.layers.Conv2D(
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
+    self._conv2d_2 = tf_keras.layers.Conv2D(
         filters=self.filters,
         kernel_size=3,
         strides=1,
         use_bias=False,
         padding='same',
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer)
     self._batch_norm_2 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
-    self._conv2d_3 = tf.keras.layers.Conv2D(
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
+    self._conv2d_3 = tf_keras.layers.Conv2D(
         filters=self.filters * 4,
         kernel_size=1,
         strides=1,
         use_bias=False,
         padding='same',
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer)
@@ -1022,50 +1036,50 @@
     x = self._batch_norm_2(x, training=training)
     x = self._activation_fn(x)
     x = self._conv2d_3(x)
 
     return x
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ReversibleLayer(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ReversibleLayer(tf_keras.layers.Layer):
   """Creates a reversible layer.
 
   Computes y1 = x1 + f(x2), y2 = x2 + g(y1), where f and g can be arbitrary
   layers that are stateless, which in this case are `ResidualInner` layers.
   """
 
   def __init__(self,
-               f: tf.keras.layers.Layer,
-               g: tf.keras.layers.Layer,
+               f: tf_keras.layers.Layer,
+               g: tf_keras.layers.Layer,
                manual_grads: bool = True,
                **kwargs):
     """Initializes a ReversibleLayer.
 
     Args:
-      f: A `tf.keras.layers.Layer` instance of `f` inner block referred to in
+      f: A `tf_keras.layers.Layer` instance of `f` inner block referred to in
         paper. Each reversible layer consists of two inner functions. For
         example, in RevNet the reversible residual consists of two f/g inner
         (bottleneck) residual functions. Where the input to the reversible layer
         is x, the input gets partitioned in the channel dimension and the
         forward pass follows (eq8): x = [x1; x2], z1 = x1 + f(x2), y2 = x2 +
         g(z1), y1 = stop_gradient(z1).
-      g: A `tf.keras.layers.Layer` instance of `g` inner block referred to in
+      g: A `tf_keras.layers.Layer` instance of `g` inner block referred to in
         paper. Detailed explanation same as above as `f` arg.
       manual_grads: A `bool` [Testing Only] of whether to manually take
         gradients as in Algorithm 1 or defer to autograd.
       **kwargs: Additional keyword arguments to be passed.
     """
     super(ReversibleLayer, self).__init__(**kwargs)
 
     self._f = f
     self._g = g
     self._manual_grads = manual_grads
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._axis = -1
     else:
       self._axis = 1
 
   def get_config(self) -> Dict[str, Any]:
     config = {
         'f': self._f,
@@ -1198,28 +1212,28 @@
 
       return y, grad_fn  # reversible end
 
     activations = reversible(inputs)
     return activations
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class DepthwiseSeparableConvBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class DepthwiseSeparableConvBlock(tf_keras.layers.Layer):
   """Creates a depthwise separable convolution block with batch normalization.
   """
 
   def __init__(
       self,
       filters: int,
       kernel_size: int = 3,
       strides: int = 1,
       regularize_depthwise=False,
       activation: Text = 'relu6',
       kernel_initializer: Text = 'VarianceScaling',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       dilation_rate: int = 1,
       use_sync_bn: bool = False,
       norm_momentum: float = 0.99,
       norm_epsilon: float = 0.001,
       **kwargs):
     """Initializes a convolution block with batch normalization.
 
@@ -1231,15 +1245,15 @@
       strides: An `int` of block stride. If greater than 1, this block will
         ultimately downsample the input.
       regularize_depthwise: A `bool`. If Ture, apply regularization on
         depthwise.
       activation: A `str` name of the activation function.
       kernel_initializer: A `str` of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
       dilation_rate: An `int` or tuple/list of 2 `int`, specifying the dilation
         rate to use for dilated convolution. Can be a single integer to specify
         the same value for all spatial dimensions.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
@@ -1253,20 +1267,17 @@
     self._regularize_depthwise = regularize_depthwise
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._dilation_rate = dilation_rate
     self._use_sync_bn = use_sync_bn
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
+    self._norm = tf_keras.layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation_fn = tf_utils.get_activation(activation)
     if regularize_depthwise:
       self._depthsize_regularizer = kernel_regularizer
     else:
@@ -1285,55 +1296,59 @@
         'norm_epsilon': self._norm_epsilon
     }
     base_config = super(DepthwiseSeparableConvBlock, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def build(self, input_shape):
 
-    self._dwconv0 = tf.keras.layers.DepthwiseConv2D(
+    self._dwconv0 = tf_keras.layers.DepthwiseConv2D(
         kernel_size=self._kernel_size,
         strides=self._strides,
         padding='same',
         depth_multiplier=1,
         dilation_rate=self._dilation_rate,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._depthsize_regularizer,
         use_bias=False)
     self._norm0 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
 
-    self._conv1 = tf.keras.layers.Conv2D(
+    self._conv1 = tf_keras.layers.Conv2D(
         filters=self._filters,
         kernel_size=1,
         strides=1,
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer)
     self._norm1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
 
     super(DepthwiseSeparableConvBlock, self).build(input_shape)
 
   def call(self, inputs, training=None):
     x = self._dwconv0(inputs)
     x = self._norm0(x)
     x = self._activation_fn(x)
 
     x = self._conv1(x)
     x = self._norm1(x)
     return self._activation_fn(x)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class TuckerConvBlock(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class TuckerConvBlock(tf_keras.layers.Layer):
   """An Tucker block (generalized bottleneck)."""
 
   def __init__(self,
                in_filters,
                out_filters,
                input_compression_ratio,
                output_compression_ratio,
@@ -1362,17 +1377,17 @@
       strides: An `int` block stride. If greater than 1, this block will
         ultimately downsample the input.
       kernel_size: An `int` kernel_size of the depthwise conv layer.
       stochastic_depth_drop_rate: A `float` or None. if not None, drop rate for
         the stochastic depth layer.
       kernel_initializer: A `str` of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2d.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2d.
         Default to None.
       activation: A `str` name of the activation function.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       divisible_by: An `int` that ensures all inner dimensions are divisible by
         this number.
       use_residual: A `bool` of whether to include residual connection between
         input and output.
@@ -1394,88 +1409,91 @@
     self._use_residual = use_residual
     self._activation = activation
     self._kernel_initializer = kernel_initializer
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
+    self._norm = tf_keras.layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
 
   def build(self, input_shape):
     input_compressed_filters = nn_layers.make_divisible(
         value=self._in_filters * self._input_compression_ratio,
         divisor=self._divisible_by,
         round_down_protect=False)
 
-    self._conv0 = tf.keras.layers.Conv2D(
+    self._conv0 = tf_keras.layers.Conv2D(
         filters=input_compressed_filters,
         kernel_size=1,
         strides=1,
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm0 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
     self._activation_layer0 = tf_utils.get_activation(
         self._activation, use_keras_layer=True)
 
     output_compressed_filters = nn_layers.make_divisible(
         value=self._out_filters * self._output_compression_ratio,
         divisor=self._divisible_by,
         round_down_protect=False)
 
-    self._conv1 = tf.keras.layers.Conv2D(
+    self._conv1 = tf_keras.layers.Conv2D(
         filters=output_compressed_filters,
         kernel_size=self._kernel_size,
         strides=self._strides,
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
     self._activation_layer1 = tf_utils.get_activation(
         self._activation, use_keras_layer=True)
 
     # Last 1x1 conv.
-    self._conv2 = tf.keras.layers.Conv2D(
+    self._conv2 = tf_keras.layers.Conv2D(
         filters=self._out_filters,
         kernel_size=1,
         strides=1,
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm2 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn,
+    )
 
     if self._stochastic_depth_drop_rate:
       self._stochastic_depth = nn_layers.StochasticDepth(
           self._stochastic_depth_drop_rate)
     else:
       self._stochastic_depth = None
-    self._add = tf.keras.layers.Add()
+    self._add = tf_keras.layers.Add()
 
     super(TuckerConvBlock, self).build(input_shape)
 
   def get_config(self):
     config = {
         'in_filters': self._in_filters,
         'out_filters': self._out_filters,
@@ -1516,109 +1534,348 @@
       if self._stochastic_depth:
         x = self._stochastic_depth(x, training=training)
       x = self._add([x, shortcut])
 
     return x
 
 
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class LayerScale(tf_keras.layers.Layer):
+  """LayerScale as introduced in CaiT: https://arxiv.org/abs/2103.17239.
+
+  Attributes:
+      init_values (float): value to initialize the diagonal matrix of
+        LayerScale.
+  """
+
+  def __init__(self, init_values: float, **kwargs):
+    """Initializes LayerScale."""
+    super().__init__(**kwargs)
+    self.gamma_init_value = init_values
+
+  def build(self, inputs_shape):
+    gamma_shape = (1, 1, inputs_shape[2])
+    self.gamma = self.add_weight(
+        name='layerscale_gamma',
+        shape=gamma_shape,
+        initializer=tf_keras.initializers.Constant(self.gamma_init_value),
+        trainable=True,
+        dtype=tf.float32,
+    )
+
+  def call(self, inputs, inputs_positions=None):
+    del inputs_positions
+    return tf.cast(self.gamma, inputs.dtype) * inputs
+
+
+@tf_keras.utils.register_keras_serializable(package='Vision')
 class TransformerEncoderBlock(nlp_modeling.layers.TransformerEncoderBlock):
-  """TransformerEncoderBlock layer with stochastic depth."""
+  """TransformerEncoderBlock layer with stochastic depth and layerscale."""
 
-  def __init__(self,
-               *args,
-               stochastic_depth_drop_rate=0.0,
-               return_attention=False,
-               **kwargs):
-    """Initializes TransformerEncoderBlock."""
+  def __init__(
+      self,
+      *args,
+      stochastic_depth_drop_rate=0.0,
+      layer_scale_init_value=0.0,
+      transformer_partition_dims=None,
+      max_attention_inference_parallelism=None,
+      **kwargs
+  ):
+    """Initializes TransformerEncoderBlock.
+
+    Args:
+      *args: positional arguments passed to super().__init__.
+      stochastic_depth_drop_rate: the drop rate for the stochastic depth layer.
+      layer_scale_init_value:
+      transformer_partition_dims: transformer spatial partition dimenstions.
+      max_attention_inference_parallelism: the number of examples to run in
+        parallel in the attention blocks during inference. Set this limit to
+        reduce the peak memory usage. If None, use vectorized operations to run
+        the whole batch in parallel.
+      **kwargs: keyword arguments passed to super().__init__.
+    """
     super().__init__(*args, **kwargs)
     self._stochastic_depth_drop_rate = stochastic_depth_drop_rate
-    self._return_attention = return_attention
+    self._layer_scale_init_value = layer_scale_init_value
+    self._transformer_partition_dims = transformer_partition_dims
+    self._max_attention_inference_parallelism = (
+        max_attention_inference_parallelism
+    )
 
   def build(self, input_shape):
+    super().build(input_shape)
+
     if self._stochastic_depth_drop_rate:
       self._stochastic_depth = nn_layers.StochasticDepth(
           self._stochastic_depth_drop_rate)
     else:
       self._stochastic_depth = lambda x, *args, **kwargs: tf.identity(x)
 
-    super().build(input_shape)
+    if self._layer_scale_init_value:
+      self._layer_scale_attn = LayerScale(
+          init_values=self._layer_scale_init_value, name='layer_scale_attn')
+      self._layer_scale_mlp = LayerScale(
+          init_values=self._layer_scale_init_value, name='layer_scale_mlp')
+    else:
+      self._layer_scale_attn = lambda x, *args, **kwargs: tf.identity(x)
+      self._layer_scale_mlp = lambda x, *args, **kwargs: tf.identity(x)
+
+    self._attention_layer = nn_layers.MultiHeadAttention(
+        num_heads=self._num_heads,
+        key_dim=self._key_dim,
+        value_dim=self._value_dim,
+        dropout=self._attention_dropout_rate,
+        use_bias=self._use_bias,
+        kernel_initializer=self._attention_initializer,
+        bias_initializer=tf_utils.clone_initializer(self._bias_initializer),
+        attention_axes=self._attention_axes,
+        output_shape=self._output_last_dim,
+        bias_regularizer=self._bias_regularizer,
+        activity_regularizer=self._activity_regularizer,
+        kernel_constraint=self._kernel_constraint,
+        bias_constraint=self._bias_constraint,
+        max_inference_parallelism=self._max_attention_inference_parallelism,
+        partition_dims=self._transformer_partition_dims,
+        name='self_attention',
+    )
 
   def get_config(self):
-    config = {'stochastic_depth_drop_rate': self._stochastic_depth_drop_rate}
-    base_config = super().get_config()
-    return dict(list(base_config.items()) + list(config.items()))
+    config = super().get_config()
+    config.update({
+        'stochastic_depth_drop_rate': self._stochastic_depth_drop_rate,
+        'layer_scale_init_value': self._layer_scale_init_value,
+        'transformer_partition_dims': self._transformer_partition_dims,
+        'max_attention_inference_parallelism': (
+            self._max_attention_inference_parallelism
+        ),
+    })
+    return config
 
-  def call(self, inputs, training=None):
+  def call(self, inputs, output_range=None, training=None):
     """Transformer self-attention encoder block call."""
     if isinstance(inputs, (list, tuple)):
       if len(inputs) == 2:
         input_tensor, attention_mask = inputs
         key_value = None
       elif len(inputs) == 3:
         input_tensor, key_value, attention_mask = inputs
       else:
         raise ValueError('Unexpected inputs to %s with length at %d' %
                          (self.__class__, len(inputs)))
     else:
       input_tensor, key_value, attention_mask = (inputs, None, None)
 
-    if self._output_range:
+    if output_range is None:
+      output_range = self._output_range
+    if output_range:
       if self._norm_first:
-        source_tensor = input_tensor[:, 0:self._output_range, :]
+        source_tensor = input_tensor[:, 0:output_range, :]
         input_tensor = self._attention_layer_norm(input_tensor)
         if key_value is not None:
           key_value = self._attention_layer_norm(key_value)
-      target_tensor = input_tensor[:, 0:self._output_range, :]
+      target_tensor = input_tensor[:, 0:output_range, :]
       if attention_mask is not None:
-        attention_mask = attention_mask[:, 0:self._output_range, :]
+        attention_mask = attention_mask[:, 0:output_range, :]
     else:
       if self._norm_first:
         source_tensor = input_tensor
         input_tensor = self._attention_layer_norm(input_tensor)
         if key_value is not None:
           key_value = self._attention_layer_norm(key_value)
       target_tensor = input_tensor
 
     if key_value is None:
       key_value = input_tensor
+
     attention_output, attention_scores = self._attention_layer(
         query=target_tensor,
         value=key_value,
         attention_mask=attention_mask,
         return_attention_scores=True)
     attention_output = self._attention_dropout(attention_output)
 
-    if self._norm_first:
-      attention_output = source_tensor + self._stochastic_depth(
-          attention_output, training=training)
-    else:
-      attention_output = self._attention_layer_norm(
-          target_tensor +
-          self._stochastic_depth(attention_output, training=training))
+    attention_output = self._layer_scale_attn(attention_output)
 
     if self._norm_first:
+      # Important to not combine `self._norm_first` and
+      # `self._use_query_residual` into one if clause because else is only for
+      # `_norm_first == False`.
+      if self._use_query_residual:
+        attention_output = source_tensor + self._stochastic_depth(
+            attention_output, training=training)
       source_attention_output = attention_output
       attention_output = self._output_layer_norm(attention_output)
+    else:
+      if self._use_query_residual:
+        attention_output = target_tensor + self._stochastic_depth(
+            attention_output, training=training)
+      attention_output = self._attention_layer_norm(attention_output)
+
     inner_output = self._intermediate_dense(attention_output)
     inner_output = self._intermediate_activation_layer(inner_output)
     inner_output = self._inner_dropout_layer(inner_output)
     layer_output = self._output_dense(inner_output)
     layer_output = self._output_dropout(layer_output)
 
+    # Layerscale after MLP.
+    layer_output = self._layer_scale_mlp(layer_output)
+
     if self._norm_first:
-      if self._return_attention:
-        return source_attention_output + self._stochastic_depth(
-            layer_output, training=training), attention_scores
+      layer_output = source_attention_output + self._stochastic_depth(
+          layer_output, training=training)
+    else:
+      # During mixed precision training, layer norm output is always fp32 for
+      # now. Casts fp32 for the subsequent add.
+      layer_output = tf.cast(layer_output, tf.float32)
+      layer_output = self._output_layer_norm(
+          layer_output
+          + self._stochastic_depth(attention_output, training=training))
+
+    if self._return_attention_scores:
+      return layer_output, attention_scores
+    else:
+      return layer_output
+
+
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class TransformerScaffold(nlp_modeling.layers.TransformerScaffold):
+  """TransformerScaffold layer for vision applications."""
+
+  def __init__(
+      self,
+      *args,
+      stochastic_depth_drop_rate: float = 0.0,
+      return_attention_scores: bool = False,
+      ffn_has_residual_connection: bool = False,
+      max_attention_inference_parallelism: Optional[int] = None,
+      **kwargs
+  ):
+    """Initializes TransformerEncoderBlock.
+
+    Args:
+      *args: positional arguments passed to super().__init__.
+      stochastic_depth_drop_rate: the drop rate for the stochastic depth layer.
+      return_attention_scores: whether to return the attention output.
+      ffn_has_residual_connection: whether the feedforward network has internal
+        residual connection and layer norm. If False, the residual connection
+        and the layer norm op are called inside TransformerScaffold.
+      max_attention_inference_parallelism: the number of examples to run in
+        parallel in the attention blocks during inference. Set this limit to
+        reduce the peak memory usage. If None, use vectorized operations to run
+        the whole batch in parallel.
+      **kwargs: keyword arguments passed to super().__init__.
+    """
+    super().__init__(*args, **kwargs)
+    self._stochastic_depth_drop_rate = stochastic_depth_drop_rate
+    self._return_attention_scores = return_attention_scores
+    self._ffn_has_residual_connection = ffn_has_residual_connection
+    self._max_attention_inference_parallelism = (
+        max_attention_inference_parallelism
+    )
+
+  def build(self, input_shape: Union[tf.TensorShape, List[int]]):
+    if self._stochastic_depth_drop_rate:
+      self._stochastic_depth = nn_layers.StochasticDepth(
+          self._stochastic_depth_drop_rate)
+    else:
+      self._stochastic_depth = lambda x, *args, **kwargs: tf.identity(x)
+
+    super().build(input_shape)
+
+    if self._max_attention_inference_parallelism is not None:
+      attention_layer_config = self._attention_layer.get_config()
+      self._attention_layer = self._attention_cls.from_config({
+          **attention_layer_config,
+          'max_inference_parallelism': (
+              self._max_attention_inference_parallelism
+          ),
+      })
+
+  def get_config(self):
+    config = super().get_config()
+    config.update({
+        'stochastic_depth_drop_rate': self._stochastic_depth_drop_rate,
+        'return_attention_scores': self._return_attention_scores,
+        'ffn_has_residual_connection': self._ffn_has_residual_connection,
+        'max_attention_inference_parallelism': (
+            self._max_attention_inference_parallelism
+        ),
+    })
+    return config
+
+  def call(
+      self,
+      inputs: tf.Tensor,
+      training: Optional[bool] = None
+  ) -> Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]]:
+    """Transformer self-attention encoder block call."""
+    if isinstance(inputs, (list, tuple)):
+      if len(inputs) == 2:
+        input_tensor, attention_mask = inputs
+        key_value = None
+      elif len(inputs) == 3:
+        input_tensor, key_value, attention_mask = inputs
       else:
-        return source_attention_output + self._stochastic_depth(
-            layer_output, training=training)
+        raise ValueError('Unexpected inputs to %s with length at %d' %
+                         (self.__class__, len(inputs)))
+    else:
+      input_tensor, key_value, attention_mask = (inputs, None, None)
+
+    if self._norm_first:
+      source_tensor = input_tensor
+      input_tensor = self._attention_layer_norm(input_tensor)
+
+    if key_value is None:
+      key_value = input_tensor
 
-    # During mixed precision training, layer norm output is always fp32 for now.
-    # Casts fp32 for the subsequent add.
-    layer_output = tf.cast(layer_output, tf.float32)
-    if self._return_attention:
-      return self._output_layer_norm(layer_output + self._stochastic_depth(
-          attention_output, training=training)), attention_scores
+    attention_output, attention_scores = self._attention_layer(
+        query=input_tensor,
+        value=key_value,
+        attention_mask=attention_mask,
+        training=training,
+        return_attention_scores=True)
+    attention_output = self._attention_dropout(
+        attention_output, training=training)
+
+    if self._norm_first:
+      source_attention_output = source_tensor + self._stochastic_depth(
+          attention_output, training=training)
+      attention_output = self._output_layer_norm(
+          source_attention_output)
     else:
-      return self._output_layer_norm(
-          layer_output +
+      attention_output = self._attention_layer_norm(
+          input_tensor +
           self._stochastic_depth(attention_output, training=training))
+
+    if self._feedforward_block is None:
+      intermediate_output = self._intermediate_dense(attention_output)
+      intermediate_output = self._intermediate_activation_layer(
+          intermediate_output)
+      layer_output = self._output_dense(intermediate_output)
+      layer_output = self._output_dropout(layer_output, training=training)
+    else:
+      layer_output = self._feedforward_block(
+          attention_output, training=training)
+
+    if self._norm_first:
+      if self._ffn_has_residual_connection:
+        raise ValueError(
+            'In the case of `norm_first`, the residual connection should be'
+            "done in the TransformerScaffold call function, not FFN's"
+            'call function.')
+      output = source_attention_output + self._stochastic_depth(
+          layer_output, training=training)
+    else:
+      # During mixed precision training, layer norm output is always fp32 for
+      # now. Casts fp32 for the subsequent add.
+      layer_output = tf.cast(layer_output, tf.float32)
+      if self._ffn_has_residual_connection:
+        output = self._stochastic_depth(layer_output, training=training)
+      else:
+        output = self._output_layer_norm(
+            attention_output +
+            self._stochastic_depth(layer_output, training=training))
+
+    if self._return_attention_scores:
+      return output, attention_scores
+    else:
+      return output
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_blocks_3d.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_blocks_3d.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,22 +10,22 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains common building blocks for 3D networks."""
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.vision.modeling.layers import nn_layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class SelfGating(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SelfGating(tf_keras.layers.Layer):
   """Feature gating as used in S3D-G.
 
   This implements the S3D-G network from:
   Saining Xie, Chen Sun, Jonathan Huang, Zhuowen Tu, Kevin Murphy.
   Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video
   Classification.
   (https://arxiv.org/pdf/1712.04851.pdf)
@@ -38,22 +38,22 @@
       filters: An `int` number of filters for the convolutional layer.
       **kwargs: Additional keyword arguments to be passed.
     """
     super(SelfGating, self).__init__(**kwargs)
     self._filters = filters
 
   def build(self, input_shape):
-    self._spatial_temporal_average = tf.keras.layers.GlobalAveragePooling3D()
+    self._spatial_temporal_average = tf_keras.layers.GlobalAveragePooling3D()
 
     # No BN and activation after conv.
-    self._transformer_w = tf.keras.layers.Conv3D(
+    self._transformer_w = tf_keras.layers.Conv3D(
         filters=self._filters,
         kernel_size=[1, 1, 1],
         use_bias=True,
-        kernel_initializer=tf.keras.initializers.TruncatedNormal(
+        kernel_initializer=tf_keras.initializers.TruncatedNormal(
             mean=0.0, stddev=0.01))
 
     super(SelfGating, self).build(input_shape)
 
   def call(self, inputs):
     x = self._spatial_temporal_average(inputs)
 
@@ -63,16 +63,16 @@
 
     x = self._transformer_w(x)
     x = tf.nn.sigmoid(x)
 
     return tf.math.multiply(x, inputs)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class BottleneckBlock3D(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class BottleneckBlock3D(tf_keras.layers.Layer):
   """Creates a 3D bottleneck block."""
 
   def __init__(self,
                filters,
                temporal_kernel_size,
                temporal_strides,
                spatial_strides,
@@ -100,17 +100,17 @@
         layer.
       stochastic_depth_drop_rate: A `float` or None. If not None, drop rate for
         the stochastic depth layer.
       se_ratio: A `float` or None. Ratio of the Squeeze-and-Excitation layer.
       use_self_gating: A `bool` of whether to apply self-gating module or not.
       kernel_initializer: A `str` of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2d.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2d.
         Default to None.
       activation: A `str` name of the activation function.
       use_sync_bn: A `bool`. If True, use synchronized batch normalization.
       norm_momentum: A `float` of normalization momentum for the moving average.
       norm_epsilon: A `float` added to variance to avoid dividing by zero.
       **kwargs: Additional keyword arguments to be passed.
     """
@@ -126,88 +126,89 @@
     self._use_sync_bn = use_sync_bn
     self._activation = activation
     self._kernel_initializer = kernel_initializer
     self._norm_momentum = norm_momentum
     self._norm_epsilon = norm_epsilon
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
+    self._norm = tf_keras.layers.BatchNormalization
 
-    if use_sync_bn:
-      self._norm = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._norm = tf.keras.layers.BatchNormalization
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
     self._activation_fn = tf_utils.get_activation(activation)
 
   def build(self, input_shape):
-    self._shortcut_maxpool = tf.keras.layers.MaxPool3D(
+    self._shortcut_maxpool = tf_keras.layers.MaxPool3D(
         pool_size=[1, 1, 1],
         strides=[
             self._temporal_strides, self._spatial_strides, self._spatial_strides
         ])
 
-    self._shortcut_conv = tf.keras.layers.Conv3D(
+    self._shortcut_conv = tf_keras.layers.Conv3D(
         filters=4 * self._filters,
         kernel_size=1,
         strides=[
             self._temporal_strides, self._spatial_strides, self._spatial_strides
         ],
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm0 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)
 
-    self._temporal_conv = tf.keras.layers.Conv3D(
+    self._temporal_conv = tf_keras.layers.Conv3D(
         filters=self._filters,
         kernel_size=[self._temporal_kernel_size, 1, 1],
         strides=[self._temporal_strides, 1, 1],
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm1 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)
 
-    self._spatial_conv = tf.keras.layers.Conv3D(
+    self._spatial_conv = tf_keras.layers.Conv3D(
         filters=self._filters,
         kernel_size=[1, 3, 3],
         strides=[1, self._spatial_strides, self._spatial_strides],
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm2 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)
 
-    self._expand_conv = tf.keras.layers.Conv3D(
+    self._expand_conv = tf_keras.layers.Conv3D(
         filters=4 * self._filters,
         kernel_size=[1, 1, 1],
         strides=[1, 1, 1],
         padding='same',
         use_bias=False,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
     self._norm3 = self._norm(
         axis=self._bn_axis,
         momentum=self._norm_momentum,
-        epsilon=self._norm_epsilon)
+        epsilon=self._norm_epsilon,
+        synchronized=self._use_sync_bn)
 
     if self._se_ratio and self._se_ratio > 0 and self._se_ratio <= 1:
       self._squeeze_excitation = nn_layers.SqueezeExcitation(
           in_filters=self._filters * 4,
           out_filters=self._filters * 4,
           se_ratio=self._se_ratio,
           use_3d_input=True,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_blocks_3d_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_blocks_3d_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for resnet."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.layers import nn_blocks_3d
 
 
 class NNBlocksTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
@@ -30,15 +30,15 @@
   def test_bottleneck_block_creation(self, block_fn, temporal_kernel_size,
                                      temporal_strides, spatial_strides,
                                      use_self_gating, se_ratio,
                                      stochastic_depth):
     temporal_size = 16
     spatial_size = 128
     filters = 256
-    inputs = tf.keras.Input(
+    inputs = tf_keras.Input(
         shape=(temporal_size, spatial_size, spatial_size, filters * 4),
         batch_size=1)
     block = block_fn(
         filters=filters,
         temporal_kernel_size=temporal_kernel_size,
         temporal_strides=temporal_strides,
         spatial_strides=spatial_strides,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_layers.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_layers.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains common building blocks for neural networks."""
+
 from typing import Any, Callable, Dict, List, Mapping, Optional, Tuple, Union
 
 from absl import logging
-import tensorflow as tf
-import tensorflow_addons as tfa
+import tensorflow as tf, tf_keras
 
 from official.modeling import tf_utils
 from official.vision.ops import spatial_transform_ops
 
 
 # Type annotations.
 States = Dict[str, tf.Tensor]
@@ -81,16 +81,16 @@
   elif kernel_size == 3:
     return (1, 1)
   else:
     raise ValueError('Padding for kernel size {} not known.'.format(
         kernel_size))
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class SqueezeExcitation(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SqueezeExcitation(tf_keras.layers.Layer):
   """Creates a squeeze and excitation layer."""
 
   def __init__(self,
                in_filters,
                out_filters,
                se_ratio,
                divisible_by=1,
@@ -110,17 +110,17 @@
       se_ratio: A `float` or None. If not None, se ratio for the squeeze and
         excitation layer.
       divisible_by: An `int` that ensures all inner dimensions are divisible by
         this number.
       use_3d_input: A `bool` of whether input is 2D or 3D image.
       kernel_initializer: A `str` of kernel_initializer for convolutional
         layers.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default to None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2d.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2d.
         Default to None.
       activation: A `str` name of the activation function.
       gating_activation: A `str` name of the activation function for final
         gating function.
       round_down_protect: A `bool` of whether round down more than 10% will be
         allowed.
       **kwargs: Additional keyword arguments to be passed.
@@ -134,15 +134,15 @@
     self._round_down_protect = round_down_protect
     self._use_3d_input = use_3d_input
     self._activation = activation
     self._gating_activation = gating_activation
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       if not use_3d_input:
         self._spatial_axis = [1, 2]
       else:
         self._spatial_axis = [1, 2, 3]
     else:
       if not use_3d_input:
         self._spatial_axis = [2, 3]
@@ -153,25 +153,25 @@
 
   def build(self, input_shape):
     num_reduced_filters = make_divisible(
         max(1, int(self._in_filters * self._se_ratio)),
         divisor=self._divisible_by,
         round_down_protect=self._round_down_protect)
 
-    self._se_reduce = tf.keras.layers.Conv2D(
+    self._se_reduce = tf_keras.layers.Conv2D(
         filters=num_reduced_filters,
         kernel_size=1,
         strides=1,
         padding='same',
         use_bias=True,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)
 
-    self._se_expand = tf.keras.layers.Conv2D(
+    self._se_expand = tf_keras.layers.Conv2D(
         filters=self._out_filters,
         kernel_size=1,
         strides=1,
         padding='same',
         use_bias=True,
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
@@ -219,16 +219,16 @@
       raise ValueError('Initial drop rate must be within 0 and 1.')
     rate = init_rate * float(i) / n
   else:
     rate = None
   return rate
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class StochasticDepth(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class StochasticDepth(tf_keras.layers.Layer):
   """Creates a stochastic depth layer."""
 
   def __init__(self, stochastic_depth_drop_rate, **kwargs):
     """Initializes a stochastic depth layer.
 
     Args:
       stochastic_depth_drop_rate: A `float` of drop rate.
@@ -243,29 +243,29 @@
   def get_config(self):
     config = {'stochastic_depth_drop_rate': self._drop_rate}
     base_config = super(StochasticDepth, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def call(self, inputs, training=None):
     if training is None:
-      training = tf.keras.backend.learning_phase()
+      training = tf_keras.backend.learning_phase()
     if not training or self._drop_rate is None or self._drop_rate == 0:
       return inputs
 
     keep_prob = 1.0 - self._drop_rate
     batch_size = tf.shape(inputs)[0]
     random_tensor = keep_prob
     random_tensor += tf.random.uniform(
         [batch_size] + [1] * (inputs.shape.rank - 1), dtype=inputs.dtype)
     binary_tensor = tf.floor(random_tensor)
     output = tf.math.divide(inputs, keep_prob) * binary_tensor
     return output
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
+@tf_keras.utils.register_keras_serializable(package='Vision')
 def pyramid_feature_fusion(inputs, target_level):
   """Fuses all feature maps in the feature pyramid at the target level.
 
   Args:
     inputs: A dictionary containing the feature pyramid. The size of the input
       tensor needs to be fixed.
     target_level: An `int` of the target feature level for feature fusion.
@@ -295,15 +295,15 @@
       # Casts it back to be compatible with the rest opetations.
       feat = tf.cast(feat, pyramid_feats[l].dtype)
       resampled_feats.append(feat)
 
   return tf.math.add_n(resampled_feats)
 
 
-class PanopticFPNFusion(tf.keras.Model):
+class PanopticFPNFusion(tf_keras.Model):
   """Creates a Panoptic FPN feature Fusion layer.
 
   This implements feature fusion for semantic segmentation head from the paper:
   Alexander Kirillov, Ross Girshick, Kaiming He and Piotr Dollar.
   Panoptic Feature Pyramid Networks.
   (https://arxiv.org/pdf/1901.02446.pdf)
   """
@@ -312,30 +312,30 @@
       self,
       min_level: int = 2,
       max_level: int = 5,
       target_level: int = 2,
       num_filters: int = 128,
       num_fpn_filters: int = 256,
       activation: str = 'relu',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
 
     """Initializes panoptic FPN feature fusion layer.
 
     Args:
       min_level: An `int` of minimum level to use in feature fusion.
       max_level: An `int` of maximum level to use in feature fusion.
       target_level: An `int` of the target feature level for feature fusion.
       num_filters: An `int` number of filters in conv2d layers.
       num_fpn_filters: An `int` number of filters in the FPN outputs
       activation: A `str` name of the activation function.
-      kernel_regularizer: A `tf.keras.regularizers.Regularizer` object for
+      kernel_regularizer: A `tf_keras.regularizers.Regularizer` object for
         Conv2D. Default is None.
-      bias_regularizer: A `tf.keras.regularizers.Regularizer` object for Conv2D.
+      bias_regularizer: A `tf_keras.regularizers.Regularizer` object for Conv2D.
       **kwargs: Additional keyword arguments to be passed.
     Returns:
       A `float` `tf.Tensor` of shape [batch_size, feature_height, feature_width,
         feature_channel].
     """
     if target_level > max_level:
       raise ValueError('target_level should be less than max_level')
@@ -346,33 +346,33 @@
         'target_level': target_level,
         'num_filters': num_filters,
         'num_fpn_filters': num_fpn_filters,
         'activation': activation,
         'kernel_regularizer': kernel_regularizer,
         'bias_regularizer': bias_regularizer,
     }
-    norm = tfa.layers.GroupNormalization
-    conv2d = tf.keras.layers.Conv2D
+    norm = tf_keras.layers.GroupNormalization
+    conv2d = tf_keras.layers.Conv2D
     activation_fn = tf_utils.get_activation(activation)
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       norm_axis = -1
     else:
       norm_axis = 1
     inputs = self._build_inputs(num_fpn_filters, min_level, max_level)
 
     upscaled_features = []
     for level in range(min_level, max_level + 1):
       num_conv_layers = max(1, level - target_level)
       x = inputs[str(level)]
       for i in range(num_conv_layers):
         x = conv2d(
             filters=num_filters,
             kernel_size=3,
             padding='same',
-            kernel_initializer=tf.keras.initializers.VarianceScaling(),
+            kernel_initializer=tf_keras.initializers.VarianceScaling(),
             kernel_regularizer=kernel_regularizer,
             bias_regularizer=bias_regularizer)(x)
         x = norm(groups=32, axis=norm_axis)(x)
         x = activation_fn(x)
         if level != target_level:
           x = spatial_transform_ops.nearest_upsampling(x, scale=2)
       upscaled_features.append(x)
@@ -383,15 +383,15 @@
     super(PanopticFPNFusion, self).__init__(
         inputs=inputs, outputs=fused_features, **kwargs)
 
   def _build_inputs(self, num_filters: int,
                     min_level: int, max_level: int):
     inputs = {}
     for level in range(min_level, max_level + 1):
-      inputs[str(level)] = tf.keras.Input(shape=[None, None, num_filters])
+      inputs[str(level)] = tf_keras.Input(shape=[None, None, num_filters])
     return inputs
 
   def get_config(self) -> Mapping[str, Any]:
     return self._config_dict
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
@@ -399,34 +399,34 @@
 
   @property
   def output_specs(self) -> Mapping[str, tf.TensorShape]:
     """A dict of {level: TensorShape} pairs for the model output."""
     return self._output_specs
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class Scale(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class Scale(tf_keras.layers.Layer):
   """Scales the input by a trainable scalar weight.
 
   This is useful for applying ReZero to layers, which improves convergence
   speed. This implements the paper:
   ReZero is All You Need: Fast Convergence at Large Depth.
   (https://arxiv.org/pdf/2003.04887.pdf).
   """
 
   def __init__(
       self,
-      initializer: tf.keras.initializers.Initializer = 'ones',
-      regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      initializer: tf_keras.initializers.Initializer = 'ones',
+      regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       **kwargs):
     """Initializes a scale layer.
 
     Args:
       initializer: A `str` of initializer for the scalar weight.
-      regularizer: A `tf.keras.regularizers.Regularizer` for the scalar weight.
+      regularizer: A `tf_keras.regularizers.Regularizer` for the scalar weight.
       **kwargs: Additional keyword arguments to be passed to this layer.
 
     Returns:
       An `tf.Tensor` of which should have the same shape as input.
     """
     super(Scale, self).__init__(**kwargs)
 
@@ -452,16 +452,16 @@
 
   def call(self, inputs):
     """Calls the layer with the given inputs."""
     scale = tf.cast(self._scale, inputs.dtype)
     return scale * inputs
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class TemporalSoftmaxPool(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class TemporalSoftmaxPool(tf_keras.layers.Layer):
   """Creates a network layer corresponding to temporal softmax pooling.
 
   This is useful for multi-class logits (used in e.g., Charades). Modified from
   AssembleNet Charades evaluation from:
 
   Michael S. Ryoo, AJ Piergiovanni, Mingxing Tan, Anelia Angelova.
   AssembleNet: Searching for Multi-Stream Neural Connectivity in Video
@@ -475,30 +475,30 @@
     frames = tf.shape(inputs)[1]
     pre_logits = inputs / tf.sqrt(tf.cast(frames, inputs.dtype))
     activations = tf.nn.softmax(pre_logits, axis=1)
     outputs = inputs * activations
     return outputs
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class PositionalEncoding(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class PositionalEncoding(tf_keras.layers.Layer):
   """Creates a network layer that adds a sinusoidal positional encoding.
 
   Positional encoding is incremented across frames, and is added to the input.
   The positional encoding is first weighted at 0 so that the network can choose
   to ignore it. This implements:
 
   Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
   Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin.
   Attention Is All You Need.
   (https://arxiv.org/pdf/1706.03762.pdf).
   """
 
   def __init__(self,
-               initializer: tf.keras.initializers.Initializer = 'zeros',
+               initializer: tf_keras.initializers.Initializer = 'zeros',
                cache_encoding: bool = False,
                state_prefix: Optional[str] = None,
                **kwargs):
     """Initializes positional encoding.
 
     Args:
       initializer: A `str` of initializer for weighting the positional encoding.
@@ -593,15 +593,15 @@
 
     Args:
       input_shape: The input shape.
 
     Raises:
       ValueError: If using 'channels_first' data format.
     """
-    if tf.keras.backend.image_data_format() == 'channels_first':
+    if tf_keras.backend.image_data_format() == 'channels_first':
       raise ValueError('"channels_first" mode is unsupported.')
 
     if self._cache_encoding:
       self._pos_encoding = self._get_pos_encoding(input_shape)
 
     super(PositionalEncoding, self).build(input_shape)
 
@@ -643,16 +643,16 @@
     pos_encoding = tf.cast(pos_encoding, inputs.dtype)
     pos_encoding = self._rezero(pos_encoding)
     outputs = inputs + pos_encoding
 
     return (outputs, states) if output_states else outputs
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class GlobalAveragePool3D(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class GlobalAveragePool3D(tf_keras.layers.Layer):
   """Creates a global average pooling layer with causal mode.
 
   Implements causal mode, which runs a cumulative sum (with `tf.cumsum`) across
   frames in the time dimension, allowing the use of a stream buffer. Sums any
   valid input state with the current input to allow state to accumulate over
   several iterations.
   """
@@ -712,24 +712,24 @@
 
     Returns:
       An output `tf.Tensor` (and optionally the states if `output_states=True`).
       If `causal=True`, the output tensor will have shape
       `[batch_size, num_frames, 1, 1, channels]` if `keepdims=True`. We keep
       the frame dimension in this case to simulate a cumulative global average
       as if we are inputting one frame at a time. If `causal=False`, the output
-      is equivalent to `tf.keras.layers.GlobalAveragePooling3D` with shape
+      is equivalent to `tf_keras.layers.GlobalAveragePooling3D` with shape
       `[batch_size, 1, 1, 1, channels]` if `keepdims=True` (plus the optional
       buffer stored in `states`).
 
     Raises:
       ValueError: If using 'channels_first' data format.
     """
     states = dict(states) if states is not None else {}
 
-    if tf.keras.backend.image_data_format() == 'channels_first':
+    if tf_keras.backend.image_data_format() == 'channels_first':
       raise ValueError('"channels_first" mode is unsupported.')
 
     # Shape: [batch_size, 1, 1, 1, channels]
     buffer = states.get(self._state_name, None)
     if buffer is None:
       buffer = tf.zeros_like(inputs[:, :1, :1, :1], dtype=inputs.dtype)
       states[self._state_name] = buffer
@@ -777,16 +777,16 @@
 
     if not self._keepdims:
       x = tf.squeeze(x, axis=(1, 2, 3))
 
     return (x, states) if output_states else x
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class SpatialAveragePool3D(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SpatialAveragePool3D(tf_keras.layers.Layer):
   """Creates a global average pooling layer pooling across spatial dimentions."""
 
   def __init__(self, keepdims: bool = False, **kwargs):
     """Initializes a global average pool layer.
 
     Args:
       keepdims: A `bool`. If True, keep the averaged dimensions.
@@ -804,15 +804,15 @@
         'keepdims': self._keepdims,
     }
     base_config = super(SpatialAveragePool3D, self).get_config()
     return dict(list(base_config.items()) + list(config.items()))
 
   def build(self, input_shape):
     """Builds the layer with the given input shape."""
-    if tf.keras.backend.image_data_format() == 'channels_first':
+    if tf_keras.backend.image_data_format() == 'channels_first':
       raise ValueError('"channels_first" mode is unsupported.')
 
     super(SpatialAveragePool3D, self).build(input_shape)
 
   def call(self, inputs, states=None, output_states: bool = False):
     """Calls the layer with the given inputs."""
     if inputs.shape.rank != 5:
@@ -820,15 +820,15 @@
           'Input should have rank {}, got {}'.format(5, inputs.shape.rank))
 
     output = tf.reduce_mean(inputs, axis=(2, 3), keepdims=self._keepdims)
     return (output, states) if output_states else output
 
 
 class CausalConvMixin:
-  """Mixin class to implement CausalConv for `tf.keras.layers.Conv` layers."""
+  """Mixin class to implement CausalConv for `tf_keras.layers.Conv` layers."""
 
   @property
   def use_buffered_input(self) -> bool:
     return self._use_buffered_input
 
   @use_buffered_input.setter
   def use_buffered_input(self, variable: bool):
@@ -848,15 +848,15 @@
       time_axis: An `int` of the axis of the time dimension.
 
     Returns:
       A list of paddings for `tf.pad`.
     """
     input_shape = tf.shape(inputs)[1:-1]
 
-    if tf.keras.backend.image_data_format() == 'channels_first':
+    if tf_keras.backend.image_data_format() == 'channels_first':
       raise ValueError('"channels_first" mode is unsupported.')
 
     kernel_size_effective = [
         (self.kernel_size[i] +
          (self.kernel_size[i] - 1) * (self.dilation_rate[i] - 1))
         for i in range(self.rank)
     ]
@@ -898,19 +898,19 @@
     if self._use_buffered_input and spatial_output_shape[0] is not None:
       padding = self._compute_buffered_causal_padding(
           tf.zeros([1] + spatial_output_shape + [1]), use_buffered_input=False)
       spatial_output_shape[0] -= sum(padding[1])
     return spatial_output_shape
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class Conv2D(tf.keras.layers.Conv2D, CausalConvMixin):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class Conv2D(tf_keras.layers.Conv2D, CausalConvMixin):
   """Conv2D layer supporting CausalConv.
 
-  Supports `padding='causal'` option (like in `tf.keras.layers.Conv1D`),
+  Supports `padding='causal'` option (like in `tf_keras.layers.Conv1D`),
   which applies causal padding to the temporal dimension, and same padding in
   the spatial dimensions.
   """
 
   def __init__(self, *args, use_buffered_input=False, **kwargs):
     """Initializes conv2d.
 
@@ -946,19 +946,19 @@
 
   def _spatial_output_shape(self, spatial_input_shape: List[int]):
     """Computes the spatial output shape from the input shape."""
     shape = super(Conv2D, self)._spatial_output_shape(spatial_input_shape)
     return self._buffered_spatial_output_shape(shape)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class DepthwiseConv2D(tf.keras.layers.DepthwiseConv2D, CausalConvMixin):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class DepthwiseConv2D(tf_keras.layers.DepthwiseConv2D, CausalConvMixin):
   """DepthwiseConv2D layer supporting CausalConv.
 
-  Supports `padding='causal'` option (like in `tf.keras.layers.Conv1D`),
+  Supports `padding='causal'` option (like in `tf_keras.layers.Conv1D`),
   which applies causal padding to the temporal dimension, and same padding in
   the spatial dimensions.
   """
 
   def __init__(self, *args, use_buffered_input=False, **kwargs):
     """Initializes depthwise conv2d.
 
@@ -1008,19 +1008,19 @@
   def _spatial_output_shape(self, spatial_input_shape: List[int]):
     """Computes the spatial output shape from the input shape."""
     shape = super(DepthwiseConv2D, self)._spatial_output_shape(
         spatial_input_shape)
     return self._buffered_spatial_output_shape(shape)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class Conv3D(tf.keras.layers.Conv3D, CausalConvMixin):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class Conv3D(tf_keras.layers.Conv3D, CausalConvMixin):
   """Conv3D layer supporting CausalConv.
 
-  Supports `padding='causal'` option (like in `tf.keras.layers.Conv1D`),
+  Supports `padding='causal'` option (like in `tf_keras.layers.Conv1D`),
   which applies causal padding to the temporal dimension, and same padding in
   the spatial dimensions.
   """
 
   def __init__(self, *args, use_buffered_input=False, **kwargs):
     """Initializes conv3d.
 
@@ -1064,16 +1064,16 @@
 
   def _spatial_output_shape(self, spatial_input_shape: List[int]):
     """Computes the spatial output shape from the input shape."""
     shape = super(Conv3D, self)._spatial_output_shape(spatial_input_shape)
     return self._buffered_spatial_output_shape(shape)
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class SpatialPyramidPooling(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SpatialPyramidPooling(tf_keras.layers.Layer):
   """Implements the Atrous Spatial Pyramid Pooling.
 
   References:
     [Rethinking Atrous Convolution for Semantic Image Segmentation](
       https://arxiv.org/pdf/1706.05587.pdf)
     [Encoder-Decoder with Atrous Separable Convolution for Semantic Image
     Segmentation](https://arxiv.org/pdf/1802.02611.pdf)
@@ -1086,15 +1086,15 @@
       pool_kernel_size: Optional[List[int]] = None,
       use_sync_bn: bool = False,
       batchnorm_momentum: float = 0.99,
       batchnorm_epsilon: float = 0.001,
       activation: str = 'relu',
       dropout: float = 0.5,
       kernel_initializer: str = 'GlorotUniform',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       interpolation: str = 'bilinear',
       use_depthwise_convolution: bool = False,
       **kwargs):
     """Initializes `SpatialPyramidPooling`.
 
     Args:
       output_channels: Number of channels produced by SpatialPyramidPooling.
@@ -1131,123 +1131,124 @@
     self._dropout = dropout
     self._kernel_initializer = kernel_initializer
     self._kernel_regularizer = kernel_regularizer
     self._interpolation = interpolation
     self._pool_kernel_size = pool_kernel_size
     self._use_depthwise_convolution = use_depthwise_convolution
     self._activation_fn = tf_utils.get_activation(activation)
-    if self._use_sync_bn:
-      self._bn_op = tf.keras.layers.experimental.SyncBatchNormalization
-    else:
-      self._bn_op = tf.keras.layers.BatchNormalization
+    self._bn_op = tf_keras.layers.BatchNormalization
 
-    if tf.keras.backend.image_data_format() == 'channels_last':
+    if tf_keras.backend.image_data_format() == 'channels_last':
       self._bn_axis = -1
     else:
       self._bn_axis = 1
 
   def build(self, input_shape):
     height = input_shape[1]
     width = input_shape[2]
     channels = input_shape[3]
 
     self.aspp_layers = []
 
-    conv1 = tf.keras.layers.Conv2D(
+    conv1 = tf_keras.layers.Conv2D(
         filters=self._output_channels,
         kernel_size=(1, 1),
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         use_bias=False)
     norm1 = self._bn_op(
         axis=self._bn_axis,
         momentum=self._batchnorm_momentum,
-        epsilon=self._batchnorm_epsilon)
+        epsilon=self._batchnorm_epsilon,
+        synchronized=self._use_sync_bn)
 
     self.aspp_layers.append([conv1, norm1])
 
     for dilation_rate in self._dilation_rates:
       leading_layers = []
       kernel_size = (3, 3)
       if self._use_depthwise_convolution:
         leading_layers += [
-            tf.keras.layers.DepthwiseConv2D(
+            tf_keras.layers.DepthwiseConv2D(
                 depth_multiplier=1,
                 kernel_size=kernel_size,
                 padding='same',
                 depthwise_regularizer=self._kernel_regularizer,
                 depthwise_initializer=tf_utils.clone_initializer(
                     self._kernel_initializer),
                 dilation_rate=dilation_rate,
                 use_bias=False)
         ]
         kernel_size = (1, 1)
       conv_dilation = leading_layers + [
-          tf.keras.layers.Conv2D(
+          tf_keras.layers.Conv2D(
               filters=self._output_channels,
               kernel_size=kernel_size,
               padding='same',
               kernel_regularizer=self._kernel_regularizer,
               kernel_initializer=tf_utils.clone_initializer(
                   self._kernel_initializer),
               dilation_rate=dilation_rate,
               use_bias=False)
       ]
       norm_dilation = self._bn_op(
           axis=self._bn_axis,
           momentum=self._batchnorm_momentum,
-          epsilon=self._batchnorm_epsilon)
+          epsilon=self._batchnorm_epsilon,
+          synchronized=self._use_sync_bn)
 
       self.aspp_layers.append(conv_dilation + [norm_dilation])
 
     if self._pool_kernel_size is None:
       pooling = [
-          tf.keras.layers.GlobalAveragePooling2D(),
-          tf.keras.layers.Reshape((1, 1, channels))
+          tf_keras.layers.GlobalAveragePooling2D(),
+          tf_keras.layers.Reshape((1, 1, channels))
       ]
     else:
-      pooling = [tf.keras.layers.AveragePooling2D(self._pool_kernel_size)]
+      pooling = [tf_keras.layers.AveragePooling2D(self._pool_kernel_size)]
 
-    conv2 = tf.keras.layers.Conv2D(
+    conv2 = tf_keras.layers.Conv2D(
         filters=self._output_channels,
         kernel_size=(1, 1),
         kernel_initializer=tf_utils.clone_initializer(self._kernel_initializer),
         kernel_regularizer=self._kernel_regularizer,
         use_bias=False)
     norm2 = self._bn_op(
         axis=self._bn_axis,
         momentum=self._batchnorm_momentum,
-        epsilon=self._batchnorm_epsilon)
+        epsilon=self._batchnorm_epsilon,
+        synchronized=self._use_sync_bn)
 
     self.aspp_layers.append(pooling + [conv2, norm2])
 
-    self._resizing_layer = tf.keras.layers.Resizing(
+    self._resizing_layer = tf_keras.layers.Resizing(
         height, width, interpolation=self._interpolation, dtype=tf.float32)
 
     self._projection = [
-        tf.keras.layers.Conv2D(
+        tf_keras.layers.Conv2D(
             filters=self._output_channels,
             kernel_size=(1, 1),
             kernel_initializer=tf_utils.clone_initializer(
                 self._kernel_initializer),
             kernel_regularizer=self._kernel_regularizer,
             use_bias=False),
         self._bn_op(
             axis=self._bn_axis,
             momentum=self._batchnorm_momentum,
-            epsilon=self._batchnorm_epsilon)
+            epsilon=self._batchnorm_epsilon,
+            synchronized=self._use_sync_bn)
     ]
-    self._dropout_layer = tf.keras.layers.Dropout(rate=self._dropout)
-    self._concat_layer = tf.keras.layers.Concatenate(axis=-1)
+    self._dropout_layer = tf_keras.layers.Dropout(rate=self._dropout)
+    self._concat_layer = tf_keras.layers.Concatenate(axis=-1)
 
   def call(self,
            inputs: tf.Tensor,
            training: Optional[bool] = None) -> tf.Tensor:
     if training is None:
-      training = tf.keras.backend.learning_phase()
+      training = tf_keras.backend.learning_phase()
     result = []
     for i, layers in enumerate(self.aspp_layers):
       x = inputs
       for layer in layers:
         # Apply layers sequentially.
         x = layer(x, training=training)
       x = self._activation_fn(x)
@@ -1275,7 +1276,137 @@
         'dropout': self._dropout,
         'kernel_initializer': self._kernel_initializer,
         'kernel_regularizer': self._kernel_regularizer,
         'interpolation': self._interpolation,
     }
     base_config = super().get_config()
     return dict(list(base_config.items()) + list(config.items()))
+
+
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MultiHeadAttention(tf_keras.layers.MultiHeadAttention):
+  """MultiHeadAttention layer.
+
+  This is an implementation of multi-headed attention as described in the paper
+  "Attention is all you Need" (Vaswani et al., 2017).
+  """
+
+  def __init__(
+      self,
+      *args,
+      partition_dims: Optional[Tuple[int, int, int, int]] = None,
+      max_inference_parallelism: Optional[int] = None,
+      **kwargs,
+  ):
+    """Initializes MultiHeadAttention.
+
+    Args:
+      *args: Positional arguments passed to super().__init__.
+      partition_dims: Spatial partition dimensions.
+      max_inference_parallelism: The number of examples to run in parallel
+        during inference. Set this limit to reduce the peak memory usage. If
+        None, use vectorized operations to run the whole batch in parallel.
+      **kwargs: Keyword arguments passed to super().__init__.
+    """
+    super().__init__(*args, **kwargs)
+    self._partition_dims = partition_dims
+    self._max_inference_parallelism = max_inference_parallelism
+
+  def get_config(self):
+    config = super().get_config()
+    config.update({
+        'partition_dims': self._partition_dims,
+        'max_inference_parallelism': self._max_inference_parallelism,
+    })
+    return config
+
+  def _compute_attention(
+      self,
+      query: tf.Tensor,
+      key: tf.Tensor,
+      value: tf.Tensor,
+      attention_mask: Optional[tf.Tensor] = None,
+      training: Optional[bool] = None,
+  ):
+    """Applies dot-product attention with query, key, value tensors.
+
+    Args:
+      query: Projected query `Tensor` of shape `(B, T, N, key_dim)`.
+      key: Projected key `Tensor` of shape `(B, S, N, key_dim)`.
+      value: Projected value `Tensor` of shape `(B, S, N, value_dim)`.
+      attention_mask: a boolean mask of shape `(B, T, S)`, that prevents
+        attention to certain positions. It is generally not needed if the
+        `query` and `value` (and/or `key`) are masked.
+      training: Python boolean indicating whether the layer should behave in
+        training mode (adding dropout) or in inference mode (doing nothing).
+
+    Returns:
+      attention_output: Multi-headed outputs of attention computation.
+      attention_scores: Multi-headed attention weights.
+    """
+    if self._partition_dims is not None:
+      strategy = tf.distribute.get_strategy()
+      # `query` = [B, T, N ,H]
+      query = strategy.experimental_split_to_logical_devices(
+          query, self._partition_dims)
+      key = strategy.experimental_split_to_logical_devices(
+          key, self._partition_dims)
+      value = strategy.experimental_split_to_logical_devices(
+          value, self._partition_dims)
+
+    batch_size = query.get_shape().as_list()[0]  # None if dynamic.
+
+    if (
+        training
+        or self._max_inference_parallelism is None
+        or self._max_inference_parallelism <= 0
+        or (
+            # If the whole batch is allowed to be run in parallel, use fully
+            # vectorized computation instead of tf.map_fn to make things more
+            # efficient.
+            batch_size is not None
+            and batch_size <= self._max_inference_parallelism
+        )
+    ):
+      return self._compute_attention_delegate(
+          query, key, value, attention_mask, training
+      )
+    else:
+      # Sequentialize the inference execution with limited parallelism.
+      def _compute_fn(x):
+        attention_output, attention_scores = self._compute_attention_delegate(
+            query=x[0][tf.newaxis, ...],
+            key=x[1][tf.newaxis, ...],
+            value=x[2][tf.newaxis, ...],
+            attention_mask=x[3][tf.newaxis, ...] if len(x) >= 4 else None,
+            training=training,
+        )
+        attention_output = tf.squeeze(attention_output, axis=0)
+        attention_scores = tf.squeeze(attention_scores, axis=0)
+        return attention_output, attention_scores
+
+      if attention_mask is not None:
+        elems = [query, key, value, attention_mask]
+      else:
+        elems = [query, key, value]
+
+      return tf.map_fn(
+          fn=_compute_fn,
+          elems=elems,
+          fn_output_signature=(value.dtype, value.dtype),
+          parallel_iterations=self._max_inference_parallelism,
+      )
+
+  def _compute_attention_delegate(
+      self,
+      query: tf.Tensor,
+      key: tf.Tensor,
+      value: tf.Tensor,
+      attention_mask: Optional[tf.Tensor] = None,
+      training: Optional[bool] = None,
+  ):
+    """Implements dot-product attention with query, key, value tensors."""
+    # Simply calls the implementation of the super class here, while the users
+    # can override this function for customizing attention computation.
+    return super()._compute_attention(
+        query, key, value, attention_mask, training
+    )
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/nn_layers_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/nn_layers_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,23 +12,23 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for nn_layers."""
 
 # Import libraries
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.layers import nn_layers
 
 
 class NNLayersTest(parameterized.TestCase, tf.test.TestCase):
 
   def test_scale(self):
-    scale = nn_layers.Scale(initializer=tf.keras.initializers.constant(10.))
+    scale = nn_layers.Scale(initializer=tf_keras.initializers.constant(10.))
     output = scale(3.)
     self.assertAllEqual(output, 30.)
 
   def test_temporal_softmax_pool(self):
     inputs = tf.range(4, dtype=tf.float32) + 1.
     inputs = tf.reshape(inputs, [1, 4, 1, 1, 1])
     layer = nn_layers.TemporalSoftmaxPool()
@@ -114,15 +114,15 @@
       self.assertAllClose(predicted, [[[[[1.0000000, 1.0000000, 2.0000000]]],
                                        [[[2.8414710, 2.0021544, 2.5403023]]],
                                        [[[3.9092975, 3.0043090, 2.5838532]]],
                                        [[[4.1411200, 4.0064630, 3.0100074]]]]])
 
   def test_global_average_pool_keras(self):
     pool = nn_layers.GlobalAveragePool3D(keepdims=False)
-    keras_pool = tf.keras.layers.GlobalAveragePooling3D()
+    keras_pool = tf_keras.layers.GlobalAveragePooling3D()
 
     inputs = 10 * tf.random.normal([1, 2, 3, 4, 1])
 
     outputs = pool(inputs, output_states=False)
     keras_output = keras_pool(inputs)
 
     self.assertAllEqual(outputs.shape, keras_output.shape)
@@ -339,15 +339,15 @@
         strides=(1, 2, 2),
         padding='causal',
         use_buffered_input=False,
         kernel_initializer='ones',
         use_bias=False,
     )
 
-    keras_conv3d = tf.keras.layers.Conv3D(
+    keras_conv3d = tf_keras.layers.Conv3D(
         filters=1,
         kernel_size=(1, 3, 3),
         strides=(1, 2, 2),
         padding='same',
         kernel_initializer='ones',
         use_bias=False,
     )
@@ -374,15 +374,15 @@
         strides=(2, 1, 1),
         padding='causal',
         use_buffered_input=False,
         kernel_initializer='ones',
         use_bias=False,
     )
 
-    keras_conv1d = tf.keras.layers.Conv1D(
+    keras_conv1d = tf_keras.layers.Conv1D(
         filters=1,
         kernel_size=3,
         strides=2,
         padding='causal',
         kernel_initializer='ones',
         use_bias=False,
     )
@@ -402,17 +402,31 @@
 
   @parameterized.parameters(
       (None, []),
       (None, [6, 12, 18]),
       ([32, 32], [6, 12, 18]),
   )
   def test_aspp(self, pool_kernel_size, dilation_rates):
-    inputs = tf.keras.Input(shape=(64, 64, 128), dtype=tf.float32)
+    inputs = tf_keras.Input(shape=(64, 64, 128), dtype=tf.float32)
     layer = nn_layers.SpatialPyramidPooling(
         output_channels=256,
         dilation_rates=dilation_rates,
         pool_kernel_size=pool_kernel_size)
     output = layer(inputs)
     self.assertAllEqual([None, 64, 64, 256], output.shape)
 
+  @parameterized.parameters(None, 2)
+  def test_multi_head_attention(self, max_inference_parallelism):
+    layer = nn_layers.MultiHeadAttention(
+        num_heads=12,
+        key_dim=64,
+        max_inference_parallelism=max_inference_parallelism,
+    )
+    # Create a 3-dimensional input (the first dimension is implicit).
+    query = tf_keras.Input(shape=(40, 80))
+    value = tf_keras.Input(shape=(20, 80))
+    output = layer(query=query, value=value)
+    self.assertEqual(output.shape.as_list(), [None, 40, 80])
+
+
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/roi_aligner.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/roi_aligner.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,21 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains definitions of ROI aligner."""
 
 from typing import Mapping
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import spatial_transform_ops
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MultilevelROIAligner(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MultilevelROIAligner(tf_keras.layers.Layer):
   """Performs ROIAlign for the second stage processing."""
 
   def __init__(self, crop_size: int = 7, sample_offset: float = 0.5, **kwargs):
     """Initializes a ROI aligner.
 
     Args:
       crop_size: An `int` of the output size of the cropped features.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/roi_aligner_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/roi_aligner_test.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for roi_aligner.py."""
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.layers import roi_aligner
 
 
 class MultilevelROIAlignerTest(tf.test.TestCase):
 
   def test_serialize_deserialize(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/roi_generator.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/roi_generator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains definitions of ROI generator."""
 from typing import Optional, Mapping
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import box_ops
 from official.vision.ops import nms
 
 
 def _multilevel_propose_rois(raw_boxes: Mapping[str, tf.Tensor],
                              raw_scores: Mapping[str, tf.Tensor],
@@ -172,16 +172,16 @@
 
       selected_rois, selected_roi_scores = box_ops.top_k_boxes(
           all_rois, all_roi_scores, k=overall_top_k)
 
     return selected_rois, selected_roi_scores
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MultilevelROIGenerator(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MultilevelROIGenerator(tf_keras.layers.Layer):
   """Proposes RoIs for the second stage processing."""
 
   def __init__(self,
                pre_nms_top_k: int = 2000,
                pre_nms_score_threshold: float = 0.0,
                pre_nms_min_size_threshold: float = 0.0,
                nms_iou_threshold: float = 0.7,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/layers/roi_sampler.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/layers/roi_sampler.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,34 +1,39 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Contains definitions of ROI sampler."""
+from typing import Optional, Tuple, Union
 # Import libraries
-
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling.layers import box_sampler
 from official.vision.ops import box_matcher
 from official.vision.ops import iou_similarity
 from official.vision.ops import target_gather
 
+# The return type can be a tuple of 4 or 5 tf.Tensor.
+ROISamplerReturnType = Union[
+    Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor],
+    Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]]
+
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class ROISampler(tf.keras.layers.Layer):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class ROISampler(tf_keras.layers.Layer):
   """Samples ROIs and assigns targets to the sampled ROIs."""
 
   def __init__(self,
                mix_gt_boxes: bool = True,
                num_sampled_rois: int = 512,
                foreground_fraction: float = 0.25,
                foreground_iou_threshold: float = 0.5,
@@ -74,17 +79,22 @@
             foreground_iou_threshold
         ],
         indicators=[-3, -1, -2, 1])
     self._target_gather = target_gather.TargetGather()
 
     self._sampler = box_sampler.BoxSampler(
         num_sampled_rois, foreground_fraction)
-    super(ROISampler, self).__init__(**kwargs)
+    super().__init__(**kwargs)
 
-  def call(self, boxes: tf.Tensor, gt_boxes: tf.Tensor, gt_classes: tf.Tensor):
+  def call(
+      self,
+      boxes: tf.Tensor,
+      gt_boxes: tf.Tensor,
+      gt_classes: tf.Tensor,
+      gt_outer_boxes: Optional[tf.Tensor] = None) -> ROISamplerReturnType:
     """Assigns the proposals with groundtruth classes and performs subsmpling.
 
     Given `proposed_boxes`, `gt_boxes`, and `gt_classes`, the function uses the
     following algorithm to generate the final `num_samples_per_image` RoIs.
       1. Calculates the IoU between each proposal box and each gt_boxes.
       2. Assigns each proposed box with a groundtruth class and box by choosing
          the largest IoU overlap.
@@ -99,22 +109,29 @@
       gt_boxes: A `tf.Tensor` of shape of [batch_size, MAX_NUM_INSTANCES, 4].
         The coordinates of gt_boxes are in the pixel coordinates of the scaled
         image. This tensor might have padding of values -1 indicating the
         invalid box coordinates.
       gt_classes: A `tf.Tensor` with a shape of [batch_size, MAX_NUM_INSTANCES].
         This tensor might have paddings with values of -1 indicating the invalid
         classes.
+      gt_outer_boxes: A `tf.Tensor` of shape of [batch_size, MAX_NUM_INSTANCES,
+        4]. The corrdinates of gt_outer_boxes are in the pixel coordinates of
+        the scaled image. This tensor might have padding of values -1 indicating
+        the invalid box coordinates. Ignored if not provided.
 
     Returns:
       sampled_rois: A `tf.Tensor` of shape of [batch_size, K, 4], representing
         the coordinates of the sampled RoIs, where K is the number of the
         sampled RoIs, i.e. K = num_samples_per_image.
       sampled_gt_boxes: A `tf.Tensor` of shape of [batch_size, K, 4], storing
         the box coordinates of the matched groundtruth boxes of the samples
         RoIs.
+      sampled_gt_outer_boxes: A `tf.Tensor` of shape of [batch_size, K, 4],
+        storing the box coordinates of the matched groundtruth outer boxes of
+        the samples RoIs. This field is missing if gt_outer_boxes is None.
       sampled_gt_classes: A `tf.Tensor` of shape of [batch_size, K], storing the
         classes of the matched groundtruth boxes of the sampled RoIs.
       sampled_gt_indices: A `tf.Tensor` of shape of [batch_size, K], storing the
         indices of the sampled groudntruth boxes in the original `gt_boxes`
         tensor, i.e.,
         gt_boxes[sampled_gt_indices[:, i]] = sampled_gt_boxes[:, i].
     """
@@ -143,33 +160,48 @@
                                   tf.zeros_like(matched_gt_classes),
                                   matched_gt_classes)
     matched_gt_boxes = self._target_gather(gt_boxes, matched_gt_indices,
                                            tf.tile(background_mask, [1, 1, 4]))
     matched_gt_boxes = tf.where(background_mask,
                                 tf.zeros_like(matched_gt_boxes),
                                 matched_gt_boxes)
+    if gt_outer_boxes is not None:
+      matched_gt_outer_boxes = self._target_gather(
+          gt_outer_boxes, matched_gt_indices, tf.tile(background_mask,
+                                                      [1, 1, 4]))
+      matched_gt_outer_boxes = tf.where(background_mask,
+                                        tf.zeros_like(matched_gt_outer_boxes),
+                                        matched_gt_outer_boxes)
     matched_gt_indices = tf.where(
         tf.squeeze(background_mask, -1), -tf.ones_like(matched_gt_indices),
         matched_gt_indices)
 
     if self._config_dict['skip_subsampling']:
-      return (boxes, matched_gt_boxes, tf.squeeze(matched_gt_classes,
-                                                  axis=-1), matched_gt_indices)
+      matched_gt_classes = tf.squeeze(matched_gt_classes, axis=-1)
+      if gt_outer_boxes is None:
+        return (boxes, matched_gt_boxes, matched_gt_classes, matched_gt_indices)
+      return (boxes, matched_gt_boxes, matched_gt_outer_boxes,
+              matched_gt_classes, matched_gt_indices)
 
     sampled_indices = self._sampler(
         positive_matches, negative_matches, ignored_matches)
 
     sampled_rois = self._target_gather(boxes, sampled_indices)
     sampled_gt_boxes = self._target_gather(matched_gt_boxes, sampled_indices)
     sampled_gt_classes = tf.squeeze(self._target_gather(
         matched_gt_classes, sampled_indices), axis=-1)
     sampled_gt_indices = tf.squeeze(self._target_gather(
         tf.expand_dims(matched_gt_indices, -1), sampled_indices), axis=-1)
-    return (sampled_rois, sampled_gt_boxes, sampled_gt_classes,
-            sampled_gt_indices)
+    if gt_outer_boxes is None:
+      return (sampled_rois, sampled_gt_boxes, sampled_gt_classes,
+              sampled_gt_indices)
+    sampled_gt_outer_boxes = self._target_gather(matched_gt_outer_boxes,
+                                                 sampled_indices)
+    return (sampled_rois, sampled_gt_boxes, sampled_gt_outer_boxes,
+            sampled_gt_classes, sampled_gt_indices)
 
   def get_config(self):
     return self._config_dict
 
   @classmethod
   def from_config(cls, config):
     return cls(**config)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/maskrcnn_model.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/maskrcnn_model.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,51 +12,52 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """R-CNN(-RS) models."""
 
 from typing import Any, List, Mapping, Optional, Tuple, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import anchor
 from official.vision.ops import box_ops
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class MaskRCNNModel(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class MaskRCNNModel(tf_keras.Model):
   """The Mask R-CNN(-RS) and Cascade RCNN-RS models."""
 
   def __init__(self,
-               backbone: tf.keras.Model,
-               decoder: tf.keras.Model,
-               rpn_head: tf.keras.layers.Layer,
-               detection_head: Union[tf.keras.layers.Layer,
-                                     List[tf.keras.layers.Layer]],
-               roi_generator: tf.keras.layers.Layer,
-               roi_sampler: Union[tf.keras.layers.Layer,
-                                  List[tf.keras.layers.Layer]],
-               roi_aligner: tf.keras.layers.Layer,
-               detection_generator: tf.keras.layers.Layer,
-               mask_head: Optional[tf.keras.layers.Layer] = None,
-               mask_sampler: Optional[tf.keras.layers.Layer] = None,
-               mask_roi_aligner: Optional[tf.keras.layers.Layer] = None,
+               backbone: tf_keras.Model,
+               decoder: tf_keras.Model,
+               rpn_head: tf_keras.layers.Layer,
+               detection_head: Union[tf_keras.layers.Layer,
+                                     List[tf_keras.layers.Layer]],
+               roi_generator: tf_keras.layers.Layer,
+               roi_sampler: Union[tf_keras.layers.Layer,
+                                  List[tf_keras.layers.Layer]],
+               roi_aligner: tf_keras.layers.Layer,
+               detection_generator: tf_keras.layers.Layer,
+               mask_head: Optional[tf_keras.layers.Layer] = None,
+               mask_sampler: Optional[tf_keras.layers.Layer] = None,
+               mask_roi_aligner: Optional[tf_keras.layers.Layer] = None,
                class_agnostic_bbox_pred: bool = False,
                cascade_class_ensemble: bool = False,
                min_level: Optional[int] = None,
                max_level: Optional[int] = None,
                num_scales: Optional[int] = None,
                aspect_ratios: Optional[List[float]] = None,
                anchor_size: Optional[float] = None,
+               outer_boxes_scale: float = 1.0,
                **kwargs):
     """Initializes the R-CNN(-RS) model.
 
     Args:
-      backbone: `tf.keras.Model`, the backbone network.
-      decoder: `tf.keras.Model`, the decoder network.
+      backbone: `tf_keras.Model`, the backbone network.
+      decoder: `tf_keras.Model`, the decoder network.
       rpn_head: the RPN head.
       detection_head: the detection head or a list of heads.
       roi_generator: the ROI generator.
       roi_sampler: a single ROI sampler or a list of ROI samplers for cascade
         detection heads.
       roi_aligner: the ROI aligner.
       detection_generator: the detection generator.
@@ -73,26 +74,29 @@
         For instances, num_scales=2 adds one additional intermediate anchor
         scales [2^0, 2^0.5] on each level.
       aspect_ratios: A list representing the aspect raito anchors added on each
         level. The number indicates the ratio of width to height. For instances,
         aspect_ratios=[1.0, 2.0, 0.5] adds three anchors on each scale level.
       anchor_size: A number representing the scale of size of the base anchor to
         the feature stride 2^level.
+      outer_boxes_scale: a float to scale up the bounding boxes to generate
+        more inclusive masks. The scale is expected to be >=1.0.
       **kwargs: keyword arguments to be passed.
     """
-    super(MaskRCNNModel, self).__init__(**kwargs)
+    super().__init__(**kwargs)
     self._config_dict = {
         'backbone': backbone,
         'decoder': decoder,
         'rpn_head': rpn_head,
         'detection_head': detection_head,
         'roi_generator': roi_generator,
         'roi_sampler': roi_sampler,
         'roi_aligner': roi_aligner,
         'detection_generator': detection_generator,
+        'outer_boxes_scale': outer_boxes_scale,
         'mask_head': mask_head,
         'mask_sampler': mask_sampler,
         'mask_roi_aligner': mask_roi_aligner,
         'class_agnostic_bbox_pred': class_agnostic_bbox_pred,
         'cascade_class_ensemble': cascade_class_ensemble,
         'min_level': min_level,
         'max_level': max_level,
@@ -115,50 +119,72 @@
     if len(self.roi_sampler) > 1 and not class_agnostic_bbox_pred:
       raise ValueError(
           '`class_agnostic_bbox_pred` needs to be True if multiple detection heads are specified.'
       )
     self.roi_aligner = roi_aligner
     self.detection_generator = detection_generator
     self._include_mask = mask_head is not None
+    if outer_boxes_scale < 1.0:
+      raise ValueError('`outer_boxes_scale` should be a value >= 1.0.')
+    self.outer_boxes_scale = outer_boxes_scale
     self.mask_head = mask_head
     if self._include_mask and mask_sampler is None:
       raise ValueError('`mask_sampler` is not provided in Mask R-CNN.')
     self.mask_sampler = mask_sampler
     if self._include_mask and mask_roi_aligner is None:
       raise ValueError('`mask_roi_aligner` is not provided in Mask R-CNN.')
     self.mask_roi_aligner = mask_roi_aligner
     # Weights for the regression losses for each FRCNN layer.
-    # TODO(xianzhi): Make the weights configurable.
+    # TODO(jiageng): Make the weights configurable.
     self._cascade_layer_to_weights = [
         [10.0, 10.0, 5.0, 5.0],
         [20.0, 20.0, 10.0, 10.0],
         [30.0, 30.0, 15.0, 15.0],
     ]
 
-  def call(self,
-           images: tf.Tensor,
-           image_shape: tf.Tensor,
-           anchor_boxes: Optional[Mapping[str, tf.Tensor]] = None,
-           gt_boxes: Optional[tf.Tensor] = None,
-           gt_classes: Optional[tf.Tensor] = None,
-           gt_masks: Optional[tf.Tensor] = None,
-           training: Optional[bool] = None) -> Mapping[str, tf.Tensor]:
-
+  def call(  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
+      self,
+      images: tf.Tensor,
+      image_shape: tf.Tensor,
+      anchor_boxes: Optional[Mapping[str, tf.Tensor]] = None,
+      gt_boxes: Optional[tf.Tensor] = None,
+      gt_classes: Optional[tf.Tensor] = None,
+      gt_masks: Optional[tf.Tensor] = None,
+      gt_outer_boxes: Optional[tf.Tensor] = None,
+      training: Optional[bool] = None) -> Mapping[str, Optional[tf.Tensor]]:
+    call_box_outputs_kwargs = {
+        'images': images,
+        'image_shape': image_shape,
+        'anchor_boxes': anchor_boxes,
+        'gt_boxes': gt_boxes,
+        'gt_classes': gt_classes,
+        'training': training,
+    }
+    if self.outer_boxes_scale > 1.0:
+      call_box_outputs_kwargs['gt_outer_boxes'] = gt_outer_boxes
     model_outputs, intermediate_outputs = self._call_box_outputs(
-        images=images, image_shape=image_shape, anchor_boxes=anchor_boxes,
-        gt_boxes=gt_boxes, gt_classes=gt_classes, training=training)
+        **call_box_outputs_kwargs)
     if not self._include_mask:
       return model_outputs
 
+    if self.outer_boxes_scale == 1.0:
+      current_rois = intermediate_outputs['current_rois']
+      matched_gt_boxes = intermediate_outputs['matched_gt_boxes']
+    else:
+      current_rois = box_ops.compute_outer_boxes(
+          intermediate_outputs['current_rois'],
+          tf.expand_dims(image_shape, axis=1), self.outer_boxes_scale)
+      matched_gt_boxes = intermediate_outputs['matched_gt_outer_boxes']
+
     model_mask_outputs = self._call_mask_outputs(
         model_box_outputs=model_outputs,
         features=model_outputs['decoder_features'],
-        current_rois=intermediate_outputs['current_rois'],
+        current_rois=current_rois,
         matched_gt_indices=intermediate_outputs['matched_gt_indices'],
-        matched_gt_boxes=intermediate_outputs['matched_gt_boxes'],
+        matched_gt_boxes=matched_gt_boxes,
         matched_gt_classes=intermediate_outputs['matched_gt_classes'],
         gt_masks=gt_masks,
         training=training)
     model_outputs.update(model_mask_outputs)  # pytype: disable=attribute-error  # dynamic-method-lookup
     return model_outputs
 
   def _get_backbone_and_decoder_features(self, images):
@@ -167,21 +193,23 @@
     if self.decoder:
       features = self.decoder(backbone_features)
     else:
       features = backbone_features
     return backbone_features, features
 
   def _call_box_outputs(
-      self, images: tf.Tensor,
+      self,
+      images: tf.Tensor,
       image_shape: tf.Tensor,
       anchor_boxes: Optional[Mapping[str, tf.Tensor]] = None,
       gt_boxes: Optional[tf.Tensor] = None,
       gt_classes: Optional[tf.Tensor] = None,
-      training: Optional[bool] = None) -> Tuple[
-          Mapping[str, tf.Tensor], Mapping[str, tf.Tensor]]:
+      training: Optional[bool] = None,
+      gt_outer_boxes: Optional[tf.Tensor] = None,
+  ) -> Tuple[Mapping[str, Any], Mapping[str, Any]]:
     """Implementation of the Faster-RCNN logic for boxes."""
     model_outputs = {}
 
     # Feature extraction.
     (backbone_features,
      decoder_features) = self._get_backbone_and_decoder_features(images)
 
@@ -218,25 +246,39 @@
     all_class_outputs = []
     for cascade_num in range(len(self.roi_sampler)):
       # In cascade RCNN we want the higher layers to have different regression
       # weights as the predicted deltas become smaller and smaller.
       regression_weights = self._cascade_layer_to_weights[cascade_num]
       current_rois = next_rois
 
-      (class_outputs, box_outputs, model_outputs, matched_gt_boxes,
-       matched_gt_classes, matched_gt_indices,
-       current_rois) = self._run_frcnn_head(
-           features=decoder_features,
-           rois=current_rois,
-           gt_boxes=gt_boxes,
-           gt_classes=gt_classes,
-           training=training,
-           model_outputs=model_outputs,
-           cascade_num=cascade_num,
-           regression_weights=regression_weights)
+      if self.outer_boxes_scale == 1.0:
+        (class_outputs, box_outputs, model_outputs, matched_gt_boxes,
+         matched_gt_classes, matched_gt_indices,
+         current_rois) = self._run_frcnn_head(
+             features=decoder_features,
+             rois=current_rois,
+             gt_boxes=gt_boxes,
+             gt_classes=gt_classes,
+             training=training,
+             model_outputs=model_outputs,
+             cascade_num=cascade_num,
+             regression_weights=regression_weights)
+      else:
+        (class_outputs, box_outputs, model_outputs,
+         (matched_gt_boxes, matched_gt_outer_boxes), matched_gt_classes,
+         matched_gt_indices, current_rois) = self._run_frcnn_head(
+             features=decoder_features,
+             rois=current_rois,
+             gt_boxes=gt_boxes,
+             gt_outer_boxes=gt_outer_boxes,
+             gt_classes=gt_classes,
+             training=training,
+             model_outputs=model_outputs,
+             cascade_num=cascade_num,
+             regression_weights=regression_weights)
       all_class_outputs.append(class_outputs)
 
       # Generate ROIs for the next cascade head if there is any.
       if cascade_num < len(self.roi_sampler) - 1:
         next_rois = box_ops.decode_boxes(
             tf.cast(box_outputs, tf.float32),
             current_rois,
@@ -262,26 +304,33 @@
       if self.detection_generator.get_config()['apply_nms']:
         model_outputs.update({
             'detection_boxes': detections['detection_boxes'],
             'detection_scores': detections['detection_scores'],
             'detection_classes': detections['detection_classes'],
             'num_detections': detections['num_detections']
         })
+        if self.outer_boxes_scale > 1.0:
+          detection_outer_boxes = box_ops.compute_outer_boxes(
+              detections['detection_boxes'],
+              tf.expand_dims(image_shape, axis=1), self.outer_boxes_scale)
+          model_outputs['detection_outer_boxes'] = detection_outer_boxes
       else:
         model_outputs.update({
             'decoded_boxes': detections['decoded_boxes'],
             'decoded_box_scores': detections['decoded_box_scores']
         })
 
     intermediate_outputs = {
         'matched_gt_boxes': matched_gt_boxes,
         'matched_gt_indices': matched_gt_indices,
         'matched_gt_classes': matched_gt_classes,
         'current_rois': current_rois,
     }
+    if self.outer_boxes_scale > 1.0:
+      intermediate_outputs['matched_gt_outer_boxes'] = matched_gt_outer_boxes
     return (model_outputs, intermediate_outputs)
 
   def _call_mask_outputs(
       self,
       model_box_outputs: Mapping[str, tf.Tensor],
       features: tf.Tensor,
       current_rois: tf.Tensor,
@@ -300,15 +349,19 @@
       roi_masks = tf.stop_gradient(roi_masks)
 
       model_outputs.update({
           'mask_class_targets': roi_classes,
           'mask_targets': roi_masks,
       })
     else:
-      current_rois = model_outputs['detection_boxes']
+      if self.outer_boxes_scale == 1.0:
+        current_rois = model_outputs['detection_boxes']
+      else:
+        current_rois = model_outputs['detection_outer_boxes']
+
       roi_classes = model_outputs['detection_classes']
 
     mask_logits, mask_probs = self._features_to_mask_outputs(
         features, current_rois, roi_classes)
 
     if training:
       model_outputs.update({
@@ -316,16 +369,24 @@
       })
     else:
       model_outputs.update({
           'detection_masks': mask_probs,
       })
     return model_outputs
 
-  def _run_frcnn_head(self, features, rois, gt_boxes, gt_classes, training,
-                      model_outputs, cascade_num, regression_weights):
+  def _run_frcnn_head(self,
+                      features,
+                      rois,
+                      gt_boxes,
+                      gt_classes,
+                      training,
+                      model_outputs,
+                      cascade_num,
+                      regression_weights,
+                      gt_outer_boxes=None):
     """Runs the frcnn head that does both class and box prediction.
 
     Args:
       features: `list` of features from the feature extractor.
       rois: `list` of current rois that will be used to predict bbox refinement
         and classes from.
       gt_boxes: a tensor with a shape of [batch_size, MAX_NUM_INSTANCES, 4].
@@ -333,40 +394,53 @@
       gt_classes: [batch_size, MAX_INSTANCES] representing the groundtruth box
         classes. It is padded with -1s to indicate the invalid classes.
       training: `bool`, if model is training or being evaluated.
       model_outputs: `dict`, used for storing outputs used for eval and losses.
       cascade_num: `int`, the current frcnn layer in the cascade.
       regression_weights: `list`, weights used for l1 loss in bounding box
         regression.
+      gt_outer_boxes: a tensor with a shape of [batch_size, MAX_NUM_INSTANCES,
+        4]. This tensor might have paddings with a negative value. Default to
+        None.
 
     Returns:
       class_outputs: Class predictions for rois.
       box_outputs: Box predictions for rois. These are formatted for the
         regression loss and need to be converted before being used as rois
         in the next stage.
       model_outputs: Updated dict with predictions used for losses and eval.
       matched_gt_boxes: If `is_training` is true, then these give the gt box
         location of its positive match.
       matched_gt_classes: If `is_training` is true, then these give the gt class
          of the predicted box.
       matched_gt_boxes: If `is_training` is true, then these give the box
         location of its positive match.
+      matched_gt_outer_boxes: If `is_training` is true, then these give the
+        outer box location of its positive match. Only exist if
+        outer_boxes_scale is greater than 1.0.
       matched_gt_indices: If `is_training` is true, then gives the index of
         the positive box match. Used for mask prediction.
       rois: The sampled rois used for this layer.
     """
     # Only used during training.
-    matched_gt_boxes, matched_gt_classes, matched_gt_indices = (None, None,
-                                                                None)
+    matched_gt_boxes, matched_gt_classes, matched_gt_indices = None, None, None
+    if self.outer_boxes_scale > 1.0:
+      matched_gt_outer_boxes = None
+
     if training and gt_boxes is not None:
       rois = tf.stop_gradient(rois)
 
       current_roi_sampler = self.roi_sampler[cascade_num]
-      rois, matched_gt_boxes, matched_gt_classes, matched_gt_indices = (
-          current_roi_sampler(rois, gt_boxes, gt_classes))
+      if self.outer_boxes_scale == 1.0:
+        rois, matched_gt_boxes, matched_gt_classes, matched_gt_indices = (
+            current_roi_sampler(rois, gt_boxes, gt_classes))
+      else:
+        (rois, matched_gt_boxes, matched_gt_outer_boxes, matched_gt_classes,
+         matched_gt_indices) = current_roi_sampler(rois, gt_boxes, gt_classes,
+                                                   gt_outer_boxes)
       # Create bounding box training targets.
       box_targets = box_ops.encode_boxes(
           matched_gt_boxes, rois, weights=regression_weights)
       # If the target is background, the box target is set to all 0s.
       box_targets = tf.where(
           tf.tile(
               tf.expand_dims(tf.equal(matched_gt_classes, 0), axis=-1),
@@ -390,37 +464,42 @@
     model_outputs.update({
         'class_outputs_{}'.format(cascade_num)
         if cascade_num else 'class_outputs':
             class_outputs,
         'box_outputs_{}'.format(cascade_num) if cascade_num else 'box_outputs':
             box_outputs,
     })
-    return (class_outputs, box_outputs, model_outputs, matched_gt_boxes,
-            matched_gt_classes, matched_gt_indices, rois)
+    if self.outer_boxes_scale == 1.0:
+      return (class_outputs, box_outputs, model_outputs, matched_gt_boxes,
+              matched_gt_classes, matched_gt_indices, rois)
+    else:
+      return (class_outputs, box_outputs, model_outputs,
+              (matched_gt_boxes, matched_gt_outer_boxes), matched_gt_classes,
+              matched_gt_indices, rois)
 
   def _features_to_mask_outputs(self, features, rois, roi_classes):
     # Mask RoI align.
     mask_roi_features = self.mask_roi_aligner(features, rois)
 
     # Mask head.
     raw_masks = self.mask_head([mask_roi_features, roi_classes])
 
     return raw_masks, tf.nn.sigmoid(raw_masks)
 
   @property
   def checkpoint_items(
-      self) -> Mapping[str, Union[tf.keras.Model, tf.keras.layers.Layer]]:
+      self) -> Mapping[str, Union[tf_keras.Model, tf_keras.layers.Layer]]:
     """Returns a dictionary of items to be additionally checkpointed."""
     items = dict(
         backbone=self.backbone,
         rpn_head=self.rpn_head,
         detection_head=self.detection_head)
     if self.decoder is not None:
       items.update(decoder=self.decoder)
-    if self._include_mask:
+    if self._include_mask and self.mask_head is not None:
       items.update(mask_head=self.mask_head)
 
     return items
 
   def get_config(self) -> Mapping[str, Any]:
     return self._config_dict
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/maskrcnn_model_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/maskrcnn_model_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for maskrcnn_model.py."""
 
 import os
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from tensorflow.python.distribute import combinations
 from tensorflow.python.distribute import strategy_combinations
 from official.vision.modeling import maskrcnn_model
 from official.vision.modeling.backbones import resnet
 from official.vision.modeling.decoders import fpn
 from official.vision.modeling.heads import dense_prediction_heads
@@ -38,17 +38,18 @@
 class MaskRCNNModelTest(parameterized.TestCase, tf.test.TestCase):
 
   @combinations.generate(
       combinations.combine(
           include_mask=[True, False],
           use_separable_conv=[True, False],
           build_anchor_boxes=[True, False],
+          use_outer_boxes=[True, False],
           is_training=[True, False]))
   def test_build_model(self, include_mask, use_separable_conv,
-                       build_anchor_boxes, is_training):
+                       build_anchor_boxes, use_outer_boxes, is_training):
     num_classes = 3
     min_level = 3
     max_level = 7
     num_scales = 3
     aspect_ratios = [1.0]
     anchor_size = 3
     resnet_model_id = 50
@@ -115,28 +116,35 @@
         aspect_ratios=aspect_ratios,
         anchor_size=anchor_size)
 
     gt_boxes = np.array(
         [[[10, 10, 15, 15], [2.5, 2.5, 7.5, 7.5], [-1, -1, -1, -1]],
          [[100, 100, 150, 150], [-1, -1, -1, -1], [-1, -1, -1, -1]]],
         dtype=np.float32)
+    gt_outer_boxes = None
+    if use_outer_boxes:
+      gt_outer_boxes = np.array(
+          [[[11, 11, 16.5, 16.5], [2.75, 2.75, 8.25, 8.25], [-1, -1, -1, -1]],
+           [[110, 110, 165, 165], [-1, -1, -1, -1], [-1, -1, -1, -1]]],
+          dtype=np.float32)
     gt_classes = np.array([[2, 1, -1], [1, -1, -1]], dtype=np.int32)
     if include_mask:
       gt_masks = np.ones((2, 3, 100, 100))
     else:
       gt_masks = None
 
     # Results will be checked in test_forward.
     _ = model(
         images,
         image_shape,
         anchor_boxes,
         gt_boxes,
         gt_classes,
         gt_masks,
+        gt_outer_boxes,
         training=is_training)
 
   @combinations.generate(
       combinations.combine(
           strategy=[
               strategy_combinations.cloud_tpu_strategy,
               strategy_combinations.one_device_strategy_gpu,
@@ -175,15 +183,15 @@
             aspect_ratios=aspect_ratios,
             anchor_size=anchor_size,
             image_size=image_size).multilevel_boxes
       else:
         anchor_boxes = None
       num_anchors_per_location = len(aspect_ratios) * num_scales
 
-      input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, 3])
+      input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, 3])
       backbone = resnet.ResNet(model_id=50, input_specs=input_specs)
       decoder = fpn.FPN(
           min_level=min_level,
           max_level=max_level,
           input_specs=backbone.output_specs)
       rpn_head = dense_prediction_heads.RPNHead(
           min_level=min_level,
@@ -238,27 +246,32 @@
           aspect_ratios=aspect_ratios,
           anchor_size=anchor_size)
 
       gt_boxes = np.array(
           [[[10, 10, 15, 15], [2.5, 2.5, 7.5, 7.5], [-1, -1, -1, -1]],
            [[100, 100, 150, 150], [-1, -1, -1, -1], [-1, -1, -1, -1]]],
           dtype=np.float32)
+      gt_outer_boxes = np.array(
+          [[[11, 11, 16.5, 16.5], [2.75, 2.75, 8.25, 8.25], [-1, -1, -1, -1]],
+           [[110, 110, 165, 165], [-1, -1, -1, -1], [-1, -1, -1, -1]]],
+          dtype=np.float32)
       gt_classes = np.array([[2, 1, -1], [1, -1, -1]], dtype=np.int32)
       if include_mask:
         gt_masks = np.ones((2, 3, 100, 100))
       else:
         gt_masks = None
 
       results = model(
           images,
           image_shape,
           anchor_boxes,
           gt_boxes,
           gt_classes,
           gt_masks,
+          gt_outer_boxes,
           training=training)
 
     self.assertIn('rpn_boxes', results)
     self.assertIn('rpn_scores', results)
     if training:
       self.assertIn('class_targets', results)
       self.assertIn('box_targets', results)
@@ -275,15 +288,15 @@
         self.assertIn('detection_masks', results)
 
   @parameterized.parameters(
       (False,),
       (True,),
   )
   def test_serialize_deserialize(self, include_mask):
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, 3])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, 3])
     backbone = resnet.ResNet(model_id=50, input_specs=input_specs)
     decoder = fpn.FPN(
         min_level=3, max_level=7, input_specs=backbone.output_specs)
     rpn_head = dense_prediction_heads.RPNHead(
         min_level=3, max_level=7, num_anchors_per_location=3)
     detection_head = instance_heads.DetectionHead(num_classes=2)
     roi_generator_obj = roi_generator.MultilevelROIGenerator()
@@ -327,15 +340,15 @@
     self.assertAllEqual(model.get_config(), new_model.get_config())
 
   @parameterized.parameters(
       (False,),
       (True,),
   )
   def test_checkpoint(self, include_mask):
-    input_specs = tf.keras.layers.InputSpec(shape=[None, None, None, 3])
+    input_specs = tf_keras.layers.InputSpec(shape=[None, None, None, 3])
     backbone = resnet.ResNet(model_id=50, input_specs=input_specs)
     decoder = fpn.FPN(
         min_level=3, max_level=7, input_specs=backbone.output_specs)
     rpn_head = dense_prediction_heads.RPNHead(
         min_level=3, max_level=7, num_anchors_per_location=3)
     detection_head = instance_heads.DetectionHead(num_classes=2)
     roi_generator_obj = roi_generator.MultilevelROIGenerator()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/models/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/models/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/retinanet_model.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/retinanet_model.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,39 +12,39 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """RetinaNet."""
 from typing import Any, Mapping, List, Optional, Union, Sequence
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import anchor
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class RetinaNetModel(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class RetinaNetModel(tf_keras.Model):
   """The RetinaNet model class."""
 
   def __init__(self,
-               backbone: tf.keras.Model,
-               decoder: tf.keras.Model,
-               head: tf.keras.layers.Layer,
-               detection_generator: tf.keras.layers.Layer,
+               backbone: tf_keras.Model,
+               decoder: tf_keras.Model,
+               head: tf_keras.layers.Layer,
+               detection_generator: tf_keras.layers.Layer,
                min_level: Optional[int] = None,
                max_level: Optional[int] = None,
                num_scales: Optional[int] = None,
                aspect_ratios: Optional[List[float]] = None,
                anchor_size: Optional[float] = None,
                **kwargs):
-    """Classification initialization function.
+    """Detection initialization function.
 
     Args:
-      backbone: `tf.keras.Model` a backbone network.
-      decoder: `tf.keras.Model` a decoder network.
+      backbone: `tf_keras.Model` a backbone network.
+      decoder: `tf_keras.Model` a decoder network.
       head: `RetinaNetHead`, the RetinaNet head.
       detection_generator: the detection generator.
       min_level: Minimum level in output feature maps.
       max_level: Maximum level in output feature maps.
       num_scales: A number representing intermediate scales added
         on each level. For instances, num_scales=2 adds one additional
         intermediate anchor scales [2^0, 2^0.5] on each level.
@@ -169,58 +169,70 @@
       final_results = self.detection_generator(raw_boxes, raw_scores,
                                                anchor_boxes, image_shape,
                                                raw_attributes)
       outputs.update({
           'cls_outputs': raw_scores,
           'box_outputs': raw_boxes,
       })
+
+      def _update_decoded_results():
+        outputs.update({
+            'decoded_boxes': final_results['decoded_boxes'],
+            'decoded_box_scores': final_results['decoded_box_scores'],
+        })
+        if final_results.get('decoded_box_attributes') is not None:
+          outputs['decoded_box_attributes'] = final_results[
+              'decoded_box_attributes'
+          ]
+
       if self.detection_generator.get_config()['apply_nms']:
         outputs.update({
             'detection_boxes': final_results['detection_boxes'],
             'detection_scores': final_results['detection_scores'],
             'detection_classes': final_results['detection_classes'],
-            'num_detections': final_results['num_detections']
+            'num_detections': final_results['num_detections'],
         })
+        # Users can choose to include the decoded results (boxes before NMS) in
+        # the output tensor dict even if `apply_nms` is set to `True`.
+        if self.detection_generator.get_config()['return_decoded']:
+          _update_decoded_results()
       else:
-        outputs.update({
-            'decoded_boxes': final_results['decoded_boxes'],
-            'decoded_box_scores': final_results['decoded_box_scores']
-        })
+        _update_decoded_results()
 
       if raw_attributes:
         outputs.update({
             'attribute_outputs': raw_attributes,
             'detection_attributes': final_results['detection_attributes'],
         })
       return outputs
 
   @property
   def checkpoint_items(
-      self) -> Mapping[str, Union[tf.keras.Model, tf.keras.layers.Layer]]:
+      self) -> Mapping[str, Union[tf_keras.Model, tf_keras.layers.Layer]]:
     """Returns a dictionary of items to be additionally checkpointed."""
     items = dict(backbone=self.backbone, head=self.head)
     if self.decoder is not None:
       items.update(decoder=self.decoder)
 
     return items
 
   @property
-  def backbone(self) -> tf.keras.Model:
+  def backbone(self) -> tf_keras.Model:
     return self._backbone
 
   @property
-  def decoder(self) -> tf.keras.Model:
+  def decoder(self) -> tf_keras.Model:
     return self._decoder
 
   @property
-  def head(self) -> tf.keras.layers.Layer:
+  def head(self) -> tf_keras.layers.Layer:
     return self._head
 
   @property
-  def detection_generator(self) -> tf.keras.layers.Layer:
+  def detection_generator(self) -> tf_keras.layers.Layer:
     return self._detection_generator
 
   def get_config(self) -> Mapping[str, Any]:
     return self._config_dict
 
   @classmethod
   def from_config(cls, config):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/segmentation_model.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/segmentation_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,35 +12,35 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Build segmentation models."""
 from typing import Any, Mapping, Union, Optional, Dict
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class SegmentationModel(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class SegmentationModel(tf_keras.Model):
   """A Segmentation class model.
 
   Input images are passed through backbone first. Decoder network is then
   applied, and finally, segmentation head is applied on the output of the
   decoder network. Layers such as ASPP should be part of decoder. Any feature
   fusion is done as part of the segmentation head (i.e. deeplabv3+ feature
   fusion is not part of the decoder, instead it is part of the segmentation
   head). This way, different feature fusion techniques can be combined with
   different backbones, and decoders.
   """
 
-  def __init__(self, backbone: tf.keras.Model, decoder: tf.keras.Model,
-               head: tf.keras.layers.Layer,
-               mask_scoring_head: Optional[tf.keras.layers.Layer] = None,
+  def __init__(self, backbone: tf_keras.Model, decoder: tf_keras.Model,
+               head: tf_keras.layers.Layer,
+               mask_scoring_head: Optional[tf_keras.layers.Layer] = None,
                **kwargs):
     """Segmentation initialization function.
 
     Args:
       backbone: a backbone network.
       decoder: a decoder network. E.g. FPN.
       head: segmentation head.
@@ -55,15 +55,15 @@
         'mask_scoring_head': mask_scoring_head,
     }
     self.backbone = backbone
     self.decoder = decoder
     self.head = head
     self.mask_scoring_head = mask_scoring_head
 
-  def call(self, inputs: tf.Tensor, training: bool = None
+  def call(self, inputs: tf.Tensor, training: bool = None  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
            ) -> Dict[str, tf.Tensor]:
     backbone_features = self.backbone(inputs)
 
     if self.decoder:
       decoder_features = self.decoder(backbone_features)
     else:
       decoder_features = backbone_features
@@ -73,15 +73,15 @@
     if self.mask_scoring_head:
       mask_scores = self.mask_scoring_head(logits)
       outputs.update({'mask_scores': mask_scores})
     return outputs
 
   @property
   def checkpoint_items(
-      self) -> Mapping[str, Union[tf.keras.Model, tf.keras.layers.Layer]]:
+      self) -> Mapping[str, Union[tf_keras.Model, tf_keras.layers.Layer]]:
     """Returns a dictionary of items to be additionally checkpointed."""
     items = dict(backbone=self.backbone, head=self.head)
     if self.decoder is not None:
       items.update(decoder=self.decoder)
     if self.mask_scoring_head is not None:
       items.update(mask_scoring_head=self.mask_scoring_head)
     return items
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/segmentation_model_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/segmentation_model_test.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for segmentation network."""
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling import backbones
 from official.vision.modeling import segmentation_model
 from official.vision.modeling.decoders import fpn
 from official.vision.modeling.heads import segmentation_heads
 
 
@@ -35,15 +35,15 @@
       (256, 4),
   )
   def test_segmentation_network_creation(
       self, input_size, level):
     """Test for creation of a segmentation network."""
     num_classes = 10
     inputs = np.random.rand(2, input_size, input_size, 3)
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
     backbone = backbones.ResNet(model_id=50)
 
     decoder = fpn.FPN(
         input_specs=backbone.output_specs, min_level=2, max_level=7)
     head = segmentation_heads.SegmentationHead(num_classes, level=level)
 
     model = segmentation_model.SegmentationModel(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/video_classification_model.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/video_classification_model.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,48 +11,48 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Build video classification models."""
 from typing import Any, Mapping, Optional, Union, List, Text
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
-layers = tf.keras.layers
+layers = tf_keras.layers
 
 
-@tf.keras.utils.register_keras_serializable(package='Vision')
-class VideoClassificationModel(tf.keras.Model):
+@tf_keras.utils.register_keras_serializable(package='Vision')
+class VideoClassificationModel(tf_keras.Model):
   """A video classification class builder."""
 
   def __init__(
       self,
-      backbone: tf.keras.Model,
+      backbone: tf_keras.Model,
       num_classes: int,
-      input_specs: Optional[Mapping[str, tf.keras.layers.InputSpec]] = None,
+      input_specs: Optional[Mapping[str, tf_keras.layers.InputSpec]] = None,
       dropout_rate: float = 0.0,
       aggregate_endpoints: bool = False,
       kernel_initializer: str = 'random_uniform',
-      kernel_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
-      bias_regularizer: Optional[tf.keras.regularizers.Regularizer] = None,
+      kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
+      bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,
       require_endpoints: Optional[List[Text]] = None,
       **kwargs):
     """Video Classification initialization function.
 
     Args:
       backbone: a 3d backbone network.
       num_classes: `int` number of classes in classification task.
-      input_specs: `tf.keras.layers.InputSpec` specs of the input tensor.
+      input_specs: `tf_keras.layers.InputSpec` specs of the input tensor.
       dropout_rate: `float` rate for dropout regularization.
       aggregate_endpoints: `bool` aggregate all end ponits or only use the
         final end point.
       kernel_initializer: kernel initializer for the dense layer.
-      kernel_regularizer: tf.keras.regularizers.Regularizer object. Default to
+      kernel_regularizer: tf_keras.regularizers.Regularizer object. Default to
         None.
-      bias_regularizer: tf.keras.regularizers.Regularizer object. Default to
+      bias_regularizer: tf_keras.regularizers.Regularizer object. Default to
         None.
       require_endpoints: the required endpoints for prediction. If None or
         empty, then only uses the final endpoint.
       **kwargs: keyword arguments to be passed.
     """
     if not input_specs:
       input_specs = {
@@ -72,56 +72,56 @@
     }
     self._input_specs = input_specs
     self._kernel_regularizer = kernel_regularizer
     self._bias_regularizer = bias_regularizer
     self._backbone = backbone
 
     inputs = {
-        k: tf.keras.Input(shape=v.shape[1:]) for k, v in input_specs.items()
+        k: tf_keras.Input(shape=v.shape[1:]) for k, v in input_specs.items()
     }
     endpoints = backbone(inputs['image'])
 
     if aggregate_endpoints:
       pooled_feats = []
       for endpoint in endpoints.values():
-        x_pool = tf.keras.layers.GlobalAveragePooling3D()(endpoint)
+        x_pool = tf_keras.layers.GlobalAveragePooling3D()(endpoint)
         pooled_feats.append(x_pool)
       x = tf.concat(pooled_feats, axis=1)
     else:
       if not require_endpoints:
         # Uses the last endpoint for prediction.
         x = endpoints[max(endpoints.keys())]
-        x = tf.keras.layers.GlobalAveragePooling3D()(x)
+        x = tf_keras.layers.GlobalAveragePooling3D()(x)
       else:
         # Concats all the required endpoints for prediction.
         outputs = []
         for name in require_endpoints:
           x = endpoints[name]
-          x = tf.keras.layers.GlobalAveragePooling3D()(x)
+          x = tf_keras.layers.GlobalAveragePooling3D()(x)
           outputs.append(x)
         x = tf.concat(outputs, axis=1)
 
-    x = tf.keras.layers.Dropout(dropout_rate)(x)
-    x = tf.keras.layers.Dense(
+    x = tf_keras.layers.Dropout(dropout_rate)(x)
+    x = tf_keras.layers.Dense(
         num_classes, kernel_initializer=kernel_initializer,
         kernel_regularizer=self._kernel_regularizer,
         bias_regularizer=self._bias_regularizer)(
             x)
 
     super(VideoClassificationModel, self).__init__(
         inputs=inputs, outputs=x, **kwargs)
 
   @property
   def checkpoint_items(
-      self) -> Mapping[str, Union[tf.keras.Model, tf.keras.layers.Layer]]:
+      self) -> Mapping[str, Union[tf_keras.Model, tf_keras.layers.Layer]]:
     """Returns a dictionary of items to be additionally checkpointed."""
     return dict(backbone=self.backbone)
 
   @property
-  def backbone(self) -> tf.keras.Model:
+  def backbone(self) -> tf_keras.Model:
     return self._backbone
 
   def get_config(self) -> Mapping[str, Any]:
     return self._config_dict
 
   @classmethod
   def from_config(cls, config, custom_objects=None):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/modeling/video_classification_model_test.py` & `tf-models-no-deps-2.16.0/official/vision/modeling/video_classification_model_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for video classification network."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling import backbones
 from official.vision.modeling import video_classification_model
 
 
 class VideoClassificationNetworkTest(parameterized.TestCase, tf.test.TestCase):
 
@@ -29,21 +29,21 @@
       (50, 8, 112, 'relu', False),
       (50, 8, 112, 'swish', True),
   )
   def test_resnet3d_network_creation(self, model_id, temporal_size,
                                      spatial_size, activation,
                                      aggregate_endpoints):
     """Test for creation of a ResNet3D-50 classifier."""
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None, temporal_size, spatial_size, spatial_size, 3])
     temporal_strides = [1, 1, 1, 1]
     temporal_kernel_sizes = [(3, 3, 3), (3, 1, 3, 1), (3, 1, 3, 1, 3, 1),
                              (1, 3, 1)]
 
-    tf.keras.backend.set_image_data_format('channels_last')
+    tf_keras.backend.set_image_data_format('channels_last')
 
     backbone = backbones.ResNet3D(
         model_id=model_id,
         temporal_strides=temporal_strides,
         temporal_kernel_sizes=temporal_kernel_sizes,
         input_specs=input_specs,
         activation=activation)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/common/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/anchor.py` & `tf-models-no-deps-2.16.0/official/vision/ops/anchor.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,110 +11,125 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Anchor box and labeler definition."""
 
 import collections
+import math
 from typing import Dict, Optional, Tuple
 
 # Import libraries
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import anchor_generator
 from official.vision.ops import box_matcher
 from official.vision.ops import iou_similarity
 from official.vision.ops import target_gather
 from official.vision.utils.object_detection import balanced_positive_negative_sampler
 from official.vision.utils.object_detection import box_list
 from official.vision.utils.object_detection import faster_rcnn_box_coder
 
 
 class Anchor(object):
   """Anchor class for anchor-based object detectors."""
 
-  def __init__(self,
-               min_level,
-               max_level,
-               num_scales,
-               aspect_ratios,
-               anchor_size,
-               image_size):
-    """Constructs multiscale anchors.
+  def __init__(
+      self,
+      min_level,
+      max_level,
+      num_scales,
+      aspect_ratios,
+      anchor_size,
+      image_size,
+  ):
+    """Constructs multi-scale anchors.
 
     Args:
       min_level: integer number of minimum level of the output feature pyramid.
       max_level: integer number of maximum level of the output feature pyramid.
-      num_scales: integer number representing intermediate scales added
-        on each level. For instances, num_scales=2 adds one additional
-        intermediate anchor scales [2^0, 2^0.5] on each level.
-      aspect_ratios: list of float numbers representing the aspect raito anchors
+      num_scales: integer number representing intermediate scales added on each
+        level. For instances, num_scales=2 adds one additional intermediate
+        anchor scales [2^0, 2^0.5] on each level.
+      aspect_ratios: list of float numbers representing the aspect ratio anchors
         added on each level. The number indicates the ratio of width to height.
         For instances, aspect_ratios=[1.0, 2.0, 0.5] adds three anchors on each
         scale level.
       anchor_size: float number representing the scale of size of the base
         anchor to the feature stride 2^level.
-      image_size: a list of integer numbers or Tensors representing
-        [height, width] of the input image size.The image_size should be divided
-        by the largest feature stride 2^max_level.
+      image_size: a list of integer numbers or Tensors representing [height,
+        width] of the input image size.The image_size should be divided by the
+        largest feature stride 2^max_level.
     """
     self.min_level = min_level
     self.max_level = max_level
     self.num_scales = num_scales
     self.aspect_ratios = aspect_ratios
     self.anchor_size = anchor_size
     self.image_size = image_size
     self.boxes = self._generate_boxes()
 
   def _generate_boxes(self) -> tf.Tensor:
-    """Generates multiscale anchor boxes.
+    """Generates multi-scale anchor boxes.
 
     Returns:
       a Tensor of shape [N, 4], representing anchor boxes of all levels
       concatenated together.
     """
     boxes_all = []
     for level in range(self.min_level, self.max_level + 1):
       boxes_l = []
+      feat_size = math.ceil(self.image_size[0] / 2**level)
+      stride = tf.cast(self.image_size[0] / feat_size, tf.float32)
       for scale in range(self.num_scales):
         for aspect_ratio in self.aspect_ratios:
-          stride = 2 ** level
           intermidate_scale = 2 ** (scale / float(self.num_scales))
           base_anchor_size = self.anchor_size * stride * intermidate_scale
-          aspect_x = aspect_ratio ** 0.5
-          aspect_y = aspect_ratio ** -0.5
+          aspect_x = aspect_ratio**0.5
+          aspect_y = aspect_ratio**-0.5
           half_anchor_size_x = base_anchor_size * aspect_x / 2.0
           half_anchor_size_y = base_anchor_size * aspect_y / 2.0
           x = tf.range(stride / 2, self.image_size[1], stride)
           y = tf.range(stride / 2, self.image_size[0], stride)
           xv, yv = tf.meshgrid(x, y)
           xv = tf.cast(tf.reshape(xv, [-1]), dtype=tf.float32)
           yv = tf.cast(tf.reshape(yv, [-1]), dtype=tf.float32)
           # Tensor shape Nx4.
-          boxes = tf.stack([yv - half_anchor_size_y, xv - half_anchor_size_x,
-                            yv + half_anchor_size_y, xv + half_anchor_size_x],
-                           axis=1)
+          boxes = tf.stack(
+              [
+                  yv - half_anchor_size_y,
+                  xv - half_anchor_size_x,
+                  yv + half_anchor_size_y,
+                  xv + half_anchor_size_x,
+              ],
+              axis=1,
+          )
           boxes_l.append(boxes)
       # Concat anchors on the same level to tensor shape NxAx4.
       boxes_l = tf.stack(boxes_l, axis=1)
       boxes_l = tf.reshape(boxes_l, [-1, 4])
       boxes_all.append(boxes_l)
     return tf.concat(boxes_all, axis=0)
 
   def unpack_labels(self, labels: tf.Tensor) -> Dict[str, tf.Tensor]:
-    """Unpacks an array of labels into multiscales labels."""
+    """Unpacks an array of labels into multi-scales labels."""
     unpacked_labels = collections.OrderedDict()
     count = 0
     for level in range(self.min_level, self.max_level + 1):
-      feat_size_y = tf.cast(self.image_size[0] / 2 ** level, tf.int32)
-      feat_size_x = tf.cast(self.image_size[1] / 2 ** level, tf.int32)
+      feat_size_y = tf.cast(
+          math.ceil(self.image_size[0] / 2**level), tf.int32
+      )
+      feat_size_x = tf.cast(
+          math.ceil(self.image_size[1] / 2**level), tf.int32
+      )
       steps = feat_size_y * feat_size_x * self.anchors_per_location
       unpacked_labels[str(level)] = tf.reshape(
-          labels[count:count + steps], [feat_size_y, feat_size_x, -1])
+          labels[count : count + steps], [feat_size_y, feat_size_x, -1]
+      )
       count += steps
     return unpacked_labels
 
   @property
   def anchors_per_location(self):
     return self.num_scales * len(self.aspect_ratios)
 
@@ -122,62 +137,77 @@
   def multilevel_boxes(self):
     return self.unpack_labels(self.boxes)
 
 
 class AnchorLabeler(object):
   """Labeler for dense object detector."""
 
-  def __init__(self,
-               match_threshold=0.5,
-               unmatched_threshold=0.5):
+  def __init__(
+      self,
+      match_threshold=0.5,
+      unmatched_threshold=0.5,
+      box_coder_weights=None,
+  ):
     """Constructs anchor labeler to assign labels to anchors.
 
     Args:
       match_threshold: a float number between 0 and 1 representing the
         lower-bound threshold to assign positive labels for anchors. An anchor
         with a score over the threshold is labeled positive.
       unmatched_threshold: a float number between 0 and 1 representing the
         upper-bound threshold to assign negative labels for anchors. An anchor
         with a score below the threshold is labeled negative.
+      box_coder_weights: Optional `list` of 4 positive floats to scale y, x, h,
+        and w when encoding box coordinates. If set to None, does not perform
+        scaling. For Faster RCNN, the open-source implementation recommends
+        using [10.0, 10.0, 5.0, 5.0].
     """
     self.similarity_calc = iou_similarity.IouSimilarity()
     self.target_gather = target_gather.TargetGather()
     self.matcher = box_matcher.BoxMatcher(
         thresholds=[unmatched_threshold, match_threshold],
         indicators=[-1, -2, 1],
-        force_match_for_each_col=True)
-    self.box_coder = faster_rcnn_box_coder.FasterRcnnBoxCoder()
+        force_match_for_each_col=True,
+    )
+    self.box_coder = faster_rcnn_box_coder.FasterRcnnBoxCoder(
+        scale_factors=box_coder_weights,
+    )
 
   def label_anchors(
       self,
       anchor_boxes: Dict[str, tf.Tensor],
       gt_boxes: tf.Tensor,
       gt_labels: tf.Tensor,
       gt_attributes: Optional[Dict[str, tf.Tensor]] = None,
-      gt_weights: Optional[tf.Tensor] = None
-  ) -> Tuple[Dict[str, tf.Tensor], Dict[str, tf.Tensor], Dict[str, Dict[
-      str, tf.Tensor]], tf.Tensor, tf.Tensor]:
+      gt_weights: Optional[tf.Tensor] = None,
+  ) -> Tuple[
+      Dict[str, tf.Tensor],
+      Dict[str, tf.Tensor],
+      Dict[str, Dict[str, tf.Tensor]],
+      tf.Tensor,
+      tf.Tensor,
+  ]:
     """Labels anchors with ground truth inputs.
 
     Args:
-      anchor_boxes: An ordered dictionary with keys
-        [min_level, min_level+1, ..., max_level]. The values are tensor with
-        shape [height_l, width_l, num_anchors_per_location * 4]. The height_l
-        and width_l represent the dimension of the feature pyramid at l-th
-        level. For each anchor box, the tensor stores [y0, x0, y1, x1] for the
-        four corners.
-      gt_boxes: A float tensor with shape [N, 4] representing groundtruth boxes.
-        For each row, it stores [y0, x0, y1, x1] for four corners of a box.
-      gt_labels: A integer tensor with shape [N, 1] representing groundtruth
+      anchor_boxes: An ordered dictionary with keys [min_level, min_level+1,
+        ..., max_level]. The values are tensor with shape [height_l, width_l,
+        num_anchors_per_location * 4]. The height_l and width_l represent the
+        dimension of the feature pyramid at l-th level. For each anchor box, the
+        tensor stores [y0, x0, y1, x1] for the four corners.
+      gt_boxes: A float tensor with shape [N, 4] representing ground-truth
+        boxes. For each row, it stores [y0, x0, y1, x1] for four corners of a
+        box.
+      gt_labels: A integer tensor with shape [N, 1] representing ground-truth
         classes.
       gt_attributes: If not None, a dict of (name, gt_attribute) pairs.
         `gt_attribute` is a float tensor with shape [N, attribute_size]
-        representing groundtruth attributes.
+        representing ground-truth attributes.
       gt_weights: If not None, a float tensor with shape [N] representing
-        groundtruth weights.
+        ground-truth weights.
 
     Returns:
       cls_targets_dict: An ordered dictionary with keys
         [min_level, min_level+1, ..., max_level]. The values are tensor with
         shape [height_l, width_l, num_anchors_per_location]. The height_l and
         width_l represent the dimension of class logits at l-th level.
       box_targets_dict: An ordered dictionary with keys
@@ -213,106 +243,137 @@
     att_targets = {}
     if gt_attributes:
       for k, v in gt_attributes.items():
         att_size = v.get_shape().as_list()[-1]
         att_mask = tf.tile(cls_mask, [1, att_size])
         att_targets[k] = self.target_gather(v, match_indices, att_mask, 0.0)
 
-    weights = tf.squeeze(tf.ones_like(gt_labels, dtype=tf.float32), -1)
+    # When there is no ground truth labels, we force the weight to be 1 so that
+    # negative matched anchors get non-zero weights.
+    num_gt_labels = tf.shape(gt_labels)[0]
+    weights = tf.cond(
+        tf.greater(num_gt_labels, 0),
+        lambda: tf.ones_like(gt_labels, dtype=tf.float32)[..., -1],
+        lambda: tf.ones([1], dtype=tf.float32),
+    )
     if gt_weights is not None:
-      weights = tf.math.multiply(weights, gt_weights)
+      weights = tf.cond(
+          tf.greater(num_gt_labels, 0),
+          lambda: tf.math.multiply(weights, gt_weights),
+          lambda: weights,
+      )
     box_weights = self.target_gather(weights, match_indices, mask)
     ignore_mask = tf.equal(match_indicators, -2)
     cls_weights = self.target_gather(weights, match_indices, ignore_mask)
-    box_targets_list = box_list.BoxList(box_targets)
-    anchor_box_list = box_list.BoxList(flattened_anchor_boxes)
-    box_targets = self.box_coder.encode(box_targets_list, anchor_box_list)
+    box_targets = box_list.BoxList(box_targets)
+    anchor_box = box_list.BoxList(flattened_anchor_boxes)
+    box_targets = self.box_coder.encode(box_targets, anchor_box)
 
     # Unpacks labels into multi-level representations.
-    cls_targets_dict = unpack_targets(cls_targets, anchor_boxes)
-    box_targets_dict = unpack_targets(box_targets, anchor_boxes)
-    attribute_targets_dict = {}
-    for k, v in att_targets.items():
-      attribute_targets_dict[k] = unpack_targets(v, anchor_boxes)
-
-    return cls_targets_dict, box_targets_dict, attribute_targets_dict, cls_weights, box_weights
+    cls_targets = unpack_targets(cls_targets, anchor_boxes)
+    box_targets = unpack_targets(box_targets, anchor_boxes)
+    attribute_targets = {
+        k: unpack_targets(v, anchor_boxes) for k, v in att_targets.items()
+    }
+
+    return (
+        cls_targets,
+        box_targets,
+        attribute_targets,
+        cls_weights,
+        box_weights,
+    )
 
 
 class RpnAnchorLabeler(AnchorLabeler):
   """Labeler for Region Proposal Network."""
 
-  def __init__(self,
-               match_threshold=0.7,
-               unmatched_threshold=0.3,
-               rpn_batch_size_per_im=256,
-               rpn_fg_fraction=0.5):
-    AnchorLabeler.__init__(self, match_threshold=match_threshold,
-                           unmatched_threshold=unmatched_threshold)
+  def __init__(
+      self,
+      match_threshold=0.7,
+      unmatched_threshold=0.3,
+      rpn_batch_size_per_im=256,
+      rpn_fg_fraction=0.5,
+  ):
+    AnchorLabeler.__init__(
+        self,
+        match_threshold=match_threshold,
+        unmatched_threshold=unmatched_threshold,
+    )
     self._rpn_batch_size_per_im = rpn_batch_size_per_im
     self._rpn_fg_fraction = rpn_fg_fraction
 
   def _get_rpn_samples(self, match_results):
     """Computes anchor labels.
 
     This function performs subsampling for foreground (fg) and background (bg)
     anchors.
     Args:
-      match_results: A integer tensor with shape [N] representing the
-        matching results of anchors. (1) match_results[i]>=0,
-        meaning that column i is matched with row match_results[i].
-        (2) match_results[i]=-1, meaning that column i is not matched.
-        (3) match_results[i]=-2, meaning that column i is ignored.
+      match_results: A integer tensor with shape [N] representing the matching
+        results of anchors. (1) match_results[i]>=0, meaning that column i is
+        matched with row match_results[i]. (2) match_results[i]=-1, meaning that
+        column i is not matched. (3) match_results[i]=-2, meaning that column i
+        is ignored.
+
     Returns:
       score_targets: a integer tensor with the a shape of [N].
         (1) score_targets[i]=1, the anchor is a positive sample.
         (2) score_targets[i]=0, negative. (3) score_targets[i]=-1, the anchor is
         don't care (ignore).
     """
     sampler = (
         balanced_positive_negative_sampler.BalancedPositiveNegativeSampler(
-            positive_fraction=self._rpn_fg_fraction, is_static=False))
+            positive_fraction=self._rpn_fg_fraction, is_static=False
+        )
+    )
     # indicator includes both positive and negative labels.
     # labels includes only positives labels.
     # positives = indicator & labels.
     # negatives = indicator & !labels.
     # ignore = !indicator.
     indicator = tf.greater(match_results, -2)
     labels = tf.greater(match_results, -1)
 
-    samples = sampler.subsample(
-        indicator, self._rpn_batch_size_per_im, labels)
+    samples = sampler.subsample(indicator, self._rpn_batch_size_per_im, labels)
     positive_labels = tf.where(
         tf.logical_and(samples, labels),
         tf.constant(2, dtype=tf.int32, shape=match_results.shape),
-        tf.constant(0, dtype=tf.int32, shape=match_results.shape))
+        tf.constant(0, dtype=tf.int32, shape=match_results.shape),
+    )
     negative_labels = tf.where(
         tf.logical_and(samples, tf.logical_not(labels)),
         tf.constant(1, dtype=tf.int32, shape=match_results.shape),
-        tf.constant(0, dtype=tf.int32, shape=match_results.shape))
+        tf.constant(0, dtype=tf.int32, shape=match_results.shape),
+    )
     ignore_labels = tf.fill(match_results.shape, -1)
 
-    return (ignore_labels + positive_labels + negative_labels,
-            positive_labels, negative_labels)
+    return (
+        ignore_labels + positive_labels + negative_labels,
+        positive_labels,
+        negative_labels,
+    )
 
-  def label_anchors(
-      self, anchor_boxes: Dict[str, tf.Tensor], gt_boxes: tf.Tensor,
-      gt_labels: tf.Tensor
+  def label_anchors(  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks
+      self,
+      anchor_boxes: Dict[str, tf.Tensor],
+      gt_boxes: tf.Tensor,
+      gt_labels: tf.Tensor,
   ) -> Tuple[Dict[str, tf.Tensor], Dict[str, tf.Tensor]]:
     """Labels anchors with ground truth inputs.
 
     Args:
-      anchor_boxes: An ordered dictionary with keys
-        [min_level, min_level+1, ..., max_level]. The values are tensor with
-        shape [height_l, width_l, num_anchors_per_location * 4]. The height_l
-        and width_l represent the dimension of the feature pyramid at l-th
-        level. For each anchor box, the tensor stores [y0, x0, y1, x1] for the
-        four corners.
-      gt_boxes: A float tensor with shape [N, 4] representing groundtruth boxes.
-        For each row, it stores [y0, x0, y1, x1] for four corners of a box.
-      gt_labels: A integer tensor with shape [N, 1] representing groundtruth
+      anchor_boxes: An ordered dictionary with keys [min_level, min_level+1,
+        ..., max_level]. The values are tensor with shape [height_l, width_l,
+        num_anchors_per_location * 4]. The height_l and width_l represent the
+        dimension of the feature pyramid at l-th level. For each anchor box, the
+        tensor stores [y0, x0, y1, x1] for the four corners.
+      gt_boxes: A float tensor with shape [N, 4] representing ground-truth
+        boxes. For each row, it stores [y0, x0, y1, x1] for four corners of a
+        box.
+      gt_labels: A integer tensor with shape [N, 1] representing ground-truth
         classes.
 
     Returns:
       score_targets_dict: An ordered dictionary with keys
         [min_level, min_level+1, ..., max_level]. The values are tensor with
         shape [height_l, width_l, num_anchors_per_location]. The height_l and
         width_l represent the dimension of class logits at l-th level.
@@ -324,76 +385,80 @@
     """
     flattened_anchor_boxes = []
     for anchors in anchor_boxes.values():
       flattened_anchor_boxes.append(tf.reshape(anchors, [-1, 4]))
     flattened_anchor_boxes = tf.concat(flattened_anchor_boxes, axis=0)
     similarity_matrix = self.similarity_calc(flattened_anchor_boxes, gt_boxes)
     match_indices, match_indicators = self.matcher(similarity_matrix)
-    box_mask = tf.tile(tf.expand_dims(tf.less_equal(match_indicators, 0), -1),
-                       [1, 4])
+    box_mask = tf.tile(
+        tf.expand_dims(tf.less_equal(match_indicators, 0), -1), [1, 4]
+    )
     box_targets = self.target_gather(gt_boxes, match_indices, box_mask)
     box_targets_list = box_list.BoxList(box_targets)
     anchor_box_list = box_list.BoxList(flattened_anchor_boxes)
     box_targets = self.box_coder.encode(box_targets_list, anchor_box_list)
 
     # Zero out the unmatched and ignored regression targets.
     num_matches = match_indices.shape.as_list()[0] or tf.shape(match_indices)[0]
     unmatched_ignored_box_targets = tf.zeros([num_matches, 4], dtype=tf.float32)
     matched_anchors_mask = tf.greater_equal(match_indicators, 0)
     # To broadcast matched_anchors_mask to the same shape as
     # matched_reg_targets.
     matched_anchors_mask = tf.tile(
-        tf.expand_dims(matched_anchors_mask, 1),
-        [1, tf.shape(box_targets)[1]])
-    box_targets = tf.where(matched_anchors_mask, box_targets,
-                           unmatched_ignored_box_targets)
+        tf.expand_dims(matched_anchors_mask, 1), [1, tf.shape(box_targets)[1]]
+    )
+    box_targets = tf.where(
+        matched_anchors_mask, box_targets, unmatched_ignored_box_targets
+    )
 
     # score_targets contains the subsampled positive and negative anchors.
     score_targets, _, _ = self._get_rpn_samples(match_indicators)
 
     # Unpacks labels.
     score_targets_dict = unpack_targets(score_targets, anchor_boxes)
     box_targets_dict = unpack_targets(box_targets, anchor_boxes)
 
     return score_targets_dict, box_targets_dict
 
 
-def build_anchor_generator(min_level, max_level, num_scales, aspect_ratios,
-                           anchor_size):
+def build_anchor_generator(
+    min_level, max_level, num_scales, aspect_ratios, anchor_size
+):
   """Build anchor generator from levels."""
   anchor_sizes = collections.OrderedDict()
   strides = collections.OrderedDict()
   scales = []
   for scale in range(num_scales):
-    scales.append(2**(scale / float(num_scales)))
+    scales.append(2 ** (scale / float(num_scales)))
   for level in range(min_level, max_level + 1):
     stride = 2**level
     strides[str(level)] = stride
     anchor_sizes[str(level)] = anchor_size * stride
   anchor_gen = anchor_generator.AnchorGenerator(
       anchor_sizes=anchor_sizes,
       scales=scales,
       aspect_ratios=aspect_ratios,
-      strides=strides)
+      strides=strides,
+  )
   return anchor_gen
 
 
 def unpack_targets(
-    targets: tf.Tensor,
-    anchor_boxes_dict: Dict[str, tf.Tensor]) -> Dict[str, tf.Tensor]:
-  """Unpacks an array of labels into multiscales labels.
+    targets: tf.Tensor, anchor_boxes_dict: Dict[str, tf.Tensor]
+) -> Dict[str, tf.Tensor]:
+  """Unpacks an array of labels into multi-scales labels.
 
   Args:
     targets: A tensor with shape [num_anchors, M] representing the packed
       targets with M values stored for each anchor.
-    anchor_boxes_dict: An ordered dictionary with keys
-      [min_level, min_level+1, ..., max_level]. The values are tensor with shape
-      [height_l, width_l, num_anchors_per_location * 4]. The height_l and
-      width_l represent the dimension of the feature pyramid at l-th level. For
-      each anchor box, the tensor stores [y0, x0, y1, x1] for the four corners.
+    anchor_boxes_dict: An ordered dictionary with keys [min_level, min_level+1,
+      ..., max_level]. The values are tensor with shape [height_l, width_l,
+      num_anchors_per_location * 4]. The height_l and width_l represent the
+      dimension of the feature pyramid at l-th level. For each anchor box, the
+      tensor stores [y0, x0, y1, x1] for the four corners.
 
   Returns:
     unpacked_targets: An ordered dictionary with keys
       [min_level, min_level+1, ..., max_level]. The values are tensor with shape
       [height_l, width_l, num_anchors_per_location * M]. The height_l and
       width_l represent the dimension of the feature pyramid at l-th level. M is
       the number of values stored for each anchor.
@@ -402,11 +467,12 @@
   count = 0
   for level, anchor_boxes in anchor_boxes_dict.items():
     feat_size_shape = anchor_boxes.shape.as_list()
     feat_size_y = feat_size_shape[0]
     feat_size_x = feat_size_shape[1]
     anchors_per_location = int(feat_size_shape[2] / 4)
     steps = feat_size_y * feat_size_x * anchors_per_location
-    unpacked_targets[level] = tf.reshape(targets[count:count + steps],
-                                         [feat_size_y, feat_size_x, -1])
+    unpacked_targets[level] = tf.reshape(
+        targets[count : count + steps], [feat_size_y, feat_size_x, -1]
+    )
     count += steps
   return unpacked_targets
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/anchor_generator.py` & `tf-models-no-deps-2.16.0/official/vision/ops/anchor_generator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Multi scale anchor generator definition."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 # (TODO/tanzheny): consider having customized anchor offset.
 class _SingleAnchorGenerator:
   """Utility to generate anchors for a single feature map.
 
   Example:
@@ -77,17 +77,17 @@
     anchor_heights = tf.concat(anchor_heights, axis=0)
     anchor_widths = tf.concat(anchor_widths, axis=0)
     half_anchor_heights = tf.reshape(0.5 * anchor_heights, [1, 1, k])
     half_anchor_widths = tf.reshape(0.5 * anchor_widths, [1, 1, k])
 
     stride = tf.cast(self.stride, tf.float32)
     # [W]
-    cx = tf.range(0.5 * stride, image_width, stride)
+    cx = tf.range(0.5 * stride, image_width + 0.5 * stride, stride)
     # [H]
-    cy = tf.range(0.5 * stride, image_height, stride)
+    cy = tf.range(0.5 * stride, image_height + 0.5 * stride, stride)
     # [H, W]
     cx_grid, cy_grid = tf.meshgrid(cx, cy)
     # [H, W, 1]
     cx_grid = tf.expand_dims(cx_grid, axis=-1)
     cy_grid = tf.expand_dims(cy_grid, axis=-1)
 
     # [H, W, K, 1]
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/anchor_generator_test.py` & `tf-models-no-deps-2.16.0/official/vision/ops/anchor_generator_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for anchor_generator.py."""
 
 from absl.testing import parameterized
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.vision.ops import anchor_generator
 
 
 class AnchorGeneratorTest(parameterized.TestCase, tf.test.TestCase):
 
   @parameterized.parameters(
       # Single scale anchor.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/anchor_test.py` & `tf-models-no-deps-2.16.0/official/vision/ops/anchor_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for anchor.py."""
 
 # Import libraries
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.vision.ops import anchor
 
 
 class AnchorTest(parameterized.TestCase, tf.test.TestCase):
 
   # The set of parameters are tailored for the MLPerf configuration, where
   # the number of anchors is 495132, rpn_batch_size_per_im=256, and
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/augment.py` & `tf-models-no-deps-2.16.0/official/vision/ops/augment.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -25,19 +25,18 @@
 
 RandomErasing, Mixup and Cutmix are inspired by
 https://github.com/rwightman/pytorch-image-models
 
 """
 import inspect
 import math
-from typing import Any, List, Iterable, Optional, Text, Tuple
+from typing import Any, List, Iterable, Optional, Tuple, Union
 
-from keras.layers.preprocessing import image_preprocessing as image_ops
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 # This signifies the max integer that the controller RNN could predict for the
 # augmentation scheme.
 _MAX_LEVEL = 10.
 
 
@@ -78,14 +77,203 @@
   shape = tf.shape(image)
   begin = tf.cast(tf.less_equal(ndims, 3), dtype=tf.int32)
   end = 4 - tf.cast(tf.equal(ndims, 2), dtype=tf.int32)
   new_shape = shape[begin:end]
   return tf.reshape(image, new_shape)
 
 
+def _pad(
+    image: tf.Tensor,
+    filter_shape: Union[List[int], Tuple[int, ...]],
+    mode: str = 'CONSTANT',
+    constant_values: Union[int, tf.Tensor] = 0,
+) -> tf.Tensor:
+  """Explicitly pads a 4-D image.
+
+  Equivalent to the implicit padding method offered in `tf.nn.conv2d` and
+  `tf.nn.depthwise_conv2d`, but supports non-zero, reflect and symmetric
+  padding mode. For the even-sized filter, it pads one more value to the
+  right or the bottom side.
+
+  Args:
+    image: A 4-D `Tensor` of shape `[batch_size, height, width, channels]`.
+    filter_shape: A `tuple`/`list` of 2 integers, specifying the height and
+      width of the 2-D filter.
+    mode: A `string`, one of "REFLECT", "CONSTANT", or "SYMMETRIC". The type of
+      padding algorithm to use, which is compatible with `mode` argument in
+      `tf.pad`. For more details, please refer to
+      https://www.tensorflow.org/api_docs/python/tf/pad.
+    constant_values: A `scalar`, the pad value to use in "CONSTANT" padding
+      mode.
+
+  Returns:
+    A padded image.
+  """
+  if mode.upper() not in {'REFLECT', 'CONSTANT', 'SYMMETRIC'}:
+    raise ValueError(
+        'padding should be one of "REFLECT", "CONSTANT", or "SYMMETRIC".'
+    )
+  constant_values = tf.convert_to_tensor(constant_values, image.dtype)
+  filter_height, filter_width = filter_shape
+  pad_top = (filter_height - 1) // 2
+  pad_bottom = filter_height - 1 - pad_top
+  pad_left = (filter_width - 1) // 2
+  pad_right = filter_width - 1 - pad_left
+  paddings = [[0, 0], [pad_top, pad_bottom], [pad_left, pad_right], [0, 0]]
+  return tf.pad(image, paddings, mode=mode, constant_values=constant_values)
+
+
+def _get_gaussian_kernel(sigma, filter_shape):
+  """Computes 1D Gaussian kernel."""
+  sigma = tf.convert_to_tensor(sigma)
+  x = tf.range(-filter_shape // 2 + 1, filter_shape // 2 + 1)
+  x = tf.cast(x**2, sigma.dtype)
+  x = tf.nn.softmax(-x / (2.0 * (sigma**2)))
+  return x
+
+
+def _get_gaussian_kernel_2d(gaussian_filter_x, gaussian_filter_y):
+  """Computes 2D Gaussian kernel given 1D kernels."""
+  gaussian_kernel = tf.matmul(gaussian_filter_x, gaussian_filter_y)
+  return gaussian_kernel
+
+
+def _normalize_tuple(value, n, name):
+  """Transforms an integer or iterable of integers into an integer tuple.
+
+  Args:
+    value: The value to validate and convert. Could an int, or any iterable of
+      ints.
+    n: The size of the tuple to be returned.
+    name: The name of the argument being validated, e.g. "strides" or
+      "kernel_size". This is only used to format error messages.
+
+  Returns:
+    A tuple of n integers.
+
+  Raises:
+    ValueError: If something else than an int/long or iterable thereof was
+      passed.
+  """
+  if isinstance(value, int):
+    return (value,) * n
+  else:
+    try:
+      value_tuple = tuple(value)
+    except TypeError as exc:
+      raise TypeError(
+          f'The {name} argument must be a tuple of {n} integers. '
+          f'Received: {value}'
+      ) from exc
+    if len(value_tuple) != n:
+      raise ValueError(
+          f'The {name} argument must be a tuple of {n} integers. '
+          f'Received: {value}'
+      )
+    for single_value in value_tuple:
+      try:
+        int(single_value)
+      except (ValueError, TypeError) as exc:
+        raise ValueError(
+            f'The {name} argument must be a tuple of {n} integers. Received:'
+            f' {value} including element {single_value} of type'
+            f' {type(single_value)}.'
+        ) from exc
+    return value_tuple
+
+
+def gaussian_filter2d(
+    image: tf.Tensor,
+    filter_shape: Union[List[int], Tuple[int, ...], int],
+    sigma: Union[List[float], Tuple[float], float] = 1.0,
+    padding: str = 'REFLECT',
+    constant_values: Union[int, tf.Tensor] = 0,
+    name: Optional[str] = None,
+) -> tf.Tensor:
+  """Performs Gaussian blur on image(s).
+
+  Args:
+    image: Either a 2-D `Tensor` of shape `[height, width]`, a 3-D `Tensor` of
+      shape `[height, width, channels]`, or a 4-D `Tensor` of shape
+      `[batch_size, height, width, channels]`.
+    filter_shape: An `integer` or `tuple`/`list` of 2 integers, specifying the
+      height and width of the 2-D gaussian filter. Can be a single integer to
+      specify the same value for all spatial dimensions.
+    sigma: A `float` or `tuple`/`list` of 2 floats, specifying the standard
+      deviation in x and y direction the 2-D gaussian filter. Can be a single
+      float to specify the same value for all spatial dimensions.
+    padding: A `string`, one of "REFLECT", "CONSTANT", or "SYMMETRIC". The type
+      of padding algorithm to use, which is compatible with `mode` argument in
+      `tf.pad`. For more details, please refer to
+      https://www.tensorflow.org/api_docs/python/tf/pad.
+    constant_values: A `scalar`, the pad value to use in "CONSTANT" padding
+      mode.
+    name: A name for this operation (optional).
+
+  Returns:
+    2-D, 3-D or 4-D `Tensor` of the same dtype as input.
+
+  Raises:
+    ValueError: If `image` is not 2, 3 or 4-dimensional,
+      if `padding` is other than "REFLECT", "CONSTANT" or "SYMMETRIC",
+      if `filter_shape` is invalid,
+      or if `sigma` is invalid.
+  """
+  with tf.name_scope(name or 'gaussian_filter2d'):
+    if isinstance(sigma, (list, tuple)):
+      if len(sigma) != 2:
+        raise ValueError('sigma should be a float or a tuple/list of 2 floats')
+    else:
+      sigma = (sigma,) * 2
+
+    if any(s < 0 for s in sigma):
+      raise ValueError('sigma should be greater than or equal to 0.')
+
+    image = tf.convert_to_tensor(image, name='image')
+    sigma = tf.convert_to_tensor(sigma, name='sigma')
+
+    original_ndims = tf.rank(image)
+    image = to_4d(image)
+
+    # Keep the precision if it's float;
+    # otherwise, convert to float32 for computing.
+    orig_dtype = image.dtype
+    if not image.dtype.is_floating:
+      image = tf.cast(image, tf.float32)
+
+    channels = tf.shape(image)[3]
+    filter_shape = _normalize_tuple(filter_shape, 2, 'filter_shape')
+
+    sigma = tf.cast(sigma, image.dtype)
+    gaussian_kernel_x = _get_gaussian_kernel(sigma[1], filter_shape[1])
+    gaussian_kernel_x = gaussian_kernel_x[tf.newaxis, :]
+
+    gaussian_kernel_y = _get_gaussian_kernel(sigma[0], filter_shape[0])
+    gaussian_kernel_y = gaussian_kernel_y[:, tf.newaxis]
+
+    gaussian_kernel_2d = _get_gaussian_kernel_2d(
+        gaussian_kernel_y, gaussian_kernel_x
+    )
+    gaussian_kernel_2d = gaussian_kernel_2d[:, :, tf.newaxis, tf.newaxis]
+    gaussian_kernel_2d = tf.tile(gaussian_kernel_2d, [1, 1, channels, 1])
+
+    image = _pad(
+        image, filter_shape, mode=padding, constant_values=constant_values
+    )
+
+    output = tf.nn.depthwise_conv2d(
+        input=image,
+        filter=gaussian_kernel_2d,
+        strides=(1, 1, 1, 1),
+        padding='VALID',
+    )
+    output = from_4d(output, original_ndims)
+    return tf.cast(output, orig_dtype)
+
+
 def _convert_translation_to_transform(translations: tf.Tensor) -> tf.Tensor:
   """Converts translations to a projective transform.
 
   The translation matrix looks like this:
     [[1 0 -dx]
      [0 1 -dy]
      [0 0 1]]
@@ -166,39 +354,149 @@
           y_offset[:, None],
           tf.zeros((num_angles, 2), tf.dtypes.float32),
       ],
       axis=1,
   )
 
 
-def transform(image: tf.Tensor, transforms) -> tf.Tensor:
-  """Prepares input data for `image_ops.transform`."""
+def _apply_transform_to_images(
+    images,
+    transforms,
+    fill_mode='reflect',
+    fill_value=0.0,
+    interpolation='bilinear',
+    output_shape=None,
+    name=None,
+):
+  """Applies the given transform(s) to the image(s).
+
+  Args:
+    images: A tensor of shape `(num_images, num_rows, num_columns,
+      num_channels)` (NHWC). The rank must be statically known (the shape is
+      not `TensorShape(None)`).
+    transforms: Projective transform matrix/matrices. A vector of length 8 or
+      tensor of size N x 8. If one row of transforms is [a0, a1, a2, b0, b1,
+      b2, c0, c1], then it maps the *output* point `(x, y)` to a transformed
+      *input* point `(x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) /
+      k)`, where `k = c0 x + c1 y + 1`. The transforms are *inverted* compared
+      to the transform mapping input points to output points. Note that
+      gradients are not backpropagated into transformation parameters.
+    fill_mode: Points outside the boundaries of the input are filled according
+      to the given mode (one of `{"constant", "reflect", "wrap", "nearest"}`).
+    fill_value: a float represents the value to be filled outside the
+      boundaries when `fill_mode="constant"`.
+    interpolation: Interpolation mode. Supported values: `"nearest"`,
+      `"bilinear"`.
+    output_shape: Output dimension after the transform, `[height, width]`. If
+      `None`, output is the same size as input image.
+    name: The name of the op.  Fill mode behavior for each valid value is as
+      follows
+      - `"reflect"`: `(d c b a | a b c d | d c b a)` The input is extended by
+      reflecting about the edge of the last pixel.
+      - `"constant"`: `(k k k k | a b c d | k k k k)` The input is extended by
+      filling all values beyond the edge with the same constant value k = 0.
+      - `"wrap"`: `(a b c d | a b c d | a b c d)` The input is extended by
+      wrapping around to the opposite edge.
+      - `"nearest"`: `(a a a a | a b c d | d d d d)` The input is extended by
+      the nearest pixel.  Input shape: 4D tensor with shape:
+      `(samples, height, width, channels)`, in `"channels_last"` format.
+      Output shape: 4D tensor with shape: `(samples, height, width, channels)`,
+      in `"channels_last"` format.
+
+  Returns:
+    Image(s) with the same type and shape as `images`, with the given
+    transform(s) applied. Transformed coordinates outside of the input image
+    will be filled with zeros.
+  """
+  with tf.name_scope(name or 'transform'):
+    if output_shape is None:
+      output_shape = tf.shape(images)[1:3]
+      if not tf.executing_eagerly():
+        output_shape_value = tf.get_static_value(output_shape)
+        if output_shape_value is not None:
+          output_shape = output_shape_value
+
+    output_shape = tf.convert_to_tensor(
+        output_shape, tf.int32, name='output_shape'
+    )
+
+    if not output_shape.get_shape().is_compatible_with([2]):
+      raise ValueError(
+          'output_shape must be a 1-D Tensor of 2 elements: '
+          'new_height, new_width, instead got '
+          f'output_shape={output_shape}'
+      )
+
+    fill_value = tf.convert_to_tensor(fill_value, tf.float32, name='fill_value')
+
+    return tf.raw_ops.ImageProjectiveTransformV3(
+        images=images,
+        output_shape=output_shape,
+        fill_value=fill_value,
+        transforms=transforms,
+        fill_mode=fill_mode.upper(),
+        interpolation=interpolation.upper(),
+    )
+
+
+def transform(
+    image: tf.Tensor,
+    transforms: Any,
+    interpolation: str = 'nearest',
+    output_shape=None,
+    fill_mode: str = 'reflect',
+    fill_value: float = 0.0,
+) -> tf.Tensor:
+  """Transforms an image."""
   original_ndims = tf.rank(image)
   transforms = tf.convert_to_tensor(transforms, dtype=tf.float32)
   if transforms.shape.rank == 1:
     transforms = transforms[None]
   image = to_4d(image)
-  image = image_ops.transform(
-      images=image, transforms=transforms, interpolation='nearest')
+  image = _apply_transform_to_images(
+      images=image,
+      transforms=transforms,
+      interpolation=interpolation,
+      fill_mode=fill_mode,
+      fill_value=fill_value,
+      output_shape=output_shape,
+  )
   return from_4d(image, original_ndims)
 
 
-def translate(image: tf.Tensor, translations) -> tf.Tensor:
+def translate(
+    image: tf.Tensor,
+    translations,
+    fill_value: float = 0.0,
+    fill_mode: str = 'reflect',
+    interpolation: str = 'nearest',
+) -> tf.Tensor:
   """Translates image(s) by provided vectors.
 
   Args:
     image: An image Tensor of type uint8.
     translations: A vector or matrix representing [dx dy].
+    fill_value: a float represents the value to be filled outside the boundaries
+      when `fill_mode="constant"`.
+    fill_mode: Points outside the boundaries of the input are filled according
+      to the given mode (one of `{"constant", "reflect", "wrap", "nearest"}`).
+    interpolation: Interpolation mode. Supported values: `"nearest"`,
+      `"bilinear"`.
 
   Returns:
     The translated version of the image.
-
   """
-  transforms = _convert_translation_to_transform(translations)
-  return transform(image, transforms=transforms)
+  transforms = _convert_translation_to_transform(translations)  # pytype: disable=wrong-arg-types  # always-use-return-annotations
+  return transform(
+      image,
+      transforms=transforms,
+      interpolation=interpolation,
+      fill_value=fill_value,
+      fill_mode=fill_mode,
+  )
 
 
 def rotate(image: tf.Tensor, degrees: float) -> tf.Tensor:
   """Rotates the image by degrees either clockwise or counterclockwise.
 
   Args:
     image: An image Tensor of type uint8.
@@ -384,90 +682,127 @@
   else:
     fill = tf.ones_like(image, dtype=image.dtype) * replace
   image = tf.where(tf.equal(mask, 0), fill, image)
 
   return image
 
 
-def cutout_video(image: tf.Tensor, replace: int = 0) -> tf.Tensor:
+def cutout_video(
+    video: tf.Tensor,
+    mask_shape: Optional[tf.Tensor] = None,
+    replace: int = 0,
+) -> tf.Tensor:
   """Apply cutout (https://arxiv.org/abs/1708.04552) to a video.
 
   This operation applies a random size 3D mask of zeros to a random location
-  within `image`. The mask is padded The pixel values filled in will be of the
+  within `video`. The mask is padded The pixel values filled in will be of the
   value `replace`. The location where the mask will be applied is randomly
-  chosen uniformly over the whole image. The size of the mask is randomly
-  sampled uniformly from [0.25*height, 0.5*height], [0.25*width, 0.5*width],
-  and [1, 0.25*depth], which represent the height, width, and number of frames
-  of the input video tensor respectively.
+  chosen uniformly over the whole video. If the size of the mask is not set,
+  then, it is randomly sampled uniformly from [0.25*height, 0.5*height],
+  [0.25*width, 0.5*width], and [1, 0.25*depth], which represent the height,
+  width, and number of frames of the input video tensor respectively.
 
   Args:
-    image: A video Tensor of type uint8.
+    video: A video Tensor of shape [T, H, W, C].
+    mask_shape: An optional integer tensor that specifies the depth, height and
+      width of the mask to cut. If it is not set, the shape is randomly sampled
+      as described above. The shape dimensions should be divisible by 2
+      otherwise they will rounded down.
     replace: What pixel value to fill in the image in the area that has the
       cutout mask applied to it.
 
   Returns:
-    An video Tensor that is of type uint8.
+    A video Tensor with cutout applied.
   """
-  image_depth = tf.shape(image)[0]
-  image_height = tf.shape(image)[1]
-  image_width = tf.shape(image)[2]
+  tf.debugging.assert_shapes([
+      (video, ('T', 'H', 'W', 'C')),
+  ])
+
+  video_depth = tf.shape(video)[0]
+  video_height = tf.shape(video)[1]
+  video_width = tf.shape(video)[2]
 
   # Sample the center location in the image where the zero mask will be applied.
   cutout_center_height = tf.random.uniform(
-      shape=[], minval=0, maxval=image_height, dtype=tf.int32)
+      shape=[], minval=0, maxval=video_height, dtype=tf.int32
+  )
 
   cutout_center_width = tf.random.uniform(
-      shape=[], minval=0, maxval=image_width, dtype=tf.int32)
+      shape=[], minval=0, maxval=video_width, dtype=tf.int32
+  )
 
   cutout_center_depth = tf.random.uniform(
-      shape=[], minval=0, maxval=image_depth, dtype=tf.int32)
+      shape=[], minval=0, maxval=video_depth, dtype=tf.int32
+  )
 
-  pad_size_height = tf.random.uniform(
-      shape=[],
-      minval=tf.maximum(1, tf.cast(image_height / 4, tf.int32)),
-      maxval=tf.maximum(2, tf.cast(image_height / 2, tf.int32)),
-      dtype=tf.int32)
-  pad_size_width = tf.random.uniform(
-      shape=[],
-      minval=tf.maximum(1, tf.cast(image_width / 4, tf.int32)),
-      maxval=tf.maximum(2, tf.cast(image_width / 2, tf.int32)),
-      dtype=tf.int32)
-  pad_size_depth = tf.random.uniform(
-      shape=[],
-      minval=1,
-      maxval=tf.maximum(2, tf.cast(image_depth / 4, tf.int32)),
-      dtype=tf.int32)
+  if mask_shape is not None:
+    pad_shape = tf.maximum(1, mask_shape // 2)
+    pad_size_depth, pad_size_height, pad_size_width = (
+        pad_shape[0],
+        pad_shape[1],
+        pad_shape[2],
+    )
+  else:
+    pad_size_height = tf.random.uniform(
+        shape=[],
+        minval=tf.maximum(1, tf.cast(video_height / 4, tf.int32)),
+        maxval=tf.maximum(2, tf.cast(video_height / 2, tf.int32)),
+        dtype=tf.int32,
+    )
+    pad_size_width = tf.random.uniform(
+        shape=[],
+        minval=tf.maximum(1, tf.cast(video_width / 4, tf.int32)),
+        maxval=tf.maximum(2, tf.cast(video_width / 2, tf.int32)),
+        dtype=tf.int32,
+    )
+    pad_size_depth = tf.random.uniform(
+        shape=[],
+        minval=1,
+        maxval=tf.maximum(2, tf.cast(video_depth / 4, tf.int32)),
+        dtype=tf.int32,
+    )
 
   lower_pad = tf.maximum(0, cutout_center_height - pad_size_height)
   upper_pad = tf.maximum(
-      0, image_height - cutout_center_height - pad_size_height)
+      0, video_height - cutout_center_height - pad_size_height
+  )
   left_pad = tf.maximum(0, cutout_center_width - pad_size_width)
-  right_pad = tf.maximum(0, image_width - cutout_center_width - pad_size_width)
+  right_pad = tf.maximum(0, video_width - cutout_center_width - pad_size_width)
   back_pad = tf.maximum(0, cutout_center_depth - pad_size_depth)
   forward_pad = tf.maximum(
-      0, image_depth - cutout_center_depth - pad_size_depth)
+      0, video_depth - cutout_center_depth - pad_size_depth
+  )
 
   cutout_shape = [
-      image_depth - (back_pad + forward_pad),
-      image_height - (lower_pad + upper_pad),
-      image_width - (left_pad + right_pad),
+      video_depth - (back_pad + forward_pad),
+      video_height - (lower_pad + upper_pad),
+      video_width - (left_pad + right_pad),
   ]
   padding_dims = [[back_pad, forward_pad],
                   [lower_pad, upper_pad],
                   [left_pad, right_pad]]
   mask = tf.pad(
-      tf.zeros(cutout_shape, dtype=image.dtype),
-      padding_dims,
-      constant_values=1)
+      tf.zeros(cutout_shape, dtype=video.dtype), padding_dims, constant_values=1
+  )
   mask = tf.expand_dims(mask, -1)
-  mask = tf.tile(mask, [1, 1, 1, 3])
-  image = tf.where(
-      tf.equal(mask, 0),
-      tf.ones_like(image, dtype=image.dtype) * replace, image)
-  return image
+  num_channels = tf.shape(video)[-1]
+  mask = tf.tile(mask, [1, 1, 1, num_channels])
+  video = tf.where(
+      tf.equal(mask, 0), tf.ones_like(video, dtype=video.dtype) * replace, video
+  )
+  return video
+
+
+def gaussian_noise(
+    image: tf.Tensor, low: float = 0.1, high: float = 2.0) -> tf.Tensor:
+  """Add Gaussian noise to image(s)."""
+  augmented_image = gaussian_filter2d(  # pylint: disable=g-long-lambda
+      image, filter_shape=[3, 3], sigma=np.random.uniform(low=low, high=high)
+  )
+  return augmented_image
 
 
 def solarize(image: tf.Tensor, threshold: int = 128) -> tf.Tensor:
   """Solarize the input image(s)."""
   # For each pixel in the image, select the pixel
   # if the value is less than the threshold.
   # Otherwise, subtract 255 from the pixel.
@@ -483,17 +818,22 @@
   # pixel value to be between 0 and 255. The value
   # of 'addition' is between -128 and 128.
   added_image = tf.cast(image, tf.int64) + addition
   added_image = tf.cast(tf.clip_by_value(added_image, 0, 255), tf.uint8)
   return tf.where(image < threshold, added_image, image)
 
 
+def grayscale(image: tf.Tensor) -> tf.Tensor:
+  """Convert image to grayscale."""
+  return tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))
+
+
 def color(image: tf.Tensor, factor: float) -> tf.Tensor:
   """Equivalent of PIL Color."""
-  degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))
+  degenerate = grayscale(image)
   return blend(degenerate, image, factor)
 
 
 def contrast(image: tf.Tensor, factor: float) -> tf.Tensor:
   """Equivalent of PIL Contrast."""
   degenerate = tf.image.rgb_to_grayscale(image)
   # Cast before calling tf.histogram.
@@ -1346,14 +1686,20 @@
 def _translate_level_to_arg(level: float, translate_const: float):
   level = (level / _MAX_LEVEL) * float(translate_const)
   # Flip level to negative with 50% chance.
   level = _randomly_negate_tensor(level)
   return (level,)
 
 
+def _gaussian_noise_level_to_arg(level: float, translate_const: float):
+  low_std = (level / _MAX_LEVEL)
+  high_std = translate_const * low_std
+  return low_std, high_std
+
+
 def _mult_to_arg(level: float, multiplier: float = 1.):
   return (int((level / _MAX_LEVEL) * multiplier),)
 
 
 def _apply_func_with_prob(func: Any, image: tf.Tensor,
                           bboxes: Optional[tf.Tensor], args: Any, prob: float):
   """Apply `func` to image w/ `args` as input with probability `prob`."""
@@ -1366,17 +1712,17 @@
   augmented_image, augmented_bboxes = tf.cond(
       should_apply_op,
       lambda: func(image, bboxes, *args),
       lambda: (image, bboxes))
   return augmented_image, augmented_bboxes
 
 
-def select_and_apply_random_policy(policies: Any,
-                                   image: tf.Tensor,
-                                   bboxes: Optional[tf.Tensor] = None):
+def select_and_apply_random_policy(
+    policies: Any, image: tf.Tensor, bboxes: Optional[tf.Tensor] = None
+) -> Tuple[tf.Tensor, Optional[tf.Tensor]]:
   """Select a random policy from `policies` and apply it to `image`."""
   policy_to_select = tf.random.uniform([], maxval=len(policies), dtype=tf.int32)
   # Note that using tf.case instead of tf.conds would result in significantly
   # larger graphs and would even break export for some larger policies.
   for (i, policy) in enumerate(policies):
     image, bboxes = tf.cond(
         tf.equal(i, policy_to_select),
@@ -1399,14 +1745,16 @@
     'Sharpness': sharpness,
     'ShearX': shear_x,
     'ShearY': shear_y,
     'TranslateX': translate_x,
     'TranslateY': translate_y,
     'Cutout': cutout,
     'Rotate_BBox': rotate_with_bboxes,
+    'Grayscale': grayscale,
+    'Gaussian_Noise': gaussian_noise,
     # pylint:disable=g-long-lambda
     'ShearX_BBox': lambda image, bboxes, level, replace: shear_with_bboxes(
         image, bboxes, level, replace, shear_horizontal=True),
     'ShearY_BBox': lambda image, bboxes, level, replace: shear_with_bboxes(
         image, bboxes, level, replace, shear_horizontal=False),
     'TranslateX_BBox': lambda image, bboxes, pixels, replace: translate_bbox(
         image, bboxes, pixels, replace, shift_horizontal=True),
@@ -1475,14 +1823,18 @@
       'ShearY': _shear_level_to_arg,
       'Cutout': cutout_arg,
       'TranslateX': translate_arg,
       'TranslateY': translate_arg,
       'Rotate_BBox': _rotate_level_to_arg,
       'ShearX_BBox': _shear_level_to_arg,
       'ShearY_BBox': _shear_level_to_arg,
+      'Grayscale': no_arg,
+      # pylint:disable=g-long-lambda
+      'Gaussian_Noise': lambda level: _gaussian_noise_level_to_arg(
+          level, translate_const),
       # pylint:disable=g-long-lambda
       'TranslateX_BBox': lambda level: _translate_level_to_arg(
           level, translate_const),
       'TranslateY_BBox': lambda level: _translate_level_to_arg(
           level, translate_const),
       # pylint:enable=g-long-lambda
       'TranslateY_Only_BBoxes': translate_bbox_arg,
@@ -1493,15 +1845,15 @@
 def bbox_wrapper(func):
   """Adds a bboxes function argument to func and returns unchanged bboxes."""
   def wrapper(images, bboxes, *args, **kwargs):
     return (func(images, *args, **kwargs), bboxes)
   return wrapper
 
 
-def _parse_policy_info(name: Text,
+def _parse_policy_info(name: str,
                        prob: float,
                        level: float,
                        replace_value: List[int],
                        cutout_const: float,
                        translate_const: float,
                        level_std: float = 0.) -> Tuple[Any, float, Any]:
   """Return the function that corresponds to `name` and update `level` param."""
@@ -1534,14 +1886,16 @@
 
   def distort(
       self,
       image: tf.Tensor
   ) -> tf.Tensor:
     """Given an image tensor, returns a distorted image with the same shape.
 
+    Expect the image tensor values are in the range [0, 255].
+
     Args:
       image: `Tensor` of shape [height, width, 3] or
         [num_frames, height, width, 3] representing an image or image sequence.
 
     Returns:
       The augmented version of `image`.
     """
@@ -1550,14 +1904,16 @@
   def distort_with_boxes(
       self,
       image: tf.Tensor,
       bboxes: tf.Tensor
   ) -> Tuple[tf.Tensor, tf.Tensor]:
     """Distorts the image and bounding boxes.
 
+    Expect the image tensor values are in the range [0, 255].
+
     Args:
       image: `Tensor` of shape [height, width, 3] or
         [num_frames, height, width, 3] representing an image or image sequence.
       bboxes: `Tensor` of shape [num_boxes, 4] or [num_frames, num_boxes, 4]
         representing bounding boxes for an image or image sequence.
 
     Returns:
@@ -1569,16 +1925,16 @@
 class AutoAugment(ImageAugment):
   """Applies the AutoAugment policy to images.
 
     AutoAugment is from the paper: https://arxiv.org/abs/1805.09501.
   """
 
   def __init__(self,
-               augmentation_name: Text = 'v0',
-               policies: Optional[Iterable[Iterable[Tuple[Text, float,
+               augmentation_name: str = 'v0',
+               policies: Optional[Iterable[Iterable[Tuple[str, float,
                                                           float]]]] = None,
                cutout_const: float = 100,
                translate_const: float = 250):
     """Applies the AutoAugment policy to images.
 
     Args:
       augmentation_name: The name of the AutoAugment policy to use. The
@@ -1620,14 +1976,15 @@
         'test': self.policy_test(),
         'simple': self.policy_simple(),
         'reduced_cifar10': self.policy_reduced_cifar10(),
         'svhn': self.policy_svhn(),
         'reduced_imagenet': self.policy_reduced_imagenet(),
         'panoptic_deeplab_policy': self.panoptic_deeplab_policy(),
         'vit': self.vit(),
+        'deit3_three_augment': self.deit3_three_augment(),
     }
 
     if not policies:
       if augmentation_name not in self.available_policies:
         raise ValueError(
             'Invalid augmentation_name: {}'.format(augmentation_name))
 
@@ -1713,14 +2070,16 @@
     input_image_type = image.dtype
     if input_image_type != tf.uint8:
       image = tf.clip_by_value(image, 0.0, 255.0)
       image = tf.cast(image, dtype=tf.uint8)
 
     tf_policies = self._make_tf_policies()
     image, bboxes = select_and_apply_random_policy(tf_policies, image, bboxes)
+    image = tf.cast(image, dtype=input_image_type)
+    assert bboxes is not None
     return image, bboxes
 
   @staticmethod
   def detection_policy_v0():
     """Autoaugment policy that was used in AutoAugment Paper for Detection.
 
     https://arxiv.org/pdf/1906.11172
@@ -1952,14 +2311,35 @@
         [('Invert', 0.6, 4), ('Equalize', 1.0, 8), ('Cutout', 0.8, 8)],
         [('Posterize', 0.6, 7), ('Posterize', 0.6, 6), ('Cutout', 0.8, 8)],
         [('Solarize', 0.6, 5), ('AutoContrast', 0.6, 5), ('Cutout', 0.8, 8)],
         ]
     return policy
 
   @staticmethod
+  def deit3_three_augment():
+    """Autoaugment policy for three augmentations.
+
+    Proposed in paper: https://arxiv.org/abs/2204.07118.
+
+    Each tuple is an augmentation operation of the form
+    (operation, probability, magnitude). Each element in policy is a
+    sub-policy that will be applied on the image. Randomly chooses one of the
+    three augmentation to apply on image.
+
+    Returns:
+      the policy.
+    """
+    policy = [
+        [('Grayscale', 1.0, 0)],
+        [('Solarize', 1.0, 5)],  # to have threshold as 128
+        [('Gaussian_Noise', 1.0, 1)],  # to have low_std as 0.1
+        ]
+    return policy
+
+  @staticmethod
   def policy_test():
     """Autoaugment test policy for debugging."""
     policy = [
         [('TranslateX', 1.0, 4), ('Equalize', 1.0, 10)],
     ]
     return policy
 
@@ -2110,14 +2490,15 @@
     image, _ = self._distort_common(image)
     return image
 
   def distort_with_boxes(self, image: tf.Tensor,
                          bboxes: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:
     """See base class."""
     image, bboxes = self._distort_common(image, bboxes)
+    assert bboxes is not None
     return image, bboxes
 
 
 class RandomErasing(ImageAugment):
   """Applies RandomErasing to a single image.
 
   Reference: https://arxiv.org/abs/1708.04896
@@ -2243,35 +2624,36 @@
   - Mixup: https://arxiv.org/abs/1710.09412
   - Cutmix: https://arxiv.org/abs/1905.04899
 
   Implementaion is inspired by https://github.com/rwightman/pytorch-image-models
   """
 
   def __init__(self,
+               num_classes: int,
                mixup_alpha: float = .8,
                cutmix_alpha: float = 1.,
                prob: float = 1.0,
                switch_prob: float = 0.5,
-               label_smoothing: float = 0.1,
-               num_classes: int = 1001):
+               label_smoothing: float = 0.1):
     """Applies Mixup and/or Cutmix to a batch of images.
 
     Args:
+
+      num_classes (int): Number of classes.
       mixup_alpha (float, optional): For drawing a random lambda (`lam`) from a
         beta distribution (for each image). If zero Mixup is deactivated.
         Defaults to .8.
       cutmix_alpha (float, optional): For drawing a random lambda (`lam`) from a
         beta distribution (for each image). If zero Cutmix is deactivated.
         Defaults to 1..
       prob (float, optional): Of augmenting the batch. Defaults to 1.0.
       switch_prob (float, optional): Probability of applying Cutmix for the
         batch. Defaults to 0.5.
       label_smoothing (float, optional): Constant for label smoothing. Defaults
         to 0.1.
-      num_classes (int, optional): Number of classes. Defaults to 1001.
     """
     self.mixup_alpha = mixup_alpha
     self.cutmix_alpha = cutmix_alpha
     self.mix_prob = prob
     self.switch_prob = switch_prob
     self.label_smoothing = label_smoothing
     self.num_classes = num_classes
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/augment_test.py` & `tf-models-no-deps-2.16.0/official/vision/ops/augment_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -17,15 +17,16 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import random
 from absl.testing import parameterized
 
-import tensorflow as tf
+import numpy as np
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import augment
 
 
 def get_dtype_test_cases():
   return [
       ('uint8', tf.uint8),
@@ -81,14 +82,30 @@
 
   def test_rotate_shapes(self, dtype):
     degrees = 0.
     for shape in [(3, 3), (5, 5), (224, 224, 3)]:
       image = tf.zeros(shape, dtype=dtype)
       self.assertAllEqual(image, augment.rotate(image, degrees))
 
+  def test_random_cutout_video(self, dtype):
+    for num_channels in (1, 2, 3):
+      video = tf.ones((2, 2, 2, num_channels), dtype=dtype)
+      video = augment.cutout_video(video)
+
+      num_zeros = np.sum(video == 0)
+      self.assertGreater(num_zeros, 0)
+
+  def test_cutout_video_with_fixed_shape(self, dtype):
+    tf.random.set_seed(0)
+    video = tf.ones((10, 10, 10, 1), dtype=dtype)
+    video = augment.cutout_video(video, mask_shape=tf.constant([2, 2, 2]))
+
+    num_zeros = np.sum(video == 0)
+    self.assertEqual(num_zeros, 8)
+
 
 class AutoaugmentTest(tf.test.TestCase, parameterized.TestCase):
 
   AVAILABLE_POLICIES = [
       'v0',
       'test',
       'simple',
@@ -300,14 +317,23 @@
     """Test autoaugment with a custom policy."""
     image = tf.zeros((224, 224, 3), dtype=tf.uint8)
     augmenter = augment.AutoAugment(policies=self._generate_test_policy())
     aug_image = augmenter.distort(image)
 
     self.assertEqual((224, 224, 3), aug_image.shape)
 
+  def test_autoaugment_three_augment(self):
+    """Test three augmentation."""
+    image = tf.random.normal(shape=(224, 224, 3), dtype=tf.float32)
+    augmenter = augment.AutoAugment(augmentation_name='deit3_three_augment')
+    aug_image = augmenter.distort(image)
+
+    self.assertEqual((224, 224, 3), aug_image.shape)
+    self.assertFalse(tf.math.reduce_all(image == aug_image))
+
   @parameterized.named_parameters(
       {'testcase_name': '_OutOfRangeProb',
        'sub_policy': ('Equalize', 1.1, 3), 'value': '1.1'},
       {'testcase_name': '_OutOfRangeMag',
        'sub_policy': ('Equalize', 0.9, 11), 'value': '11'},
   )
   def test_invalid_custom_sub_policy(self, sub_policy, value):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/box_matcher.py` & `tf-models-no-deps-2.16.0/official/vision/ops/box_matcher.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Box matcher implementation."""
 
 from typing import List, Tuple
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class BoxMatcher:
   """Matcher based on highest value.
 
   This class computes matches from a similarity matrix. Each column is matched
   to a single row.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/box_matcher_test.py` & `tf-models-no-deps-2.16.0/official/vision/ops/box_matcher_test.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for box_matcher.py."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import box_matcher
 
 
 class BoxMatcherTest(tf.test.TestCase):
 
   def test_box_matcher_unbatched(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/box_ops.py` & `tf-models-no-deps-2.16.0/official/vision/ops/box_ops.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Box related ops."""
 
 # Import libraries
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 EPSILON = 1e-8
 BBOX_XFORM_CLIP = np.log(1000. / 16.)
 
 
 def yxyx_to_xywh(boxes):
@@ -101,15 +101,15 @@
   boxes_xmax = boxes[..., 1] + boxes[..., 3] / 2
   new_boxes = tf.stack([
       boxes_ymin, boxes_xmin, boxes_ymax, boxes_xmax], axis=-1)
   return new_boxes
 
 
 def jitter_boxes(boxes, noise_scale=0.025):
-  """Jitter the box coordinates by some noise distribution.
+  """Jitters the box coordinates by some noise distribution.
 
   Args:
     boxes: a tensor whose last dimension is 4 representing the coordinates of
       boxes in ymin, xmin, ymax, xmax order.
     noise_scale: a python float which specifies the magnitude of noise. The rule
       of thumb is to set this between (0, 0.1]. The default value is found to
       mimic the noisy detections best empirically.
@@ -235,14 +235,36 @@
         value=normalized_boxes, num_or_size_splits=4, axis=-1)
     flipped_xmin = tf.subtract(1.0, xmax)
     flipped_xmax = tf.subtract(1.0, xmin)
     flipped_boxes = tf.concat([ymin, flipped_xmin, ymax, flipped_xmax], axis=-1)
     return flipped_boxes
 
 
+def vertical_flip_boxes(normalized_boxes):
+  """Flips normalized boxes vertically.
+
+  Args:
+    normalized_boxes: the boxes in normalzied coordinates.
+
+  Returns:
+    vertically flipped boxes.
+  """
+  if normalized_boxes.shape[-1] != 4:
+    raise ValueError('boxes.shape[-1] is {:d}, but must be 4.'.format(
+        normalized_boxes.shape[-1]))
+
+  with tf.name_scope('vertical_flip_boxes'):
+    ymin, xmin, ymax, xmax = tf.split(
+        value=normalized_boxes, num_or_size_splits=4, axis=-1)
+    flipped_ymin = tf.subtract(1.0, ymax)
+    flipped_ymax = tf.subtract(1.0, ymin)
+    flipped_boxes = tf.concat([flipped_ymin, xmin, flipped_ymax, xmax], axis=-1)
+    return flipped_boxes
+
+
 def clip_boxes(boxes, image_shape):
   """Clips boxes to image boundaries.
 
   Args:
     boxes: a tensor whose last dimension is 4 representing the coordinates
       of boxes in ymin, xmin, ymax, xmax order.
     image_shape: a list of two integers, a two-element vector or a tensor such
@@ -270,15 +292,15 @@
       max_length = tf.stack([height, width, height, width], axis=-1)
 
     clipped_boxes = tf.math.maximum(tf.math.minimum(boxes, max_length), 0.0)
     return clipped_boxes
 
 
 def compute_outer_boxes(boxes, image_shape, scale=1.0):
-  """Compute outer box encloses an object with a margin.
+  """Computes outer box encloses an object with a margin.
 
   Args:
     boxes: a tensor whose last dimension is 4 representing the coordinates of
       boxes in ymin, xmin, ymax, xmax order.
     image_shape: a list of two integers, a two-element vector or a tensor such
       that all but the last dimensions are `broadcastable` to `boxes`. The last
       dimension is 2, which represents [height, width].
@@ -289,28 +311,30 @@
     outer_boxes: a tensor whose shape is the same as `boxes` representing the
       outer boxes.
   """
   if scale < 1.0:
     raise ValueError(
         'scale is {}, but outer box scale must be greater than 1.0.'.format(
             scale))
+  if scale == 1.0:
+    return boxes
   centers_y = (boxes[..., 0] + boxes[..., 2]) / 2.0
   centers_x = (boxes[..., 1] + boxes[..., 3]) / 2.0
   box_height = (boxes[..., 2] - boxes[..., 0]) * scale
   box_width = (boxes[..., 3] - boxes[..., 1]) * scale
   outer_boxes = tf.stack(
       [centers_y - box_height / 2.0, centers_x - box_width / 2.0,
        centers_y + box_height / 2.0, centers_x + box_width / 2.0],
-      axis=1)
+      axis=-1)
   outer_boxes = clip_boxes(outer_boxes, image_shape)
   return outer_boxes
 
 
 def encode_boxes(boxes, anchors, weights=None):
-  """Encode boxes to targets.
+  """Encodes boxes to targets.
 
   Args:
     boxes: a tensor whose last dimension is 4 representing the coordinates
       of boxes in ymin, xmin, ymax, xmax order.
     anchors: a tensor whose shape is the same as, or `broadcastable` to `boxes`,
       representing the coordinates of anchors in ymin, xmin, ymax, xmax order.
     weights: None or a list of four float numbers used to scale coordinates.
@@ -342,14 +366,20 @@
     anchor_ymax = anchors[..., 2:3]
     anchor_xmax = anchors[..., 3:4]
     anchor_h = anchor_ymax - anchor_ymin
     anchor_w = anchor_xmax - anchor_xmin
     anchor_yc = anchor_ymin + 0.5 * anchor_h
     anchor_xc = anchor_xmin + 0.5 * anchor_w
 
+    # Avoid inf in log below.
+    anchor_h += EPSILON
+    anchor_w += EPSILON
+    box_h += EPSILON
+    box_w += EPSILON
+
     encoded_dy = (box_yc - anchor_yc) / anchor_h
     encoded_dx = (box_xc - anchor_xc) / anchor_w
     encoded_dh = tf.math.log(box_h / anchor_h)
     encoded_dw = tf.math.log(box_w / anchor_w)
     if weights:
       encoded_dy *= weights[0]
       encoded_dx *= weights[1]
@@ -358,50 +388,45 @@
 
     encoded_boxes = tf.concat(
         [encoded_dy, encoded_dx, encoded_dh, encoded_dw], axis=-1)
     return encoded_boxes
 
 
 def decode_boxes(encoded_boxes, anchors, weights=None):
-  """Decode boxes.
+  """Decodes boxes.
 
   Args:
     encoded_boxes: a tensor whose last dimension is 4 representing the
-      coordinates of encoded boxes in ymin, xmin, ymax, xmax order.
+      coordinates of encoded boxes in dy, dx, dh, dw in order.
     anchors: a tensor whose shape is the same as, or `broadcastable` to `boxes`,
       representing the coordinates of anchors in ymin, xmin, ymax, xmax order.
     weights: None or a list of four float numbers used to scale coordinates.
 
   Returns:
-    encoded_boxes: a tensor whose shape is the same as `boxes` representing the
+    decoded_boxes: a tensor whose shape is the same as `boxes` representing the
       decoded box targets.
   """
   if encoded_boxes.shape[-1] != 4:
     raise ValueError(
         'encoded_boxes.shape[-1] is {:d}, but must be 4.'
         .format(encoded_boxes.shape[-1]))
 
   with tf.name_scope('decode_boxes'):
     encoded_boxes = tf.cast(encoded_boxes, dtype=anchors.dtype)
-    dy = encoded_boxes[..., 0:1]
-    dx = encoded_boxes[..., 1:2]
-    dh = encoded_boxes[..., 2:3]
-    dw = encoded_boxes[..., 3:4]
+    dy, dx, dh, dw = tf.split(encoded_boxes, 4, -1)
     if weights:
       dy /= weights[0]
       dx /= weights[1]
       dh /= weights[2]
       dw /= weights[3]
     dh = tf.math.minimum(dh, BBOX_XFORM_CLIP)
     dw = tf.math.minimum(dw, BBOX_XFORM_CLIP)
 
-    anchor_ymin = anchors[..., 0:1]
-    anchor_xmin = anchors[..., 1:2]
-    anchor_ymax = anchors[..., 2:3]
-    anchor_xmax = anchors[..., 3:4]
+    anchor_ymin, anchor_xmin, anchor_ymax, anchor_xmax = tf.split(
+        anchors, 4, -1)
     anchor_h = anchor_ymax - anchor_ymin
     anchor_w = anchor_xmax - anchor_xmin
     anchor_yc = anchor_ymin + 0.5 * anchor_h
     anchor_xc = anchor_xmin + 0.5 * anchor_w
 
     decoded_boxes_yc = dy * anchor_h + anchor_yc
     decoded_boxes_xc = dx * anchor_w + anchor_xc
@@ -417,15 +442,15 @@
         [decoded_boxes_ymin, decoded_boxes_xmin,
          decoded_boxes_ymax, decoded_boxes_xmax],
         axis=-1)
     return decoded_boxes
 
 
 def filter_boxes(boxes, scores, image_shape, min_size_threshold):
-  """Filter and remove boxes that are too small or fall outside the image.
+  """Filters and remove boxes that are too small or fall outside the image.
 
   Args:
     boxes: a tensor whose last dimension is 4 representing the coordinates of
       boxes in ymin, xmin, ymax, xmax order.
     scores: a tensor whose shape is the same as tf.shape(boxes)[:-1]
       representing the original scores of the boxes.
     image_shape: a tensor whose shape is the same as, or `broadcastable` to
@@ -477,15 +502,15 @@
     filtered_scores = tf.where(filtered_mask, scores, tf.zeros_like(scores))
     filtered_boxes = tf.cast(
         tf.expand_dims(filtered_mask, axis=-1), dtype=boxes.dtype) * boxes
     return filtered_boxes, filtered_scores
 
 
 def filter_boxes_by_scores(boxes, scores, min_score_threshold):
-  """Filter and remove boxes whose scores are smaller than the threshold.
+  """Filters and remove boxes whose scores are smaller than the threshold.
 
   Args:
     boxes: a tensor whose last dimension is 4 representing the coordinates of
       boxes in ymin, xmin, ymax, xmax order.
     scores: a tensor whose shape is the same as tf.shape(boxes)[:-1]
       representing the original scores of the boxes.
     min_score_threshold: a float representing the minimal box score threshold.
@@ -507,15 +532,15 @@
     filtered_boxes = tf.cast(
         tf.expand_dims(filtered_mask, axis=-1), dtype=boxes.dtype) * boxes
 
     return filtered_boxes, filtered_scores
 
 
 def gather_instances(selected_indices, instances, *aux_instances):
-  """Gather instances by indices.
+  """Gathers instances by indices.
 
   Args:
     selected_indices: a Tensor of shape [batch, K] which indicates the selected
       indices in instance dimension (2nd dimension).
     instances: a Tensor of shape [batch, N, ...] where the 2nd dimension is
       the instance dimension to be selected from.
     *aux_instances: the additional Tensors whose shapes are in [batch, N, ...]
@@ -555,15 +580,15 @@
       ]
       return tuple([selected_instances] + selected_aux_instances)
     else:
       return selected_instances
 
 
 def top_k_boxes(boxes, scores, k):
-  """Sort and select top k boxes according to the scores.
+  """Sorts and select top k boxes according to the scores.
 
   Args:
     boxes: a tensor of shape [batch_size, N, 4] representing the coordinate of
       the boxes. N is the number of boxes per image.
     scores: a tensor of shsape [batch_size, N] representing the socre of the
       boxes.
     k: an integer or a tensor indicating the top k number.
@@ -577,15 +602,15 @@
   with tf.name_scope('top_k_boxes'):
     selected_scores, top_k_indices = tf.nn.top_k(scores, k=k, sorted=True)
     selected_boxes = gather_instances(top_k_indices, boxes)
     return selected_boxes, selected_scores
 
 
 def get_non_empty_box_indices(boxes):
-  """Get indices for non-empty boxes."""
+  """Gets indices for non-empty boxes."""
   # Selects indices if box height or width is 0.
   height = boxes[:, 2] - boxes[:, 0]
   width = boxes[:, 3] - boxes[:, 1]
   indices = tf.where(tf.logical_and(tf.greater(height, 0),
                                     tf.greater(width, 0)))
   return indices[:, 0]
 
@@ -712,16 +737,71 @@
         tf.reduce_max(gt_boxes, axis=-1, keepdims=True), 0.0)
     padding_mask = tf.broadcast_to(
         tf.transpose(gt_invalid_mask, [0, 2, 1]), tf.shape(giou))
     giou = tf.where(padding_mask, -tf.ones_like(giou), giou)
     return giou
 
 
+def bbox_intersection_over_area(boxes, gt_boxes):
+  """Calculates IoAs (intersection over area) between proposal and ground truth boxes.
+
+  Some `boxes` or `gt_boxes` may have been padded.  The returned `iou` tensor
+  for these boxes will be -1.
+
+  Args:
+    boxes: a tensor with a shape of [batch_size, N, 4]. N is the number of
+      proposals before groundtruth assignment (e.g., rpn_post_nms_topn). The
+      last dimension is the pixel coordinates in [ymin, xmin, ymax, xmax] form.
+    gt_boxes: a tensor with a shape of [batch_size, M, 4]. This tensor might
+      have paddings with a negative value.
+
+  Returns:
+    ioa: a tensor with as a shape of [batch_size, N, M].
+  """
+  with tf.name_scope('bbox_overlap'):
+    bb_y_min, bb_x_min, bb_y_max, bb_x_max = tf.split(
+        value=boxes, num_or_size_splits=4, axis=2
+    )
+    gt_y_min, gt_x_min, gt_y_max, gt_x_max = tf.split(
+        value=gt_boxes, num_or_size_splits=4, axis=2
+    )
+
+    # Calculates the intersection area.
+    i_xmin = tf.math.maximum(bb_x_min, tf.transpose(gt_x_min, [0, 2, 1]))
+    i_xmax = tf.math.minimum(bb_x_max, tf.transpose(gt_x_max, [0, 2, 1]))
+    i_ymin = tf.math.maximum(bb_y_min, tf.transpose(gt_y_min, [0, 2, 1]))
+    i_ymax = tf.math.minimum(bb_y_max, tf.transpose(gt_y_max, [0, 2, 1]))
+    i_area = tf.math.maximum((i_xmax - i_xmin), 0) * tf.math.maximum(
+        (i_ymax - i_ymin), 0
+    )
+
+    bb_area = (bb_y_max - bb_y_min) * (bb_x_max - bb_x_min)
+    ioa = tf.math.divide_no_nan(i_area, bb_area)
+
+    # Fills -1 for IoA entries between the padded ground truth boxes.
+    gt_invalid_mask = tf.less(
+        tf.reduce_max(gt_boxes, axis=-1, keepdims=True), 0.0
+    )
+    padding_mask = tf.logical_or(
+        tf.zeros_like(bb_x_min, dtype=tf.bool),
+        tf.transpose(gt_invalid_mask, [0, 2, 1]),
+    )
+    ioa = tf.where(padding_mask, -1., ioa)
+
+    # Fills -1 for invalid (-1) boxes.
+    boxes_invalid_mask = tf.less(
+        tf.reduce_max(boxes, axis=-1, keepdims=True), 0.0
+    )
+    ioa = tf.where(boxes_invalid_mask, -1., ioa)
+
+    return ioa
+
+
 def box_matching(boxes, gt_boxes, gt_classes):
-  """Match boxes to groundtruth boxes.
+  """Matches boxes to groundtruth boxes.
 
   Given the proposal boxes and the groundtruth boxes and classes, perform the
   groundtruth matching by taking the argmax of the IoU between boxes and
   groundtruth boxes.
 
   Args:
     boxes: a tensor of shape of [batch_size, N, 4] representing the box
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/iou_similarity.py` & `tf-models-no-deps-2.16.0/official/vision/ops/iou_similarity.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Region Similarity Calculators."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def area(box):
   """Computes area of boxes.
 
   B: batch_size
   N: number of boxes
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/iou_similarity_test.py` & `tf-models-no-deps-2.16.0/official/vision/ops/iou_similarity_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for iou_similarity.py."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import iou_similarity
 
 
 class BoxMatcherTest(tf.test.TestCase):
 
   def test_similarity_unbatched(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/mask_ops.py` & `tf-models-no-deps-2.16.0/official/vision/ops/mask_ops.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,17 +11,22 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Utility functions for segmentations."""
 
 import math
+from typing import List, Tuple
+
 # Import libraries
+
 import cv2
 import numpy as np
+import tensorflow as tf, tf_keras
+from official.vision.ops import spatial_transform_ops
 
 
 def paste_instance_masks(masks: np.ndarray, detected_boxes: np.ndarray,
                          image_height: int, image_width: int) -> np.ndarray:
   """Paste instance masks to generate the image segmentation results.
 
   Args:
@@ -179,7 +184,86 @@
         (y0 - ymin_int):(y1 - ymin_int),
         (x0 - xmin_int):(x1 - xmin_int)]
 
     segms.append(img_mask)
 
   segms = np.array(segms)
   return segms
+
+
+def instance_masks_overlap(
+    boxes: tf.Tensor,
+    masks: tf.Tensor,
+    gt_boxes: tf.Tensor,
+    gt_masks: tf.Tensor,
+    output_size: List[int],
+    mask_binarize_threshold: float = 0.5,
+) -> Tuple[tf.Tensor, tf.Tensor]:
+  """Calculates the IoUs and IoAs between the detection masks and the ground truth masks.
+
+  IoU: intersection over union.
+  IoA: intersection over the area of the detection masks.
+
+  Args:
+    boxes: a tensor with a shape of [batch_size, N, 4]. The last dimension is
+      the pixel coordinates in [ymin, xmin, ymax, xmax] form.
+    masks: a float tensor with a shape of [batch_size, N, mask_height,
+      mask_width] representing the instance masks w.r.t. the `boxes`.
+    gt_boxes: a tensor with a shape of [batch_size, M, 4]. The last dimension is
+      the pixel coordinates in [ymin, xmin, ymax, xmax] form.
+    gt_masks: a float tensor with a shape of [batch_size, M, gt_mask_height,
+      gt_mask_width] representing the instance masks w.r.t. the `gt_boxes`.
+    output_size: two integers that represent the height and width of the output
+      masks.
+    mask_binarize_threshold: a float representing the threshold for binarizing
+      mask values. Default value is 0.5.
+
+  Returns:
+    iou: a tensor with as a shape of [batch_size, N, M].
+  """
+  _, num_detections, mask_height, mask_width = masks.get_shape().as_list()
+  _, num_gts, gt_mask_height, gt_mask_width = gt_masks.get_shape().as_list()
+  output_height, output_width = output_size
+
+  masks = tf.where(masks < 0, tf.zeros_like(masks), masks)
+  gt_masks = tf.where(gt_masks < 0, tf.zeros_like(gt_masks), gt_masks)
+
+  pasted_masks = tf.reshape(
+      spatial_transform_ops.bilinear_resize_to_bbox(
+          tf.reshape(masks, [-1, mask_height, mask_width]),
+          tf.reshape(boxes, [-1, 4]),
+          output_size,
+      ),
+      shape=[-1, num_detections, output_height, output_width],
+  )
+  pasted_gt_masks = tf.reshape(
+      spatial_transform_ops.bilinear_resize_to_bbox(
+          tf.reshape(gt_masks, [-1, gt_mask_height, gt_mask_width]),
+          tf.reshape(gt_boxes, [-1, 4]),
+          output_size,
+      ),
+      shape=[-1, num_gts, output_height, output_width],
+  )
+  # (batch_size, num_detections, output_height * output_width)
+  flattened_binary_masks = tf.reshape(
+      pasted_masks > mask_binarize_threshold,
+      [-1, num_detections, output_height * output_width],
+  )
+  # (batch_size, num_gts, output_height * output_width)
+  flattened_gt_binary_masks = tf.reshape(
+      pasted_gt_masks > mask_binarize_threshold,
+      [-1, num_gts, output_height * output_width],
+  )
+  # (batch_size, output_height * output_width, num_gts)
+  flattened_gt_binary_masks = tf.transpose(flattened_gt_binary_masks, [0, 2, 1])
+
+  flattened_binary_masks = tf.cast(flattened_binary_masks, tf.float32)
+  flattened_gt_binary_masks = tf.cast(flattened_gt_binary_masks, tf.float32)
+
+  # (batch_size, num_detections, num_gts)
+  intersection = tf.matmul(flattened_binary_masks, flattened_gt_binary_masks)
+  detection_area = tf.reduce_sum(flattened_binary_masks, axis=-1, keepdims=True)
+  gt_area = tf.reduce_sum(flattened_gt_binary_masks, axis=-2, keepdims=True)
+  union = detection_area + gt_area - intersection
+  return tf.math.divide_no_nan(intersection, union), tf.math.divide_no_nan(
+      intersection, detection_area
+  )
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/nms.py` & `tf-models-no-deps-2.16.0/official/legacy/detection/ops/nms.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,19 +10,21 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tensorflow implementation of non max suppression."""
 
-# Import libraries
-import tensorflow as tf
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
 
-from official.vision.ops import box_ops
+import tensorflow as tf, tf_keras
 
+from official.legacy.detection.utils import box_utils
 
 NMS_TILE_SIZE = 512
 
 
 def _self_suppression(iou, _, iou_sum):
   batch_size = tf.shape(iou)[0]
   can_suppress_others = tf.cast(
@@ -37,15 +39,15 @@
   ]
 
 
 def _cross_suppression(boxes, box_slice, iou_threshold, inner_idx):
   batch_size = tf.shape(boxes)[0]
   new_slice = tf.slice(boxes, [0, inner_idx * NMS_TILE_SIZE, 0],
                        [batch_size, NMS_TILE_SIZE, 4])
-  iou = box_ops.bbox_overlap(new_slice, box_slice)
+  iou = box_utils.bbox_overlap(new_slice, box_slice)
   ret_slice = tf.expand_dims(
       tf.cast(tf.reduce_all(iou < iou_threshold, [1]), box_slice.dtype),
       2) * box_slice
   return boxes, ret_slice, iou_threshold, inner_idx + 1
 
 
 def _suppression_loop_body(boxes, iou_threshold, output_size, idx):
@@ -61,27 +63,28 @@
 
   Returns:
     boxes: updated boxes.
     iou_threshold: pass down iou_threshold to the next iteration.
     output_size: the updated output_size.
     idx: the updated induction variable.
   """
-  num_tiles = tf.shape(boxes)[1] // NMS_TILE_SIZE
-  batch_size = tf.shape(boxes)[0]
+  boxes_shape = tf.shape(boxes)
+  num_tiles = boxes_shape[1] // NMS_TILE_SIZE
+  batch_size = boxes_shape[0]
 
   # Iterates over tiles that can possibly suppress the current tile.
   box_slice = tf.slice(boxes, [0, idx * NMS_TILE_SIZE, 0],
                        [batch_size, NMS_TILE_SIZE, 4])
   _, box_slice, _, _ = tf.while_loop(
       lambda _boxes, _box_slice, _threshold, inner_idx: inner_idx < idx,
       _cross_suppression, [boxes, box_slice, iou_threshold,
                            tf.constant(0)])
 
   # Iterates over the current tile to compute self-suppression.
-  iou = box_ops.bbox_overlap(box_slice, box_slice)
+  iou = box_utils.bbox_overlap(box_slice, box_slice)
   mask = tf.expand_dims(
       tf.reshape(tf.range(NMS_TILE_SIZE), [1, -1]) > tf.reshape(
           tf.range(NMS_TILE_SIZE), [-1, 1]), 0)
   iou *= tf.cast(tf.logical_and(mask, iou >= iou_threshold), iou.dtype)
   suppressed_iou, _, _ = tf.while_loop(
       lambda _iou, loop_condition, _iou_sum: loop_condition, _self_suppression,
       [iou, tf.constant(True),
@@ -91,25 +94,23 @@
 
   # Uses box_slice to update the input boxes.
   mask = tf.reshape(
       tf.cast(tf.equal(tf.range(num_tiles), idx), boxes.dtype), [1, -1, 1, 1])
   boxes = tf.tile(tf.expand_dims(
       box_slice, [1]), [1, num_tiles, 1, 1]) * mask + tf.reshape(
           boxes, [batch_size, num_tiles, NMS_TILE_SIZE, 4]) * (1 - mask)
-  boxes = tf.reshape(boxes, [batch_size, -1, 4])
+  boxes = tf.reshape(boxes, boxes_shape)
 
   # Updates output_size.
   output_size += tf.reduce_sum(
       tf.cast(tf.reduce_any(box_slice > 0, [2]), tf.int32), [1])
   return boxes, iou_threshold, output_size, idx + 1
 
 
-def sorted_non_max_suppression_padded(scores,
-                                      boxes,
-                                      max_output_size,
+def sorted_non_max_suppression_padded(scores, boxes, max_output_size,
                                       iou_threshold):
   """A wrapper that handles non-maximum suppression.
 
   Assumption:
     * The boxes are sorted by scores unless the box is a dot (all coordinates
       are zero).
     * Boxes with higher scores can be used to suppress boxes with lower scores.
@@ -170,27 +171,26 @@
 
   def _loop_cond(unused_boxes, unused_threshold, output_size, idx):
     return tf.logical_and(
         tf.reduce_min(output_size) < max_output_size,
         idx < num_boxes // NMS_TILE_SIZE)
 
   selected_boxes, _, output_size, _ = tf.while_loop(
-      _loop_cond, _suppression_loop_body, [
-          boxes, iou_threshold,
-          tf.zeros([batch_size], tf.int32),
-          tf.constant(0)
-      ])
+      _loop_cond, _suppression_loop_body,
+      [boxes, iou_threshold,
+       tf.zeros([batch_size], tf.int32),
+       tf.constant(0)])
   idx = num_boxes - tf.cast(
       tf.nn.top_k(
           tf.cast(tf.reduce_any(selected_boxes > 0, [2]), tf.int32) *
           tf.expand_dims(tf.range(num_boxes, 0, -1), 0), max_output_size)[0],
       tf.int32)
   idx = tf.minimum(idx, num_boxes - 1)
-  idx = tf.reshape(
-      idx + tf.reshape(tf.range(batch_size) * num_boxes, [-1, 1]), [-1])
+  idx = tf.reshape(idx + tf.reshape(tf.range(batch_size) * num_boxes, [-1, 1]),
+                   [-1])
   boxes = tf.reshape(
       tf.gather(tf.reshape(boxes, [-1, 4]), idx),
       [batch_size, max_output_size, 4])
   boxes = boxes * tf.cast(
       tf.reshape(tf.range(max_output_size), [1, -1, 1]) < tf.reshape(
           output_size, [-1, 1, 1]), boxes.dtype)
   scores = tf.reshape(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/preprocess_ops.py` & `tf-models-no-deps-2.16.0/official/vision/ops/preprocess_ops.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,31 +11,33 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Preprocessing ops."""
 
 import math
-from typing import Optional, Tuple, Sequence, Union
+from typing import Optional, Sequence, Tuple, Union
 from six.moves import range
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import augment
 from official.vision.ops import box_ops
 
 CENTER_CROP_FRACTION = 0.875
 
 # Calculated from the ImageNet training set
 MEAN_NORM = (0.485, 0.456, 0.406)
 STDDEV_NORM = (0.229, 0.224, 0.225)
 MEAN_RGB = tuple(255 * i for i in MEAN_NORM)
 STDDEV_RGB = tuple(255 * i for i in STDDEV_NORM)
+MEDIAN_RGB = (128.0, 128.0, 128.0)
 
 # Alias for convenience. PLEASE use `box_ops.horizontal_flip_boxes` directly.
 horizontal_flip_boxes = box_ops.horizontal_flip_boxes
+vertical_flip_boxes = box_ops.vertical_flip_boxes
 
 
 def clip_or_pad_to_fixed_size(input_tensor, size, constant_values=0):
   """Pads data to a fixed length at the first dimension.
 
   Args:
     input_tensor: `Tensor` with any dimension.
@@ -69,30 +71,45 @@
   output_shape[0] = size
   padded_tensor.set_shape(output_shape)
   return padded_tensor
 
 
 def normalize_image(image: tf.Tensor,
                     offset: Sequence[float] = MEAN_NORM,
-                    scale: Sequence[float] = STDDEV_NORM):
-  """Normalizes the image to zero mean and unit variance."""
+                    scale: Sequence[float] = STDDEV_NORM) -> tf.Tensor:
+  """Normalizes the image to zero mean and unit variance.
+
+  If the input image dtype is float, it is expected to either have values in
+  [0, 1) and offset is MEAN_NORM, or have values in [0, 255] and offset is
+  MEAN_RGB.
+
+  Args:
+    image: A tf.Tensor in either (1) float dtype with values in range [0, 1) or
+      [0, 255], or (2) int type with values in range [0, 255].
+    offset: A tuple of mean values to be subtracted from the image.
+    scale: A tuple of normalization factors.
+
+  Returns:
+    A normalized image tensor.
+  """
   with tf.name_scope('normalize_image'):
     image = tf.image.convert_image_dtype(image, dtype=tf.float32)
     return normalize_scaled_float_image(image, offset, scale)
 
 
 def normalize_scaled_float_image(image: tf.Tensor,
                                  offset: Sequence[float] = MEAN_NORM,
                                  scale: Sequence[float] = STDDEV_NORM):
   """Normalizes a scaled float image to zero mean and unit variance.
 
-  It assumes the input image is float dtype with values in [0, 1).
+  It assumes the input image is float dtype with values in [0, 1) if offset is
+  MEAN_NORM, values in [0, 255] if offset is MEAN_RGB.
 
   Args:
-    image: A tf.Tensor in float32 dtype with values in range [0, 1).
+    image: A tf.Tensor in float32 dtype with values in range [0, 1) or [0, 255].
     offset: A tuple of mean values to be subtracted from the image.
     scale: A tuple of normalization factors.
 
   Returns:
     A normalized image tensor.
   """
   offset = tf.constant(offset)
@@ -137,15 +154,16 @@
 
 def resize_and_crop_image(image,
                           desired_size,
                           padded_size,
                           aug_scale_min=1.0,
                           aug_scale_max=1.0,
                           seed=1,
-                          method=tf.image.ResizeMethod.BILINEAR):
+                          method=tf.image.ResizeMethod.BILINEAR,
+                          keep_aspect_ratio=True):
   """Resizes the input image to output size (RetinaNet style).
 
   Resize and pad images given the desired output size of the image and
   stride size.
 
   Here are the preprocessing steps.
   1. For a given image, keep its aspect ratio and rescale the image to make it
@@ -155,21 +173,23 @@
 
   Args:
     image: a `Tensor` of shape [height, width, 3] representing an image.
     desired_size: a `Tensor` or `int` list/tuple of two elements representing
       [height, width] of the desired actual output image size.
     padded_size: a `Tensor` or `int` list/tuple of two elements representing
       [height, width] of the padded output image size. Padding will be applied
-      after scaling the image to the desired_size.
+      after scaling the image to the desired_size. Can be None to disable
+      padding.
     aug_scale_min: a `float` with range between [0, 1.0] representing minimum
       random scale applied to desired_size for training scale jittering.
     aug_scale_max: a `float` with range between [1.0, inf] representing maximum
       random scale applied to desired_size for training scale jittering.
     seed: seed for random scale jittering.
     method: function to resize input image to scaled image.
+    keep_aspect_ratio: whether or not to keep the aspect ratio when resizing.
 
   Returns:
     output_image: `Tensor` of shape [height, width, 3] where [height, width]
       equals to `output_size`.
     image_info: a 2D `Tensor` that encodes the information of the image and the
       applied preprocessing. It is in the format of
       [[original_height, original_width], [desired_height, desired_width],
@@ -177,34 +197,40 @@
       desired_width] is the actual scaled image size, and [y_scale, x_scale] is
       the scaling factor, which is the ratio of
       scaled dimension / original dimension.
   """
   with tf.name_scope('resize_and_crop_image'):
     image_size = tf.cast(tf.shape(image)[0:2], tf.float32)
 
-    random_jittering = (aug_scale_min != 1.0 or aug_scale_max != 1.0)
+    random_jittering = (
+        isinstance(aug_scale_min, tf.Tensor)
+        or isinstance(aug_scale_max, tf.Tensor)
+        or not math.isclose(aug_scale_min, 1.0)
+        or not math.isclose(aug_scale_max, 1.0)
+    )
 
     if random_jittering:
       random_scale = tf.random.uniform(
           [], aug_scale_min, aug_scale_max, seed=seed)
-      scaled_size = tf.round(random_scale * desired_size)
+      scaled_size = tf.round(random_scale * tf.cast(desired_size, tf.float32))
     else:
-      scaled_size = desired_size
+      scaled_size = tf.cast(desired_size, tf.float32)
 
-    scale = tf.minimum(
-        scaled_size[0] / image_size[0], scaled_size[1] / image_size[1])
-    scaled_size = tf.round(image_size * scale)
+    if keep_aspect_ratio:
+      scale = tf.minimum(
+          scaled_size[0] / image_size[0], scaled_size[1] / image_size[1])
+      scaled_size = tf.round(image_size * scale)
 
     # Computes 2D image_scale.
     image_scale = scaled_size / image_size
 
     # Selects non-zero random offset (x, y) if scaled image is larger than
     # desired_size.
     if random_jittering:
-      max_offset = scaled_size - desired_size
+      max_offset = scaled_size - tf.cast(desired_size, tf.float32)
       max_offset = tf.where(
           tf.less(max_offset, 0), tf.zeros_like(max_offset), max_offset)
       offset = max_offset * tf.random.uniform([2,], 0, 1, seed=seed)
       offset = tf.cast(offset, tf.int32)
     else:
       offset = tf.zeros((2,), tf.int32)
 
@@ -212,20 +238,22 @@
         image, tf.cast(scaled_size, tf.int32), method=method)
 
     if random_jittering:
       scaled_image = scaled_image[
           offset[0]:offset[0] + desired_size[0],
           offset[1]:offset[1] + desired_size[1], :]
 
-    output_image = tf.image.pad_to_bounding_box(
-        scaled_image, 0, 0, padded_size[0], padded_size[1])
+    output_image = scaled_image
+    if padded_size is not None:
+      output_image = tf.image.pad_to_bounding_box(
+          scaled_image, 0, 0, padded_size[0], padded_size[1])
 
     image_info = tf.stack([
         image_size,
-        tf.constant(desired_size, dtype=tf.float32),
+        tf.cast(desired_size, dtype=tf.float32),
         image_scale,
         tf.cast(offset, tf.float32)])
     return output_image, image_info
 
 
 def resize_and_crop_image_v2(image,
                              short_side,
@@ -240,30 +268,31 @@
   Resize and pad images given the specified short / long side length and the
   stride size.
 
   Here are the preprocessing steps.
   1. For a given image, keep its aspect ratio and first try to rescale the short
      side of the original image to `short_side`.
   2. If the scaled image after 1 has a long side that exceeds `long_side`, keep
-     the aspect ratio and rescal the long side of the image to `long_side`.
-  2. Pad the rescaled image to the padded_size.
+     the aspect ratio and rescale the long side of the image to `long_side`.
+  3. (Optional) Apply random jittering according to `aug_scale_min` and
+    `aug_scale_max`. By default this step is skipped.
+  4. Pad the rescaled image to the padded_size.
 
   Args:
     image: a `Tensor` of shape [height, width, 3] representing an image.
     short_side: a scalar `Tensor` or `int` representing the desired short side
       to be rescaled to.
     long_side: a scalar `Tensor` or `int` representing the desired long side to
       be rescaled to.
     padded_size: a `Tensor` or `int` list/tuple of two elements representing
-      [height, width] of the padded output image size. Padding will be applied
-      after scaling the image to the desired_size.
+      [height, width] of the padded output image size.
     aug_scale_min: a `float` with range between [0, 1.0] representing minimum
-      random scale applied to desired_size for training scale jittering.
+      random scale applied for training scale jittering.
     aug_scale_max: a `float` with range between [1.0, inf] representing maximum
-      random scale applied to desired_size for training scale jittering.
+      random scale applied for training scale jittering.
     seed: seed for random scale jittering.
     method: function to resize input image to scaled image.
 
   Returns:
     output_image: `Tensor` of shape [height, width, 3] where [height, width]
       equals to `output_size`.
     image_info: a 2D `Tensor` that encodes the information of the image and the
@@ -286,15 +315,20 @@
     scaled_size = tf.where(
         tf.math.greater(
             tf.math.maximum(scaled_size[0], scaled_size[1]), long_side),
         tf.math.round(image_size * scale_using_long_side),
         scaled_size)
     desired_size = scaled_size
 
-    random_jittering = (aug_scale_min != 1.0 or aug_scale_max != 1.0)
+    random_jittering = (
+        isinstance(aug_scale_min, tf.Tensor)
+        or isinstance(aug_scale_max, tf.Tensor)
+        or not math.isclose(aug_scale_min, 1.0)
+        or not math.isclose(aug_scale_max, 1.0)
+    )
 
     if random_jittering:
       random_scale = tf.random.uniform(
           [], aug_scale_min, aug_scale_max, seed=seed)
       scaled_size = tf.math.round(random_scale * scaled_size)
 
     # Computes 2D image_scale.
@@ -406,43 +440,48 @@
       tf.cast(size, dtype=tf.float32),
       tf.cast(image_scale, tf.float32),
       tf.constant([0.0, 0.0], dtype=tf.float32)
   ])
   return rescaled_image, image_info
 
 
-def center_crop_image(image):
+def center_crop_image(
+    image, center_crop_fraction: float = CENTER_CROP_FRACTION):
   """Center crop a square shape slice from the input image.
 
   It crops a square shape slice from the image. The side of the actual crop
   is 224 / 256 = 0.875 of the short side of the original image. References:
   [1] Very Deep Convolutional Networks for Large-Scale Image Recognition
       https://arxiv.org/abs/1409.1556
   [2] Deep Residual Learning for Image Recognition
       https://arxiv.org/abs/1512.03385
 
   Args:
     image: a Tensor of shape [height, width, 3] representing the input image.
+    center_crop_fraction: a float of ratio between the side of the cropped image
+      and the short side of the original image
 
   Returns:
     cropped_image: a Tensor representing the center cropped image.
   """
   with tf.name_scope('center_crop_image'):
     image_size = tf.cast(tf.shape(image)[:2], dtype=tf.float32)
     crop_size = (
-        CENTER_CROP_FRACTION * tf.math.minimum(image_size[0], image_size[1]))
+        center_crop_fraction * tf.math.minimum(image_size[0], image_size[1]))
     crop_offset = tf.cast((image_size - crop_size) / 2.0, dtype=tf.int32)
     crop_size = tf.cast(crop_size, dtype=tf.int32)
     cropped_image = image[
         crop_offset[0]:crop_offset[0] + crop_size,
         crop_offset[1]:crop_offset[1] + crop_size, :]
     return cropped_image
 
 
-def center_crop_image_v2(image_bytes, image_shape):
+def center_crop_image_v2(
+    image_bytes, image_shape, center_crop_fraction: float = CENTER_CROP_FRACTION
+):
   """Center crop a square shape slice from the input image.
 
   It crops a square shape slice from the image. The side of the actual crop
   is 224 / 256 = 0.875 of the short side of the original image. References:
   [1] Very Deep Convolutional Networks for Large-Scale Image Recognition
       https://arxiv.org/abs/1409.1556
   [2] Deep Residual Learning for Image Recognition
@@ -451,22 +490,25 @@
   This is a faster version of `center_crop_image` which takes the original
   image bytes and image size as the inputs, and partially decode the JPEG
   bytes according to the center crop.
 
   Args:
     image_bytes: a Tensor of type string representing the raw image bytes.
     image_shape: a Tensor specifying the shape of the raw image.
+    center_crop_fraction: a float of ratio between the side of the cropped image
+      and the short side of the original image
 
   Returns:
     cropped_image: a Tensor representing the center cropped image.
   """
   with tf.name_scope('center_image_crop_v2'):
     image_shape = tf.cast(image_shape, tf.float32)
-    crop_size = (
-        CENTER_CROP_FRACTION * tf.math.minimum(image_shape[0], image_shape[1]))
+    crop_size = center_crop_fraction * tf.math.minimum(
+        image_shape[0], image_shape[1]
+    )
     crop_offset = tf.cast((image_shape - crop_size) / 2.0, dtype=tf.int32)
     crop_size = tf.cast(crop_size, dtype=tf.int32)
     crop_window = tf.stack(
         [crop_offset[0], crop_offset[1], crop_size, crop_size])
     cropped_image = tf.image.decode_and_crop_jpeg(
         image_bytes, crop_window, channels=3)
     return cropped_image
@@ -623,22 +665,42 @@
 
 def horizontal_flip_image(image):
   """Flips image horizontally."""
   return tf.image.flip_left_right(image)
 
 
 def horizontal_flip_masks(masks):
-  """Flips masks horizontally."""
-  return masks[:, :, ::-1]
+  """Flips masks horizontally. Expects rank-3 input dimensions [h, w, 1]."""
+  return masks[:, ::-1, :]
 
 
-def random_horizontal_flip(image, normalized_boxes=None, masks=None, seed=1):
-  """Randomly flips input image and bounding boxes."""
+def random_horizontal_flip(
+    image, normalized_boxes=None, masks=None, seed=1, prob=0.5
+):
+  """Randomly flips input image and bounding boxes and/or masks horizontally.
+  
+  Expects input tensors without the batch dimension; i.e. for RGB image assume
+  rank-3 input like [h, w, 3], for masks assume [h, w, 1].
+  
+  Args:
+    image: `tf.Tensor`, the image to apply the random flip, [h, w, channels].
+    normalized_boxes: `tf.Tensor` or `None`, boxes corresponding to the image.
+    masks: `tf.Tensor` or `None`, masks corresponding to the image, [h, w, 1].
+    seed: Seed for Tensorflow's random number generator.
+    prob: A float from 0 to 1 indicating the probability of flipping the input
+      horizontally.
+
+  Returns:
+    image: `tf.Tensor`, flipped image.
+    boxes: `tf.Tensor` or `None`, flipped normalized boxes corresponding to the
+      image.
+    masks: `tf.Tensor` or `None`, flipped masks corresponding to the image.
+  """
   with tf.name_scope('random_horizontal_flip'):
-    do_flip = tf.greater(tf.random.uniform([], seed=seed), 0.5)
+    do_flip = tf.less(tf.random.uniform([], seed=seed), prob)
 
     image = tf.cond(
         do_flip,
         lambda: horizontal_flip_image(image),
         lambda: image)
 
     if normalized_boxes is not None:
@@ -660,15 +722,15 @@
     image: tf.Tensor,
     boxes: Optional[tf.Tensor] = None,
     masks: Optional[tf.Tensor] = None,
     roi_boxes: Optional[tf.Tensor] = None,
     seed: int = 1
 ) -> Tuple[tf.Tensor, Optional[tf.Tensor], Optional[tf.Tensor],
            Optional[tf.Tensor]]:
-  """Randomly flips input image and bounding boxes.
+  """Randomly flips input image and bounding boxes horizontally.
 
   Extends preprocess_ops.random_horizontal_flip to also flip roi_boxes used
   by ViLD.
 
   Args:
     image: `tf.Tensor`, the image to apply the random flip.
     boxes: `tf.Tensor` or `None`, boxes corresponding to the image.
@@ -699,14 +761,41 @@
     if roi_boxes is not None:
       roi_boxes = tf.cond(do_flip, lambda: horizontal_flip_boxes(roi_boxes),
                           lambda: roi_boxes)
 
     return image, boxes, masks, roi_boxes
 
 
+def random_vertical_flip(
+    image, normalized_boxes=None, masks=None, seed=1, prob=0.5
+):
+  """Randomly flips input image and bounding boxes vertically."""
+  with tf.name_scope('random_vertical_flip'):
+    do_flip = tf.less(tf.random.uniform([], seed=seed), prob)
+
+    image = tf.cond(
+        do_flip,
+        lambda: tf.image.flip_up_down(image),
+        lambda: image)
+
+    if normalized_boxes is not None:
+      normalized_boxes = tf.cond(
+          do_flip,
+          lambda: vertical_flip_boxes(normalized_boxes),
+          lambda: normalized_boxes)
+
+    if masks is not None:
+      masks = tf.cond(
+          do_flip,
+          lambda: tf.image.flip_up_down(masks[..., None])[..., 0],
+          lambda: masks)
+
+    return image, normalized_boxes, masks
+
+
 def color_jitter(image: tf.Tensor,
                  brightness: Optional[float] = 0.,
                  contrast: Optional[float] = 0.,
                  saturation: Optional[float] = 0.,
                  seed: Optional[int] = None) -> tf.Tensor:
   """Applies color jitter to an image, similarly to torchvision`s ColorJitter.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/preprocess_ops_3d.py` & `tf-models-no-deps-2.16.0/official/vision/ops/preprocess_ops_3d.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,15 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Utils for processing video dataset features."""
 
 from typing import Optional, Tuple
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _sample_or_pad_sequence_indices(sequence: tf.Tensor, num_steps: int,
                                     stride: int,
                                     offset: tf.Tensor) -> tf.Tensor:
   """Returns indices to take for sampling or padding sequences to fixed size."""
   sequence_length = tf.shape(sequence)[0]
@@ -194,20 +194,44 @@
   return tf.map_fn(
       lambda x: tf.image.decode_jpeg(x, channels=channels),
       image_string,
       back_prop=False,
       dtype=tf.uint8)
 
 
-def crop_image(frames: tf.Tensor,
-               target_height: int,
-               target_width: int,
-               random: bool = False,
-               num_crops: int = 1,
-               seed: Optional[int] = None) -> tf.Tensor:
+def decode_image(image_string: tf.Tensor, channels: int = 0) -> tf.Tensor:
+  """Decodes PNG or JPEG raw bytes string into a RGB uint8 Tensor.
+
+  Args:
+    image_string: A `tf.Tensor` of type strings with the raw PNG or JPEG bytes
+      where the first dimension is timesteps.
+    channels: Number of channels of the PNG image. Allowed values are 0, 1 and
+      3. If 0, the number of channels will be calculated at runtime and no
+      static shape is set.
+
+  Returns:
+    A Tensor of shape [T, H, W, C] of type uint8 with the decoded images.
+  """
+  return tf.map_fn(
+      lambda x: tf.image.decode_image(  # pylint: disable=g-long-lambda
+          x, channels=channels, expand_animations=False),
+      image_string,
+      back_prop=False,
+      dtype=tf.uint8,
+  )
+
+
+def crop_image(
+    frames: tf.Tensor,
+    target_height: int,
+    target_width: int,
+    random: bool = False,
+    num_crops: int = 1,
+    seed: Optional[int] = None,
+) -> tf.Tensor:
   """Crops the image sequence of images.
 
   If requested size is bigger than image size, image is padded with 0. If not
   random cropping, a central crop is performed if num_crops is 1.
 
   Args:
     frames: A Tensor of dimension [timesteps, in_height, in_width, channels].
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/preprocess_ops_3d_test.py` & `tf-models-no-deps-2.16.0/official/vision/ops/preprocess_ops_3d_test.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 
 import io
 import itertools
 import numpy as np
 from PIL import Image
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import preprocess_ops_3d
 
 
 class ParserUtilsTest(tf.test.TestCase):
 
   def setUp(self):
@@ -92,14 +92,41 @@
 
     raw_image = tf.constant([raw_image_bytes, raw_image_bytes])
     decoded_image = preprocess_ops_3d.decode_jpeg(raw_image, 3)
 
     self.assertEqual(decoded_image.shape.as_list()[3], 3)
     self.assertAllEqual(decoded_image.shape, (2, 263, 320, 3))
 
+  def test_decode_image(self):
+    # Create a random RGB JPEG image.
+    random_image = np.random.randint(0, 256, size=(263, 320, 3), dtype=np.uint8)
+    random_image = Image.fromarray(random_image)
+    with io.BytesIO() as buffer:
+      random_image.save(buffer, format='JPEG')
+      raw_image_bytes = buffer.getvalue()
+
+    raw_image = tf.constant([raw_image_bytes, raw_image_bytes])
+    decoded_image = preprocess_ops_3d.decode_image(raw_image, 3)
+
+    self.assertEqual(decoded_image.shape.as_list()[3], 3)
+    self.assertAllEqual(decoded_image.shape, (2, 263, 320, 3))
+
+    # Create a random RGB PNG image.
+    random_image = np.random.randint(0, 256, size=(263, 320, 3), dtype=np.uint8)
+    random_image = Image.fromarray(random_image)
+    with io.BytesIO() as buffer:
+      random_image.save(buffer, format='PNG')
+      raw_image_bytes = buffer.getvalue()
+
+    raw_image = tf.constant([raw_image_bytes, raw_image_bytes])
+    decoded_image = preprocess_ops_3d.decode_image(raw_image, 3)
+
+    self.assertEqual(decoded_image.shape.as_list()[3], 3)
+    self.assertAllEqual(decoded_image.shape, (2, 263, 320, 3))
+
   def test_crop_image(self):
     cropped_image_1 = preprocess_ops_3d.crop_image(self._frames, 50, 70)
     cropped_image_2 = preprocess_ops_3d.crop_image(self._frames, 200, 200)
     cropped_image_3 = preprocess_ops_3d.crop_image(self._frames, 50, 70, True)
     cropped_image_4 = preprocess_ops_3d.crop_image(
         self._frames, 90, 90, False, 3)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/preprocess_ops_test.py` & `tf-models-no-deps-2.16.0/official/vision/ops/preprocess_ops_test.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,19 +11,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for preprocess_ops.py."""
 
 import io
+
 # Import libraries
+
 from absl.testing import parameterized
 import numpy as np
 from PIL import Image
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import preprocess_ops
 
 
 def _encode_image(image_array, fmt):
   image = Image.fromarray(image_array)
   with io.BytesIO() as output:
@@ -53,14 +55,52 @@
     data = tf.ones(input_shape)
     output_data = preprocess_ops.clip_or_pad_to_fixed_size(
         data, output_size, constant_values=0)
     output_data = output_data.numpy()
     self.assertAllClose(output_size, output_data.shape[0])
     self.assertAllClose(expected_outputs, output_data)
 
+  @parameterized.named_parameters(
+      dict(
+          testcase_name='no_jittering',
+          input_size=(100, 200),
+          desired_size=(20, 10),
+          aug_scale_max=1.0,
+          output_scales=(20 / 100, 10 / 200),
+      ),
+      dict(
+          testcase_name='with_jittering',
+          input_size=(100, 200),
+          desired_size=(20, 10),
+          aug_scale_max=2.0,
+          output_scales=(20 / 100, 10 / 200),
+      ),
+  )
+  def test_resize_and_crop_image_not_keep_aspect_ratio(
+      self, input_size, desired_size, aug_scale_max, output_scales
+  ):
+    image = tf.convert_to_tensor(np.random.rand(*input_size, 3))
+
+    resized_image, image_info = preprocess_ops.resize_and_crop_image(
+        image,
+        desired_size=desired_size,
+        padded_size=desired_size,
+        aug_scale_max=aug_scale_max,
+        keep_aspect_ratio=False,
+    )
+    resized_image_shape = tf.shape(resized_image)
+
+    self.assertAllEqual([*desired_size, 3], resized_image_shape.numpy())
+    if aug_scale_max == 1:
+      self.assertNDArrayNear(
+          [input_size, desired_size, output_scales, [0.0, 0.0]],
+          image_info.numpy(),
+          1e-5,
+      )
+
   @parameterized.parameters(
       (100, 200, 100, 200, 32, 1.0, 1.0, 128, 224),
       (100, 256, 128, 256, 32, 1.0, 1.0, 128, 256),
       (200, 512, 200, 128, 32, 0.25, 0.25, 224, 128),
   )
   def test_resize_and_crop_image_rectangluar_case(self, input_height,
                                                   input_width, desired_height,
@@ -113,14 +153,35 @@
         [[input_height, input_width],
          [desired_height, desired_width],
          [scale_y, scale_x],
          [0.0, 0.0]],
         image_info.numpy(),
         1e-5)
 
+  @parameterized.parameters((1,), (2,))
+  def test_resize_and_crop_image_tensor_desired_size(self, aug_scale_max):
+    image = tf.convert_to_tensor(np.random.rand(100, 200, 3))
+
+    desired_size = tf.convert_to_tensor((220, 220), dtype=tf.int32)
+    resized_image, image_info = preprocess_ops.resize_and_crop_image(
+        image,
+        desired_size=desired_size,
+        padded_size=preprocess_ops.compute_padded_size(desired_size, 32),
+        aug_scale_max=aug_scale_max)
+    resized_image_shape = tf.shape(resized_image)
+
+    self.assertAllEqual([224, 224, 3], resized_image_shape.numpy())
+    self.assertAllEqual([[100, 200], [220, 220]], image_info[:2].numpy())
+    if aug_scale_max == 1:  # No random jittering.
+      self.assertNDArrayNear(
+          [[1.1, 1.1], [0.0, 0.0]],
+          image_info[2:].numpy(),
+          1e-5,
+      )
+
   @parameterized.parameters(
       (100, 200, 100, 300, 32, 1.0, 1.0, 100, 200, 128, 320),
       (200, 100, 100, 300, 32, 1.0, 1.0, 200, 100, 320, 128),
       (100, 200, 80, 100, 32, 0.5, 0.5, 50, 100, 96, 128),
       (200, 100, 80, 100, 32, 0.5, 0.5, 100, 50, 128, 96),
   )
   def test_resize_and_crop_image_v2(self, input_height, input_width, short_side,
@@ -281,10 +342,59 @@
                 [0, 0, 0],
                 [0, 0, 0],
             ],
         ],
     ])
     self.assertAllEqual(expected_output, output)
 
+  @parameterized.parameters(
+      (100, 200, 1.0, 224, 224, 224, 224),
+      (512, 512, 1.0, 1024, 1024, 1024, 1024),
+  )
+  def test_deit3_resize_center_crop(
+      self, input_height, input_width, center_crop_fraction,
+      desired_height, desired_width,
+      output_height, output_width):
+    # Make sure that with center_crop_ratio = 1; result has desired resolution.
+    image = tf.convert_to_tensor(
+        np.random.rand(input_height, input_width, 3))
+
+    desired_size = (desired_height, desired_width)
+    center_cropped = preprocess_ops.center_crop_image(
+        image,
+        center_crop_fraction=center_crop_fraction)
+    resized_image = tf.image.resize(
+        center_cropped, desired_size, method=tf.image.ResizeMethod.BICUBIC)
+    resized_image_shape = tf.shape(resized_image)
+
+    self.assertAllEqual(
+        [output_height, output_width, 3],
+        resized_image_shape.numpy())
+
+  @parameterized.product(
+      prenormalize=[True, False],
+      dtype=[tf.uint8, tf.float32, tf.float64, tf.float16],
+  )
+  def test_normalize_image(self, prenormalize, dtype):
+    image = tf.constant([[[0, 200, 255]]], dtype=tf.uint8)
+    image = tf.tile(image, [64, 64, 1])
+
+    if dtype != tf.uint8 and prenormalize:
+      image = image / 255
+    image = tf.cast(image, dtype=dtype)
+
+    if dtype == tf.uint8 or prenormalize:
+      normalized_image = preprocess_ops.normalize_image(
+          image, offset=[0.5, 0.5, 0.5], scale=[0.5, 0.5, 0.5]
+      )
+    else:
+      normalized_image = preprocess_ops.normalize_image(
+          image, offset=[127.0, 127.0, 127.0], scale=[127.0, 127.0, 127.0]
+      )
+    max_val = tf.reduce_max(normalized_image)
+    # If we mistakely use scale=[0.5, 0.5, 0.5] for non-normalized float input,
+    # the normalized image data will contain very large values (e.g. 500).
+    tf.assert_greater(2.0, max_val)
+
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/sampling_ops.py` & `tf-models-no-deps-2.16.0/official/vision/ops/sampling_ops.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -28,15 +28,15 @@
 It also ensures the length of output of the subsample is always batch_size, even
 when number of examples set to True in indicator is less than batch_size.
 
 This is originally implemented in TensorFlow Object Detection API.
 """
 
 # Import libraries
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def combined_static_and_dynamic_shape(tensor):
   """Returns a list containing static and dynamic values for the dimensions.
 
   Returns a list of static and dynamic values for shape dimensions. This is
   useful to preserve static shapes when available in reshape operation.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/spatial_transform_ops.py` & `tf-models-no-deps-2.16.0/official/vision/ops/spatial_transform_ops.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Spatial transform ops."""
 
 from typing import Dict, Tuple
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops.box_ops import bbox2mask
 
 _EPSILON = 1e-8
 
 
 def _feature_bilinear_interpolation(features: tf.Tensor, kernel_y: tf.Tensor,
@@ -537,15 +537,15 @@
 
   Returns:
     data_up: A tensor with a shape of
       [batch, height_in*scale, width_in*scale, channels]. Same dtype as input
       data.
   """
   if use_keras_layer:
-    return tf.keras.layers.UpSampling2D(size=(scale, scale),
+    return tf_keras.layers.UpSampling2D(size=(scale, scale),
                                         interpolation='nearest')(data)
   with tf.name_scope('nearest_upsampling'):
     bs, _, _, c = data.get_shape().as_list()
     shape = tf.shape(input=data)
     h = shape[1]
     w = shape[2]
     bs = -1 if bs is None else bs
@@ -588,27 +588,30 @@
   indices_one_hot = tf.one_hot(
       row_indices, depth=input_matrix_shape[0], dtype=input_matrix.dtype)
   # Matrix multiplication: (output_h, input_h) x (input_h, input_w)
   # (output_h, input_w)
   return tf.linalg.matmul(indices_one_hot, input_matrix, a_is_sparse=True)
 
 
-def bilinear_resize_to_bbox(images: tf.Tensor, bbox: tf.Tensor,
-                            output_size: tf.Tensor) -> tf.Tensor:
+def bilinear_resize_to_bbox(
+    images: tf.Tensor, bbox: tf.Tensor, output_size: tf.Tensor
+) -> tf.Tensor:
   """Bilinear resizes the images to fit into the bounding boxes in the output.
 
   Args:
     images: A tensor in shape (batch_size, input_h, input_w, ...) with arbitrary
       numbers of channel dimensions.
     bbox: A tensor in shape (batch_size, 4), representing the absolute
       coordinates (ymin, xmin, ymax, xmax) for each bounding box.
     output_size: The size of the output images in (output_h, output_w).
 
   Returns:
-    A tensor in shape (batch_size, output_h, output_w, ...).
+    A tensor in shape (batch_size, output_h, output_w, ...). The result has the
+    same dtype as the input if it's float32, float16, bfloat16, otherwise the
+    result is float32.
   """
   images_shape = images.get_shape().as_list()
   images_rank = len(images_shape)
   if images_rank < 3:
     raise ValueError(
         'Expected the input images (batch_size, height, width, ...) '
         'has rank >= 3, was: %s' % images_shape)
@@ -688,32 +691,35 @@
   input_y1 = tf.where(output_y_mask, input_y1, -tf.ones_like(input_y1))
   # (batch_size, output_w)
   input_x0 = tf.where(output_x_mask, input_x0, -tf.ones_like(input_x0))
   input_x1 = tf.where(output_x_mask, input_x1, -tf.ones_like(input_x1))
 
   input_h = tf.cast(input_h, tf.int32)
   input_w = tf.cast(input_w, tf.int32)
-  images = tf.cast(images, tf.float32)
+  if images.dtype not in {tf.float32, tf.bfloat16, tf.float16}:
+    images = tf.cast(images, tf.float32)
   if images_rank > 3:
     # Reshapes the images since _gather_rows_from_matrix only takes 2-D tensor.
     # (batch_size, input_h, input_w * extra_dims_product)
     images = tf.reshape(images, [-1, input_h, input_w * extra_dims_product])
 
   # Fetches the rows from the input source images.
   # (batch_size, output_h, input_w * extra_dims_product)
   val_y0 = tf.map_fn(
       lambda x: _gather_rows_from_matrix(x[0], x[1]),
       elems=(images, input_y0),
-      fn_output_signature=tf.float32,
-      parallel_iterations=32)
+      fn_output_signature=images.dtype,
+      parallel_iterations=32,
+  )
   val_y1 = tf.map_fn(
       lambda x: _gather_rows_from_matrix(x[0], x[1]),
       elems=(images, input_y1),
-      fn_output_signature=tf.float32,
-      parallel_iterations=32)
+      fn_output_signature=images.dtype,
+      parallel_iterations=32,
+  )
 
   if images_rank > 3:
     new_shape = [-1, output_h, input_w] + extra_dims
     # (batch_size, output_h, input_w, ...)
     val_y0 = tf.reshape(val_y0, new_shape)
     val_y1 = tf.reshape(val_y1, new_shape)
 
@@ -732,31 +738,35 @@
   # Fetches the pixels from the rows using the column indices.
   # val_00, val_01, val_10, val_11 store the pixels of the four nearest
   # neighbors of the input source position.
   # (batch_size, output_w, output_h * extra_dims_product)
   val_00 = tf.map_fn(
       lambda x: _gather_rows_from_matrix(x[0], x[1]),
       elems=(val_y0, input_x0),
-      fn_output_signature=tf.float32,
-      parallel_iterations=32)
+      fn_output_signature=images.dtype,
+      parallel_iterations=32,
+  )
   val_01 = tf.map_fn(
       lambda x: _gather_rows_from_matrix(x[0], x[1]),
       elems=(val_y0, input_x1),
-      fn_output_signature=tf.float32,
-      parallel_iterations=32)
+      fn_output_signature=images.dtype,
+      parallel_iterations=32,
+  )
   val_10 = tf.map_fn(
       lambda x: _gather_rows_from_matrix(x[0], x[1]),
       elems=(val_y1, input_x0),
-      fn_output_signature=tf.float32,
-      parallel_iterations=32)
+      fn_output_signature=images.dtype,
+      parallel_iterations=32,
+  )
   val_11 = tf.map_fn(
       lambda x: _gather_rows_from_matrix(x[0], x[1]),
       elems=(val_y1, input_x1),
-      fn_output_signature=tf.float32,
-      parallel_iterations=32)
+      fn_output_signature=images.dtype,
+      parallel_iterations=32,
+  )
 
   if images_rank > 3:
     new_shape = [-1, output_w, output_h] + extra_dims
     # (batch_size, output_w, output_h, ...)
     val_00 = tf.reshape(val_00, new_shape)
     val_01 = tf.reshape(val_01, new_shape)
     val_10 = tf.reshape(val_10, new_shape)
@@ -766,21 +776,21 @@
   new_perm = extra_dims_perm + [0, 2, 1]
   val_00 = tf.transpose(val_00, new_perm)
   val_01 = tf.transpose(val_01, new_perm)
   val_10 = tf.transpose(val_10, new_perm)
   val_11 = tf.transpose(val_11, new_perm)
 
   # (batch_size, output_height, 1)
-  input_y_pos = input_y_pos[:, :, tf.newaxis]
-  input_y0 = tf.cast(input_y0[:, :, tf.newaxis], input_y_pos.dtype)
-  input_y1 = tf.cast(input_y1[:, :, tf.newaxis], input_y_pos.dtype)
+  input_y_pos = tf.cast(input_y_pos[:, :, tf.newaxis], images.dtype)
+  input_y0 = tf.cast(input_y0[:, :, tf.newaxis], images.dtype)
+  input_y1 = tf.cast(input_y1[:, :, tf.newaxis], images.dtype)
   # (batch_size, 1, output_width)
-  input_x_pos = input_x_pos[:, tf.newaxis, :]
-  input_x0 = tf.cast(input_x0[:, tf.newaxis, :], input_x_pos.dtype)
-  input_x1 = tf.cast(input_x1[:, tf.newaxis, :], input_x_pos.dtype)
+  input_x_pos = tf.cast(input_x_pos[:, tf.newaxis, :], images.dtype)
+  input_x0 = tf.cast(input_x0[:, tf.newaxis, :], images.dtype)
+  input_x1 = tf.cast(input_x1[:, tf.newaxis, :], images.dtype)
 
   # Compute the weights of the four nearest neighbors for interpolation.
   # (batch_size, output_height, output_width)
   weight_00 = (input_y1 - input_y_pos) * (input_x1 - input_x_pos)
   weight_01 = (input_y1 - input_y_pos) * (input_x_pos - input_x0)
   weight_10 = (input_y_pos - input_y0) * (input_x1 - input_x_pos)
   weight_11 = (input_y_pos - input_y0) * (input_x_pos - input_x0)
@@ -810,15 +820,17 @@
       left-top offset of the crop box. Applying negative offsets means adding
       extra margins at the left-top.
     crop_size: An int tensor in shape (batch_size, 2), representing the sizes of
       the cropped images.
     output_size: The size of the output image in (output_h, output_w).
 
   Returns:
-    A tensor in shape (batch_size, output_h, output_w, ...).
+    A tensor in shape (batch_size, output_h, output_w, ...). The result has the
+    same dtype as the input if it's float32, float16, bfloat16, otherwise the
+    result is float32.
   """
   images_shape = images.get_shape().as_list()
   images_rank = len(images_shape)
   if images_rank < 3:
     raise ValueError(
         'Expected the input images (batch_size, height, width, ...) '
         'has rank >= 3, was: %s' % images_shape)
@@ -846,7 +858,66 @@
   crop_bbox_mask = bbox2mask(
       crop_bbox,
       image_height=output_size[0],
       image_width=output_size[1],
       dtype=rescaled_padded_images.dtype)[[...] + [tf.newaxis] * num_extra_dims]
   # (batch_size, output_height, output_width, ...)
   return rescaled_padded_images * crop_bbox_mask
+
+
+def bilinear_resize_with_pad(
+    images: tf.Tensor, rescale_size: tf.Tensor, output_size: tf.Tensor
+) -> tf.Tensor:
+  """Bilinear resizes the images, then pads to output size.
+
+  Args:
+    images: A tensor in shape (batch_size, input_h, input_w, ...) with arbitrary
+      numbers of channel dimensions.
+    rescale_size: An int tensor in shape (2,) or (batch_size, 2), representing
+      the sizes of the rescaled images.
+    output_size: The size of the output image in (output_h, output_w).
+
+  Returns:
+    A tensor in shape (batch_size, output_h, output_w, ...). The result has the
+    same dtype as the input if it's float32, float16, bfloat16, otherwise the
+    result is float32.
+  """
+  images_shape = images.get_shape().as_list()
+  images_rank = len(images_shape)
+  if images_rank < 3:
+    raise ValueError(
+        'Expected the input images (batch_size, height, width, ...) '
+        'has rank >= 3, was: %s' % images_shape
+    )
+  batch_size = tf.shape(images)[0]
+  rescale_size = tf.convert_to_tensor(rescale_size)
+  if len(rescale_size.get_shape().as_list()) == 1:
+    rescale_size = tf.broadcast_to(rescale_size, [batch_size, 2])
+
+  # Rescales the images, applies the offset and pastes to the output canvas.
+
+  # (batch_size, 2)
+  ymin_xmin = tf.broadcast_to([0, 0], [batch_size, 2])
+  # (batch_size, 2)
+  ymax_xmax = tf.cast(ymin_xmin, rescale_size.dtype) + rescale_size
+  # (batch_size, 4)
+  rescale_bbox = tf.concat([ymin_xmin, ymax_xmax], axis=1)
+  # (batch_size, output_height, output_width, ...)
+  return bilinear_resize_to_bbox(images, rescale_bbox, output_size)
+
+
+def bilinear_resize(images: tf.Tensor, output_size: tf.Tensor) -> tf.Tensor:
+  """Bilinear resizes the images.
+
+  Args:
+    images: A tensor in shape (batch_size, input_h, input_w, ...) with arbitrary
+      numbers of channel dimensions.
+    output_size: The size of the output image in (output_h, output_w).
+
+  Returns:
+    A tensor in shape (batch_size, output_h, output_w, ...). The result has the
+    same dtype as the input if it's float32, float16, bfloat16, otherwise the
+    result is float32.
+  """
+  return bilinear_resize_with_pad(
+      images, rescale_size=output_size, output_size=output_size
+  )
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/target_gather.py` & `tf-models-no-deps-2.16.0/official/vision/ops/target_gather.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Definition of target gather, which gathers targets from indices."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class TargetGather:
   """Targer gather for dense object detector."""
 
   def __call__(self, labels, match_indices, mask=None, mask_val=0.0):
     """Labels anchors with ground truth inputs.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/ops/target_gather_test.py` & `tf-models-no-deps-2.16.0/official/vision/ops/target_gather_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for target_gather.py."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import target_gather
 
 
 class TargetGatherTest(tf.test.TestCase):
 
   def test_target_gather_batched(self):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/registry_imports.py` & `tf-models-no-deps-2.16.0/official/vision/registry_imports.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/serving/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/detection_test.py` & `tf-models-no-deps-2.16.0/official/vision/serving/semantic_segmentation_test.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,132 +1,145 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Test for image detection export lib."""
+"""Test for semantic segmentation export lib."""
 
 import io
 import os
 
 from absl.testing import parameterized
 import numpy as np
 from PIL import Image
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import exp_factory
 from official.vision import registry_imports  # pylint: disable=unused-import
-from official.vision.serving import detection
+from official.vision.serving import semantic_segmentation
 
 
-class DetectionExportTest(tf.test.TestCase, parameterized.TestCase):
+class SemanticSegmentationExportTest(tf.test.TestCase, parameterized.TestCase):
 
-  def _get_detection_module(self, experiment_name, input_type):
-    params = exp_factory.get_exp_config(experiment_name)
-    params.task.model.backbone.resnet.model_id = 18
-    params.task.model.detection_generator.nms_version = 'batched'
-    detection_module = detection.DetectionModule(
+  def _get_segmentation_module(self,
+                               input_type,
+                               rescale_output,
+                               preserve_aspect_ratio,
+                               batch_size=1):
+    params = exp_factory.get_exp_config('mnv2_deeplabv3_pascal')
+    params.task.export_config.rescale_output = rescale_output
+    params.task.train_data.preserve_aspect_ratio = preserve_aspect_ratio
+    segmentation_module = semantic_segmentation.SegmentationModule(
         params,
-        batch_size=1,
-        input_image_size=[640, 640],
+        batch_size=batch_size,
+        input_image_size=[112, 112],
         input_type=input_type)
-    return detection_module
+    return segmentation_module
 
   def _export_from_module(self, module, input_type, save_directory):
     signatures = module.get_inference_signatures(
         {input_type: 'serving_default'})
     tf.saved_model.save(module, save_directory, signatures=signatures)
 
-  def _get_dummy_input(self, input_type, batch_size, image_size):
+  def _get_dummy_input(self, input_type, input_image_size):
     """Get dummy input for the given input type."""
-    h, w = image_size
 
+    height = input_image_size[0]
+    width = input_image_size[1]
     if input_type == 'image_tensor':
-      return tf.zeros((batch_size, h, w, 3), dtype=np.uint8)
+      return tf.zeros((1, height, width, 3), dtype=np.uint8)
     elif input_type == 'image_bytes':
-      image = Image.fromarray(np.zeros((h, w, 3), dtype=np.uint8))
+      image = Image.fromarray(np.zeros((height, width, 3), dtype=np.uint8))
       byte_io = io.BytesIO()
       image.save(byte_io, 'PNG')
-      return [byte_io.getvalue() for b in range(batch_size)]
+      return [byte_io.getvalue()]
     elif input_type == 'tf_example':
-      image_tensor = tf.zeros((h, w, 3), dtype=tf.uint8)
+      image_tensor = tf.zeros((height, width, 3), dtype=tf.uint8)
       encoded_jpeg = tf.image.encode_jpeg(tf.constant(image_tensor)).numpy()
       example = tf.train.Example(
           features=tf.train.Features(
               feature={
                   'image/encoded':
                       tf.train.Feature(
                           bytes_list=tf.train.BytesList(value=[encoded_jpeg])),
               })).SerializeToString()
-      return [example for b in range(batch_size)]
+      return [example]
     elif input_type == 'tflite':
-      return tf.zeros((batch_size, h, w, 3), dtype=np.float32)
+      return tf.zeros((1, height, width, 3), dtype=np.float32)
 
   @parameterized.parameters(
-      ('image_tensor', 'fasterrcnn_resnetfpn_coco', [384, 384]),
-      ('image_bytes', 'fasterrcnn_resnetfpn_coco', [640, 640]),
-      ('tf_example', 'fasterrcnn_resnetfpn_coco', [640, 640]),
-      ('tflite', 'fasterrcnn_resnetfpn_coco', [640, 640]),
-      ('image_tensor', 'maskrcnn_resnetfpn_coco', [640, 640]),
-      ('image_bytes', 'maskrcnn_resnetfpn_coco', [640, 384]),
-      ('tf_example', 'maskrcnn_resnetfpn_coco', [640, 640]),
-      ('tflite', 'maskrcnn_resnetfpn_coco', [640, 640]),
-      ('image_tensor', 'retinanet_resnetfpn_coco', [640, 640]),
-      ('image_bytes', 'retinanet_resnetfpn_coco', [640, 640]),
-      ('tf_example', 'retinanet_resnetfpn_coco', [384, 640]),
-      ('tflite', 'retinanet_resnetfpn_coco', [640, 640]),
-      ('image_tensor', 'retinanet_resnetfpn_coco', [384, 384]),
-      ('image_bytes', 'retinanet_spinenet_coco', [640, 640]),
-      ('tf_example', 'retinanet_spinenet_coco', [640, 384]),
-      ('tflite', 'retinanet_spinenet_coco', [640, 640]),
+      ('image_tensor', False, [112, 112], False),
+      ('image_bytes', False, [112, 112], False),
+      ('tf_example', False, [112, 112], True),
+      ('tflite', False, [112, 112], False),
+      ('image_tensor', True, [112, 56], True),
+      ('image_bytes', True, [112, 56], True),
+      ('tf_example', True, [56, 112], False),
   )
-  def test_export(self, input_type, experiment_name, image_size):
+  def test_export(self, input_type, rescale_output, input_image_size,
+                  preserve_aspect_ratio):
     tmp_dir = self.get_temp_dir()
-    module = self._get_detection_module(experiment_name, input_type)
+    module = self._get_segmentation_module(
+        input_type=input_type,
+        rescale_output=rescale_output,
+        preserve_aspect_ratio=preserve_aspect_ratio)
 
     self._export_from_module(module, input_type, tmp_dir)
 
     self.assertTrue(os.path.exists(os.path.join(tmp_dir, 'saved_model.pb')))
     self.assertTrue(
         os.path.exists(os.path.join(tmp_dir, 'variables', 'variables.index')))
     self.assertTrue(
         os.path.exists(
             os.path.join(tmp_dir, 'variables',
                          'variables.data-00000-of-00001')))
 
     imported = tf.saved_model.load(tmp_dir)
-    detection_fn = imported.signatures['serving_default']
+    segmentation_fn = imported.signatures['serving_default']
 
-    images = self._get_dummy_input(
-        input_type, batch_size=1, image_size=image_size)
+    images = self._get_dummy_input(input_type, input_image_size)
+    if input_type != 'tflite':
+      processed_images, _ = tf.nest.map_structure(
+          tf.stop_gradient,
+          tf.map_fn(
+              module._build_inputs,
+              elems=tf.zeros((1, 112, 112, 3), dtype=tf.uint8),
+              fn_output_signature=(tf.TensorSpec(
+                  shape=[112, 112, 3], dtype=tf.float32),
+                                   tf.TensorSpec(
+                                       shape=[4, 2], dtype=tf.float32))))
+    else:
+      processed_images = images
+
+    logits = module.model(processed_images, training=False)['logits']
+    if rescale_output:
+      expected_output = tf.image.resize(
+          logits, input_image_size, method='bilinear')
+    else:
+      expected_output = tf.image.resize(logits, [112, 112], method='bilinear')
+    out = segmentation_fn(tf.constant(images))
+    self.assertAllClose(out['logits'].numpy(), expected_output.numpy())
 
-    signatures = module.get_inference_signatures(
-        {input_type: 'serving_default'})
-    expected_outputs = signatures['serving_default'](tf.constant(images))
-    outputs = detection_fn(tf.constant(images))
-
-    self.assertAllEqual(outputs['detection_boxes'].numpy(),
-                        expected_outputs['detection_boxes'].numpy())
-    self.assertAllEqual(outputs['detection_classes'].numpy(),
-                        expected_outputs['detection_classes'].numpy())
-    self.assertAllEqual(outputs['detection_scores'].numpy(),
-                        expected_outputs['detection_scores'].numpy())
-    self.assertAllEqual(outputs['num_detections'].numpy(),
-                        expected_outputs['num_detections'].numpy())
-
-  def test_build_model_fail_with_none_batch_size(self):
-    params = exp_factory.get_exp_config('retinanet_resnetfpn_coco')
-    detection.DetectionModule(
-        params, batch_size=None, input_image_size=[640, 640])
+  def test_export_invalid_batch_size(self):
+    batch_size = 3
+    tmp_dir = self.get_temp_dir()
+    module = self._get_segmentation_module(
+        input_type='image_tensor',
+        rescale_output=True,
+        preserve_aspect_ratio=False,
+        batch_size=batch_size)
+    with self.assertRaisesRegex(ValueError,
+                                'Batch size cannot be more than 1.'):
+      self._export_from_module(module, 'image_tensor', tmp_dir)
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_base.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,41 +13,41 @@
 # limitations under the License.
 
 """Base class for model export."""
 
 import abc
 from typing import Dict, List, Mapping, Optional, Text
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import config_definitions as cfg
 from official.core import export_base
 
 
 class ExportModule(export_base.ExportModule, metaclass=abc.ABCMeta):
   """Base Export Module."""
 
   def __init__(self,
                params: cfg.ExperimentConfig,
                *,
                batch_size: int,
                input_image_size: List[int],
                input_type: str = 'image_tensor',
                num_channels: int = 3,
-               model: Optional[tf.keras.Model] = None,
+               model: Optional[tf_keras.Model] = None,
                input_name: Optional[str] = None):
     """Initializes a module for export.
 
     Args:
       params: Experiment params.
       batch_size: The batch size of the model input. Can be `int` or None.
       input_image_size: List or Tuple of size of the input image. For 2D image,
         it is [height, width].
       input_type: The input signature type.
       num_channels: The number of the image channels.
-      model: A tf.keras.Model instance to be exported.
+      model: A tf_keras.Model instance to be exported.
       input_name: A customized input tensor name.
     """
     self.params = params
     self._batch_size = batch_size
     self._input_image_size = input_image_size
     self._num_channels = num_channels
     self._input_type = input_type
@@ -92,14 +92,17 @@
     Returns:
       A decoded image tensor.
     """
     keys_to_features = {'image/encoded': tf.io.FixedLenFeature((), tf.string)}
     parsed_tensors = tf.io.parse_single_example(
         serialized=tf_example_string_tensor, features=keys_to_features)
     image_tensor = self._decode_image(parsed_tensors['image/encoded'])
+    image_tensor.set_shape(
+        [None] * len(self._input_image_size) + [self._num_channels]
+    )
     return image_tensor
 
   def _build_model(self, **kwargs):
     """Returns a model built from the params."""
     return None
 
   @tf.function
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_base_v2.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_base_v2.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,34 +12,34 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Base class for model export."""
 
 from typing import Dict, Optional, Text, Callable, Any, Union
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import export_base
 
 
 class ExportModule(export_base.ExportModule):
   """Base Export Module."""
 
   def __init__(self,
                params,
-               model: tf.keras.Model,
+               model: tf_keras.Model,
                input_signature: Union[tf.TensorSpec, Dict[str, tf.TensorSpec]],
                preprocessor: Optional[Callable[..., Any]] = None,
                inference_step: Optional[Callable[..., Any]] = None,
                postprocessor: Optional[Callable[..., Any]] = None):
     """Initializes a module for export.
 
     Args:
       params: A dataclass for parameters to the module.
-      model: A tf.keras.Model instance to be exported.
+      model: A tf_keras.Model instance to be exported.
       input_signature: tf.TensorSpec, e.g.
         tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.uint8)
       preprocessor: An optional callable to preprocess the inputs.
       inference_step: An optional callable to forward-pass the model.
       postprocessor: An optional callable to postprocess the model outputs.
     """
     super().__init__(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_base_v2_test.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_base_v2_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,25 +11,25 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for official.core.export_base_v2."""
 import os
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import export_base
 from official.vision.serving import export_base_v2
 
 
-class TestModel(tf.keras.Model):
+class TestModel(tf_keras.Model):
 
   def __init__(self):
     super().__init__()
-    self._dense = tf.keras.layers.Dense(2)
+    self._dense = tf_keras.layers.Dense(2)
 
   def call(self, inputs):
     return {'outputs': self._dense(inputs)}
 
 
 class ExportBaseTest(tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_module_factory.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_module_factory.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Factory for vision export modules."""
 
 from typing import List, Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.vision import configs
 from official.vision.dataloaders import classification_input
 from official.vision.modeling import factory
 from official.vision.serving import export_base_v2 as export_base
 from official.vision.serving import export_utils
@@ -30,15 +30,15 @@
                                         input_type: str,
                                         batch_size: int,
                                         input_image_size: List[int],
                                         num_channels: int = 3):
   """Creats classification export module."""
   input_signature = export_utils.get_image_input_signatures(
       input_type, batch_size, input_image_size, num_channels)
-  input_specs = tf.keras.layers.InputSpec(
+  input_specs = tf_keras.layers.InputSpec(
       shape=[batch_size] + input_image_size + [num_channels])
 
   model = factory.build_classification_model(
       input_specs=input_specs,
       model_config=params.task.model,
       l2_regularizer=None)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_module_factory_test.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_module_factory_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import io
 import os
 
 from absl.testing import parameterized
 import numpy as np
 from PIL import Image
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import exp_factory
 from official.core import export_base
 from official.vision import registry_imports  # pylint: disable=unused-import
 from official.vision.dataloaders import classification_input
 from official.vision.serving import export_module_factory
 
@@ -67,15 +67,15 @@
   )
   def test_export(self, input_type='image_tensor'):
     input_image_size = [32, 32]
     tmp_dir = self.get_temp_dir()
     module = self._get_classification_module(input_type, input_image_size)
     # Test that the model restores any attrs that are trackable objects
     # (eg: tables, resource variables, keras models/layers, tf.hub modules).
-    module.model.test_trackable = tf.keras.layers.InputLayer(input_shape=(4,))
+    module.model.test_trackable = tf_keras.layers.InputLayer(input_shape=(4,))
     ckpt_path = tf.train.Checkpoint(model=module.model).save(
         os.path.join(tmp_dir, 'ckpt'))
     export_dir = export_base.export(
         module, [input_type],
         export_savedmodel_dir=tmp_dir,
         checkpoint_path=ckpt_path,
         timestamped=False)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_saved_model.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/serving/export_saved_model.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,116 +1,125 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-r"""Vision models export binary for serving/inference.
+r"""Volumetric model export binary for serving/inference.
 
 To export a trained checkpoint in saved_model format (shell script):
 
 EXPERIMENT_TYPE = XX
 CHECKPOINT_PATH = XX
 EXPORT_DIR_PATH = XX
 export_saved_model --experiment=${EXPERIMENT_TYPE} \
                    --export_dir=${EXPORT_DIR_PATH}/ \
                    --checkpoint_path=${CHECKPOINT_PATH} \
-                   --batch_size=2 \
-                   --input_image_size=224,224
+                   --batch_size=1 \
+                   --input_image_size=128,128,128 \
+                   --num_channels=1
 
 To serve (python):
 
 export_dir_path = XX
 input_type = XX
 input_images = XX
 imported = tf.saved_model.load(export_dir_path)
 model_fn = imported.signatures['serving_default']
 output = model_fn(input_images)
 """
 
 from absl import app
 from absl import flags
 
+from official.common import registry_imports  # pylint: disable=unused-import
 from official.core import exp_factory
 from official.modeling import hyperparams
-from official.vision import registry_imports  # pylint: disable=unused-import
+from official.projects.volumetric_models.serving import semantic_segmentation_3d
 from official.vision.serving import export_saved_model_lib
 
 FLAGS = flags.FLAGS
 
-_EXPERIMENT = flags.DEFINE_string(
+
+flags.DEFINE_string(
     'experiment', None, 'experiment type, e.g. retinanet_resnetfpn_coco')
-_EXPORT_DIR = flags.DEFINE_string('export_dir', None, 'The export directory.')
-_CHECKPOINT_PATH = flags.DEFINE_string('checkpoint_path', None,
-                                       'Checkpoint path.')
-_CONFIG_FILE = flags.DEFINE_multi_string(
+flags.DEFINE_string('export_dir', None, 'The export directory.')
+flags.DEFINE_string('checkpoint_path', None, 'Checkpoint path.')
+flags.DEFINE_multi_string(
     'config_file',
     default=None,
     help='YAML/JSON files which specifies overrides. The override order '
     'follows the order of args. Note that each file '
     'can be used as an override template to override the default parameters '
     'specified in Python. If the same parameter is specified in both '
     '`--config_file` and `--params_override`, `config_file` will be used '
     'first, followed by params_override.')
-_PARAMS_OVERRIDE = flags.DEFINE_string(
+flags.DEFINE_string(
     'params_override', '',
     'The JSON/YAML file or string which specifies the parameter to be overriden'
     ' on top of `config_file` template.')
-_BATCH_SIZE = flags.DEFINE_integer('batch_size', None, 'The batch size.')
-_IMAGE_TYPE = flags.DEFINE_string(
+flags.DEFINE_integer(
+    'batch_size', None, 'The batch size.')
+flags.DEFINE_string(
     'input_type', 'image_tensor',
-    'One of `image_tensor`, `image_bytes`, `tf_example` and `tflite`.')
-_INPUT_IMAGE_SIZE = flags.DEFINE_string(
-    'input_image_size', '224,224',
-    'The comma-separated string of two integers representing the height,width '
-    'of the input to the model.')
-_EXPORT_CHECKPOINT_SUBDIR = flags.DEFINE_string(
-    'export_checkpoint_subdir', 'checkpoint',
-    'The subdirectory for checkpoints.')
-_EXPORT_SAVED_MODEL_SUBDIR = flags.DEFINE_string(
-    'export_saved_model_subdir', 'saved_model',
-    'The subdirectory for saved model.')
-_LOG_MODEL_FLOPS_AND_PARAMS = flags.DEFINE_bool(
-    'log_model_flops_and_params', False,
-    'If true, logs model flops and parameters.')
-_INPUT_NAME = flags.DEFINE_string(
-    'input_name', None,
-    'Input tensor name in signature def. Default at None which'
-    'produces input tensor name `inputs`.')
+    'One of `image_tensor`, `image_bytes`, `tf_example`.')
+flags.DEFINE_list(
+    'input_image_size', None,
+    'The comma-separated string of three integers representing the '
+    'height, width and depth of the input to the model.')
+flags.DEFINE_integer('num_channels', 1,
+                     'The number of channels of input image.')
+
+flags.register_validator(
+    'input_image_size',
+    lambda value: value is not None and len(value) == 3,
+    message='--input_image_size must be comma-separated string of three '
+    'integers representing the height, width and depth of the input to '
+    'the model.')
 
 
 def main(_):
+  flags.mark_flag_as_required('export_dir')
+  flags.mark_flag_as_required('checkpoint_path')
 
-  params = exp_factory.get_exp_config(_EXPERIMENT.value)
-  for config_file in _CONFIG_FILE.value or []:
+  params = exp_factory.get_exp_config(FLAGS.experiment)
+  for config_file in FLAGS.config_file or []:
     params = hyperparams.override_params_dict(
         params, config_file, is_strict=True)
-  if _PARAMS_OVERRIDE.value:
+  if FLAGS.params_override:
     params = hyperparams.override_params_dict(
-        params, _PARAMS_OVERRIDE.value, is_strict=True)
+        params, FLAGS.params_override, is_strict=True)
 
   params.validate()
   params.lock()
 
+  input_image_size = FLAGS.input_image_size
+
+  export_module = semantic_segmentation_3d.SegmentationModule(
+      params=params,
+      batch_size=1,
+      input_image_size=input_image_size,
+      num_channels=FLAGS.num_channels)
+
   export_saved_model_lib.export_inference_graph(
-      input_type=_IMAGE_TYPE.value,
-      batch_size=_BATCH_SIZE.value,
-      input_image_size=[int(x) for x in _INPUT_IMAGE_SIZE.value.split(',')],
+      input_type=FLAGS.input_type,
+      batch_size=FLAGS.batch_size,
+      input_image_size=input_image_size,
       params=params,
-      checkpoint_path=_CHECKPOINT_PATH.value,
-      export_dir=_EXPORT_DIR.value,
-      export_checkpoint_subdir=_EXPORT_CHECKPOINT_SUBDIR.value,
-      export_saved_model_subdir=_EXPORT_SAVED_MODEL_SUBDIR.value,
-      log_model_flops_and_params=_LOG_MODEL_FLOPS_AND_PARAMS.value,
-      input_name=_INPUT_NAME.value)
+      checkpoint_path=FLAGS.checkpoint_path,
+      export_dir=FLAGS.export_dir,
+      num_channels=FLAGS.num_channels,
+      export_module=export_module,
+      export_checkpoint_subdir='checkpoint',
+      export_saved_model_subdir='saved_model')
 
 
 if __name__ == '__main__':
   app.run(main)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_saved_model_lib.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_saved_model_lib.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 r"""Vision models export utility function for serving/inference."""
 
 import os
 from typing import Optional, List, Union, Text, Dict
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.core import export_base
 from official.core import train_utils
 from official.vision import configs
 from official.vision.serving import detection
 from official.vision.serving import image_classification
@@ -41,45 +41,48 @@
     export_module: Optional[export_base.ExportModule] = None,
     export_checkpoint_subdir: Optional[str] = None,
     export_saved_model_subdir: Optional[str] = None,
     save_options: Optional[tf.saved_model.SaveOptions] = None,
     log_model_flops_and_params: bool = False,
     checkpoint: Optional[tf.train.Checkpoint] = None,
     input_name: Optional[str] = None,
-    function_keys: Optional[Union[List[Text], Dict[Text, Text]]] = None,):
+    function_keys: Optional[Union[List[Text], Dict[Text, Text]]] = None,
+    add_tpu_function_alias: Optional[bool] = False,
+):
   """Exports inference graph for the model specified in the exp config.
 
   Saved model is stored at export_dir/saved_model, checkpoint is saved
   at export_dir/checkpoint, and params is saved at export_dir/params.yaml.
 
   Args:
     input_type: One of `image_tensor`, `image_bytes`, `tf_example` or `tflite`.
     batch_size: 'int', or None.
     input_image_size: List or Tuple of height and width.
     params: Experiment params.
     checkpoint_path: Trained checkpoint path or directory.
     export_dir: Export directory path.
     num_channels: The number of input image channels.
-    export_module: Optional export module to be used instead of using params
-      to create one. If None, the params will be used to create an export
-      module.
-    export_checkpoint_subdir: Optional subdirectory under export_dir
-      to store checkpoint.
-    export_saved_model_subdir: Optional subdirectory under export_dir
-      to store saved model.
+    export_module: Optional export module to be used instead of using params to
+      create one. If None, the params will be used to create an export module.
+    export_checkpoint_subdir: Optional subdirectory under export_dir to store
+      checkpoint.
+    export_saved_model_subdir: Optional subdirectory under export_dir to store
+      saved model.
     save_options: `SaveOptions` for `tf.saved_model.save`.
     log_model_flops_and_params: If True, writes model FLOPs to model_flops.txt
       and model parameters to model_params.txt.
     checkpoint: An optional tf.train.Checkpoint. If provided, the export module
       will use it to read the weights.
     input_name: The input tensor name, default at `None` which produces input
       tensor name `inputs`.
     function_keys: a list of string keys to retrieve pre-defined serving
       signatures. The signaute keys will be set with defaults. If a dictionary
       is provided, the values will be used as signature keys.
+    add_tpu_function_alias: Whether to add TPU function alias so that it can be
+      converted to a TPU compatible saved model later. Default is False.
   """
 
   if export_checkpoint_subdir:
     output_checkpoint_directory = os.path.join(
         export_dir, export_checkpoint_subdir)
   else:
     output_checkpoint_directory = None
@@ -128,14 +131,32 @@
           input_type=input_type,
           num_channels=num_channels,
           input_name=input_name)
     else:
       raise ValueError('Export module not implemented for {} task.'.format(
           type(params.task)))
 
+  if add_tpu_function_alias:
+    if input_type == 'image_tensor':
+      inference_func = export_module.inference_from_image_tensors
+    elif input_type == 'image_bytes':
+      inference_func = export_module.inference_from_image_bytes
+    elif input_type == 'tf_example':
+      inference_func = export_module.inference_from_tf_example
+    else:
+      raise ValueError(
+          'add_tpu_function_alias is only allowed for input_type of:'
+          ' image_tensor, image_bytes, tf_example.'
+      )
+    save_options = tf.saved_model.SaveOptions(
+        function_aliases={
+            'tpu_candidate': inference_func,
+        }
+    )
+
   export_base.export(
       export_module,
       function_keys=function_keys if function_keys else [input_type],
       export_savedmodel_dir=output_saved_model_directory,
       checkpoint=checkpoint,
       checkpoint_path=checkpoint_path,
       timestamped=False,
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_saved_model_lib_test.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_saved_model_lib_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Tests for official.core.export_saved_model_lib."""
 
 import os
 from unittest import mock
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import export_base
 from official.vision import configs
 from official.vision.serving import export_saved_model_lib
 
 
 class WriteModelFlopsAndParamsTest(tf.test.TestCase):
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_saved_model_lib_v2.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_saved_model_lib_v2.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 r"""Vision models export utility function for serving/inference."""
 
 import os
 from typing import Optional, List, Union, Text, Dict
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import config_definitions as cfg
 from official.core import export_base
 from official.core import train_utils
 from official.vision.serving import export_module_factory
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_tfhub.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_tfhub.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,91 +14,93 @@
 
 """A script to export the image classification as a TF-Hub SavedModel."""
 
 # Import libraries
 from absl import app
 from absl import flags
 
-import tensorflow as tf
-
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.vision import registry_imports  # pylint: disable=unused-import
-from official.vision.modeling import factory
-
+from official.vision.serving import export_tfhub_lib
 
 FLAGS = flags.FLAGS
 
-flags.DEFINE_string(
-    'experiment', None, 'experiment type, e.g. resnet_imagenet')
-flags.DEFINE_string(
-    'checkpoint_path', None, 'Checkpoint path.')
-flags.DEFINE_string(
-    'export_path', None, 'The export directory.')
-flags.DEFINE_multi_string(
+_EXPERIMENT = flags.DEFINE_string(
+    'experiment', None, 'experiment type, e.g. retinanet_resnetfpn_coco'
+)
+_EXPORT_DIR = flags.DEFINE_string('export_dir', None, 'The export directory.')
+_CHECKPOINT_PATH = flags.DEFINE_string(
+    'checkpoint_path', None, 'Checkpoint path.'
+)
+_CONFIG_FILE = flags.DEFINE_multi_string(
     'config_file',
-    None,
-    'A YAML/JSON files which specifies overrides. The override order '
-    'follows the order of args. Note that each file '
-    'can be used as an override template to override the default parameters '
-    'specified in Python. If the same parameter is specified in both '
-    '`--config_file` and `--params_override`, `config_file` will be used '
-    'first, followed by params_override.')
-flags.DEFINE_string(
-    'params_override', '',
-    'The JSON/YAML file or string which specifies the parameter to be overriden'
-    ' on top of `config_file` template.')
-flags.DEFINE_integer(
-    'batch_size', None, 'The batch size.')
-flags.DEFINE_string(
+    default=None,
+    help=(
+        'YAML/JSON files which specifies overrides. The override order follows'
+        ' the order of args. Note that each file can be used as an override'
+        ' template to override the default parameters specified in Python. If'
+        ' the same parameter is specified in both `--config_file` and'
+        ' `--params_override`, `config_file` will be used first, followed by'
+        ' params_override.'
+    ),
+)
+_PARAMS_OVERRIDE = flags.DEFINE_string(
+    'params_override',
+    '',
+    (
+        'The JSON/YAML file or string which specifies the parameter to be'
+        ' overriden on top of `config_file` template.'
+    ),
+)
+_BATCH_SIZE = flags.DEFINE_integer('batch_size', None, 'The batch size.')
+_INPUT_IMAGE_SIZE = flags.DEFINE_string(
     'input_image_size',
     '224,224',
-    'The comma-separated string of two integers representing the height,width '
-    'of the input to the model.')
-flags.DEFINE_boolean(
+    (
+        'The comma-separated string of two integers representing the'
+        ' height,width of the input to the model.'
+    ),
+)
+_SKIP_LOGITS_LAYER = flags.DEFINE_boolean(
     'skip_logits_layer',
     False,
-    'Whether to skip the prediction layer and only output the feature vector.')
-
-
-def export_model_to_tfhub(params,
-                          batch_size,
-                          input_image_size,
-                          skip_logits_layer,
-                          checkpoint_path,
-                          export_path):
-  """Export an image classification model to TF-Hub."""
-  input_specs = tf.keras.layers.InputSpec(shape=[batch_size] +
-                                          input_image_size + [3])
-
-  model = factory.build_classification_model(
-      input_specs=input_specs,
-      model_config=params.task.model,
-      l2_regularizer=None,
-      skip_logits_layer=skip_logits_layer)
-  checkpoint = tf.train.Checkpoint(model=model)
-  checkpoint.restore(checkpoint_path).assert_existing_objects_matched()
-  model.save(export_path, include_optimizer=False, save_format='tf')
+    'Whether to skip the prediction layer and only output the feature vector.',
+)
 
 
 def main(_):
-  params = exp_factory.get_exp_config(FLAGS.experiment)
-  for config_file in FLAGS.config_file or []:
-    params = hyperparams.override_params_dict(
-        params, config_file, is_strict=True)
-  if FLAGS.params_override:
-    params = hyperparams.override_params_dict(
-        params, FLAGS.params_override, is_strict=True)
+  params = exp_factory.get_exp_config(_EXPERIMENT.value)
+  for config_file in _CONFIG_FILE.value or []:
+    try:
+      params = hyperparams.override_params_dict(
+          params, config_file, is_strict=True
+      )
+    except KeyError:
+      params = hyperparams.override_params_dict(
+          params, config_file, is_strict=False
+      )
+  if _PARAMS_OVERRIDE.value:
+    try:
+      params = hyperparams.override_params_dict(
+          params, _PARAMS_OVERRIDE.value, is_strict=True
+      )
+    except KeyError:
+      params = hyperparams.override_params_dict(
+          params, _PARAMS_OVERRIDE.value, is_strict=False
+      )
   params.validate()
   params.lock()
 
-  export_model_to_tfhub(
+  export_tfhub_lib.export_model_to_tfhub(
       params=params,
-      batch_size=FLAGS.batch_size,
-      input_image_size=[int(x) for x in FLAGS.input_image_size.split(',')],
-      skip_logits_layer=FLAGS.skip_logits_layer,
-      checkpoint_path=FLAGS.checkpoint_path,
-      export_path=FLAGS.export_path)
+      batch_size=_BATCH_SIZE.value,
+      input_image_size=[int(x) for x in _INPUT_IMAGE_SIZE.value.split(',')],
+      checkpoint_path=_CHECKPOINT_PATH.value,
+      export_path=_EXPORT_DIR.value,
+      num_channels=3,
+      skip_logits_layer=_SKIP_LOGITS_LAYER.value,
+  )
 
 
 if __name__ == '__main__':
   app.run(main)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_tflite.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_tflite.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -32,15 +32,15 @@
               --quant_type=fp16 \
               --calibration_steps=500
 """
 from absl import app
 from absl import flags
 from absl import logging
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import exp_factory
 from official.modeling import hyperparams
 from official.vision import registry_imports  # pylint: disable=unused-import
 from official.vision.serving import export_tflite_lib
 
 FLAGS = flags.FLAGS
 
@@ -85,20 +85,32 @@
     'Valid ops that should not be included are quantization friendly ops, such '
     'as CONV_2D, DEPTHWISE_CONV_2D, FULLY_CONNECTED, etc.')
 
 
 def main(_) -> None:
   params = exp_factory.get_exp_config(_EXPERIMENT.value)
   if _CONFIG_FILE.value is not None:
-    for config_file in _CONFIG_FILE.value:
-      params = hyperparams.override_params_dict(
-          params, config_file, is_strict=True)
+    for config_file in _CONFIG_FILE.value or []:
+      try:
+        params = hyperparams.override_params_dict(
+            params, config_file, is_strict=True
+        )
+      except KeyError:
+        params = hyperparams.override_params_dict(
+            params, config_file, is_strict=False
+        )
   if _PARAMS_OVERRIDE.value:
-    params = hyperparams.override_params_dict(
-        params, _PARAMS_OVERRIDE.value, is_strict=True)
+    try:
+      params = hyperparams.override_params_dict(
+          params, _PARAMS_OVERRIDE.value, is_strict=True
+      )
+    except KeyError:
+      params = hyperparams.override_params_dict(
+          params, _PARAMS_OVERRIDE.value, is_strict=False
+      )
 
   params.validate()
   params.lock()
 
   logging.info('Converting SavedModel from %s to TFLite model...',
                _SAVED_MODEL_DIR.value)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_tflite_lib.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_tflite_lib.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Library to facilitate TFLite model conversion."""
 import functools
 from typing import Iterator, List, Optional
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import base_task
 from official.core import config_definitions as cfg
 from official.vision import configs
 from official.vision import tasks
 
 
@@ -81,24 +81,31 @@
   for image, _ in dataset.take(calibration_steps):
     # Skip images that do not have 3 channels.
     if image.shape[-1] != 3:
       continue
     yield [image]
 
 
-def convert_tflite_model(saved_model_dir: str,
-                         quant_type: Optional[str] = None,
-                         params: Optional[cfg.ExperimentConfig] = None,
-                         task: Optional[base_task.Task] = None,
-                         calibration_steps: Optional[int] = 2000,
-                         denylisted_ops: Optional[list[str]] = None) -> bytes:
+def convert_tflite_model(
+    saved_model_dir: Optional[str] = None,
+    concrete_function: Optional[tf.types.experimental.ConcreteFunction] = None,
+    model: Optional[tf.Module] = None,
+    quant_type: Optional[str] = None,
+    params: Optional[cfg.ExperimentConfig] = None,
+    task: Optional[base_task.Task] = None,
+    calibration_steps: Optional[int] = 2000,
+    denylisted_ops: Optional[List[str]] = None,
+) -> 'bytes':
   """Converts and returns a TFLite model.
 
   Args:
     saved_model_dir: The directory to the SavedModel.
+    concrete_function: An optional concrete function to be exported.
+    model: An optional tf_keras.Model instance. If both `saved_model_dir` and
+      `concrete_function` are not available, convert this model to TFLite.
     quant_type: The post training quantization (PTQ) method. It can be one of
       `default` (dynamic range), `fp16` (float16), `int8` (integer wih float
       fallback), `int8_full` (integer only) and None (no quantization).
     params: An optional ExperimentConfig to load and preprocess input images to
       do calibration for integer quantization.
     task: An optional task instance. If it is None, task will be built according
       to the task type in params.
@@ -107,17 +114,30 @@
       integer quantization.
 
   Returns:
     A converted TFLite model with optional PTQ.
 
   Raises:
     ValueError: If `representative_dataset_path` is not present if integer
-    quantization is requested.
+      quantization is requested, or `saved_model_dir`, `concrete_function` or
+      `model` are not provided.
   """
-  converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
+  if saved_model_dir:
+    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
+  elif concrete_function is not None:
+    converter = tf.lite.TFLiteConverter.from_concrete_functions(
+        [concrete_function]
+    )
+  elif model is not None:
+    converter = tf.lite.TFLiteConverter.from_keras_model(model)
+  else:
+    raise ValueError(
+        '`saved_model_dir`, `model` or `concrete_function` must be specified.'
+    )
+
   if quant_type:
     if quant_type.startswith('int8'):
       converter.optimizations = [tf.lite.Optimize.DEFAULT]
       converter.representative_dataset = functools.partial(
           representative_dataset,
           params=params,
           task=task,
@@ -142,14 +162,19 @@
                 representative_dataset,
                 params=params,
                 calibration_steps=calibration_steps),
             debug_options=debug_options)
         debugger.run()
         return debugger.get_nondebug_quantized_model()
 
+    elif quant_type == 'uint8':
+      converter.optimizations = [tf.lite.Optimize.DEFAULT]
+      converter.default_ranges_stats = (-10, 10)
+      converter.inference_type = tf.uint8
+      converter.quantized_input_stats = {'input_placeholder': (0., 1.)}
     elif quant_type == 'fp16':
       converter.optimizations = [tf.lite.Optimize.DEFAULT]
       converter.target_spec.supported_types = [tf.float16]
     elif quant_type in ('default', 'qat_fp32_io'):
       converter.optimizations = [tf.lite.Optimize.DEFAULT]
     elif quant_type == 'qat':
       converter.optimizations = [tf.lite.Optimize.DEFAULT]
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/export_utils.py` & `tf-models-no-deps-2.16.0/official/vision/serving/export_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,42 +11,48 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Helper utils for export library."""
 
 from typing import List, Optional
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # pylint: disable=g-long-lambda
 
 
 def get_image_input_signatures(input_type: str,
                                batch_size: Optional[int],
                                input_image_size: List[int],
-                               num_channels: int = 3):
+                               num_channels: int = 3,
+                               input_name: Optional[str] = None):
   """Gets input signatures for an image.
 
   Args:
     input_type: A `str`, can be either tf_example, image_bytes, or image_tensor.
     batch_size: `int` for batch size or None.
     input_image_size: List[int] for the height and width of the input image.
     num_channels: `int` for number of channels in the input image.
+    input_name: A `str` to set the input image name in the signature, if None,
+      a default name `inputs` will be used.
   Returns:
     tf.TensorSpec of the input tensor.
   """
   if input_type == 'image_tensor':
     input_signature = tf.TensorSpec(
         shape=[batch_size] + [None] * len(input_image_size) + [num_channels],
-        dtype=tf.uint8)
+        dtype=tf.uint8, name=input_name)
   elif input_type in ['image_bytes', 'serve_examples', 'tf_example']:
-    input_signature = tf.TensorSpec(shape=[batch_size], dtype=tf.string)
+    input_signature = tf.TensorSpec(
+        shape=[batch_size], dtype=tf.string, name=input_name)
   elif input_type == 'tflite':
     input_signature = tf.TensorSpec(
-        shape=[1] + input_image_size + [num_channels], dtype=tf.float32)
+        shape=[1] + input_image_size + [num_channels],
+        dtype=tf.float32,
+        name=input_name)
   else:
     raise ValueError('Unrecognized `input_type`')
   return input_signature
 
 
 def decode_image(encoded_image_bytes: str,
                  input_image_size: List[int],
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/image_classification.py` & `tf-models-no-deps-2.16.0/official/vision/serving/image_classification.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,26 +10,26 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Image classification input and model functions for serving/inference."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling import factory
 from official.vision.ops import preprocess_ops
 from official.vision.serving import export_base
 
 
 class ClassificationModule(export_base.ExportModule):
   """classification Module."""
 
   def _build_model(self):
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[self._batch_size] + self._input_image_size + [3])
 
     return factory.build_classification_model(
         input_specs=input_specs,
         model_config=self.params.task.model,
         l2_regularizer=None)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/image_classification_test.py` & `tf-models-no-deps-2.16.0/official/vision/serving/image_classification_test.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import io
 import os
 
 from absl.testing import parameterized
 import numpy as np
 from PIL import Image
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.core import exp_factory
 from official.vision import registry_imports  # pylint: disable=unused-import
 from official.vision.serving import image_classification
 
 
 class ImageClassificationExportTest(tf.test.TestCase, parameterized.TestCase):
@@ -77,15 +77,15 @@
       {'input_type': 'tflite'},
   )
   def test_export(self, input_type='image_tensor'):
     tmp_dir = self.get_temp_dir()
     module = self._get_classification_module(input_type)
     # Test that the model restores any attrs that are trackable objects
     # (eg: tables, resource variables, keras models/layers, tf.hub modules).
-    module.model.test_trackable = tf.keras.layers.InputLayer(input_shape=(4,))
+    module.model.test_trackable = tf_keras.layers.InputLayer(input_shape=(4,))
 
     self._export_from_module(module, input_type, tmp_dir)
 
     self.assertTrue(os.path.exists(os.path.join(tmp_dir, 'saved_model.pb')))
     self.assertTrue(os.path.exists(
         os.path.join(tmp_dir, 'variables', 'variables.index')))
     self.assertTrue(os.path.exists(
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/semantic_segmentation.py` & `tf-models-no-deps-2.16.0/official/vision/serving/semantic_segmentation.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,26 +10,26 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Semantic segmentation input and model functions for serving/inference."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.modeling import factory
 from official.vision.ops import preprocess_ops
 from official.vision.serving import export_base
 
 
 class SegmentationModule(export_base.ExportModule):
   """Segmentation Module."""
 
   def _build_model(self):
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[self._batch_size] + self._input_image_size + [3])
 
     return factory.build_segmentation_model(
         input_specs=input_specs,
         model_config=self.params.task.model,
         l2_regularizer=None)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/serving/video_classification_test.py` & `tf-models-no-deps-2.16.0/official/projects/volumetric_models/serving/semantic_segmentation_3d_test.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,113 +1,112 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+"""Test for semantic_segmentation_3d export lib."""
 
-# import io
 import os
-import random
 
 from absl.testing import parameterized
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
+# pylint: disable=unused-import
 from official.core import exp_factory
-from official.vision import registry_imports  # pylint: disable=unused-import
-from official.vision.dataloaders import tfexample_utils
-from official.vision.serving import video_classification
-
-
-class VideoClassificationTest(tf.test.TestCase, parameterized.TestCase):
-
-  def _get_classification_module(self):
-    params = exp_factory.get_exp_config('video_classification_ucf101')
-    params.task.train_data.feature_shape = (8, 64, 64, 3)
-    params.task.validation_data.feature_shape = (8, 64, 64, 3)
-    params.task.model.backbone.resnet_3d.model_id = 50
-    classification_module = video_classification.VideoClassificationModule(
-        params, batch_size=1, input_image_size=[8, 64, 64])
-    return classification_module
+from official.projects.volumetric_models.configs import semantic_segmentation_3d as exp_cfg
+from official.projects.volumetric_models.modeling import backbones
+from official.projects.volumetric_models.modeling import decoders
+from official.projects.volumetric_models.serving import semantic_segmentation_3d
+
+
+class SemanticSegmentationExportTest(tf.test.TestCase, parameterized.TestCase):
+
+  def setUp(self):
+    super().setUp()
+    self._num_channels = 2
+    self._input_image_size = [32, 32, 32]
+    self._params = exp_factory.get_exp_config('seg_unet3d_test')
+
+    input_shape = self._input_image_size + [self._num_channels]
+    self._image_array = np.zeros(shape=input_shape, dtype=np.uint8)
+
+  def _get_segmentation_module(self):
+    return semantic_segmentation_3d.SegmentationModule(
+        self._params,
+        batch_size=1,
+        input_image_size=self._input_image_size,
+        num_channels=self._num_channels)
 
-  def _export_from_module(self, module, input_type, save_directory):
+  def _export_from_module(self, module, input_type: str, save_directory: str):
     signatures = module.get_inference_signatures(
         {input_type: 'serving_default'})
-    tf.saved_model.save(module, save_directory, signatures=signatures)
+    tf.saved_model.save(module,
+                        save_directory,
+                        signatures=signatures)
 
-  def _get_dummy_input(self, input_type, module=None):
+  def _get_dummy_input(self, input_type):
     """Get dummy input for the given input type."""
 
     if input_type == 'image_tensor':
-      images = np.random.randint(
-          low=0, high=255, size=(1, 8, 64, 64, 3), dtype=np.uint8)
-      # images = np.zeros((1, 8, 64, 64, 3), dtype=np.uint8)
-      return images, images
-    elif input_type == 'tf_example':
-      example = tfexample_utils.make_video_test_example(
-          image_shape=(64, 64, 3),
-          audio_shape=(20, 128),
-          label=random.randint(0, 100)).SerializeToString()
-      images = tf.nest.map_structure(
-          tf.stop_gradient,
-          tf.map_fn(
-              module._decode_tf_example,
-              elems=tf.constant([example]),
-              fn_output_signature={
-                  video_classification.video_input.IMAGE_KEY: tf.string,
-              }))
-      images = images[video_classification.video_input.IMAGE_KEY]
-      return [example], images
-    else:
-      raise ValueError(f'{input_type}')
+      image_tensor = tf.convert_to_tensor(self._image_array, dtype=tf.uint8)
+      return tf.expand_dims(image_tensor, axis=0)
+    if input_type == 'image_bytes':
+      return [self._image_array.tostring()]
+    if input_type == 'tf_example':
+      encoded_image = self._image_array.tostring()
+      example = tf.train.Example(
+          features=tf.train.Features(
+              feature={
+                  'image/encoded':
+                      tf.train.Feature(
+                          bytes_list=tf.train.BytesList(value=[encoded_image])),
+              })).SerializeToString()
+      return [example]
 
   @parameterized.parameters(
       {'input_type': 'image_tensor'},
+      {'input_type': 'image_bytes'},
       {'input_type': 'tf_example'},
   )
-  def test_export(self, input_type):
+  def test_export(self, input_type: str = 'image_tensor'):
     tmp_dir = self.get_temp_dir()
-    module = self._get_classification_module()
 
+    module = self._get_segmentation_module()
     self._export_from_module(module, input_type, tmp_dir)
 
-    self.assertTrue(os.path.exists(os.path.join(tmp_dir, 'saved_model.pb')))
+    # Check if model is successfully exported.
+    self.assertTrue(tf.io.gfile.exists(os.path.join(tmp_dir, 'saved_model.pb')))
     self.assertTrue(
-        os.path.exists(os.path.join(tmp_dir, 'variables', 'variables.index')))
+        tf.io.gfile.exists(
+            os.path.join(tmp_dir, 'variables', 'variables.index')))
     self.assertTrue(
-        os.path.exists(
+        tf.io.gfile.exists(
             os.path.join(tmp_dir, 'variables',
                          'variables.data-00000-of-00001')))
 
+    # Get inference signature from loaded SavedModel.
     imported = tf.saved_model.load(tmp_dir)
-    classification_fn = imported.signatures['serving_default']
+    segmentation_fn = imported.signatures['serving_default']
 
-    images, images_tensor = self._get_dummy_input(input_type, module)
-    processed_images = tf.nest.map_structure(
-        tf.stop_gradient,
-        tf.map_fn(
-            module._preprocess_image,
-            elems=images_tensor,
-            fn_output_signature={
-                'image': tf.float32,
-            }))
-    expected_logits = module.model(processed_images, training=False)
-    expected_prob = tf.nn.softmax(expected_logits)
-    out = classification_fn(tf.constant(images))
-
-    # The imported model should contain any trackable attrs that the original
-    # model had.
-    self.assertAllClose(out['logits'].numpy(), expected_logits.numpy())
-    self.assertAllClose(out['probs'].numpy(), expected_prob.numpy())
+    images = self._get_dummy_input(input_type)
+    image_tensor = self._get_dummy_input(input_type='image_tensor')
+
+    # Perform inference using loaded SavedModel and model instance and check if
+    # outputs equal.
+    expected_output = module.model(image_tensor, training=False)
+    out = segmentation_fn(tf.constant(images))
+    self.assertAllClose(out['logits'].numpy(),
+                        expected_output['logits'].numpy())
 
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/tasks/__init__.py` & `tf-models-no-deps-2.16.0/official/vision/tasks/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/tasks/image_classification.py` & `tf-models-no-deps-2.16.0/official/vision/tasks/semantic_segmentation.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,368 +1,375 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Image classification task definition."""
-from typing import Any, Optional, List, Tuple
+"""Image segmentation task definition."""
+from typing import Any, List, Mapping, Optional, Tuple, Union
+
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import dataset_fn
 from official.core import base_task
 from official.core import task_factory
-from official.modeling import tf_utils
-from official.vision.configs import image_classification as exp_cfg
-from official.vision.dataloaders import classification_input
+from official.vision.configs import semantic_segmentation as exp_cfg
+from official.vision.dataloaders import input_reader
 from official.vision.dataloaders import input_reader_factory
+from official.vision.dataloaders import segmentation_input
 from official.vision.dataloaders import tfds_factory
+from official.vision.evaluation import segmentation_metrics
+from official.vision.losses import segmentation_losses
 from official.vision.modeling import factory
-from official.vision.ops import augment
+from official.vision.utils.object_detection import visualization_utils
 
 
-@task_factory.register_task_cls(exp_cfg.ImageClassificationTask)
-class ImageClassificationTask(base_task.Task):
-  """A task for image classification."""
+@task_factory.register_task_cls(exp_cfg.SemanticSegmentationTask)
+class SemanticSegmentationTask(base_task.Task):
+  """A task for semantic segmentation."""
 
   def build_model(self):
-    """Builds classification model."""
-    input_specs = tf.keras.layers.InputSpec(
-        shape=[None] + self.task_config.model.input_size)
+    """Builds segmentation model."""
+    input_specs = tf_keras.layers.InputSpec(shape=[None] +
+                                            self.task_config.model.input_size)
 
     l2_weight_decay = self.task_config.losses.l2_weight_decay
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (tf.keras.regularizers.l2(
-        l2_weight_decay / 2.0) if l2_weight_decay else None)
+    l2_regularizer = (
+        tf_keras.regularizers.l2(l2_weight_decay /
+                                 2.0) if l2_weight_decay else None)
 
-    model = factory.build_classification_model(
+    model = factory.build_segmentation_model(
         input_specs=input_specs,
         model_config=self.task_config.model,
         l2_regularizer=l2_regularizer)
-
-    if self.task_config.freeze_backbone:
-      model.backbone.trainable = False
+    # Builds the model
+    dummy_inputs = tf_keras.Input(self.task_config.model.input_size)
+    _ = model(dummy_inputs, training=False)
     return model
 
-  def initialize(self, model: tf.keras.Model):
+  def initialize(self, model: tf_keras.Model):
     """Loads pretrained checkpoint."""
     if not self.task_config.init_checkpoint:
       return
 
     ckpt_dir_or_file = self.task_config.init_checkpoint
     if tf.io.gfile.isdir(ckpt_dir_or_file):
       ckpt_dir_or_file = tf.train.latest_checkpoint(ckpt_dir_or_file)
 
     # Restoring checkpoint.
-    if self.task_config.init_checkpoint_modules == 'all':
-      ckpt = tf.train.Checkpoint(model=model)
+    if 'all' in self.task_config.init_checkpoint_modules:
+      ckpt = tf.train.Checkpoint(**model.checkpoint_items)
       status = ckpt.read(ckpt_dir_or_file)
       status.expect_partial().assert_existing_objects_matched()
-    elif self.task_config.init_checkpoint_modules == 'backbone':
-      ckpt = tf.train.Checkpoint(backbone=model.backbone)
+    else:
+      ckpt_items = {}
+      if 'backbone' in self.task_config.init_checkpoint_modules:
+        ckpt_items.update(backbone=model.backbone)
+      if 'decoder' in self.task_config.init_checkpoint_modules:
+        ckpt_items.update(decoder=model.decoder)
+
+      ckpt = tf.train.Checkpoint(**ckpt_items)
       status = ckpt.read(ckpt_dir_or_file)
       status.expect_partial().assert_existing_objects_matched()
-    else:
-      raise ValueError(
-          "Only 'all' or 'backbone' can be used to initialize the model.")
 
     logging.info('Finished loading pretrained checkpoint from %s',
                  ckpt_dir_or_file)
 
-  def build_inputs(
-      self,
-      params: exp_cfg.DataConfig,
-      input_context: Optional[tf.distribute.InputContext] = None
-  ) -> tf.data.Dataset:
+  def build_inputs(self,
+                   params: exp_cfg.DataConfig,
+                   input_context: Optional[tf.distribute.InputContext] = None):
     """Builds classification input."""
 
-    num_classes = self.task_config.model.num_classes
-    input_size = self.task_config.model.input_size
-    image_field_key = self.task_config.train_data.image_field_key
-    label_field_key = self.task_config.train_data.label_field_key
-    is_multilabel = self.task_config.train_data.is_multilabel
+    ignore_label = self.task_config.losses.ignore_label
+    gt_is_matting_map = self.task_config.losses.gt_is_matting_map
 
     if params.tfds_name:
-      decoder = tfds_factory.get_classification_decoder(params.tfds_name)
+      decoder = tfds_factory.get_segmentation_decoder(params.tfds_name)
     else:
-      decoder = classification_input.Decoder(
-          image_field_key=image_field_key, label_field_key=label_field_key,
-          is_multilabel=is_multilabel)
-
-    parser = classification_input.Parser(
-        output_size=input_size[:2],
-        num_classes=num_classes,
-        image_field_key=image_field_key,
-        label_field_key=label_field_key,
-        decode_jpeg_only=params.decode_jpeg_only,
+      decoder = segmentation_input.Decoder(
+          image_feature=params.image_feature,
+          additional_dense_features=params.additional_dense_features)
+
+    parser = segmentation_input.Parser(
+        output_size=params.output_size,
+        crop_size=params.crop_size,
+        ignore_label=ignore_label,
+        resize_eval_groundtruth=params.resize_eval_groundtruth,
+        gt_is_matting_map=gt_is_matting_map,
+        groundtruth_padded_size=params.groundtruth_padded_size,
+        aug_scale_min=params.aug_scale_min,
+        aug_scale_max=params.aug_scale_max,
         aug_rand_hflip=params.aug_rand_hflip,
-        aug_crop=params.aug_crop,
-        aug_type=params.aug_type,
-        color_jitter=params.color_jitter,
-        random_erasing=params.random_erasing,
-        is_multilabel=is_multilabel,
-        dtype=params.dtype)
-
-    postprocess_fn = None
-    if params.mixup_and_cutmix:
-      postprocess_fn = augment.MixupAndCutmix(
-          mixup_alpha=params.mixup_and_cutmix.mixup_alpha,
-          cutmix_alpha=params.mixup_and_cutmix.cutmix_alpha,
-          prob=params.mixup_and_cutmix.prob,
-          label_smoothing=params.mixup_and_cutmix.label_smoothing,
-          num_classes=num_classes)
+        preserve_aspect_ratio=params.preserve_aspect_ratio,
+        dtype=params.dtype,
+        image_feature=params.image_feature,
+        additional_dense_features=params.additional_dense_features)
 
     reader = input_reader_factory.input_reader_generator(
         params,
         dataset_fn=dataset_fn.pick_dataset_fn(params.file_type),
         decoder_fn=decoder.decode,
-        parser_fn=parser.parse_fn(params.is_training),
-        postprocess_fn=postprocess_fn)
+        combine_fn=input_reader.create_combine_fn(params),
+        parser_fn=parser.parse_fn(params.is_training))
 
     dataset = reader.read(input_context=input_context)
 
     return dataset
 
   def build_losses(self,
-                   labels: tf.Tensor,
-                   model_outputs: tf.Tensor,
-                   aux_losses: Optional[Any] = None) -> tf.Tensor:
-    """Builds sparse categorical cross entropy loss.
+                   labels: Mapping[str, tf.Tensor],
+                   model_outputs: Union[Mapping[str, tf.Tensor], tf.Tensor],
+                   aux_losses: Optional[Any] = None):
+    """Segmentation loss.
 
     Args:
-      labels: Input groundtruth labels.
+      labels: labels.
       model_outputs: Output logits of the classifier.
-      aux_losses: The auxiliarly loss tensors, i.e. `losses` in tf.keras.Model.
+      aux_losses: auxiliarly loss tensors, i.e. `losses` in keras.Model.
 
     Returns:
       The total loss tensor.
     """
-    losses_config = self.task_config.losses
-    is_multilabel = self.task_config.train_data.is_multilabel
+    loss_params = self._task_config.losses
+    segmentation_loss_fn = segmentation_losses.SegmentationLoss(
+        loss_params.label_smoothing,
+        loss_params.class_weights,
+        loss_params.ignore_label,
+        use_groundtruth_dimension=loss_params.use_groundtruth_dimension,
+        use_binary_cross_entropy=loss_params.use_binary_cross_entropy,
+        top_k_percent_pixels=loss_params.top_k_percent_pixels,
+        gt_is_matting_map=loss_params.gt_is_matting_map)
+
+    total_loss = segmentation_loss_fn(model_outputs['logits'], labels['masks'])
+
+    if 'mask_scores' in model_outputs:
+      mask_scoring_loss_fn = segmentation_losses.MaskScoringLoss(
+          loss_params.ignore_label)
+      total_loss += loss_params.mask_scoring_weight * mask_scoring_loss_fn(
+          model_outputs['mask_scores'],
+          model_outputs['logits'],
+          labels['masks'])
 
-    if not is_multilabel:
-      if losses_config.one_hot:
-        total_loss = tf.keras.losses.categorical_crossentropy(
-            labels,
-            model_outputs,
-            from_logits=True,
-            label_smoothing=losses_config.label_smoothing)
-      elif losses_config.soft_labels:
-        total_loss = tf.nn.softmax_cross_entropy_with_logits(
-            labels, model_outputs)
-      else:
-        total_loss = tf.keras.losses.sparse_categorical_crossentropy(
-            labels, model_outputs, from_logits=True)
-    else:
-      # Multi-label weighted binary cross entropy loss.
-      total_loss = tf.nn.sigmoid_cross_entropy_with_logits(
-          labels=labels, logits=model_outputs)
-      total_loss = tf.reduce_sum(total_loss, axis=-1)
-
-    total_loss = tf_utils.safe_mean(total_loss)
     if aux_losses:
       total_loss += tf.add_n(aux_losses)
 
-    total_loss = losses_config.loss_weight * total_loss
+    total_loss = loss_params.loss_weight * total_loss
+
     return total_loss
 
-  def build_metrics(self,
-                    training: bool = True) -> List[tf.keras.metrics.Metric]:
-    """Gets streaming metrics for training/validation."""
-    is_multilabel = self.task_config.train_data.is_multilabel
-    if not is_multilabel:
-      k = self.task_config.evaluation.top_k
-      if (self.task_config.losses.one_hot or
-          self.task_config.losses.soft_labels):
-        metrics = [
-            tf.keras.metrics.CategoricalAccuracy(name='accuracy'),
-            tf.keras.metrics.TopKCategoricalAccuracy(
-                k=k, name='top_{}_accuracy'.format(k))]
-        if hasattr(
-            self.task_config.evaluation, 'precision_and_recall_thresholds'
-        ) and self.task_config.evaluation.precision_and_recall_thresholds:
-          thresholds = self.task_config.evaluation.precision_and_recall_thresholds
-          # pylint:disable=g-complex-comprehension
-          metrics += [
-              tf.keras.metrics.Precision(
-                  thresholds=th,
-                  name='precision_at_threshold_{}'.format(th),
-                  top_k=1) for th in thresholds
-          ]
-          metrics += [
-              tf.keras.metrics.Recall(
-                  thresholds=th,
-                  name='recall_at_threshold_{}'.format(th),
-                  top_k=1) for th in thresholds
-          ]
-
-          # Add per-class precision and recall.
-          if hasattr(
-              self.task_config.evaluation,
-              'report_per_class_precision_and_recall'
-          ) and self.task_config.evaluation.report_per_class_precision_and_recall:
-            for class_id in range(self.task_config.model.num_classes):
-              metrics += [
-                  tf.keras.metrics.Precision(
-                      thresholds=th,
-                      class_id=class_id,
-                      name=f'precision_at_threshold_{th}/{class_id}',
-                      top_k=1) for th in thresholds
-              ]
-              metrics += [
-                  tf.keras.metrics.Recall(
-                      thresholds=th,
-                      class_id=class_id,
-                      name=f'recall_at_threshold_{th}/{class_id}',
-                      top_k=1) for th in thresholds
-              ]
-              # pylint:enable=g-complex-comprehension
+  def process_metrics(self, metrics, labels, model_outputs, **kwargs):
+    """Process and update metrics.
+
+    Called when using custom training loop API.
+
+    Args:
+      metrics: a nested structure of metrics objects. The return of function
+        self.build_metrics.
+      labels: a tensor or a nested structure of tensors.
+      model_outputs: a tensor or a nested structure of tensors. For example,
+        output of the keras model built by self.build_model.
+      **kwargs: other args.
+    """
+    for metric in metrics:
+      if 'mask_scores_mse' == metric.name:
+        actual_mask_scores = segmentation_losses.get_actual_mask_scores(
+            model_outputs['logits'], labels['masks'],
+            self.task_config.losses.ignore_label)
+        metric.update_state(actual_mask_scores, model_outputs['mask_scores'])
       else:
-        metrics = [
-            tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
-            tf.keras.metrics.SparseTopKCategoricalAccuracy(
-                k=k, name='top_{}_accuracy'.format(k))]
-    else:
-      metrics = []
-      # These metrics destablize the training if included in training. The jobs
-      # fail due to OOM.
-      # TODO(arashwan): Investigate adding following metric to train.
-      if not training:
-        metrics = [
-            tf.keras.metrics.AUC(
-                name='globalPR-AUC',
-                curve='PR',
-                multi_label=False,
-                from_logits=True),
-            tf.keras.metrics.AUC(
-                name='meanPR-AUC',
-                curve='PR',
-                multi_label=True,
-                num_labels=self.task_config.model.num_classes,
-                from_logits=True),
-        ]
+        metric.update_state(labels, model_outputs['logits'])
+
+  def build_metrics(self, training: bool = True):
+    """Gets streaming metrics for training/validation."""
+    metrics = []
+    self.iou_metric = None
+
+    if training and self.task_config.evaluation.report_train_mean_iou:
+      metrics.append(
+          segmentation_metrics.MeanIoU(
+              name='mean_iou',
+              num_classes=self.task_config.model.num_classes,
+              rescale_predictions=False,
+              dtype=tf.float32))
+      if self.task_config.model.get('mask_scoring_head'):
+        metrics.append(
+            tf_keras.metrics.MeanSquaredError(name='mask_scores_mse'))
+
+    if not training:
+      self.iou_metric = segmentation_metrics.PerClassIoU(
+          name='per_class_iou',
+          num_classes=self.task_config.model.num_classes,
+          rescale_predictions=(
+              not self.task_config.validation_data.resize_eval_groundtruth),
+          dtype=tf.float32)
+      if (self.task_config.validation_data.resize_eval_groundtruth and
+          self.task_config.model.get('mask_scoring_head')):
+        # Masks scores metric can only be computed if labels are scaled to match
+        # preticted mask scores.
+        metrics.append(
+            tf_keras.metrics.MeanSquaredError(name='mask_scores_mse'))
+
     return metrics
 
   def train_step(self,
                  inputs: Tuple[Any, Any],
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
+                 model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer,
                  metrics: Optional[List[Any]] = None):
     """Does forward and backward.
 
     Args:
-      inputs: A tuple of input tensors of (features, labels).
-      model: A tf.keras.Model instance.
-      optimizer: The optimizer for this training step.
-      metrics: A nested structure of metrics objects.
+      inputs: a dictionary of input tensors.
+      model: the model, forward pass definition.
+      optimizer: the optimizer for this training step.
+      metrics: a nested structure of metrics objects.
 
     Returns:
       A dictionary of logs.
     """
     features, labels = inputs
-    is_multilabel = self.task_config.train_data.is_multilabel
-    if self.task_config.losses.one_hot and not is_multilabel:
-      labels = tf.one_hot(labels, self.task_config.model.num_classes)
+
+    input_partition_dims = self.task_config.train_input_partition_dims
+    if input_partition_dims:
+      strategy = tf.distribute.get_strategy()
+      features = strategy.experimental_split_to_logical_devices(
+          features, input_partition_dims)
 
     num_replicas = tf.distribute.get_strategy().num_replicas_in_sync
     with tf.GradientTape() as tape:
       outputs = model(features, training=True)
-
+      if isinstance(outputs, tf.Tensor):
+        outputs = {'logits': outputs}
       # Casting output layer as float32 is necessary when mixed_precision is
       # mixed_float16 or mixed_bfloat16 to ensure output is casted as float32.
-      outputs = tf.nest.map_structure(
-          lambda x: tf.cast(x, tf.float32), outputs)
+      outputs = tf.nest.map_structure(lambda x: tf.cast(x, tf.float32), outputs)
 
       # Computes per-replica loss.
       loss = self.build_losses(
-          model_outputs=outputs,
-          labels=labels,
-          aux_losses=model.losses)
+          model_outputs=outputs, labels=labels, aux_losses=model.losses)
       # Scales loss as the default gradients allreduce performs sum inside the
       # optimizer.
       scaled_loss = loss / num_replicas
 
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
-      if isinstance(
-          optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     # Scales back gradient before apply_gradients when LossScaleOptimizer is
     # used.
-    if isinstance(
-        optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
     optimizer.apply_gradients(list(zip(grads, tvars)))
 
     logs = {self.loss: loss}
-
-    # Convert logits to softmax for metric computation if needed.
-    if hasattr(self.task_config.model,
-               'output_softmax') and self.task_config.model.output_softmax:
-      outputs = tf.nn.softmax(outputs, axis=-1)
     if metrics:
       self.process_metrics(metrics, labels, outputs)
-    elif model.compiled_metrics:
-      self.process_compiled_metrics(model.compiled_metrics, labels, outputs)
-      logs.update({m.name: m.result() for m in model.metrics})
+      logs.update({m.name: m.result() for m in metrics})
+
     return logs
 
   def validation_step(self,
                       inputs: Tuple[Any, Any],
-                      model: tf.keras.Model,
+                      model: tf_keras.Model,
                       metrics: Optional[List[Any]] = None):
-    """Runs validatation step.
+    """Validatation step.
 
     Args:
-      inputs: A tuple of input tensors of (features, labels).
-      model: A tf.keras.Model instance.
-      metrics: A nested structure of metrics objects.
+      inputs: a dictionary of input tensors.
+      model: the keras.Model.
+      metrics: a nested structure of metrics objects.
 
     Returns:
       A dictionary of logs.
     """
     features, labels = inputs
-    one_hot = self.task_config.losses.one_hot
-    soft_labels = self.task_config.losses.soft_labels
-    is_multilabel = self.task_config.train_data.is_multilabel
-    # Note: `soft_labels`` only apply to the training phrase. In the validation
-    # phrase, labels should still be integer ids and need to be converted to
-    # one hot format.
-    if (one_hot or soft_labels) and not is_multilabel:
-      labels = tf.one_hot(labels, self.task_config.model.num_classes)
+
+    input_partition_dims = self.task_config.eval_input_partition_dims
+    if input_partition_dims:
+      strategy = tf.distribute.get_strategy()
+      features = strategy.experimental_split_to_logical_devices(
+          features, input_partition_dims)
 
     outputs = self.inference_step(features, model)
+    if isinstance(outputs, tf.Tensor):
+      outputs = {'logits': outputs}
     outputs = tf.nest.map_structure(lambda x: tf.cast(x, tf.float32), outputs)
-    loss = self.build_losses(
-        model_outputs=outputs,
-        labels=labels,
-        aux_losses=model.losses)
+
+    if self.task_config.validation_data.resize_eval_groundtruth:
+      loss = self.build_losses(
+          model_outputs=outputs, labels=labels, aux_losses=model.losses)
+    else:
+      loss = 0
 
     logs = {self.loss: loss}
-    # Convert logits to softmax for metric computation if needed.
-    if hasattr(self.task_config.model,
-               'output_softmax') and self.task_config.model.output_softmax:
-      outputs = tf.nn.softmax(outputs, axis=-1)
+
+    if self.iou_metric is not None:
+      self.iou_metric.update_state(labels, outputs['logits'])
     if metrics:
       self.process_metrics(metrics, labels, outputs)
-    elif model.compiled_metrics:
-      self.process_compiled_metrics(model.compiled_metrics, labels, outputs)
-      logs.update({m.name: m.result() for m in model.metrics})
+
+    if (
+        hasattr(self.task_config, 'allow_image_summary')
+        and self.task_config.allow_image_summary
+    ):
+      logs.update(
+          {'visualization': (tf.cast(features, dtype=tf.float32), outputs)}
+      )
+
     return logs
 
-  def inference_step(self, inputs: tf.Tensor, model: tf.keras.Model):
+  def inference_step(self, inputs: tf.Tensor, model: tf_keras.Model):
     """Performs the forward step."""
     return model(inputs, training=False)
+
+  def aggregate_logs(self, state=None, step_outputs=None):
+    if state is None and self.iou_metric is not None:
+      self.iou_metric.reset_states()
+
+    if 'visualization' in step_outputs:
+      # Update segmentation state for writing summary if there are artifacts for
+      # visualization.
+      if state is None:
+        state = {}
+      state.update(visualization_utils.update_segmentation_state(step_outputs))
+
+    if state is None:
+      # Create an arbitrary state to indicate it's not the first step in the
+      # following calls to this function.
+      state = True
+
+    return state
+
+  def reduce_aggregated_logs(self, aggregated_logs, global_step=None):
+    logs = {}
+    if self.iou_metric is not None:
+      ious = self.iou_metric.result()
+      # TODO(arashwan): support loading class name from a label map file.
+      if self.task_config.evaluation.report_per_class_iou:
+        for i, value in enumerate(ious.numpy()):
+          logs.update({'iou/{}'.format(i): value})
+      # Computes mean IoU
+      logs.update({'mean_iou': tf.reduce_mean(ious)})
+
+    # Add visualization for summary.
+    if isinstance(aggregated_logs, dict) and 'image' in aggregated_logs:
+      validation_outputs = visualization_utils.visualize_segmentation_outputs(
+          logs=aggregated_logs, task_config=self.task_config
+      )
+      logs.update(validation_outputs)
+
+    return logs
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/tasks/maskrcnn.py` & `tf-models-no-deps-2.16.0/official/vision/tasks/maskrcnn.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,35 +11,40 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """MaskRCNN task definition."""
 
 import os
-from typing import Any, Dict, Optional, List, Tuple, Mapping
+from typing import Any, Dict, List, Mapping, Optional, Tuple
 
 from absl import logging
-import tensorflow as tf
+import numpy as np
+import tensorflow as tf, tf_keras
+
 from official.common import dataset_fn as dataset_fn_lib
 from official.core import base_task
 from official.core import task_factory
 from official.vision.configs import maskrcnn as exp_cfg
+from official.vision.dataloaders import input_reader
 from official.vision.dataloaders import input_reader_factory
 from official.vision.dataloaders import maskrcnn_input
 from official.vision.dataloaders import tf_example_decoder
 from official.vision.dataloaders import tf_example_label_map_decoder
 from official.vision.evaluation import coco_evaluator
 from official.vision.evaluation import coco_utils
+from official.vision.evaluation import instance_metrics as metrics_lib
 from official.vision.losses import maskrcnn_losses
 from official.vision.modeling import factory
+from official.vision.utils.object_detection import visualization_utils
 
 
 def zero_out_disallowed_class_ids(batch_class_ids: tf.Tensor,
                                   allowed_class_ids: List[int]):
-  """Zero out IDs of classes not in allowed_class_ids.
+  """Zeroes out IDs of classes not in allowed_class_ids.
 
   Args:
     batch_class_ids: A [batch_size, num_instances] int tensor of input
       class IDs.
     allowed_class_ids: A python list of class IDs which we want to allow.
 
   Returns:
@@ -63,49 +68,54 @@
 
   Mask R-CNN task provides artifacts for training/evalution procedures,
   including loading/iterating over Datasets, initializing the model, calculating
   the loss, post-processing, and customized metrics with reduction.
   """
 
   def build_model(self):
-    """Build Mask R-CNN model."""
+    """Builds Mask R-CNN model."""
 
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None] + self.task_config.model.input_size)
 
     l2_weight_decay = self.task_config.losses.l2_weight_decay
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (tf.keras.regularizers.l2(
+    l2_regularizer = (tf_keras.regularizers.l2(
         l2_weight_decay / 2.0) if l2_weight_decay else None)
 
     model = factory.build_maskrcnn(
         input_specs=input_specs,
         model_config=self.task_config.model,
         l2_regularizer=l2_regularizer)
 
     if self.task_config.freeze_backbone:
       model.backbone.trainable = False
 
+    # Builds the model through warm-up call.
+    dummy_images = tf_keras.Input(self.task_config.model.input_size)
+    dummy_image_shape = tf_keras.layers.Input([2])
+    _ = model(dummy_images, image_shape=dummy_image_shape, training=False)
+
     return model
 
-  def initialize(self, model: tf.keras.Model):
-    """Loading pretrained checkpoint."""
+  def initialize(self, model: tf_keras.Model):
+    """Loads pretrained checkpoint."""
 
     if not self.task_config.init_checkpoint:
       return
 
     ckpt_dir_or_file = self.task_config.init_checkpoint
     if tf.io.gfile.isdir(ckpt_dir_or_file):
       ckpt_dir_or_file = tf.train.latest_checkpoint(ckpt_dir_or_file)
 
     # Restoring checkpoint.
     if self.task_config.init_checkpoint_modules == 'all':
-      ckpt = tf.train.Checkpoint(**model.checkpoint_items)
+      ckpt = tf.train.Checkpoint(model=model)
       status = ckpt.read(ckpt_dir_or_file)
       status.expect_partial().assert_existing_objects_matched()
     else:
       ckpt_items = {}
       if 'backbone' in self.task_config.init_checkpoint_modules:
         ckpt_items.update(backbone=model.backbone)
       if 'decoder' in self.task_config.init_checkpoint_modules:
@@ -120,15 +130,15 @@
 
   def build_inputs(
       self,
       params: exp_cfg.DataConfig,
       input_context: Optional[tf.distribute.InputContext] = None,
       dataset_fn: Optional[dataset_fn_lib.PossibleDatasetType] = None
   ) -> tf.data.Dataset:
-    """Build input dataset."""
+    """Builds input dataset."""
     decoder_cfg = params.decoder.get()
     if params.decoder.type == 'simple_decoder':
       decoder = tf_example_decoder.TfExampleDecoder(
           include_mask=self._task_config.model.include_mask,
           regenerate_source_id=decoder_cfg.regenerate_source_id,
           mask_binarize_threshold=decoder_cfg.mask_binarize_threshold)
     elif params.decoder.type == 'label_map_decoder':
@@ -143,76 +153,94 @@
     parser = maskrcnn_input.Parser(
         output_size=self.task_config.model.input_size[:2],
         min_level=self.task_config.model.min_level,
         max_level=self.task_config.model.max_level,
         num_scales=self.task_config.model.anchor.num_scales,
         aspect_ratios=self.task_config.model.anchor.aspect_ratios,
         anchor_size=self.task_config.model.anchor.anchor_size,
-        dtype=params.dtype,
         rpn_match_threshold=params.parser.rpn_match_threshold,
         rpn_unmatched_threshold=params.parser.rpn_unmatched_threshold,
         rpn_batch_size_per_im=params.parser.rpn_batch_size_per_im,
         rpn_fg_fraction=params.parser.rpn_fg_fraction,
         aug_rand_hflip=params.parser.aug_rand_hflip,
+        aug_rand_vflip=params.parser.aug_rand_vflip,
         aug_scale_min=params.parser.aug_scale_min,
         aug_scale_max=params.parser.aug_scale_max,
         aug_type=params.parser.aug_type,
         skip_crowd_during_training=params.parser.skip_crowd_during_training,
         max_num_instances=params.parser.max_num_instances,
-        include_mask=self._task_config.model.include_mask,
-        mask_crop_size=params.parser.mask_crop_size)
+        include_mask=self.task_config.model.include_mask,
+        outer_boxes_scale=self.task_config.model.outer_boxes_scale,
+        mask_crop_size=params.parser.mask_crop_size,
+        dtype=params.dtype,
+    )
 
     if not dataset_fn:
       dataset_fn = dataset_fn_lib.pick_dataset_fn(params.file_type)
 
     reader = input_reader_factory.input_reader_generator(
         params,
         dataset_fn=dataset_fn,
         decoder_fn=decoder.decode,
+        combine_fn=input_reader.create_combine_fn(params),
         parser_fn=parser.parse_fn(params.is_training))
     dataset = reader.read(input_context=input_context)
 
     return dataset
 
   def _build_rpn_losses(
       self, outputs: Mapping[str, Any],
       labels: Mapping[str, Any]) -> Tuple[tf.Tensor, tf.Tensor]:
-    """Build losses for Region Proposal Network (RPN)."""
+    """Builds losses for Region Proposal Network (RPN)."""
     rpn_score_loss_fn = maskrcnn_losses.RpnScoreLoss(
         tf.shape(outputs['box_outputs'])[1])
     rpn_box_loss_fn = maskrcnn_losses.RpnBoxLoss(
         self.task_config.losses.rpn_huber_loss_delta)
     rpn_score_loss = tf.reduce_mean(
         rpn_score_loss_fn(outputs['rpn_scores'], labels['rpn_score_targets']))
     rpn_box_loss = tf.reduce_mean(
         rpn_box_loss_fn(outputs['rpn_boxes'], labels['rpn_box_targets']))
     return rpn_score_loss, rpn_box_loss
 
   def _build_frcnn_losses(
-      self, outputs: Mapping[str, Any],
-      labels: Mapping[str, Any]) -> Tuple[tf.Tensor, tf.Tensor]:
-    """Build losses for Fast R-CNN."""
+      self,
+      outputs: Mapping[str, Any],
+      labels: Mapping[str, Any],
+  ) -> Tuple[tf.Tensor, tf.Tensor]:
+    """Builds losses for Fast R-CNN."""
     cascade_ious = self.task_config.model.roi_sampler.cascade_iou_thresholds
 
-    frcnn_cls_loss_fn = maskrcnn_losses.FastrcnnClassLoss()
+    frcnn_cls_loss_fn = maskrcnn_losses.FastrcnnClassLoss(
+        use_binary_cross_entropy=self.task_config.losses
+        .frcnn_class_use_binary_cross_entropy,
+        top_k_percent=self.task_config.losses.frcnn_class_loss_top_k_percent)
     frcnn_box_loss_fn = maskrcnn_losses.FastrcnnBoxLoss(
         self.task_config.losses.frcnn_huber_loss_delta,
         self.task_config.model.detection_head.class_agnostic_bbox_pred)
 
     # Final cls/box losses are computed as an average of all detection heads.
     frcnn_cls_loss = 0.0
     frcnn_box_loss = 0.0
     num_det_heads = 1 if cascade_ious is None else 1 + len(cascade_ious)
     for cas_num in range(num_det_heads):
       frcnn_cls_loss_i = tf.reduce_mean(
           frcnn_cls_loss_fn(
-              outputs['class_outputs_{}'
-                      .format(cas_num) if cas_num else 'class_outputs'],
-              outputs['class_targets_{}'
-                      .format(cas_num) if cas_num else 'class_targets']))
+              outputs[
+                  'class_outputs_{}'.format(cas_num)
+                  if cas_num
+                  else 'class_outputs'
+              ],
+              outputs[
+                  'class_targets_{}'.format(cas_num)
+                  if cas_num
+                  else 'class_targets'
+              ],
+              self.task_config.losses.class_weights,
+          )
+      )
       frcnn_box_loss_i = tf.reduce_mean(
           frcnn_box_loss_fn(
               outputs['box_outputs_{}'.format(cas_num
                                              ) if cas_num else 'box_outputs'],
               outputs['class_targets_{}'
                       .format(cas_num) if cas_num else 'class_targets'],
               outputs['box_targets_{}'.format(cas_num
@@ -220,64 +248,65 @@
       frcnn_cls_loss += frcnn_cls_loss_i
       frcnn_box_loss += frcnn_box_loss_i
     frcnn_cls_loss /= num_det_heads
     frcnn_box_loss /= num_det_heads
     return frcnn_cls_loss, frcnn_box_loss
 
   def _build_mask_loss(self, outputs: Mapping[str, Any]) -> tf.Tensor:
-    """Build losses for the masks."""
+    """Builds losses for the masks."""
     mask_loss_fn = maskrcnn_losses.MaskrcnnLoss()
     mask_class_targets = outputs['mask_class_targets']
     if self.task_config.allowed_mask_class_ids is not None:
       # Classes with ID=0 are ignored by mask_loss_fn in loss computation.
       mask_class_targets = zero_out_disallowed_class_ids(
           mask_class_targets, self.task_config.allowed_mask_class_ids)
     return tf.reduce_mean(
         mask_loss_fn(outputs['mask_outputs'], outputs['mask_targets'],
                      mask_class_targets))
 
   def build_losses(self,
                    outputs: Mapping[str, Any],
                    labels: Mapping[str, Any],
                    aux_losses: Optional[Any] = None) -> Dict[str, tf.Tensor]:
-    """Build Mask R-CNN losses."""
+    """Builds Mask R-CNN losses."""
+    loss_params = self.task_config.losses
     rpn_score_loss, rpn_box_loss = self._build_rpn_losses(outputs, labels)
     frcnn_cls_loss, frcnn_box_loss = self._build_frcnn_losses(outputs, labels)
     if self.task_config.model.include_mask:
       mask_loss = self._build_mask_loss(outputs)
     else:
       mask_loss = tf.constant(0.0, dtype=tf.float32)
 
-    params = self.task_config
     model_loss = (
-        params.losses.rpn_score_weight * rpn_score_loss +
-        params.losses.rpn_box_weight * rpn_box_loss +
-        params.losses.frcnn_class_weight * frcnn_cls_loss +
-        params.losses.frcnn_box_weight * frcnn_box_loss +
-        params.losses.mask_weight * mask_loss)
+        loss_params.rpn_score_weight * rpn_score_loss
+        + loss_params.rpn_box_weight * rpn_box_loss
+        + loss_params.frcnn_class_weight * frcnn_cls_loss
+        + loss_params.frcnn_box_weight * frcnn_box_loss
+        + loss_params.mask_weight * mask_loss
+    )
 
     total_loss = model_loss
     if aux_losses:
       reg_loss = tf.reduce_sum(aux_losses)
       total_loss = model_loss + reg_loss
 
-    total_loss = params.losses.loss_weight * total_loss
+    total_loss = loss_params.loss_weight * total_loss
     losses = {
         'total_loss': total_loss,
         'rpn_score_loss': rpn_score_loss,
         'rpn_box_loss': rpn_box_loss,
         'frcnn_cls_loss': frcnn_cls_loss,
         'frcnn_box_loss': frcnn_box_loss,
         'mask_loss': mask_loss,
         'model_loss': model_loss,
     }
     return losses
 
   def _build_coco_metrics(self):
-    """Build COCO metrics evaluator."""
+    """Builds COCO metrics evaluator."""
     if (not self._task_config.model.include_mask
        ) or self._task_config.annotation_file:
       self.coco_metric = coco_evaluator.COCOEvaluator(
           annotation_file=self._task_config.annotation_file,
           include_mask=self._task_config.model.include_mask,
           per_category_metrics=self._task_config.per_category_metrics)
     else:
@@ -304,29 +333,30 @@
             .simple_decoder.regenerate_source_id)
       self.coco_metric = coco_evaluator.COCOEvaluator(
           annotation_file=annotation_path,
           include_mask=self._task_config.model.include_mask,
           per_category_metrics=self._task_config.per_category_metrics)
 
   def build_metrics(self, training: bool = True):
-    """Build detection metrics."""
-    metrics = []
+    """Builds detection metrics."""
+    self.instance_box_perclass_metrics = None
+    self.instance_mask_perclass_metrics = None
     if training:
       metric_names = [
           'total_loss',
           'rpn_score_loss',
           'rpn_box_loss',
           'frcnn_cls_loss',
           'frcnn_box_loss',
           'mask_loss',
-          'model_loss'
+          'model_loss',
+      ]
+      return [
+          tf_keras.metrics.Mean(name, dtype=tf.float32) for name in metric_names
       ]
-      for name in metric_names:
-        metrics.append(tf.keras.metrics.Mean(name, dtype=tf.float32))
-
     else:
       if self._task_config.use_coco_metrics:
         self._build_coco_metrics()
       if self._task_config.use_wod_metrics:
         # To use Waymo open dataset metrics, please install one of the pip
         # package `waymo-open-dataset-tf-*` from
         # https://github.com/waymo-research/waymo-open-dataset/blob/master/docs/quick_start.md#use-pre-compiled-pippip3-packages-for-linux
@@ -337,20 +367,34 @@
           from official.vision.evaluation import wod_detection_evaluator  # pylint: disable=g-import-not-at-top
         except ModuleNotFoundError:
           logging.error('waymo-open-dataset should be installed to enable Waymo'
                         ' evaluator.')
           raise
         self.wod_metric = wod_detection_evaluator.WOD2dDetectionEvaluator()
 
-    return metrics
+      if self.task_config.use_approx_instance_metrics:
+        self.instance_box_perclass_metrics = metrics_lib.InstanceMetrics(
+            name='instance_box_perclass',
+            num_classes=self.task_config.model.num_classes,
+            iou_thresholds=np.arange(0.5, 1.0, step=0.05),
+        )
+        if self.task_config.model.include_mask:
+          self.instance_mask_perclass_metrics = metrics_lib.InstanceMetrics(
+              name='instance_mask_perclass',
+              use_masks=True,
+              num_classes=self.task_config.model.num_classes,
+              iou_thresholds=np.arange(0.5, 1.0, step=0.05),
+          )
+
+      return []
 
   def train_step(self,
                  inputs: Tuple[Any, Any],
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
+                 model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer,
                  metrics: Optional[List[Any]] = None):
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
@@ -358,122 +402,242 @@
 
     Returns:
       A dictionary of logs.
     """
     images, labels = inputs
     num_replicas = tf.distribute.get_strategy().num_replicas_in_sync
     with tf.GradientTape() as tape:
+      model_kwargs = {
+          'image_shape': labels['image_info'][:, 1, :],
+          'anchor_boxes': labels['anchor_boxes'],
+          'gt_boxes': labels['gt_boxes'],
+          'gt_classes': labels['gt_classes'],
+          'training': True,
+      }
+      if self.task_config.model.include_mask:
+        model_kwargs['gt_masks'] = labels['gt_masks']
+        if self.task_config.model.outer_boxes_scale > 1.0:
+          model_kwargs['gt_outer_boxes'] = labels['gt_outer_boxes']
       outputs = model(
-          images,
-          image_shape=labels['image_info'][:, 1, :],
-          anchor_boxes=labels['anchor_boxes'],
-          gt_boxes=labels['gt_boxes'],
-          gt_classes=labels['gt_classes'],
-          gt_masks=(labels['gt_masks'] if self.task_config.model.include_mask
-                    else None),
-          training=True)
+          images, **model_kwargs)
       outputs = tf.nest.map_structure(
           lambda x: tf.cast(x, tf.float32), outputs)
 
       # Computes per-replica loss.
       losses = self.build_losses(
           outputs=outputs, labels=labels, aux_losses=model.losses)
       scaled_loss = losses['total_loss'] / num_replicas
 
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     # Scales back gradient when LossScaleOptimizer is used.
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
     optimizer.apply_gradients(list(zip(grads, tvars)))
 
     logs = {self.loss: losses['total_loss']}
 
     if metrics:
       for m in metrics:
         m.update_state(losses[m.name])
 
     return logs
 
+  def _update_metrics(self, labels, outputs, logs):
+    instance_predictions = {
+        'detection_boxes': outputs['detection_boxes'],
+        'detection_scores': outputs['detection_scores'],
+        'detection_classes': outputs['detection_classes'],
+        'num_detections': outputs['num_detections'],
+        'source_id': labels['groundtruths']['source_id'],
+        'image_info': labels['image_info'],
+    }
+    if 'detection_outer_boxes' in outputs:
+      instance_predictions['detection_outer_boxes'] = outputs[
+          'detection_outer_boxes'
+      ]
+    if 'detection_masks' in outputs:
+      instance_predictions['detection_masks'] = outputs['detection_masks']
+
+    if self._task_config.use_coco_metrics:
+      logs[self.coco_metric.name] = (
+          labels['groundtruths'],
+          instance_predictions,
+      )
+    if self.task_config.use_wod_metrics:
+      logs[self.wod_metric.name] = (
+          labels['groundtruths'],
+          instance_predictions,
+      )
+
+    instance_labels = {
+        'boxes': labels['groundtruths']['boxes'],
+        'classes': labels['groundtruths']['classes'],
+        'is_crowds': labels['groundtruths']['is_crowds'],
+        'image_info': labels['image_info'],
+    }
+    if self.instance_box_perclass_metrics is not None:
+      self.instance_box_perclass_metrics.update_state(
+          y_true=instance_labels, y_pred=instance_predictions
+      )
+    if self.instance_mask_perclass_metrics is not None:
+      instance_labels['masks'] = labels['groundtruths']['masks']
+      self.instance_mask_perclass_metrics.update_state(
+          y_true=instance_labels, y_pred=instance_predictions
+      )
+
   def validation_step(self,
                       inputs: Tuple[Any, Any],
-                      model: tf.keras.Model,
+                      model: tf_keras.Model,
                       metrics: Optional[List[Any]] = None):
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
 
     Returns:
       A dictionary of logs.
     """
     images, labels = inputs
-
     outputs = model(
         images,
         anchor_boxes=labels['anchor_boxes'],
         image_shape=labels['image_info'][:, 1, :],
-        training=False)
+        training=False,
+    )
 
     logs = {self.loss: 0}
-    if self._task_config.use_coco_metrics:
-      coco_model_outputs = {
-          'detection_boxes': outputs['detection_boxes'],
-          'detection_scores': outputs['detection_scores'],
-          'detection_classes': outputs['detection_classes'],
-          'num_detections': outputs['num_detections'],
-          'source_id': labels['groundtruths']['source_id'],
-          'image_info': labels['image_info']
-      }
-      if self.task_config.model.include_mask:
-        coco_model_outputs.update({
-            'detection_masks': outputs['detection_masks'],
-        })
-      logs.update(
-          {self.coco_metric.name: (labels['groundtruths'], coco_model_outputs)})
+    self._update_metrics(labels, outputs, logs)
 
-    if self.task_config.use_wod_metrics:
-      wod_model_outputs = {
-          'detection_boxes': outputs['detection_boxes'],
-          'detection_scores': outputs['detection_scores'],
-          'detection_classes': outputs['detection_classes'],
-          'num_detections': outputs['num_detections'],
-          'source_id': labels['groundtruths']['source_id'],
-          'image_info': labels['image_info']
-      }
+    if (
+        hasattr(self.task_config, 'allow_image_summary')
+        and self.task_config.allow_image_summary
+    ):
       logs.update(
-          {self.wod_metric.name: (labels['groundtruths'], wod_model_outputs)})
+          {'visualization': (tf.cast(images, dtype=tf.float32), outputs)}
+      )
+
     return logs
 
-  def aggregate_logs(self, state=None, step_outputs=None):
-    if self._task_config.use_coco_metrics:
-      if state is None:
+  def aggregate_logs(
+      self,
+      state: Optional[Any] = None,
+      step_outputs: Optional[Dict[str, Any]] = None,
+  ) -> Optional[Any]:
+    """Optional aggregation over logs returned from a validation step."""
+    if not state:
+      # The metrics which update state on CPU.
+      if self.task_config.use_coco_metrics:
         self.coco_metric.reset_states()
+      if self.task_config.use_wod_metrics:
+        self.wod_metric.reset_states()
+
+    if self.task_config.use_coco_metrics:
       self.coco_metric.update_state(
           step_outputs[self.coco_metric.name][0],
-          step_outputs[self.coco_metric.name][1])
-    if self._task_config.use_wod_metrics:
-      if state is None:
-        self.wod_metric.reset_states()
+          step_outputs[self.coco_metric.name][1],
+      )
+    if self.task_config.use_wod_metrics:
       self.wod_metric.update_state(
           step_outputs[self.wod_metric.name][0],
-          step_outputs[self.wod_metric.name][1])
-    if state is None:
+          step_outputs[self.wod_metric.name][1],
+      )
+
+    if 'visualization' in step_outputs:
+      # Update detection state for writing summary if there are artifacts for
+      # visualization.
+      if state is None:
+        state = {}
+      state.update(visualization_utils.update_detection_state(step_outputs))
+      # TODO(allenyan): Mapping `detection_masks` (w.r.t. the `gt_boxes`) back
+      # to full masks (w.r.t. the image). Disable mask visualization fow now.
+      state.pop('detection_masks', None)
+
+    if not state:
       # Create an arbitrary state to indicate it's not the first step in the
       # following calls to this function.
       state = True
     return state
 
-  def reduce_aggregated_logs(self, aggregated_logs, global_step=None):
+  def _reduce_instance_metrics(
+      self, logs: Dict[str, Any], use_masks: bool = False
+  ):
+    """Updates the per class and mean instance metrics in the logs."""
+    if use_masks:
+      instance_metrics = self.instance_mask_perclass_metrics
+      prefix = 'mask_'
+    else:
+      instance_metrics = self.instance_box_perclass_metrics
+      prefix = ''
+    if instance_metrics is None:
+      raise ValueError(
+          'No instance metrics defined when use_masks is %s' % use_masks
+      )
+    result = instance_metrics.result()
+    iou_thresholds = instance_metrics.get_config()['iou_thresholds']
+
+    for ap_key in instance_metrics.get_average_precision_metrics_keys():
+      # (num_iou_thresholds, num_classes)
+      per_class_ap = tf.where(
+          result['valid_classes'], result[ap_key], tf.zeros_like(result[ap_key])
+      )
+      # (num_iou_thresholds,)
+      mean_ap_by_iou = tf.math.divide_no_nan(
+          tf.reduce_sum(per_class_ap, axis=-1),
+          tf.reduce_sum(
+              tf.cast(result['valid_classes'], dtype=per_class_ap.dtype),
+              axis=-1,
+          ),
+      )
+      logs[f'{prefix}{ap_key}'] = tf.reduce_mean(mean_ap_by_iou)
+      for j, iou in enumerate(iou_thresholds):
+        if int(iou * 100) in {50, 75}:
+          logs[f'{prefix}{ap_key}{int(iou * 100)}'] = mean_ap_by_iou[j]
+
+      if self.task_config.per_category_metrics:
+        # (num_classes,)
+        per_class_mean_ap = tf.reduce_mean(per_class_ap, axis=0)
+        valid_classes = result['valid_classes'].numpy()
+        for k in range(self.task_config.model.num_classes):
+          if valid_classes[k]:
+            logs[f'{prefix}{ap_key} ByCategory/{k}'] = per_class_mean_ap[k]
+            for j, iou in enumerate(iou_thresholds):
+              if int(iou * 100) in {50, 75}:
+                logs[f'{prefix}{ap_key}{int(iou * 100)} ByCategory/{k}'] = (
+                    per_class_ap[j][k]
+                )
+
+  def reduce_aggregated_logs(
+      self,
+      aggregated_logs: Dict[str, Any],
+      global_step: Optional[tf.Tensor] = None,
+  ) -> Dict[str, tf.Tensor]:
+    """Optional reduce of aggregated logs over validation steps."""
     logs = {}
-    if self._task_config.use_coco_metrics:
+    # The metrics which update state on device.
+    if self.instance_box_perclass_metrics is not None:
+      self._reduce_instance_metrics(logs, use_masks=False)
+      self.instance_box_perclass_metrics.reset_state()
+    if self.instance_mask_perclass_metrics is not None:
+      self._reduce_instance_metrics(logs, use_masks=True)
+      self.instance_mask_perclass_metrics.reset_state()
+    # The metrics which update state on CPU.
+    if self.task_config.use_coco_metrics:
       logs.update(self.coco_metric.result())
-    if self._task_config.use_wod_metrics:
+    if self.task_config.use_wod_metrics:
       logs.update(self.wod_metric.result())
+
+    # Add visualization for summary.
+    if isinstance(aggregated_logs, dict) and 'image' in aggregated_logs:
+      validation_outputs = visualization_utils.visualize_outputs(
+          logs=aggregated_logs, task_config=self.task_config
+      )
+      logs.update(validation_outputs)
+
     return logs
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/tasks/retinanet.py` & `tf-models-no-deps-2.16.0/official/vision/tasks/retinanet.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,64 +12,66 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """RetinaNet task definition."""
 from typing import Any, List, Mapping, Optional, Tuple
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import dataset_fn
 from official.core import base_task
 from official.core import task_factory
 from official.vision.configs import retinanet as exp_cfg
+from official.vision.dataloaders import input_reader
 from official.vision.dataloaders import input_reader_factory
 from official.vision.dataloaders import retinanet_input
 from official.vision.dataloaders import tf_example_decoder
 from official.vision.dataloaders import tfds_factory
 from official.vision.dataloaders import tf_example_label_map_decoder
 from official.vision.evaluation import coco_evaluator
 from official.vision.losses import focal_loss
 from official.vision.losses import loss_utils
 from official.vision.modeling import factory
+from official.vision.utils.object_detection import visualization_utils
 
 
 @task_factory.register_task_cls(exp_cfg.RetinaNetTask)
 class RetinaNetTask(base_task.Task):
   """A single-replica view of training procedure.
 
   RetinaNet task provides artifacts for training/evalution procedures, including
   loading/iterating over Datasets, initializing the model, calculating the loss,
   post-processing, and customized metrics with reduction.
   """
 
   def build_model(self):
     """Build RetinaNet model."""
 
-    input_specs = tf.keras.layers.InputSpec(
+    input_specs = tf_keras.layers.InputSpec(
         shape=[None] + self.task_config.model.input_size)
 
     l2_weight_decay = self.task_config.losses.l2_weight_decay
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (tf.keras.regularizers.l2(
+    l2_regularizer = (tf_keras.regularizers.l2(
         l2_weight_decay / 2.0) if l2_weight_decay else None)
 
     model = factory.build_retinanet(
         input_specs=input_specs,
         model_config=self.task_config.model,
         l2_regularizer=l2_regularizer)
 
     if self.task_config.freeze_backbone:
       model.backbone.trainable = False
 
     return model
 
-  def initialize(self, model: tf.keras.Model):
+  def initialize(self, model: tf_keras.Model):
     """Loading pretrained checkpoint."""
     if not self.task_config.init_checkpoint:
       return
 
     ckpt_dir_or_file = self.task_config.init_checkpoint
     if tf.io.gfile.isdir(ckpt_dir_or_file):
       ckpt_dir_or_file = tf.train.latest_checkpoint(ckpt_dir_or_file)
@@ -100,15 +102,17 @@
 
     if params.tfds_name:
       decoder = tfds_factory.get_detection_decoder(params.tfds_name)
     else:
       decoder_cfg = params.decoder.get()
       if params.decoder.type == 'simple_decoder':
         decoder = tf_example_decoder.TfExampleDecoder(
-            regenerate_source_id=decoder_cfg.regenerate_source_id)
+            regenerate_source_id=decoder_cfg.regenerate_source_id,
+            attribute_names=decoder_cfg.attribute_names,
+        )
       elif params.decoder.type == 'label_map_decoder':
         decoder = tf_example_label_map_decoder.TfExampleDecoderLabelMap(
             label_map=decoder_cfg.label_map,
             regenerate_source_id=decoder_cfg.regenerate_source_id)
       else:
         raise ValueError('Unknown decoder type: {}!'.format(
             params.decoder.type))
@@ -119,25 +123,32 @@
         max_level=self.task_config.model.max_level,
         num_scales=self.task_config.model.anchor.num_scales,
         aspect_ratios=self.task_config.model.anchor.aspect_ratios,
         anchor_size=self.task_config.model.anchor.anchor_size,
         dtype=params.dtype,
         match_threshold=params.parser.match_threshold,
         unmatched_threshold=params.parser.unmatched_threshold,
+        box_coder_weights=(
+            self.task_config.model.detection_generator.box_coder_weights
+        ),
         aug_type=params.parser.aug_type,
         aug_rand_hflip=params.parser.aug_rand_hflip,
         aug_scale_min=params.parser.aug_scale_min,
         aug_scale_max=params.parser.aug_scale_max,
         skip_crowd_during_training=params.parser.skip_crowd_during_training,
-        max_num_instances=params.parser.max_num_instances)
+        max_num_instances=params.parser.max_num_instances,
+        pad=params.parser.pad,
+        keep_aspect_ratio=params.parser.keep_aspect_ratio,
+    )
 
     reader = input_reader_factory.input_reader_generator(
         params,
         dataset_fn=dataset_fn.pick_dataset_fn(params.file_type),
         decoder_fn=decoder.decode,
+        combine_fn=input_reader.create_combine_fn(params),
         parser_fn=parser.parse_fn(params.is_training))
     dataset = reader.read(input_context=input_context)
 
     return dataset
 
   def build_attribute_loss(self,
                            attribute_heads: List[exp_cfg.AttributeHead],
@@ -151,52 +162,75 @@
       outputs: RetinaNet model outputs.
       labels: RetinaNet labels.
       box_sample_weight: normalized bounding box sample weights.
 
     Returns:
       Attribute loss of all attribute heads.
     """
+    params = self.task_config
     attribute_loss = 0.0
     for head in attribute_heads:
       if head.name not in labels['attribute_targets']:
         raise ValueError(f'Attribute {head.name} not found in label targets.')
       if head.name not in outputs['attribute_outputs']:
         raise ValueError(f'Attribute {head.name} not found in model outputs.')
 
-      y_true_att = loss_utils.multi_level_flatten(
-          labels['attribute_targets'][head.name], last_dim=head.size)
-      y_pred_att = loss_utils.multi_level_flatten(
-          outputs['attribute_outputs'][head.name], last_dim=head.size)
       if head.type == 'regression':
-        att_loss_fn = tf.keras.losses.Huber(
-            1.0, reduction=tf.keras.losses.Reduction.SUM)
+        y_true_att = loss_utils.multi_level_flatten(
+            labels['attribute_targets'][head.name], last_dim=head.size
+        )
+        y_pred_att = loss_utils.multi_level_flatten(
+            outputs['attribute_outputs'][head.name], last_dim=head.size
+        )
+        att_loss_fn = tf_keras.losses.Huber(
+            1.0, reduction=tf_keras.losses.Reduction.SUM)
         att_loss = att_loss_fn(
             y_true=y_true_att,
             y_pred=y_pred_att,
             sample_weight=box_sample_weight)
+      elif head.type == 'classification':
+        y_true_att = loss_utils.multi_level_flatten(
+            labels['attribute_targets'][head.name], last_dim=None
+        )
+        y_true_att = tf.one_hot(y_true_att, head.size)
+        y_pred_att = loss_utils.multi_level_flatten(
+            outputs['attribute_outputs'][head.name], last_dim=head.size
+        )
+        cls_loss_fn = focal_loss.FocalLoss(
+            alpha=params.losses.focal_loss_alpha,
+            gamma=params.losses.focal_loss_gamma,
+            reduction=tf_keras.losses.Reduction.SUM,
+        )
+        att_loss = cls_loss_fn(
+            y_true=y_true_att,
+            y_pred=y_pred_att,
+            sample_weight=box_sample_weight,
+        )
       else:
         raise ValueError(f'Attribute type {head.type} not supported.')
       attribute_loss += att_loss
 
     return attribute_loss
 
-  def build_losses(self,
-                   outputs: Mapping[str, Any],
-                   labels: Mapping[str, Any],
-                   aux_losses: Optional[Any] = None):
+  def build_losses(
+      self,
+      outputs: Mapping[str, Any],
+      labels: Mapping[str, Any],
+      aux_losses: Optional[Any] = None,
+  ):
     """Build RetinaNet losses."""
     params = self.task_config
     attribute_heads = self.task_config.model.head.attribute_heads
 
     cls_loss_fn = focal_loss.FocalLoss(
         alpha=params.losses.focal_loss_alpha,
         gamma=params.losses.focal_loss_gamma,
-        reduction=tf.keras.losses.Reduction.SUM)
-    box_loss_fn = tf.keras.losses.Huber(
-        params.losses.huber_loss_delta, reduction=tf.keras.losses.Reduction.SUM)
+        reduction=tf_keras.losses.Reduction.SUM)
+    box_loss_fn = tf_keras.losses.Huber(
+        params.losses.huber_loss_delta, reduction=tf_keras.losses.Reduction.SUM)
 
     # Sums all positives in a batch for normalization and avoids zero
     # num_positives_sum, which would lead to inf loss during training
     cls_sample_weight = labels['cls_weights']
     box_sample_weight = labels['box_weights']
     num_positives = tf.reduce_sum(box_sample_weight) + 1.0
     cls_sample_weight = cls_sample_weight / num_positives
@@ -232,25 +266,31 @@
     return total_loss, cls_loss, box_loss, model_loss
 
   def build_metrics(self, training: bool = True):
     """Build detection metrics."""
     metrics = []
     metric_names = ['total_loss', 'cls_loss', 'box_loss', 'model_loss']
     for name in metric_names:
-      metrics.append(tf.keras.metrics.Mean(name, dtype=tf.float32))
+      metrics.append(tf_keras.metrics.Mean(name, dtype=tf.float32))
 
     if not training:
-      if self.task_config.validation_data.tfds_name and self.task_config.annotation_file:
+      if (
+          self.task_config.validation_data.tfds_name
+          and self.task_config.annotation_file
+      ):
         raise ValueError(
-            "Can't evaluate using annotation file when TFDS is used.")
+            "Can't evaluate using annotation file when TFDS is used."
+        )
       if self._task_config.use_coco_metrics:
         self.coco_metric = coco_evaluator.COCOEvaluator(
             annotation_file=self.task_config.annotation_file,
             include_mask=False,
-            per_category_metrics=self.task_config.per_category_metrics)
+            per_category_metrics=self.task_config.per_category_metrics,
+            max_num_eval_detections=self.task_config.max_num_eval_detections,
+        )
       if self._task_config.use_wod_metrics:
         # To use Waymo open dataset metrics, please install one of the pip
         # package `waymo-open-dataset-tf-*` from
         # https://github.com/waymo-research/waymo-open-dataset/blob/master/docs/quick_start.md#use-pre-compiled-pippip3-packages-for-linux
         # Note that the package is built with specific tensorflow version and
         # will produce error if it does not match the tf version that is
         # currently used.
@@ -262,16 +302,16 @@
           raise
         self.wod_metric = wod_detection_evaluator.WOD2dDetectionEvaluator()
 
     return metrics
 
   def train_step(self,
                  inputs: Tuple[Any, Any],
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
+                 model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer,
                  metrics: Optional[List[Any]] = None):
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
@@ -285,26 +325,27 @@
     with tf.GradientTape() as tape:
       outputs = model(features, training=True)
       outputs = tf.nest.map_structure(
           lambda x: tf.cast(x, tf.float32), outputs)
 
       # Computes per-replica loss.
       loss, cls_loss, box_loss, model_loss = self.build_losses(
-          outputs=outputs, labels=labels, aux_losses=model.losses)
+          outputs=outputs, labels=labels, aux_losses=model.losses
+      )
       scaled_loss = loss / num_replicas
 
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     # Scales back gradient when LossScaleOptimizer is used.
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
     optimizer.apply_gradients(list(zip(grads, tvars)))
 
     logs = {self.loss: loss}
 
     all_losses = {
         'total_loss': loss,
@@ -317,15 +358,15 @@
         m.update_state(all_losses[m.name])
         logs.update({m.name: m.result()})
 
     return logs
 
   def validation_step(self,
                       inputs: Tuple[Any, Any],
-                      model: tf.keras.Model,
+                      model: tf_keras.Model,
                       metrics: Optional[List[Any]] = None):
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
@@ -335,15 +376,16 @@
     """
     features, labels = inputs
 
     outputs = model(features, anchor_boxes=labels['anchor_boxes'],
                     image_shape=labels['image_info'][:, 1, :],
                     training=False)
     loss, cls_loss, box_loss, model_loss = self.build_losses(
-        outputs=outputs, labels=labels, aux_losses=model.losses)
+        outputs=outputs, labels=labels, aux_losses=model.losses
+    )
     logs = {self.loss: loss}
 
     all_losses = {
         'total_loss': loss,
         'cls_loss': cls_loss,
         'box_loss': box_loss,
         'model_loss': model_loss,
@@ -372,33 +414,58 @@
       logs.update(
           {self.wod_metric.name: (labels['groundtruths'], wod_model_outputs)})
 
     if metrics:
       for m in metrics:
         m.update_state(all_losses[m.name])
         logs.update({m.name: m.result()})
+
+    if (
+        hasattr(self.task_config, 'allow_image_summary')
+        and self.task_config.allow_image_summary
+    ):
+      logs.update(
+          {'visualization': (tf.cast(features, dtype=tf.float32), outputs)}
+      )
     return logs
 
   def aggregate_logs(self, state=None, step_outputs=None):
     if self._task_config.use_coco_metrics:
       if state is None:
         self.coco_metric.reset_states()
       self.coco_metric.update_state(step_outputs[self.coco_metric.name][0],
                                     step_outputs[self.coco_metric.name][1])
     if self._task_config.use_wod_metrics:
       if state is None:
         self.wod_metric.reset_states()
       self.wod_metric.update_state(step_outputs[self.wod_metric.name][0],
                                    step_outputs[self.wod_metric.name][1])
+
+    if 'visualization' in step_outputs:
+      # Update detection state for writing summary if there are artifacts for
+      # visualization.
+      if state is None:
+        state = {}
+      state.update(visualization_utils.update_detection_state(step_outputs))
+
     if state is None:
       # Create an arbitrary state to indicate it's not the first step in the
       # following calls to this function.
       state = True
+
     return state
 
   def reduce_aggregated_logs(self, aggregated_logs, global_step=None):
     logs = {}
     if self._task_config.use_coco_metrics:
       logs.update(self.coco_metric.result())
     if self._task_config.use_wod_metrics:
       logs.update(self.wod_metric.result())
+
+    # Add visualization for summary.
+    if isinstance(aggregated_logs, dict) and 'image' in aggregated_logs:
+      validation_outputs = visualization_utils.visualize_outputs(
+          logs=aggregated_logs, task_config=self.task_config
+      )
+      logs.update(validation_outputs)
+
     return logs
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/tasks/semantic_segmentation.py` & `tf-models-no-deps-2.16.0/official/projects/yt8m/tasks/yt8m_task.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,334 +1,436 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""Image segmentation task definition."""
-from typing import Any, Optional, List, Tuple, Mapping, Union
+"""Video classification task definition."""
+from typing import Dict, List, Optional, Tuple
 
 from absl import logging
-import tensorflow as tf
-from official.common import dataset_fn
+import tensorflow as tf, tf_keras
+
 from official.core import base_task
 from official.core import task_factory
-from official.vision.configs import semantic_segmentation as exp_cfg
-from official.vision.dataloaders import input_reader_factory
-from official.vision.dataloaders import segmentation_input
-from official.vision.dataloaders import tfds_factory
-from official.vision.evaluation import segmentation_metrics
-from official.vision.losses import segmentation_losses
-from official.vision.modeling import factory
+from official.modeling import tf_utils
+from official.projects.yt8m.configs import yt8m as yt8m_cfg
+from official.projects.yt8m.dataloaders import yt8m_input
+from official.projects.yt8m.eval_utils import eval_util
+from official.projects.yt8m.modeling import yt8m_model
+from official.core import input_reader
 
 
-@task_factory.register_task_cls(exp_cfg.SemanticSegmentationTask)
-class SemanticSegmentationTask(base_task.Task):
-  """A task for semantic segmentation."""
+@task_factory.register_task_cls(yt8m_cfg.YT8MTask)
+class YT8MTask(base_task.Task):
+  """A task for video classification."""
 
   def build_model(self):
-    """Builds segmentation model."""
-    input_specs = tf.keras.layers.InputSpec(shape=[None] +
-                                            self.task_config.model.input_size)
+    """Builds model for YT8M Task."""
+    train_cfg = self.task_config.train_data
+    common_input_shape = [None, sum(train_cfg.feature_sizes)]
+
+    # [batch_size x num_frames x num_features]
+    input_specs = tf_keras.layers.InputSpec(shape=[None] + common_input_shape)
+    logging.info('Build model input %r', common_input_shape)
 
     l2_weight_decay = self.task_config.losses.l2_weight_decay
-    # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
-    # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
-    # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (
-        tf.keras.regularizers.l2(l2_weight_decay /
-                                 2.0) if l2_weight_decay else None)
-
-    model = factory.build_segmentation_model(
+    # Model configuration.
+    model_config = self.task_config.model
+    model = yt8m_model.VideoClassificationModel(
+        params=model_config,
         input_specs=input_specs,
-        model_config=self.task_config.model,
-        l2_regularizer=l2_regularizer)
+        num_classes=train_cfg.num_classes,
+        l2_weight_decay=l2_weight_decay,
+    )
+
+    # Warmup calls to build model variables.
+    _ = model(
+        inputs=tf_keras.Input(common_input_shape, dtype=tf.float32),
+        num_frames=tf_keras.Input([], dtype=tf.float32),
+    )
+
+    non_trainable_batch_norm_variables = []
+    non_trainable_extra_variables = []
+    for var in model.non_trainable_variables:
+      if 'moving_mean' in var.name or 'moving_variance' in var.name:
+        non_trainable_batch_norm_variables.append(var)
+      else:
+        non_trainable_extra_variables.append(var)
+
+    logging.info(
+        'Trainable model variables:\n%s',
+        '\n'.join(
+            [f'{var.name}\t{var.shape}' for var in model.trainable_variables]
+        ),
+    )
+    logging.info(
+        (
+            'Non-trainable batch norm variables (get updated in training'
+            ' mode):\n%s'
+        ),
+        '\n'.join(
+            [
+                f'{var.name}\t{var.shape}'
+                for var in non_trainable_batch_norm_variables
+            ]
+        ),
+    )
+    logging.info(
+        'Non-trainable frozen model variables:\n%s',
+        '\n'.join(
+            [
+                f'{var.name}\t{var.shape}'
+                for var in non_trainable_extra_variables
+            ]
+        ),
+    )
     return model
 
-  def initialize(self, model: tf.keras.Model):
-    """Loads pretrained checkpoint."""
-    if not self.task_config.init_checkpoint:
-      return
-
-    ckpt_dir_or_file = self.task_config.init_checkpoint
-    if tf.io.gfile.isdir(ckpt_dir_or_file):
-      ckpt_dir_or_file = tf.train.latest_checkpoint(ckpt_dir_or_file)
-
-    # Restoring checkpoint.
-    if 'all' in self.task_config.init_checkpoint_modules:
-      ckpt = tf.train.Checkpoint(**model.checkpoint_items)
-      status = ckpt.read(ckpt_dir_or_file)
-      status.expect_partial().assert_existing_objects_matched()
-    else:
-      ckpt_items = {}
-      if 'backbone' in self.task_config.init_checkpoint_modules:
-        ckpt_items.update(backbone=model.backbone)
-      if 'decoder' in self.task_config.init_checkpoint_modules:
-        ckpt_items.update(decoder=model.decoder)
-
-      ckpt = tf.train.Checkpoint(**ckpt_items)
-      status = ckpt.read(ckpt_dir_or_file)
-      status.expect_partial().assert_existing_objects_matched()
-
-    logging.info('Finished loading pretrained checkpoint from %s',
-                 ckpt_dir_or_file)
-
-  def build_inputs(self,
-                   params: exp_cfg.DataConfig,
-                   input_context: Optional[tf.distribute.InputContext] = None):
-    """Builds classification input."""
+  def build_inputs(self, params: yt8m_cfg.DataConfig, input_context=None):
+    """Builds input.
 
-    ignore_label = self.task_config.losses.ignore_label
-    gt_is_matting_map = self.task_config.losses.gt_is_matting_map
+    Args:
+      params: configuration for input data
+      input_context: indicates information about the compute replicas and input
+        pipelines
 
-    if params.tfds_name:
-      decoder = tfds_factory.get_segmentation_decoder(params.tfds_name)
-    else:
-      decoder = segmentation_input.Decoder()
+    Returns:
+      dataset: dataset fetched from reader
+    """
 
-    parser = segmentation_input.Parser(
-        output_size=params.output_size,
-        crop_size=params.crop_size,
-        ignore_label=ignore_label,
-        resize_eval_groundtruth=params.resize_eval_groundtruth,
-        gt_is_matting_map=gt_is_matting_map,
-        groundtruth_padded_size=params.groundtruth_padded_size,
-        aug_scale_min=params.aug_scale_min,
-        aug_scale_max=params.aug_scale_max,
-        aug_rand_hflip=params.aug_rand_hflip,
-        preserve_aspect_ratio=params.preserve_aspect_ratio,
-        dtype=params.dtype)
+    decoder = yt8m_input.Decoder(input_params=params)
+    decoder_fn = decoder.decode
+    parser = yt8m_input.Parser(input_params=params)
+    parser_fn = parser.parse_fn(params.is_training)
+    postprocess = yt8m_input.PostBatchProcessor(input_params=params)
+    postprocess_fn = postprocess.post_fn
+    transform_batch = yt8m_input.TransformBatcher(input_params=params)
+    batch_fn = transform_batch.batch_fn
 
-    reader = input_reader_factory.input_reader_generator(
+    reader = input_reader.InputReader(
         params,
-        dataset_fn=dataset_fn.pick_dataset_fn(params.file_type),
-        decoder_fn=decoder.decode,
-        parser_fn=parser.parse_fn(params.is_training))
+        dataset_fn=tf.data.TFRecordDataset,
+        decoder_fn=decoder_fn,
+        parser_fn=parser_fn,
+        postprocess_fn=postprocess_fn,
+        transform_and_batch_fn=batch_fn,
+    )
 
     dataset = reader.read(input_context=input_context)
 
     return dataset
 
-  def build_losses(self,
-                   labels: Mapping[str, tf.Tensor],
-                   model_outputs: Union[Mapping[str, tf.Tensor], tf.Tensor],
-                   aux_losses: Optional[Any] = None):
-    """Segmentation loss.
+  def build_losses(
+      self, labels, model_outputs, label_weights=None, aux_losses=None
+  ):
+    """Sigmoid Cross Entropy.
 
     Args:
-      labels: labels.
-      model_outputs: Output logits of the classifier.
-      aux_losses: auxiliarly loss tensors, i.e. `losses` in keras.Model.
+      labels: tensor containing truth labels.
+      model_outputs: output probabilities of the classifier.
+      label_weights: optional tensor of label weights.
+      aux_losses: tensor containing auxiliarly loss tensors, i.e. `losses` in
+        keras.Model.
 
     Returns:
-      The total loss tensor.
+      A dict of tensors contains total loss, model loss tensors.
     """
-    loss_params = self._task_config.losses
-    segmentation_loss_fn = segmentation_losses.SegmentationLoss(
-        loss_params.label_smoothing,
-        loss_params.class_weights,
-        loss_params.ignore_label,
-        use_groundtruth_dimension=loss_params.use_groundtruth_dimension,
-        top_k_percent_pixels=loss_params.top_k_percent_pixels,
-        gt_is_matting_map=loss_params.gt_is_matting_map)
-
-    total_loss = segmentation_loss_fn(model_outputs['logits'], labels['masks'])
-
-    if 'mask_scores' in model_outputs:
-      mask_scoring_loss_fn = segmentation_losses.MaskScoringLoss(
-          loss_params.ignore_label)
-      total_loss += mask_scoring_loss_fn(model_outputs['mask_scores'],
-                                         model_outputs['logits'],
-                                         labels['masks'])
+    losses_config = self.task_config.losses
+    model_loss = tf_keras.losses.binary_crossentropy(
+        tf.expand_dims(labels, axis=-1),
+        tf.expand_dims(model_outputs, axis=-1),
+        from_logits=losses_config.from_logits,
+        label_smoothing=losses_config.label_smoothing,
+        axis=-1,
+    )
+    if label_weights is None:
+      model_loss = tf_utils.safe_mean(model_loss)
+    else:
+      model_loss = model_loss * label_weights
+      # Manutally compute weighted mean loss.
+      total_loss = tf.reduce_sum(model_loss)
+      total_weight = tf.cast(
+          tf.reduce_sum(label_weights), dtype=total_loss.dtype
+      )
+      model_loss = tf.math.divide_no_nan(total_loss, total_weight)
 
+    total_loss = model_loss
     if aux_losses:
       total_loss += tf.add_n(aux_losses)
 
-    total_loss = loss_params.loss_weight * total_loss
+    return {'total_loss': total_loss, 'model_loss': model_loss}
+
+  def build_metrics(self, training=True):
+    """Gets streaming metrics for training/validation.
+
+       metric: mAP/gAP
+       top_k: A positive integer specifying how many predictions are considered
+        per video.
+       top_n: A positive Integer specifying the average precision at n, or None
+        to use all provided data points.
+    Args:
+      training: Bool value, true for training mode, false for eval/validation.
 
-    return total_loss
+    Returns:
+      A list of metrics to be used.
+    """
+    metrics = []
+    metric_names = ['total_loss', 'model_loss']
+    for name in metric_names:
+      metrics.append(tf_keras.metrics.Mean(name, dtype=tf.float32))
+
+    if (
+        self.task_config.evaluation.average_precision is not None
+        and not training
+    ):
+      # Cannot run in train step.
+      num_classes = self.task_config.validation_data.num_classes
+      top_k = self.task_config.evaluation.average_precision.top_k
+      top_n = self.task_config.evaluation.average_precision.top_n
+      self.avg_prec_metric = eval_util.EvaluationMetrics(
+          num_classes, top_k=top_k, top_n=top_n
+      )
 
-  def process_metrics(self, metrics, labels, model_outputs, **kwargs):
-    """Process and update metrics.
+    return metrics
 
-    Called when using custom training loop API.
+  def process_metrics(
+      self,
+      metrics: List[tf_keras.metrics.Metric],
+      labels: tf.Tensor,
+      outputs: tf.Tensor,
+      model_losses: Optional[Dict[str, tf.Tensor]] = None,
+      label_weights: Optional[tf.Tensor] = None,
+      training: bool = True,
+      **kwargs,
+  ) -> Dict[str, Tuple[tf.Tensor, ...]]:
+    """Updates metrics.
 
     Args:
-      metrics: a nested structure of metrics objects. The return of function
-        self.build_metrics.
-      labels: a tensor or a nested structure of tensors.
-      model_outputs: a tensor or a nested structure of tensors. For example,
-        output of the keras model built by self.build_model.
-      **kwargs: other args.
-    """
-    for metric in metrics:
-      if 'mask_scores_mse' == metric.name:
-        actual_mask_scores = segmentation_losses.get_actual_mask_scores(
-            model_outputs['logits'], labels['masks'],
-            self.task_config.losses.ignore_label)
-        metric.update_state(actual_mask_scores, model_outputs['mask_scores'])
-      else:
-        metric.update_state(labels, model_outputs['logits'])
+      metrics: Evaluation metrics to be updated.
+      labels: A tensor containing truth labels.
+      outputs: Model output logits of the classifier.
+      model_losses: An optional dict of model losses.
+      label_weights: Optional label weights, can be broadcast into shape of
+        outputs/labels.
+      training: Bool indicates if in training mode.
+      **kwargs: Additional input arguments.
 
-  def build_metrics(self, training: bool = True):
-    """Gets streaming metrics for training/validation."""
-    metrics = []
-    self.iou_metric = None
+    Returns:
+      Updated dict of metrics log.
+    """
+    if model_losses is None:
+      model_losses = {}
 
-    if training and self.task_config.evaluation.report_train_mean_iou:
-      metrics.append(
-          segmentation_metrics.MeanIoU(
-              name='mean_iou',
-              num_classes=self.task_config.model.num_classes,
-              rescale_predictions=False,
-              dtype=tf.float32))
-      if self.task_config.model.get('mask_scoring_head'):
-        metrics.append(
-            tf.keras.metrics.MeanSquaredError(name='mask_scores_mse'))
-
-    if not training:
-      self.iou_metric = segmentation_metrics.PerClassIoU(
-          name='per_class_iou',
-          num_classes=self.task_config.model.num_classes,
-          rescale_predictions=(
-              not self.task_config.validation_data.resize_eval_groundtruth),
-          dtype=tf.float32)
-      if (self.task_config.validation_data.resize_eval_groundtruth and
-          self.task_config.model.get('mask_scoring_head')):
-        # Masks scores metric can only be computed if labels are scaled to match
-        # preticted mask scores.
-        metrics.append(
-            tf.keras.metrics.MeanSquaredError(name='mask_scores_mse'))
+    logs = {}
+    if (
+        self.task_config.evaluation.average_precision is not None
+        and not training
+    ):
+      logs.update({self.avg_prec_metric.name: (labels, outputs)})
+
+    for m in metrics:
+      if m.name in model_losses:
+        m.update_state(model_losses[m.name])
+        logs[m.name] = m.result()
+    return logs
 
-    return metrics
+  def _preprocess_model_inputs(
+      self,
+      inputs: dict[str, tf.Tensor],
+      require_num_frames: bool = True,
+      training: bool = True,
+  ):
+    """Preprocesses input tensors before model on device."""
+    extra_inputs = {
+        'num_frames': (
+            tf.reshape(inputs['num_frames'], [-1])
+            if require_num_frames
+            else None
+        ),
+        'training': training,
+    }
+    return inputs['video_matrix'], extra_inputs
+
+  def _preprocess_labels(
+      self, inputs: dict[str, tf.Tensor], training: bool = True
+  ):
+    """Preprocesses labels."""
+    del training  # training is unused in _preprocess_labels in YT8M.
+    labels = inputs['labels']
+    label_weights = inputs.get('label_weights', None)
+
+    return labels, label_weights
+
+  def _postprocess_outputs(
+      self, outputs, labels, label_weights, training: bool = True
+  ):
+    """Postprocess model outputs (inputs / labels / label_weights)."""
+    if not training and self.task_config.validation_data.segment_labels:
+      # workaround to ignore the unrated labels.
+      outputs *= label_weights
+      # remove padding
+      outputs = outputs[~tf.reduce_all(labels == -1, axis=1)]
+      labels = labels[~tf.reduce_all(labels == -1, axis=1)]
+    return outputs, labels, label_weights
 
-  def train_step(self,
-                 inputs: Tuple[Any, Any],
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
-                 metrics: Optional[List[Any]] = None):
+  def train_step(self, inputs, model, optimizer, metrics=None):
     """Does forward and backward.
 
     Args:
-      inputs: a dictionary of input tensors.
+      inputs: a dictionary of input tensors. output_dict = { "video_ids":
+        batch_video_ids, "video_matrix": batch_video_matrix, "labels":
+        batch_labels, "num_frames": batch_frames, }
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
       metrics: a nested structure of metrics objects.
 
     Returns:
-      A dictionary of logs.
+      a dictionary of logs.
     """
-    features, labels = inputs
-
-    input_partition_dims = self.task_config.train_input_partition_dims
-    if input_partition_dims:
-      strategy = tf.distribute.get_strategy()
-      features = strategy.experimental_split_to_logical_devices(
-          features, input_partition_dims)
+    # Will require `num_frames` if `num_sample_frames` is None since
+    # video_matrix is padded to max_frames in this case.
+    require_num_frames = self.task_config.train_data.num_sample_frames is None
+    inputs_tensor, extra_inputs = self._preprocess_model_inputs(
+        inputs,
+        require_num_frames=require_num_frames,
+        training=True,
+    )
+    labels, label_weights = self._preprocess_labels(inputs, training=True)
 
     num_replicas = tf.distribute.get_strategy().num_replicas_in_sync
     with tf.GradientTape() as tape:
-      outputs = model(features, training=True)
-      if isinstance(outputs, tf.Tensor):
-        outputs = {'logits': outputs}
+      outputs = model(inputs_tensor, **extra_inputs)['predictions']
       # Casting output layer as float32 is necessary when mixed_precision is
       # mixed_float16 or mixed_bfloat16 to ensure output is casted as float32.
       outputs = tf.nest.map_structure(lambda x: tf.cast(x, tf.float32), outputs)
+      # Post-process model / label outputs.
+      outputs, labels, label_weights = self._postprocess_outputs(
+          outputs, labels, label_weights, training=True
+      )
+
+      # Computes per-replica loss
+      all_losses = self.build_losses(
+          model_outputs=outputs,
+          labels=labels,
+          label_weights=label_weights,
+          aux_losses=model.losses,
+      )
 
-      # Computes per-replica loss.
-      loss = self.build_losses(
-          model_outputs=outputs, labels=labels, aux_losses=model.losses)
+      loss = all_losses['total_loss']
       # Scales loss as the default gradients allreduce performs sum inside the
       # optimizer.
       scaled_loss = loss / num_replicas
 
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
-      if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+      if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     # Scales back gradient before apply_gradients when LossScaleOptimizer is
     # used.
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
+
+    # Apply gradient clipping.
+    if self.task_config.gradient_clip_norm > 0:
+      grads, _ = tf.clip_by_global_norm(
+          grads, self.task_config.gradient_clip_norm
+      )
     optimizer.apply_gradients(list(zip(grads, tvars)))
 
     logs = {self.loss: loss}
-    if metrics:
-      self.process_metrics(metrics, labels, outputs)
-      logs.update({m.name: m.result() for m in metrics})
-
+    logs.update(
+        self.process_metrics(
+            metrics,
+            labels=labels,
+            outputs=outputs,
+            model_losses=all_losses,
+            label_weights=label_weights,
+            training=True,
+        )
+    )
     return logs
 
-  def validation_step(self,
-                      inputs: Tuple[Any, Any],
-                      model: tf.keras.Model,
-                      metrics: Optional[List[Any]] = None):
+  def validation_step(self, inputs, model, metrics=None):
     """Validatation step.
 
     Args:
-      inputs: a dictionary of input tensors.
-      model: the keras.Model.
+      inputs: a dictionary of input tensors. output_dict = { "video_ids":
+        batch_video_ids, "video_matrix": batch_video_matrix, "labels":
+        batch_labels, "num_frames": batch_frames}.
+      model: the model, forward definition.
       metrics: a nested structure of metrics objects.
 
     Returns:
-      A dictionary of logs.
+      a dictionary of logs.
     """
-    features, labels = inputs
-
-    input_partition_dims = self.task_config.eval_input_partition_dims
-    if input_partition_dims:
-      strategy = tf.distribute.get_strategy()
-      features = strategy.experimental_split_to_logical_devices(
-          features, input_partition_dims)
-
-    outputs = self.inference_step(features, model)
-    if isinstance(outputs, tf.Tensor):
-      outputs = {'logits': outputs}
+    # Will require `num_frames` if `num_sample_frames` is None since
+    # video_matrix is padded to max_frames in this case.
+    require_num_frames = (
+        self.task_config.validation_data.num_sample_frames is None
+    )
+    outputs = self.inference_step(
+        model, inputs, require_num_frames=require_num_frames
+    )['predictions']
     outputs = tf.nest.map_structure(lambda x: tf.cast(x, tf.float32), outputs)
-
-    if self.task_config.validation_data.resize_eval_groundtruth:
-      loss = self.build_losses(
-          model_outputs=outputs, labels=labels, aux_losses=model.losses)
-    else:
-      loss = 0
-
-    logs = {self.loss: loss}
-
-    if self.iou_metric is not None:
-      self.iou_metric.update_state(labels, outputs['logits'])
-    if metrics:
-      self.process_metrics(metrics, labels, outputs)
+    labels, label_weights = self._preprocess_labels(inputs, training=False)
+    outputs, labels, label_weights = self._postprocess_outputs(
+        outputs, labels, label_weights, training=False
+    )
+
+    all_losses = self.build_losses(
+        labels=labels,
+        model_outputs=outputs,
+        label_weights=label_weights,
+        aux_losses=model.losses,
+    )
+
+    logs = {self.loss: all_losses['total_loss']}
+    logs.update(
+        self.process_metrics(
+            metrics,
+            labels=labels,
+            outputs=outputs,
+            model_losses=all_losses,
+            label_weights=inputs.get('label_weights', None),
+            training=False,
+        )
+    )
 
     return logs
 
-  def inference_step(self, inputs: tf.Tensor, model: tf.keras.Model):
+  def inference_step(self, model, inputs, require_num_frames=True):
     """Performs the forward step."""
-    return model(inputs, training=False)
-
-  def aggregate_logs(self, state=None, step_outputs=None):
-    if state is None and self.iou_metric is not None:
-      self.iou_metric.reset_states()
-      state = self.iou_metric
+    model_inputs, extra_inputs = self._preprocess_model_inputs(
+        inputs, require_num_frames=require_num_frames, training=False
+    )
+    return model(model_inputs, **extra_inputs)
+
+  def aggregate_logs(self, state=None, step_logs=None):
+    if self.task_config.evaluation.average_precision is not None:
+      if state is None:
+        state = self.avg_prec_metric
+      self.avg_prec_metric.accumulate(
+          labels=step_logs[self.avg_prec_metric.name][0],
+          predictions=step_logs[self.avg_prec_metric.name][1],
+      )
     return state
 
   def reduce_aggregated_logs(self, aggregated_logs, global_step=None):
-    result = {}
-    if self.iou_metric is not None:
-      ious = self.iou_metric.result()
-      # TODO(arashwan): support loading class name from a label map file.
-      if self.task_config.evaluation.report_per_class_iou:
-        for i, value in enumerate(ious.numpy()):
-          result.update({'iou/{}'.format(i): value})
-      # Computes mean IoU
-      result.update({'mean_iou': tf.reduce_mean(ious)})
-    return result
+    if self.task_config.evaluation.average_precision is not None:
+      avg_prec_metrics = self.avg_prec_metric.get(
+          self.task_config.evaluation.average_precision.return_per_class_ap
+      )
+      self.avg_prec_metric.clear()
+      return avg_prec_metrics
+    return None
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/tasks/video_classification.py` & `tf-models-no-deps-2.16.0/official/vision/tasks/video_classification.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Video classification task definition."""
 from typing import Any, Optional, List, Tuple
 
 from absl import logging
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.core import base_task
 from official.core import task_factory
 from official.modeling import tf_utils
 from official.vision.configs import video_classification as exp_cfg
 from official.vision.dataloaders import input_reader_factory
 from official.vision.dataloaders import video_input
 from official.vision.modeling import factory_3d
@@ -53,37 +53,37 @@
   def _is_multilabel(self):
     """If the label is multi-labels."""
     return self.task_config.train_data.is_multilabel
 
   def build_model(self):
     """Builds video classification model."""
     common_input_shape = self._get_feature_shape()
-    input_specs = tf.keras.layers.InputSpec(shape=[None] + common_input_shape)
+    input_specs = tf_keras.layers.InputSpec(shape=[None] + common_input_shape)
     logging.info('Build model input %r', common_input_shape)
 
     l2_weight_decay = float(self.task_config.losses.l2_weight_decay)
     # Divide weight decay by 2.0 to match the implementation of tf.nn.l2_loss.
     # (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2)
     # (https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss)
-    l2_regularizer = (tf.keras.regularizers.l2(
+    l2_regularizer = (tf_keras.regularizers.l2(
         l2_weight_decay / 2.0) if l2_weight_decay else None)
 
     model = factory_3d.build_model(
         self.task_config.model.model_type,
         input_specs=input_specs,
         model_config=self.task_config.model,
         num_classes=self._get_num_classes(),
         l2_regularizer=l2_regularizer)
 
     if self.task_config.freeze_backbone:
       logging.info('Freezing model backbone.')
       model.backbone.trainable = False
     return model
 
-  def initialize(self, model: tf.keras.Model):
+  def initialize(self, model: tf_keras.Model):
     """Loads pretrained checkpoint."""
     if not self.task_config.init_checkpoint:
       return
 
     ckpt_dir_or_file = self.task_config.init_checkpoint
     if tf.io.gfile.isdir(ckpt_dir_or_file):
       ckpt_dir_or_file = tf.train.latest_checkpoint(ckpt_dir_or_file)
@@ -172,29 +172,29 @@
     """
     all_losses = {}
     losses_config = self.task_config.losses
     total_loss = None
     if self._is_multilabel():
       entropy = -tf.reduce_mean(
           tf.reduce_sum(model_outputs * tf.math.log(model_outputs + 1e-8), -1))
-      total_loss = tf.keras.losses.binary_crossentropy(
+      total_loss = tf_keras.losses.binary_crossentropy(
           labels, model_outputs, from_logits=False)
       all_losses.update({
           'class_loss': total_loss,
           'entropy': entropy,
       })
     else:
       if losses_config.one_hot:
-        total_loss = tf.keras.losses.categorical_crossentropy(
+        total_loss = tf_keras.losses.categorical_crossentropy(
             labels,
             model_outputs,
             from_logits=False,
             label_smoothing=losses_config.label_smoothing)
       else:
-        total_loss = tf.keras.losses.sparse_categorical_crossentropy(
+        total_loss = tf_keras.losses.sparse_categorical_crossentropy(
             labels, model_outputs, from_logits=False)
 
       total_loss = tf_utils.safe_mean(total_loss)
       all_losses.update({
           'class_loss': total_loss,
       })
     if aux_losses:
@@ -206,38 +206,38 @@
 
     return all_losses
 
   def build_metrics(self, training: bool = True):
     """Gets streaming metrics for training/validation."""
     if self.task_config.losses.one_hot:
       metrics = [
-          tf.keras.metrics.CategoricalAccuracy(name='accuracy'),
-          tf.keras.metrics.TopKCategoricalAccuracy(k=1, name='top_1_accuracy'),
-          tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')
+          tf_keras.metrics.CategoricalAccuracy(name='accuracy'),
+          tf_keras.metrics.TopKCategoricalAccuracy(k=1, name='top_1_accuracy'),
+          tf_keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')
       ]
       if self._is_multilabel():
         metrics.append(
-            tf.keras.metrics.AUC(
+            tf_keras.metrics.AUC(
                 curve='ROC', multi_label=self._is_multilabel(), name='ROC-AUC'))
         metrics.append(
-            tf.keras.metrics.RecallAtPrecision(
+            tf_keras.metrics.RecallAtPrecision(
                 0.95, name='RecallAtPrecision95'))
         metrics.append(
-            tf.keras.metrics.AUC(
+            tf_keras.metrics.AUC(
                 curve='PR', multi_label=self._is_multilabel(), name='PR-AUC'))
         if self.task_config.metrics.use_per_class_recall:
           for i in range(self._get_num_classes()):
             metrics.append(
-                tf.keras.metrics.Recall(class_id=i, name=f'recall-{i}'))
+                tf_keras.metrics.Recall(class_id=i, name=f'recall-{i}'))
     else:
       metrics = [
-          tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
-          tf.keras.metrics.SparseTopKCategoricalAccuracy(
+          tf_keras.metrics.SparseCategoricalAccuracy(name='accuracy'),
+          tf_keras.metrics.SparseTopKCategoricalAccuracy(
               k=1, name='top_1_accuracy'),
-          tf.keras.metrics.SparseTopKCategoricalAccuracy(
+          tf_keras.metrics.SparseTopKCategoricalAccuracy(
               k=5, name='top_5_accuracy')
       ]
     return metrics
 
   def process_metrics(self, metrics: List[Any], labels: Any,
                       model_outputs: Any):
     """Process and update metrics.
@@ -252,16 +252,16 @@
         output of the keras model built by self.build_model.
     """
     for metric in metrics:
       metric.update_state(labels, model_outputs)
 
   def train_step(self,
                  inputs: Tuple[Any, Any],
-                 model: tf.keras.Model,
-                 optimizer: tf.keras.optimizers.Optimizer,
+                 model: tf_keras.Model,
+                 optimizer: tf_keras.optimizers.Optimizer,
                  metrics: Optional[List[Any]] = None):
     """Does forward and backward.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the model, forward pass definition.
       optimizer: the optimizer for this training step.
@@ -296,37 +296,37 @@
       # Scales loss as the default gradients allreduce performs sum inside the
       # optimizer.
       scaled_loss = loss / num_replicas
 
       # For mixed_precision policy, when LossScaleOptimizer is used, loss is
       # scaled for numerical stability.
       if isinstance(
-          optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+          optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
         scaled_loss = optimizer.get_scaled_loss(scaled_loss)
 
     tvars = model.trainable_variables
     grads = tape.gradient(scaled_loss, tvars)
     # Scales back gradient before apply_gradients when LossScaleOptimizer is
     # used.
-    if isinstance(optimizer, tf.keras.mixed_precision.LossScaleOptimizer):
+    if isinstance(optimizer, tf_keras.mixed_precision.LossScaleOptimizer):
       grads = optimizer.get_unscaled_gradients(grads)
     optimizer.apply_gradients(list(zip(grads, tvars)))
 
     logs = all_losses
     if metrics:
       self.process_metrics(metrics, labels, outputs)
       logs.update({m.name: m.result() for m in metrics})
     elif model.compiled_metrics:
       self.process_compiled_metrics(model.compiled_metrics, labels, outputs)
       logs.update({m.name: m.result() for m in model.metrics})
     return logs
 
   def validation_step(self,
                       inputs: Tuple[Any, Any],
-                      model: tf.keras.Model,
+                      model: tf_keras.Model,
                       metrics: Optional[List[Any]] = None):
     """Validatation step.
 
     Args:
       inputs: a dictionary of input tensors.
       model: the keras.Model.
       metrics: a nested structure of metrics objects.
@@ -350,15 +350,15 @@
       self.process_metrics(metrics, labels, outputs)
       logs.update({m.name: m.result() for m in metrics})
     elif model.compiled_metrics:
       self.process_compiled_metrics(model.compiled_metrics, labels, outputs)
       logs.update({m.name: m.result() for m in model.metrics})
     return logs
 
-  def inference_step(self, features: tf.Tensor, model: tf.keras.Model):
+  def inference_step(self, features: tf.Tensor, model: tf_keras.Model):
     """Performs the forward step."""
     outputs = model(features, training=False)
     if self._is_multilabel():
       outputs = tf.nest.map_structure(tf.math.sigmoid, outputs)
     else:
       outputs = tf.nest.map_structure(tf.math.softmax, outputs)
     num_test_views = self._get_num_test_views()
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/train.py` & `tf-models-no-deps-2.16.0/official/projects/video_ssl/train.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,49 +1,58 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-"""TensorFlow Model Garden Vision training driver."""
+"""Training driver."""
 
 from absl import app
 from absl import flags
 import gin
 
+# pylint: disable=unused-import
 from official.common import distribute_utils
 from official.common import flags as tfm_flags
 from official.core import task_factory
 from official.core import train_lib
 from official.core import train_utils
 from official.modeling import performance
-# pylint: disable=unused-import
+from official.projects.video_ssl.modeling import video_ssl_model
+from official.projects.video_ssl.tasks import linear_eval
+from official.projects.video_ssl.tasks import pretrain
 from official.vision import registry_imports
-# pylint: enable=unused-import
+# pylint: disable=unused-import
 
 FLAGS = flags.FLAGS
 
 
 def main(_):
   gin.parse_config_files_and_bindings(FLAGS.gin_file, FLAGS.gin_params)
   params = train_utils.parse_configuration(FLAGS)
   model_dir = FLAGS.model_dir
   if 'train' in FLAGS.mode:
     # Pure eval modes do not output yaml files. Otherwise continuous eval job
     # may race against the train job for writing the same file.
     train_utils.serialize_config(params, model_dir)
 
+  if 'train_and_eval' in FLAGS.mode:
+    assert (params.task.train_data.feature_shape ==
+            params.task.validation_data.feature_shape), (
+                f'train {params.task.train_data.feature_shape} != validate '
+                f'{params.task.validation_data.feature_shape}')
+
   # Sets mixed_precision policy. Using 'mixed_float16' or 'mixed_bfloat16'
   # can have significant impact on model speeds by utilizing float16 in case of
   # GPUs, and bfloat16 in the case of TPUs. loss_scale takes effect only when
   # dtype is float16
   if params.runtime.mixed_precision_dtype:
     performance.set_mixed_precision_policy(params.runtime.mixed_precision_dtype)
   distribution_strategy = distribute_utils.get_distribution_strategy(
@@ -61,9 +70,8 @@
       params=params,
       model_dir=model_dir)
 
   train_utils.save_gin_config(FLAGS.mode, model_dir)
 
 if __name__ == '__main__':
   tfm_flags.define_flags()
-  flags.mark_flags_as_required(['experiment', 'mode', 'model_dir'])
   app.run(main)
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/train_spatial_partitioning.py` & `tf-models-no-deps-2.16.0/official/vision/train_spatial_partitioning.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """TensorFlow Model Garden Vision training driver with spatial partitioning."""
 from typing import Sequence
 
 from absl import app
 from absl import flags
 import gin
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.common import distribute_utils
 from official.common import flags as tfm_flags
 from official.core import task_factory
 from official.core import train_lib
 from official.core import train_utils
 from official.modeling import performance
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/configs/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/yolo/dataloaders/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,15 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/argmax_matcher.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/argmax_matcher.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,36 +22,36 @@
 resulting in neither a positive or negative training example).
 
 This matcher is used in Fast(er)-RCNN.
 
 Note: matchers are used in TargetAssigners. There is a create_target_assigner
 factory function for popular implementations.
 """
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.utils.object_detection import matcher
 from official.vision.utils.object_detection import shape_utils
 
 
 class ArgMaxMatcher(matcher.Matcher):
   """Matcher based on highest value.
 
   This class computes matches from a similarity matrix. Each column is matched
   to a single row.
 
   To support object detection target assignment this class enables setting both
-  matched_threshold (upper threshold) and unmatched_threshold (lower thresholds)
+  matched_threshold (upper threshold) and unmatched_threshold (lower threshold)
   defining three categories of similarity which define whether examples are
   positive, negative, or ignored:
   (1) similarity >= matched_threshold: Highest similarity. Matched/Positive!
   (2) matched_threshold > similarity >= unmatched_threshold: Medium similarity.
           Depending on negatives_lower_than_unmatched, this is either
           Unmatched/Negative OR Ignore.
   (3) unmatched_threshold > similarity: Lowest similarity. Depending on flag
-          negatives_lower_than_unmatched, either Unmatched/Negative OR Ignore.
+          negatives_lower_than_unmatched, either Unmatched/Negative or Ignore.
   For ignored matches this class sets the values in the Match object to -2.
   """
 
   def __init__(self,
                matched_threshold,
                unmatched_threshold=None,
                negatives_lower_than_unmatched=True,
@@ -63,15 +63,15 @@
         sim >= matched_threshold, where sim is the maximum value of the
         similarity matrix for a given column. Set to None for no threshold.
       unmatched_threshold: Threshold for negative matches. Negative if
         sim < unmatched_threshold. Defaults to matched_threshold
         when set to None.
       negatives_lower_than_unmatched: Boolean which defaults to True. If True
         then negative matches are the ones below the unmatched_threshold,
-        whereas ignored matches are in between the matched and umatched
+        whereas ignored matches are in between the matched and unmatched
         threshold. If False, then negative matches are in between the matched
         and unmatched threshold, and everything lower than unmatched is ignored.
       force_match_for_each_row: If True, ensures that each row is matched to
         at least one column (which is not guaranteed otherwise if the
         matched_threshold is high). Defaults to False. See
         argmax_matcher_test.testMatcherForceMatch() for an example.
 
@@ -120,23 +120,23 @@
         matches:  int32 tensor indicating the row each column matches to.
       """
       similarity_matrix_shape = shape_utils.combined_static_and_dynamic_shape(
           similarity_matrix)
       return -1 * tf.ones([similarity_matrix_shape[1]], dtype=tf.int32)
 
     def _match_when_rows_are_non_empty():
-      """Performs matching when the rows of similarity matrix are non empty.
+      """Performs matching when the rows of similarity matrix are non-empty.
 
       Returns:
         matches:  int32 tensor indicating the row each column matches to.
       """
-      # Matches for each column
+      # Matches for each column.
       matches = tf.argmax(input=similarity_matrix, axis=0, output_type=tf.int32)
 
-      # Deal with matched and unmatched threshold
+      # Deal with matched and unmatched threshold.
       if self._matched_threshold is not None:
         # Get logical indices of ignored and unmatched columns as tf.int64
         matched_vals = tf.reduce_max(input_tensor=similarity_matrix, axis=0)
         below_unmatched_threshold = tf.greater(self._unmatched_threshold,
                                                matched_vals)
         between_thresholds = tf.logical_and(
             tf.greater_equal(matched_vals, self._unmatched_threshold),
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/balanced_positive_negative_sampler.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/balanced_positive_negative_sampler.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -27,15 +27,15 @@
 When is_static is True, it implements a method that guarantees static shapes.
 It also ensures the length of output of the subsample is always batch_size, even
 when number of examples set to True in indicator is less than batch_size.
 
 This is originally implemented in TensorFlow Object Detection API.
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.utils.object_detection import minibatch_sampler
 from official.vision.utils.object_detection import ops
 
 
 class BalancedPositiveNegativeSampler(minibatch_sampler.MinibatchSampler):
   """Subsamples minibatches to a desired balance of positives and negatives."""
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/box_coder.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/box_coder.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -25,15 +25,15 @@
 In both cases, the arguments are assumed to be in 1-1 correspondence already;
 it is not the job of a BoxCoder to perform matching.
 """
 from abc import ABCMeta
 from abc import abstractmethod
 from abc import abstractproperty
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 # Box coder types.
 FASTER_RCNN = 'faster_rcnn'
 KEYPOINT = 'keypoint'
 MEAN_STDDEV = 'mean_stddev'
 SQUARE = 'square'
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/box_list.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/box_list.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -29,15 +29,15 @@
 
 Some other notes:
   * Following tensorflow conventions, we use height, width ordering,
   and correspondingly, y,x (or ymin, xmin, ymax, xmax) ordering
   * Tensors are always provided as (flat) [N, 4] tensors.
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class BoxList(object):
   """Box collection."""
 
   def __init__(self, boxes):
     """Constructs box collection.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/box_list_ops.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/box_list_ops.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -23,15 +23,15 @@
 BoxList are retained unless documented otherwise.
 """
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 from six.moves import range
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.utils.object_detection import box_list
 from official.vision.utils.object_detection import ops
 
 
 class SortOrder(object):
   """Enum class for sort order.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/faster_rcnn_box_coder.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/faster_rcnn_box_coder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -23,15 +23,15 @@
   respectively. Similarly, xa, ya, wa, ha denote the anchor's center
   coordinates, width and height. tx, ty, tw and th denote the anchor-encoded
   center, width and height respectively.
 
   See http://arxiv.org/abs/1506.01497 for details.
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.utils.object_detection import box_coder
 from official.vision.utils.object_detection import box_list
 
 EPSILON = 1e-8
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/matcher.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/matcher.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -29,15 +29,15 @@
 
 The Match class is used to store the match results and it provides simple apis
 to query the results.
 """
 from abc import ABCMeta
 from abc import abstractmethod
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class Match(object):
   """Class to store results from the matcher.
 
   This class is used to store the results from the matcher. It provides
   convenient methods to query the matching results.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/minibatch_sampler.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/minibatch_sampler.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -28,15 +28,15 @@
 
 This is originally implemented in TensorFlow Object Detection API.
 """
 
 from abc import ABCMeta
 from abc import abstractmethod
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.utils.object_detection import ops
 
 
 class MinibatchSampler(object):
   """Abstract base class for subsampling minibatches."""
   __metaclass__ = ABCMeta
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/preprocessor.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/preprocessor.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -36,15 +36,15 @@
 functions receive a rank 3 tensor for processing the image. Thus, inside the
 preprocess function we squeeze the image to become a rank 3 tensor and then
 we pass it to the functions. At the end of the preprocess we expand the image
 back to rank 4.
 """
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 from official.vision.utils.object_detection import box_list
 
 
 def _flip_boxes_left_right(boxes):
   """Left-right flip the boxes.
 
   Args:
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/region_similarity_calculator.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/region_similarity_calculator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 Region Similarity Calculators compare a pairwise measure of similarity
 between the boxes in two BoxLists.
 """
 from abc import ABCMeta
 from abc import abstractmethod
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def area(boxlist, scope=None):
   """Computes area of boxes.
 
   Args:
     boxlist: BoxList holding N boxes
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/shape_utils.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/shape_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Utils used to manipulate tensor shapes."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def assert_shape_equal(shape_a, shape_b):
   """Asserts that shape_a and shape_b are equal.
 
   If the shapes are static, raises a ValueError when the shapes
   mismatch.
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/target_assigner.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/target_assigner.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -27,15 +27,15 @@
 4) Assigning classification targets based on the matching and groundtruth labels
 
 Note that TargetAssigners only operate on detections from a single
 image at a time, so any logic for applying a TargetAssigner to multiple
 images must be handled externally.
 """
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.utils.object_detection import box_list
 from official.vision.utils.object_detection import shape_utils
 
 KEYPOINTS_FIELD_NAME = 'keypoints'
```

### Comparing `tf-models-no-deps-2.11.2/official/vision/utils/object_detection/visualization_utils.py` & `tf-models-no-deps-2.16.0/official/vision/utils/object_detection/visualization_utils.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,33 +12,34 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """A set of functions that are used for visualization.
 
 These functions often receive an image, perform some visualization on the image.
 The functions do not return a value, instead they modify the image itself.
-
 """
 import collections
 import functools
+from typing import Any, Dict, Optional, List, Union
 
 from absl import logging
 # Set headless-friendly backend.
 import matplotlib
 matplotlib.use('Agg')  # pylint: disable=multiple-statements
 import matplotlib.pyplot as plt  # pylint: disable=g-import-not-at-top
 import numpy as np
-import PIL.Image as Image
-import PIL.ImageColor as ImageColor
-import PIL.ImageDraw as ImageDraw
-import PIL.ImageFont as ImageFont
+from PIL import Image
+from PIL import ImageColor
+from PIL import ImageDraw
+from PIL import ImageFont
 import six
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 from official.vision.ops import box_ops
+from official.vision.ops import preprocess_ops
 from official.vision.utils.object_detection import shape_utils
 
 _TITLE_LEFT_MARGIN = 10
 _TITLE_TOP_MARGIN = 10
 STANDARD_COLORS = [
     'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',
     'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',
@@ -201,33 +202,48 @@
     font = ImageFont.truetype('arial.ttf', 24)
   except IOError:
     font = ImageFont.load_default()
 
   # If the total height of the display strings added to the top of the bounding
   # box exceeds the top of the image, stack the strings below the bounding box
   # instead of above.
-  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]
+  if hasattr(font, 'getsize'):
+    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]
+  else:
+    display_str_heights = [font.getbbox(ds)[3] for ds in display_str_list]
   # Each display_str has a top and bottom margin of 0.05x.
   total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)
 
   if top > total_display_str_height:
     text_bottom = top
   else:
     text_bottom = bottom + total_display_str_height
   # Reverse list and print from bottom to top.
   for display_str in display_str_list[::-1]:
-    text_width, text_height = font.getsize(display_str)
-    margin = np.ceil(0.05 * text_height)
-    draw.rectangle([(left, text_bottom - text_height - 2 * margin),
-                    (left + text_width, text_bottom)],
-                   fill=color)
-    draw.text((left + margin, text_bottom - text_height - margin),
-              display_str,
-              fill='black',
-              font=font)
+    try:
+      if hasattr(font, 'getsize'):
+        text_width, text_height = font.getsize(display_str)
+      else:
+        text_width, text_height = font.getbbox(display_str)[2:4]
+      margin = np.ceil(0.05 * text_height)
+      draw.rectangle(
+          [
+              (left, text_bottom - text_height - 2 * margin),
+              (left + text_width, text_bottom),
+          ],
+          fill=color,
+      )
+      draw.text(
+          (left + margin, text_bottom - text_height - margin),
+          display_str,
+          fill='black',
+          font=font,
+      )
+    except ValueError:
+      pass
     text_bottom -= text_height - 2 * margin
 
 
 def draw_bounding_boxes_on_image_array(image,
                                        boxes,
                                        color='red',
                                        thickness=4,
@@ -332,14 +348,134 @@
 def _resize_original_image(image, image_shape):
   image = tf.expand_dims(image, 0)
   image = tf.image.resize(
       image, image_shape, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
   return tf.cast(tf.squeeze(image, 0), tf.uint8)
 
 
+def visualize_outputs(
+    logs,
+    task_config,
+    original_image_spatial_shape=None,
+    true_image_shape=None,
+    max_boxes_to_draw=20,
+    min_score_thresh=0.2,
+    use_normalized_coordinates=False,
+    image_mean: Optional[Union[float, List[float]]] = None,
+    image_std: Optional[Union[float, List[float]]] = None,
+    key: str = 'image/validation_outputs',
+) -> Dict[str, Any]:
+  """Visualizes the detection outputs.
+
+  It extracts images and predictions from logs and draws visualization on input
+  images. By default, it requires `detection_boxes`, `detection_classes` and
+  `detection_scores` in the prediction, and optionally accepts
+  `detection_keypoints` and `detection_masks`.
+
+  Args:
+    logs: A dictionaty of log that contains images and predictions.
+    task_config: A task config.
+    original_image_spatial_shape: A [N, 2] tensor containing the spatial size of
+      the original image.
+    true_image_shape: A [N, 3] tensor containing the spatial size of unpadded
+      original_image.
+    max_boxes_to_draw: The maximum number of boxes to draw on an image. Default
+      20.
+    min_score_thresh: The minimum score threshold for visualization. Default
+      0.2.
+    use_normalized_coordinates: Whether to assume boxes and kepoints are in
+      normalized coordinates (as opposed to absolute coordiantes). Default is
+      False.
+    image_mean: An optional float or list of floats used as the mean pixel value
+      to normalize images.
+    image_std: An optional float or list of floats used as the std to normalize
+      images.
+    key: A string specifying the key of the returned dictionary.
+
+  Returns:
+    A dictionary of images with visualization drawn on it. Each key corresponds
+      to a 4D tensor with predictions (boxes, segments and/or keypoints) drawn
+      on each image.
+  """
+  images = logs['image']
+  boxes = logs['detection_boxes']
+  classes = tf.cast(logs['detection_classes'], dtype=tf.int32)
+  scores = logs['detection_scores']
+  num_classes = task_config.model.num_classes
+
+  keypoints = (
+      logs['detection_keypoints'] if 'detection_keypoints' in logs else None
+  )
+  instance_masks = (
+      logs['detection_masks'] if 'detection_masks' in logs else None
+  )
+
+  category_index = {}
+  for i in range(1, num_classes + 1):
+    category_index[i] = {'id': i, 'name': str(i)}
+
+  def _denormalize_images(images: tf.Tensor) -> tf.Tensor:
+    if image_mean is None and image_std is None:
+      images *= tf.constant(
+          preprocess_ops.STDDEV_RGB, shape=[1, 1, 3], dtype=images.dtype
+      )
+      images += tf.constant(
+          preprocess_ops.MEAN_RGB, shape=[1, 1, 3], dtype=images.dtype
+      )
+    elif image_mean is not None and image_std is not None:
+      if isinstance(image_mean, float) and isinstance(image_std, float):
+        images = images * image_std + image_mean
+      elif isinstance(image_mean, list) and isinstance(image_std, list):
+        images *= tf.constant(image_std, shape=[1, 1, 3], dtype=images.dtype)
+        images += tf.constant(image_mean, shape=[1, 1, 3], dtype=images.dtype)
+      else:
+        raise ValueError(
+            '`image_mean` and `image_std` should be the same type.'
+        )
+    else:
+      raise ValueError(
+          'Both `image_mean` and `image_std` should be set or None at the same '
+          'time.'
+      )
+    return tf.cast(images, dtype=tf.uint8)
+
+  images = tf.nest.map_structure(
+      tf.identity,
+      tf.map_fn(
+          _denormalize_images,
+          elems=images,
+          fn_output_signature=tf.TensorSpec(
+              shape=images.shape.as_list()[1:], dtype=tf.uint8
+          ),
+          parallel_iterations=32,
+      ),
+  )
+
+  images_with_boxes = draw_bounding_boxes_on_image_tensors(
+      images,
+      boxes,
+      classes,
+      scores,
+      category_index,
+      original_image_spatial_shape,
+      true_image_shape,
+      instance_masks,
+      keypoints,
+      max_boxes_to_draw,
+      min_score_thresh,
+      use_normalized_coordinates,
+  )
+
+  outputs = {}
+  for i, image in enumerate(images_with_boxes):
+    outputs[key + f'/{i}'] = image[None, ...]
+
+  return outputs
+
+
 def draw_bounding_boxes_on_image_tensors(images,
                                          boxes,
                                          classes,
                                          scores,
                                          category_index,
                                          original_image_spatial_shape=None,
                                          true_image_shape=None,
@@ -718,7 +854,201 @@
     image = np.fromstring(
         fig.canvas.tostring_rgb(),
         dtype='uint8').reshape(1, int(height), int(width), 3)
     return image
 
   hist_plot = tf.compat.v1.py_func(hist_plot, [values, bins], tf.uint8)
   tf.compat.v1.summary.image(name, hist_plot)
+
+
+def update_detection_state(step_outputs=None) -> Dict[str, Any]:
+  """Updates detection state to optionally add input image and predictions."""
+  state = {}
+  if step_outputs:
+    state['image'] = tf.concat(step_outputs['visualization'][0], axis=0)
+    state['detection_boxes'] = tf.concat(
+        step_outputs['visualization'][1]['detection_boxes'], axis=0
+    )
+    state['detection_classes'] = tf.concat(
+        step_outputs['visualization'][1]['detection_classes'], axis=0
+    )
+    state['detection_scores'] = tf.concat(
+        step_outputs['visualization'][1]['detection_scores'], axis=0
+    )
+
+    if 'detection_kpts' in step_outputs['visualization'][1]:
+      detection_keypoints = step_outputs['visualization'][1]['detection_kpts']
+    elif 'detection_keypoints' in step_outputs['visualization'][1]:
+      detection_keypoints = step_outputs['visualization'][1][
+          'detection_keypoints'
+      ]
+    else:
+      detection_keypoints = None
+
+    if detection_keypoints is not None:
+      state['detection_keypoints'] = tf.concat(detection_keypoints, axis=0)
+
+    detection_masks = step_outputs['visualization'][1].get(
+        'detection_masks', None
+    )
+    if detection_masks:
+      state['detection_masks'] = tf.concat(detection_masks, axis=0)
+
+  return state
+
+
+def update_segmentation_state(step_outputs=None) -> Dict[str, Any]:
+  """Updates segmentation state to optionally add input image and predictions."""
+  state = {}
+  if step_outputs:
+    state['image'] = tf.concat(step_outputs['visualization'][0], axis=0)
+    state['logits'] = tf.concat(
+        step_outputs['visualization'][1]['logits'], axis=0
+    )
+  return state
+
+
+def visualize_segmentation_outputs(
+    logs,
+    task_config,
+    original_image_spatial_shape=None,
+    true_image_shape=None,
+    image_mean: Optional[Union[float, List[float]]] = None,
+    image_std: Optional[Union[float, List[float]]] = None,
+    key: str = 'image/validation_outputs',
+) -> Dict[str, Any]:
+  """Visualizes the detection outputs.
+
+  It extracts images and predictions from logs and draws visualization on input
+  images. By default, it requires `detection_boxes`, `detection_classes` and
+  `detection_scores` in the prediction, and optionally accepts
+  `detection_keypoints` and `detection_masks`.
+
+  Args:
+    logs: A dictionaty of log that contains images and predictions.
+    task_config: A task config.
+    original_image_spatial_shape: A [N, 2] tensor containing the spatial size of
+      the original image.
+    true_image_shape: A [N, 3] tensor containing the spatial size of unpadded
+      original_image.
+    image_mean: An optional float or list of floats used as the mean pixel value
+      to normalize images.
+    image_std: An optional float or list of floats used as the std to normalize
+      images.
+    key: A string specifying the key of the returned dictionary.
+
+  Returns:
+    A dictionary of images with visualization drawn on it. Each key corresponds
+      to a 4D tensor with segments drawn on each image.
+  """
+  images = logs['image']
+  masks = np.argmax(logs['logits'], axis=-1)
+  num_classes = task_config.model.num_classes
+
+  def _denormalize_images(images: tf.Tensor) -> tf.Tensor:
+    if image_mean is None and image_std is None:
+      images *= tf.constant(
+          preprocess_ops.STDDEV_RGB, shape=[1, 1, 3], dtype=images.dtype
+      )
+      images += tf.constant(
+          preprocess_ops.MEAN_RGB, shape=[1, 1, 3], dtype=images.dtype
+      )
+    elif image_mean is not None and image_std is not None:
+      if isinstance(image_mean, float) and isinstance(image_std, float):
+        images = images * image_std + image_mean
+      elif isinstance(image_mean, list) and isinstance(image_std, list):
+        images *= tf.constant(image_std, shape=[1, 1, 3], dtype=images.dtype)
+        images += tf.constant(image_mean, shape=[1, 1, 3], dtype=images.dtype)
+      else:
+        raise ValueError(
+            '`image_mean` and `image_std` should be the same type.'
+        )
+    else:
+      raise ValueError(
+          'Both `image_mean` and `image_std` should be set or None at the same '
+          'time.'
+      )
+    return tf.cast(images, dtype=tf.uint8)
+
+  if images.shape[3] > 3:
+    images = images[:, :, :, 0:3]
+  elif images.shape[3] == 1:
+    images = tf.image.grayscale_to_rgb(images)
+
+  images = tf.nest.map_structure(
+      tf.identity,
+      tf.map_fn(
+          _denormalize_images,
+          elems=images,
+          fn_output_signature=tf.TensorSpec(
+              shape=images.shape.as_list()[1:], dtype=tf.uint8
+          ),
+          parallel_iterations=32,
+      ),
+  )
+
+  if true_image_shape is None:
+    true_shapes = tf.constant(-1, shape=[images.shape.as_list()[0], 3])
+  else:
+    true_shapes = true_image_shape
+  if original_image_spatial_shape is None:
+    original_shapes = tf.constant(-1, shape=[images.shape.as_list()[0], 2])
+  else:
+    original_shapes = original_image_spatial_shape
+
+  visualize_fn = functools.partial(_visualize_masks, num_classes=num_classes)
+  elems = [true_shapes, original_shapes, images, masks]
+
+  def draw_segments(image_and_segments):
+    """Draws boxes on image."""
+    true_shape = image_and_segments[0]
+    original_shape = image_and_segments[1]
+    if true_image_shape is not None:
+      image = shape_utils.pad_or_clip_nd(
+          image_and_segments[2], [true_shape[0], true_shape[1], 3]
+      )
+    if original_image_spatial_shape is not None:
+      image_and_segments[2] = _resize_original_image(image, original_shape)
+
+    image_with_boxes = tf.compat.v1.py_func(
+        visualize_fn, image_and_segments[2:], tf.uint8
+    )
+    return image_with_boxes
+
+  images_with_segments = tf.map_fn(
+      draw_segments, elems, dtype=tf.uint8, back_prop=False
+  )
+
+  outputs = {}
+  for i, image in enumerate(images_with_segments):
+    outputs[key + f'/{i}'] = image[None, ...]
+
+  return outputs
+
+
+def _visualize_masks(image, mask, num_classes, alpha=0.4):
+  """Visualizes semantic segmentation masks."""
+  solid_color = np.repeat(
+      np.expand_dims(np.zeros_like(mask), axis=2), 3, axis=2
+  )
+  for i in range(num_classes):
+    color = STANDARD_COLORS[i % len(STANDARD_COLORS)]
+    rgb = ImageColor.getrgb(color)
+    one_class_mask = np.where(mask == i, 1, 0)
+    solid_color = solid_color + np.expand_dims(
+        one_class_mask, axis=2
+    ) * np.reshape(list(rgb), [1, 1, 3])
+
+  pil_image = Image.fromarray(image)
+  pil_solid_color = (
+      Image.fromarray(np.uint8(solid_color))
+      .convert('RGBA')
+      .resize(pil_image.size)
+  )
+  pil_mask = (
+      Image.fromarray(np.uint8(255.0 * alpha * np.ones_like(mask)))
+      .convert('L')
+      .resize(pil_image.size)
+  )
+  pil_image = Image.composite(pil_solid_color, pil_image, pil_mask)
+  np.copyto(image, np.array(pil_image.convert('RGB')))
+  return image
```

### Comparing `tf-models-no-deps-2.11.2/orbit/__init__.py` & `tf-models-no-deps-2.16.0/orbit/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/orbit/actions/__init__.py` & `tf-models-no-deps-2.16.0/orbit/actions/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -68,7 +68,9 @@
 from orbit.actions.conditional_action import ConditionalAction
 
 from orbit.actions.export_saved_model import ExportFileManager
 from orbit.actions.export_saved_model import ExportSavedModel
 
 from orbit.actions.new_best_metric import JSONPersistedValue
 from orbit.actions.new_best_metric import NewBestMetric
+
+from orbit.actions.save_checkpoint_if_preempted import SaveCheckpointIfPreempted
```

### Comparing `tf-models-no-deps-2.11.2/orbit/actions/conditional_action.py` & `tf-models-no-deps-2.16.0/orbit/actions/conditional_action.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Provides a `ConditionalAction` abstraction."""
 
 from typing import Any, Callable, Sequence, Union
 
 from orbit import controller
 from orbit import runner
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 Condition = Callable[[runner.Output], Union[bool, tf.Tensor]]
 
 
 def _as_sequence(maybe_sequence: Union[Any, Sequence[Any]]) -> Sequence[Any]:
   if isinstance(maybe_sequence, Sequence):
     return maybe_sequence
```

### Comparing `tf-models-no-deps-2.11.2/orbit/actions/conditional_action_test.py` & `tf-models-no-deps-2.16.0/orbit/actions/conditional_action_test.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for orbit.actions.conditional_action."""
 
 from orbit import actions
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class ConditionalActionTest(tf.test.TestCase):
 
   def test_conditional_action(self):
     # Define a function to raise an AssertionError, since we can't in a lambda.
     def raise_assertion(arg):
```

### Comparing `tf-models-no-deps-2.11.2/orbit/actions/export_saved_model.py` & `tf-models-no-deps-2.16.0/orbit/actions/export_saved_model.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,25 @@
 """Provides the `ExportSavedModel` action and associated helper classes."""
 
 import os
 import re
 
 from typing import Callable, Optional
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
+
+
+_GS_PREFIX = r'gs://'  # Google Cloud Storage Prefix
+
+
+def safe_normpath(path: str) -> str:
+  """Normalize path safely to get around gfile.glob limitations."""
+  if path.startswith(_GS_PREFIX):
+    return _GS_PREFIX + os.path.normpath(path[len(_GS_PREFIX):])
+  return os.path.normpath(path)
 
 
 def _id_key(filename):
   _, id_num = filename.rsplit('-', maxsplit=1)
   return int(id_num)
 
 
@@ -55,62 +65,78 @@
   file naming and cleanup strategies that may be desirable. This class provides
   a basic interface allowing SavedModel export to be decoupled from these
   details, and a default implementation that should work for many basic
   scenarios. Users may subclass this class to alter behavior and define more
   customized naming and cleanup strategies.
   """
 
-  def __init__(self,
-               base_name: str,
-               max_to_keep: int = 5,
-               next_id_fn: Optional[Callable[[], int]] = None):
+  def __init__(
+      self,
+      base_name: str,
+      max_to_keep: int = 5,
+      next_id_fn: Optional[Callable[[], int]] = None,
+      subdirectory: Optional[str] = None,
+  ):
     """Initializes the instance.
 
     Args:
       base_name: A shared base name for file names generated by this class.
       max_to_keep: The maximum number of files matching `base_name` to keep
         after each call to `cleanup`. The most recent (as determined by file
         modification time) `max_to_keep` files are preserved; the rest are
         deleted. If < 0, all files are preserved.
       next_id_fn: An optional callable that returns integer IDs to append to
         base name (formatted as `'{base_name}-{id}'`). The order of integers is
         used to sort files to determine the oldest ones deleted by `clean_up`.
         If not supplied, a default ID based on an incrementing counter is used.
         One common alternative maybe be to use the current global step count,
         for instance passing `next_id_fn=global_step.numpy`.
+      subdirectory: An optional subdirectory to concat after the
+        {base_name}-{id}. Then the file manager will manage
+        {base_name}-{id}/{subdirectory} files.
     """
-    self._base_name = os.path.normpath(base_name)
+    self._base_name = safe_normpath(base_name)
     self._max_to_keep = max_to_keep
     self._next_id_fn = next_id_fn or _CounterIdFn(self._base_name)
+    self._subdirectory = subdirectory or ''
 
   @property
   def managed_files(self):
     """Returns all files managed by this instance, in sorted order.
 
     Returns:
       The list of files matching the `base_name` provided when constructing this
       `ExportFileManager` instance, sorted in increasing integer order of the
       IDs returned by `next_id_fn`.
     """
-    return _find_managed_files(self._base_name)
+    files = []
+    for file in _find_managed_files(self._base_name):
+      # Normalize path and maybe add subdirectory...
+      file = safe_normpath(os.path.join(file, self._subdirectory))
+      if tf.io.gfile.exists(file):
+        files.append(file)
+    return files
 
   def clean_up(self):
     """Cleans up old files matching `{base_name}-*`.
 
     The most recent `max_to_keep` files are preserved.
     """
     if self._max_to_keep < 0:
       return
 
-    for filename in self.managed_files[:-self._max_to_keep]:
+    # Note that the base folder will remain intact, only the folder with suffix
+    # is deleted.
+    for filename in self.managed_files[: -self._max_to_keep]:
       tf.io.gfile.rmtree(filename)
 
   def next_name(self) -> str:
     """Returns a new file name based on `base_name` and `next_id_fn()`."""
-    return f'{self._base_name}-{self._next_id_fn()}'
+    base_path = f'{self._base_name}-{self._next_id_fn()}'
+    return safe_normpath(os.path.join(base_path, self._subdirectory))
 
 
 class ExportSavedModel:
   """Action that exports the given model as a SavedModel."""
 
   def __init__(self,
                model: tf.Module,
```

### Comparing `tf-models-no-deps-2.11.2/orbit/actions/export_saved_model_test.py` & `tf-models-no-deps-2.16.0/orbit/actions/export_saved_model_test.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,16 +13,17 @@
 # limitations under the License.
 
 """Tests for orbit.actions.export_saved_model."""
 
 import os
 
 from orbit import actions
+from orbit.actions import export_saved_model
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def _id_key(name):
   _, id_num = name.rsplit('-', maxsplit=1)
   return int(id_num)
 
 
@@ -42,15 +43,15 @@
 
 class ExportSavedModelTest(tf.test.TestCase):
 
   def test_export_file_manager_default_ids(self):
     directory = self.create_tempdir()
     base_name = os.path.join(directory.full_path, 'basename')
     manager = actions.ExportFileManager(base_name, max_to_keep=3)
-    self.assertLen(tf.io.gfile.listdir(directory.full_path), 0)
+    self.assertEmpty(tf.io.gfile.listdir(directory.full_path))
     directory.create_file(manager.next_name())
     manager.clean_up()  # Shouldn't do anything...
     self.assertLen(tf.io.gfile.listdir(directory.full_path), 1)
     directory.create_file(manager.next_name())
     manager.clean_up()  # Shouldn't do anything...
     self.assertLen(tf.io.gfile.listdir(directory.full_path), 2)
     directory.create_file(manager.next_name())
@@ -75,15 +76,15 @@
     id_num = 0
 
     def next_id():
       return id_num
 
     manager = actions.ExportFileManager(
         base_name, max_to_keep=2, next_id_fn=next_id)
-    self.assertLen(tf.io.gfile.listdir(directory.full_path), 0)
+    self.assertEmpty(tf.io.gfile.listdir(directory.full_path))
     id_num = 30
     directory.create_file(manager.next_name())
     self.assertLen(tf.io.gfile.listdir(directory.full_path), 1)
     manager.clean_up()  # Shouldn't do anything...
     self.assertEqual(
         _id_sorted_file_base_names(directory.full_path), ['basename-30'])
     id_num = 200
@@ -101,14 +102,118 @@
         ['basename-30', 'basename-200', 'basename-1000'])
     manager.clean_up()  # Should delete file with lowest ID.
     self.assertLen(tf.io.gfile.listdir(directory.full_path), 2)
     self.assertEqual(
         _id_sorted_file_base_names(directory.full_path),
         ['basename-200', 'basename-1000'])
 
+  def test_export_file_manager_with_suffix(self):
+    directory = self.create_tempdir()
+    base_name = os.path.join(directory.full_path, 'basename')
+
+    id_num = 0
+
+    def next_id():
+      return id_num
+
+    subdirectory = 'sub'
+
+    manager = actions.ExportFileManager(
+        base_name, max_to_keep=2, next_id_fn=next_id, subdirectory=subdirectory
+    )
+    self.assertEmpty(tf.io.gfile.listdir(directory.full_path))
+    id_num = 30
+    directory.create_file(manager.next_name())
+    self.assertLen(tf.io.gfile.listdir(directory.full_path), 1)
+    manager.clean_up()  # Shouldn't do anything...
+    self.assertEqual(
+        _id_sorted_file_base_names(directory.full_path), ['basename-30']
+    )
+    id_num = 200
+    directory.create_file(manager.next_name())
+    self.assertLen(tf.io.gfile.listdir(directory.full_path), 2)
+    manager.clean_up()  # Shouldn't do anything...
+    self.assertEqual(
+        _id_sorted_file_base_names(directory.full_path),
+        ['basename-30', 'basename-200'],
+    )
+    id_num = 1000
+    directory.create_file(manager.next_name())
+    self.assertLen(tf.io.gfile.listdir(directory.full_path), 3)
+    self.assertEqual(
+        _id_sorted_file_base_names(directory.full_path),
+        ['basename-30', 'basename-200', 'basename-1000'],
+    )
+    manager.clean_up()  # Should delete file with lowest ID.
+    self.assertLen(tf.io.gfile.listdir(directory.full_path), 3)
+    # Note that the base folder is intact, only the suffix folder is deleted.
+    self.assertEqual(
+        _id_sorted_file_base_names(directory.full_path),
+        ['basename-30', 'basename-200', 'basename-1000'],
+    )
+
+    step_folder = os.path.join(directory.full_path, 'basename-1000')
+    self.assertIn(subdirectory, tf.io.gfile.listdir(step_folder))
+
+  def test_export_file_manager_with_suffix_second_cleanup_succeeds(self):
+    directory = self.create_tempdir()
+    base_name = os.path.join(directory.full_path, 'basename')
+
+    id_num = 0
+
+    def next_id():
+      return id_num
+
+    subdirectory = 'sub'
+
+    manager = actions.ExportFileManager(
+        base_name, max_to_keep=2, next_id_fn=next_id, subdirectory=subdirectory
+    )
+    id_num = 30
+    directory.create_file(manager.next_name())
+    id_num = 200
+    directory.create_file(manager.next_name())
+    id_num = 1000
+    directory.create_file(manager.next_name())
+    manager.clean_up()  # Should delete file with lowest ID.
+    # Note that the base folder is intact, only the suffix folder is deleted.
+    self.assertEqual(
+        _id_sorted_file_base_names(directory.full_path),
+        ['basename-30', 'basename-200', 'basename-1000'],
+    )
+    # Verify that the suffix folder has been deleted from the lowest ID
+    # but not from the others.
+    self.assertEmpty(
+        tf.io.gfile.listdir(os.path.join(directory.full_path, 'basename-30'))
+    )
+    self.assertNotEmpty(
+        tf.io.gfile.listdir(os.path.join(directory.full_path, 'basename-200'))
+    )
+    self.assertNotEmpty(
+        tf.io.gfile.listdir(os.path.join(directory.full_path, 'basename-1000'))
+    )
+    # Add another ID, run clean_up again and verify that it worked.
+    id_num = 2000
+    directory.create_file(manager.next_name())
+    manager.clean_up()  # Should delete file with lowest ID.
+    # Verify that the suffix folder has been deleted from the two lowest ID
+    # directories but not from the others.
+    self.assertEmpty(
+        tf.io.gfile.listdir(os.path.join(directory.full_path, 'basename-30'))
+    )
+    self.assertEmpty(
+        tf.io.gfile.listdir(os.path.join(directory.full_path, 'basename-200'))
+    )
+    self.assertNotEmpty(
+        tf.io.gfile.listdir(os.path.join(directory.full_path, 'basename-1000'))
+    )
+    self.assertNotEmpty(
+        tf.io.gfile.listdir(os.path.join(directory.full_path, 'basename-2000'))
+    )
+
   def test_export_file_manager_managed_files(self):
     directory = self.create_tempdir()
     directory.create_file('basename-5')
     directory.create_file('basename-10')
     directory.create_file('basename-50')
     directory.create_file('basename-1000')
     directory.create_file('basename-9')
@@ -168,10 +273,14 @@
     model.value.assign(7)
     self.assertEqual(model(), 7)
     export_action({})
     self.assertLen(file_manager.managed_files, 2)  # Still 2, due to clean up.
     reloaded_model = tf.saved_model.load(file_manager.managed_files[-1])
     self.assertEqual(reloaded_model(), 7)
 
+  def test_safe_normpath_gs(self):
+    path = export_saved_model.safe_normpath('gs://foo//bar')
+    self.assertEqual(path, 'gs://foo/bar')
+
 
 if __name__ == '__main__':
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/orbit/actions/new_best_metric.py` & `tf-models-no-deps-2.16.0/orbit/actions/new_best_metric.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -19,15 +19,15 @@
 import sys
 from typing import Any, Callable, Optional, Union
 import uuid
 
 from orbit import runner
 from orbit import utils
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 MetricFn = Callable[[runner.Output], Union[float, tf.Tensor]]
 
 
 class NewBestMetric:
   """Condition that is satisfied when a new best metric is achieved.
```

### Comparing `tf-models-no-deps-2.11.2/orbit/actions/new_best_metric_test.py` & `tf-models-no-deps-2.16.0/orbit/actions/new_best_metric_test.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Tests for orbit.actions.new_best_metric."""
 
 import os
 
 from orbit import actions
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class NewBestMetricTest(tf.test.TestCase):
 
   def test_new_best_metric_higher_is_better(self):
     new_best_metric = actions.NewBestMetric(
         lambda x: x['value'], higher_is_better=True)
```

### Comparing `tf-models-no-deps-2.11.2/orbit/controller.py` & `tf-models-no-deps-2.16.0/orbit/controller.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -20,15 +20,23 @@
 from typing import Callable, Iterable, Optional, Union
 
 from absl import logging
 
 from orbit import runner
 from orbit import utils
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
+
+# pylint: disable=g-direct-tensorflow-import
+from tensorflow.python.eager import monitoring
+# pylint: enable=g-direct-tensorflow-import
+
+_orbit_api_gauge = monitoring.BoolGauge(
+    "/tensorflow/api/orbit", "orbit api usage"
+)
 
 
 def _log(message: str):
   """Logs `message` to the `info` log, and also prints to stdout."""
   logging.info(message)
   print(message)
 
@@ -92,14 +100,15 @@
       strategy: Optional[tf.distribute.Strategy] = None,
       # Actions
       train_actions: Optional[Iterable[Action]] = None,
       eval_actions: Optional[Iterable[Action]] = None,
       # Train related
       steps_per_loop: Optional[Union[int, Callable[[int], int]]] = None,
       checkpoint_manager: Optional[tf.train.CheckpointManager] = None,
+      enable_async_checkpointing: bool = False,
       # Summary related
       summary_interval: Optional[int] = None,
       summary_dir: Optional[str] = None,
       # Evaluation related
       eval_summary_dir: Optional[str] = None,
       summary_manager: Optional[utils.SummaryManagerInterface] = None,
       eval_summary_manager: Optional[utils.SummaryManagerInterface] = None):
@@ -137,14 +146,16 @@
         global step value as input and returns the number of steps to run as
         output.
       checkpoint_manager: An instance of `tf.train.CheckpointManager`. If
         provided and there are checkpoints in the associated model directory,
         the model will be restored from the most recent checkpoint inside this
         `__init__` method. If not provided, the `Controller` will not
         automatically save to or restore from checkpoints.
+      enable_async_checkpointing: Optional bool indicating whether to enable
+        async checkpoint saving.
       summary_interval: Step interval for training summaries. Note that this
         argument only applies to `tf.summary` calls inside the `trainer.train`
         function. Summaries written by the `Controller` (specifically
         "steps_per_second" and output from the `trainer.train` method) will
         always be enabled unless the `summary_dir` parameter is `None`. If set,
         the value must be divisible by `steps_per_loop`.
       summary_dir: The directory to write summaries to. To use the same
@@ -200,14 +211,18 @@
     self.strategy = strategy or tf.distribute.get_strategy()
 
     self.train_actions = () if train_actions is None else tuple(train_actions)
     self.eval_actions = () if eval_actions is None else tuple(eval_actions)
 
     self.global_step = global_step
     self.checkpoint_manager = checkpoint_manager
+    self._enable_async_checkpoint_saving = enable_async_checkpointing
+    self._checkpoint_options = tf.train.CheckpointOptions(
+        enable_async=enable_async_checkpointing
+    )
 
     if self.trainer is not None:
       self.step_timer = None
       self.summary_interval = summary_interval
       if summary_manager:
         self.summary_manager = summary_manager
       else:
@@ -232,22 +247,29 @@
 
     # Restores the model if needed.
     if self.checkpoint_manager is not None:
       restored_path = self.restore_checkpoint()
       if restored_path:
         _log(f"restored from checkpoint: {restored_path}")
 
+    # Set Orbit framework gauge to True value
+    _orbit_api_gauge.get_cell().set(True)
+
   def train(self, steps: int, checkpoint_at_completion: bool = True):
     """Runs training until the specified global step count has been reached.
 
     This method makes calls to `self.trainer.train()` until the global step
     count is equal to `steps`. It will additionally save checkpoints (if a
     `CheckpointManager` was passed to `Controller.__init__`) and summarize
     training output (if `summary_dir` is set).
 
+    When async checkpointing is enabled, a sync is triggered at the end of this
+    method to make sure any ongoing async checkpoint saving is finished before
+    returning.
+
     Args:
       steps: The global step count to train up to.
       checkpoint_at_completion: Whether to save a checkpoint when this method
         returns (regardless of the checkpointing interval). Defaults to `True`.
     """
     self._require("trainer", for_method="train")
 
@@ -260,14 +282,16 @@
       self._train_n_steps(num_steps)
       self._maybe_save_checkpoint()
       current_step = self.global_step.numpy()
 
     if checkpoint_at_completion:
       self._maybe_save_checkpoint(check_interval=False)
 
+    self._sync_on_async_checkpointing()
+
   def evaluate(self, steps: int = -1) -> Optional[runner.Output]:
     """Runs evaluation for the given number of steps.
 
     This method calls `self.evaluator.evaluate(steps)`, then writes the returned
     summaries (if any).
 
     Args:
@@ -293,72 +317,96 @@
     else:
       raise ValueError(f"`steps` ({steps}) should be > 0, or == -1.")
 
     current_step = self.global_step.numpy()
     _log(f" eval | step: {current_step: 6d} | {steps_msg}")
 
     start = time.time()
+    assert isinstance(self.evaluator, runner.AbstractEvaluator)
     with self.eval_summary_manager.summary_writer().as_default():
       steps_tensor = tf.convert_to_tensor(steps, dtype=tf.int32)
       eval_output = self.evaluator.evaluate(steps_tensor)
     elapsed = time.time() - start
 
     eval_output = eval_output or {}
     for action in self.eval_actions:
       action(eval_output)
     eval_output = tf.nest.map_structure(utils.get_value, eval_output)
 
+    if steps > 0:
+      # Only log if steps has been specified.
+      steps_per_second = steps / elapsed
+      eval_output["steps_per_second"] = steps_per_second
+      steps_per_second_log = f"steps/sec: {steps_per_second: 6.1f} | "
+    else:
+      steps_per_second_log = ""
+
     _log(f" eval | step: {current_step: 6d} | "
+         f"{steps_per_second_log}"
          f"eval time: {elapsed: 6.1f} sec | "
          f"output: {_format_output(eval_output)}")
 
     self.eval_summary_manager.write_summaries(eval_output)
     self.eval_summary_manager.flush()
 
     return eval_output
 
-  def train_and_evaluate(self,
-                         train_steps: int,
-                         eval_steps: int = -1,
-                         eval_interval: Optional[int] = None) -> None:
+  def train_and_evaluate(
+      self,
+      train_steps: int,
+      eval_steps: int = -1,
+      eval_interval: Optional[int] = None,
+  ) -> Optional[runner.Output]:
     """Runs interleaved training and evaluation.
 
     This method interleaves calls to `self.train()` and `self.evaluate()`,
     training the model until the global step count equals `train_steps`, and
     running an evaluation for `eval_steps` every `eval_interval` training steps.
     In addition, this method will run a final evaluation at the end of the
     training sequence.
 
+    When async checkpointing is enabled, a sync is triggered at the end of this
+    method to make sure any ongoing async checkpoint saving is finished before
+    returning.
+
     Args:
       train_steps: The global step count to train up to.
       eval_steps: The number of steps to run during an evaluation. If -1, this
         method will evaluate over the entire evaluation dataset.
       eval_interval: The number of training steps to run between evaluations. If
         set, training will always stop every `eval_interval` steps, even if this
         results in a shorter inner loop than specified by `steps_per_loop`
         setting. If None, evaluation will only be performed after training is
         complete.
+
+    Returns:
+      The evaluation results as a dictionary mapping names to NumPy values.
     """
     self._require("trainer", for_method="train_and_evaluate")
     self._require("evaluator", for_method="train_and_evaluate")
 
+    output = None
     current_step = self.global_step.numpy()  # Cache, since this is expensive.
     eval_interval = eval_interval or (train_steps - current_step)
     while current_step < train_steps:
       interval = min(train_steps - current_step, eval_interval)
       num_steps = current_step + interval
       self.train(steps=num_steps, checkpoint_at_completion=False)
-      self.evaluate(steps=eval_steps)
+      output = self.evaluate(steps=eval_steps)
       current_step = self.global_step.numpy()
     self._maybe_save_checkpoint(check_interval=False)
+    self._sync_on_async_checkpointing()
+    return output
 
-  def evaluate_continuously(self,
-                            steps: int = -1,
-                            timeout: Optional[Union[int, float]] = None,
-                            timeout_fn: Optional[Callable[[], bool]] = None):
+  def evaluate_continuously(
+      self,
+      steps: int = -1,
+      timeout: Optional[Union[int, float]] = None,
+      timeout_fn: Optional[Callable[[], bool]] = None,
+  ) -> Optional[runner.Output]:
     """Continuously monitors a directory and evaluates new checkpoints in it.
 
     This method continuously monitors a directory as specified by this
     Controller's CheckpointManager init arg and runs evaluation on the
     checkpoints found there.
 
     Args:
@@ -366,27 +414,33 @@
         evaluate over the entire evaluation dataset.
       timeout: The maximum number of seconds to wait between checkpoints. See
         tf.train.checkpoints_iterator documentation.
       timeout_fn: Optional callable to call after a timeout. If the function
         returns True, then it means that no new checkpoints will be generated
         and the iterator will exit.
 
+    Returns:
+      The evaluation results as a dictionary mapping names to NumPy values.
+
     Raises:
       ValueError: If no checkpoint found in `self.checkpoint_manager.directory`.
       ValueError: If `evaluator` was not provided as a controller init arg.
     """
     self._require("evaluator", for_method="evaluate_continuously")
     self._require("checkpoint_manager", for_method="evaluate_continuously")
 
+    output = None
+    assert isinstance(self.checkpoint_manager, tf.train.CheckpointManager)
     for checkpoint_path in tf.train.checkpoints_iterator(
         self.checkpoint_manager.directory,
         timeout=timeout,
         timeout_fn=timeout_fn):
       self.restore_checkpoint(checkpoint_path)
-      self.evaluate(steps)
+      output = self.evaluate(steps)
+    return output
 
   def restore_checkpoint(self, checkpoint_path: Optional[str] = None):
     """Restores the model from a checkpoint.
 
     Args:
       checkpoint_path: An optional string specifying the checkpoint path to
         restore from. If `None`, will restore from the most recent checkpoint
@@ -395,27 +449,26 @@
 
     Returns:
       The path to the restored checkpoint if a restore happened, or `None` if no
       restore occurred.
     """
     self._require("checkpoint_manager", for_method="restore_checkpoint")
 
+    assert isinstance(self.checkpoint_manager, tf.train.CheckpointManager)
     with self.strategy.scope():
       # Checkpoint restoring should be inside scope (b/139450638).
       if checkpoint_path is not None:
         _log(f"restoring model from {checkpoint_path}...")
         self.checkpoint_manager.checkpoint.restore(checkpoint_path)
       else:
         _log("restoring or initializing model...")
         checkpoint_path = self.checkpoint_manager.restore_or_initialize()
 
     if checkpoint_path is not None:
       _log(f"restored model from {checkpoint_path}.")
-    else:
-      _log("initialized model.")
 
     return checkpoint_path
 
   def save_checkpoint(self):
     """Saves the model to a checkpoint.
 
     This method will save a checkpoint containing the current state of the
@@ -454,14 +507,15 @@
     current_step = self.global_step.numpy()
 
     with self.summary_manager.summary_writer().as_default():
       should_record = False  # Allows static optimization in no-summary cases.
       if self.summary_interval:
         # Create a predicate to determine when summaries should be written.
         should_record = lambda: (self.global_step % self.summary_interval == 0)
+      assert isinstance(self.trainer, runner.AbstractTrainer)
       with tf.summary.record_if(should_record):
         num_steps_tensor = tf.convert_to_tensor(num_steps, dtype=tf.int32)
         train_output = self.trainer.train(num_steps_tensor)
 
     # Verify that global_step was updated properly, then update current_step.
     expected_step = current_step + num_steps
     if self.global_step.numpy() != expected_step:
@@ -501,27 +555,35 @@
 
     Returns:
       A boolean indicating whether a checkpoint was saved.
     """
     if self.checkpoint_manager and self.checkpoint_manager.checkpoint_interval:
       ckpt_path = self.checkpoint_manager.save(
           checkpoint_number=self.global_step.numpy(),
-          check_interval=check_interval)
+          check_interval=check_interval,
+          options=self._checkpoint_options)
       if ckpt_path is not None:
         _log(f"saved checkpoint to {ckpt_path}.")
         return True
     return False
 
   def _require(self, attribute, for_method):
     """Utility method to raise an error if the given `attribute` is not set."""
     if getattr(self, attribute, None) is None:
       raise ValueError(
           f"`{attribute}` is not set. Pass `{attribute}` to "
           f"`Controller.__init__` before calling `{for_method}()`.")
 
+  def _sync_on_async_checkpointing(self):
+    """Force to wait for the async checkpoint saving (if any) to finish."""
+    # pylint: disable=protected-access
+    if self.checkpoint_manager:
+      logging.info("Sync on async checkpoint saving.")
+      self.checkpoint_manager.sync()
+
 
 class StepTimer:
   """Utility class for measuring steps/second."""
 
   def __init__(self, step):
     self.step = step
     self.start()
```

### Comparing `tf-models-no-deps-2.11.2/orbit/controller_test.py` & `tf-models-no-deps-2.16.0/orbit/controller_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -22,21 +22,21 @@
 import numpy as np
 
 from orbit import controller
 from orbit import runner
 from orbit import standard_runner
 import orbit.utils
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def create_model():
-  x = tf.keras.layers.Input(shape=(3,), name="input")
-  y = tf.keras.layers.Dense(4, name="dense")(x)
-  model = tf.keras.Model(x, y)
+  x = tf_keras.layers.Input(shape=(3,), name="input")
+  y = tf_keras.layers.Dense(4, name="dense")(x)
+  model = tf_keras.Model(x, y)
   return model
 
 
 def summaries_with_matching_keyword(keyword, summary_dir):
   """Returns summary protos matching given keyword from event file."""
   matches = []
   event_paths = tf.io.gfile.glob(os.path.join(summary_dir, "events*"))
@@ -61,32 +61,32 @@
 class TestRunner(standard_runner.StandardTrainer,
                  standard_runner.StandardEvaluator):
   """Implements the training and evaluation APIs for the test model."""
 
   def __init__(self, return_numpy=False):
     self.strategy = tf.distribute.get_strategy()
     self.model = create_model()
-    self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.1)
+    self.optimizer = tf_keras.optimizers.RMSprop(learning_rate=0.1)
     self.global_step = self.optimizer.iterations
-    self.train_loss = tf.keras.metrics.Mean("train_loss", dtype=tf.float32)
-    self.eval_loss = tf.keras.metrics.Mean("eval_loss", dtype=tf.float32)
+    self.train_loss = tf_keras.metrics.Mean("train_loss", dtype=tf.float32)
+    self.eval_loss = tf_keras.metrics.Mean("eval_loss", dtype=tf.float32)
     self.return_numpy = return_numpy
     train_dataset = self.strategy.distribute_datasets_from_function(dataset_fn)
     eval_dataset = self.strategy.distribute_datasets_from_function(dataset_fn)
     standard_runner.StandardTrainer.__init__(self, train_dataset)
     standard_runner.StandardEvaluator.__init__(self, eval_dataset)
 
   def train_step(self, iterator):
 
     def _replicated_step(inputs):
       """Replicated training step."""
       inputs, targets = inputs
       with tf.GradientTape() as tape:
         outputs = self.model(inputs)
-        loss = tf.reduce_mean(tf.keras.losses.MSE(targets, outputs))
+        loss = tf.reduce_mean(tf_keras.losses.MSE(targets, outputs))
       grads = tape.gradient(loss, self.model.variables)
       self.optimizer.apply_gradients(zip(grads, self.model.variables))
       self.train_loss.update_state(loss)
 
     self.strategy.run(_replicated_step, args=(next(iterator),))
 
   def train_loop_end(self):
@@ -103,15 +103,15 @@
 
   def eval_step(self, iterator):
 
     def _replicated_step(inputs):
       """Replicated evaluation step."""
       inputs, targets = inputs
       outputs = self.model(inputs)
-      loss = tf.reduce_mean(tf.keras.losses.MSE(targets, outputs))
+      loss = tf.reduce_mean(tf_keras.losses.MSE(targets, outputs))
       self.eval_loss.update_state(loss)
 
     self.strategy.run(_replicated_step, args=(next(iterator),))
 
   def eval_end(self):
     eval_loss = self.eval_loss.result()
     return {
@@ -137,15 +137,15 @@
 
   def eval_step(self, iterator):
 
     def _replicated_step(inputs):
       """Replicated evaluation step."""
       inputs, targets = inputs
       outputs = self.model(inputs)
-      loss = tf.reduce_mean(tf.keras.losses.MSE(targets, outputs))
+      loss = tf.reduce_mean(tf_keras.losses.MSE(targets, outputs))
       return loss
 
     per_replica_losses = self.strategy.run(
         _replicated_step, args=(next(iterator),))
     mean_loss = self.strategy.reduce(
         tf.distribute.ReduceOp.MEAN, per_replica_losses, axis=None)
     return mean_loss
@@ -166,33 +166,33 @@
   """Implements the training and evaluation APIs for the test model."""
 
   def __init__(self):
     self.strategy = tf.distribute.get_strategy()
     self.model = create_model()
     dataset = self.strategy.distribute_datasets_from_function(dataset_fn)
     dataset2 = self.strategy.distribute_datasets_from_function(dataset_fn)
-    self.loss = tf.keras.metrics.Mean("loss", dtype=tf.float32)
-    self.accuracy = tf.keras.metrics.CategoricalAccuracy(
+    self.loss = tf_keras.metrics.Mean("loss", dtype=tf.float32)
+    self.accuracy = tf_keras.metrics.CategoricalAccuracy(
         "accuracy", dtype=tf.float32)
-    self.loss2 = tf.keras.metrics.Mean("loss", dtype=tf.float32)
-    self.accuracy2 = tf.keras.metrics.CategoricalAccuracy(
+    self.loss2 = tf_keras.metrics.Mean("loss", dtype=tf.float32)
+    self.accuracy2 = tf_keras.metrics.CategoricalAccuracy(
         "accuracy", dtype=tf.float32)
     standard_runner.StandardEvaluator.__init__(
         self, eval_dataset={
             "dataset": dataset,
             "dataset2": dataset2
         })
 
   def eval_step(self, iterator):
 
     def _replicated_step(loss, accuracy, inputs):
       """Replicated evaluation step."""
       inputs, targets = inputs
       outputs = self.model(inputs)
-      loss.update_state(tf.keras.losses.MSE(targets, outputs))
+      loss.update_state(tf_keras.losses.MSE(targets, outputs))
       accuracy.update_state(targets, outputs)
 
     self.strategy.run(
         lambda inputs: _replicated_step(self.loss, self.accuracy, inputs),
         args=(next(iterator["dataset"]),))
     self.strategy.run(
         lambda inputs: _replicated_step(self.loss2, self.accuracy2, inputs),
@@ -213,17 +213,17 @@
 
 class TestTrainerWithSummaries(standard_runner.StandardTrainer):
   """A Trainer model with summaries for testing purposes."""
 
   def __init__(self):
     self.strategy = tf.distribute.get_strategy()
     self.model = create_model()
-    self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.1)
+    self.optimizer = tf_keras.optimizers.RMSprop(learning_rate=0.1)
     self.global_step = self.optimizer.iterations
-    self.train_loss = tf.keras.metrics.Mean("train_loss", dtype=tf.float32)
+    self.train_loss = tf_keras.metrics.Mean("train_loss", dtype=tf.float32)
     train_dataset = self.strategy.distribute_datasets_from_function(dataset_fn)
     standard_runner.StandardTrainer.__init__(
         self,
         train_dataset,
         options=standard_runner.StandardTrainerOptions(
             use_tpu_summary_optimization=True))
 
@@ -233,15 +233,15 @@
   def train_step(self, iterator):
 
     def _replicated_step(inputs):
       """Replicated training step."""
       inputs, targets = inputs
       with tf.GradientTape() as tape:
         outputs = self.model(inputs)
-        loss = tf.reduce_mean(tf.keras.losses.MSE(targets, outputs))
+        loss = tf.reduce_mean(tf_keras.losses.MSE(targets, outputs))
       tf.summary.scalar("loss", loss)
       grads = tape.gradient(loss, self.model.variables)
       self.optimizer.apply_gradients(zip(grads, self.model.variables))
       self.train_loss.update_state(loss)
 
     self.strategy.run(_replicated_step, args=(next(iterator),))
 
@@ -277,100 +277,128 @@
         summaries_with_matching_keyword(
             "eval_loss", os.path.join(self.model_dir, "summaries/eval")))
     # No checkpoint, so global step starts from 0.
     test_runner.global_step.assign(0)
     test_controller.train_and_evaluate(
         train_steps=10, eval_steps=2, eval_interval=6)
     self.assertEqual(test_runner.global_step, 10)
+    self.assertTrue(controller._orbit_api_gauge.get_cell().value())
 
   def test_no_checkpoint_and_summaries(self):
     test_runner = TestRunner()
     # No checkpoint + summary directories.
     test_controller = controller.Controller(
         trainer=test_runner,
         evaluator=test_runner,
         global_step=test_runner.global_step,
         steps_per_loop=2)
     test_controller.train_and_evaluate(
         train_steps=10, eval_steps=2, eval_interval=6)
     self.assertEqual(test_runner.global_step, 10)
+    self.assertTrue(controller._orbit_api_gauge.get_cell().value())
 
-  def test_has_checkpoint_no_summaries(self):
+  @parameterized.named_parameters(
+      ("_sync_checkpoint_saving", False),
+      ("_async_checkpoint_saving", True)
+  )
+  def test_has_checkpoint_no_summaries(self, enable_async_checkpoint_saving):
     test_runner = TestRunner()
     # Has checkpoint, but no summary directories.
     checkpoint = tf.train.Checkpoint(model=test_runner.model)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
         self.model_dir,
         max_to_keep=None,
         step_counter=test_runner.global_step)
     test_controller = controller.Controller(
         trainer=test_runner,
         evaluator=test_runner,
         global_step=test_runner.global_step,
         checkpoint_manager=checkpoint_manager,
+        enable_async_checkpointing=enable_async_checkpoint_saving,
         steps_per_loop=2)
     test_controller.train_and_evaluate(
         train_steps=10, eval_steps=2, eval_interval=6)
     self.assertEqual(test_runner.global_step, 10)
+    self.assertTrue(controller._orbit_api_gauge.get_cell().value())
 
     # No summaries are saved.
     self.assertEmpty(tf.io.gfile.glob(
         os.path.join(checkpoint_manager.directory, "events.*")))
 
-  def test_has_checkpoint_eval_summary_only(self):
+  @parameterized.named_parameters(
+      ("_sync_checkpoint_saving", False),
+      ("_async_checkpoint_saving", True)
+  )
+  def test_has_checkpoint_eval_summary_only(
+      self, enable_async_checkpoint_saving
+  ):
     test_runner = TestRunner()
     # Has checkpoint, but no summary directories.
     checkpoint = tf.train.Checkpoint(model=test_runner.model)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
         self.model_dir,
         max_to_keep=None,
         step_counter=test_runner.global_step)
     test_controller = controller.Controller(
         trainer=test_runner,
         evaluator=test_runner,
         global_step=test_runner.global_step,
         checkpoint_manager=checkpoint_manager,
+        enable_async_checkpointing=enable_async_checkpoint_saving,
         eval_summary_dir=os.path.join(self.model_dir, "summaries/eval"),
         steps_per_loop=2)
     test_controller.train_and_evaluate(
         train_steps=10, eval_steps=2, eval_interval=6)
     self.assertEqual(test_runner.global_step, 10)
 
     # Training summaries are not saved.
     self.assertEmpty(tf.io.gfile.glob(
         os.path.join(checkpoint_manager.directory, "events.*")))
     # Evaluation summaries are saved.
     self.assertNotEmpty(tf.io.gfile.glob(
         os.path.join(self.model_dir, "summaries/eval/events.*")))
 
-  def test_restore_from_most_recent_checkpoint(self):
+  @parameterized.named_parameters(
+      ("_sync_checkpoint_saving", False),
+      ("_async_checkpoint_saving", True)
+  )
+  def test_restore_from_most_recent_checkpoint(
+      self, enable_async_checkpoint_saving
+  ):
     test_runner = TestRunner()
     checkpoint = tf.train.Checkpoint(model=test_runner.model)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
         self.model_dir,
         max_to_keep=None,
         step_counter=test_runner.global_step,
         checkpoint_interval=5)
     test_controller = controller.Controller(
         trainer=test_runner,
         global_step=test_runner.global_step,
         checkpoint_manager=checkpoint_manager,
+        enable_async_checkpointing=enable_async_checkpoint_saving,
         eval_summary_dir=os.path.join(self.model_dir, "summaries/eval"),
         steps_per_loop=5)
     test_controller.train(20)
     self.assertLen(checkpoint_manager.checkpoints, 4)
     restored_path = test_controller.restore_checkpoint()
     self.assertEqual(restored_path, checkpoint_manager.checkpoints[-1])
 
-  @parameterized.named_parameters(("return_numpy", True),
-                                  ("return_tensor", False))
-  def test_train_and_evaluate(self, return_numpy):
+  @parameterized.named_parameters(
+      ("return_numpy_sync_checkpoint_saving", True, False),
+      ("return_numpy_async_checkpoint_saving", True, True),
+      ("return_tensor_sync_checkpoint_saving", False, False),
+      ("return_tensor_async_checkpoint_saving", False, True),
+  )
+  def test_train_and_evaluate(
+      self, return_numpy, enable_async_checkpoint_saving
+  ):
     test_runner = TestRunner(return_numpy=return_numpy)
 
     checkpoint = tf.train.Checkpoint(
         model=test_runner.model, optimizer=test_runner.optimizer)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
         self.model_dir,
@@ -380,14 +408,15 @@
     test_controller = controller.Controller(
         trainer=test_runner,
         evaluator=test_runner,
         global_step=test_runner.global_step,
         steps_per_loop=2,
         summary_dir=os.path.join(self.model_dir, "summaries/train"),
         checkpoint_manager=checkpoint_manager,
+        enable_async_checkpointing=enable_async_checkpoint_saving,
         eval_summary_dir=os.path.join(self.model_dir, "summaries/eval"))
     test_controller.train_and_evaluate(
         train_steps=10, eval_steps=2, eval_interval=6)
 
     # Checkpoints are saved.
     self.assertNotEmpty(tf.io.gfile.glob(os.path.join(self.model_dir, "ckpt*")))
 
@@ -399,15 +428,19 @@
             "loss", os.path.join(self.model_dir, "summaries/train")))
     self.assertNotEmpty(
         tf.io.gfile.listdir(os.path.join(self.model_dir, "summaries/eval")))
     self.assertNotEmpty(
         summaries_with_matching_keyword(
             "eval_loss", os.path.join(self.model_dir, "summaries/eval")))
 
-  def test_train_only(self):
+  @parameterized.named_parameters(
+      ("_sync_checkpoint_saving", False),
+      ("_async_checkpoint_saving", True)
+  )
+  def test_train_only(self, enable_async_checkpoint_saving):
     test_runner = TestRunner()
 
     checkpoint = tf.train.Checkpoint(
         model=test_runner.model, optimizer=test_runner.optimizer)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
         self.model_dir,
@@ -416,14 +449,15 @@
         checkpoint_interval=10)
     test_controller = controller.Controller(
         trainer=test_runner,
         global_step=test_runner.global_step,
         steps_per_loop=2,
         summary_dir=os.path.join(self.model_dir, "summaries/train"),
         checkpoint_manager=checkpoint_manager,
+        enable_async_checkpointing=enable_async_checkpoint_saving,
         eval_summary_dir=os.path.join(self.model_dir, "summaries/eval"),
     )
     test_controller.train(steps=10)
 
     # Checkpoints are saved.
     self.assertNotEmpty(tf.io.gfile.glob(os.path.join(self.model_dir, "ckpt*")))
 
@@ -493,15 +527,19 @@
         step_counter=test_runner.global_step)
     test_controller = controller.Controller(
         evaluator=test_runner,
         global_step=test_runner.global_step,
         checkpoint_manager=checkpoint_manager)
     test_controller.evaluate()
 
-  def test_already_trained_model(self):
+  @parameterized.named_parameters(
+      ("_sync_checkpoint_saving", False),
+      ("_async_checkpoint_saving", True)
+  )
+  def test_already_trained_model(self, enable_async_checkpoint_saving):
     test_runner = TestRunner()
     test_runner.global_step.assign(10)
 
     checkpoint = tf.train.Checkpoint(
         model=test_runner.model, optimizer=test_runner.optimizer)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
@@ -509,15 +547,16 @@
         max_to_keep=None,
         step_counter=test_runner.global_step,
         checkpoint_interval=10)
     test_controller = controller.Controller(
         trainer=test_runner,
         global_step=test_runner.global_step,
         steps_per_loop=2,
-        checkpoint_manager=checkpoint_manager)
+        checkpoint_manager=checkpoint_manager,
+        enable_async_checkpointing=enable_async_checkpoint_saving)
     # `global_step` is already `train_steps`.
     test_controller.train(steps=10)
 
   def test_summaries_inside_train_fn(self):
     test_runner = TestTrainerWithSummaries()
 
     checkpoint = tf.train.Checkpoint(
@@ -529,15 +568,15 @@
         step_counter=test_runner.global_step)
     test_controller = controller.Controller(
         trainer=test_runner,
         global_step=test_runner.global_step,
         steps_per_loop=2,
         summary_dir=os.path.join(self.model_dir, "summaries/train"),
         summary_interval=2,
-        checkpoint_manager=checkpoint_manager,
+        checkpoint_manager=checkpoint_manager
     )
     test_controller.train(steps=10)
 
     # Checkpoints are saved.
     self.assertEmpty(tf.io.gfile.glob(os.path.join(self.model_dir, "ckpt*")))
 
     # Only train summaries are written.
@@ -590,14 +629,15 @@
                              train_steps: int = None,
                              eval_steps: int = None,
                              eval_interval: int = None):
         while self.global_step.numpy() < train_steps:
           interval = min(train_steps - self.global_step.numpy(), eval_interval)
           num_steps = self.global_step.numpy() + interval
           self.train(steps=num_steps, checkpoint_at_completion=False)
+          self._sync_on_async_checkpointing()
           self.evaluate(steps=eval_steps)
           # Early stop condition.
           if test_runner.eval_loss.result() < 0.1:
             logging.info(
                 "Training early stopped as eval_loss %s is less than 0.1",
                 test_runner.eval_loss.result())
             return
@@ -643,15 +683,16 @@
             "eval_loss", os.path.join(self.model_dir, "summaries/eval")))
 
   def test_evaluate_with_no_output(self):
     test_controller = controller.Controller(
         evaluator=TestEvaluatorNoOutput(),
         global_step=tf.Variable(0, dtype=tf.int64),
         eval_summary_dir=os.path.join(self.model_dir, "summaries/eval"))
-    self.assertEqual(test_controller.evaluate(steps=5), {})
+    self.assertSameElements(["steps_per_second"],
+                            test_controller.evaluate(steps=5).keys())
 
   def test_train_and_evaluate_reset_datasets(self):
     test_runner = TestRunner()
 
     test_controller = controller.Controller(
         trainer=test_runner,
         evaluator=test_runner,
@@ -667,15 +708,19 @@
         test_runner.strategy.distribute_datasets_from_function(dataset_fn))
     test_runner.train_dataset = train_dataset
     test_runner.eval_dataset = eval_dataset
 
     test_controller.train_and_evaluate(
         train_steps=10, eval_steps=2, eval_interval=6)
 
-  def test_eval_and_checkpoint_interval(self):
+  @parameterized.named_parameters(
+      ("_sync_checkpoint_saving", False),
+      ("_async_checkpoint_saving", True)
+  )
+  def test_eval_and_checkpoint_interval(self, enable_async_checkpoint_saving):
     test_runner = TestRunner()
 
     checkpoint = tf.train.Checkpoint(
         model=test_runner.model, optimizer=test_runner.optimizer)
     checkpoint_manager = tf.train.CheckpointManager(
         checkpoint,
         self.model_dir,
@@ -684,14 +729,15 @@
         checkpoint_interval=5)
     test_controller = controller.Controller(
         trainer=test_runner,
         evaluator=test_runner,
         global_step=test_runner.global_step,
         steps_per_loop=10,
         checkpoint_manager=checkpoint_manager,
+        enable_async_checkpointing=enable_async_checkpoint_saving,
         summary_dir=self.model_dir)
     test_controller.train_and_evaluate(
         train_steps=10, eval_steps=2, eval_interval=5)
 
     # Expect 3 checkpoints to be saved at step: 5, 10.
     self.assertLen(
         tf.io.gfile.glob(os.path.join(self.model_dir, "ckpt-*.data*")), 2)
@@ -798,15 +844,15 @@
         return 4
       return 2
 
     test_controller = controller.Controller(
         trainer=test_runner,
         global_step=test_runner.global_step,
         steps_per_loop=steps_per_loop_fn,
-        checkpoint_manager=checkpoint_manager,
+        checkpoint_manager=checkpoint_manager
     )
     test_controller.train(steps=10)
     self.assertEqual(test_runner.global_step, 10)
 
 
 if __name__ == "__main__":
   tf.test.main()
```

### Comparing `tf-models-no-deps-2.11.2/orbit/examples/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/vision/quantization/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,14 +1,15 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+"""Configs package definition."""
```

### Comparing `tf-models-no-deps-2.11.2/orbit/examples/single_task/__init__.py` & `tf-models-no-deps-2.16.0/official/projects/qat/vision/modeling/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,14 +1,17 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+"""Modeling package definition."""
+from official.projects.qat.vision.modeling import heads
+from official.projects.qat.vision.modeling import layers
```

### Comparing `tf-models-no-deps-2.11.2/orbit/examples/single_task/single_task_evaluator.py` & `tf-models-no-deps-2.16.0/orbit/examples/single_task/single_task_evaluator.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,23 +10,23 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """An evaluator object that can evaluate models with a single output."""
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class SingleTaskEvaluator(orbit.StandardEvaluator):
   """Evaluates a single-output model on a given dataset.
 
   This evaluator will handle running a model with one output on a single
   dataset, and will apply the output of that model to one or more
-  `tf.keras.metrics.Metric` objects.
+  `tf_keras.metrics.Metric` objects.
   """
 
   def __init__(self,
                eval_dataset,
                label_key,
                model,
                metrics,
@@ -39,16 +39,16 @@
     Arguments:
       eval_dataset: A `tf.data.Dataset` or `DistributedDataset` that contains a
         string-keyed dict of `Tensor`s.
       label_key: The key corresponding to the label value in feature
         dictionaries dequeued from `eval_dataset`. This key will be removed from
         the dictionary before it is passed to the model.
       model: A `tf.Module` or Keras `Model` object to evaluate.
-      metrics: A single `tf.keras.metrics.Metric` object, or a list of
-        `tf.keras.metrics.Metric` objects.
+      metrics: A single `tf_keras.metrics.Metric` object, or a list of
+        `tf_keras.metrics.Metric` objects.
       evaluator_options: An optional `orbit.StandardEvaluatorOptions` object.
     """
 
     self.label_key = label_key
     self.model = model
     self.metrics = metrics if isinstance(metrics, list) else [metrics]
```

### Comparing `tf-models-no-deps-2.11.2/orbit/examples/single_task/single_task_evaluator_test.py` & `tf-models-no-deps-2.16.0/orbit/examples/single_task/single_task_evaluator_test.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,44 +13,44 @@
 # limitations under the License.
 
 """Tests for the single_task_evaluator."""
 import orbit
 from orbit.examples.single_task import single_task_evaluator
 from orbit.examples.single_task import single_task_trainer
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 
 class SingleTaskEvaluatorTest(tf.test.TestCase):
 
   def test_single_task_evaluation(self):
 
     iris = tfds.load('iris')
     train_ds = iris['train'].batch(32)
 
-    model = tf.keras.Sequential([
-        tf.keras.Input(shape=(4,), name='features'),
-        tf.keras.layers.Dense(10, activation=tf.nn.relu),
-        tf.keras.layers.Dense(10, activation=tf.nn.relu),
-        tf.keras.layers.Dense(3)
+    model = tf_keras.Sequential([
+        tf_keras.Input(shape=(4,), name='features'),
+        tf_keras.layers.Dense(10, activation=tf.nn.relu),
+        tf_keras.layers.Dense(10, activation=tf.nn.relu),
+        tf_keras.layers.Dense(3)
     ])
 
     trainer = single_task_trainer.SingleTaskTrainer(
         train_ds,
         label_key='label',
         model=model,
-        loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
-        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))
+        loss_fn=tf_keras.losses.SparseCategoricalCrossentropy(from_logits=True),
+        optimizer=tf_keras.optimizers.SGD(learning_rate=0.01))
 
     evaluator = single_task_evaluator.SingleTaskEvaluator(
         train_ds,
         label_key='label',
         model=model,
-        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
+        metrics=[tf_keras.metrics.SparseCategoricalAccuracy()])
 
     controller = orbit.Controller(
         trainer=trainer,
         evaluator=evaluator,
         steps_per_loop=100,
         global_step=trainer.optimizer.iterations)
```

### Comparing `tf-models-no-deps-2.11.2/orbit/examples/single_task/single_task_trainer.py` & `tf-models-no-deps-2.16.0/orbit/examples/single_task/single_task_trainer.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,24 +11,24 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """A trainer object that can train models with a single output."""
 
 import orbit
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class SingleTaskTrainer(orbit.StandardTrainer):
   """Trains a single-output model on a given dataset.
 
   This trainer will handle running a model with one output on a single
   dataset. It will apply the provided loss function to the model's output
   to calculate gradients and will apply them via the provided optimizer. It will
-  also supply the output of that model to one or more `tf.keras.metrics.Metric`
+  also supply the output of that model to one or more `tf_keras.metrics.Metric`
   objects.
   """
 
   def __init__(self,
                train_dataset,
                label_key,
                model,
@@ -52,31 +52,31 @@
         dictionaries dequeued from `train_dataset`. This key will be removed
         from the dictionary before it is passed to the model.
       model: A `tf.Module` or Keras `Model` object to evaluate. It must accept a
         `training` kwarg.
       loss_fn: A per-element loss function of the form (target, output). The
         output of this loss function will be reduced via `tf.reduce_mean` to
         create the final loss. We recommend using the functions in the
-        `tf.keras.losses` package or `tf.keras.losses.Loss` objects with
-        `reduction=tf.keras.losses.reduction.NONE`.
-      optimizer: A `tf.keras.optimizers.Optimizer` instance.
-      metrics: A single `tf.keras.metrics.Metric` object, or a list of
-        `tf.keras.metrics.Metric` objects.
+        `tf_keras.losses` package or `tf_keras.losses.Loss` objects with
+        `reduction=tf_keras.losses.reduction.NONE`.
+      optimizer: A `tf_keras.optimizers.Optimizer` instance.
+      metrics: A single `tf_keras.metrics.Metric` object, or a list of
+        `tf_keras.metrics.Metric` objects.
       trainer_options: An optional `orbit.utils.StandardTrainerOptions` object.
     """
     self.label_key = label_key
     self.model = model
     self.loss_fn = loss_fn
     self.optimizer = optimizer
 
     # Capture the strategy from the containing scope.
     self.strategy = tf.distribute.get_strategy()
 
     # We always want to report training loss.
-    self.train_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)
+    self.train_loss = tf_keras.metrics.Mean('training_loss', dtype=tf.float32)
 
     # We need self.metrics to be an iterable later, so we handle that here.
     if metrics is None:
       self.metrics = []
     elif isinstance(metrics, list):
       self.metrics = metrics
     else:
@@ -105,15 +105,15 @@
 
         # Get the average per-batch loss and scale it down by the number of
         # replicas. This ensures that we don't end up multiplying our loss by
         # the number of workers - gradients are summed, not averaged, across
         # replicas during the apply_gradients call.
         # Note, the reduction of loss is explicitly handled and scaled by
         # num_replicas_in_sync. Recommend to use a plain loss function.
-        # If you're using tf.keras.losses.Loss object, you may need to set
+        # If you're using tf_keras.losses.Loss object, you may need to set
         # reduction argument explicitly.
         loss = tf.reduce_mean(self.loss_fn(target, output))
         scaled_loss = loss / self.strategy.num_replicas_in_sync
 
         # Get the gradients by applying the loss to the model's trainable
         # variables.
         gradients = tape.gradient(scaled_loss, self.model.trainable_variables)
```

### Comparing `tf-models-no-deps-2.11.2/orbit/examples/single_task/single_task_trainer_test.py` & `tf-models-no-deps-2.16.0/orbit/examples/single_task/single_task_trainer_test.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,38 +12,38 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for the single_task_trainer."""
 import orbit
 from orbit.examples.single_task import single_task_trainer
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_datasets as tfds
 
 
 class SingleTaskTrainerTest(tf.test.TestCase):
 
   def test_single_task_training(self):
     iris = tfds.load('iris')
     train_ds = iris['train'].batch(32).repeat()
 
-    model = tf.keras.Sequential([
-        tf.keras.Input(shape=(4,), name='features'),
-        tf.keras.layers.Dense(10, activation=tf.nn.relu),
-        tf.keras.layers.Dense(10, activation=tf.nn.relu),
-        tf.keras.layers.Dense(3),
-        tf.keras.layers.Softmax(),
+    model = tf_keras.Sequential([
+        tf_keras.Input(shape=(4,), name='features'),
+        tf_keras.layers.Dense(10, activation=tf.nn.relu),
+        tf_keras.layers.Dense(10, activation=tf.nn.relu),
+        tf_keras.layers.Dense(3),
+        tf_keras.layers.Softmax(),
     ])
 
     trainer = single_task_trainer.SingleTaskTrainer(
         train_ds,
         label_key='label',
         model=model,
-        loss_fn=tf.keras.losses.sparse_categorical_crossentropy,
-        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01))
+        loss_fn=tf_keras.losses.sparse_categorical_crossentropy,
+        optimizer=tf_keras.optimizers.SGD(learning_rate=0.01))
 
     controller = orbit.Controller(
         trainer=trainer,
         steps_per_loop=100,
         global_step=trainer.optimizer.iterations)
 
     controller.train(1)
```

### Comparing `tf-models-no-deps-2.11.2/orbit/runner.py` & `tf-models-no-deps-2.16.0/orbit/runner.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Provides AbstractTrainer/Evaluator base classes, defining train/eval APIs."""
 
 import abc
 
 from typing import Dict, Optional, Union
 
 import numpy as np
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 Output = Dict[str, Union[tf.Tensor, float, np.number, np.ndarray, 'Output']]  # pytype: disable=not-supported-yet
 
 
 class AbstractTrainer(tf.Module, metaclass=abc.ABCMeta):
   """An abstract class defining the API required for training."""
```

### Comparing `tf-models-no-deps-2.11.2/orbit/standard_runner.py` & `tf-models-no-deps-2.16.0/orbit/standard_runner.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -38,15 +38,15 @@
 from typing import Any, Optional
 
 import dataclasses
 
 from orbit import runner
 from orbit.utils import loop_fns
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 @dataclasses.dataclass(frozen=True)
 class StandardTrainerOptions:
   """Advanced options for `orbit.StandardTrainer`.
 
   Attributes:
```

### Comparing `tf-models-no-deps-2.11.2/orbit/standard_runner_test.py` & `tf-models-no-deps-2.16.0/orbit/standard_runner_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -15,15 +15,15 @@
 """Tests for orbit.standard_runner."""
 
 from absl.testing import parameterized
 
 from orbit import standard_runner
 from orbit import utils
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def dataset_fn(input_context=None):
   del input_context
 
   def dummy_data(_):
     return tf.zeros((1, 1), dtype=tf.float32)
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/__init__.py` & `tf-models-no-deps-2.16.0/orbit/utils/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/common.py` & `tf-models-no-deps-2.16.0/orbit/utils/common.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Some layered modules/functions to help users writing custom training loop."""
 
 import inspect
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def create_global_step() -> tf.Variable:
   """Creates a `tf.Variable` suitable for use as a global step counter.
 
   Creating and managing a global step variable may be necessary for
   `AbstractTrainer` subclasses that perform multiple parameter updates per
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/common_test.py` & `tf-models-no-deps-2.16.0/orbit/utils/common_test.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for orbit.utils.common."""
 
 from orbit.utils import common
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class UtilsTest(tf.test.TestCase):
 
   def test_create_global_step(self):
     step = common.create_global_step()
     self.assertEqual(step.name, "global_step:0")
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/epoch_helper.py` & `tf-models-no-deps-2.16.0/orbit/utils/epoch_helper.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Provides a utility class for training in epochs."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class EpochHelper:
   """A helper class handle bookkeeping of epochs in custom training loops."""
 
   def __init__(self, epoch_steps: int, global_step: tf.Variable):
     """Initializes the `EpochHelper` instance.
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/loop_fns.py` & `tf-models-no-deps-2.16.0/orbit/utils/loop_fns.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Utilities for creating loop functions."""
 
 from absl import logging
 from orbit.utils import tpu_summaries
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 def create_loop_fn(step_fn):
   """Creates a loop function driven by a Python `while` loop.
 
   Args:
     step_fn: A function taking a nested structure of `tf.data.Iterator` or
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/summary_manager.py` & `tf-models-no-deps-2.16.0/orbit/utils/summary_manager.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -14,15 +14,15 @@
 
 """Provides a utility class for managing summary writing."""
 
 import os
 
 from orbit.utils.summary_manager_interface import SummaryManagerInterface
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class SummaryManager(SummaryManagerInterface):
   """A utility class for managing summary writing."""
 
   def __init__(self, summary_dir, summary_fn, global_step=None):
     """Initializes the `SummaryManager` instance.
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/summary_manager_interface.py` & `tf-models-no-deps-2.16.0/orbit/utils/summary_manager_interface.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/tpu_summaries.py` & `tf-models-no-deps-2.16.0/orbit/utils/tpu_summaries.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,15 +13,15 @@
 # limitations under the License.
 
 """Contains utilities for TPU summary optimization."""
 
 import contextlib
 import functools
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 @contextlib.contextmanager
 def _soft_device_placement():
   """Context manager for soft device placement, allowing summaries on CPU."""
   original_setting = tf.config.get_soft_device_placement()
   try:
```

### Comparing `tf-models-no-deps-2.11.2/orbit/utils/tpu_summaries_test.py` & `tf-models-no-deps-2.16.0/orbit/utils/tpu_summaries_test.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The Orbit Authors. All Rights Reserved.
+# Copyright 2024 The Orbit Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -16,15 +16,15 @@
 
 import functools
 import os
 
 from orbit.utils import common
 from orbit.utils import tpu_summaries
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 
 
 class TrainFunctionWithSummaries(tpu_summaries.OptionalSummariesFunction):
   """Implements a two-program approach for summaries on TPU."""
 
   def __call__(self, num_steps):
     if tf.summary.should_record_summaries():
```

### Comparing `tf-models-no-deps-2.11.2/tensorflow_models/__init__.py` & `tf-models-no-deps-2.16.0/tensorflow_models/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/tensorflow_models/nlp/__init__.py` & `tf-models-no-deps-2.16.0/tensorflow_models/nlp/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/tensorflow_models/tensorflow_models_test.py` & `tf-models-no-deps-2.16.0/tensorflow_models/tensorflow_models_test.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -10,15 +10,15 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """Tests for tensorflow_models imports."""
 
-import tensorflow as tf
+import tensorflow as tf, tf_keras
 import tensorflow_models as tfm
 
 
 class TensorflowModelsTest(tf.test.TestCase):
 
   def testVisionImport(self):
     _ = tfm.vision.layers.SqueezeExcitation(
```

### Comparing `tf-models-no-deps-2.11.2/tensorflow_models/vision/__init__.py` & `tf-models-no-deps-2.16.0/tensorflow_models/vision/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-# Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+# Copyright 2024 The TensorFlow Authors. All Rights Reserved.
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `tf-models-no-deps-2.11.2/tf_models_no_deps.egg-info/PKG-INFO` & `tf-models-no-deps-2.16.0/tf_models_no_deps.egg-info/PKG-INFO`

 * *Files 21% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 Metadata-Version: 2.1
 Name: tf-models-no-deps
-Version: 2.11.2
+Version: 2.16.0
 Summary: TensorFlow Official Models
 Home-page: https://github.com/tensorflow/models
 Author: Google Inc.
 Author-email: packages@tensorflow.org
 License: Apache 2.0
-Platform: UNKNOWN
 Requires-Python: >=3.7
 License-File: LICENSE
 License-File: AUTHORS
 
 The TensorFlow official models are a collection of
 models that use TensorFlow's high-level APIs.
 They are intended to be well-maintained, tested, and kept up to date with the
 latest TensorFlow API. They should also be reasonably optimized for fast
 performance while still being easy to read.
-
```

### Comparing `tf-models-no-deps-2.11.2/tf_models_no_deps.egg-info/SOURCES.txt` & `tf-models-no-deps-2.16.0/tf_models_no_deps.egg-info/SOURCES.txt`

 * *Files 16% similar despite different names*

```diff
@@ -228,15 +228,17 @@
 official/modeling/multitask/task_sampler_test.py
 official/modeling/multitask/test_utils.py
 official/modeling/multitask/train_lib.py
 official/modeling/multitask/train_lib_test.py
 official/modeling/optimization/__init__.py
 official/modeling/optimization/adafactor_optimizer.py
 official/modeling/optimization/ema_optimizer.py
-official/modeling/optimization/lars_optimizer.py
+official/modeling/optimization/lamb.py
+official/modeling/optimization/lamb_test.py
+official/modeling/optimization/lars.py
 official/modeling/optimization/legacy_adamw.py
 official/modeling/optimization/lr_schedule.py
 official/modeling/optimization/lr_schedule_test.py
 official/modeling/optimization/optimizer_factory.py
 official/modeling/optimization/optimizer_factory_test.py
 official/modeling/optimization/slide_optimizer.py
 official/modeling/optimization/configs/__init__.py
@@ -276,14 +278,15 @@
 official/nlp/data/data_loader_factory_test.py
 official/nlp/data/dual_encoder_dataloader.py
 official/nlp/data/dual_encoder_dataloader_test.py
 official/nlp/data/pretrain_dataloader.py
 official/nlp/data/pretrain_dataloader_test.py
 official/nlp/data/pretrain_dynamic_dataloader.py
 official/nlp/data/pretrain_dynamic_dataloader_test.py
+official/nlp/data/pretrain_text_dataloader.py
 official/nlp/data/question_answering_dataloader.py
 official/nlp/data/question_answering_dataloader_test.py
 official/nlp/data/sentence_prediction_dataloader.py
 official/nlp/data/sentence_prediction_dataloader_test.py
 official/nlp/data/sentence_retrieval_lib.py
 official/nlp/data/squad_lib.py
 official/nlp/data/squad_lib_sp.py
@@ -405,14 +408,16 @@
 official/nlp/modeling/networks/funnel_transformer_test.py
 official/nlp/modeling/networks/mobile_bert_encoder.py
 official/nlp/modeling/networks/mobile_bert_encoder_test.py
 official/nlp/modeling/networks/packed_sequence_embedding.py
 official/nlp/modeling/networks/packed_sequence_embedding_test.py
 official/nlp/modeling/networks/span_labeling.py
 official/nlp/modeling/networks/span_labeling_test.py
+official/nlp/modeling/networks/sparse_mixer.py
+official/nlp/modeling/networks/sparse_mixer_test.py
 official/nlp/modeling/networks/xlnet_base.py
 official/nlp/modeling/networks/xlnet_base_test.py
 official/nlp/modeling/ops/__init__.py
 official/nlp/modeling/ops/beam_search.py
 official/nlp/modeling/ops/beam_search_test.py
 official/nlp/modeling/ops/decoding_module.py
 official/nlp/modeling/ops/decoding_module_test.py
@@ -483,14 +488,15 @@
 official/projects/centernet/modeling/heads/__init__.py
 official/projects/centernet/modeling/heads/centernet_head.py
 official/projects/centernet/modeling/heads/centernet_head_test.py
 official/projects/centernet/modeling/layers/__init__.py
 official/projects/centernet/modeling/layers/cn_nn_blocks.py
 official/projects/centernet/modeling/layers/cn_nn_blocks_test.py
 official/projects/centernet/modeling/layers/detection_generator.py
+official/projects/centernet/modeling/layers/detection_generator_test.py
 official/projects/centernet/ops/__init__.py
 official/projects/centernet/ops/box_list.py
 official/projects/centernet/ops/box_list_ops.py
 official/projects/centernet/ops/loss_ops.py
 official/projects/centernet/ops/nms_ops.py
 official/projects/centernet/ops/preprocess_ops.py
 official/projects/centernet/ops/target_assigner.py
@@ -520,14 +526,33 @@
 official/projects/deepmac_maskrcnn/modeling/heads/instance_heads_test.py
 official/projects/deepmac_maskrcnn/serving/__init__.py
 official/projects/deepmac_maskrcnn/serving/detection.py
 official/projects/deepmac_maskrcnn/serving/detection_test.py
 official/projects/deepmac_maskrcnn/serving/export_saved_model.py
 official/projects/deepmac_maskrcnn/tasks/__init__.py
 official/projects/deepmac_maskrcnn/tasks/deep_mask_head_rcnn.py
+official/projects/maxvit/__init__.py
+official/projects/maxvit/registry_imports.py
+official/projects/maxvit/train.py
+official/projects/maxvit/train_test.py
+official/projects/maxvit/configs/__init__.py
+official/projects/maxvit/configs/backbones.py
+official/projects/maxvit/configs/image_classification.py
+official/projects/maxvit/configs/image_classification_test.py
+official/projects/maxvit/configs/rcnn.py
+official/projects/maxvit/configs/rcnn_test.py
+official/projects/maxvit/configs/retinanet.py
+official/projects/maxvit/configs/retinanet_test.py
+official/projects/maxvit/configs/semantic_segmentation.py
+official/projects/maxvit/configs/semantic_segmentation_test.py
+official/projects/maxvit/modeling/__init__.py
+official/projects/maxvit/modeling/common_ops.py
+official/projects/maxvit/modeling/layers.py
+official/projects/maxvit/modeling/maxvit.py
+official/projects/maxvit/modeling/maxvit_test.py
 official/projects/mobilebert/__init__.py
 official/projects/mobilebert/distillation.py
 official/projects/mobilebert/distillation_test.py
 official/projects/mobilebert/export_tfhub.py
 official/projects/mobilebert/model_utils.py
 official/projects/mobilebert/run_distillation.py
 official/projects/mobilebert/tf2_model_checkpoint_converter.py
@@ -570,14 +595,87 @@
 official/projects/panoptic/train.py
 official/projects/panoptic/configs/__init__.py
 official/projects/panoptic/configs/panoptic_deeplab.py
 official/projects/panoptic/configs/panoptic_maskrcnn.py
 official/projects/panoptic/tasks/__init__.py
 official/projects/panoptic/tasks/panoptic_deeplab.py
 official/projects/panoptic/tasks/panoptic_maskrcnn.py
+official/projects/qat/__init__.py
+official/projects/qat/nlp/__init__.py
+official/projects/qat/nlp/pretrained_checkpoint_converter.py
+official/projects/qat/nlp/registry_imports.py
+official/projects/qat/nlp/train.py
+official/projects/qat/nlp/configs/__init__.py
+official/projects/qat/nlp/configs/finetuning_experiments.py
+official/projects/qat/nlp/modeling/__init__.py
+official/projects/qat/nlp/modeling/layers/__init__.py
+official/projects/qat/nlp/modeling/layers/mobile_bert_layers.py
+official/projects/qat/nlp/modeling/layers/multi_head_attention.py
+official/projects/qat/nlp/modeling/layers/transformer_encoder_block.py
+official/projects/qat/nlp/modeling/layers/transformer_encoder_block_test.py
+official/projects/qat/nlp/modeling/models/__init__.py
+official/projects/qat/nlp/modeling/models/bert_span_labeler.py
+official/projects/qat/nlp/modeling/networks/__init__.py
+official/projects/qat/nlp/modeling/networks/span_labeling.py
+official/projects/qat/nlp/quantization/__init__.py
+official/projects/qat/nlp/quantization/configs.py
+official/projects/qat/nlp/quantization/configs_test.py
+official/projects/qat/nlp/quantization/helper.py
+official/projects/qat/nlp/quantization/schemes.py
+official/projects/qat/nlp/quantization/wrappers.py
+official/projects/qat/nlp/tasks/__init__.py
+official/projects/qat/nlp/tasks/question_answering.py
+official/projects/qat/nlp/tasks/question_answering_test.py
+official/projects/qat/vision/__init__.py
+official/projects/qat/vision/registry_imports.py
+official/projects/qat/vision/train.py
+official/projects/qat/vision/configs/__init__.py
+official/projects/qat/vision/configs/common.py
+official/projects/qat/vision/configs/image_classification.py
+official/projects/qat/vision/configs/image_classification_test.py
+official/projects/qat/vision/configs/retinanet.py
+official/projects/qat/vision/configs/retinanet_test.py
+official/projects/qat/vision/configs/semantic_segmentation.py
+official/projects/qat/vision/configs/semantic_segmentation_test.py
+official/projects/qat/vision/modeling/__init__.py
+official/projects/qat/vision/modeling/factory.py
+official/projects/qat/vision/modeling/factory_test.py
+official/projects/qat/vision/modeling/segmentation_model.py
+official/projects/qat/vision/modeling/heads/__init__.py
+official/projects/qat/vision/modeling/heads/dense_prediction_heads.py
+official/projects/qat/vision/modeling/heads/dense_prediction_heads_test.py
+official/projects/qat/vision/modeling/layers/__init__.py
+official/projects/qat/vision/modeling/layers/nn_blocks.py
+official/projects/qat/vision/modeling/layers/nn_blocks_test.py
+official/projects/qat/vision/modeling/layers/nn_layers.py
+official/projects/qat/vision/modeling/layers/nn_layers_test.py
+official/projects/qat/vision/n_bit/__init__.py
+official/projects/qat/vision/n_bit/configs.py
+official/projects/qat/vision/n_bit/configs_test.py
+official/projects/qat/vision/n_bit/nn_blocks.py
+official/projects/qat/vision/n_bit/nn_blocks_test.py
+official/projects/qat/vision/n_bit/nn_layers.py
+official/projects/qat/vision/n_bit/schemes.py
+official/projects/qat/vision/quantization/__init__.py
+official/projects/qat/vision/quantization/configs.py
+official/projects/qat/vision/quantization/configs_test.py
+official/projects/qat/vision/quantization/helper.py
+official/projects/qat/vision/quantization/helper_test.py
+official/projects/qat/vision/quantization/layer_transforms.py
+official/projects/qat/vision/quantization/schemes.py
+official/projects/qat/vision/serving/__init__.py
+official/projects/qat/vision/serving/export_module.py
+official/projects/qat/vision/serving/export_saved_model.py
+official/projects/qat/vision/serving/export_tflite.py
+official/projects/qat/vision/tasks/__init__.py
+official/projects/qat/vision/tasks/image_classification.py
+official/projects/qat/vision/tasks/image_classification_test.py
+official/projects/qat/vision/tasks/retinanet.py
+official/projects/qat/vision/tasks/retinanet_test.py
+official/projects/qat/vision/tasks/semantic_segmentation.py
 official/projects/roformer/__init__.py
 official/projects/roformer/roformer.py
 official/projects/roformer/roformer_attention.py
 official/projects/roformer/roformer_attention_test.py
 official/projects/roformer/roformer_encoder.py
 official/projects/roformer/roformer_encoder_block.py
 official/projects/roformer/roformer_encoder_block_test.py
@@ -600,51 +698,128 @@
 official/projects/triviaqa/inputs.py
 official/projects/triviaqa/modeling.py
 official/projects/triviaqa/predict.py
 official/projects/triviaqa/prediction.py
 official/projects/triviaqa/preprocess.py
 official/projects/triviaqa/sentencepiece_pb2.py
 official/projects/triviaqa/train.py
+official/projects/video_ssl/__init__.py
+official/projects/video_ssl/train.py
+official/projects/video_ssl/configs/__init__.py
+official/projects/video_ssl/configs/video_ssl.py
+official/projects/video_ssl/configs/video_ssl_test.py
+official/projects/video_ssl/dataloaders/__init__.py
+official/projects/video_ssl/dataloaders/video_ssl_input.py
+official/projects/video_ssl/dataloaders/video_ssl_input_test.py
+official/projects/video_ssl/losses/__init__.py
+official/projects/video_ssl/losses/losses.py
+official/projects/video_ssl/modeling/__init__.py
+official/projects/video_ssl/modeling/video_ssl_model.py
+official/projects/video_ssl/ops/__init__.py
+official/projects/video_ssl/ops/video_ssl_preprocess_ops.py
+official/projects/video_ssl/ops/video_ssl_preprocess_ops_test.py
+official/projects/video_ssl/tasks/__init__.py
+official/projects/video_ssl/tasks/linear_eval.py
+official/projects/video_ssl/tasks/pretrain.py
+official/projects/video_ssl/tasks/pretrain_test.py
+official/projects/volumetric_models/__init__.py
+official/projects/volumetric_models/registry_imports.py
+official/projects/volumetric_models/train.py
+official/projects/volumetric_models/train_test.py
+official/projects/volumetric_models/configs/__init__.py
+official/projects/volumetric_models/configs/backbones.py
+official/projects/volumetric_models/configs/decoders.py
+official/projects/volumetric_models/configs/semantic_segmentation_3d.py
+official/projects/volumetric_models/configs/semantic_segmentation_3d_test.py
+official/projects/volumetric_models/dataloaders/__init__.py
+official/projects/volumetric_models/dataloaders/segmentation_input_3d.py
+official/projects/volumetric_models/dataloaders/segmentation_input_3d_test.py
+official/projects/volumetric_models/evaluation/__init__.py
+official/projects/volumetric_models/evaluation/segmentation_metrics.py
+official/projects/volumetric_models/evaluation/segmentation_metrics_test.py
+official/projects/volumetric_models/losses/__init__.py
+official/projects/volumetric_models/losses/segmentation_losses.py
+official/projects/volumetric_models/losses/segmentation_losses_test.py
+official/projects/volumetric_models/modeling/__init__.py
+official/projects/volumetric_models/modeling/factory.py
+official/projects/volumetric_models/modeling/factory_test.py
+official/projects/volumetric_models/modeling/nn_blocks_3d.py
+official/projects/volumetric_models/modeling/nn_blocks_3d_test.py
+official/projects/volumetric_models/modeling/segmentation_model_test.py
+official/projects/volumetric_models/modeling/backbones/__init__.py
+official/projects/volumetric_models/modeling/backbones/unet_3d.py
+official/projects/volumetric_models/modeling/backbones/unet_3d_test.py
+official/projects/volumetric_models/modeling/decoders/__init__.py
+official/projects/volumetric_models/modeling/decoders/factory.py
+official/projects/volumetric_models/modeling/decoders/factory_test.py
+official/projects/volumetric_models/modeling/decoders/unet_3d_decoder.py
+official/projects/volumetric_models/modeling/decoders/unet_3d_decoder_test.py
+official/projects/volumetric_models/modeling/heads/__init__.py
+official/projects/volumetric_models/modeling/heads/segmentation_heads_3d.py
+official/projects/volumetric_models/modeling/heads/segmentation_heads_3d_test.py
+official/projects/volumetric_models/serving/__init__.py
+official/projects/volumetric_models/serving/export_saved_model.py
+official/projects/volumetric_models/serving/semantic_segmentation_3d.py
+official/projects/volumetric_models/serving/semantic_segmentation_3d_test.py
+official/projects/volumetric_models/tasks/__init__.py
+official/projects/volumetric_models/tasks/semantic_segmentation_3d.py
+official/projects/volumetric_models/tasks/semantic_segmentation_3d_test.py
+official/projects/waste_identification_ml/__init__.py
+official/projects/waste_identification_ml/data_generation/__init__.py
+official/projects/waste_identification_ml/data_generation/utils.py
+official/projects/waste_identification_ml/data_generation/utils_test.py
 official/projects/yolo/__init__.py
 official/projects/yolo/train.py
 official/projects/yolo/common/__init__.py
 official/projects/yolo/common/registry_imports.py
 official/projects/yolo/configs/__init__.py
 official/projects/yolo/configs/backbones.py
 official/projects/yolo/configs/darknet_classification.py
 official/projects/yolo/configs/decoders.py
 official/projects/yolo/configs/yolo.py
+official/projects/yolo/configs/yolov7.py
 official/projects/yolo/dataloaders/__init__.py
 official/projects/yolo/dataloaders/classification_input.py
 official/projects/yolo/dataloaders/tf_example_decoder.py
 official/projects/yolo/dataloaders/yolo_input.py
 official/projects/yolo/losses/__init__.py
 official/projects/yolo/losses/yolo_loss.py
 official/projects/yolo/losses/yolo_loss_test.py
+official/projects/yolo/losses/yolov7_loss.py
+official/projects/yolo/losses/yolov7_loss_test.py
 official/projects/yolo/modeling/__init__.py
 official/projects/yolo/modeling/factory.py
+official/projects/yolo/modeling/factory_test.py
 official/projects/yolo/modeling/yolo_model.py
+official/projects/yolo/modeling/yolov7_model.py
 official/projects/yolo/modeling/backbones/__init__.py
 official/projects/yolo/modeling/backbones/darknet.py
 official/projects/yolo/modeling/backbones/darknet_test.py
+official/projects/yolo/modeling/backbones/yolov7.py
+official/projects/yolo/modeling/backbones/yolov7_test.py
 official/projects/yolo/modeling/decoders/__init__.py
 official/projects/yolo/modeling/decoders/yolo_decoder.py
 official/projects/yolo/modeling/decoders/yolo_decoder_test.py
+official/projects/yolo/modeling/decoders/yolov7.py
+official/projects/yolo/modeling/decoders/yolov7_test.py
 official/projects/yolo/modeling/heads/__init__.py
 official/projects/yolo/modeling/heads/yolo_head.py
 official/projects/yolo/modeling/heads/yolo_head_test.py
+official/projects/yolo/modeling/heads/yolov7_head.py
+official/projects/yolo/modeling/heads/yolov7_head_test.py
 official/projects/yolo/modeling/layers/__init__.py
 official/projects/yolo/modeling/layers/detection_generator.py
 official/projects/yolo/modeling/layers/detection_generator_test.py
 official/projects/yolo/modeling/layers/nn_blocks.py
 official/projects/yolo/modeling/layers/nn_blocks_test.py
 official/projects/yolo/ops/__init__.py
 official/projects/yolo/ops/anchor.py
 official/projects/yolo/ops/box_ops.py
 official/projects/yolo/ops/box_ops_test.py
+official/projects/yolo/ops/initializer_ops.py
 official/projects/yolo/ops/kmeans_anchors.py
 official/projects/yolo/ops/kmeans_anchors_test.py
 official/projects/yolo/ops/loss_utils.py
 official/projects/yolo/ops/math_ops.py
 official/projects/yolo/ops/mosaic.py
 official/projects/yolo/ops/preprocessing_ops.py
 official/projects/yolo/ops/preprocessing_ops_test.py
@@ -653,30 +828,40 @@
 official/projects/yolo/optimization/sgd_torch.py
 official/projects/yolo/optimization/configs/__init__.py
 official/projects/yolo/optimization/configs/optimization_config.py
 official/projects/yolo/optimization/configs/optimizer_config.py
 official/projects/yolo/serving/__init__.py
 official/projects/yolo/serving/export_module_factory.py
 official/projects/yolo/serving/export_saved_model.py
+official/projects/yolo/serving/export_tflite.py
 official/projects/yolo/serving/model_fn.py
 official/projects/yolo/tasks/__init__.py
 official/projects/yolo/tasks/image_classification.py
 official/projects/yolo/tasks/task_utils.py
 official/projects/yolo/tasks/yolo.py
+official/projects/yolo/tasks/yolov7.py
 official/projects/yt8m/__init__.py
 official/projects/yt8m/train.py
 official/projects/yt8m/train_test.py
 official/projects/yt8m/configs/__init__.py
 official/projects/yt8m/configs/yt8m.py
 official/projects/yt8m/configs/yt8m_test.py
 official/projects/yt8m/modeling/__init__.py
 official/projects/yt8m/modeling/nn_layers.py
+official/projects/yt8m/modeling/nn_layers_test.py
 official/projects/yt8m/modeling/yt8m_model.py
 official/projects/yt8m/modeling/yt8m_model_test.py
 official/projects/yt8m/modeling/yt8m_model_utils.py
+official/projects/yt8m/modeling/yt8m_model_utils_test.py
+official/projects/yt8m/modeling/backbones/__init__.py
+official/projects/yt8m/modeling/backbones/dbof.py
+official/projects/yt8m/modeling/backbones/dbof_test.py
+official/projects/yt8m/modeling/heads/__init__.py
+official/projects/yt8m/modeling/heads/logistic.py
+official/projects/yt8m/modeling/heads/moe.py
 official/projects/yt8m/tasks/__init__.py
 official/projects/yt8m/tasks/yt8m_task.py
 official/recommendation/__init__.py
 official/recommendation/constants.py
 official/recommendation/create_ncf_data.py
 official/recommendation/data_pipeline.py
 official/recommendation/data_preprocessing.py
@@ -776,29 +961,33 @@
 official/vision/dataloaders/utils_test.py
 official/vision/dataloaders/video_input.py
 official/vision/dataloaders/video_input_test.py
 official/vision/evaluation/__init__.py
 official/vision/evaluation/coco_evaluator.py
 official/vision/evaluation/coco_utils.py
 official/vision/evaluation/coco_utils_test.py
+official/vision/evaluation/instance_metrics.py
+official/vision/evaluation/instance_metrics_test.py
 official/vision/evaluation/iou.py
 official/vision/evaluation/iou_test.py
 official/vision/evaluation/panoptic_quality.py
 official/vision/evaluation/panoptic_quality_evaluator.py
 official/vision/evaluation/panoptic_quality_evaluator_test.py
 official/vision/evaluation/panoptic_quality_test.py
 official/vision/evaluation/segmentation_metrics.py
 official/vision/evaluation/segmentation_metrics_test.py
 official/vision/evaluation/wod_detection_evaluator.py
 official/vision/losses/__init__.py
 official/vision/losses/focal_loss.py
 official/vision/losses/loss_utils.py
 official/vision/losses/maskrcnn_losses.py
+official/vision/losses/maskrcnn_losses_test.py
 official/vision/losses/retinanet_losses.py
 official/vision/losses/segmentation_losses.py
+official/vision/losses/segmentation_losses_test.py
 official/vision/modeling/__init__.py
 official/vision/modeling/classification_model.py
 official/vision/modeling/classification_model_test.py
 official/vision/modeling/factory.py
 official/vision/modeling/factory_3d.py
 official/vision/modeling/factory_test.py
 official/vision/modeling/maskrcnn_model.py
@@ -851,14 +1040,16 @@
 official/vision/modeling/heads/segmentation_heads_test.py
 official/vision/modeling/layers/__init__.py
 official/vision/modeling/layers/box_sampler.py
 official/vision/modeling/layers/deeplab.py
 official/vision/modeling/layers/deeplab_test.py
 official/vision/modeling/layers/detection_generator.py
 official/vision/modeling/layers/detection_generator_test.py
+official/vision/modeling/layers/edgetpu.py
+official/vision/modeling/layers/edgetpu_test.py
 official/vision/modeling/layers/mask_sampler.py
 official/vision/modeling/layers/nn_blocks.py
 official/vision/modeling/layers/nn_blocks_3d.py
 official/vision/modeling/layers/nn_blocks_3d_test.py
 official/vision/modeling/layers/nn_blocks_test.py
 official/vision/modeling/layers/nn_layers.py
 official/vision/modeling/layers/nn_layers_test.py
@@ -899,31 +1090,33 @@
 official/vision/serving/export_module_factory.py
 official/vision/serving/export_module_factory_test.py
 official/vision/serving/export_saved_model.py
 official/vision/serving/export_saved_model_lib.py
 official/vision/serving/export_saved_model_lib_test.py
 official/vision/serving/export_saved_model_lib_v2.py
 official/vision/serving/export_tfhub.py
+official/vision/serving/export_tfhub_lib.py
 official/vision/serving/export_tflite.py
 official/vision/serving/export_tflite_lib.py
-official/vision/serving/export_tflite_lib_test.py
 official/vision/serving/export_utils.py
 official/vision/serving/image_classification.py
 official/vision/serving/image_classification_test.py
 official/vision/serving/semantic_segmentation.py
 official/vision/serving/semantic_segmentation_test.py
 official/vision/serving/video_classification.py
 official/vision/serving/video_classification_test.py
 official/vision/tasks/__init__.py
 official/vision/tasks/image_classification.py
 official/vision/tasks/maskrcnn.py
 official/vision/tasks/retinanet.py
 official/vision/tasks/semantic_segmentation.py
 official/vision/tasks/video_classification.py
 official/vision/utils/__init__.py
+official/vision/utils/ops_test.py
+official/vision/utils/summary_manager.py
 official/vision/utils/object_detection/__init__.py
 official/vision/utils/object_detection/argmax_matcher.py
 official/vision/utils/object_detection/balanced_positive_negative_sampler.py
 official/vision/utils/object_detection/box_coder.py
 official/vision/utils/object_detection/box_list.py
 official/vision/utils/object_detection/box_list_ops.py
 official/vision/utils/object_detection/faster_rcnn_box_coder.py
@@ -944,14 +1137,15 @@
 orbit/actions/__init__.py
 orbit/actions/conditional_action.py
 orbit/actions/conditional_action_test.py
 orbit/actions/export_saved_model.py
 orbit/actions/export_saved_model_test.py
 orbit/actions/new_best_metric.py
 orbit/actions/new_best_metric_test.py
+orbit/actions/save_checkpoint_if_preempted.py
 orbit/examples/__init__.py
 orbit/examples/single_task/__init__.py
 orbit/examples/single_task/single_task_evaluator.py
 orbit/examples/single_task/single_task_evaluator_test.py
 orbit/examples/single_task/single_task_trainer.py
 orbit/examples/single_task/single_task_trainer_test.py
 orbit/utils/__init__.py
```


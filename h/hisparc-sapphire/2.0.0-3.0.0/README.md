# Comparing `tmp/hisparc-sapphire-2.0.0.tar.gz` & `tmp/hisparc_sapphire-3.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "hisparc-sapphire-2.0.0.tar", last modified: Fri Aug  5 19:44:15 2022, max compression
+gzip compressed data, was "hisparc_sapphire-3.0.0.tar", last modified: Fri Jan  1 00:00:00 2016, max compression
```

## Comparing `hisparc-sapphire-2.0.0.tar` & `hisparc_sapphire-3.0.0.tar`

### file list

```diff
@@ -1,1711 +1,1793 @@
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.954448 hisparc-sapphire-2.0.0/
--rw-r--r--   0 arne       (501) staff       (20)    35149 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/LICENSE
--rw-r--r--   0 arne       (501) staff       (20)     4346 2022-08-05 19:44:15.954673 hisparc-sapphire-2.0.0/PKG-INFO
--rw-r--r--   0 arne       (501) staff       (20)     3581 2022-08-05 18:25:15.000000 hisparc-sapphire-2.0.0/README.rst
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.621171 hisparc-sapphire-2.0.0/hisparc_sapphire.egg-info/
--rw-r--r--   0 arne       (501) staff       (20)     4346 2022-08-05 19:44:15.000000 hisparc-sapphire-2.0.0/hisparc_sapphire.egg-info/PKG-INFO
--rw-r--r--   0 arne       (501) staff       (20)    58078 2022-08-05 19:44:15.000000 hisparc-sapphire-2.0.0/hisparc_sapphire.egg-info/SOURCES.txt
--rw-r--r--   0 arne       (501) staff       (20)        1 2022-08-05 19:44:15.000000 hisparc-sapphire-2.0.0/hisparc_sapphire.egg-info/dependency_links.txt
--rw-r--r--   0 arne       (501) staff       (20)      468 2022-08-05 19:44:15.000000 hisparc-sapphire-2.0.0/hisparc_sapphire.egg-info/entry_points.txt
--rw-r--r--   0 arne       (501) staff       (20)      120 2022-08-05 19:44:15.000000 hisparc-sapphire-2.0.0/hisparc_sapphire.egg-info/requires.txt
--rw-r--r--   0 arne       (501) staff       (20)        9 2022-08-05 19:44:15.000000 hisparc-sapphire-2.0.0/hisparc_sapphire.egg-info/top_level.txt
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.624764 hisparc-sapphire-2.0.0/sapphire/
--rw-r--r--   0 arne       (501) staff       (20)     4644 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/__init__.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.627735 hisparc-sapphire-2.0.0/sapphire/analysis/
--rw-r--r--   0 arne       (501) staff       (20)     2327 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/__init__.py
--rw-r--r--   0 arne       (501) staff       (20)    15840 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/calibration.py
--rwxr-xr-x   0 arne       (501) staff       (20)    14706 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/coincidence_queries.py
--rw-r--r--   0 arne       (501) staff       (20)    32178 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/coincidences.py
--rw-r--r--   0 arne       (501) staff       (20)    19598 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/core_reconstruction.py
--rw-r--r--   0 arne       (501) staff       (20)    49848 2022-07-30 13:03:41.000000 hisparc-sapphire-2.0.0/sapphire/analysis/direction_reconstruction.py
--rw-r--r--   0 arne       (501) staff       (20)     7043 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/analysis/event_utils.py
--rw-r--r--   0 arne       (501) staff       (20)     5144 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/find_mpv.py
--rw-r--r--   0 arne       (501) staff       (20)     6161 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/landau.py
--rw-r--r--   0 arne       (501) staff       (20)    44125 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/process_events.py
--rw-r--r--   0 arne       (501) staff       (20)    13936 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/process_traces.py
--rw-r--r--   0 arne       (501) staff       (20)    28838 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/analysis/reconstructions.py
--rw-r--r--   0 arne       (501) staff       (20)     6727 2022-07-30 13:03:41.000000 hisparc-sapphire-2.0.0/sapphire/analysis/time_deltas.py
--rw-r--r--   0 arne       (501) staff       (20)    35683 2022-07-17 19:56:58.000000 hisparc-sapphire-2.0.0/sapphire/api.py
--rw-r--r--   0 arne       (501) staff       (20)    32576 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/clusters.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.630080 hisparc-sapphire-2.0.0/sapphire/corsika/
--rw-r--r--   0 arne       (501) staff       (20)     1466 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/corsika/LICENSE
--rw-r--r--   0 arne       (501) staff       (20)     1119 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/__init__.py
--rw-r--r--   0 arne       (501) staff       (20)    20957 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/blocks.py
--rwxr-xr-x   0 arne       (501) staff       (20)     6874 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/corsika_queries.py
--rw-r--r--   0 arne       (501) staff       (20)     7152 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/generate_corsika_overview.py
--rw-r--r--   0 arne       (501) staff       (20)     6575 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/mergesort.py
--rw-r--r--   0 arne       (501) staff       (20)    11030 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/particles.py
--rw-r--r--   0 arne       (501) staff       (20)    14167 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/qsub_corsika.py
--rw-r--r--   0 arne       (501) staff       (20)     4880 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/qsub_store_corsika_data.py
--rw-r--r--   0 arne       (501) staff       (20)    14554 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/reader.py
--rw-r--r--   0 arne       (501) staff       (20)     8573 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/corsika/store_corsika_data.py
--rw-r--r--   0 arne       (501) staff       (20)     5895 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/corsika/units.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.631756 hisparc-sapphire-2.0.0/sapphire/data/
--rw-r--r--   0 arne       (501) staff       (20)      395 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/data/__init__.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.634772 hisparc-sapphire-2.0.0/sapphire/data/clusters/
--rw-r--r--   0 arne       (501) staff       (20)      445 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/0.json
--rw-r--r--   0 arne       (501) staff       (20)      130 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/1000.json
--rw-r--r--   0 arne       (501) staff       (20)       68 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/11000.json
--rw-r--r--   0 arne       (501) staff       (20)       65 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/12000.json
--rw-r--r--   0 arne       (501) staff       (20)      452 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/13000.json
--rw-r--r--   0 arne       (501) staff       (20)       69 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/14000.json
--rw-r--r--   0 arne       (501) staff       (20)       65 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/15000.json
--rw-r--r--   0 arne       (501) staff       (20)      130 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/16000.json
--rw-r--r--   0 arne       (501) staff       (20)       65 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/17000.json
--rw-r--r--   0 arne       (501) staff       (20)      194 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/2000.json
--rw-r--r--   0 arne       (501) staff       (20)       65 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/20000.json
--rw-r--r--   0 arne       (501) staff       (20)      540 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/3000.json
--rw-r--r--   0 arne       (501) staff       (20)       67 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/4000.json
--rw-r--r--   0 arne       (501) staff       (20)       67 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/40000.json
--rw-r--r--   0 arne       (501) staff       (20)       73 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/50000.json
--rw-r--r--   0 arne       (501) staff       (20)       67 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/60000.json
--rw-r--r--   0 arne       (501) staff       (20)      447 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/7000.json
--rw-r--r--   0 arne       (501) staff       (20)       68 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/70000.json
--rw-r--r--   0 arne       (501) staff       (20)      322 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters/8000.json
--rw-r--r--   0 arne       (501) staff       (20)     1227 2022-08-05 15:47:32.000000 hisparc-sapphire-2.0.0/sapphire/data/clusters.json
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.636011 hisparc-sapphire-2.0.0/sapphire/data/countries/
--rw-r--r--   0 arne       (501) staff       (20)      447 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/countries/0.json
--rw-r--r--   0 arne       (501) staff       (20)      452 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/countries/10000.json
--rw-r--r--   0 arne       (501) staff       (20)       65 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/countries/20000.json
--rw-r--r--   0 arne       (501) staff       (20)        2 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/countries/30000.json
--rw-r--r--   0 arne       (501) staff       (20)       67 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/countries/40000.json
--rw-r--r--   0 arne       (501) staff       (20)       73 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/countries/50000.json
--rw-r--r--   0 arne       (501) staff       (20)       67 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/countries/60000.json
--rw-r--r--   0 arne       (501) staff       (20)       68 2022-08-05 15:48:00.000000 hisparc-sapphire-2.0.0/sapphire/data/countries/70000.json
--rw-r--r--   0 arne       (501) staff       (20)      530 2022-08-05 15:47:32.000000 hisparc-sapphire-2.0.0/sapphire/data/countries.json
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.679065 hisparc-sapphire-2.0.0/sapphire/data/current/
--rw-r--r--   0 arne       (501) staff       (20)      435 2022-08-05 15:49:56.000000 hisparc-sapphire-2.0.0/sapphire/data/current/10.tsv
--rw-r--r--   0 arne       (501) staff       (20)    11900 2022-08-05 15:51:00.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      124 2022-08-05 15:51:00.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      341 2022-08-05 15:51:00.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       35 2022-08-05 15:51:00.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1005.tsv
--rw-r--r--   0 arne       (501) staff       (20)    33298 2022-08-05 15:51:01.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1006.tsv
--rw-r--r--   0 arne       (501) staff       (20)    20956 2022-08-05 15:51:02.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1007.tsv
--rw-r--r--   0 arne       (501) staff       (20)    17278 2022-08-05 15:51:03.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1008.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6218 2022-08-05 15:51:03.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1009.tsv
--rw-r--r--   0 arne       (501) staff       (20)     9951 2022-08-05 15:50:06.000000 hisparc-sapphire-2.0.0/sapphire/data/current/101.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7101 2022-08-05 15:51:03.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1010.tsv
--rw-r--r--   0 arne       (501) staff       (20)   114328 2022-08-05 15:50:10.000000 hisparc-sapphire-2.0.0/sapphire/data/current/102.tsv
--rw-r--r--   0 arne       (501) staff       (20)      227 2022-08-05 15:50:10.000000 hisparc-sapphire-2.0.0/sapphire/data/current/103.tsv
--rw-r--r--   0 arne       (501) staff       (20)    44052 2022-08-05 15:50:11.000000 hisparc-sapphire-2.0.0/sapphire/data/current/104.tsv
--rw-r--r--   0 arne       (501) staff       (20)    31930 2022-08-05 15:50:13.000000 hisparc-sapphire-2.0.0/sapphire/data/current/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28148 2022-08-05 15:50:13.000000 hisparc-sapphire-2.0.0/sapphire/data/current/106.tsv
--rw-r--r--   0 arne       (501) staff       (20)    60654 2022-08-05 15:51:05.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    56404 2022-08-05 15:51:07.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    37290 2022-08-05 15:51:08.000000 hisparc-sapphire-2.0.0/sapphire/data/current/1103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      620 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/12001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      651 2022-08-05 15:49:56.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13.tsv
--rw-r--r--   0 arne       (501) staff       (20)      506 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      558 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13002.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2275 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      620 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13004.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1643 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      231 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       33 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      132 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      713 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      589 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      806 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       66 2022-08-05 15:51:47.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13103.tsv
--rw-r--r--   0 arne       (501) staff       (20)    26721 2022-08-05 15:51:47.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13104.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1395 2022-08-05 15:51:48.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      310 2022-08-05 15:51:48.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       33 2022-08-05 15:51:48.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      231 2022-08-05 15:51:48.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      264 2022-08-05 15:51:48.000000 hisparc-sapphire-2.0.0/sapphire/data/current/13601.tsv
--rw-r--r--   0 arne       (501) staff       (20)    37662 2022-08-05 15:51:49.000000 hisparc-sapphire-2.0.0/sapphire/data/current/14001.tsv
--rw-r--r--   0 arne       (501) staff       (20)     9834 2022-08-05 15:51:49.000000 hisparc-sapphire-2.0.0/sapphire/data/current/14002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    50490 2022-08-05 15:51:51.000000 hisparc-sapphire-2.0.0/sapphire/data/current/14003.tsv
--rw-r--r--   0 arne       (501) staff       (20)    39930 2022-08-05 15:51:52.000000 hisparc-sapphire-2.0.0/sapphire/data/current/14004.tsv
--rw-r--r--   0 arne       (501) staff       (20)    16467 2022-08-05 15:51:53.000000 hisparc-sapphire-2.0.0/sapphire/data/current/14005.tsv
--rw-r--r--   0 arne       (501) staff       (20)    31251 2022-08-05 15:51:54.000000 hisparc-sapphire-2.0.0/sapphire/data/current/14006.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6897 2022-08-05 15:51:54.000000 hisparc-sapphire-2.0.0/sapphire/data/current/14007.tsv
--rw-r--r--   0 arne       (501) staff       (20)    31119 2022-08-05 15:51:55.000000 hisparc-sapphire-2.0.0/sapphire/data/current/14008.tsv
--rw-r--r--   0 arne       (501) staff       (20)    90354 2022-08-05 15:49:59.000000 hisparc-sapphire-2.0.0/sapphire/data/current/15.tsv
--rw-r--r--   0 arne       (501) staff       (20)      857 2022-08-05 15:51:55.000000 hisparc-sapphire-2.0.0/sapphire/data/current/15001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      297 2022-08-05 15:51:55.000000 hisparc-sapphire-2.0.0/sapphire/data/current/15002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    15906 2022-08-05 15:51:56.000000 hisparc-sapphire-2.0.0/sapphire/data/current/16001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    15510 2022-08-05 15:51:56.000000 hisparc-sapphire-2.0.0/sapphire/data/current/16101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    23661 2022-08-05 15:51:57.000000 hisparc-sapphire-2.0.0/sapphire/data/current/17001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      354 2022-08-05 15:49:49.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2.tsv
--rw-r--r--   0 arne       (501) staff       (20)    20119 2022-08-05 15:51:58.000000 hisparc-sapphire-2.0.0/sapphire/data/current/20001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    19747 2022-08-05 15:51:59.000000 hisparc-sapphire-2.0.0/sapphire/data/current/20002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    16337 2022-08-05 15:51:59.000000 hisparc-sapphire-2.0.0/sapphire/data/current/20003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      341 2022-08-05 15:51:08.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      620 2022-08-05 15:51:08.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:51:08.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      257 2022-08-05 15:51:08.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      496 2022-08-05 15:51:08.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      217 2022-08-05 15:51:08.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2006.tsv
--rw-r--r--   0 arne       (501) staff       (20)      155 2022-08-05 15:51:08.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2008.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32589 2022-08-05 15:50:15.000000 hisparc-sapphire-2.0.0/sapphire/data/current/201.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28996 2022-08-05 15:51:09.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2010.tsv
--rw-r--r--   0 arne       (501) staff       (20)    62560 2022-08-05 15:50:17.000000 hisparc-sapphire-2.0.0/sapphire/data/current/202.tsv
--rw-r--r--   0 arne       (501) staff       (20)    46686 2022-08-05 15:50:18.000000 hisparc-sapphire-2.0.0/sapphire/data/current/203.tsv
--rw-r--r--   0 arne       (501) staff       (20)    55880 2022-08-05 15:50:01.000000 hisparc-sapphire-2.0.0/sapphire/data/current/21.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1440 2022-08-05 15:51:10.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2101.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3069 2022-08-05 15:51:10.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       31 2022-08-05 15:51:10.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2103.tsv
--rw-r--r--   0 arne       (501) staff       (20)    36166 2022-08-05 15:50:02.000000 hisparc-sapphire-2.0.0/sapphire/data/current/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)      992 2022-08-05 15:51:10.000000 hisparc-sapphire-2.0.0/sapphire/data/current/2201.tsv
--rw-r--r--   0 arne       (501) staff       (20)    64878 2022-08-05 15:50:04.000000 hisparc-sapphire-2.0.0/sapphire/data/current/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)    51329 2022-08-05 15:50:06.000000 hisparc-sapphire-2.0.0/sapphire/data/current/24.tsv
--rw-r--r--   0 arne       (501) staff       (20)       33 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/current/25.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2519 2022-08-05 15:49:50.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3.tsv
--rw-r--r--   0 arne       (501) staff       (20)    43320 2022-08-05 15:51:11.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    34451 2022-08-05 15:51:12.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    54095 2022-08-05 15:50:20.000000 hisparc-sapphire-2.0.0/sapphire/data/current/301.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6417 2022-08-05 15:50:20.000000 hisparc-sapphire-2.0.0/sapphire/data/current/303.tsv
--rw-r--r--   0 arne       (501) staff       (20)    33148 2022-08-05 15:50:21.000000 hisparc-sapphire-2.0.0/sapphire/data/current/304.tsv
--rw-r--r--   0 arne       (501) staff       (20)    51065 2022-08-05 15:50:23.000000 hisparc-sapphire-2.0.0/sapphire/data/current/305.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1155 2022-08-05 15:51:13.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      639 2022-08-05 15:51:13.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       93 2022-08-05 15:51:13.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      945 2022-08-05 15:51:13.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3104.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4247 2022-08-05 15:51:13.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3105.tsv
--rw-r--r--   0 arne       (501) staff       (20)    35062 2022-08-05 15:51:14.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      713 2022-08-05 15:51:14.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3202.tsv
--rw-r--r--   0 arne       (501) staff       (20)      531 2022-08-05 15:51:14.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3203.tsv
--rw-r--r--   0 arne       (501) staff       (20)    27172 2022-08-05 15:51:15.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      248 2022-08-05 15:51:15.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3302.tsv
--rw-r--r--   0 arne       (501) staff       (20)    10015 2022-08-05 15:51:16.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3303.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12995 2022-08-05 15:51:16.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3304.tsv
--rw-r--r--   0 arne       (501) staff       (20)      341 2022-08-05 15:51:16.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3401.tsv
--rw-r--r--   0 arne       (501) staff       (20)    42537 2022-08-05 15:51:18.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3501.tsv
--rw-r--r--   0 arne       (501) staff       (20)    47850 2022-08-05 15:51:19.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      363 2022-08-05 15:51:19.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3701.tsv
--rw-r--r--   0 arne       (501) staff       (20)    21179 2022-08-05 15:51:20.000000 hisparc-sapphire-2.0.0/sapphire/data/current/3702.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28312 2022-08-05 15:49:51.000000 hisparc-sapphire-2.0.0/sapphire/data/current/4.tsv
--rw-r--r--   0 arne       (501) staff       (20)    15708 2022-08-05 15:52:00.000000 hisparc-sapphire-2.0.0/sapphire/data/current/40001.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1085 2022-08-05 15:51:20.000000 hisparc-sapphire-2.0.0/sapphire/data/current/4001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       93 2022-08-05 15:51:20.000000 hisparc-sapphire-2.0.0/sapphire/data/current/4002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      473 2022-08-05 15:51:20.000000 hisparc-sapphire-2.0.0/sapphire/data/current/4003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      310 2022-08-05 15:51:20.000000 hisparc-sapphire-2.0.0/sapphire/data/current/4004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      881 2022-08-05 15:50:23.000000 hisparc-sapphire-2.0.0/sapphire/data/current/401.tsv
--rw-r--r--   0 arne       (501) staff       (20)    40114 2022-08-05 15:49:52.000000 hisparc-sapphire-2.0.0/sapphire/data/current/5.tsv
--rw-r--r--   0 arne       (501) staff       (20)    78080 2022-08-05 15:50:26.000000 hisparc-sapphire-2.0.0/sapphire/data/current/501.tsv
--rw-r--r--   0 arne       (501) staff       (20)    52284 2022-08-05 15:50:27.000000 hisparc-sapphire-2.0.0/sapphire/data/current/502.tsv
--rw-r--r--   0 arne       (501) staff       (20)    47942 2022-08-05 15:50:29.000000 hisparc-sapphire-2.0.0/sapphire/data/current/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)    49104 2022-08-05 15:50:31.000000 hisparc-sapphire-2.0.0/sapphire/data/current/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)    44330 2022-08-05 15:50:32.000000 hisparc-sapphire-2.0.0/sapphire/data/current/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)      899 2022-08-05 15:50:32.000000 hisparc-sapphire-2.0.0/sapphire/data/current/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)    58769 2022-08-05 15:50:34.000000 hisparc-sapphire-2.0.0/sapphire/data/current/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)    51593 2022-08-05 15:50:36.000000 hisparc-sapphire-2.0.0/sapphire/data/current/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    44330 2022-08-05 15:50:38.000000 hisparc-sapphire-2.0.0/sapphire/data/current/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)    79638 2022-08-05 15:50:40.000000 hisparc-sapphire-2.0.0/sapphire/data/current/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)    47185 2022-08-05 15:50:42.000000 hisparc-sapphire-2.0.0/sapphire/data/current/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)    48668 2022-08-05 15:50:43.000000 hisparc-sapphire-2.0.0/sapphire/data/current/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)    43834 2022-08-05 15:50:45.000000 hisparc-sapphire-2.0.0/sapphire/data/current/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)    33480 2022-08-05 15:50:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)      231 2022-08-05 15:50:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       70 2022-08-05 15:50:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)   278566 2022-08-05 15:50:55.000000 hisparc-sapphire-2.0.0/sapphire/data/current/599.tsv
--rw-r--r--   0 arne       (501) staff       (20)    67315 2022-08-05 15:49:54.000000 hisparc-sapphire-2.0.0/sapphire/data/current/6.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4619 2022-08-05 15:52:00.000000 hisparc-sapphire-2.0.0/sapphire/data/current/60001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    47401 2022-08-05 15:50:57.000000 hisparc-sapphire-2.0.0/sapphire/data/current/601.tsv
--rw-r--r--   0 arne       (501) staff       (20)    46134 2022-08-05 15:50:58.000000 hisparc-sapphire-2.0.0/sapphire/data/current/602.tsv
--rw-r--r--   0 arne       (501) staff       (20)    29766 2022-08-05 15:50:59.000000 hisparc-sapphire-2.0.0/sapphire/data/current/603.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7359 2022-08-05 15:50:59.000000 hisparc-sapphire-2.0.0/sapphire/data/current/604.tsv
--rw-r--r--   0 arne       (501) staff       (20)    13516 2022-08-05 15:49:54.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7.tsv
--rw-r--r--   0 arne       (501) staff       (20)    41433 2022-08-05 15:51:22.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    34472 2022-08-05 15:51:23.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    37975 2022-08-05 15:51:24.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      186 2022-08-05 15:51:24.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    41975 2022-08-05 15:51:26.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       62 2022-08-05 15:51:26.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7201.tsv
--rw-r--r--   0 arne       (501) staff       (20)    42243 2022-08-05 15:51:27.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7301.tsv
--rw-r--r--   0 arne       (501) staff       (20)    26598 2022-08-05 15:51:28.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       62 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7501.tsv
--rw-r--r--   0 arne       (501) staff       (20)    44616 2022-08-05 15:51:30.000000 hisparc-sapphire-2.0.0/sapphire/data/current/7601.tsv
--rw-r--r--   0 arne       (501) staff       (20)    53662 2022-08-05 15:51:31.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      403 2022-08-05 15:51:31.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    44395 2022-08-05 15:51:33.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8003.tsv
--rw-r--r--   0 arne       (501) staff       (20)    60819 2022-08-05 15:51:35.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8004.tsv
--rw-r--r--   0 arne       (501) staff       (20)    37016 2022-08-05 15:51:37.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8005.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6541 2022-08-05 15:51:37.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8006.tsv
--rw-r--r--   0 arne       (501) staff       (20)      406 2022-08-05 15:51:37.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8007.tsv
--rw-r--r--   0 arne       (501) staff       (20)    57164 2022-08-05 15:51:39.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8008.tsv
--rw-r--r--   0 arne       (501) staff       (20)    57477 2022-08-05 15:51:41.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8009.tsv
--rw-r--r--   0 arne       (501) staff       (20)     5146 2022-08-05 15:51:41.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      217 2022-08-05 15:51:41.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8102.tsv
--rw-r--r--   0 arne       (501) staff       (20)      465 2022-08-05 15:51:41.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      403 2022-08-05 15:51:41.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8104.tsv
--rw-r--r--   0 arne       (501) staff       (20)    24743 2022-08-05 15:51:42.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8105.tsv
--rw-r--r--   0 arne       (501) staff       (20)    19532 2022-08-05 15:51:43.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      558 2022-08-05 15:51:43.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      248 2022-08-05 15:51:43.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8302.tsv
--rw-r--r--   0 arne       (501) staff       (20)      558 2022-08-05 15:51:44.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8303.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28117 2022-08-05 15:51:46.000000 hisparc-sapphire-2.0.0/sapphire/data/current/8401.tsv
--rw-r--r--   0 arne       (501) staff       (20)    46384 2022-08-05 15:49:56.000000 hisparc-sapphire-2.0.0/sapphire/data/current/9.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.724686 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/
--rw-r--r--   0 arne       (501) staff       (20)    16690 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/10.tsv
--rw-r--r--   0 arne       (501) staff       (20)    18164 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      565 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    23315 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1003.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1030 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1005.tsv
--rw-r--r--   0 arne       (501) staff       (20)    50861 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1006.tsv
--rw-r--r--   0 arne       (501) staff       (20)    36503 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1007.tsv
--rw-r--r--   0 arne       (501) staff       (20)    31520 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1008.tsv
--rw-r--r--   0 arne       (501) staff       (20)    42878 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1009.tsv
--rw-r--r--   0 arne       (501) staff       (20)    51750 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12547 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1010.tsv
--rw-r--r--   0 arne       (501) staff       (20)    49084 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    19742 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/103.tsv
--rw-r--r--   0 arne       (501) staff       (20)    50987 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/104.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32180 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)    13167 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/106.tsv
--rw-r--r--   0 arne       (501) staff       (20)    21551 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    43444 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    15550 2022-08-05 15:52:35.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/12001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    39790 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13.tsv
--rw-r--r--   0 arne       (501) staff       (20)    26897 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13001.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4369 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13002.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4730 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13003.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2482 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13004.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3589 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      195 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13006.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1123 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      167 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13009.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4970 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    11481 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13102.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3372 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13103.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7085 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13104.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4849 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:52:41.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      517 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13501.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1945 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13601.tsv
--rw-r--r--   0 arne       (501) staff       (20)    52421 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    20550 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    19099 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14003.tsv
--rw-r--r--   0 arne       (501) staff       (20)    14938 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14004.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7125 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14005.tsv
--rw-r--r--   0 arne       (501) staff       (20)    16849 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14006.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2337 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      111 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14008.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32848 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/15.tsv
--rw-r--r--   0 arne       (501) staff       (20)    17039 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/15001.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1698 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/15002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    10740 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/16001.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6106 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/16101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    25658 2022-08-05 15:52:42.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/17001.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3418 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12264 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/20001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    15319 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/20002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12663 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/20003.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2008 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2002.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1066 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      194 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2004.tsv
--rw-r--r--   0 arne       (501) staff       (20)    11110 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2005.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6800 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2006.tsv
--rw-r--r--   0 arne       (501) staff       (20)    14658 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2008.tsv
--rw-r--r--   0 arne       (501) staff       (20)   110840 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/201.tsv
--rw-r--r--   0 arne       (501) staff       (20)    25716 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2010.tsv
--rw-r--r--   0 arne       (501) staff       (20)    49839 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/202.tsv
--rw-r--r--   0 arne       (501) staff       (20)    30167 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/203.tsv
--rw-r--r--   0 arne       (501) staff       (20)    27411 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/21.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1943 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2103.tsv
--rw-r--r--   0 arne       (501) staff       (20)    61157 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)    13878 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2201.tsv
--rw-r--r--   0 arne       (501) staff       (20)    29926 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28484 2022-08-05 15:52:31.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/24.tsv
--rw-r--r--   0 arne       (501) staff       (20)    35232 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3.tsv
--rw-r--r--   0 arne       (501) staff       (20)    34657 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32015 2022-08-05 15:52:36.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32552 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/301.tsv
--rw-r--r--   0 arne       (501) staff       (20)    25569 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/303.tsv
--rw-r--r--   0 arne       (501) staff       (20)    40547 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/304.tsv
--rw-r--r--   0 arne       (501) staff       (20)    41803 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/305.tsv
--rw-r--r--   0 arne       (501) staff       (20)    35581 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    23763 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3102.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4625 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3103.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7347 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3104.tsv
--rw-r--r--   0 arne       (501) staff       (20)    11197 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3105.tsv
--rw-r--r--   0 arne       (501) staff       (20)    98737 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3201.tsv
--rw-r--r--   0 arne       (501) staff       (20)    61228 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3202.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4263 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3203.tsv
--rw-r--r--   0 arne       (501) staff       (20)    41548 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3301.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32379 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3302.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28702 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3303.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4571 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3304.tsv
--rw-r--r--   0 arne       (501) staff       (20)    16134 2022-08-05 15:52:37.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3401.tsv
--rw-r--r--   0 arne       (501) staff       (20)    21939 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3501.tsv
--rw-r--r--   0 arne       (501) staff       (20)    19166 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3601.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2328 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3701.tsv
--rw-r--r--   0 arne       (501) staff       (20)    15750 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3702.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7747 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1871 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/40001.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4440 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4001.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2997 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4002.tsv
--rw-r--r--   0 arne       (501) staff       (20)     8873 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4003.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32523 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4004.tsv
--rw-r--r--   0 arne       (501) staff       (20)    27371 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/401.tsv
--rw-r--r--   0 arne       (501) staff       (20)    38038 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/5.tsv
--rw-r--r--   0 arne       (501) staff       (20)   121084 2022-08-05 15:52:32.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/501.tsv
--rw-r--r--   0 arne       (501) staff       (20)   114120 2022-08-05 15:52:33.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/502.tsv
--rw-r--r--   0 arne       (501) staff       (20)   105890 2022-08-05 15:52:33.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)   111766 2022-08-05 15:52:33.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)   118263 2022-08-05 15:52:33.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)    52508 2022-08-05 15:52:33.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)   129482 2022-08-05 15:52:33.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)    66220 2022-08-05 15:52:33.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    95239 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)    71767 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)    54252 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)    35191 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)    37225 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)    29121 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)      143 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       83 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)      244 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/599.tsv
--rw-r--r--   0 arne       (501) staff       (20)    30320 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/6.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1543 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/60001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    64359 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/601.tsv
--rw-r--r--   0 arne       (501) staff       (20)    16125 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/602.tsv
--rw-r--r--   0 arne       (501) staff       (20)    11909 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/603.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3188 2022-08-05 15:52:34.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/604.tsv
--rw-r--r--   0 arne       (501) staff       (20)    22653 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28257 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    34441 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    38080 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)    27031 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7101.tsv
--rw-r--r--   0 arne       (501) staff       (20)    14430 2022-08-05 15:52:38.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    39557 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7201.tsv
--rw-r--r--   0 arne       (501) staff       (20)    63151 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7301.tsv
--rw-r--r--   0 arne       (501) staff       (20)    34570 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7501.tsv
--rw-r--r--   0 arne       (501) staff       (20)     5296 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7601.tsv
--rw-r--r--   0 arne       (501) staff       (20)    59554 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8001.tsv
--rw-r--r--   0 arne       (501) staff       (20)    29174 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8002.tsv
--rw-r--r--   0 arne       (501) staff       (20)   102127 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8003.tsv
--rw-r--r--   0 arne       (501) staff       (20)    39079 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8004.tsv
--rw-r--r--   0 arne       (501) staff       (20)    23893 2022-08-05 15:52:39.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8005.tsv
--rw-r--r--   0 arne       (501) staff       (20)    43523 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8006.tsv
--rw-r--r--   0 arne       (501) staff       (20)    10633 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8007.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28620 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8008.tsv
--rw-r--r--   0 arne       (501) staff       (20)    40837 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8009.tsv
--rw-r--r--   0 arne       (501) staff       (20)    35875 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8101.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2475 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    51405 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8103.tsv
--rw-r--r--   0 arne       (501) staff       (20)     8438 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8104.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32005 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8105.tsv
--rw-r--r--   0 arne       (501) staff       (20)    23531 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8201.tsv
--rw-r--r--   0 arne       (501) staff       (20)    10930 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8301.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2199 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8302.tsv
--rw-r--r--   0 arne       (501) staff       (20)    13844 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8303.tsv
--rw-r--r--   0 arne       (501) staff       (20)    11348 2022-08-05 15:52:40.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8401.tsv
--rw-r--r--   0 arne       (501) staff       (20)   100829 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/9.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.750984 hisparc-sapphire-2.0.0/sapphire/data/electronics/
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:02.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/10.tsv
--rw-r--r--   0 arne       (501) staff       (20)       70 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       25 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:15.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1007.tsv
--rw-r--r--   0 arne       (501) staff       (20)       70 2022-08-05 15:52:15.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       69 2022-08-05 15:52:15.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      329 2022-08-05 15:52:03.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:15.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1010.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:04.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:04.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:04.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/104.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:05.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:05.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/106.tsv
--rw-r--r--   0 arne       (501) staff       (20)      168 2022-08-05 15:52:15.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      175 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       96 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/1103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/12001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:02.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13004.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       25 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13007.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13009.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       25 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       49 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13104.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       22 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       50 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13501.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/13601.tsv
--rw-r--r--   0 arne       (501) staff       (20)       49 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/14001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       74 2022-08-05 15:52:27.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/14002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      196 2022-08-05 15:52:28.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/14003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:28.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/14004.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:28.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/14005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:28.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/14006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:28.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/14007.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:28.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/14008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       96 2022-08-05 15:52:02.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/15.tsv
--rw-r--r--   0 arne       (501) staff       (20)      120 2022-08-05 15:52:28.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/15001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:29.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/15002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:29.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/16001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:29.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/16101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:29.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/17001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:00.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2.tsv
--rw-r--r--   0 arne       (501) staff       (20)       22 2022-08-05 15:52:29.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/20001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:29.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/20002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       22 2022-08-05 15:52:29.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/20003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2004.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:05.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2010.tsv
--rw-r--r--   0 arne       (501) staff       (20)      165 2022-08-05 15:52:05.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/202.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:05.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/203.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:03.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/21.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:16.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:03.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/2201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      122 2022-08-05 15:52:03.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)      321 2022-08-05 15:52:03.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/24.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/25.tsv
--rw-r--r--   0 arne       (501) staff       (20)       94 2022-08-05 15:52:00.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3.tsv
--rw-r--r--   0 arne       (501) staff       (20)       95 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       72 2022-08-05 15:52:06.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:06.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/303.tsv
--rw-r--r--   0 arne       (501) staff       (20)       71 2022-08-05 15:52:06.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/304.tsv
--rw-r--r--   0 arne       (501) staff       (20)       69 2022-08-05 15:52:06.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/305.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3104.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:17.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3105.tsv
--rw-r--r--   0 arne       (501) staff       (20)      221 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       43 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3202.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3203.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3302.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3303.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3304.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:18.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      144 2022-08-05 15:52:19.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3601.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:19.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3701.tsv
--rw-r--r--   0 arne       (501) staff       (20)       69 2022-08-05 15:52:19.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/3702.tsv
--rw-r--r--   0 arne       (501) staff       (20)      119 2022-08-05 15:52:00.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/4.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:29.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/40001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:19.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/4001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:19.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/4002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:19.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/4003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:19.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/4004.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:06.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:01.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/5.tsv
--rw-r--r--   0 arne       (501) staff       (20)      421 2022-08-05 15:52:07.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      273 2022-08-05 15:52:07.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/502.tsv
--rw-r--r--   0 arne       (501) staff       (20)       96 2022-08-05 15:52:07.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)      265 2022-08-05 15:52:08.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)      119 2022-08-05 15:52:08.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)       73 2022-08-05 15:52:08.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)      184 2022-08-05 15:52:08.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)      298 2022-08-05 15:52:10.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)       74 2022-08-05 15:52:10.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)      300 2022-08-05 15:52:10.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)      125 2022-08-05 15:52:11.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)      100 2022-08-05 15:52:11.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       75 2022-08-05 15:52:11.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)      148 2022-08-05 15:52:11.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:11.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:11.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)      583 2022-08-05 15:52:13.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/599.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:01.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/6.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:30.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/60001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       92 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/601.tsv
--rw-r--r--   0 arne       (501) staff       (20)       96 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/602.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/603.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:14.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/604.tsv
--rw-r--r--   0 arne       (501) staff       (20)      263 2022-08-05 15:52:01.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:19.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:20.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:20.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:20.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:20.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:20.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       95 2022-08-05 15:52:20.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:20.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7501.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:21.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/7601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      162 2022-08-05 15:52:21.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:21.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       95 2022-08-05 15:52:21.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       92 2022-08-05 15:52:22.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8004.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:22.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       95 2022-08-05 15:52:22.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:22.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8007.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:22.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8009.tsv
--rw-r--r--   0 arne       (501) staff       (20)       70 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       46 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8104.tsv
--rw-r--r--   0 arne       (501) staff       (20)       48 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8105.tsv
--rw-r--r--   0 arne       (501) staff       (20)       23 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:23.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8302.tsv
--rw-r--r--   0 arne       (501) staff       (20)       24 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8303.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:52:26.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/8401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      543 2022-08-05 15:52:01.000000 hisparc-sapphire-2.0.0/sapphire/data/electronics/9.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1506 2022-07-30 12:46:49.000000 hisparc-sapphire-2.0.0/sapphire/data/extend_local_data.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.778020 hisparc-sapphire-2.0.0/sapphire/data/gps/
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:03.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/10.tsv
--rw-r--r--   0 arne       (501) staff       (20)      266 2022-08-05 15:48:19.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:19.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:19.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:19.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:19.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1006.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3649 2022-08-05 15:48:20.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      230 2022-08-05 15:48:20.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:20.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:05.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:20.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1010.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:06.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       76 2022-08-05 15:48:06.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       76 2022-08-05 15:48:07.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      494 2022-08-05 15:48:07.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:07.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/106.tsv
--rw-r--r--   0 arne       (501) staff       (20)      722 2022-08-05 15:48:21.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:21.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)      418 2022-08-05 15:48:21.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/1103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      240 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/12001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:03.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13.tsv
--rw-r--r--   0 arne       (501) staff       (20)      240 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      480 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      200 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      120 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      200 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      156 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       80 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13009.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      200 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      160 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      240 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       80 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      120 2022-08-05 15:48:37.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/13601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      600 2022-08-05 15:48:38.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/14001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      160 2022-08-05 15:48:38.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/14002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      120 2022-08-05 15:48:39.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/14003.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1080 2022-08-05 15:48:39.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/14004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      200 2022-08-05 15:48:39.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/14005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       80 2022-08-05 15:48:39.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/14006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       80 2022-08-05 15:48:39.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/14007.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:48:40.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/14008.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6802 2022-08-05 15:48:04.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/15.tsv
--rw-r--r--   0 arne       (501) staff       (20)      559 2022-08-05 15:48:40.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/15001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      120 2022-08-05 15:48:40.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/15002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      156 2022-08-05 15:48:40.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/16001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      160 2022-08-05 15:48:40.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/16101.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7488 2022-08-05 15:48:41.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/17001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:01.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2.tsv
--rw-r--r--   0 arne       (501) staff       (20)      278 2022-08-05 15:48:41.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/20001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      119 2022-08-05 15:48:41.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/20002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      159 2022-08-05 15:48:41.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/20003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      156 2022-08-05 15:48:21.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       76 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      418 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2006.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:07.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      456 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2010.tsv
--rw-r--r--   0 arne       (501) staff       (20)      798 2022-08-05 15:48:08.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/202.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3230 2022-08-05 15:48:09.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/203.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:04.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/21.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      494 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:22.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:04.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)      570 2022-08-05 15:48:23.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/2201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      418 2022-08-05 15:48:05.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1178 2022-08-05 15:48:05.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/24.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/25.tsv
--rw-r--r--   0 arne       (501) staff       (20)      380 2022-08-05 15:48:01.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3.tsv
--rw-r--r--   0 arne       (501) staff       (20)      342 2022-08-05 15:48:23.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      266 2022-08-05 15:48:23.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:09.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      266 2022-08-05 15:48:09.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/303.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:09.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/304.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:10.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/305.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:23.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:23.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:23.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:23.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:24.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3105.tsv
--rw-r--r--   0 arne       (501) staff       (20)      380 2022-08-05 15:48:24.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:24.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3202.tsv
--rw-r--r--   0 arne       (501) staff       (20)      456 2022-08-05 15:48:24.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3203.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:24.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:24.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3302.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:24.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3303.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:25.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3304.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:25.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      342 2022-08-05 15:48:25.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3501.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1444 2022-08-05 15:48:26.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:26.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3701.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:26.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/3702.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1596 2022-08-05 15:48:01.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/4.tsv
--rw-r--r--   0 arne       (501) staff       (20)      546 2022-08-05 15:48:41.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/40001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      229 2022-08-05 15:48:26.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/4001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:26.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/4002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:26.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/4003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      266 2022-08-05 15:48:26.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/4004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:10.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:01.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/5.tsv
--rw-r--r--   0 arne       (501) staff       (20)      912 2022-08-05 15:48:11.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      380 2022-08-05 15:48:11.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/502.tsv
--rw-r--r--   0 arne       (501) staff       (20)      380 2022-08-05 15:48:11.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)      342 2022-08-05 15:48:12.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)      874 2022-08-05 15:48:12.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:12.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)      380 2022-08-05 15:48:13.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)      570 2022-08-05 15:48:13.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:13.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)      494 2022-08-05 15:48:14.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)       76 2022-08-05 15:48:14.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)     8588 2022-08-05 15:48:15.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:15.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:16.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:16.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:16.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2091 2022-08-05 15:48:18.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/599.tsv
--rw-r--r--   0 arne       (501) staff       (20)      266 2022-08-05 15:48:02.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/6.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:48:41.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/60001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      456 2022-08-05 15:48:18.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      418 2022-08-05 15:48:19.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/602.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:19.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/603.tsv
--rw-r--r--   0 arne       (501) staff       (20)      266 2022-08-05 15:48:19.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/604.tsv
--rw-r--r--   0 arne       (501) staff       (20)      418 2022-08-05 15:48:02.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7.tsv
--rw-r--r--   0 arne       (501) staff       (20)       77 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/70001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      418 2022-08-05 15:48:27.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      117 2022-08-05 15:48:27.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      229 2022-08-05 15:48:27.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:27.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:28.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:28.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      342 2022-08-05 15:48:28.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:28.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       77 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      190 2022-08-05 15:48:29.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/7601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      342 2022-08-05 15:48:29.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:29.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      228 2022-08-05 15:48:30.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8003.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1292 2022-08-05 15:48:30.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:31.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      456 2022-08-05 15:48:31.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8006.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:31.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      117 2022-08-05 15:48:31.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:32.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      456 2022-08-05 15:48:32.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:32.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8102.tsv
--rw-r--r--   0 arne       (501) staff       (20)      152 2022-08-05 15:48:32.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8103.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:32.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      494 2022-08-05 15:48:32.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8105.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:33.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       76 2022-08-05 15:48:33.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       76 2022-08-05 15:48:33.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8302.tsv
--rw-r--r--   0 arne       (501) staff       (20)       38 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8303.tsv
--rw-r--r--   0 arne       (501) staff       (20)      114 2022-08-05 15:48:36.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/8401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      494 2022-08-05 15:48:03.000000 hisparc-sapphire-2.0.0/sapphire/data/gps/9.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.785190 hisparc-sapphire-2.0.0/sapphire/data/layout/
--rw-r--r--   0 arne       (501) staff       (20)       99 2022-08-05 15:49:14.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/1009.tsv
--rw-r--r--   0 arne       (501) staff       (20)       83 2022-08-05 15:49:12.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:49:12.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      169 2022-08-05 15:49:12.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:49:14.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/1101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       93 2022-08-05 15:49:14.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       83 2022-08-05 15:49:18.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/13102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       99 2022-08-05 15:49:18.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/14001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:49:19.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/16001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       82 2022-08-05 15:49:14.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/2006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       91 2022-08-05 15:49:12.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       80 2022-08-05 15:49:15.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/2010.tsv
--rw-r--r--   0 arne       (501) staff       (20)      161 2022-08-05 15:49:12.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)       83 2022-08-05 15:49:12.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)       82 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/305.tsv
--rw-r--r--   0 arne       (501) staff       (20)       89 2022-08-05 15:49:15.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/3201.tsv
--rw-r--r--   0 arne       (501) staff       (20)       88 2022-08-05 15:49:11.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/4.tsv
--rw-r--r--   0 arne       (501) staff       (20)       83 2022-08-05 15:49:19.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/40001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/401.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1074 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      183 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/502.tsv
--rw-r--r--   0 arne       (501) staff       (20)       94 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)       91 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)      275 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)       87 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)      107 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)       91 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)       91 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)      278 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)       90 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       92 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)      191 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       91 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       85 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)      249 2022-08-05 15:49:11.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/6.tsv
--rw-r--r--   0 arne       (501) staff       (20)      166 2022-08-05 15:49:13.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/601.tsv
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:49:14.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/602.tsv
--rw-r--r--   0 arne       (501) staff       (20)       86 2022-08-05 15:49:16.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/7001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       88 2022-08-05 15:49:16.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/7002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       90 2022-08-05 15:49:16.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       93 2022-08-05 15:49:16.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/8003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       83 2022-08-05 15:49:17.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/8006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       91 2022-08-05 15:49:17.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/8101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       83 2022-08-05 15:49:17.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/8105.tsv
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:49:17.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/8401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       89 2022-08-05 15:49:12.000000 hisparc-sapphire-2.0.0/sapphire/data/layout/9.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.812215 hisparc-sapphire-2.0.0/sapphire/data/station/
--rw-r--r--   0 arne       (501) staff       (20)      795 2022-08-05 15:47:34.000000 hisparc-sapphire-2.0.0/sapphire/data/station/10.json
--rw-r--r--   0 arne       (501) staff       (20)      528 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1001.json
--rw-r--r--   0 arne       (501) staff       (20)      539 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1002.json
--rw-r--r--   0 arne       (501) staff       (20)      540 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1003.json
--rw-r--r--   0 arne       (501) staff       (20)      797 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1005.json
--rw-r--r--   0 arne       (501) staff       (20)      537 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1006.json
--rw-r--r--   0 arne       (501) staff       (20)      537 2022-08-05 15:47:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1007.json
--rw-r--r--   0 arne       (501) staff       (20)      534 2022-08-05 15:47:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1008.json
--rw-r--r--   0 arne       (501) staff       (20)      786 2022-08-05 15:47:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1009.json
--rw-r--r--   0 arne       (501) staff       (20)      531 2022-08-05 15:47:35.000000 hisparc-sapphire-2.0.0/sapphire/data/station/101.json
--rw-r--r--   0 arne       (501) staff       (20)      786 2022-08-05 15:47:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1010.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:35.000000 hisparc-sapphire-2.0.0/sapphire/data/station/102.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:35.000000 hisparc-sapphire-2.0.0/sapphire/data/station/103.json
--rw-r--r--   0 arne       (501) staff       (20)      530 2022-08-05 15:47:35.000000 hisparc-sapphire-2.0.0/sapphire/data/station/104.json
--rw-r--r--   0 arne       (501) staff       (20)      531 2022-08-05 15:47:36.000000 hisparc-sapphire-2.0.0/sapphire/data/station/105.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:36.000000 hisparc-sapphire-2.0.0/sapphire/data/station/106.json
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:47:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1101.json
--rw-r--r--   0 arne       (501) staff       (20)      803 2022-08-05 15:47:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1102.json
--rw-r--r--   0 arne       (501) staff       (20)      535 2022-08-05 15:47:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station/1103.json
--rw-r--r--   0 arne       (501) staff       (20)      794 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/12001.json
--rw-r--r--   0 arne       (501) staff       (20)      530 2022-08-05 15:47:34.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13.json
--rw-r--r--   0 arne       (501) staff       (20)      791 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13001.json
--rw-r--r--   0 arne       (501) staff       (20)      524 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13002.json
--rw-r--r--   0 arne       (501) staff       (20)      537 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13003.json
--rw-r--r--   0 arne       (501) staff       (20)      534 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13004.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13005.json
--rw-r--r--   0 arne       (501) staff       (20)      536 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13006.json
--rw-r--r--   0 arne       (501) staff       (20)      788 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13007.json
--rw-r--r--   0 arne       (501) staff       (20)      542 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13008.json
--rw-r--r--   0 arne       (501) staff       (20)      525 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13009.json
--rw-r--r--   0 arne       (501) staff       (20)      532 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13101.json
--rw-r--r--   0 arne       (501) staff       (20)      530 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13102.json
--rw-r--r--   0 arne       (501) staff       (20)      781 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13103.json
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13104.json
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13201.json
--rw-r--r--   0 arne       (501) staff       (20)      532 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13301.json
--rw-r--r--   0 arne       (501) staff       (20)      514 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13401.json
--rw-r--r--   0 arne       (501) staff       (20)      801 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13501.json
--rw-r--r--   0 arne       (501) staff       (20)      539 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/13601.json
--rw-r--r--   0 arne       (501) staff       (20)      808 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/14001.json
--rw-r--r--   0 arne       (501) staff       (20)      565 2022-08-05 15:47:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station/14002.json
--rw-r--r--   0 arne       (501) staff       (20)      557 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/14003.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/14004.json
--rw-r--r--   0 arne       (501) staff       (20)      531 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/14005.json
--rw-r--r--   0 arne       (501) staff       (20)      537 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/14006.json
--rw-r--r--   0 arne       (501) staff       (20)      561 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/14007.json
--rw-r--r--   0 arne       (501) staff       (20)      542 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/14008.json
--rw-r--r--   0 arne       (501) staff       (20)      525 2022-08-05 15:47:34.000000 hisparc-sapphire-2.0.0/sapphire/data/station/15.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/15001.json
--rw-r--r--   0 arne       (501) staff       (20)      544 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/15002.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/16001.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/16101.json
--rw-r--r--   0 arne       (501) staff       (20)      530 2022-08-05 15:47:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station/17001.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:32.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2.json
--rw-r--r--   0 arne       (501) staff       (20)      525 2022-08-05 15:47:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station/20001.json
--rw-r--r--   0 arne       (501) staff       (20)      525 2022-08-05 15:47:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station/20002.json
--rw-r--r--   0 arne       (501) staff       (20)      525 2022-08-05 15:47:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station/20003.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2001.json
--rw-r--r--   0 arne       (501) staff       (20)      549 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2002.json
--rw-r--r--   0 arne       (501) staff       (20)      538 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2003.json
--rw-r--r--   0 arne       (501) staff       (20)      528 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2004.json
--rw-r--r--   0 arne       (501) staff       (20)      528 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2005.json
--rw-r--r--   0 arne       (501) staff       (20)      531 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2006.json
--rw-r--r--   0 arne       (501) staff       (20)      540 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2008.json
--rw-r--r--   0 arne       (501) staff       (20)      784 2022-08-05 15:47:36.000000 hisparc-sapphire-2.0.0/sapphire/data/station/201.json
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2010.json
--rw-r--r--   0 arne       (501) staff       (20)      526 2022-08-05 15:47:37.000000 hisparc-sapphire-2.0.0/sapphire/data/station/202.json
--rw-r--r--   0 arne       (501) staff       (20)      526 2022-08-05 15:47:37.000000 hisparc-sapphire-2.0.0/sapphire/data/station/203.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:34.000000 hisparc-sapphire-2.0.0/sapphire/data/station/21.json
--rw-r--r--   0 arne       (501) staff       (20)      525 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2101.json
--rw-r--r--   0 arne       (501) staff       (20)      534 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2102.json
--rw-r--r--   0 arne       (501) staff       (20)      540 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2103.json
--rw-r--r--   0 arne       (501) staff       (20)      530 2022-08-05 15:47:34.000000 hisparc-sapphire-2.0.0/sapphire/data/station/22.json
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:47:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station/2201.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:35.000000 hisparc-sapphire-2.0.0/sapphire/data/station/23.json
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:47:35.000000 hisparc-sapphire-2.0.0/sapphire/data/station/24.json
--rw-r--r--   0 arne       (501) staff       (20)      531 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station/25.json
--rw-r--r--   0 arne       (501) staff       (20)      790 2022-08-05 15:47:33.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3.json
--rw-r--r--   0 arne       (501) staff       (20)      526 2022-08-05 15:47:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3001.json
--rw-r--r--   0 arne       (501) staff       (20)      522 2022-08-05 15:47:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3002.json
--rw-r--r--   0 arne       (501) staff       (20)      538 2022-08-05 15:47:37.000000 hisparc-sapphire-2.0.0/sapphire/data/station/301.json
--rw-r--r--   0 arne       (501) staff       (20)      531 2022-08-05 15:47:37.000000 hisparc-sapphire-2.0.0/sapphire/data/station/303.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:37.000000 hisparc-sapphire-2.0.0/sapphire/data/station/304.json
--rw-r--r--   0 arne       (501) staff       (20)      536 2022-08-05 15:47:38.000000 hisparc-sapphire-2.0.0/sapphire/data/station/305.json
--rw-r--r--   0 arne       (501) staff       (20)      786 2022-08-05 15:47:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3101.json
--rw-r--r--   0 arne       (501) staff       (20)      550 2022-08-05 15:47:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3102.json
--rw-r--r--   0 arne       (501) staff       (20)      540 2022-08-05 15:47:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3103.json
--rw-r--r--   0 arne       (501) staff       (20)      524 2022-08-05 15:47:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3104.json
--rw-r--r--   0 arne       (501) staff       (20)      531 2022-08-05 15:47:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3105.json
--rw-r--r--   0 arne       (501) staff       (20)      788 2022-08-05 15:47:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3201.json
--rw-r--r--   0 arne       (501) staff       (20)      788 2022-08-05 15:47:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3202.json
--rw-r--r--   0 arne       (501) staff       (20)      528 2022-08-05 15:47:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3203.json
--rw-r--r--   0 arne       (501) staff       (20)      534 2022-08-05 15:47:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3301.json
--rw-r--r--   0 arne       (501) staff       (20)      542 2022-08-05 15:47:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3302.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3303.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3304.json
--rw-r--r--   0 arne       (501) staff       (20)      536 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3401.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3501.json
--rw-r--r--   0 arne       (501) staff       (20)      543 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3601.json
--rw-r--r--   0 arne       (501) staff       (20)      525 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3701.json
--rw-r--r--   0 arne       (501) staff       (20)      769 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/3702.json
--rw-r--r--   0 arne       (501) staff       (20)      535 2022-08-05 15:47:33.000000 hisparc-sapphire-2.0.0/sapphire/data/station/4.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station/40001.json
--rw-r--r--   0 arne       (501) staff       (20)      515 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/4001.json
--rw-r--r--   0 arne       (501) staff       (20)      787 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/4002.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/4003.json
--rw-r--r--   0 arne       (501) staff       (20)      534 2022-08-05 15:47:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station/4004.json
--rw-r--r--   0 arne       (501) staff       (20)      786 2022-08-05 15:47:38.000000 hisparc-sapphire-2.0.0/sapphire/data/station/401.json
--rw-r--r--   0 arne       (501) staff       (20)      537 2022-08-05 15:47:33.000000 hisparc-sapphire-2.0.0/sapphire/data/station/5.json
--rw-r--r--   0 arne       (501) staff       (20)      522 2022-08-05 15:47:38.000000 hisparc-sapphire-2.0.0/sapphire/data/station/501.json
--rw-r--r--   0 arne       (501) staff       (20)      800 2022-08-05 15:47:38.000000 hisparc-sapphire-2.0.0/sapphire/data/station/502.json
--rw-r--r--   0 arne       (501) staff       (20)      785 2022-08-05 15:47:38.000000 hisparc-sapphire-2.0.0/sapphire/data/station/503.json
--rw-r--r--   0 arne       (501) staff       (20)      790 2022-08-05 15:47:39.000000 hisparc-sapphire-2.0.0/sapphire/data/station/504.json
--rw-r--r--   0 arne       (501) staff       (20)      787 2022-08-05 15:47:39.000000 hisparc-sapphire-2.0.0/sapphire/data/station/505.json
--rw-r--r--   0 arne       (501) staff       (20)      778 2022-08-05 15:47:39.000000 hisparc-sapphire-2.0.0/sapphire/data/station/506.json
--rw-r--r--   0 arne       (501) staff       (20)      805 2022-08-05 15:47:39.000000 hisparc-sapphire-2.0.0/sapphire/data/station/507.json
--rw-r--r--   0 arne       (501) staff       (20)      783 2022-08-05 15:47:39.000000 hisparc-sapphire-2.0.0/sapphire/data/station/508.json
--rw-r--r--   0 arne       (501) staff       (20)      801 2022-08-05 15:47:40.000000 hisparc-sapphire-2.0.0/sapphire/data/station/509.json
--rw-r--r--   0 arne       (501) staff       (20)      781 2022-08-05 15:47:40.000000 hisparc-sapphire-2.0.0/sapphire/data/station/510.json
--rw-r--r--   0 arne       (501) staff       (20)      777 2022-08-05 15:47:40.000000 hisparc-sapphire-2.0.0/sapphire/data/station/511.json
--rw-r--r--   0 arne       (501) staff       (20)      781 2022-08-05 15:47:40.000000 hisparc-sapphire-2.0.0/sapphire/data/station/512.json
--rw-r--r--   0 arne       (501) staff       (20)      787 2022-08-05 15:47:40.000000 hisparc-sapphire-2.0.0/sapphire/data/station/513.json
--rw-r--r--   0 arne       (501) staff       (20)      781 2022-08-05 15:47:40.000000 hisparc-sapphire-2.0.0/sapphire/data/station/514.json
--rw-r--r--   0 arne       (501) staff       (20)      532 2022-08-05 15:47:40.000000 hisparc-sapphire-2.0.0/sapphire/data/station/521.json
--rw-r--r--   0 arne       (501) staff       (20)      536 2022-08-05 15:47:40.000000 hisparc-sapphire-2.0.0/sapphire/data/station/522.json
--rw-r--r--   0 arne       (501) staff       (20)      793 2022-08-05 15:47:41.000000 hisparc-sapphire-2.0.0/sapphire/data/station/599.json
--rw-r--r--   0 arne       (501) staff       (20)      523 2022-08-05 15:47:33.000000 hisparc-sapphire-2.0.0/sapphire/data/station/6.json
--rw-r--r--   0 arne       (501) staff       (20)      535 2022-08-05 15:47:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station/60001.json
--rw-r--r--   0 arne       (501) staff       (20)      519 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/601.json
--rw-r--r--   0 arne       (501) staff       (20)      519 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/602.json
--rw-r--r--   0 arne       (501) staff       (20)      514 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/603.json
--rw-r--r--   0 arne       (501) staff       (20)      520 2022-08-05 15:47:42.000000 hisparc-sapphire-2.0.0/sapphire/data/station/604.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:33.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7.json
--rw-r--r--   0 arne       (501) staff       (20)      535 2022-08-05 15:47:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7001.json
--rw-r--r--   0 arne       (501) staff       (20)      536 2022-08-05 15:47:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7002.json
--rw-r--r--   0 arne       (501) staff       (20)      539 2022-08-05 15:47:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7003.json
--rw-r--r--   0 arne       (501) staff       (20)      523 2022-08-05 15:47:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7101.json
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:47:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7102.json
--rw-r--r--   0 arne       (501) staff       (20)      524 2022-08-05 15:47:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7201.json
--rw-r--r--   0 arne       (501) staff       (20)      789 2022-08-05 15:47:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7301.json
--rw-r--r--   0 arne       (501) staff       (20)      527 2022-08-05 15:47:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7401.json
--rw-r--r--   0 arne       (501) staff       (20)      524 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7501.json
--rw-r--r--   0 arne       (501) staff       (20)      521 2022-08-05 15:47:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station/7601.json
--rw-r--r--   0 arne       (501) staff       (20)      537 2022-08-05 15:47:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8001.json
--rw-r--r--   0 arne       (501) staff       (20)      534 2022-08-05 15:47:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8002.json
--rw-r--r--   0 arne       (501) staff       (20)      790 2022-08-05 15:47:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8003.json
--rw-r--r--   0 arne       (501) staff       (20)      536 2022-08-05 15:47:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8004.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8005.json
--rw-r--r--   0 arne       (501) staff       (20)      540 2022-08-05 15:47:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8006.json
--rw-r--r--   0 arne       (501) staff       (20)      540 2022-08-05 15:47:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8007.json
--rw-r--r--   0 arne       (501) staff       (20)      537 2022-08-05 15:47:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8008.json
--rw-r--r--   0 arne       (501) staff       (20)      537 2022-08-05 15:47:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8009.json
--rw-r--r--   0 arne       (501) staff       (20)      792 2022-08-05 15:47:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8101.json
--rw-r--r--   0 arne       (501) staff       (20)      538 2022-08-05 15:47:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8102.json
--rw-r--r--   0 arne       (501) staff       (20)      534 2022-08-05 15:47:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8103.json
--rw-r--r--   0 arne       (501) staff       (20)      533 2022-08-05 15:47:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8104.json
--rw-r--r--   0 arne       (501) staff       (20)      528 2022-08-05 15:47:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8105.json
--rw-r--r--   0 arne       (501) staff       (20)      541 2022-08-05 15:47:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8201.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8301.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8302.json
--rw-r--r--   0 arne       (501) staff       (20)      529 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8303.json
--rw-r--r--   0 arne       (501) staff       (20)      528 2022-08-05 15:47:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station/8401.json
--rw-r--r--   0 arne       (501) staff       (20)      784 2022-08-05 15:47:34.000000 hisparc-sapphire-2.0.0/sapphire/data/station/9.json
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.618513 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.812641 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1001/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1001/1005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      330 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1001/1010.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.813050 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1002/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1002/1003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1002/1008.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.813214 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1003/
--rw-r--r--   0 arne       (501) staff       (20)    21862 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1003/1008.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.813597 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1005/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1005/1010.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.813757 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1006/
--rw-r--r--   0 arne       (501) staff       (20)    30875 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1006/1007.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.814665 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/102/
--rw-r--r--   0 arne       (501) staff       (20)    12369 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/102/104.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7955 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/102/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/102/106.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.815110 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/104/
--rw-r--r--   0 arne       (501) staff       (20)     7376 2022-08-05 15:52:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/104/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/104/106.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.815326 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/105/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:45.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/105/106.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.815805 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13001/
--rw-r--r--   0 arne       (501) staff       (20)     1594 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13001/13003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13001/13008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13001/13009.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.816149 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13003/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13003/13008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13003/13009.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.816333 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13008/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13008/13009.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.816710 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/14001/
--rw-r--r--   0 arne       (501) staff       (20)     6144 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/14001/14003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/14001/14008.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.816868 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/14003/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/14003/14008.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.817176 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/15/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/15/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/15/23.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.817319 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2/15.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.817681 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/20001/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/20001/20002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/20001/20003.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.817895 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/20002/
--rw-r--r--   0 arne       (501) staff       (20)     2371 2022-08-05 15:53:03.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/20002/20003.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.818191 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2001/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2001/2002.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2001/2006.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.818329 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2002/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2002/2006.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.818611 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2101/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2101/2102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2101/2103.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.818745 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2102/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:00.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/2102/2103.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.819105 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/22/
--rw-r--r--   0 arne       (501) staff       (20)     4177 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/22/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/22/25.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.819327 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/23/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/23/25.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.820235 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3/15.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3941 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3/25.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:43.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3/7.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.820370 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/304/
--rw-r--r--   0 arne       (501) staff       (20)     8452 2022-08-05 15:52:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/304/305.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.820787 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3201/
--rw-r--r--   0 arne       (501) staff       (20)    25371 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3201/3202.tsv
--rw-r--r--   0 arne       (501) staff       (20)     5495 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3201/3203.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.821021 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3202/
--rw-r--r--   0 arne       (501) staff       (20)     6594 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3202/3203.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.821226 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3302/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3302/3304.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.821363 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/5/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/5/13.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.826282 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    29938 2022-08-05 15:52:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/502.tsv
--rw-r--r--   0 arne       (501) staff       (20)    29248 2022-08-05 15:52:46.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)    22752 2022-08-05 15:52:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)    24126 2022-08-05 15:52:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)    20605 2022-08-05 15:52:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)    38734 2022-08-05 15:52:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)    14421 2022-08-05 15:52:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    17172 2022-08-05 15:52:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7958 2022-08-05 15:52:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6115 2022-08-05 15:52:47.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/599.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6013 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/offsets_ref501_s502.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.829422 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    25706 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)    20685 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)    23299 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)    18622 2022-08-05 15:52:48.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)    34273 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12911 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    14795 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6464 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     5234 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:52:49.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.832144 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    29039 2022-08-05 15:52:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)    22316 2022-08-05 15:52:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)    23028 2022-08-05 15:52:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)    33657 2022-08-05 15:52:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12320 2022-08-05 15:52:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    21410 2022-08-05 15:52:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)     5669 2022-08-05 15:52:50.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3918 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.834580 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    20737 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)    23387 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28451 2022-08-05 15:52:51.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)    13298 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    24234 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3258 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     2360 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       42 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:52.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.836705 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    21871 2022-08-05 15:52:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)    30737 2022-08-05 15:52:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)    16202 2022-08-05 15:52:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    20177 2022-08-05 15:52:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4504 2022-08-05 15:52:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6165 2022-08-05 15:52:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:53.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       42 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       42 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.838915 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    28243 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12929 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    19905 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6406 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     4921 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:54.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       39 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.840849 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    16808 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)    21557 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)    10021 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     5218 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:55.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.842825 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12733 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7456 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6082 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:56.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.844118 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1602 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)     5974 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.845259 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3807 2022-08-05 15:52:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.846214 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/511/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/511/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/511/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/511/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/511/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       40 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/511/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       39 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/511/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/511/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.846917 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/512/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:58.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/512/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/512/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/512/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/512/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/512/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.847461 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/513/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/513/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/513/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/513/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/513/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.847865 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/514/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/514/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/514/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/514/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.848310 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/521/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/521/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       39 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/521/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/521/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.848724 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/522/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/522/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/522/599.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.848884 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/602/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:59.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/602/604.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.849812 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7/15.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:52:44.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7/25.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.850646 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7001/
--rw-r--r--   0 arne       (501) staff       (20)    16044 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7001/7002.tsv
--rw-r--r--   0 arne       (501) staff       (20)    17562 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7001/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7001/7501.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.851096 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7002/
--rw-r--r--   0 arne       (501) staff       (20)    32697 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7002/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7002/7501.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.851246 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7003/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7003/7501.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.851828 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8001/
--rw-r--r--   0 arne       (501) staff       (20)     2135 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8001/8004.tsv
--rw-r--r--   0 arne       (501) staff       (20)     8813 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8001/8008.tsv
--rw-r--r--   0 arne       (501) staff       (20)    18155 2022-08-05 15:53:01.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8001/8009.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.852338 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8004/
--rw-r--r--   0 arne       (501) staff       (20)      563 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8004/8008.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1175 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8004/8009.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.852686 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8008/
--rw-r--r--   0 arne       (501) staff       (20)     6843 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8008/8009.tsv
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.852853 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8301/
--rw-r--r--   0 arne       (501) staff       (20)       19 2022-08-05 15:53:02.000000 hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8301/8302.tsv
--rw-r--r--   0 arne       (501) staff       (20)    12079 2022-08-05 15:47:32.000000 hisparc-sapphire-2.0.0/sapphire/data/stations.json
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.861433 hisparc-sapphire-2.0.0/sapphire/data/subclusters/
--rw-r--r--   0 arne       (501) staff       (20)     1029 2022-08-05 15:47:55.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/0.json
--rw-r--r--   0 arne       (501) staff       (20)      440 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/100.json
--rw-r--r--   0 arne       (501) staff       (20)      728 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/1000.json
--rw-r--r--   0 arne       (501) staff       (20)      242 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/1100.json
--rw-r--r--   0 arne       (501) staff       (20)        2 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/11000.json
--rw-r--r--   0 arne       (501) staff       (20)       82 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/12000.json
--rw-r--r--   0 arne       (501) staff       (20)      672 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/13000.json
--rw-r--r--   0 arne       (501) staff       (20)      293 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/13100.json
--rw-r--r--   0 arne       (501) staff       (20)       70 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/13200.json
--rw-r--r--   0 arne       (501) staff       (20)       73 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/13300.json
--rw-r--r--   0 arne       (501) staff       (20)       69 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/13400.json
--rw-r--r--   0 arne       (501) staff       (20)       87 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/13500.json
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/13600.json
--rw-r--r--   0 arne       (501) staff       (20)      654 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/14000.json
--rw-r--r--   0 arne       (501) staff       (20)      167 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/15000.json
--rw-r--r--   0 arne       (501) staff       (20)       77 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/16000.json
--rw-r--r--   0 arne       (501) staff       (20)       77 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/16100.json
--rw-r--r--   0 arne       (501) staff       (20)       79 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/17000.json
--rw-r--r--   0 arne       (501) staff       (20)      215 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/200.json
--rw-r--r--   0 arne       (501) staff       (20)      643 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/2000.json
--rw-r--r--   0 arne       (501) staff       (20)      230 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/20000.json
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/2100.json
--rw-r--r--   0 arne       (501) staff       (20)       72 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/2200.json
--rw-r--r--   0 arne       (501) staff       (20)      301 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/300.json
--rw-r--r--   0 arne       (501) staff       (20)      149 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/3000.json
--rw-r--r--   0 arne       (501) staff       (20)      395 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/3100.json
--rw-r--r--   0 arne       (501) staff       (20)      221 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/3200.json
--rw-r--r--   0 arne       (501) staff       (20)      292 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/3300.json
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/3400.json
--rw-r--r--   0 arne       (501) staff       (20)       86 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/3500.json
--rw-r--r--   0 arne       (501) staff       (20)       79 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/3600.json
--rw-r--r--   0 arne       (501) staff       (20)      133 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/3700.json
--rw-r--r--   0 arne       (501) staff       (20)       73 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/400.json
--rw-r--r--   0 arne       (501) staff       (20)      288 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/4000.json
--rw-r--r--   0 arne       (501) staff       (20)       80 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/40000.json
--rw-r--r--   0 arne       (501) staff       (20)     1162 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/500.json
--rw-r--r--   0 arne       (501) staff       (20)        2 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/50000.json
--rw-r--r--   0 arne       (501) staff       (20)      261 2022-08-05 15:47:56.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/600.json
--rw-r--r--   0 arne       (501) staff       (20)       82 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/60000.json
--rw-r--r--   0 arne       (501) staff       (20)      233 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/7000.json
--rw-r--r--   0 arne       (501) staff       (20)        2 2022-08-05 15:47:59.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/70000.json
--rw-r--r--   0 arne       (501) staff       (20)      145 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/7100.json
--rw-r--r--   0 arne       (501) staff       (20)       73 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/7200.json
--rw-r--r--   0 arne       (501) staff       (20)       78 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/7300.json
--rw-r--r--   0 arne       (501) staff       (20)       71 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/7400.json
--rw-r--r--   0 arne       (501) staff       (20)        2 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/7500.json
--rw-r--r--   0 arne       (501) staff       (20)       69 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/7600.json
--rw-r--r--   0 arne       (501) staff       (20)      714 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/8000.json
--rw-r--r--   0 arne       (501) staff       (20)      393 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/8100.json
--rw-r--r--   0 arne       (501) staff       (20)       87 2022-08-05 15:47:57.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/8200.json
--rw-r--r--   0 arne       (501) staff       (20)      227 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/8300.json
--rw-r--r--   0 arne       (501) staff       (20)       71 2022-08-05 15:47:58.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters/8400.json
--rw-r--r--   0 arne       (501) staff       (20)     3363 2022-08-05 15:47:32.000000 hisparc-sapphire-2.0.0/sapphire/data/subclusters.json
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.889253 hisparc-sapphire-2.0.0/sapphire/data/trigger/
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:43.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/10.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1020 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      255 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1006.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:45.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      357 2022-08-05 15:48:55.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1010.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:48:45.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:46.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:46.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:48:46.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:46.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/106.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:48:56.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      188 2022-08-05 15:48:56.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:48:56.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/1103.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1173 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/12001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:48:43.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      251 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      408 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13007.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      408 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      306 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      351 2022-08-05 15:49:08.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13501.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/13601.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1271 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/14001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      200 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/14002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      455 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/14003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      384 2022-08-05 15:49:09.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/14004.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:49:10.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/14005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:49:10.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/14006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:49:10.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/14007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      282 2022-08-05 15:49:10.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/14008.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:48:44.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/15.tsv
--rw-r--r--   0 arne       (501) staff       (20)      329 2022-08-05 15:49:10.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/15001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:49:10.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/15002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      329 2022-08-05 15:49:10.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/16001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:49:10.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/16101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:49:11.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/17001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:48:42.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2.tsv
--rw-r--r--   0 arne       (501) staff       (20)      255 2022-08-05 15:49:11.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/20001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      306 2022-08-05 15:49:11.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/20002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:11.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/20003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      306 2022-08-05 15:48:56.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      255 2022-08-05 15:48:56.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      612 2022-08-05 15:48:56.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      357 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      408 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2006.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      255 2022-08-05 15:48:46.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      563 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2010.tsv
--rw-r--r--   0 arne       (501) staff       (20)      402 2022-08-05 15:48:47.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/202.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:47.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/203.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:44.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/21.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1632 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      510 2022-08-05 15:48:44.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)      663 2022-08-05 15:48:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/2201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      612 2022-08-05 15:48:45.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)      376 2022-08-05 15:48:45.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/24.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/25.tsv
--rw-r--r--   0 arne       (501) staff       (20)      510 2022-08-05 15:48:42.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      665 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:47.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:47.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/303.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:48:48.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/304.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:48.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/305.tsv
--rw-r--r--   0 arne       (501) staff       (20)      663 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      510 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3105.tsv
--rw-r--r--   0 arne       (501) staff       (20)      612 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      306 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3202.tsv
--rw-r--r--   0 arne       (501) staff       (20)      408 2022-08-05 15:48:59.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3203.tsv
--rw-r--r--   0 arne       (501) staff       (20)      408 2022-08-05 15:48:59.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:59.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3302.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:59.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3303.tsv
--rw-r--r--   0 arne       (501) staff       (20)       98 2022-08-05 15:48:59.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3304.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:59.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      306 2022-08-05 15:48:59.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      251 2022-08-05 15:49:00.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:49:00.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3701.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:49:00.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/3702.tsv
--rw-r--r--   0 arne       (501) staff       (20)      239 2022-08-05 15:48:42.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/4.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:49:11.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/40001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      867 2022-08-05 15:49:00.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/4001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:00.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/4002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      306 2022-08-05 15:49:00.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/4003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:00.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/4004.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:48.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:42.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/5.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1006 2022-08-05 15:48:48.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      200 2022-08-05 15:48:49.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/502.tsv
--rw-r--r--   0 arne       (501) staff       (20)      306 2022-08-05 15:48:49.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)       98 2022-08-05 15:48:49.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)      380 2022-08-05 15:48:49.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:50.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)      358 2022-08-05 15:48:50.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)      666 2022-08-05 15:48:50.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)      149 2022-08-05 15:48:50.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)      290 2022-08-05 15:48:51.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)       98 2022-08-05 15:48:51.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)       94 2022-08-05 15:48:51.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:48:51.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)      231 2022-08-05 15:48:52.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:48:52.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:48:52.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1069 2022-08-05 15:48:54.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/599.tsv
--rw-r--r--   0 arne       (501) staff       (20)      412 2022-08-05 15:48:43.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/6.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:49:11.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/60001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:48:54.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      141 2022-08-05 15:48:54.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/602.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:48:54.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/603.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:48:54.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/604.tsv
--rw-r--r--   0 arne       (501) staff       (20)      541 2022-08-05 15:48:43.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7.tsv
--rw-r--r--   0 arne       (501) staff       (20)       50 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/70001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      255 2022-08-05 15:49:00.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:01.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:01.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:01.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:01.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7102.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:49:01.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      772 2022-08-05 15:49:01.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:02.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7501.tsv
--rw-r--r--   0 arne       (501) staff       (20)       47 2022-08-05 15:49:02.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/7601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      408 2022-08-05 15:49:02.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:02.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8002.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1632 2022-08-05 15:49:03.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:03.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      510 2022-08-05 15:49:03.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      510 2022-08-05 15:49:03.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:03.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:04.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      102 2022-08-05 15:49:04.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:49:04.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:04.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8102.tsv
--rw-r--r--   0 arne       (501) staff       (20)      357 2022-08-05 15:49:04.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      153 2022-08-05 15:49:05.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      667 2022-08-05 15:49:05.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8105.tsv
--rw-r--r--   0 arne       (501) staff       (20)      357 2022-08-05 15:49:05.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:05.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:05.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8302.tsv
--rw-r--r--   0 arne       (501) staff       (20)      204 2022-08-05 15:49:07.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8303.tsv
--rw-r--r--   0 arne       (501) staff       (20)       51 2022-08-05 15:49:07.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/8401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      971 2022-08-05 15:48:43.000000 hisparc-sapphire-2.0.0/sapphire/data/trigger/9.tsv
--rw-r--r--   0 arne       (501) staff       (20)     6327 2022-08-05 15:48:58.000000 hisparc-sapphire-2.0.0/sapphire/data/update_local_data.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.920251 hisparc-sapphire-2.0.0/sapphire/data/voltage/
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:21.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/10.tsv
--rw-r--r--   0 arne       (501) staff       (20)      684 2022-08-05 15:49:33.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       56 2022-08-05 15:49:33.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      111 2022-08-05 15:49:34.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:49:34.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      363 2022-08-05 15:49:34.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1006.tsv
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:34.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      244 2022-08-05 15:49:34.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:34.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      541 2022-08-05 15:49:23.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      411 2022-08-05 15:49:34.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1010.tsv
--rw-r--r--   0 arne       (501) staff       (20)      347 2022-08-05 15:49:24.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       54 2022-08-05 15:49:24.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:24.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      621 2022-08-05 15:49:24.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/105.tsv
--rw-r--r--   0 arne       (501) staff       (20)      168 2022-08-05 15:49:24.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/106.tsv
--rw-r--r--   0 arne       (501) staff       (20)      324 2022-08-05 15:49:35.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      297 2022-08-05 15:49:35.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1102.tsv
--rw-r--r--   0 arne       (501) staff       (20)      270 2022-08-05 15:49:35.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/1103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      687 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/12001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:21.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13.tsv
--rw-r--r--   0 arne       (501) staff       (20)      298 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      513 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      167 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      653 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13007.tsv
--rw-r--r--   0 arne       (501) staff       (20)       54 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      135 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       54 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      486 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      324 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13301.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      109 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/13601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      972 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/14001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/14002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:47.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/14003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      216 2022-08-05 15:49:48.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/14004.tsv
--rw-r--r--   0 arne       (501) staff       (20)       81 2022-08-05 15:49:48.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/14005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       81 2022-08-05 15:49:48.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/14006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       54 2022-08-05 15:49:48.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/14007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:48.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/14008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:22.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/15.tsv
--rw-r--r--   0 arne       (501) staff       (20)      432 2022-08-05 15:49:48.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/15001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      135 2022-08-05 15:49:48.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/15002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:48.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/16001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      135 2022-08-05 15:49:49.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/16101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:49.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/17001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      249 2022-08-05 15:49:19.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2.tsv
--rw-r--r--   0 arne       (501) staff       (20)      324 2022-08-05 15:49:49.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/20001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      498 2022-08-05 15:49:49.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/20002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      382 2022-08-05 15:49:49.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/20003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:35.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      162 2022-08-05 15:49:35.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      270 2022-08-05 15:49:35.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      162 2022-08-05 15:49:35.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      135 2022-08-05 15:49:35.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2005.tsv
--rw-r--r--   0 arne       (501) staff       (20)       81 2022-08-05 15:49:36.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2006.tsv
--rw-r--r--   0 arne       (501) staff       (20)       81 2022-08-05 15:49:36.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      569 2022-08-05 15:49:24.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      893 2022-08-05 15:49:36.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2010.tsv
--rw-r--r--   0 arne       (501) staff       (20)      500 2022-08-05 15:49:25.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/202.tsv
--rw-r--r--   0 arne       (501) staff       (20)      216 2022-08-05 15:49:25.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/203.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:22.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/21.tsv
--rw-r--r--   0 arne       (501) staff       (20)      604 2022-08-05 15:49:36.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       54 2022-08-05 15:49:36.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:49:36.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      409 2022-08-05 15:49:22.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/22.tsv
--rw-r--r--   0 arne       (501) staff       (20)      595 2022-08-05 15:49:36.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/2201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      729 2022-08-05 15:49:23.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/23.tsv
--rw-r--r--   0 arne       (501) staff       (20)      972 2022-08-05 15:49:23.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/24.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/25.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1232 2022-08-05 15:49:19.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3.tsv
--rw-r--r--   0 arne       (501) staff       (20)      371 2022-08-05 15:49:36.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      434 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:25.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      135 2022-08-05 15:49:26.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/303.tsv
--rw-r--r--   0 arne       (501) staff       (20)      162 2022-08-05 15:49:26.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/304.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:26.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/305.tsv
--rw-r--r--   0 arne       (501) staff       (20)      621 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       54 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      405 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3104.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3105.tsv
--rw-r--r--   0 arne       (501) staff       (20)      756 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      324 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3202.tsv
--rw-r--r--   0 arne       (501) staff       (20)      245 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3203.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:37.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:38.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3302.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:38.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3303.tsv
--rw-r--r--   0 arne       (501) staff       (20)      378 2022-08-05 15:49:38.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3304.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:38.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:38.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      270 2022-08-05 15:49:38.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3601.tsv
--rw-r--r--   0 arne       (501) staff       (20)       81 2022-08-05 15:49:38.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3701.tsv
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:38.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/3702.tsv
--rw-r--r--   0 arne       (501) staff       (20)      351 2022-08-05 15:49:20.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/4.tsv
--rw-r--r--   0 arne       (501) staff       (20)      108 2022-08-05 15:49:49.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/40001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      778 2022-08-05 15:49:39.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/4001.tsv
--rw-r--r--   0 arne       (501) staff       (20)       81 2022-08-05 15:49:39.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/4002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      168 2022-08-05 15:49:39.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/4003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      224 2022-08-05 15:49:39.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/4004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      662 2022-08-05 15:49:26.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      193 2022-08-05 15:49:20.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/5.tsv
--rw-r--r--   0 arne       (501) staff       (20)      972 2022-08-05 15:49:27.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      648 2022-08-05 15:49:27.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/502.tsv
--rw-r--r--   0 arne       (501) staff       (20)      795 2022-08-05 15:49:27.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/503.tsv
--rw-r--r--   0 arne       (501) staff       (20)      756 2022-08-05 15:49:28.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/504.tsv
--rw-r--r--   0 arne       (501) staff       (20)      814 2022-08-05 15:49:29.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/505.tsv
--rw-r--r--   0 arne       (501) staff       (20)      378 2022-08-05 15:49:29.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/506.tsv
--rw-r--r--   0 arne       (501) staff       (20)      702 2022-08-05 15:49:29.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/507.tsv
--rw-r--r--   0 arne       (501) staff       (20)      737 2022-08-05 15:49:30.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/508.tsv
--rw-r--r--   0 arne       (501) staff       (20)      378 2022-08-05 15:49:30.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/509.tsv
--rw-r--r--   0 arne       (501) staff       (20)      648 2022-08-05 15:49:30.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/510.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:30.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/511.tsv
--rw-r--r--   0 arne       (501) staff       (20)      297 2022-08-05 15:49:31.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/512.tsv
--rw-r--r--   0 arne       (501) staff       (20)      162 2022-08-05 15:49:31.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/513.tsv
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:31.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/514.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:49:31.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/521.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:49:31.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/522.tsv
--rw-r--r--   0 arne       (501) staff       (20)      569 2022-08-05 15:49:33.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/599.tsv
--rw-r--r--   0 arne       (501) staff       (20)      729 2022-08-05 15:49:21.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/6.tsv
--rw-r--r--   0 arne       (501) staff       (20)      297 2022-08-05 15:49:49.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/60001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      336 2022-08-05 15:49:33.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      270 2022-08-05 15:49:33.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/602.tsv
--rw-r--r--   0 arne       (501) staff       (20)      162 2022-08-05 15:49:33.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/603.tsv
--rw-r--r--   0 arne       (501) staff       (20)       27 2022-08-05 15:49:33.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/604.tsv
--rw-r--r--   0 arne       (501) staff       (20)      866 2022-08-05 15:49:21.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7.tsv
--rw-r--r--   0 arne       (501) staff       (20)      383 2022-08-05 15:49:39.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      248 2022-08-05 15:49:39.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7002.tsv
--rw-r--r--   0 arne       (501) staff       (20)      112 2022-08-05 15:49:39.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7003.tsv
--rw-r--r--   0 arne       (501) staff       (20)       84 2022-08-05 15:49:39.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7101.tsv
--rw-r--r--   0 arne       (501) staff       (20)      165 2022-08-05 15:49:40.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7102.tsv
--rw-r--r--   0 arne       (501) staff       (20)       56 2022-08-05 15:49:40.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      548 2022-08-05 15:49:40.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      278 2022-08-05 15:49:41.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7401.tsv
--rw-r--r--   0 arne       (501) staff       (20)       56 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7501.tsv
--rw-r--r--   0 arne       (501) staff       (20)      459 2022-08-05 15:49:41.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/7601.tsv
--rw-r--r--   0 arne       (501) staff       (20)      684 2022-08-05 15:49:41.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8001.tsv
--rw-r--r--   0 arne       (501) staff       (20)      135 2022-08-05 15:49:41.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8002.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1083 2022-08-05 15:49:42.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8003.tsv
--rw-r--r--   0 arne       (501) staff       (20)      334 2022-08-05 15:49:42.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8004.tsv
--rw-r--r--   0 arne       (501) staff       (20)      487 2022-08-05 15:49:42.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8005.tsv
--rw-r--r--   0 arne       (501) staff       (20)      540 2022-08-05 15:49:42.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8006.tsv
--rw-r--r--   0 arne       (501) staff       (20)      224 2022-08-05 15:49:42.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8007.tsv
--rw-r--r--   0 arne       (501) staff       (20)      327 2022-08-05 15:49:43.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8008.tsv
--rw-r--r--   0 arne       (501) staff       (20)      189 2022-08-05 15:49:43.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8009.tsv
--rw-r--r--   0 arne       (501) staff       (20)      270 2022-08-05 15:49:43.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8101.tsv
--rw-r--r--   0 arne       (501) staff       (20)       54 2022-08-05 15:49:43.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8102.tsv
--rw-r--r--   0 arne       (501) staff       (20)      216 2022-08-05 15:49:43.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8103.tsv
--rw-r--r--   0 arne       (501) staff       (20)      243 2022-08-05 15:49:43.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8104.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1365 2022-08-05 15:49:43.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8105.tsv
--rw-r--r--   0 arne       (501) staff       (20)      216 2022-08-05 15:49:44.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8201.tsv
--rw-r--r--   0 arne       (501) staff       (20)      362 2022-08-05 15:49:44.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8301.tsv
--rw-r--r--   0 arne       (501) staff       (20)      109 2022-08-05 15:49:44.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8302.tsv
--rw-r--r--   0 arne       (501) staff       (20)      387 2022-08-05 15:49:45.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8303.tsv
--rw-r--r--   0 arne       (501) staff       (20)      489 2022-08-05 15:49:46.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/8401.tsv
--rw-r--r--   0 arne       (501) staff       (20)      976 2022-08-05 15:49:21.000000 hisparc-sapphire-2.0.0/sapphire/data/voltage/9.tsv
--rw-r--r--   0 arne       (501) staff       (20)    32776 2022-07-30 13:03:41.000000 hisparc-sapphire-2.0.0/sapphire/esd.py
--rw-r--r--   0 arne       (501) staff       (20)    10401 2022-07-30 13:03:41.000000 hisparc-sapphire-2.0.0/sapphire/kascade.py
--rw-r--r--   0 arne       (501) staff       (20)     7869 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/publicdb.py
--rw-r--r--   0 arne       (501) staff       (20)     3187 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/qsub.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.922264 hisparc-sapphire-2.0.0/sapphire/simulations/
--rw-r--r--   0 arne       (501) staff       (20)      908 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/simulations/__init__.py
--rw-r--r--   0 arne       (501) staff       (20)    12537 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/simulations/base.py
--rw-r--r--   0 arne       (501) staff       (20)    10376 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/simulations/detector.py
--rw-r--r--   0 arne       (501) staff       (20)     7846 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/simulations/gammas.py
--rw-r--r--   0 arne       (501) staff       (20)    24181 2022-07-30 13:03:41.000000 hisparc-sapphire-2.0.0/sapphire/simulations/groundparticles.py
--rw-r--r--   0 arne       (501) staff       (20)    16416 2022-07-30 13:03:41.000000 hisparc-sapphire-2.0.0/sapphire/simulations/ldf.py
--rw-r--r--   0 arne       (501) staff       (20)    10593 2022-07-30 13:03:41.000000 hisparc-sapphire-2.0.0/sapphire/simulations/showerfront.py
--rw-r--r--   0 arne       (501) staff       (20)     7632 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/storage.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.925312 hisparc-sapphire-2.0.0/sapphire/tests/
--rw-r--r--   0 arne       (501) staff       (20)      690 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/__init__.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.928159 hisparc-sapphire-2.0.0/sapphire/tests/analysis/
--rw-r--r--   0 arne       (501) staff       (20)        0 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/__init__.py
--rw-r--r--   0 arne       (501) staff       (20)    16214 2022-07-30 12:46:49.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_calibration.py
--rw-r--r--   0 arne       (501) staff       (20)     9957 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_coincidence_queries.py
--rw-r--r--   0 arne       (501) staff       (20)     8999 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_coincidences.py
--rw-r--r--   0 arne       (501) staff       (20)     1238 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_core_reconstruction.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.929059 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_data/
--rw-r--r--   0 arne       (501) staff       (20)    51926 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_data/coincidences.h5
--rw-r--r--   0 arne       (501) staff       (20)    43894 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_data/esd_coincidences.h5
--rw-r--r--   0 arne       (501) staff       (20)   295955 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_data/process_events.h5
--rw-r--r--   0 arne       (501) staff       (20)    32523 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_direction_reconstruction.py
--rw-r--r--   0 arne       (501) staff       (20)    11423 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_event_utils.py
--rw-r--r--   0 arne       (501) staff       (20)     1745 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_find_mpv.py
--rw-r--r--   0 arne       (501) staff       (20)      811 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_landau.py
--rw-r--r--   0 arne       (501) staff       (20)    15861 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_process_events.py
--rw-r--r--   0 arne       (501) staff       (20)     9526 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_process_traces.py
--rw-r--r--   0 arne       (501) staff       (20)    17210 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_reconstructions.py
--rw-r--r--   0 arne       (501) staff       (20)     2414 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_time_deltas.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.931484 hisparc-sapphire-2.0.0/sapphire/tests/corsika/
--rw-r--r--   0 arne       (501) staff       (20)        0 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/__init__.py
--rw-r--r--   0 arne       (501) staff       (20)     5529 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_blocks.py
--rw-r--r--   0 arne       (501) staff       (20)     3194 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_corsika.py
--rw-r--r--   0 arne       (501) staff       (20)     5610 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_corsika_queries.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.931640 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.934005 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/1_2/
--rw-r--r--   0 arne       (501) staff       (20)  1101120 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/1_2/DAT000000
--rw-r--r--   0 arne       (501) staff       (20)  1581730 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/1_2/corsika.h5
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.936935 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/3_4/
--rw-r--r--   0 arne       (501) staff       (20)    78648 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/3_4/DAT000000
--rw-r--r--   0 arne       (501) staff       (20)   177555 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/3_4/corsika.h5
--rw-r--r--   0 arne       (501) staff       (20)    72256 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/corsika_overview.h5
--rw-r--r--   0 arne       (501) staff       (20)     1958 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_generate_corsika_overview.py
--rw-r--r--   0 arne       (501) staff       (20)     1907 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_particles.py
--rw-r--r--   0 arne       (501) staff       (20)     9192 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_qsub_corsika.py
--rw-r--r--   0 arne       (501) staff       (20)     5145 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_qsub_store_corsika_data.py
--rw-r--r--   0 arne       (501) staff       (20)     3766 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_store_corsika_data.py
--rw-r--r--   0 arne       (501) staff       (20)     2793 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_units.py
--rwxr-xr-x   0 arne       (501) staff       (20)      262 2022-08-05 17:58:16.000000 hisparc-sapphire-2.0.0/sapphire/tests/create_and_store_test_data.py
--rw-r--r--   0 arne       (501) staff       (20)     4022 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/esd_load_data.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.940723 hisparc-sapphire-2.0.0/sapphire/tests/simulations/
--rw-r--r--   0 arne       (501) staff       (20)        0 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/__init__.py
--rw-r--r--   0 arne       (501) staff       (20)     3350 2022-07-30 13:03:41.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/perform_simulation.py
--rw-r--r--   0 arne       (501) staff       (20)    11459 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_base_simulation.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.945063 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/
--rw-r--r--   0 arne       (501) staff       (20)  1581730 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/corsika.h5
--rw-r--r--   0 arne       (501) staff       (20)    69174 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/flatfront_sim.h5
--rw-r--r--   0 arne       (501) staff       (20)    61258 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/gamma_sim.h5
--rw-r--r--   0 arne       (501) staff       (20)    67441 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/groundparticles_sim.h5
--rw-r--r--   0 arne       (501) staff       (20)    67318 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/nkgldf_sim.h5
--rw-r--r--   0 arne       (501) staff       (20)     5665 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_detectors.py
--rw-r--r--   0 arne       (501) staff       (20)     6114 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_gammas.py
--rw-r--r--   0 arne       (501) staff       (20)     9363 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_groundparticles.py
--rw-r--r--   0 arne       (501) staff       (20)     2159 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_ldf.py
--rw-r--r--   0 arne       (501) staff       (20)     1830 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_simulation_acceptance.py
--rw-r--r--   0 arne       (501) staff       (20)    31172 2022-07-17 20:01:03.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_api.py
--rw-r--r--   0 arne       (501) staff       (20)    29822 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_clusters.py
--rw-r--r--   0 arne       (501) staff       (20)     1289 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_clusters_acceptance.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.950365 hisparc-sapphire-2.0.0/sapphire/tests/test_data/
--rw-r--r--   0 arne       (501) staff       (20)     4296 2022-08-05 18:00:28.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/coincidences-20160310.tsv
--rw-r--r--   0 arne       (501) staff       (20)    81944 2022-08-05 17:53:06.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/esd_coincidence_data.h5
--rw-r--r--   0 arne       (501) staff       (20)    29454 2022-08-05 17:53:02.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/esd_load_data.h5
--rw-r--r--   0 arne       (501) staff       (20)     5975 2022-08-05 18:00:28.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/events-s501-20120101.tsv
--rw-r--r--   0 arne       (501) staff       (20)     1832 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/kascade.dat
--rw-r--r--   0 arne       (501) staff       (20)    72676 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/kascade.h5
--rw-r--r--   0 arne       (501) staff       (20)     1324 2022-08-05 17:53:06.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/lightning-knmi-20150717.tsv
--rw-r--r--   0 arne       (501) staff       (20)   416604 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/publicdb.h5
--rw-r--r--   0 arne       (501) staff       (20)   419051 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/publicdb_src.h5
--rw-r--r--   0 arne       (501) staff       (20)    38516 2022-08-05 18:00:28.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/singles-s501-20170101.tsv
--rw-r--r--   0 arne       (501) staff       (20)     3014 2022-08-05 18:00:28.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_data/weather-s501-20120101.tsv
--rw-r--r--   0 arne       (501) staff       (20)     7498 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_esd.py
--rw-r--r--   0 arne       (501) staff       (20)     1169 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_kascade.py
--rw-r--r--   0 arne       (501) staff       (20)     6275 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_publicdb.py
--rw-r--r--   0 arne       (501) staff       (20)     4593 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_qsub.py
--rw-r--r--   0 arne       (501) staff       (20)     1153 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_time_util.py
--rw-r--r--   0 arne       (501) staff       (20)     6947 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/test_utils.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.951523 hisparc-sapphire-2.0.0/sapphire/tests/transformations/
--rw-r--r--   0 arne       (501) staff       (20)        0 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/transformations/__init__.py
--rw-r--r--   0 arne       (501) staff       (20)     1415 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_angles.py
--rw-r--r--   0 arne       (501) staff       (20)     4247 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_axes.py
--rw-r--r--   0 arne       (501) staff       (20)     1013 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_base.py
--rw-r--r--   0 arne       (501) staff       (20)    12382 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_celestial.py
--rw-r--r--   0 arne       (501) staff       (20)     7892 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_clock.py
--rw-r--r--   0 arne       (501) staff       (20)     1869 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_geographic.py
--rw-r--r--   0 arne       (501) staff       (20)     4502 2022-07-30 12:46:49.000000 hisparc-sapphire-2.0.0/sapphire/tests/validate_results.py
--rw-r--r--   0 arne       (501) staff       (20)     2373 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/time_util.py
-drwxr-xr-x   0 arne       (501) staff       (20)        0 2022-08-05 19:44:15.952933 hisparc-sapphire-2.0.0/sapphire/transformations/
--rw-r--r--   0 arne       (501) staff       (20)      915 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/transformations/__init__.py
--rw-r--r--   0 arne       (501) staff       (20)      923 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/transformations/angles.py
--rw-r--r--   0 arne       (501) staff       (20)     4567 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/transformations/axes.py
--rw-r--r--   0 arne       (501) staff       (20)     1044 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/transformations/base.py
--rw-r--r--   0 arne       (501) staff       (20)    11223 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/transformations/celestial.py
--rw-r--r--   0 arne       (501) staff       (20)    10275 2022-01-17 10:27:57.000000 hisparc-sapphire-2.0.0/sapphire/transformations/clock.py
--rw-r--r--   0 arne       (501) staff       (20)     5734 2022-07-07 05:21:20.000000 hisparc-sapphire-2.0.0/sapphire/transformations/geographic.py
--rw-r--r--   0 arne       (501) staff       (20)     5172 2022-07-17 12:21:46.000000 hisparc-sapphire-2.0.0/sapphire/utils.py
--rw-r--r--   0 arne       (501) staff       (20)       58 2022-08-05 19:44:15.000000 hisparc-sapphire-2.0.0/sapphire/version.py
--rw-r--r--   0 arne       (501) staff       (20)      611 2022-08-05 19:44:15.955804 hisparc-sapphire-2.0.0/setup.cfg
--rw-r--r--   0 arne       (501) staff       (20)     3186 2022-08-05 18:16:11.000000 hisparc-sapphire-2.0.0/setup.py
+-rw-r--r--   0        0        0      274 2024-04-12 12:43:10.843635 hisparc_sapphire-3.0.0/.editorconfig
+-rw-r--r--   0        0        0      118 2022-10-27 21:53:40.041861 hisparc_sapphire-3.0.0/.github/dependabot.yml
+-rw-r--r--   0        0        0     1531 2024-04-22 19:55:07.303807 hisparc_sapphire-3.0.0/.github/workflows/tests.yml
+-rw-r--r--   0        0        0      249 2022-08-05 19:27:28.169304 hisparc_sapphire-3.0.0/.gitignore
+-rw-r--r--   0        0        0    35149 2022-01-17 10:27:57.300305 hisparc_sapphire-3.0.0/LICENSE
+-rw-r--r--   0        0        0      658 2024-04-15 07:17:57.485008 hisparc_sapphire-3.0.0/Makefile
+-rw-r--r--   0        0        0     3457 2023-05-13 13:08:54.624685 hisparc_sapphire-3.0.0/README.rst
+-rw-r--r--   0        0        0     5611 2022-01-17 10:27:57.300562 hisparc_sapphire-3.0.0/doc/Makefile
+-rw-r--r--   0        0        0     4286 2022-01-17 10:27:57.300652 hisparc_sapphire-3.0.0/doc/_static/favicon.ico
+-rw-r--r--   0        0        0     1139 2022-01-17 10:27:57.300709 hisparc_sapphire-3.0.0/doc/_static/hisparc_style.css
+-rw-r--r--   0        0        0      442 2022-01-17 10:27:57.300762 hisparc_sapphire-3.0.0/doc/analysis.rst
+-rw-r--r--   0        0        0      176 2022-01-17 10:27:57.300848 hisparc_sapphire-3.0.0/doc/analysis/calibration.rst
+-rw-r--r--   0        0        0      184 2022-01-17 10:27:57.300913 hisparc_sapphire-3.0.0/doc/analysis/coincidence_queries.rst
+-rw-r--r--   0        0        0      209 2022-01-17 10:27:57.300964 hisparc_sapphire-3.0.0/doc/analysis/coincidences.rst
+-rw-r--r--   0        0        0      159 2022-01-17 10:27:57.301013 hisparc_sapphire-3.0.0/doc/analysis/core_reconstruction.rst
+-rw-r--r--   0        0        0      156 2022-01-17 10:27:57.301067 hisparc_sapphire-3.0.0/doc/analysis/direction_reconstruction.rst
+-rw-r--r--   0        0        0      188 2022-01-17 10:27:57.301116 hisparc_sapphire-3.0.0/doc/analysis/event_utils.rst
+-rw-r--r--   0        0        0       92 2022-01-17 10:27:57.301166 hisparc_sapphire-3.0.0/doc/analysis/find_mpv.rst
+-rw-r--r--   0        0        0      114 2022-01-17 10:27:57.301215 hisparc_sapphire-3.0.0/doc/analysis/landau.rst
+-rw-r--r--   0        0        0      140 2022-01-17 10:27:57.301265 hisparc_sapphire-3.0.0/doc/analysis/process_events.rst
+-rw-r--r--   0        0        0      140 2022-01-17 10:27:57.301324 hisparc_sapphire-3.0.0/doc/analysis/process_traces.rst
+-rw-r--r--   0        0        0      116 2022-01-17 10:27:57.301379 hisparc_sapphire-3.0.0/doc/analysis/reconstructions.rst
+-rw-r--r--   0        0        0      104 2022-01-17 10:27:57.301431 hisparc_sapphire-3.0.0/doc/analysis/time_deltas.rst
+-rw-r--r--   0        0        0       86 2022-01-17 10:27:57.301481 hisparc_sapphire-3.0.0/doc/api.rst
+-rw-r--r--   0        0        0      101 2022-01-17 10:27:57.301530 hisparc_sapphire-3.0.0/doc/clusters.rst
+-rw-r--r--   0        0        0     4725 2024-04-14 19:13:10.140018 hisparc_sapphire-3.0.0/doc/conf.py
+-rw-r--r--   0        0        0      867 2022-11-04 07:18:04.932756 hisparc_sapphire-3.0.0/doc/configuration.rst
+-rw-r--r--   0        0        0     1077 2022-01-17 10:27:57.301739 hisparc_sapphire-3.0.0/doc/corsika.rst
+-rw-r--r--   0        0        0      103 2022-01-17 10:27:57.301813 hisparc_sapphire-3.0.0/doc/corsika/blocks.rst
+-rw-r--r--   0        0        0      160 2022-01-17 10:27:57.301863 hisparc_sapphire-3.0.0/doc/corsika/corsika_queries.rst
+-rw-r--r--   0        0        0      176 2022-01-17 10:27:57.301914 hisparc_sapphire-3.0.0/doc/corsika/generate_corsika_overview.rst
+-rw-r--r--   0        0        0      112 2022-01-17 10:27:57.301963 hisparc_sapphire-3.0.0/doc/corsika/particles.rst
+-rw-r--r--   0        0        0      121 2022-01-17 10:27:57.302008 hisparc_sapphire-3.0.0/doc/corsika/qsub_corsika.rst
+-rw-r--r--   0        0        0      172 2022-01-17 10:27:57.302057 hisparc_sapphire-3.0.0/doc/corsika/qsub_store_corsika_data.rst
+-rw-r--r--   0        0        0      103 2022-01-17 10:27:57.302101 hisparc_sapphire-3.0.0/doc/corsika/reader.rst
+-rw-r--r--   0        0        0      139 2022-01-17 10:27:57.302149 hisparc_sapphire-3.0.0/doc/corsika/store_corsika_data.rst
+-rw-r--r--   0        0        0      100 2022-01-17 10:27:57.302194 hisparc_sapphire-3.0.0/doc/corsika/units.rst
+-rw-r--r--   0        0        0      210 2022-01-17 10:27:57.302253 hisparc_sapphire-3.0.0/doc/data.rst
+-rw-r--r--   0        0        0      143 2022-01-17 10:27:57.302332 hisparc_sapphire-3.0.0/doc/data/extend_local_data.rst
+-rw-r--r--   0        0        0      195 2022-01-17 10:27:57.302386 hisparc_sapphire-3.0.0/doc/data/update_local_data.rst
+-rw-r--r--   0        0        0      100 2022-01-17 10:27:57.302432 hisparc_sapphire-3.0.0/doc/esd.rst
+-rw-r--r--   0        0        0     6084 2022-01-17 10:27:57.302500 hisparc_sapphire-3.0.0/doc/examples.rst
+-rw-r--r--   0        0        0   167967 2022-01-17 10:27:57.303237 hisparc_sapphire-3.0.0/doc/images/github-zipball.png
+-rw-r--r--   0        0        0    38514 2022-01-17 10:27:57.303459 hisparc_sapphire-3.0.0/doc/images/tutorial-hist-better.png
+-rw-r--r--   0        0        0    18757 2022-01-17 10:27:57.303595 hisparc_sapphire-3.0.0/doc/images/tutorial-hist-simple.png
+-rw-r--r--   0        0        0      747 2022-01-17 10:27:57.303664 hisparc_sapphire-3.0.0/doc/index.rst
+-rw-r--r--   0        0        0     8035 2022-01-17 10:27:57.303743 hisparc_sapphire-3.0.0/doc/installation.rst
+-rw-r--r--   0        0        0       92 2022-01-17 10:27:57.303796 hisparc_sapphire-3.0.0/doc/kascade.rst
+-rw-r--r--   0        0        0     5304 2022-01-17 10:27:57.303895 hisparc_sapphire-3.0.0/doc/logo/header.pdf
+-rw-r--r--   0        0        0     3210 2022-01-17 10:27:57.303945 hisparc_sapphire-3.0.0/doc/logo/header.png
+-rw-r--r--   0        0        0     5192 2022-01-17 10:27:57.304015 hisparc_sapphire-3.0.0/doc/logo/logo.pdf
+-rw-r--r--   0        0        0     9961 2022-01-17 10:27:57.304102 hisparc_sapphire-3.0.0/doc/logo/logo.png
+-rw-r--r--   0        0        0     5100 2022-01-17 10:27:57.304166 hisparc_sapphire-3.0.0/doc/make.bat
+-rw-r--r--   0        0        0      105 2022-01-17 10:27:57.304211 hisparc_sapphire-3.0.0/doc/publicdb.rst
+-rw-r--r--   0        0        0      119 2022-01-17 10:27:57.304262 hisparc_sapphire-3.0.0/doc/qsub.rst
+-rw-r--r--   0        0        0      255 2022-01-17 10:27:57.304320 hisparc_sapphire-3.0.0/doc/sapphire.rst
+-rw-r--r--   0        0        0        5 2022-01-17 10:27:57.304399 hisparc_sapphire-3.0.0/doc/scripts/.gitignore
+-rw-r--r--   0        0        0      591 2022-01-17 10:27:57.304457 hisparc_sapphire-3.0.0/doc/scripts/download_and_reconstruct_coincidences.py
+-rw-r--r--   0        0        0      406 2022-01-17 10:27:57.304508 hisparc_sapphire-3.0.0/doc/scripts/download_esd_coincidences.py
+-rw-r--r--   0        0        0      445 2022-01-17 10:27:57.304560 hisparc_sapphire-3.0.0/doc/scripts/download_esd_events.py
+-rw-r--r--   0        0        0       87 2024-04-14 19:13:10.138908 hisparc_sapphire-3.0.0/doc/scripts/is_useful.py
+-rw-r--r--   0        0        0      122 2024-04-14 19:13:10.138432 hisparc_sapphire-3.0.0/doc/scripts/is_useful_and_importable.py
+-rw-r--r--   0        0        0      526 2024-04-14 19:12:48.714152 hisparc_sapphire-3.0.0/doc/scripts/plot_zenith_distribution.py
+-rw-r--r--   0        0        0      305 2022-01-17 10:27:57.304768 hisparc_sapphire-3.0.0/doc/scripts/simple-download-with-checks.py
+-rw-r--r--   0        0        0      280 2022-01-17 10:27:57.304826 hisparc_sapphire-3.0.0/doc/scripts/simple-download-with-globals.py
+-rw-r--r--   0        0        0      244 2022-01-17 10:27:57.304878 hisparc_sapphire-3.0.0/doc/scripts/simple-download.py
+-rw-r--r--   0        0        0     1214 2022-01-17 10:27:57.304933 hisparc_sapphire-3.0.0/doc/simulations.rst
+-rw-r--r--   0        0        0      123 2022-01-17 10:27:57.305008 hisparc_sapphire-3.0.0/doc/simulations/base.rst
+-rw-r--r--   0        0        0      121 2022-01-17 10:27:57.305056 hisparc_sapphire-3.0.0/doc/simulations/detector.rst
+-rw-r--r--   0        0        0      192 2022-01-17 10:27:57.305104 hisparc_sapphire-3.0.0/doc/simulations/gammas.rst
+-rw-r--r--   0        0        0      202 2022-01-17 10:27:57.305152 hisparc_sapphire-3.0.0/doc/simulations/groundparticles.rst
+-rw-r--r--   0        0        0      212 2022-01-17 10:27:57.305199 hisparc_sapphire-3.0.0/doc/simulations/ldf.rst
+-rw-r--r--   0        0        0      196 2022-01-17 10:27:57.305247 hisparc_sapphire-3.0.0/doc/simulations/showerfront.rst
+-rw-r--r--   0        0        0      146 2022-01-17 10:27:57.305295 hisparc_sapphire-3.0.0/doc/storage.rst
+-rw-r--r--   0        0        0       96 2022-01-17 10:27:57.305343 hisparc_sapphire-3.0.0/doc/subst.inc
+-rw-r--r--   0        0        0      100 2022-01-17 10:27:57.305395 hisparc_sapphire-3.0.0/doc/tests.rst
+-rw-r--r--   0        0        0      132 2022-01-17 10:27:57.305444 hisparc_sapphire-3.0.0/doc/time_util.rst
+-rw-r--r--   0        0        0      331 2022-01-17 10:27:57.305501 hisparc_sapphire-3.0.0/doc/transformations.rst
+-rw-r--r--   0        0        0      171 2022-01-17 10:27:57.305575 hisparc_sapphire-3.0.0/doc/transformations/angles.rst
+-rw-r--r--   0        0        0      165 2022-01-17 10:27:57.305627 hisparc_sapphire-3.0.0/doc/transformations/axes.rst
+-rw-r--r--   0        0        0      149 2022-01-17 10:27:57.305682 hisparc_sapphire-3.0.0/doc/transformations/base.rst
+-rw-r--r--   0        0        0      190 2022-01-17 10:27:57.305730 hisparc_sapphire-3.0.0/doc/transformations/celestial.rst
+-rw-r--r--   0        0        0      132 2022-01-17 10:27:57.305776 hisparc_sapphire-3.0.0/doc/transformations/clock.rst
+-rw-r--r--   0        0        0      193 2022-01-17 10:27:57.305824 hisparc_sapphire-3.0.0/doc/transformations/geographic.rst
+-rw-r--r--   0        0        0    34290 2022-11-04 07:18:10.151334 hisparc_sapphire-3.0.0/doc/tutorial.rst
+-rw-r--r--   0        0        0      114 2022-01-17 10:27:57.306047 hisparc_sapphire-3.0.0/doc/utils.rst
+-rw-r--r--   0        0        0     5029 2024-05-10 09:27:03.216688 hisparc_sapphire-3.0.0/pyproject.toml
+-rw-r--r--   0        0        0       74 2024-05-05 09:32:51.421371 hisparc_sapphire-3.0.0/sapphire/README.md
+-rw-r--r--   0        0        0     4409 2024-04-15 07:19:11.603892 hisparc_sapphire-3.0.0/sapphire/__init__.py
+-rw-r--r--   0        0        0     2258 2024-04-14 19:13:10.154828 hisparc_sapphire-3.0.0/sapphire/analysis/__init__.py
+-rw-r--r--   0        0        0    15563 2024-04-15 07:25:28.598801 hisparc_sapphire-3.0.0/sapphire/analysis/calibration.py
+-rw-r--r--   0        0        0    14176 2024-04-27 09:27:55.634132 hisparc_sapphire-3.0.0/sapphire/analysis/coincidence_queries.py
+-rw-r--r--   0        0        0    31134 2024-05-05 08:07:22.379451 hisparc_sapphire-3.0.0/sapphire/analysis/coincidences.py
+-rw-r--r--   0        0        0    19323 2024-04-27 10:27:56.153115 hisparc_sapphire-3.0.0/sapphire/analysis/core_reconstruction.py
+-rw-r--r--   0        0        0    48348 2024-04-27 10:28:59.643463 hisparc_sapphire-3.0.0/sapphire/analysis/direction_reconstruction.py
+-rw-r--r--   0        0        0     6798 2024-04-27 10:29:25.494709 hisparc_sapphire-3.0.0/sapphire/analysis/event_utils.py
+-rw-r--r--   0        0        0     5118 2024-04-14 19:13:10.155505 hisparc_sapphire-3.0.0/sapphire/analysis/find_mpv.py
+-rw-r--r--   0        0        0     5957 2024-04-14 19:13:13.660360 hisparc_sapphire-3.0.0/sapphire/analysis/landau.py
+-rw-r--r--   0        0        0    42935 2024-04-27 11:44:36.100696 hisparc_sapphire-3.0.0/sapphire/analysis/process_events.py
+-rw-r--r--   0        0        0    13767 2024-04-27 11:41:46.238627 hisparc_sapphire-3.0.0/sapphire/analysis/process_traces.py
+-rw-r--r--   0        0        0    28150 2024-04-27 10:30:04.214330 hisparc_sapphire-3.0.0/sapphire/analysis/reconstructions.py
+-rw-r--r--   0        0        0     6462 2024-04-27 10:31:29.911936 hisparc_sapphire-3.0.0/sapphire/analysis/time_deltas.py
+-rw-r--r--   0        0        0    36249 2024-04-27 09:25:52.348894 hisparc_sapphire-3.0.0/sapphire/api.py
+-rw-r--r--   0        0        0    32407 2024-04-27 10:32:30.180181 hisparc_sapphire-3.0.0/sapphire/clusters.py
+-rw-r--r--   0        0        0     1466 2022-01-17 10:27:57.308266 hisparc_sapphire-3.0.0/sapphire/corsika/LICENSE
+-rw-r--r--   0        0        0      413 2022-11-04 07:15:35.924278 hisparc_sapphire-3.0.0/sapphire/corsika/README.md
+-rw-r--r--   0        0        0     1087 2024-04-14 19:13:10.139647 hisparc_sapphire-3.0.0/sapphire/corsika/__init__.py
+-rw-r--r--   0        0        0    20876 2024-04-27 10:33:05.897299 hisparc_sapphire-3.0.0/sapphire/corsika/blocks.py
+-rw-r--r--   0        0        0     6866 2024-05-04 20:41:54.699976 hisparc_sapphire-3.0.0/sapphire/corsika/corsika_queries.py
+-rw-r--r--   0        0        0     6865 2024-04-27 10:33:32.730566 hisparc_sapphire-3.0.0/sapphire/corsika/generate_corsika_overview.py
+-rw-r--r--   0        0        0     6238 2024-04-27 09:49:05.888559 hisparc_sapphire-3.0.0/sapphire/corsika/mergesort.py
+-rw-r--r--   0        0        0     9457 2024-04-14 19:13:10.138052 hisparc_sapphire-3.0.0/sapphire/corsika/particles.py
+-rw-r--r--   0        0        0    13725 2024-04-27 10:46:22.087291 hisparc_sapphire-3.0.0/sapphire/corsika/qsub_corsika.py
+-rw-r--r--   0        0        0     4664 2024-04-27 10:46:43.162684 hisparc_sapphire-3.0.0/sapphire/corsika/qsub_store_corsika_data.py
+-rw-r--r--   0        0        0    14029 2024-04-27 11:26:12.502190 hisparc_sapphire-3.0.0/sapphire/corsika/reader.py
+-rw-r--r--   0        0        0     8275 2024-04-27 09:52:12.366350 hisparc_sapphire-3.0.0/sapphire/corsika/store_corsika_data.py
+-rw-r--r--   0        0        0     5906 2024-04-14 19:13:10.144641 hisparc_sapphire-3.0.0/sapphire/corsika/units.py
+-rw-r--r--   0        0        0      385 2024-04-14 19:13:10.140985 hisparc_sapphire-3.0.0/sapphire/data/__init__.py
+-rw-r--r--   0        0        0     1227 2022-08-05 15:47:32.580676 hisparc_sapphire-3.0.0/sapphire/data/clusters.json
+-rw-r--r--   0        0        0      445 2022-08-05 15:47:59.388089 hisparc_sapphire-3.0.0/sapphire/data/clusters/0.json
+-rw-r--r--   0        0        0      130 2022-08-05 15:47:59.437758 hisparc_sapphire-3.0.0/sapphire/data/clusters/1000.json
+-rw-r--r--   0        0        0       68 2022-08-05 15:47:59.771816 hisparc_sapphire-3.0.0/sapphire/data/clusters/11000.json
+-rw-r--r--   0        0        0       65 2022-08-05 15:47:59.826706 hisparc_sapphire-3.0.0/sapphire/data/clusters/12000.json
+-rw-r--r--   0        0        0      452 2022-08-05 15:47:59.883155 hisparc_sapphire-3.0.0/sapphire/data/clusters/13000.json
+-rw-r--r--   0        0        0       69 2022-08-05 15:47:59.932252 hisparc_sapphire-3.0.0/sapphire/data/clusters/14000.json
+-rw-r--r--   0        0        0       65 2022-08-05 15:47:59.984477 hisparc_sapphire-3.0.0/sapphire/data/clusters/15000.json
+-rw-r--r--   0        0        0      130 2022-08-05 15:48:00.042519 hisparc_sapphire-3.0.0/sapphire/data/clusters/16000.json
+-rw-r--r--   0        0        0       65 2022-08-05 15:48:00.100836 hisparc_sapphire-3.0.0/sapphire/data/clusters/17000.json
+-rw-r--r--   0        0        0      194 2022-08-05 15:47:59.492174 hisparc_sapphire-3.0.0/sapphire/data/clusters/2000.json
+-rw-r--r--   0        0        0       65 2022-08-05 15:48:00.157383 hisparc_sapphire-3.0.0/sapphire/data/clusters/20000.json
+-rw-r--r--   0        0        0      540 2022-08-05 15:47:59.549682 hisparc_sapphire-3.0.0/sapphire/data/clusters/3000.json
+-rw-r--r--   0        0        0       67 2022-08-05 15:47:59.606280 hisparc_sapphire-3.0.0/sapphire/data/clusters/4000.json
+-rw-r--r--   0        0        0       67 2022-08-05 15:48:00.210719 hisparc_sapphire-3.0.0/sapphire/data/clusters/40000.json
+-rw-r--r--   0        0        0       73 2022-08-05 15:48:00.262033 hisparc_sapphire-3.0.0/sapphire/data/clusters/50000.json
+-rw-r--r--   0        0        0       67 2022-08-05 15:48:00.313183 hisparc_sapphire-3.0.0/sapphire/data/clusters/60000.json
+-rw-r--r--   0        0        0      447 2022-08-05 15:47:59.662463 hisparc_sapphire-3.0.0/sapphire/data/clusters/7000.json
+-rw-r--r--   0        0        0       68 2022-08-05 15:48:00.365728 hisparc_sapphire-3.0.0/sapphire/data/clusters/70000.json
+-rw-r--r--   0        0        0      322 2022-08-05 15:47:59.715497 hisparc_sapphire-3.0.0/sapphire/data/clusters/8000.json
+-rw-r--r--   0        0        0      530 2022-08-05 15:47:32.618259 hisparc_sapphire-3.0.0/sapphire/data/countries.json
+-rw-r--r--   0        0        0      447 2022-08-05 15:48:00.506452 hisparc_sapphire-3.0.0/sapphire/data/countries/0.json
+-rw-r--r--   0        0        0      452 2022-08-05 15:48:00.562107 hisparc_sapphire-3.0.0/sapphire/data/countries/10000.json
+-rw-r--r--   0        0        0       65 2022-08-05 15:48:00.628981 hisparc_sapphire-3.0.0/sapphire/data/countries/20000.json
+-rw-r--r--   0        0        0        2 2022-08-05 15:48:00.678259 hisparc_sapphire-3.0.0/sapphire/data/countries/30000.json
+-rw-r--r--   0        0        0       67 2022-08-05 15:48:00.743866 hisparc_sapphire-3.0.0/sapphire/data/countries/40000.json
+-rw-r--r--   0        0        0       73 2022-08-05 15:48:00.807056 hisparc_sapphire-3.0.0/sapphire/data/countries/50000.json
+-rw-r--r--   0        0        0       67 2022-08-05 15:48:00.865045 hisparc_sapphire-3.0.0/sapphire/data/countries/60000.json
+-rw-r--r--   0        0        0       68 2022-08-05 15:48:00.929472 hisparc_sapphire-3.0.0/sapphire/data/countries/70000.json
+-rw-r--r--   0        0        0      435 2022-08-05 15:49:56.619074 hisparc_sapphire-3.0.0/sapphire/data/current/10.tsv
+-rw-r--r--   0        0        0    11900 2022-08-05 15:51:00.327408 hisparc_sapphire-3.0.0/sapphire/data/current/1001.tsv
+-rw-r--r--   0        0        0      124 2022-08-05 15:51:00.384993 hisparc_sapphire-3.0.0/sapphire/data/current/1002.tsv
+-rw-r--r--   0        0        0      341 2022-08-05 15:51:00.461058 hisparc_sapphire-3.0.0/sapphire/data/current/1003.tsv
+-rw-r--r--   0        0        0       35 2022-08-05 15:51:00.512207 hisparc_sapphire-3.0.0/sapphire/data/current/1005.tsv
+-rw-r--r--   0        0        0    33298 2022-08-05 15:51:01.671512 hisparc_sapphire-3.0.0/sapphire/data/current/1006.tsv
+-rw-r--r--   0        0        0    20956 2022-08-05 15:51:02.402979 hisparc_sapphire-3.0.0/sapphire/data/current/1007.tsv
+-rw-r--r--   0        0        0    17278 2022-08-05 15:51:03.000189 hisparc_sapphire-3.0.0/sapphire/data/current/1008.tsv
+-rw-r--r--   0        0        0     6218 2022-08-05 15:51:03.258985 hisparc_sapphire-3.0.0/sapphire/data/current/1009.tsv
+-rw-r--r--   0        0        0     9951 2022-08-05 15:50:06.753826 hisparc_sapphire-3.0.0/sapphire/data/current/101.tsv
+-rw-r--r--   0        0        0     7101 2022-08-05 15:51:03.543412 hisparc_sapphire-3.0.0/sapphire/data/current/1010.tsv
+-rw-r--r--   0        0        0   114328 2022-08-05 15:50:10.385336 hisparc_sapphire-3.0.0/sapphire/data/current/102.tsv
+-rw-r--r--   0        0        0      227 2022-08-05 15:50:10.456070 hisparc_sapphire-3.0.0/sapphire/data/current/103.tsv
+-rw-r--r--   0        0        0    44052 2022-08-05 15:50:11.904523 hisparc_sapphire-3.0.0/sapphire/data/current/104.tsv
+-rw-r--r--   0        0        0    31930 2022-08-05 15:50:13.026414 hisparc_sapphire-3.0.0/sapphire/data/current/105.tsv
+-rw-r--r--   0        0        0    28148 2022-08-05 15:50:13.949615 hisparc_sapphire-3.0.0/sapphire/data/current/106.tsv
+-rw-r--r--   0        0        0    60654 2022-08-05 15:51:05.471631 hisparc_sapphire-3.0.0/sapphire/data/current/1101.tsv
+-rw-r--r--   0        0        0    56404 2022-08-05 15:51:07.209359 hisparc_sapphire-3.0.0/sapphire/data/current/1102.tsv
+-rw-r--r--   0        0        0    37290 2022-08-05 15:51:08.431565 hisparc_sapphire-3.0.0/sapphire/data/current/1103.tsv
+-rw-r--r--   0        0        0      620 2022-08-05 15:51:46.092828 hisparc_sapphire-3.0.0/sapphire/data/current/12001.tsv
+-rw-r--r--   0        0        0      651 2022-08-05 15:49:56.707830 hisparc_sapphire-3.0.0/sapphire/data/current/13.tsv
+-rw-r--r--   0        0        0      506 2022-08-05 15:51:46.170833 hisparc_sapphire-3.0.0/sapphire/data/current/13001.tsv
+-rw-r--r--   0        0        0      558 2022-08-05 15:51:46.244890 hisparc_sapphire-3.0.0/sapphire/data/current/13002.tsv
+-rw-r--r--   0        0        0     2275 2022-08-05 15:51:46.371274 hisparc_sapphire-3.0.0/sapphire/data/current/13003.tsv
+-rw-r--r--   0        0        0      620 2022-08-05 15:51:46.442162 hisparc_sapphire-3.0.0/sapphire/data/current/13004.tsv
+-rw-r--r--   0        0        0     1643 2022-08-05 15:51:46.562791 hisparc_sapphire-3.0.0/sapphire/data/current/13005.tsv
+-rw-r--r--   0        0        0      231 2022-08-05 15:51:46.621667 hisparc_sapphire-3.0.0/sapphire/data/current/13006.tsv
+-rw-r--r--   0        0        0       33 2022-08-05 15:51:46.675231 hisparc_sapphire-3.0.0/sapphire/data/current/13007.tsv
+-rw-r--r--   0        0        0      132 2022-08-05 15:51:46.733348 hisparc_sapphire-3.0.0/sapphire/data/current/13008.tsv
+-rw-r--r--   0        0        0      713 2022-08-05 15:51:46.807436 hisparc_sapphire-3.0.0/sapphire/data/current/13009.tsv
+-rw-r--r--   0        0        0      589 2022-08-05 15:51:46.880702 hisparc_sapphire-3.0.0/sapphire/data/current/13101.tsv
+-rw-r--r--   0        0        0      806 2022-08-05 15:51:46.967356 hisparc_sapphire-3.0.0/sapphire/data/current/13102.tsv
+-rw-r--r--   0        0        0       66 2022-08-05 15:51:47.025319 hisparc_sapphire-3.0.0/sapphire/data/current/13103.tsv
+-rw-r--r--   0        0        0    26721 2022-08-05 15:51:47.954083 hisparc_sapphire-3.0.0/sapphire/data/current/13104.tsv
+-rw-r--r--   0        0        0     1395 2022-08-05 15:51:48.061496 hisparc_sapphire-3.0.0/sapphire/data/current/13201.tsv
+-rw-r--r--   0        0        0      310 2022-08-05 15:51:48.126446 hisparc_sapphire-3.0.0/sapphire/data/current/13301.tsv
+-rw-r--r--   0        0        0       33 2022-08-05 15:51:48.180638 hisparc_sapphire-3.0.0/sapphire/data/current/13401.tsv
+-rw-r--r--   0        0        0      231 2022-08-05 15:51:48.242310 hisparc_sapphire-3.0.0/sapphire/data/current/13501.tsv
+-rw-r--r--   0        0        0      264 2022-08-05 15:51:48.305018 hisparc_sapphire-3.0.0/sapphire/data/current/13601.tsv
+-rw-r--r--   0        0        0    37662 2022-08-05 15:51:49.497583 hisparc_sapphire-3.0.0/sapphire/data/current/14001.tsv
+-rw-r--r--   0        0        0     9834 2022-08-05 15:51:49.893316 hisparc_sapphire-3.0.0/sapphire/data/current/14002.tsv
+-rw-r--r--   0        0        0    50490 2022-08-05 15:51:51.445772 hisparc_sapphire-3.0.0/sapphire/data/current/14003.tsv
+-rw-r--r--   0        0        0    39930 2022-08-05 15:51:52.770556 hisparc_sapphire-3.0.0/sapphire/data/current/14004.tsv
+-rw-r--r--   0        0        0    16467 2022-08-05 15:51:53.377941 hisparc_sapphire-3.0.0/sapphire/data/current/14005.tsv
+-rw-r--r--   0        0        0    31251 2022-08-05 15:51:54.407137 hisparc_sapphire-3.0.0/sapphire/data/current/14006.tsv
+-rw-r--r--   0        0        0     6897 2022-08-05 15:51:54.669121 hisparc_sapphire-3.0.0/sapphire/data/current/14007.tsv
+-rw-r--r--   0        0        0    31119 2022-08-05 15:51:55.738550 hisparc_sapphire-3.0.0/sapphire/data/current/14008.tsv
+-rw-r--r--   0        0        0    90354 2022-08-05 15:49:59.735850 hisparc_sapphire-3.0.0/sapphire/data/current/15.tsv
+-rw-r--r--   0        0        0      857 2022-08-05 15:51:55.840123 hisparc_sapphire-3.0.0/sapphire/data/current/15001.tsv
+-rw-r--r--   0        0        0      297 2022-08-05 15:51:55.909738 hisparc_sapphire-3.0.0/sapphire/data/current/15002.tsv
+-rw-r--r--   0        0        0    15906 2022-08-05 15:51:56.428539 hisparc_sapphire-3.0.0/sapphire/data/current/16001.tsv
+-rw-r--r--   0        0        0    15510 2022-08-05 15:51:56.960840 hisparc_sapphire-3.0.0/sapphire/data/current/16101.tsv
+-rw-r--r--   0        0        0    23661 2022-08-05 15:51:57.782298 hisparc_sapphire-3.0.0/sapphire/data/current/17001.tsv
+-rw-r--r--   0        0        0      354 2022-08-05 15:49:49.913036 hisparc_sapphire-3.0.0/sapphire/data/current/2.tsv
+-rw-r--r--   0        0        0    20119 2022-08-05 15:51:58.498659 hisparc_sapphire-3.0.0/sapphire/data/current/20001.tsv
+-rw-r--r--   0        0        0    19747 2022-08-05 15:51:59.215135 hisparc_sapphire-3.0.0/sapphire/data/current/20002.tsv
+-rw-r--r--   0        0        0    16337 2022-08-05 15:51:59.829832 hisparc_sapphire-3.0.0/sapphire/data/current/20003.tsv
+-rw-r--r--   0        0        0      341 2022-08-05 15:51:08.504847 hisparc_sapphire-3.0.0/sapphire/data/current/2001.tsv
+-rw-r--r--   0        0        0      620 2022-08-05 15:51:08.585822 hisparc_sapphire-3.0.0/sapphire/data/current/2002.tsv
+-rw-r--r--   0        0        0      527 2022-08-05 15:51:08.666113 hisparc_sapphire-3.0.0/sapphire/data/current/2003.tsv
+-rw-r--r--   0        0        0      257 2022-08-05 15:51:08.740711 hisparc_sapphire-3.0.0/sapphire/data/current/2004.tsv
+-rw-r--r--   0        0        0      496 2022-08-05 15:51:08.813087 hisparc_sapphire-3.0.0/sapphire/data/current/2005.tsv
+-rw-r--r--   0        0        0      217 2022-08-05 15:51:08.884997 hisparc_sapphire-3.0.0/sapphire/data/current/2006.tsv
+-rw-r--r--   0        0        0      155 2022-08-05 15:51:08.963523 hisparc_sapphire-3.0.0/sapphire/data/current/2008.tsv
+-rw-r--r--   0        0        0    32589 2022-08-05 15:50:15.176536 hisparc_sapphire-3.0.0/sapphire/data/current/201.tsv
+-rw-r--r--   0        0        0    28996 2022-08-05 15:51:09.963058 hisparc_sapphire-3.0.0/sapphire/data/current/2010.tsv
+-rw-r--r--   0        0        0    62560 2022-08-05 15:50:17.232367 hisparc_sapphire-3.0.0/sapphire/data/current/202.tsv
+-rw-r--r--   0        0        0    46686 2022-08-05 15:50:18.765224 hisparc_sapphire-3.0.0/sapphire/data/current/203.tsv
+-rw-r--r--   0        0        0    55880 2022-08-05 15:50:01.569857 hisparc_sapphire-3.0.0/sapphire/data/current/21.tsv
+-rw-r--r--   0        0        0     1440 2022-08-05 15:51:10.091010 hisparc_sapphire-3.0.0/sapphire/data/current/2101.tsv
+-rw-r--r--   0        0        0     3069 2022-08-05 15:51:10.242815 hisparc_sapphire-3.0.0/sapphire/data/current/2102.tsv
+-rw-r--r--   0        0        0       31 2022-08-05 15:51:10.296326 hisparc_sapphire-3.0.0/sapphire/data/current/2103.tsv
+-rw-r--r--   0        0        0    36166 2022-08-05 15:50:02.743806 hisparc_sapphire-3.0.0/sapphire/data/current/22.tsv
+-rw-r--r--   0        0        0      992 2022-08-05 15:51:10.387985 hisparc_sapphire-3.0.0/sapphire/data/current/2201.tsv
+-rw-r--r--   0        0        0    64878 2022-08-05 15:50:04.739549 hisparc_sapphire-3.0.0/sapphire/data/current/23.tsv
+-rw-r--r--   0        0        0    51329 2022-08-05 15:50:06.378213 hisparc_sapphire-3.0.0/sapphire/data/current/24.tsv
+-rw-r--r--   0        0        0       33 2022-01-17 10:27:57.314942 hisparc_sapphire-3.0.0/sapphire/data/current/25.tsv
+-rw-r--r--   0        0        0     2519 2022-08-05 15:49:50.061266 hisparc_sapphire-3.0.0/sapphire/data/current/3.tsv
+-rw-r--r--   0        0        0    43320 2022-08-05 15:51:11.786697 hisparc_sapphire-3.0.0/sapphire/data/current/3001.tsv
+-rw-r--r--   0        0        0    34451 2022-08-05 15:51:12.936770 hisparc_sapphire-3.0.0/sapphire/data/current/3002.tsv
+-rw-r--r--   0        0        0    54095 2022-08-05 15:50:20.508906 hisparc_sapphire-3.0.0/sapphire/data/current/301.tsv
+-rw-r--r--   0        0        0     6417 2022-08-05 15:50:20.765422 hisparc_sapphire-3.0.0/sapphire/data/current/303.tsv
+-rw-r--r--   0        0        0    33148 2022-08-05 15:50:21.831772 hisparc_sapphire-3.0.0/sapphire/data/current/304.tsv
+-rw-r--r--   0        0        0    51065 2022-08-05 15:50:23.434100 hisparc_sapphire-3.0.0/sapphire/data/current/305.tsv
+-rw-r--r--   0        0        0     1155 2022-08-05 15:51:13.039092 hisparc_sapphire-3.0.0/sapphire/data/current/3101.tsv
+-rw-r--r--   0        0        0      639 2022-08-05 15:51:13.121326 hisparc_sapphire-3.0.0/sapphire/data/current/3102.tsv
+-rw-r--r--   0        0        0       93 2022-08-05 15:51:13.178649 hisparc_sapphire-3.0.0/sapphire/data/current/3103.tsv
+-rw-r--r--   0        0        0      945 2022-08-05 15:51:13.259756 hisparc_sapphire-3.0.0/sapphire/data/current/3104.tsv
+-rw-r--r--   0        0        0     4247 2022-08-05 15:51:13.450018 hisparc_sapphire-3.0.0/sapphire/data/current/3105.tsv
+-rw-r--r--   0        0        0    35062 2022-08-05 15:51:14.676821 hisparc_sapphire-3.0.0/sapphire/data/current/3201.tsv
+-rw-r--r--   0        0        0      713 2022-08-05 15:51:14.768967 hisparc_sapphire-3.0.0/sapphire/data/current/3202.tsv
+-rw-r--r--   0        0        0      531 2022-08-05 15:51:14.841610 hisparc_sapphire-3.0.0/sapphire/data/current/3203.tsv
+-rw-r--r--   0        0        0    27172 2022-08-05 15:51:15.799682 hisparc_sapphire-3.0.0/sapphire/data/current/3301.tsv
+-rw-r--r--   0        0        0      248 2022-08-05 15:51:15.879959 hisparc_sapphire-3.0.0/sapphire/data/current/3302.tsv
+-rw-r--r--   0        0        0    10015 2022-08-05 15:51:16.307045 hisparc_sapphire-3.0.0/sapphire/data/current/3303.tsv
+-rw-r--r--   0        0        0    12995 2022-08-05 15:51:16.817935 hisparc_sapphire-3.0.0/sapphire/data/current/3304.tsv
+-rw-r--r--   0        0        0      341 2022-08-05 15:51:16.893803 hisparc_sapphire-3.0.0/sapphire/data/current/3401.tsv
+-rw-r--r--   0        0        0    42537 2022-08-05 15:51:18.264875 hisparc_sapphire-3.0.0/sapphire/data/current/3501.tsv
+-rw-r--r--   0        0        0    47850 2022-08-05 15:51:19.802831 hisparc_sapphire-3.0.0/sapphire/data/current/3601.tsv
+-rw-r--r--   0        0        0      363 2022-08-05 15:51:19.874168 hisparc_sapphire-3.0.0/sapphire/data/current/3701.tsv
+-rw-r--r--   0        0        0    21179 2022-08-05 15:51:20.610896 hisparc_sapphire-3.0.0/sapphire/data/current/3702.tsv
+-rw-r--r--   0        0        0    28312 2022-08-05 15:49:51.009548 hisparc_sapphire-3.0.0/sapphire/data/current/4.tsv
+-rw-r--r--   0        0        0    15708 2022-08-05 15:52:00.444539 hisparc_sapphire-3.0.0/sapphire/data/current/40001.tsv
+-rw-r--r--   0        0        0     1085 2022-08-05 15:51:20.706135 hisparc_sapphire-3.0.0/sapphire/data/current/4001.tsv
+-rw-r--r--   0        0        0       93 2022-08-05 15:51:20.766312 hisparc_sapphire-3.0.0/sapphire/data/current/4002.tsv
+-rw-r--r--   0        0        0      473 2022-08-05 15:51:20.837216 hisparc_sapphire-3.0.0/sapphire/data/current/4003.tsv
+-rw-r--r--   0        0        0      310 2022-08-05 15:51:20.914948 hisparc_sapphire-3.0.0/sapphire/data/current/4004.tsv
+-rw-r--r--   0        0        0      881 2022-08-05 15:50:23.533580 hisparc_sapphire-3.0.0/sapphire/data/current/401.tsv
+-rw-r--r--   0        0        0    40114 2022-08-05 15:49:52.347387 hisparc_sapphire-3.0.0/sapphire/data/current/5.tsv
+-rw-r--r--   0        0        0    78080 2022-08-05 15:50:26.153319 hisparc_sapphire-3.0.0/sapphire/data/current/501.tsv
+-rw-r--r--   0        0        0    52284 2022-08-05 15:50:27.914357 hisparc_sapphire-3.0.0/sapphire/data/current/502.tsv
+-rw-r--r--   0        0        0    47942 2022-08-05 15:50:29.492000 hisparc_sapphire-3.0.0/sapphire/data/current/503.tsv
+-rw-r--r--   0        0        0    49104 2022-08-05 15:50:31.264414 hisparc_sapphire-3.0.0/sapphire/data/current/504.tsv
+-rw-r--r--   0        0        0    44330 2022-08-05 15:50:32.760005 hisparc_sapphire-3.0.0/sapphire/data/current/505.tsv
+-rw-r--r--   0        0        0      899 2022-08-05 15:50:32.855868 hisparc_sapphire-3.0.0/sapphire/data/current/506.tsv
+-rw-r--r--   0        0        0    58769 2022-08-05 15:50:34.845726 hisparc_sapphire-3.0.0/sapphire/data/current/507.tsv
+-rw-r--r--   0        0        0    51593 2022-08-05 15:50:36.585822 hisparc_sapphire-3.0.0/sapphire/data/current/508.tsv
+-rw-r--r--   0        0        0    44330 2022-08-05 15:50:38.117136 hisparc_sapphire-3.0.0/sapphire/data/current/509.tsv
+-rw-r--r--   0        0        0    79638 2022-08-05 15:50:40.584268 hisparc_sapphire-3.0.0/sapphire/data/current/510.tsv
+-rw-r--r--   0        0        0    47185 2022-08-05 15:50:42.114746 hisparc_sapphire-3.0.0/sapphire/data/current/511.tsv
+-rw-r--r--   0        0        0    48668 2022-08-05 15:50:43.649696 hisparc_sapphire-3.0.0/sapphire/data/current/512.tsv
+-rw-r--r--   0        0        0    43834 2022-08-05 15:50:45.184363 hisparc_sapphire-3.0.0/sapphire/data/current/513.tsv
+-rw-r--r--   0        0        0    33480 2022-08-05 15:50:46.412144 hisparc_sapphire-3.0.0/sapphire/data/current/514.tsv
+-rw-r--r--   0        0        0      231 2022-08-05 15:50:46.473665 hisparc_sapphire-3.0.0/sapphire/data/current/521.tsv
+-rw-r--r--   0        0        0       70 2022-08-05 15:50:46.530009 hisparc_sapphire-3.0.0/sapphire/data/current/522.tsv
+-rw-r--r--   0        0        0   278566 2022-08-05 15:50:55.584012 hisparc_sapphire-3.0.0/sapphire/data/current/599.tsv
+-rw-r--r--   0        0        0    67315 2022-08-05 15:49:54.394556 hisparc_sapphire-3.0.0/sapphire/data/current/6.tsv
+-rw-r--r--   0        0        0     4619 2022-08-05 15:52:00.639356 hisparc_sapphire-3.0.0/sapphire/data/current/60001.tsv
+-rw-r--r--   0        0        0    47401 2022-08-05 15:50:57.167033 hisparc_sapphire-3.0.0/sapphire/data/current/601.tsv
+-rw-r--r--   0        0        0    46134 2022-08-05 15:50:58.599862 hisparc_sapphire-3.0.0/sapphire/data/current/602.tsv
+-rw-r--r--   0        0        0    29766 2022-08-05 15:50:59.620140 hisparc_sapphire-3.0.0/sapphire/data/current/603.tsv
+-rw-r--r--   0        0        0     7359 2022-08-05 15:50:59.889240 hisparc_sapphire-3.0.0/sapphire/data/current/604.tsv
+-rw-r--r--   0        0        0    13516 2022-08-05 15:49:54.895687 hisparc_sapphire-3.0.0/sapphire/data/current/7.tsv
+-rw-r--r--   0        0        0    41433 2022-08-05 15:51:22.258811 hisparc_sapphire-3.0.0/sapphire/data/current/7001.tsv
+-rw-r--r--   0        0        0    34472 2022-08-05 15:51:23.394776 hisparc_sapphire-3.0.0/sapphire/data/current/7002.tsv
+-rw-r--r--   0        0        0    37975 2022-08-05 15:51:24.713598 hisparc_sapphire-3.0.0/sapphire/data/current/7003.tsv
+-rw-r--r--   0        0        0      186 2022-08-05 15:51:24.782742 hisparc_sapphire-3.0.0/sapphire/data/current/7101.tsv
+-rw-r--r--   0        0        0    41975 2022-08-05 15:51:26.148446 hisparc_sapphire-3.0.0/sapphire/data/current/7102.tsv
+-rw-r--r--   0        0        0       62 2022-08-05 15:51:26.219169 hisparc_sapphire-3.0.0/sapphire/data/current/7201.tsv
+-rw-r--r--   0        0        0    42243 2022-08-05 15:51:27.621062 hisparc_sapphire-3.0.0/sapphire/data/current/7301.tsv
+-rw-r--r--   0        0        0    26598 2022-08-05 15:51:28.601104 hisparc_sapphire-3.0.0/sapphire/data/current/7401.tsv
+-rw-r--r--   0        0        0       62 2022-01-17 10:27:57.318474 hisparc_sapphire-3.0.0/sapphire/data/current/7501.tsv
+-rw-r--r--   0        0        0    44616 2022-08-05 15:51:30.044011 hisparc_sapphire-3.0.0/sapphire/data/current/7601.tsv
+-rw-r--r--   0        0        0    53662 2022-08-05 15:51:31.761388 hisparc_sapphire-3.0.0/sapphire/data/current/8001.tsv
+-rw-r--r--   0        0        0      403 2022-08-05 15:51:31.840583 hisparc_sapphire-3.0.0/sapphire/data/current/8002.tsv
+-rw-r--r--   0        0        0    44395 2022-08-05 15:51:33.420402 hisparc_sapphire-3.0.0/sapphire/data/current/8003.tsv
+-rw-r--r--   0        0        0    60819 2022-08-05 15:51:35.350461 hisparc_sapphire-3.0.0/sapphire/data/current/8004.tsv
+-rw-r--r--   0        0        0    37016 2022-08-05 15:51:37.002015 hisparc_sapphire-3.0.0/sapphire/data/current/8005.tsv
+-rw-r--r--   0        0        0     6541 2022-08-05 15:51:37.273870 hisparc_sapphire-3.0.0/sapphire/data/current/8006.tsv
+-rw-r--r--   0        0        0      406 2022-08-05 15:51:37.348788 hisparc_sapphire-3.0.0/sapphire/data/current/8007.tsv
+-rw-r--r--   0        0        0    57164 2022-08-05 15:51:39.261725 hisparc_sapphire-3.0.0/sapphire/data/current/8008.tsv
+-rw-r--r--   0        0        0    57477 2022-08-05 15:51:41.134476 hisparc_sapphire-3.0.0/sapphire/data/current/8009.tsv
+-rw-r--r--   0        0        0     5146 2022-08-05 15:51:41.360738 hisparc_sapphire-3.0.0/sapphire/data/current/8101.tsv
+-rw-r--r--   0        0        0      217 2022-08-05 15:51:41.423611 hisparc_sapphire-3.0.0/sapphire/data/current/8102.tsv
+-rw-r--r--   0        0        0      465 2022-08-05 15:51:41.506749 hisparc_sapphire-3.0.0/sapphire/data/current/8103.tsv
+-rw-r--r--   0        0        0      403 2022-08-05 15:51:41.577630 hisparc_sapphire-3.0.0/sapphire/data/current/8104.tsv
+-rw-r--r--   0        0        0    24743 2022-08-05 15:51:42.424843 hisparc_sapphire-3.0.0/sapphire/data/current/8105.tsv
+-rw-r--r--   0        0        0    19532 2022-08-05 15:51:43.089994 hisparc_sapphire-3.0.0/sapphire/data/current/8201.tsv
+-rw-r--r--   0        0        0      558 2022-08-05 15:51:43.164434 hisparc_sapphire-3.0.0/sapphire/data/current/8301.tsv
+-rw-r--r--   0        0        0      248 2022-08-05 15:51:43.228622 hisparc_sapphire-3.0.0/sapphire/data/current/8302.tsv
+-rw-r--r--   0        0        0      558 2022-08-05 15:51:44.980337 hisparc_sapphire-3.0.0/sapphire/data/current/8303.tsv
+-rw-r--r--   0        0        0    28117 2022-08-05 15:51:46.014426 hisparc_sapphire-3.0.0/sapphire/data/current/8401.tsv
+-rw-r--r--   0        0        0    46384 2022-08-05 15:49:56.545543 hisparc_sapphire-3.0.0/sapphire/data/current/9.tsv
+-rw-r--r--   0        0        0    16690 2022-08-05 15:52:30.782938 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/10.tsv
+-rw-r--r--   0        0        0    18164 2022-08-05 15:52:35.069914 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1001.tsv
+-rw-r--r--   0        0        0      565 2022-08-05 15:52:35.120985 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1002.tsv
+-rw-r--r--   0        0        0    23315 2022-08-05 15:52:35.211840 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1003.tsv
+-rw-r--r--   0        0        0     1030 2022-08-05 15:52:35.257053 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1005.tsv
+-rw-r--r--   0        0        0    50861 2022-08-05 15:52:35.370597 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1006.tsv
+-rw-r--r--   0        0        0    36503 2022-08-05 15:52:35.469281 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1007.tsv
+-rw-r--r--   0        0        0    31520 2022-08-05 15:52:35.564111 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1008.tsv
+-rw-r--r--   0        0        0    42878 2022-08-05 15:52:35.651562 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1009.tsv
+-rw-r--r--   0        0        0    51750 2022-08-05 15:52:31.449780 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/101.tsv
+-rw-r--r--   0        0        0    12547 2022-08-05 15:52:35.710514 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1010.tsv
+-rw-r--r--   0        0        0    49084 2022-08-05 15:52:31.558406 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/102.tsv
+-rw-r--r--   0        0        0    19742 2022-08-05 15:52:31.640659 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/103.tsv
+-rw-r--r--   0        0        0    50987 2022-08-05 15:52:31.747983 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/104.tsv
+-rw-r--r--   0        0        0    32180 2022-08-05 15:52:31.835610 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/105.tsv
+-rw-r--r--   0        0        0    13167 2022-08-05 15:52:31.896993 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/106.tsv
+-rw-r--r--   0        0        0    21551 2022-08-05 15:52:35.786631 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1101.tsv
+-rw-r--r--   0        0        0    43444 2022-08-05 15:52:35.878832 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1102.tsv
+-rw-r--r--   0        0        0    15550 2022-08-05 15:52:35.947853 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1103.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:52:41.048931 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/12001.tsv
+-rw-r--r--   0        0        0    39790 2022-08-05 15:52:30.885442 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13.tsv
+-rw-r--r--   0        0        0    26897 2022-08-05 15:52:41.118094 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13001.tsv
+-rw-r--r--   0        0        0     4369 2022-08-05 15:52:41.170858 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13002.tsv
+-rw-r--r--   0        0        0     4730 2022-08-05 15:52:41.231111 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13003.tsv
+-rw-r--r--   0        0        0     2482 2022-08-05 15:52:41.282735 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13004.tsv
+-rw-r--r--   0        0        0     3589 2022-08-05 15:52:41.348931 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13005.tsv
+-rw-r--r--   0        0        0      195 2022-08-05 15:52:41.399472 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13006.tsv
+-rw-r--r--   0        0        0     1123 2022-08-05 15:52:41.448616 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13007.tsv
+-rw-r--r--   0        0        0      167 2022-08-05 15:52:41.498440 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13008.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:52:41.547323 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13009.tsv
+-rw-r--r--   0        0        0     4970 2022-08-05 15:52:41.605721 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13101.tsv
+-rw-r--r--   0        0        0    11481 2022-08-05 15:52:41.671729 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13102.tsv
+-rw-r--r--   0        0        0     3372 2022-08-05 15:52:41.726276 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13103.tsv
+-rw-r--r--   0        0        0     7085 2022-08-05 15:52:41.787238 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13104.tsv
+-rw-r--r--   0        0        0     4849 2022-08-05 15:52:41.854780 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13201.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:52:41.910160 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13301.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:52:41.958181 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13401.tsv
+-rw-r--r--   0        0        0      517 2022-08-05 15:52:42.006730 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13501.tsv
+-rw-r--r--   0        0        0     1945 2022-08-05 15:52:42.060081 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13601.tsv
+-rw-r--r--   0        0        0    52421 2022-08-05 15:52:42.164403 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14001.tsv
+-rw-r--r--   0        0        0    20550 2022-08-05 15:52:42.230174 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14002.tsv
+-rw-r--r--   0        0        0    19099 2022-08-05 15:52:42.299551 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14003.tsv
+-rw-r--r--   0        0        0    14938 2022-08-05 15:52:42.371075 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14004.tsv
+-rw-r--r--   0        0        0     7125 2022-08-05 15:52:42.430062 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14005.tsv
+-rw-r--r--   0        0        0    16849 2022-08-05 15:52:42.501606 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14006.tsv
+-rw-r--r--   0        0        0     2337 2022-08-05 15:52:42.558344 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14007.tsv
+-rw-r--r--   0        0        0      111 2022-08-05 15:52:42.617133 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14008.tsv
+-rw-r--r--   0        0        0    32848 2022-08-05 15:52:30.969705 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/15.tsv
+-rw-r--r--   0        0        0    17039 2022-08-05 15:52:42.694684 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/15001.tsv
+-rw-r--r--   0        0        0     1698 2022-08-05 15:52:42.750644 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/15002.tsv
+-rw-r--r--   0        0        0    10740 2022-08-05 15:52:42.808431 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/16001.tsv
+-rw-r--r--   0        0        0     6106 2022-08-05 15:52:42.866667 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/16101.tsv
+-rw-r--r--   0        0        0    25658 2022-08-05 15:52:42.941415 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/17001.tsv
+-rw-r--r--   0        0        0     3418 2022-08-05 15:52:30.071566 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2.tsv
+-rw-r--r--   0        0        0    12264 2022-08-05 15:52:43.013679 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/20001.tsv
+-rw-r--r--   0        0        0    15319 2022-08-05 15:52:43.098026 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/20002.tsv
+-rw-r--r--   0        0        0    12663 2022-08-05 15:52:43.174059 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/20003.tsv
+-rw-r--r--   0        0        0     2008 2022-08-05 15:52:36.011454 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2001.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:52:36.070913 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2002.tsv
+-rw-r--r--   0        0        0     1066 2022-08-05 15:52:36.133297 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2003.tsv
+-rw-r--r--   0        0        0      194 2022-08-05 15:52:36.199665 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2004.tsv
+-rw-r--r--   0        0        0    11110 2022-08-05 15:52:36.263726 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2005.tsv
+-rw-r--r--   0        0        0     6800 2022-08-05 15:52:36.336894 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2006.tsv
+-rw-r--r--   0        0        0    14658 2022-08-05 15:52:36.420142 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2008.tsv
+-rw-r--r--   0        0        0   110840 2022-08-05 15:52:32.054290 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/201.tsv
+-rw-r--r--   0        0        0    25716 2022-08-05 15:52:36.500416 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2010.tsv
+-rw-r--r--   0        0        0    49839 2022-08-05 15:52:32.166058 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/202.tsv
+-rw-r--r--   0        0        0    30167 2022-08-05 15:52:32.254170 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/203.tsv
+-rw-r--r--   0        0        0    27411 2022-08-05 15:52:31.059539 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/21.tsv
+-rw-r--r--   0        0        0     1943 2022-08-05 15:52:36.554678 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2101.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:52:36.606136 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2102.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:52:36.660325 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2103.tsv
+-rw-r--r--   0        0        0    61157 2022-08-05 15:52:31.179182 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/22.tsv
+-rw-r--r--   0        0        0    13878 2022-08-05 15:52:36.724058 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2201.tsv
+-rw-r--r--   0        0        0    29926 2022-08-05 15:52:31.268073 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/23.tsv
+-rw-r--r--   0        0        0    28484 2022-08-05 15:52:31.345154 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/24.tsv
+-rw-r--r--   0        0        0    35232 2022-08-05 15:52:30.194965 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3.tsv
+-rw-r--r--   0        0        0    34657 2022-08-05 15:52:36.827905 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3001.tsv
+-rw-r--r--   0        0        0    32015 2022-08-05 15:52:36.926817 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3002.tsv
+-rw-r--r--   0        0        0    32552 2022-08-05 15:52:32.352726 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/301.tsv
+-rw-r--r--   0        0        0    25569 2022-08-05 15:52:32.430690 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/303.tsv
+-rw-r--r--   0        0        0    40547 2022-08-05 15:52:32.532830 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/304.tsv
+-rw-r--r--   0        0        0    41803 2022-08-05 15:52:32.633028 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/305.tsv
+-rw-r--r--   0        0        0    35581 2022-08-05 15:52:37.017394 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3101.tsv
+-rw-r--r--   0        0        0    23763 2022-08-05 15:52:37.098356 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3102.tsv
+-rw-r--r--   0        0        0     4625 2022-08-05 15:52:37.156117 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3103.tsv
+-rw-r--r--   0        0        0     7347 2022-08-05 15:52:37.214669 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3104.tsv
+-rw-r--r--   0        0        0    11197 2022-08-05 15:52:37.270233 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3105.tsv
+-rw-r--r--   0        0        0    98737 2022-08-05 15:52:37.417395 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3201.tsv
+-rw-r--r--   0        0        0    61228 2022-08-05 15:52:37.529107 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3202.tsv
+-rw-r--r--   0        0        0     4263 2022-08-05 15:52:37.582195 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3203.tsv
+-rw-r--r--   0        0        0    41548 2022-08-05 15:52:37.677419 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3301.tsv
+-rw-r--r--   0        0        0    32379 2022-08-05 15:52:37.770917 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3302.tsv
+-rw-r--r--   0        0        0    28702 2022-08-05 15:52:37.857824 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3303.tsv
+-rw-r--r--   0        0        0     4571 2022-08-05 15:52:37.917300 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3304.tsv
+-rw-r--r--   0        0        0    16134 2022-08-05 15:52:37.994845 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3401.tsv
+-rw-r--r--   0        0        0    21939 2022-08-05 15:52:38.070113 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3501.tsv
+-rw-r--r--   0        0        0    19166 2022-08-05 15:52:38.143517 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3601.tsv
+-rw-r--r--   0        0        0     2328 2022-08-05 15:52:38.197864 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3701.tsv
+-rw-r--r--   0        0        0    15750 2022-08-05 15:52:38.261540 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3702.tsv
+-rw-r--r--   0        0        0     7747 2022-08-05 15:52:30.259666 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4.tsv
+-rw-r--r--   0        0        0     1871 2022-08-05 15:52:43.226805 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/40001.tsv
+-rw-r--r--   0        0        0     4440 2022-08-05 15:52:38.321230 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4001.tsv
+-rw-r--r--   0        0        0     2997 2022-08-05 15:52:38.380608 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4002.tsv
+-rw-r--r--   0        0        0     8873 2022-08-05 15:52:38.443791 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4003.tsv
+-rw-r--r--   0        0        0    32523 2022-08-05 15:52:38.541908 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4004.tsv
+-rw-r--r--   0        0        0    27371 2022-08-05 15:52:32.722509 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/401.tsv
+-rw-r--r--   0        0        0    38038 2022-08-05 15:52:30.360177 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/5.tsv
+-rw-r--r--   0        0        0   121084 2022-08-05 15:52:32.895434 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/501.tsv
+-rw-r--r--   0        0        0   114120 2022-08-05 15:52:33.057083 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/502.tsv
+-rw-r--r--   0        0        0   105890 2022-08-05 15:52:33.211459 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/503.tsv
+-rw-r--r--   0        0        0   111766 2022-08-05 15:52:33.374008 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/504.tsv
+-rw-r--r--   0        0        0   118263 2022-08-05 15:52:33.533574 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/505.tsv
+-rw-r--r--   0        0        0    52508 2022-08-05 15:52:33.635684 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/506.tsv
+-rw-r--r--   0        0        0   129482 2022-08-05 15:52:33.803272 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/507.tsv
+-rw-r--r--   0        0        0    66220 2022-08-05 15:52:33.916305 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/508.tsv
+-rw-r--r--   0        0        0    95239 2022-08-05 15:52:34.067727 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/509.tsv
+-rw-r--r--   0        0        0    71767 2022-08-05 15:52:34.189241 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/510.tsv
+-rw-r--r--   0        0        0    54252 2022-08-05 15:52:34.292839 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/511.tsv
+-rw-r--r--   0        0        0    35191 2022-08-05 15:52:34.375751 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/512.tsv
+-rw-r--r--   0        0        0    37225 2022-08-05 15:52:34.458448 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/513.tsv
+-rw-r--r--   0        0        0    29121 2022-08-05 15:52:34.535367 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/514.tsv
+-rw-r--r--   0        0        0      143 2022-08-05 15:52:34.583681 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/521.tsv
+-rw-r--r--   0        0        0       83 2022-08-05 15:52:34.630862 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/522.tsv
+-rw-r--r--   0        0        0      244 2022-08-05 15:52:34.684368 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/599.tsv
+-rw-r--r--   0        0        0    30320 2022-08-05 15:52:30.452476 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/6.tsv
+-rw-r--r--   0        0        0     1543 2022-08-05 15:52:43.278002 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/60001.tsv
+-rw-r--r--   0        0        0    64359 2022-08-05 15:52:34.810057 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/601.tsv
+-rw-r--r--   0        0        0    16125 2022-08-05 15:52:34.877656 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/602.tsv
+-rw-r--r--   0        0        0    11909 2022-08-05 15:52:34.934143 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/603.tsv
+-rw-r--r--   0        0        0     3188 2022-08-05 15:52:34.978937 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/604.tsv
+-rw-r--r--   0        0        0    22653 2022-08-05 15:52:30.534737 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7.tsv
+-rw-r--r--   0        0        0    28257 2022-08-05 15:52:38.634601 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7001.tsv
+-rw-r--r--   0        0        0    34441 2022-08-05 15:52:38.735902 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7002.tsv
+-rw-r--r--   0        0        0    38080 2022-08-05 15:52:38.838284 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7003.tsv
+-rw-r--r--   0        0        0    27031 2022-08-05 15:52:38.916696 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7101.tsv
+-rw-r--r--   0        0        0    14430 2022-08-05 15:52:38.981604 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7102.tsv
+-rw-r--r--   0        0        0    39557 2022-08-05 15:52:39.079266 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7201.tsv
+-rw-r--r--   0        0        0    63151 2022-08-05 15:52:39.197339 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7301.tsv
+-rw-r--r--   0        0        0    34570 2022-08-05 15:52:39.299356 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7401.tsv
+-rw-r--r--   0        0        0       27 2022-01-17 10:27:57.334934 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7501.tsv
+-rw-r--r--   0        0        0     5296 2022-08-05 15:52:39.364385 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7601.tsv
+-rw-r--r--   0        0        0    59554 2022-08-05 15:52:39.479874 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8001.tsv
+-rw-r--r--   0        0        0    29174 2022-08-05 15:52:39.566483 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8002.tsv
+-rw-r--r--   0        0        0   102127 2022-08-05 15:52:39.716869 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8003.tsv
+-rw-r--r--   0        0        0    39079 2022-08-05 15:52:39.816395 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8004.tsv
+-rw-r--r--   0        0        0    23893 2022-08-05 15:52:39.900523 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8005.tsv
+-rw-r--r--   0        0        0    43523 2022-08-05 15:52:40.005587 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8006.tsv
+-rw-r--r--   0        0        0    10633 2022-08-05 15:52:40.060007 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8007.tsv
+-rw-r--r--   0        0        0    28620 2022-08-05 15:52:40.149009 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8008.tsv
+-rw-r--r--   0        0        0    40837 2022-08-05 15:52:40.252139 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8009.tsv
+-rw-r--r--   0        0        0    35875 2022-08-05 15:52:40.342414 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8101.tsv
+-rw-r--r--   0        0        0     2475 2022-08-05 15:52:40.393252 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8102.tsv
+-rw-r--r--   0        0        0    51405 2022-08-05 15:52:40.502193 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8103.tsv
+-rw-r--r--   0        0        0     8438 2022-08-05 15:52:40.556542 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8104.tsv
+-rw-r--r--   0        0        0    32005 2022-08-05 15:52:40.656767 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8105.tsv
+-rw-r--r--   0        0        0    23531 2022-08-05 15:52:40.744591 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8201.tsv
+-rw-r--r--   0        0        0    10930 2022-08-05 15:52:40.817259 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8301.tsv
+-rw-r--r--   0        0        0     2199 2022-08-05 15:52:40.870767 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8302.tsv
+-rw-r--r--   0        0        0    13844 2022-08-05 15:52:40.936876 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8303.tsv
+-rw-r--r--   0        0        0    11348 2022-08-05 15:52:40.997083 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8401.tsv
+-rw-r--r--   0        0        0   100829 2022-08-05 15:52:30.686952 hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/9.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:02.005762 hisparc_sapphire-3.0.0/sapphire/data/electronics/10.tsv
+-rw-r--r--   0        0        0       70 2022-08-05 15:52:14.610015 hisparc_sapphire-3.0.0/sapphire/data/electronics/1001.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:14.661441 hisparc_sapphire-3.0.0/sapphire/data/electronics/1002.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:14.719572 hisparc_sapphire-3.0.0/sapphire/data/electronics/1003.tsv
+-rw-r--r--   0        0        0       25 2022-08-05 15:52:14.774332 hisparc_sapphire-3.0.0/sapphire/data/electronics/1005.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:14.961792 hisparc_sapphire-3.0.0/sapphire/data/electronics/1006.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:15.118855 hisparc_sapphire-3.0.0/sapphire/data/electronics/1007.tsv
+-rw-r--r--   0        0        0       70 2022-08-05 15:52:15.245309 hisparc_sapphire-3.0.0/sapphire/data/electronics/1008.tsv
+-rw-r--r--   0        0        0       69 2022-08-05 15:52:15.322872 hisparc_sapphire-3.0.0/sapphire/data/electronics/1009.tsv
+-rw-r--r--   0        0        0      329 2022-08-05 15:52:03.990754 hisparc_sapphire-3.0.0/sapphire/data/electronics/101.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:15.401640 hisparc_sapphire-3.0.0/sapphire/data/electronics/1010.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:04.534759 hisparc_sapphire-3.0.0/sapphire/data/electronics/102.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:04.593730 hisparc_sapphire-3.0.0/sapphire/data/electronics/103.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:04.831941 hisparc_sapphire-3.0.0/sapphire/data/electronics/104.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:05.020958 hisparc_sapphire-3.0.0/sapphire/data/electronics/105.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:05.186643 hisparc_sapphire-3.0.0/sapphire/data/electronics/106.tsv
+-rw-r--r--   0        0        0      168 2022-08-05 15:52:15.799723 hisparc_sapphire-3.0.0/sapphire/data/electronics/1101.tsv
+-rw-r--r--   0        0        0      175 2022-08-05 15:52:16.054571 hisparc_sapphire-3.0.0/sapphire/data/electronics/1102.tsv
+-rw-r--r--   0        0        0       96 2022-08-05 15:52:16.264401 hisparc_sapphire-3.0.0/sapphire/data/electronics/1103.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:26.467101 hisparc_sapphire-3.0.0/sapphire/data/electronics/12001.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:02.072470 hisparc_sapphire-3.0.0/sapphire/data/electronics/13.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:26.517351 hisparc_sapphire-3.0.0/sapphire/data/electronics/13001.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:26.574104 hisparc_sapphire-3.0.0/sapphire/data/electronics/13002.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:26.641196 hisparc_sapphire-3.0.0/sapphire/data/electronics/13003.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:26.693330 hisparc_sapphire-3.0.0/sapphire/data/electronics/13004.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:26.761101 hisparc_sapphire-3.0.0/sapphire/data/electronics/13005.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:26.814602 hisparc_sapphire-3.0.0/sapphire/data/electronics/13006.tsv
+-rw-r--r--   0        0        0       25 2022-08-05 15:52:26.865676 hisparc_sapphire-3.0.0/sapphire/data/electronics/13007.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:26.916804 hisparc_sapphire-3.0.0/sapphire/data/electronics/13008.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:26.969500 hisparc_sapphire-3.0.0/sapphire/data/electronics/13009.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:27.025456 hisparc_sapphire-3.0.0/sapphire/data/electronics/13101.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:27.085173 hisparc_sapphire-3.0.0/sapphire/data/electronics/13102.tsv
+-rw-r--r--   0        0        0       25 2022-08-05 15:52:27.134493 hisparc_sapphire-3.0.0/sapphire/data/electronics/13103.tsv
+-rw-r--r--   0        0        0       49 2022-08-05 15:52:27.288609 hisparc_sapphire-3.0.0/sapphire/data/electronics/13104.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:27.351111 hisparc_sapphire-3.0.0/sapphire/data/electronics/13201.tsv
+-rw-r--r--   0        0        0       22 2022-08-05 15:52:27.405485 hisparc_sapphire-3.0.0/sapphire/data/electronics/13301.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:27.456549 hisparc_sapphire-3.0.0/sapphire/data/electronics/13401.tsv
+-rw-r--r--   0        0        0       50 2022-08-05 15:52:27.503387 hisparc_sapphire-3.0.0/sapphire/data/electronics/13501.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:27.555277 hisparc_sapphire-3.0.0/sapphire/data/electronics/13601.tsv
+-rw-r--r--   0        0        0       49 2022-08-05 15:52:27.745296 hisparc_sapphire-3.0.0/sapphire/data/electronics/14001.tsv
+-rw-r--r--   0        0        0       74 2022-08-05 15:52:27.839359 hisparc_sapphire-3.0.0/sapphire/data/electronics/14002.tsv
+-rw-r--r--   0        0        0      196 2022-08-05 15:52:28.084104 hisparc_sapphire-3.0.0/sapphire/data/electronics/14003.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:28.298441 hisparc_sapphire-3.0.0/sapphire/data/electronics/14004.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:28.417128 hisparc_sapphire-3.0.0/sapphire/data/electronics/14005.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:28.606296 hisparc_sapphire-3.0.0/sapphire/data/electronics/14006.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:28.688237 hisparc_sapphire-3.0.0/sapphire/data/electronics/14007.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:28.889957 hisparc_sapphire-3.0.0/sapphire/data/electronics/14008.tsv
+-rw-r--r--   0        0        0       96 2022-08-05 15:52:02.865114 hisparc_sapphire-3.0.0/sapphire/data/electronics/15.tsv
+-rw-r--r--   0        0        0      120 2022-08-05 15:52:28.964614 hisparc_sapphire-3.0.0/sapphire/data/electronics/15001.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:29.027708 hisparc_sapphire-3.0.0/sapphire/data/electronics/15002.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:29.139309 hisparc_sapphire-3.0.0/sapphire/data/electronics/16001.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:29.253491 hisparc_sapphire-3.0.0/sapphire/data/electronics/16101.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:29.410987 hisparc_sapphire-3.0.0/sapphire/data/electronics/17001.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:00.693413 hisparc_sapphire-3.0.0/sapphire/data/electronics/2.tsv
+-rw-r--r--   0        0        0       22 2022-08-05 15:52:29.557545 hisparc_sapphire-3.0.0/sapphire/data/electronics/20001.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:29.695687 hisparc_sapphire-3.0.0/sapphire/data/electronics/20002.tsv
+-rw-r--r--   0        0        0       22 2022-08-05 15:52:29.826597 hisparc_sapphire-3.0.0/sapphire/data/electronics/20003.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:16.323612 hisparc_sapphire-3.0.0/sapphire/data/electronics/2001.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:16.383242 hisparc_sapphire-3.0.0/sapphire/data/electronics/2002.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:16.443810 hisparc_sapphire-3.0.0/sapphire/data/electronics/2003.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:16.499965 hisparc_sapphire-3.0.0/sapphire/data/electronics/2004.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:16.555820 hisparc_sapphire-3.0.0/sapphire/data/electronics/2005.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:16.617011 hisparc_sapphire-3.0.0/sapphire/data/electronics/2006.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:16.679393 hisparc_sapphire-3.0.0/sapphire/data/electronics/2008.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:05.375198 hisparc_sapphire-3.0.0/sapphire/data/electronics/201.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:16.853890 hisparc_sapphire-3.0.0/sapphire/data/electronics/2010.tsv
+-rw-r--r--   0        0        0      165 2022-08-05 15:52:05.691217 hisparc_sapphire-3.0.0/sapphire/data/electronics/202.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:05.944070 hisparc_sapphire-3.0.0/sapphire/data/electronics/203.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:03.143564 hisparc_sapphire-3.0.0/sapphire/data/electronics/21.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:16.940473 hisparc_sapphire-3.0.0/sapphire/data/electronics/2101.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:17.006651 hisparc_sapphire-3.0.0/sapphire/data/electronics/2102.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:17.057127 hisparc_sapphire-3.0.0/sapphire/data/electronics/2103.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:03.349511 hisparc_sapphire-3.0.0/sapphire/data/electronics/22.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:17.114368 hisparc_sapphire-3.0.0/sapphire/data/electronics/2201.tsv
+-rw-r--r--   0        0        0      122 2022-08-05 15:52:03.645996 hisparc_sapphire-3.0.0/sapphire/data/electronics/23.tsv
+-rw-r--r--   0        0        0      321 2022-08-05 15:52:03.886252 hisparc_sapphire-3.0.0/sapphire/data/electronics/24.tsv
+-rw-r--r--   0        0        0       24 2022-01-17 10:27:57.341227 hisparc_sapphire-3.0.0/sapphire/data/electronics/25.tsv
+-rw-r--r--   0        0        0       94 2022-08-05 15:52:00.755425 hisparc_sapphire-3.0.0/sapphire/data/electronics/3.tsv
+-rw-r--r--   0        0        0       95 2022-08-05 15:52:17.357539 hisparc_sapphire-3.0.0/sapphire/data/electronics/3001.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:17.563776 hisparc_sapphire-3.0.0/sapphire/data/electronics/3002.tsv
+-rw-r--r--   0        0        0       72 2022-08-05 15:52:06.280494 hisparc_sapphire-3.0.0/sapphire/data/electronics/301.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:06.366195 hisparc_sapphire-3.0.0/sapphire/data/electronics/303.tsv
+-rw-r--r--   0        0        0       71 2022-08-05 15:52:06.557063 hisparc_sapphire-3.0.0/sapphire/data/electronics/304.tsv
+-rw-r--r--   0        0        0       69 2022-08-05 15:52:06.837437 hisparc_sapphire-3.0.0/sapphire/data/electronics/305.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:17.629181 hisparc_sapphire-3.0.0/sapphire/data/electronics/3101.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:17.689259 hisparc_sapphire-3.0.0/sapphire/data/electronics/3102.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:17.747508 hisparc_sapphire-3.0.0/sapphire/data/electronics/3103.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:17.799781 hisparc_sapphire-3.0.0/sapphire/data/electronics/3104.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:17.870944 hisparc_sapphire-3.0.0/sapphire/data/electronics/3105.tsv
+-rw-r--r--   0        0        0      221 2022-08-05 15:52:18.070464 hisparc_sapphire-3.0.0/sapphire/data/electronics/3201.tsv
+-rw-r--r--   0        0        0       43 2022-08-05 15:52:18.133711 hisparc_sapphire-3.0.0/sapphire/data/electronics/3202.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:18.187906 hisparc_sapphire-3.0.0/sapphire/data/electronics/3203.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:18.348970 hisparc_sapphire-3.0.0/sapphire/data/electronics/3301.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:18.412231 hisparc_sapphire-3.0.0/sapphire/data/electronics/3302.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:18.520766 hisparc_sapphire-3.0.0/sapphire/data/electronics/3303.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:18.629112 hisparc_sapphire-3.0.0/sapphire/data/electronics/3304.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:18.692835 hisparc_sapphire-3.0.0/sapphire/data/electronics/3401.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:18.902542 hisparc_sapphire-3.0.0/sapphire/data/electronics/3501.tsv
+-rw-r--r--   0        0        0      144 2022-08-05 15:52:19.142272 hisparc_sapphire-3.0.0/sapphire/data/electronics/3601.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:19.203684 hisparc_sapphire-3.0.0/sapphire/data/electronics/3701.tsv
+-rw-r--r--   0        0        0       69 2022-08-05 15:52:19.334711 hisparc_sapphire-3.0.0/sapphire/data/electronics/3702.tsv
+-rw-r--r--   0        0        0      119 2022-08-05 15:52:00.929689 hisparc_sapphire-3.0.0/sapphire/data/electronics/4.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:29.936560 hisparc_sapphire-3.0.0/sapphire/data/electronics/40001.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:19.390203 hisparc_sapphire-3.0.0/sapphire/data/electronics/4001.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:19.442592 hisparc_sapphire-3.0.0/sapphire/data/electronics/4002.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:19.499918 hisparc_sapphire-3.0.0/sapphire/data/electronics/4003.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:19.562709 hisparc_sapphire-3.0.0/sapphire/data/electronics/4004.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:06.901990 hisparc_sapphire-3.0.0/sapphire/data/electronics/401.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:01.161570 hisparc_sapphire-3.0.0/sapphire/data/electronics/5.tsv
+-rw-r--r--   0        0        0      421 2022-08-05 15:52:07.275249 hisparc_sapphire-3.0.0/sapphire/data/electronics/501.tsv
+-rw-r--r--   0        0        0      273 2022-08-05 15:52:07.553229 hisparc_sapphire-3.0.0/sapphire/data/electronics/502.tsv
+-rw-r--r--   0        0        0       96 2022-08-05 15:52:07.796137 hisparc_sapphire-3.0.0/sapphire/data/electronics/503.tsv
+-rw-r--r--   0        0        0      265 2022-08-05 15:52:08.056383 hisparc_sapphire-3.0.0/sapphire/data/electronics/504.tsv
+-rw-r--r--   0        0        0      119 2022-08-05 15:52:08.302661 hisparc_sapphire-3.0.0/sapphire/data/electronics/505.tsv
+-rw-r--r--   0        0        0       73 2022-08-05 15:52:08.368857 hisparc_sapphire-3.0.0/sapphire/data/electronics/506.tsv
+-rw-r--r--   0        0        0      184 2022-08-05 15:52:08.733583 hisparc_sapphire-3.0.0/sapphire/data/electronics/507.tsv
+-rw-r--r--   0        0        0      298 2022-08-05 15:52:10.186674 hisparc_sapphire-3.0.0/sapphire/data/electronics/508.tsv
+-rw-r--r--   0        0        0       74 2022-08-05 15:52:10.431815 hisparc_sapphire-3.0.0/sapphire/data/electronics/509.tsv
+-rw-r--r--   0        0        0      300 2022-08-05 15:52:10.884232 hisparc_sapphire-3.0.0/sapphire/data/electronics/510.tsv
+-rw-r--r--   0        0        0      125 2022-08-05 15:52:11.113666 hisparc_sapphire-3.0.0/sapphire/data/electronics/511.tsv
+-rw-r--r--   0        0        0      100 2022-08-05 15:52:11.340226 hisparc_sapphire-3.0.0/sapphire/data/electronics/512.tsv
+-rw-r--r--   0        0        0       75 2022-08-05 15:52:11.574922 hisparc_sapphire-3.0.0/sapphire/data/electronics/513.tsv
+-rw-r--r--   0        0        0      148 2022-08-05 15:52:11.767744 hisparc_sapphire-3.0.0/sapphire/data/electronics/514.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:11.821923 hisparc_sapphire-3.0.0/sapphire/data/electronics/521.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:11.870577 hisparc_sapphire-3.0.0/sapphire/data/electronics/522.tsv
+-rw-r--r--   0        0        0      583 2022-08-05 15:52:13.751824 hisparc_sapphire-3.0.0/sapphire/data/electronics/599.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:01.566896 hisparc_sapphire-3.0.0/sapphire/data/electronics/6.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:30.009139 hisparc_sapphire-3.0.0/sapphire/data/electronics/60001.tsv
+-rw-r--r--   0        0        0       92 2022-08-05 15:52:14.025462 hisparc_sapphire-3.0.0/sapphire/data/electronics/601.tsv
+-rw-r--r--   0        0        0       96 2022-08-05 15:52:14.248577 hisparc_sapphire-3.0.0/sapphire/data/electronics/602.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:14.417625 hisparc_sapphire-3.0.0/sapphire/data/electronics/603.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:14.500586 hisparc_sapphire-3.0.0/sapphire/data/electronics/604.tsv
+-rw-r--r--   0        0        0      263 2022-08-05 15:52:01.690547 hisparc_sapphire-3.0.0/sapphire/data/electronics/7.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:19.796399 hisparc_sapphire-3.0.0/sapphire/data/electronics/7001.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:20.004522 hisparc_sapphire-3.0.0/sapphire/data/electronics/7002.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:20.227201 hisparc_sapphire-3.0.0/sapphire/data/electronics/7003.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:20.285714 hisparc_sapphire-3.0.0/sapphire/data/electronics/7101.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:20.501010 hisparc_sapphire-3.0.0/sapphire/data/electronics/7102.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:20.564712 hisparc_sapphire-3.0.0/sapphire/data/electronics/7201.tsv
+-rw-r--r--   0        0        0       95 2022-08-05 15:52:20.783572 hisparc_sapphire-3.0.0/sapphire/data/electronics/7301.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:20.968300 hisparc_sapphire-3.0.0/sapphire/data/electronics/7401.tsv
+-rw-r--r--   0        0        0       24 2022-01-17 10:27:57.344250 hisparc_sapphire-3.0.0/sapphire/data/electronics/7501.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:21.214244 hisparc_sapphire-3.0.0/sapphire/data/electronics/7601.tsv
+-rw-r--r--   0        0        0      162 2022-08-05 15:52:21.494353 hisparc_sapphire-3.0.0/sapphire/data/electronics/8001.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:21.559800 hisparc_sapphire-3.0.0/sapphire/data/electronics/8002.tsv
+-rw-r--r--   0        0        0       95 2022-08-05 15:52:21.796388 hisparc_sapphire-3.0.0/sapphire/data/electronics/8003.tsv
+-rw-r--r--   0        0        0       92 2022-08-05 15:52:22.147724 hisparc_sapphire-3.0.0/sapphire/data/electronics/8004.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:22.377709 hisparc_sapphire-3.0.0/sapphire/data/electronics/8005.tsv
+-rw-r--r--   0        0        0       95 2022-08-05 15:52:22.469904 hisparc_sapphire-3.0.0/sapphire/data/electronics/8006.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:22.524606 hisparc_sapphire-3.0.0/sapphire/data/electronics/8007.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:22.867295 hisparc_sapphire-3.0.0/sapphire/data/electronics/8008.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:23.266587 hisparc_sapphire-3.0.0/sapphire/data/electronics/8009.tsv
+-rw-r--r--   0        0        0       70 2022-08-05 15:52:23.344636 hisparc_sapphire-3.0.0/sapphire/data/electronics/8101.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:23.400776 hisparc_sapphire-3.0.0/sapphire/data/electronics/8102.tsv
+-rw-r--r--   0        0        0       46 2022-08-05 15:52:23.466395 hisparc_sapphire-3.0.0/sapphire/data/electronics/8103.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:23.521657 hisparc_sapphire-3.0.0/sapphire/data/electronics/8104.tsv
+-rw-r--r--   0        0        0       48 2022-08-05 15:52:23.687895 hisparc_sapphire-3.0.0/sapphire/data/electronics/8105.tsv
+-rw-r--r--   0        0        0       23 2022-08-05 15:52:23.829578 hisparc_sapphire-3.0.0/sapphire/data/electronics/8201.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:23.889783 hisparc_sapphire-3.0.0/sapphire/data/electronics/8301.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:23.941758 hisparc_sapphire-3.0.0/sapphire/data/electronics/8302.tsv
+-rw-r--r--   0        0        0       24 2022-08-05 15:52:26.245789 hisparc_sapphire-3.0.0/sapphire/data/electronics/8303.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:52:26.414676 hisparc_sapphire-3.0.0/sapphire/data/electronics/8401.tsv
+-rw-r--r--   0        0        0      543 2022-08-05 15:52:01.944003 hisparc_sapphire-3.0.0/sapphire/data/electronics/9.tsv
+-rw-r--r--   0        0        0     1506 2024-04-14 19:13:10.154848 hisparc_sapphire-3.0.0/sapphire/data/extend_local_data.py
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:03.355094 hisparc_sapphire-3.0.0/sapphire/data/gps/10.tsv
+-rw-r--r--   0        0        0      266 2022-08-05 15:48:19.525894 hisparc_sapphire-3.0.0/sapphire/data/gps/1001.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:19.584543 hisparc_sapphire-3.0.0/sapphire/data/gps/1002.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:19.658855 hisparc_sapphire-3.0.0/sapphire/data/gps/1003.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:19.717527 hisparc_sapphire-3.0.0/sapphire/data/gps/1005.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:19.979496 hisparc_sapphire-3.0.0/sapphire/data/gps/1006.tsv
+-rw-r--r--   0        0        0     3649 2022-08-05 15:48:20.274236 hisparc_sapphire-3.0.0/sapphire/data/gps/1007.tsv
+-rw-r--r--   0        0        0      230 2022-08-05 15:48:20.460301 hisparc_sapphire-3.0.0/sapphire/data/gps/1008.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:20.559564 hisparc_sapphire-3.0.0/sapphire/data/gps/1009.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:05.912031 hisparc_sapphire-3.0.0/sapphire/data/gps/101.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:20.662929 hisparc_sapphire-3.0.0/sapphire/data/gps/1010.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:06.657490 hisparc_sapphire-3.0.0/sapphire/data/gps/102.tsv
+-rw-r--r--   0        0        0       76 2022-08-05 15:48:06.736821 hisparc_sapphire-3.0.0/sapphire/data/gps/103.tsv
+-rw-r--r--   0        0        0       76 2022-08-05 15:48:07.168057 hisparc_sapphire-3.0.0/sapphire/data/gps/104.tsv
+-rw-r--r--   0        0        0      494 2022-08-05 15:48:07.442031 hisparc_sapphire-3.0.0/sapphire/data/gps/105.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:07.672593 hisparc_sapphire-3.0.0/sapphire/data/gps/106.tsv
+-rw-r--r--   0        0        0      722 2022-08-05 15:48:21.095545 hisparc_sapphire-3.0.0/sapphire/data/gps/1101.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:21.504204 hisparc_sapphire-3.0.0/sapphire/data/gps/1102.tsv
+-rw-r--r--   0        0        0      418 2022-08-05 15:48:21.915186 hisparc_sapphire-3.0.0/sapphire/data/gps/1103.tsv
+-rw-r--r--   0        0        0      240 2022-08-05 15:48:36.358023 hisparc_sapphire-3.0.0/sapphire/data/gps/12001.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:03.440468 hisparc_sapphire-3.0.0/sapphire/data/gps/13.tsv
+-rw-r--r--   0        0        0      240 2022-08-05 15:48:36.433773 hisparc_sapphire-3.0.0/sapphire/data/gps/13001.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:48:36.498803 hisparc_sapphire-3.0.0/sapphire/data/gps/13002.tsv
+-rw-r--r--   0        0        0      480 2022-08-05 15:48:36.595518 hisparc_sapphire-3.0.0/sapphire/data/gps/13003.tsv
+-rw-r--r--   0        0        0      200 2022-08-05 15:48:36.674890 hisparc_sapphire-3.0.0/sapphire/data/gps/13004.tsv
+-rw-r--r--   0        0        0      120 2022-08-05 15:48:36.780868 hisparc_sapphire-3.0.0/sapphire/data/gps/13005.tsv
+-rw-r--r--   0        0        0      200 2022-08-05 15:48:36.852356 hisparc_sapphire-3.0.0/sapphire/data/gps/13006.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:48:36.910984 hisparc_sapphire-3.0.0/sapphire/data/gps/13007.tsv
+-rw-r--r--   0        0        0      156 2022-08-05 15:48:36.987567 hisparc_sapphire-3.0.0/sapphire/data/gps/13008.tsv
+-rw-r--r--   0        0        0       80 2022-08-05 15:48:37.056634 hisparc_sapphire-3.0.0/sapphire/data/gps/13009.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:48:37.128750 hisparc_sapphire-3.0.0/sapphire/data/gps/13101.tsv
+-rw-r--r--   0        0        0      200 2022-08-05 15:48:37.203053 hisparc_sapphire-3.0.0/sapphire/data/gps/13102.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:48:37.265532 hisparc_sapphire-3.0.0/sapphire/data/gps/13103.tsv
+-rw-r--r--   0        0        0      160 2022-08-05 15:48:37.481791 hisparc_sapphire-3.0.0/sapphire/data/gps/13104.tsv
+-rw-r--r--   0        0        0      240 2022-08-05 15:48:37.568215 hisparc_sapphire-3.0.0/sapphire/data/gps/13201.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:48:37.634529 hisparc_sapphire-3.0.0/sapphire/data/gps/13301.tsv
+-rw-r--r--   0        0        0       80 2022-08-05 15:48:37.756692 hisparc_sapphire-3.0.0/sapphire/data/gps/13501.tsv
+-rw-r--r--   0        0        0      120 2022-08-05 15:48:37.824566 hisparc_sapphire-3.0.0/sapphire/data/gps/13601.tsv
+-rw-r--r--   0        0        0      600 2022-08-05 15:48:38.102019 hisparc_sapphire-3.0.0/sapphire/data/gps/14001.tsv
+-rw-r--r--   0        0        0      160 2022-08-05 15:48:38.226842 hisparc_sapphire-3.0.0/sapphire/data/gps/14002.tsv
+-rw-r--r--   0        0        0      120 2022-08-05 15:48:39.016448 hisparc_sapphire-3.0.0/sapphire/data/gps/14003.tsv
+-rw-r--r--   0        0        0     1080 2022-08-05 15:48:39.425875 hisparc_sapphire-3.0.0/sapphire/data/gps/14004.tsv
+-rw-r--r--   0        0        0      200 2022-08-05 15:48:39.586096 hisparc_sapphire-3.0.0/sapphire/data/gps/14005.tsv
+-rw-r--r--   0        0        0       80 2022-08-05 15:48:39.847854 hisparc_sapphire-3.0.0/sapphire/data/gps/14006.tsv
+-rw-r--r--   0        0        0       80 2022-08-05 15:48:39.952292 hisparc_sapphire-3.0.0/sapphire/data/gps/14007.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:48:40.236716 hisparc_sapphire-3.0.0/sapphire/data/gps/14008.tsv
+-rw-r--r--   0        0        0     6802 2022-08-05 15:48:04.103944 hisparc_sapphire-3.0.0/sapphire/data/gps/15.tsv
+-rw-r--r--   0        0        0      559 2022-08-05 15:48:40.334382 hisparc_sapphire-3.0.0/sapphire/data/gps/15001.tsv
+-rw-r--r--   0        0        0      120 2022-08-05 15:48:40.409078 hisparc_sapphire-3.0.0/sapphire/data/gps/15002.tsv
+-rw-r--r--   0        0        0      156 2022-08-05 15:48:40.568163 hisparc_sapphire-3.0.0/sapphire/data/gps/16001.tsv
+-rw-r--r--   0        0        0      160 2022-08-05 15:48:40.733951 hisparc_sapphire-3.0.0/sapphire/data/gps/16101.tsv
+-rw-r--r--   0        0        0     7488 2022-08-05 15:48:41.168206 hisparc_sapphire-3.0.0/sapphire/data/gps/17001.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:01.152654 hisparc_sapphire-3.0.0/sapphire/data/gps/2.tsv
+-rw-r--r--   0        0        0      278 2022-08-05 15:48:41.370687 hisparc_sapphire-3.0.0/sapphire/data/gps/20001.tsv
+-rw-r--r--   0        0        0      119 2022-08-05 15:48:41.561344 hisparc_sapphire-3.0.0/sapphire/data/gps/20002.tsv
+-rw-r--r--   0        0        0      159 2022-08-05 15:48:41.740961 hisparc_sapphire-3.0.0/sapphire/data/gps/20003.tsv
+-rw-r--r--   0        0        0      156 2022-08-05 15:48:21.992294 hisparc_sapphire-3.0.0/sapphire/data/gps/2001.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:22.065977 hisparc_sapphire-3.0.0/sapphire/data/gps/2002.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:22.147016 hisparc_sapphire-3.0.0/sapphire/data/gps/2003.tsv
+-rw-r--r--   0        0        0       76 2022-08-05 15:48:22.224126 hisparc_sapphire-3.0.0/sapphire/data/gps/2004.tsv
+-rw-r--r--   0        0        0      418 2022-08-05 15:48:22.300493 hisparc_sapphire-3.0.0/sapphire/data/gps/2005.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:22.385620 hisparc_sapphire-3.0.0/sapphire/data/gps/2006.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:22.471038 hisparc_sapphire-3.0.0/sapphire/data/gps/2008.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:07.946997 hisparc_sapphire-3.0.0/sapphire/data/gps/201.tsv
+-rw-r--r--   0        0        0      456 2022-08-05 15:48:22.715154 hisparc_sapphire-3.0.0/sapphire/data/gps/2010.tsv
+-rw-r--r--   0        0        0      798 2022-08-05 15:48:08.500045 hisparc_sapphire-3.0.0/sapphire/data/gps/202.tsv
+-rw-r--r--   0        0        0     3230 2022-08-05 15:48:09.012971 hisparc_sapphire-3.0.0/sapphire/data/gps/203.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:04.611548 hisparc_sapphire-3.0.0/sapphire/data/gps/21.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:22.833473 hisparc_sapphire-3.0.0/sapphire/data/gps/2101.tsv
+-rw-r--r--   0        0        0      494 2022-08-05 15:48:22.929017 hisparc_sapphire-3.0.0/sapphire/data/gps/2102.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:22.988395 hisparc_sapphire-3.0.0/sapphire/data/gps/2103.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:04.916323 hisparc_sapphire-3.0.0/sapphire/data/gps/22.tsv
+-rw-r--r--   0        0        0      570 2022-08-05 15:48:23.069728 hisparc_sapphire-3.0.0/sapphire/data/gps/2201.tsv
+-rw-r--r--   0        0        0      418 2022-08-05 15:48:05.428604 hisparc_sapphire-3.0.0/sapphire/data/gps/23.tsv
+-rw-r--r--   0        0        0     1178 2022-08-05 15:48:05.786889 hisparc_sapphire-3.0.0/sapphire/data/gps/24.tsv
+-rw-r--r--   0        0        0       38 2022-01-17 10:27:57.348603 hisparc_sapphire-3.0.0/sapphire/data/gps/25.tsv
+-rw-r--r--   0        0        0      380 2022-08-05 15:48:01.244458 hisparc_sapphire-3.0.0/sapphire/data/gps/3.tsv
+-rw-r--r--   0        0        0      342 2022-08-05 15:48:23.409710 hisparc_sapphire-3.0.0/sapphire/data/gps/3001.tsv
+-rw-r--r--   0        0        0      266 2022-08-05 15:48:23.697067 hisparc_sapphire-3.0.0/sapphire/data/gps/3002.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:09.524190 hisparc_sapphire-3.0.0/sapphire/data/gps/301.tsv
+-rw-r--r--   0        0        0      266 2022-08-05 15:48:09.643670 hisparc_sapphire-3.0.0/sapphire/data/gps/303.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:09.932352 hisparc_sapphire-3.0.0/sapphire/data/gps/304.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:10.343810 hisparc_sapphire-3.0.0/sapphire/data/gps/305.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:23.780060 hisparc_sapphire-3.0.0/sapphire/data/gps/3101.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:23.858222 hisparc_sapphire-3.0.0/sapphire/data/gps/3102.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:23.922552 hisparc_sapphire-3.0.0/sapphire/data/gps/3103.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:23.994474 hisparc_sapphire-3.0.0/sapphire/data/gps/3104.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:24.100386 hisparc_sapphire-3.0.0/sapphire/data/gps/3105.tsv
+-rw-r--r--   0        0        0      380 2022-08-05 15:48:24.379041 hisparc_sapphire-3.0.0/sapphire/data/gps/3201.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:24.461100 hisparc_sapphire-3.0.0/sapphire/data/gps/3202.tsv
+-rw-r--r--   0        0        0      456 2022-08-05 15:48:24.531625 hisparc_sapphire-3.0.0/sapphire/data/gps/3203.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:24.755538 hisparc_sapphire-3.0.0/sapphire/data/gps/3301.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:24.838842 hisparc_sapphire-3.0.0/sapphire/data/gps/3302.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:24.984454 hisparc_sapphire-3.0.0/sapphire/data/gps/3303.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:25.130499 hisparc_sapphire-3.0.0/sapphire/data/gps/3304.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:25.209346 hisparc_sapphire-3.0.0/sapphire/data/gps/3401.tsv
+-rw-r--r--   0        0        0      342 2022-08-05 15:48:25.731644 hisparc_sapphire-3.0.0/sapphire/data/gps/3501.tsv
+-rw-r--r--   0        0        0     1444 2022-08-05 15:48:26.129868 hisparc_sapphire-3.0.0/sapphire/data/gps/3601.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:26.214727 hisparc_sapphire-3.0.0/sapphire/data/gps/3701.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:26.393031 hisparc_sapphire-3.0.0/sapphire/data/gps/3702.tsv
+-rw-r--r--   0        0        0     1596 2022-08-05 15:48:01.523083 hisparc_sapphire-3.0.0/sapphire/data/gps/4.tsv
+-rw-r--r--   0        0        0      546 2022-08-05 15:48:41.895114 hisparc_sapphire-3.0.0/sapphire/data/gps/40001.tsv
+-rw-r--r--   0        0        0      229 2022-08-05 15:48:26.471232 hisparc_sapphire-3.0.0/sapphire/data/gps/4001.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:26.536529 hisparc_sapphire-3.0.0/sapphire/data/gps/4002.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:26.606773 hisparc_sapphire-3.0.0/sapphire/data/gps/4003.tsv
+-rw-r--r--   0        0        0      266 2022-08-05 15:48:26.687631 hisparc_sapphire-3.0.0/sapphire/data/gps/4004.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:10.429885 hisparc_sapphire-3.0.0/sapphire/data/gps/401.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:01.828126 hisparc_sapphire-3.0.0/sapphire/data/gps/5.tsv
+-rw-r--r--   0        0        0      912 2022-08-05 15:48:11.059372 hisparc_sapphire-3.0.0/sapphire/data/gps/501.tsv
+-rw-r--r--   0        0        0      380 2022-08-05 15:48:11.451570 hisparc_sapphire-3.0.0/sapphire/data/gps/502.tsv
+-rw-r--r--   0        0        0      380 2022-08-05 15:48:11.811130 hisparc_sapphire-3.0.0/sapphire/data/gps/503.tsv
+-rw-r--r--   0        0        0      342 2022-08-05 15:48:12.182475 hisparc_sapphire-3.0.0/sapphire/data/gps/504.tsv
+-rw-r--r--   0        0        0      874 2022-08-05 15:48:12.599047 hisparc_sapphire-3.0.0/sapphire/data/gps/505.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:12.689261 hisparc_sapphire-3.0.0/sapphire/data/gps/506.tsv
+-rw-r--r--   0        0        0      380 2022-08-05 15:48:13.211835 hisparc_sapphire-3.0.0/sapphire/data/gps/507.tsv
+-rw-r--r--   0        0        0      570 2022-08-05 15:48:13.621400 hisparc_sapphire-3.0.0/sapphire/data/gps/508.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:13.966697 hisparc_sapphire-3.0.0/sapphire/data/gps/509.tsv
+-rw-r--r--   0        0        0      494 2022-08-05 15:48:14.547309 hisparc_sapphire-3.0.0/sapphire/data/gps/510.tsv
+-rw-r--r--   0        0        0       76 2022-08-05 15:48:14.956209 hisparc_sapphire-3.0.0/sapphire/data/gps/511.tsv
+-rw-r--r--   0        0        0     8588 2022-08-05 15:48:15.465519 hisparc_sapphire-3.0.0/sapphire/data/gps/512.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:15.829049 hisparc_sapphire-3.0.0/sapphire/data/gps/513.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:16.100734 hisparc_sapphire-3.0.0/sapphire/data/gps/514.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:16.174214 hisparc_sapphire-3.0.0/sapphire/data/gps/521.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:16.243178 hisparc_sapphire-3.0.0/sapphire/data/gps/522.tsv
+-rw-r--r--   0        0        0     2091 2022-08-05 15:48:18.330802 hisparc_sapphire-3.0.0/sapphire/data/gps/599.tsv
+-rw-r--r--   0        0        0      266 2022-08-05 15:48:02.664343 hisparc_sapphire-3.0.0/sapphire/data/gps/6.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:48:41.986849 hisparc_sapphire-3.0.0/sapphire/data/gps/60001.tsv
+-rw-r--r--   0        0        0      456 2022-08-05 15:48:18.690602 hisparc_sapphire-3.0.0/sapphire/data/gps/601.tsv
+-rw-r--r--   0        0        0      418 2022-08-05 15:48:19.045358 hisparc_sapphire-3.0.0/sapphire/data/gps/602.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:19.265038 hisparc_sapphire-3.0.0/sapphire/data/gps/603.tsv
+-rw-r--r--   0        0        0      266 2022-08-05 15:48:19.373824 hisparc_sapphire-3.0.0/sapphire/data/gps/604.tsv
+-rw-r--r--   0        0        0      418 2022-08-05 15:48:02.843991 hisparc_sapphire-3.0.0/sapphire/data/gps/7.tsv
+-rw-r--r--   0        0        0       77 2022-01-17 10:27:57.350824 hisparc_sapphire-3.0.0/sapphire/data/gps/70001.tsv
+-rw-r--r--   0        0        0      418 2022-08-05 15:48:27.035133 hisparc_sapphire-3.0.0/sapphire/data/gps/7001.tsv
+-rw-r--r--   0        0        0      117 2022-08-05 15:48:27.444676 hisparc_sapphire-3.0.0/sapphire/data/gps/7002.tsv
+-rw-r--r--   0        0        0      229 2022-08-05 15:48:27.854799 hisparc_sapphire-3.0.0/sapphire/data/gps/7003.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:27.928679 hisparc_sapphire-3.0.0/sapphire/data/gps/7101.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:28.212087 hisparc_sapphire-3.0.0/sapphire/data/gps/7102.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:28.287537 hisparc_sapphire-3.0.0/sapphire/data/gps/7201.tsv
+-rw-r--r--   0        0        0      342 2022-08-05 15:48:28.672500 hisparc_sapphire-3.0.0/sapphire/data/gps/7301.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:28.907639 hisparc_sapphire-3.0.0/sapphire/data/gps/7401.tsv
+-rw-r--r--   0        0        0       77 2022-01-17 10:27:57.351409 hisparc_sapphire-3.0.0/sapphire/data/gps/7501.tsv
+-rw-r--r--   0        0        0      190 2022-08-05 15:48:29.284994 hisparc_sapphire-3.0.0/sapphire/data/gps/7601.tsv
+-rw-r--r--   0        0        0      342 2022-08-05 15:48:29.800009 hisparc_sapphire-3.0.0/sapphire/data/gps/8001.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:29.879440 hisparc_sapphire-3.0.0/sapphire/data/gps/8002.tsv
+-rw-r--r--   0        0        0      228 2022-08-05 15:48:30.312165 hisparc_sapphire-3.0.0/sapphire/data/gps/8003.tsv
+-rw-r--r--   0        0        0     1292 2022-08-05 15:48:30.824384 hisparc_sapphire-3.0.0/sapphire/data/gps/8004.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:31.233392 hisparc_sapphire-3.0.0/sapphire/data/gps/8005.tsv
+-rw-r--r--   0        0        0      456 2022-08-05 15:48:31.357988 hisparc_sapphire-3.0.0/sapphire/data/gps/8006.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:31.427163 hisparc_sapphire-3.0.0/sapphire/data/gps/8007.tsv
+-rw-r--r--   0        0        0      117 2022-08-05 15:48:31.946850 hisparc_sapphire-3.0.0/sapphire/data/gps/8008.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:32.381021 hisparc_sapphire-3.0.0/sapphire/data/gps/8009.tsv
+-rw-r--r--   0        0        0      456 2022-08-05 15:48:32.488101 hisparc_sapphire-3.0.0/sapphire/data/gps/8101.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:32.536524 hisparc_sapphire-3.0.0/sapphire/data/gps/8102.tsv
+-rw-r--r--   0        0        0      152 2022-08-05 15:48:32.608916 hisparc_sapphire-3.0.0/sapphire/data/gps/8103.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:32.669756 hisparc_sapphire-3.0.0/sapphire/data/gps/8104.tsv
+-rw-r--r--   0        0        0      494 2022-08-05 15:48:32.903677 hisparc_sapphire-3.0.0/sapphire/data/gps/8105.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:33.094856 hisparc_sapphire-3.0.0/sapphire/data/gps/8201.tsv
+-rw-r--r--   0        0        0       76 2022-08-05 15:48:33.157423 hisparc_sapphire-3.0.0/sapphire/data/gps/8301.tsv
+-rw-r--r--   0        0        0       76 2022-08-05 15:48:33.216326 hisparc_sapphire-3.0.0/sapphire/data/gps/8302.tsv
+-rw-r--r--   0        0        0       38 2022-08-05 15:48:36.047045 hisparc_sapphire-3.0.0/sapphire/data/gps/8303.tsv
+-rw-r--r--   0        0        0      114 2022-08-05 15:48:36.275760 hisparc_sapphire-3.0.0/sapphire/data/gps/8401.tsv
+-rw-r--r--   0        0        0      494 2022-08-05 15:48:03.278646 hisparc_sapphire-3.0.0/sapphire/data/gps/9.tsv
+-rw-r--r--   0        0        0       99 2022-08-05 15:49:14.494797 hisparc_sapphire-3.0.0/sapphire/data/layout/1009.tsv
+-rw-r--r--   0        0        0       83 2022-08-05 15:49:12.505273 hisparc_sapphire-3.0.0/sapphire/data/layout/102.tsv
+-rw-r--r--   0        0        0       84 2022-08-05 15:49:12.595521 hisparc_sapphire-3.0.0/sapphire/data/layout/104.tsv
+-rw-r--r--   0        0        0      169 2022-08-05 15:49:12.642395 hisparc_sapphire-3.0.0/sapphire/data/layout/105.tsv
+-rw-r--r--   0        0        0       84 2022-08-05 15:49:14.587307 hisparc_sapphire-3.0.0/sapphire/data/layout/1101.tsv
+-rw-r--r--   0        0        0       93 2022-08-05 15:49:14.644143 hisparc_sapphire-3.0.0/sapphire/data/layout/1102.tsv
+-rw-r--r--   0        0        0       83 2022-08-05 15:49:18.237519 hisparc_sapphire-3.0.0/sapphire/data/layout/13102.tsv
+-rw-r--r--   0        0        0       99 2022-08-05 15:49:18.608913 hisparc_sapphire-3.0.0/sapphire/data/layout/14001.tsv
+-rw-r--r--   0        0        0       84 2022-08-05 15:49:19.070666 hisparc_sapphire-3.0.0/sapphire/data/layout/16001.tsv
+-rw-r--r--   0        0        0       82 2022-08-05 15:49:14.978750 hisparc_sapphire-3.0.0/sapphire/data/layout/2006.tsv
+-rw-r--r--   0        0        0       91 2022-08-05 15:49:12.739665 hisparc_sapphire-3.0.0/sapphire/data/layout/201.tsv
+-rw-r--r--   0        0        0       80 2022-08-05 15:49:15.081746 hisparc_sapphire-3.0.0/sapphire/data/layout/2010.tsv
+-rw-r--r--   0        0        0      161 2022-08-05 15:49:12.315025 hisparc_sapphire-3.0.0/sapphire/data/layout/22.tsv
+-rw-r--r--   0        0        0       83 2022-08-05 15:49:12.363588 hisparc_sapphire-3.0.0/sapphire/data/layout/23.tsv
+-rw-r--r--   0        0        0       82 2022-08-05 15:49:13.015378 hisparc_sapphire-3.0.0/sapphire/data/layout/305.tsv
+-rw-r--r--   0        0        0       89 2022-08-05 15:49:15.663644 hisparc_sapphire-3.0.0/sapphire/data/layout/3201.tsv
+-rw-r--r--   0        0        0       88 2022-08-05 15:49:11.899322 hisparc_sapphire-3.0.0/sapphire/data/layout/4.tsv
+-rw-r--r--   0        0        0       83 2022-08-05 15:49:19.358764 hisparc_sapphire-3.0.0/sapphire/data/layout/40001.tsv
+-rw-r--r--   0        0        0       84 2022-08-05 15:49:13.064067 hisparc_sapphire-3.0.0/sapphire/data/layout/401.tsv
+-rw-r--r--   0        0        0     1074 2022-08-05 15:49:13.120984 hisparc_sapphire-3.0.0/sapphire/data/layout/501.tsv
+-rw-r--r--   0        0        0      183 2022-08-05 15:49:13.169888 hisparc_sapphire-3.0.0/sapphire/data/layout/502.tsv
+-rw-r--r--   0        0        0       94 2022-08-05 15:49:13.218113 hisparc_sapphire-3.0.0/sapphire/data/layout/503.tsv
+-rw-r--r--   0        0        0       91 2022-08-05 15:49:13.266321 hisparc_sapphire-3.0.0/sapphire/data/layout/504.tsv
+-rw-r--r--   0        0        0      275 2022-08-05 15:49:13.321039 hisparc_sapphire-3.0.0/sapphire/data/layout/505.tsv
+-rw-r--r--   0        0        0       87 2022-08-05 15:49:13.374090 hisparc_sapphire-3.0.0/sapphire/data/layout/506.tsv
+-rw-r--r--   0        0        0      107 2022-08-05 15:49:13.423368 hisparc_sapphire-3.0.0/sapphire/data/layout/507.tsv
+-rw-r--r--   0        0        0       91 2022-08-05 15:49:13.470107 hisparc_sapphire-3.0.0/sapphire/data/layout/508.tsv
+-rw-r--r--   0        0        0       91 2022-08-05 15:49:13.517255 hisparc_sapphire-3.0.0/sapphire/data/layout/509.tsv
+-rw-r--r--   0        0        0      278 2022-08-05 15:49:13.568934 hisparc_sapphire-3.0.0/sapphire/data/layout/510.tsv
+-rw-r--r--   0        0        0       90 2022-08-05 15:49:13.619719 hisparc_sapphire-3.0.0/sapphire/data/layout/511.tsv
+-rw-r--r--   0        0        0       92 2022-08-05 15:49:13.670488 hisparc_sapphire-3.0.0/sapphire/data/layout/512.tsv
+-rw-r--r--   0        0        0      191 2022-08-05 15:49:13.721218 hisparc_sapphire-3.0.0/sapphire/data/layout/513.tsv
+-rw-r--r--   0        0        0       91 2022-08-05 15:49:13.771644 hisparc_sapphire-3.0.0/sapphire/data/layout/514.tsv
+-rw-r--r--   0        0        0       84 2022-08-05 15:49:13.822116 hisparc_sapphire-3.0.0/sapphire/data/layout/521.tsv
+-rw-r--r--   0        0        0       85 2022-08-05 15:49:13.870122 hisparc_sapphire-3.0.0/sapphire/data/layout/522.tsv
+-rw-r--r--   0        0        0      249 2022-08-05 15:49:11.999352 hisparc_sapphire-3.0.0/sapphire/data/layout/6.tsv
+-rw-r--r--   0        0        0      166 2022-08-05 15:49:13.968834 hisparc_sapphire-3.0.0/sapphire/data/layout/601.tsv
+-rw-r--r--   0        0        0       84 2022-08-05 15:49:14.016456 hisparc_sapphire-3.0.0/sapphire/data/layout/602.tsv
+-rw-r--r--   0        0        0       86 2022-08-05 15:49:16.413221 hisparc_sapphire-3.0.0/sapphire/data/layout/7001.tsv
+-rw-r--r--   0        0        0       88 2022-08-05 15:49:16.457749 hisparc_sapphire-3.0.0/sapphire/data/layout/7002.tsv
+-rw-r--r--   0        0        0       90 2022-08-05 15:49:16.505767 hisparc_sapphire-3.0.0/sapphire/data/layout/7003.tsv
+-rw-r--r--   0        0        0       93 2022-08-05 15:49:16.909934 hisparc_sapphire-3.0.0/sapphire/data/layout/8003.tsv
+-rw-r--r--   0        0        0       83 2022-08-05 15:49:17.053539 hisparc_sapphire-3.0.0/sapphire/data/layout/8006.tsv
+-rw-r--r--   0        0        0       91 2022-08-05 15:49:17.246560 hisparc_sapphire-3.0.0/sapphire/data/layout/8101.tsv
+-rw-r--r--   0        0        0       83 2022-08-05 15:49:17.424235 hisparc_sapphire-3.0.0/sapphire/data/layout/8105.tsv
+-rw-r--r--   0        0        0       84 2022-08-05 15:49:17.654740 hisparc_sapphire-3.0.0/sapphire/data/layout/8401.tsv
+-rw-r--r--   0        0        0       89 2022-08-05 15:49:12.089917 hisparc_sapphire-3.0.0/sapphire/data/layout/9.tsv
+-rw-r--r--   0        0        0      795 2022-08-05 15:47:34.204438 hisparc_sapphire-3.0.0/sapphire/data/station/10.json
+-rw-r--r--   0        0        0      528 2022-08-05 15:47:42.560687 hisparc_sapphire-3.0.0/sapphire/data/station/1001.json
+-rw-r--r--   0        0        0      539 2022-08-05 15:47:42.636060 hisparc_sapphire-3.0.0/sapphire/data/station/1002.json
+-rw-r--r--   0        0        0      540 2022-08-05 15:47:42.712592 hisparc_sapphire-3.0.0/sapphire/data/station/1003.json
+-rw-r--r--   0        0        0      797 2022-08-05 15:47:42.789390 hisparc_sapphire-3.0.0/sapphire/data/station/1005.json
+-rw-r--r--   0        0        0      537 2022-08-05 15:47:42.996386 hisparc_sapphire-3.0.0/sapphire/data/station/1006.json
+-rw-r--r--   0        0        0      537 2022-08-05 15:47:43.197469 hisparc_sapphire-3.0.0/sapphire/data/station/1007.json
+-rw-r--r--   0        0        0      534 2022-08-05 15:47:43.393968 hisparc_sapphire-3.0.0/sapphire/data/station/1008.json
+-rw-r--r--   0        0        0      786 2022-08-05 15:47:43.473763 hisparc_sapphire-3.0.0/sapphire/data/station/1009.json
+-rw-r--r--   0        0        0      531 2022-08-05 15:47:35.388034 hisparc_sapphire-3.0.0/sapphire/data/station/101.json
+-rw-r--r--   0        0        0      786 2022-08-05 15:47:43.555339 hisparc_sapphire-3.0.0/sapphire/data/station/1010.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:35.611837 hisparc_sapphire-3.0.0/sapphire/data/station/102.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:35.689076 hisparc_sapphire-3.0.0/sapphire/data/station/103.json
+-rw-r--r--   0        0        0      530 2022-08-05 15:47:35.902403 hisparc_sapphire-3.0.0/sapphire/data/station/104.json
+-rw-r--r--   0        0        0      531 2022-08-05 15:47:36.113109 hisparc_sapphire-3.0.0/sapphire/data/station/105.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:36.215191 hisparc_sapphire-3.0.0/sapphire/data/station/106.json
+-rw-r--r--   0        0        0      527 2022-08-05 15:47:43.675865 hisparc_sapphire-3.0.0/sapphire/data/station/1101.json
+-rw-r--r--   0        0        0      803 2022-08-05 15:47:43.791035 hisparc_sapphire-3.0.0/sapphire/data/station/1102.json
+-rw-r--r--   0        0        0      535 2022-08-05 15:47:43.892043 hisparc_sapphire-3.0.0/sapphire/data/station/1103.json
+-rw-r--r--   0        0        0      794 2022-08-05 15:47:52.404092 hisparc_sapphire-3.0.0/sapphire/data/station/12001.json
+-rw-r--r--   0        0        0      530 2022-08-05 15:47:34.388084 hisparc_sapphire-3.0.0/sapphire/data/station/13.json
+-rw-r--r--   0        0        0      791 2022-08-05 15:47:52.492468 hisparc_sapphire-3.0.0/sapphire/data/station/13001.json
+-rw-r--r--   0        0        0      524 2022-08-05 15:47:52.575844 hisparc_sapphire-3.0.0/sapphire/data/station/13002.json
+-rw-r--r--   0        0        0      537 2022-08-05 15:47:52.664392 hisparc_sapphire-3.0.0/sapphire/data/station/13003.json
+-rw-r--r--   0        0        0      534 2022-08-05 15:47:52.737031 hisparc_sapphire-3.0.0/sapphire/data/station/13004.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:52.817155 hisparc_sapphire-3.0.0/sapphire/data/station/13005.json
+-rw-r--r--   0        0        0      536 2022-08-05 15:47:52.885500 hisparc_sapphire-3.0.0/sapphire/data/station/13006.json
+-rw-r--r--   0        0        0      788 2022-08-05 15:47:52.950620 hisparc_sapphire-3.0.0/sapphire/data/station/13007.json
+-rw-r--r--   0        0        0      542 2022-08-05 15:47:53.017120 hisparc_sapphire-3.0.0/sapphire/data/station/13008.json
+-rw-r--r--   0        0        0      525 2022-08-05 15:47:53.086699 hisparc_sapphire-3.0.0/sapphire/data/station/13009.json
+-rw-r--r--   0        0        0      532 2022-08-05 15:47:53.158070 hisparc_sapphire-3.0.0/sapphire/data/station/13101.json
+-rw-r--r--   0        0        0      530 2022-08-05 15:47:53.226937 hisparc_sapphire-3.0.0/sapphire/data/station/13102.json
+-rw-r--r--   0        0        0      781 2022-08-05 15:47:53.293007 hisparc_sapphire-3.0.0/sapphire/data/station/13103.json
+-rw-r--r--   0        0        0      527 2022-08-05 15:47:53.383955 hisparc_sapphire-3.0.0/sapphire/data/station/13104.json
+-rw-r--r--   0        0        0      527 2022-08-05 15:47:53.464198 hisparc_sapphire-3.0.0/sapphire/data/station/13201.json
+-rw-r--r--   0        0        0      532 2022-08-05 15:47:53.532232 hisparc_sapphire-3.0.0/sapphire/data/station/13301.json
+-rw-r--r--   0        0        0      514 2022-08-05 15:47:53.600234 hisparc_sapphire-3.0.0/sapphire/data/station/13401.json
+-rw-r--r--   0        0        0      801 2022-08-05 15:47:53.687138 hisparc_sapphire-3.0.0/sapphire/data/station/13501.json
+-rw-r--r--   0        0        0      539 2022-08-05 15:47:53.773136 hisparc_sapphire-3.0.0/sapphire/data/station/13601.json
+-rw-r--r--   0        0        0      808 2022-08-05 15:47:53.874240 hisparc_sapphire-3.0.0/sapphire/data/station/14001.json
+-rw-r--r--   0        0        0      565 2022-08-05 15:47:53.958622 hisparc_sapphire-3.0.0/sapphire/data/station/14002.json
+-rw-r--r--   0        0        0      557 2022-08-05 15:47:54.059239 hisparc_sapphire-3.0.0/sapphire/data/station/14003.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:54.162769 hisparc_sapphire-3.0.0/sapphire/data/station/14004.json
+-rw-r--r--   0        0        0      531 2022-08-05 15:47:54.246150 hisparc_sapphire-3.0.0/sapphire/data/station/14005.json
+-rw-r--r--   0        0        0      537 2022-08-05 15:47:54.343620 hisparc_sapphire-3.0.0/sapphire/data/station/14006.json
+-rw-r--r--   0        0        0      561 2022-08-05 15:47:54.421360 hisparc_sapphire-3.0.0/sapphire/data/station/14007.json
+-rw-r--r--   0        0        0      542 2022-08-05 15:47:54.526047 hisparc_sapphire-3.0.0/sapphire/data/station/14008.json
+-rw-r--r--   0        0        0      525 2022-08-05 15:47:34.512061 hisparc_sapphire-3.0.0/sapphire/data/station/15.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:54.607030 hisparc_sapphire-3.0.0/sapphire/data/station/15001.json
+-rw-r--r--   0        0        0      544 2022-08-05 15:47:54.686275 hisparc_sapphire-3.0.0/sapphire/data/station/15002.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:54.770790 hisparc_sapphire-3.0.0/sapphire/data/station/16001.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:54.855268 hisparc_sapphire-3.0.0/sapphire/data/station/16101.json
+-rw-r--r--   0        0        0      530 2022-08-05 15:47:54.949247 hisparc_sapphire-3.0.0/sapphire/data/station/17001.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:32.931729 hisparc_sapphire-3.0.0/sapphire/data/station/2.json
+-rw-r--r--   0        0        0      525 2022-08-05 15:47:55.160041 hisparc_sapphire-3.0.0/sapphire/data/station/20001.json
+-rw-r--r--   0        0        0      525 2022-08-05 15:47:55.361492 hisparc_sapphire-3.0.0/sapphire/data/station/20002.json
+-rw-r--r--   0        0        0      525 2022-08-05 15:47:55.558427 hisparc_sapphire-3.0.0/sapphire/data/station/20003.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:43.981301 hisparc_sapphire-3.0.0/sapphire/data/station/2001.json
+-rw-r--r--   0        0        0      549 2022-08-05 15:47:44.060353 hisparc_sapphire-3.0.0/sapphire/data/station/2002.json
+-rw-r--r--   0        0        0      538 2022-08-05 15:47:44.131670 hisparc_sapphire-3.0.0/sapphire/data/station/2003.json
+-rw-r--r--   0        0        0      528 2022-08-05 15:47:44.200986 hisparc_sapphire-3.0.0/sapphire/data/station/2004.json
+-rw-r--r--   0        0        0      528 2022-08-05 15:47:44.268913 hisparc_sapphire-3.0.0/sapphire/data/station/2005.json
+-rw-r--r--   0        0        0      531 2022-08-05 15:47:44.349163 hisparc_sapphire-3.0.0/sapphire/data/station/2006.json
+-rw-r--r--   0        0        0      540 2022-08-05 15:47:44.548952 hisparc_sapphire-3.0.0/sapphire/data/station/2008.json
+-rw-r--r--   0        0        0      784 2022-08-05 15:47:36.427221 hisparc_sapphire-3.0.0/sapphire/data/station/201.json
+-rw-r--r--   0        0        0      527 2022-08-05 15:47:44.662257 hisparc_sapphire-3.0.0/sapphire/data/station/2010.json
+-rw-r--r--   0        0        0      526 2022-08-05 15:47:37.062167 hisparc_sapphire-3.0.0/sapphire/data/station/202.json
+-rw-r--r--   0        0        0      526 2022-08-05 15:47:37.269415 hisparc_sapphire-3.0.0/sapphire/data/station/203.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:34.740582 hisparc_sapphire-3.0.0/sapphire/data/station/21.json
+-rw-r--r--   0        0        0      525 2022-08-05 15:47:44.750219 hisparc_sapphire-3.0.0/sapphire/data/station/2101.json
+-rw-r--r--   0        0        0      534 2022-08-05 15:47:44.823893 hisparc_sapphire-3.0.0/sapphire/data/station/2102.json
+-rw-r--r--   0        0        0      540 2022-08-05 15:47:44.898315 hisparc_sapphire-3.0.0/sapphire/data/station/2103.json
+-rw-r--r--   0        0        0      530 2022-08-05 15:47:34.958343 hisparc_sapphire-3.0.0/sapphire/data/station/22.json
+-rw-r--r--   0        0        0      527 2022-08-05 15:47:44.975785 hisparc_sapphire-3.0.0/sapphire/data/station/2201.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:35.102146 hisparc_sapphire-3.0.0/sapphire/data/station/23.json
+-rw-r--r--   0        0        0      527 2022-08-05 15:47:35.205008 hisparc_sapphire-3.0.0/sapphire/data/station/24.json
+-rw-r--r--   0        0        0      531 2022-01-17 10:27:57.358264 hisparc_sapphire-3.0.0/sapphire/data/station/25.json
+-rw-r--r--   0        0        0      790 2022-08-05 15:47:33.111488 hisparc_sapphire-3.0.0/sapphire/data/station/3.json
+-rw-r--r--   0        0        0      526 2022-08-05 15:47:45.200957 hisparc_sapphire-3.0.0/sapphire/data/station/3001.json
+-rw-r--r--   0        0        0      522 2022-08-05 15:47:45.414034 hisparc_sapphire-3.0.0/sapphire/data/station/3002.json
+-rw-r--r--   0        0        0      538 2022-08-05 15:47:37.494375 hisparc_sapphire-3.0.0/sapphire/data/station/301.json
+-rw-r--r--   0        0        0      531 2022-08-05 15:47:37.580412 hisparc_sapphire-3.0.0/sapphire/data/station/303.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:37.790995 hisparc_sapphire-3.0.0/sapphire/data/station/304.json
+-rw-r--r--   0        0        0      536 2022-08-05 15:47:38.014615 hisparc_sapphire-3.0.0/sapphire/data/station/305.json
+-rw-r--r--   0        0        0      786 2022-08-05 15:47:45.497788 hisparc_sapphire-3.0.0/sapphire/data/station/3101.json
+-rw-r--r--   0        0        0      550 2022-08-05 15:47:45.583066 hisparc_sapphire-3.0.0/sapphire/data/station/3102.json
+-rw-r--r--   0        0        0      540 2022-08-05 15:47:45.655544 hisparc_sapphire-3.0.0/sapphire/data/station/3103.json
+-rw-r--r--   0        0        0      524 2022-08-05 15:47:45.746492 hisparc_sapphire-3.0.0/sapphire/data/station/3104.json
+-rw-r--r--   0        0        0      531 2022-08-05 15:47:45.833993 hisparc_sapphire-3.0.0/sapphire/data/station/3105.json
+-rw-r--r--   0        0        0      788 2022-08-05 15:47:46.042668 hisparc_sapphire-3.0.0/sapphire/data/station/3201.json
+-rw-r--r--   0        0        0      788 2022-08-05 15:47:46.227655 hisparc_sapphire-3.0.0/sapphire/data/station/3202.json
+-rw-r--r--   0        0        0      528 2022-08-05 15:47:46.300268 hisparc_sapphire-3.0.0/sapphire/data/station/3203.json
+-rw-r--r--   0        0        0      534 2022-08-05 15:47:46.503121 hisparc_sapphire-3.0.0/sapphire/data/station/3301.json
+-rw-r--r--   0        0        0      542 2022-08-05 15:47:46.692652 hisparc_sapphire-3.0.0/sapphire/data/station/3302.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:46.891775 hisparc_sapphire-3.0.0/sapphire/data/station/3303.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:46.987454 hisparc_sapphire-3.0.0/sapphire/data/station/3304.json
+-rw-r--r--   0        0        0      536 2022-08-05 15:47:47.071437 hisparc_sapphire-3.0.0/sapphire/data/station/3401.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:47.173107 hisparc_sapphire-3.0.0/sapphire/data/station/3501.json
+-rw-r--r--   0        0        0      543 2022-08-05 15:47:47.289189 hisparc_sapphire-3.0.0/sapphire/data/station/3601.json
+-rw-r--r--   0        0        0      525 2022-08-05 15:47:47.377118 hisparc_sapphire-3.0.0/sapphire/data/station/3701.json
+-rw-r--r--   0        0        0      769 2022-08-05 15:47:47.468793 hisparc_sapphire-3.0.0/sapphire/data/station/3702.json
+-rw-r--r--   0        0        0      535 2022-08-05 15:47:33.213464 hisparc_sapphire-3.0.0/sapphire/data/station/4.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:55.647467 hisparc_sapphire-3.0.0/sapphire/data/station/40001.json
+-rw-r--r--   0        0        0      515 2022-08-05 15:47:47.548861 hisparc_sapphire-3.0.0/sapphire/data/station/4001.json
+-rw-r--r--   0        0        0      787 2022-08-05 15:47:47.632536 hisparc_sapphire-3.0.0/sapphire/data/station/4002.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:47.705778 hisparc_sapphire-3.0.0/sapphire/data/station/4003.json
+-rw-r--r--   0        0        0      534 2022-08-05 15:47:47.900442 hisparc_sapphire-3.0.0/sapphire/data/station/4004.json
+-rw-r--r--   0        0        0      786 2022-08-05 15:47:38.213751 hisparc_sapphire-3.0.0/sapphire/data/station/401.json
+-rw-r--r--   0        0        0      537 2022-08-05 15:47:33.413629 hisparc_sapphire-3.0.0/sapphire/data/station/5.json
+-rw-r--r--   0        0        0      522 2022-08-05 15:47:38.447672 hisparc_sapphire-3.0.0/sapphire/data/station/501.json
+-rw-r--r--   0        0        0      800 2022-08-05 15:47:38.669875 hisparc_sapphire-3.0.0/sapphire/data/station/502.json
+-rw-r--r--   0        0        0      785 2022-08-05 15:47:38.885274 hisparc_sapphire-3.0.0/sapphire/data/station/503.json
+-rw-r--r--   0        0        0      790 2022-08-05 15:47:39.110221 hisparc_sapphire-3.0.0/sapphire/data/station/504.json
+-rw-r--r--   0        0        0      787 2022-08-05 15:47:39.327297 hisparc_sapphire-3.0.0/sapphire/data/station/505.json
+-rw-r--r--   0        0        0      778 2022-08-05 15:47:39.409433 hisparc_sapphire-3.0.0/sapphire/data/station/506.json
+-rw-r--r--   0        0        0      805 2022-08-05 15:47:39.637286 hisparc_sapphire-3.0.0/sapphire/data/station/507.json
+-rw-r--r--   0        0        0      783 2022-08-05 15:47:39.870065 hisparc_sapphire-3.0.0/sapphire/data/station/508.json
+-rw-r--r--   0        0        0      801 2022-08-05 15:47:40.090632 hisparc_sapphire-3.0.0/sapphire/data/station/509.json
+-rw-r--r--   0        0        0      781 2022-08-05 15:47:40.315465 hisparc_sapphire-3.0.0/sapphire/data/station/510.json
+-rw-r--r--   0        0        0      777 2022-08-05 15:47:40.436603 hisparc_sapphire-3.0.0/sapphire/data/station/511.json
+-rw-r--r--   0        0        0      781 2022-08-05 15:47:40.558272 hisparc_sapphire-3.0.0/sapphire/data/station/512.json
+-rw-r--r--   0        0        0      787 2022-08-05 15:47:40.666784 hisparc_sapphire-3.0.0/sapphire/data/station/513.json
+-rw-r--r--   0        0        0      781 2022-08-05 15:47:40.773406 hisparc_sapphire-3.0.0/sapphire/data/station/514.json
+-rw-r--r--   0        0        0      532 2022-08-05 15:47:40.860507 hisparc_sapphire-3.0.0/sapphire/data/station/521.json
+-rw-r--r--   0        0        0      536 2022-08-05 15:47:40.940131 hisparc_sapphire-3.0.0/sapphire/data/station/522.json
+-rw-r--r--   0        0        0      793 2022-08-05 15:47:41.085673 hisparc_sapphire-3.0.0/sapphire/data/station/599.json
+-rw-r--r--   0        0        0      523 2022-08-05 15:47:33.624534 hisparc_sapphire-3.0.0/sapphire/data/station/6.json
+-rw-r--r--   0        0        0      535 2022-08-05 15:47:55.724288 hisparc_sapphire-3.0.0/sapphire/data/station/60001.json
+-rw-r--r--   0        0        0      519 2022-08-05 15:47:42.080136 hisparc_sapphire-3.0.0/sapphire/data/station/601.json
+-rw-r--r--   0        0        0      519 2022-08-05 15:47:42.195779 hisparc_sapphire-3.0.0/sapphire/data/station/602.json
+-rw-r--r--   0        0        0      514 2022-08-05 15:47:42.288017 hisparc_sapphire-3.0.0/sapphire/data/station/603.json
+-rw-r--r--   0        0        0      520 2022-08-05 15:47:42.366858 hisparc_sapphire-3.0.0/sapphire/data/station/604.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:33.811903 hisparc_sapphire-3.0.0/sapphire/data/station/7.json
+-rw-r--r--   0        0        0      535 2022-08-05 15:47:48.115385 hisparc_sapphire-3.0.0/sapphire/data/station/7001.json
+-rw-r--r--   0        0        0      536 2022-08-05 15:47:48.338630 hisparc_sapphire-3.0.0/sapphire/data/station/7002.json
+-rw-r--r--   0        0        0      539 2022-08-05 15:47:48.558242 hisparc_sapphire-3.0.0/sapphire/data/station/7003.json
+-rw-r--r--   0        0        0      523 2022-08-05 15:47:48.645045 hisparc_sapphire-3.0.0/sapphire/data/station/7101.json
+-rw-r--r--   0        0        0      527 2022-08-05 15:47:48.751691 hisparc_sapphire-3.0.0/sapphire/data/station/7102.json
+-rw-r--r--   0        0        0      524 2022-08-05 15:47:48.955388 hisparc_sapphire-3.0.0/sapphire/data/station/7201.json
+-rw-r--r--   0        0        0      789 2022-08-05 15:47:49.170411 hisparc_sapphire-3.0.0/sapphire/data/station/7301.json
+-rw-r--r--   0        0        0      527 2022-08-05 15:47:49.382117 hisparc_sapphire-3.0.0/sapphire/data/station/7401.json
+-rw-r--r--   0        0        0      524 2022-01-17 10:27:57.361328 hisparc_sapphire-3.0.0/sapphire/data/station/7501.json
+-rw-r--r--   0        0        0      521 2022-08-05 15:47:49.506075 hisparc_sapphire-3.0.0/sapphire/data/station/7601.json
+-rw-r--r--   0        0        0      537 2022-08-05 15:47:49.737251 hisparc_sapphire-3.0.0/sapphire/data/station/8001.json
+-rw-r--r--   0        0        0      534 2022-08-05 15:47:49.813985 hisparc_sapphire-3.0.0/sapphire/data/station/8002.json
+-rw-r--r--   0        0        0      790 2022-08-05 15:47:50.028787 hisparc_sapphire-3.0.0/sapphire/data/station/8003.json
+-rw-r--r--   0        0        0      536 2022-08-05 15:47:50.252873 hisparc_sapphire-3.0.0/sapphire/data/station/8004.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:50.368238 hisparc_sapphire-3.0.0/sapphire/data/station/8005.json
+-rw-r--r--   0        0        0      540 2022-08-05 15:47:50.572048 hisparc_sapphire-3.0.0/sapphire/data/station/8006.json
+-rw-r--r--   0        0        0      540 2022-08-05 15:47:50.653769 hisparc_sapphire-3.0.0/sapphire/data/station/8007.json
+-rw-r--r--   0        0        0      537 2022-08-05 15:47:50.882668 hisparc_sapphire-3.0.0/sapphire/data/station/8008.json
+-rw-r--r--   0        0        0      537 2022-08-05 15:47:51.114228 hisparc_sapphire-3.0.0/sapphire/data/station/8009.json
+-rw-r--r--   0        0        0      792 2022-08-05 15:47:51.192128 hisparc_sapphire-3.0.0/sapphire/data/station/8101.json
+-rw-r--r--   0        0        0      538 2022-08-05 15:47:51.274891 hisparc_sapphire-3.0.0/sapphire/data/station/8102.json
+-rw-r--r--   0        0        0      534 2022-08-05 15:47:51.466855 hisparc_sapphire-3.0.0/sapphire/data/station/8103.json
+-rw-r--r--   0        0        0      533 2022-08-05 15:47:51.543179 hisparc_sapphire-3.0.0/sapphire/data/station/8104.json
+-rw-r--r--   0        0        0      528 2022-08-05 15:47:51.747015 hisparc_sapphire-3.0.0/sapphire/data/station/8105.json
+-rw-r--r--   0        0        0      541 2022-08-05 15:47:51.948577 hisparc_sapphire-3.0.0/sapphire/data/station/8201.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:52.034200 hisparc_sapphire-3.0.0/sapphire/data/station/8301.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:52.117332 hisparc_sapphire-3.0.0/sapphire/data/station/8302.json
+-rw-r--r--   0        0        0      529 2022-08-05 15:47:52.227972 hisparc_sapphire-3.0.0/sapphire/data/station/8303.json
+-rw-r--r--   0        0        0      528 2022-08-05 15:47:52.332743 hisparc_sapphire-3.0.0/sapphire/data/station/8401.json
+-rw-r--r--   0        0        0      784 2022-08-05 15:47:34.022712 hisparc_sapphire-3.0.0/sapphire/data/station/9.json
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.943161 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1001/1005.tsv
+-rw-r--r--   0        0        0      330 2022-08-05 15:52:59.987287 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1001/1010.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.047686 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1002/1003.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.109840 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1002/1008.tsv
+-rw-r--r--   0        0        0    21862 2022-08-05 15:53:00.202144 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1003/1008.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.261664 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1005/1010.tsv
+-rw-r--r--   0        0        0    30875 2022-08-05 15:53:00.369125 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1006/1007.tsv
+-rw-r--r--   0        0        0    12369 2022-08-05 15:52:44.885129 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/102/104.tsv
+-rw-r--r--   0        0        0     7955 2022-08-05 15:52:44.963918 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/102/105.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:45.018713 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/102/106.tsv
+-rw-r--r--   0        0        0     7376 2022-08-05 15:52:45.134175 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/104/105.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:45.184463 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/104/106.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:45.254838 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/105/106.tsv
+-rw-r--r--   0        0        0     1594 2022-08-05 15:53:02.392956 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/13001/13003.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.432483 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/13001/13008.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.473749 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/13001/13009.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.521658 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/13003/13008.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.562720 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/13003/13009.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.623932 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/13008/13009.tsv
+-rw-r--r--   0        0        0     6144 2022-08-05 15:53:02.711123 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/14001/14003.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.762397 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/14001/14008.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.819965 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/14003/14008.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:44.568140 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/15/22.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:44.635892 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/15/23.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:43.685477 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/2/15.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.893261 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/20001/20002.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.961119 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/20001/20003.tsv
+-rw-r--r--   0        0        0     2371 2022-08-05 15:53:03.041335 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/20002/20003.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.510424 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/2001/2002.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.571443 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/2001/2006.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.641805 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/2002/2006.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.751842 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/2101/2102.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.790297 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/2101/2103.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:00.839778 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/2102/2103.tsv
+-rw-r--r--   0        0        0     4177 2022-08-05 15:52:44.746487 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/22/23.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.364528 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/22/25.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.364618 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/23/25.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:43.903705 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3/15.tsv
+-rw-r--r--   0        0        0     3941 2022-08-05 15:52:43.998995 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3/22.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:44.079782 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3/23.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.364831 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3/25.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:43.843252 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3/7.tsv
+-rw-r--r--   0        0        0     8452 2022-08-05 15:52:46.585785 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/304/305.tsv
+-rw-r--r--   0        0        0    25371 2022-08-05 15:53:01.002603 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3201/3202.tsv
+-rw-r--r--   0        0        0     5495 2022-08-05 15:53:01.048424 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3201/3203.tsv
+-rw-r--r--   0        0        0     6594 2022-08-05 15:53:01.103310 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3202/3203.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:01.172549 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3302/3304.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:44.178648 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/5/13.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.365504 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/1102.tsv
+-rw-r--r--   0        0        0    29938 2022-08-05 15:52:46.749775 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/502.tsv
+-rw-r--r--   0        0        0    29248 2022-08-05 15:52:46.871270 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/503.tsv
+-rw-r--r--   0        0        0    22752 2022-08-05 15:52:47.006003 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/504.tsv
+-rw-r--r--   0        0        0    24126 2022-08-05 15:52:47.144799 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/505.tsv
+-rw-r--r--   0        0        0    20605 2022-08-05 15:52:47.246806 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/506.tsv
+-rw-r--r--   0        0        0    38734 2022-08-05 15:52:47.410575 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/507.tsv
+-rw-r--r--   0        0        0    14421 2022-08-05 15:52:47.534493 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/508.tsv
+-rw-r--r--   0        0        0    17172 2022-08-05 15:52:47.695278 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/509.tsv
+-rw-r--r--   0        0        0     7958 2022-08-05 15:52:47.824957 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/510.tsv
+-rw-r--r--   0        0        0     6115 2022-08-05 15:52:47.940545 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:48.033508 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:48.130100 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:48.219549 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/514.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:48.263585 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/521.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:48.308257 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:48.359983 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/599.tsv
+-rw-r--r--   0        0        0     6013 2022-01-17 10:27:57.367312 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/offsets_ref501_s502.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.367576 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/1102.tsv
+-rw-r--r--   0        0        0    25706 2022-08-05 15:52:48.499415 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/503.tsv
+-rw-r--r--   0        0        0    20685 2022-08-05 15:52:48.629847 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/504.tsv
+-rw-r--r--   0        0        0    23299 2022-08-05 15:52:48.770502 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/505.tsv
+-rw-r--r--   0        0        0    18622 2022-08-05 15:52:48.877405 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/506.tsv
+-rw-r--r--   0        0        0    34273 2022-08-05 15:52:49.042006 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/507.tsv
+-rw-r--r--   0        0        0    12911 2022-08-05 15:52:49.156511 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/508.tsv
+-rw-r--r--   0        0        0    14795 2022-08-05 15:52:49.321073 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/509.tsv
+-rw-r--r--   0        0        0     6464 2022-08-05 15:52:49.450044 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/510.tsv
+-rw-r--r--   0        0        0     5234 2022-08-05 15:52:49.572614 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:49.667444 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:49.764726 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:49.858232 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/514.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:52:49.909594 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/521.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:52:49.956633 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:50.010897 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.368950 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/1102.tsv
+-rw-r--r--   0        0        0    29039 2022-08-05 15:52:50.167781 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/504.tsv
+-rw-r--r--   0        0        0    22316 2022-08-05 15:52:50.308830 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/505.tsv
+-rw-r--r--   0        0        0    23028 2022-08-05 15:52:50.417208 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/506.tsv
+-rw-r--r--   0        0        0    33657 2022-08-05 15:52:50.584645 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/507.tsv
+-rw-r--r--   0        0        0    12320 2022-08-05 15:52:50.701558 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/508.tsv
+-rw-r--r--   0        0        0    21410 2022-08-05 15:52:50.863197 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/509.tsv
+-rw-r--r--   0        0        0     5669 2022-08-05 15:52:50.990607 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/510.tsv
+-rw-r--r--   0        0        0     3918 2022-08-05 15:52:51.107512 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:51.211100 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:51.308032 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:51.399118 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/514.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:51.450254 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/521.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:51.494282 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:51.548695 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.370103 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/1102.tsv
+-rw-r--r--   0        0        0    20737 2022-08-05 15:52:51.704865 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/505.tsv
+-rw-r--r--   0        0        0    23387 2022-08-05 15:52:51.816653 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/506.tsv
+-rw-r--r--   0        0        0    28451 2022-08-05 15:52:51.974818 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/507.tsv
+-rw-r--r--   0        0        0    13298 2022-08-05 15:52:52.097452 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/508.tsv
+-rw-r--r--   0        0        0    24234 2022-08-05 15:52:52.267466 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/509.tsv
+-rw-r--r--   0        0        0     3258 2022-08-05 15:52:52.397666 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/510.tsv
+-rw-r--r--   0        0        0     2360 2022-08-05 15:52:52.510787 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:52.604273 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:52.700399 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:52.793004 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/514.tsv
+-rw-r--r--   0        0        0       42 2022-08-05 15:52:52.843823 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/521.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:52:52.894283 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:52.947710 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.371090 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/1102.tsv
+-rw-r--r--   0        0        0    21871 2022-08-05 15:52:53.072023 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/506.tsv
+-rw-r--r--   0        0        0    30737 2022-08-05 15:52:53.232059 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/507.tsv
+-rw-r--r--   0        0        0    16202 2022-08-05 15:52:53.355299 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/508.tsv
+-rw-r--r--   0        0        0    20177 2022-08-05 15:52:53.522510 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/509.tsv
+-rw-r--r--   0        0        0     4504 2022-08-05 15:52:53.651278 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/510.tsv
+-rw-r--r--   0        0        0     6165 2022-08-05 15:52:53.764391 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:53.855892 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:53.955911 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:54.050644 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/514.tsv
+-rw-r--r--   0        0        0       42 2022-08-05 15:52:54.098759 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/521.tsv
+-rw-r--r--   0        0        0       42 2022-08-05 15:52:54.148778 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:54.200675 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.371957 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/1102.tsv
+-rw-r--r--   0        0        0    28243 2022-08-05 15:52:54.368939 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/507.tsv
+-rw-r--r--   0        0        0    12929 2022-08-05 15:52:54.484623 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/508.tsv
+-rw-r--r--   0        0        0    19905 2022-08-05 15:52:54.644398 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/509.tsv
+-rw-r--r--   0        0        0     6406 2022-08-05 15:52:54.769634 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/510.tsv
+-rw-r--r--   0        0        0     4921 2022-08-05 15:52:54.883986 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:54.974728 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:55.074251 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:55.165969 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/514.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:52:55.211998 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/521.tsv
+-rw-r--r--   0        0        0       39 2022-08-05 15:52:55.255298 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:55.312347 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.372678 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/1102.tsv
+-rw-r--r--   0        0        0    16808 2022-08-05 15:52:55.456542 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/508.tsv
+-rw-r--r--   0        0        0    21557 2022-08-05 15:52:55.619268 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/509.tsv
+-rw-r--r--   0        0        0    10021 2022-08-05 15:52:55.753044 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/510.tsv
+-rw-r--r--   0        0        0     5218 2022-08-05 15:52:55.865871 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:55.958232 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:56.051863 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:56.146125 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/514.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:52:56.195872 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/521.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:52:56.244651 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:56.298593 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.373284 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/1102.tsv
+-rw-r--r--   0        0        0    12733 2022-08-05 15:52:56.468708 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/509.tsv
+-rw-r--r--   0        0        0     7456 2022-08-05 15:52:56.598422 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/510.tsv
+-rw-r--r--   0        0        0     6082 2022-08-05 15:52:56.714762 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:56.806411 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:56.905452 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:56.997538 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/514.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.049678 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/521.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.100164 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.155513 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.373745 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/1102.tsv
+-rw-r--r--   0        0        0     1602 2022-08-05 15:52:57.298336 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/510.tsv
+-rw-r--r--   0        0        0     5974 2022-08-05 15:52:57.415497 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.509144 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.605198 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.695633 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/514.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.744825 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/521.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.792493 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:57.846346 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.374064 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/1102.tsv
+-rw-r--r--   0        0        0     3807 2022-08-05 15:52:57.980048 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/511.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.074052 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.172922 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.266574 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/514.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.313423 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/521.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.359568 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.414504 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.374306 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/511/1102.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.521017 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/511/512.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.614341 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/511/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.706540 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/511/514.tsv
+-rw-r--r--   0        0        0       40 2022-08-05 15:52:58.751184 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/511/521.tsv
+-rw-r--r--   0        0        0       39 2022-08-05 15:52:58.795847 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/511/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.844997 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/511/599.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:58.954864 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/512/513.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.044251 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/512/514.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.097394 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/512/521.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.149763 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/512/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.199523 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/512/599.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.298809 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/513/514.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.352000 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/513/521.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.401988 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/513/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.458428 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/513/599.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.525294 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/514/521.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.570118 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/514/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.619091 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/514/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.374464 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/521/1102.tsv
+-rw-r--r--   0        0        0       39 2022-08-05 15:52:59.679634 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/521/522.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.729928 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/521/599.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.374604 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/522/1102.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.792445 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/522/599.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:59.871665 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/602/604.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:44.262342 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7/15.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:44.343583 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7/22.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:52:44.417992 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7/23.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.374776 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7/25.tsv
+-rw-r--r--   0        0        0    16044 2022-08-05 15:53:01.343677 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7001/7002.tsv
+-rw-r--r--   0        0        0    17562 2022-08-05 15:53:01.440566 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7001/7003.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.375066 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7001/7501.tsv
+-rw-r--r--   0        0        0    32697 2022-08-05 15:53:01.565343 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7002/7003.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.375303 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7002/7501.tsv
+-rw-r--r--   0        0        0       19 2022-01-17 10:27:57.375395 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7003/7501.tsv
+-rw-r--r--   0        0        0     2135 2022-08-05 15:53:01.702854 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8001/8004.tsv
+-rw-r--r--   0        0        0     8813 2022-08-05 15:53:01.786478 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8001/8008.tsv
+-rw-r--r--   0        0        0    18155 2022-08-05 15:53:01.894536 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8001/8009.tsv
+-rw-r--r--   0        0        0      563 2022-08-05 15:53:02.005154 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8004/8008.tsv
+-rw-r--r--   0        0        0     1175 2022-08-05 15:53:02.105655 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8004/8009.tsv
+-rw-r--r--   0        0        0     6843 2022-08-05 15:53:02.231373 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8008/8009.tsv
+-rw-r--r--   0        0        0       19 2022-08-05 15:53:02.319040 hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8301/8302.tsv
+-rw-r--r--   0        0        0    12079 2022-08-05 15:47:32.506868 hisparc_sapphire-3.0.0/sapphire/data/stations.json
+-rw-r--r--   0        0        0     3363 2022-08-05 15:47:32.544277 hisparc_sapphire-3.0.0/sapphire/data/subclusters.json
+-rw-r--r--   0        0        0     1029 2022-08-05 15:47:55.926192 hisparc_sapphire-3.0.0/sapphire/data/subclusters/0.json
+-rw-r--r--   0        0        0      440 2022-08-05 15:47:56.007495 hisparc_sapphire-3.0.0/sapphire/data/subclusters/100.json
+-rw-r--r--   0        0        0      728 2022-08-05 15:47:56.476992 hisparc_sapphire-3.0.0/sapphire/data/subclusters/1000.json
+-rw-r--r--   0        0        0      242 2022-08-05 15:47:56.540414 hisparc_sapphire-3.0.0/sapphire/data/subclusters/1100.json
+-rw-r--r--   0        0        0        2 2022-08-05 15:47:58.138562 hisparc_sapphire-3.0.0/sapphire/data/subclusters/11000.json
+-rw-r--r--   0        0        0       82 2022-08-05 15:47:58.197922 hisparc_sapphire-3.0.0/sapphire/data/subclusters/12000.json
+-rw-r--r--   0        0        0      672 2022-08-05 15:47:58.258968 hisparc_sapphire-3.0.0/sapphire/data/subclusters/13000.json
+-rw-r--r--   0        0        0      293 2022-08-05 15:47:58.318735 hisparc_sapphire-3.0.0/sapphire/data/subclusters/13100.json
+-rw-r--r--   0        0        0       70 2022-08-05 15:47:58.377862 hisparc_sapphire-3.0.0/sapphire/data/subclusters/13200.json
+-rw-r--r--   0        0        0       73 2022-08-05 15:47:58.433553 hisparc_sapphire-3.0.0/sapphire/data/subclusters/13300.json
+-rw-r--r--   0        0        0       69 2022-08-05 15:47:58.488021 hisparc_sapphire-3.0.0/sapphire/data/subclusters/13400.json
+-rw-r--r--   0        0        0       87 2022-08-05 15:47:58.549137 hisparc_sapphire-3.0.0/sapphire/data/subclusters/13500.json
+-rw-r--r--   0        0        0       84 2022-08-05 15:47:58.613739 hisparc_sapphire-3.0.0/sapphire/data/subclusters/13600.json
+-rw-r--r--   0        0        0      654 2022-08-05 15:47:58.693508 hisparc_sapphire-3.0.0/sapphire/data/subclusters/14000.json
+-rw-r--r--   0        0        0      167 2022-08-05 15:47:58.762556 hisparc_sapphire-3.0.0/sapphire/data/subclusters/15000.json
+-rw-r--r--   0        0        0       77 2022-08-05 15:47:58.816205 hisparc_sapphire-3.0.0/sapphire/data/subclusters/16000.json
+-rw-r--r--   0        0        0       77 2022-08-05 15:47:58.877648 hisparc_sapphire-3.0.0/sapphire/data/subclusters/16100.json
+-rw-r--r--   0        0        0       79 2022-08-05 15:47:58.936707 hisparc_sapphire-3.0.0/sapphire/data/subclusters/17000.json
+-rw-r--r--   0        0        0      215 2022-08-05 15:47:56.086833 hisparc_sapphire-3.0.0/sapphire/data/subclusters/200.json
+-rw-r--r--   0        0        0      643 2022-08-05 15:47:56.613331 hisparc_sapphire-3.0.0/sapphire/data/subclusters/2000.json
+-rw-r--r--   0        0        0      230 2022-08-05 15:47:58.998971 hisparc_sapphire-3.0.0/sapphire/data/subclusters/20000.json
+-rw-r--r--   0        0        0      243 2022-08-05 15:47:56.671236 hisparc_sapphire-3.0.0/sapphire/data/subclusters/2100.json
+-rw-r--r--   0        0        0       72 2022-08-05 15:47:56.728239 hisparc_sapphire-3.0.0/sapphire/data/subclusters/2200.json
+-rw-r--r--   0        0        0      301 2022-08-05 15:47:56.157046 hisparc_sapphire-3.0.0/sapphire/data/subclusters/300.json
+-rw-r--r--   0        0        0      149 2022-08-05 15:47:56.791750 hisparc_sapphire-3.0.0/sapphire/data/subclusters/3000.json
+-rw-r--r--   0        0        0      395 2022-08-05 15:47:56.859093 hisparc_sapphire-3.0.0/sapphire/data/subclusters/3100.json
+-rw-r--r--   0        0        0      221 2022-08-05 15:47:56.926729 hisparc_sapphire-3.0.0/sapphire/data/subclusters/3200.json
+-rw-r--r--   0        0        0      292 2022-08-05 15:47:57.002165 hisparc_sapphire-3.0.0/sapphire/data/subclusters/3300.json
+-rw-r--r--   0        0        0       84 2022-08-05 15:47:57.061616 hisparc_sapphire-3.0.0/sapphire/data/subclusters/3400.json
+-rw-r--r--   0        0        0       86 2022-08-05 15:47:57.122846 hisparc_sapphire-3.0.0/sapphire/data/subclusters/3500.json
+-rw-r--r--   0        0        0       79 2022-08-05 15:47:57.187613 hisparc_sapphire-3.0.0/sapphire/data/subclusters/3600.json
+-rw-r--r--   0        0        0      133 2022-08-05 15:47:57.246609 hisparc_sapphire-3.0.0/sapphire/data/subclusters/3700.json
+-rw-r--r--   0        0        0       73 2022-08-05 15:47:56.217224 hisparc_sapphire-3.0.0/sapphire/data/subclusters/400.json
+-rw-r--r--   0        0        0      288 2022-08-05 15:47:57.309087 hisparc_sapphire-3.0.0/sapphire/data/subclusters/4000.json
+-rw-r--r--   0        0        0       80 2022-08-05 15:47:59.054926 hisparc_sapphire-3.0.0/sapphire/data/subclusters/40000.json
+-rw-r--r--   0        0        0     1162 2022-08-05 15:47:56.317385 hisparc_sapphire-3.0.0/sapphire/data/subclusters/500.json
+-rw-r--r--   0        0        0        2 2022-08-05 15:47:59.110144 hisparc_sapphire-3.0.0/sapphire/data/subclusters/50000.json
+-rw-r--r--   0        0        0      261 2022-08-05 15:47:56.398320 hisparc_sapphire-3.0.0/sapphire/data/subclusters/600.json
+-rw-r--r--   0        0        0       82 2022-08-05 15:47:59.164240 hisparc_sapphire-3.0.0/sapphire/data/subclusters/60000.json
+-rw-r--r--   0        0        0      233 2022-08-05 15:47:57.390409 hisparc_sapphire-3.0.0/sapphire/data/subclusters/7000.json
+-rw-r--r--   0        0        0        2 2022-08-05 15:47:59.223021 hisparc_sapphire-3.0.0/sapphire/data/subclusters/70000.json
+-rw-r--r--   0        0        0      145 2022-08-05 15:47:57.453180 hisparc_sapphire-3.0.0/sapphire/data/subclusters/7100.json
+-rw-r--r--   0        0        0       73 2022-08-05 15:47:57.511422 hisparc_sapphire-3.0.0/sapphire/data/subclusters/7200.json
+-rw-r--r--   0        0        0       78 2022-08-05 15:47:57.571542 hisparc_sapphire-3.0.0/sapphire/data/subclusters/7300.json
+-rw-r--r--   0        0        0       71 2022-08-05 15:47:57.635366 hisparc_sapphire-3.0.0/sapphire/data/subclusters/7400.json
+-rw-r--r--   0        0        0        2 2022-08-05 15:47:57.692240 hisparc_sapphire-3.0.0/sapphire/data/subclusters/7500.json
+-rw-r--r--   0        0        0       69 2022-08-05 15:47:57.749277 hisparc_sapphire-3.0.0/sapphire/data/subclusters/7600.json
+-rw-r--r--   0        0        0      714 2022-08-05 15:47:57.827731 hisparc_sapphire-3.0.0/sapphire/data/subclusters/8000.json
+-rw-r--r--   0        0        0      393 2022-08-05 15:47:57.897421 hisparc_sapphire-3.0.0/sapphire/data/subclusters/8100.json
+-rw-r--r--   0        0        0       87 2022-08-05 15:47:57.971877 hisparc_sapphire-3.0.0/sapphire/data/subclusters/8200.json
+-rw-r--r--   0        0        0      227 2022-08-05 15:47:58.031318 hisparc_sapphire-3.0.0/sapphire/data/subclusters/8300.json
+-rw-r--r--   0        0        0       71 2022-08-05 15:47:58.089840 hisparc_sapphire-3.0.0/sapphire/data/subclusters/8400.json
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:43.526253 hisparc_sapphire-3.0.0/sapphire/data/trigger/10.tsv
+-rw-r--r--   0        0        0     1020 2022-08-05 15:48:55.083456 hisparc_sapphire-3.0.0/sapphire/data/trigger/1001.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:55.151207 hisparc_sapphire-3.0.0/sapphire/data/trigger/1002.tsv
+-rw-r--r--   0        0        0      255 2022-08-05 15:48:55.225382 hisparc_sapphire-3.0.0/sapphire/data/trigger/1003.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:55.290064 hisparc_sapphire-3.0.0/sapphire/data/trigger/1005.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:55.488962 hisparc_sapphire-3.0.0/sapphire/data/trigger/1006.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:55.659922 hisparc_sapphire-3.0.0/sapphire/data/trigger/1007.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:48:55.810602 hisparc_sapphire-3.0.0/sapphire/data/trigger/1008.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:55.902638 hisparc_sapphire-3.0.0/sapphire/data/trigger/1009.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:45.416283 hisparc_sapphire-3.0.0/sapphire/data/trigger/101.tsv
+-rw-r--r--   0        0        0      357 2022-08-05 15:48:55.996924 hisparc_sapphire-3.0.0/sapphire/data/trigger/1010.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:48:45.927176 hisparc_sapphire-3.0.0/sapphire/data/trigger/102.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:46.000648 hisparc_sapphire-3.0.0/sapphire/data/trigger/103.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:46.254390 hisparc_sapphire-3.0.0/sapphire/data/trigger/104.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:48:46.453184 hisparc_sapphire-3.0.0/sapphire/data/trigger/105.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:46.627133 hisparc_sapphire-3.0.0/sapphire/data/trigger/106.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:48:56.284764 hisparc_sapphire-3.0.0/sapphire/data/trigger/1101.tsv
+-rw-r--r--   0        0        0      188 2022-08-05 15:48:56.553375 hisparc_sapphire-3.0.0/sapphire/data/trigger/1102.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:48:56.768897 hisparc_sapphire-3.0.0/sapphire/data/trigger/1103.tsv
+-rw-r--r--   0        0        0     1173 2022-08-05 15:49:08.038365 hisparc_sapphire-3.0.0/sapphire/data/trigger/12001.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:48:43.612918 hisparc_sapphire-3.0.0/sapphire/data/trigger/13.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:49:08.102935 hisparc_sapphire-3.0.0/sapphire/data/trigger/13001.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:08.162903 hisparc_sapphire-3.0.0/sapphire/data/trigger/13002.tsv
+-rw-r--r--   0        0        0      251 2022-08-05 15:49:08.236473 hisparc_sapphire-3.0.0/sapphire/data/trigger/13003.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:08.297604 hisparc_sapphire-3.0.0/sapphire/data/trigger/13004.tsv
+-rw-r--r--   0        0        0      408 2022-08-05 15:49:08.378094 hisparc_sapphire-3.0.0/sapphire/data/trigger/13005.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:08.432513 hisparc_sapphire-3.0.0/sapphire/data/trigger/13006.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:08.487220 hisparc_sapphire-3.0.0/sapphire/data/trigger/13007.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:49:08.538274 hisparc_sapphire-3.0.0/sapphire/data/trigger/13008.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:49:08.599037 hisparc_sapphire-3.0.0/sapphire/data/trigger/13009.tsv
+-rw-r--r--   0        0        0      408 2022-08-05 15:49:08.660484 hisparc_sapphire-3.0.0/sapphire/data/trigger/13101.tsv
+-rw-r--r--   0        0        0      306 2022-08-05 15:49:08.723775 hisparc_sapphire-3.0.0/sapphire/data/trigger/13102.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:08.772926 hisparc_sapphire-3.0.0/sapphire/data/trigger/13103.tsv
+-rw-r--r--   0        0        0      351 2022-08-05 15:49:08.936609 hisparc_sapphire-3.0.0/sapphire/data/trigger/13104.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:49:09.011241 hisparc_sapphire-3.0.0/sapphire/data/trigger/13201.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:49:09.074088 hisparc_sapphire-3.0.0/sapphire/data/trigger/13301.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:09.130198 hisparc_sapphire-3.0.0/sapphire/data/trigger/13401.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:49:09.185332 hisparc_sapphire-3.0.0/sapphire/data/trigger/13501.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:49:09.242575 hisparc_sapphire-3.0.0/sapphire/data/trigger/13601.tsv
+-rw-r--r--   0        0        0     1271 2022-08-05 15:49:09.444483 hisparc_sapphire-3.0.0/sapphire/data/trigger/14001.tsv
+-rw-r--r--   0        0        0      200 2022-08-05 15:49:09.545148 hisparc_sapphire-3.0.0/sapphire/data/trigger/14002.tsv
+-rw-r--r--   0        0        0      455 2022-08-05 15:49:09.785578 hisparc_sapphire-3.0.0/sapphire/data/trigger/14003.tsv
+-rw-r--r--   0        0        0      384 2022-08-05 15:49:09.993616 hisparc_sapphire-3.0.0/sapphire/data/trigger/14004.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:49:10.114498 hisparc_sapphire-3.0.0/sapphire/data/trigger/14005.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:49:10.302478 hisparc_sapphire-3.0.0/sapphire/data/trigger/14006.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:49:10.388792 hisparc_sapphire-3.0.0/sapphire/data/trigger/14007.tsv
+-rw-r--r--   0        0        0      282 2022-08-05 15:49:10.586726 hisparc_sapphire-3.0.0/sapphire/data/trigger/14008.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:48:44.033784 hisparc_sapphire-3.0.0/sapphire/data/trigger/15.tsv
+-rw-r--r--   0        0        0      329 2022-08-05 15:49:10.669725 hisparc_sapphire-3.0.0/sapphire/data/trigger/15001.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:49:10.732502 hisparc_sapphire-3.0.0/sapphire/data/trigger/15002.tsv
+-rw-r--r--   0        0        0      329 2022-08-05 15:49:10.851029 hisparc_sapphire-3.0.0/sapphire/data/trigger/16001.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:49:10.972008 hisparc_sapphire-3.0.0/sapphire/data/trigger/16101.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:49:11.128257 hisparc_sapphire-3.0.0/sapphire/data/trigger/17001.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:48:42.071285 hisparc_sapphire-3.0.0/sapphire/data/trigger/2.tsv
+-rw-r--r--   0        0        0      255 2022-08-05 15:49:11.272408 hisparc_sapphire-3.0.0/sapphire/data/trigger/20001.tsv
+-rw-r--r--   0        0        0      306 2022-08-05 15:49:11.426570 hisparc_sapphire-3.0.0/sapphire/data/trigger/20002.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:11.565810 hisparc_sapphire-3.0.0/sapphire/data/trigger/20003.tsv
+-rw-r--r--   0        0        0      306 2022-08-05 15:48:56.844505 hisparc_sapphire-3.0.0/sapphire/data/trigger/2001.tsv
+-rw-r--r--   0        0        0      255 2022-08-05 15:48:56.916069 hisparc_sapphire-3.0.0/sapphire/data/trigger/2002.tsv
+-rw-r--r--   0        0        0      612 2022-08-05 15:48:56.996272 hisparc_sapphire-3.0.0/sapphire/data/trigger/2003.tsv
+-rw-r--r--   0        0        0      357 2022-08-05 15:48:57.073155 hisparc_sapphire-3.0.0/sapphire/data/trigger/2004.tsv
+-rw-r--r--   0        0        0      408 2022-08-05 15:48:57.145620 hisparc_sapphire-3.0.0/sapphire/data/trigger/2005.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:57.237332 hisparc_sapphire-3.0.0/sapphire/data/trigger/2006.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:57.319829 hisparc_sapphire-3.0.0/sapphire/data/trigger/2008.tsv
+-rw-r--r--   0        0        0      255 2022-08-05 15:48:46.834980 hisparc_sapphire-3.0.0/sapphire/data/trigger/201.tsv
+-rw-r--r--   0        0        0      563 2022-08-05 15:48:57.509405 hisparc_sapphire-3.0.0/sapphire/data/trigger/2010.tsv
+-rw-r--r--   0        0        0      402 2022-08-05 15:48:47.203570 hisparc_sapphire-3.0.0/sapphire/data/trigger/202.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:47.460315 hisparc_sapphire-3.0.0/sapphire/data/trigger/203.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:44.449119 hisparc_sapphire-3.0.0/sapphire/data/trigger/21.tsv
+-rw-r--r--   0        0        0     1632 2022-08-05 15:48:57.622242 hisparc_sapphire-3.0.0/sapphire/data/trigger/2101.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:57.700889 hisparc_sapphire-3.0.0/sapphire/data/trigger/2102.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:57.760871 hisparc_sapphire-3.0.0/sapphire/data/trigger/2103.tsv
+-rw-r--r--   0        0        0      510 2022-08-05 15:48:44.697635 hisparc_sapphire-3.0.0/sapphire/data/trigger/22.tsv
+-rw-r--r--   0        0        0      663 2022-08-05 15:48:57.838087 hisparc_sapphire-3.0.0/sapphire/data/trigger/2201.tsv
+-rw-r--r--   0        0        0      612 2022-08-05 15:48:45.060304 hisparc_sapphire-3.0.0/sapphire/data/trigger/23.tsv
+-rw-r--r--   0        0        0      376 2022-08-05 15:48:45.302256 hisparc_sapphire-3.0.0/sapphire/data/trigger/24.tsv
+-rw-r--r--   0        0        0       47 2022-01-17 10:27:57.382568 hisparc_sapphire-3.0.0/sapphire/data/trigger/25.tsv
+-rw-r--r--   0        0        0      510 2022-08-05 15:48:42.159519 hisparc_sapphire-3.0.0/sapphire/data/trigger/3.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:48:58.092299 hisparc_sapphire-3.0.0/sapphire/data/trigger/3001.tsv
+-rw-r--r--   0        0        0      665 2022-08-05 15:48:58.315649 hisparc_sapphire-3.0.0/sapphire/data/trigger/3002.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:47.763140 hisparc_sapphire-3.0.0/sapphire/data/trigger/301.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:47.869198 hisparc_sapphire-3.0.0/sapphire/data/trigger/303.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:48:48.080457 hisparc_sapphire-3.0.0/sapphire/data/trigger/304.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:48.364727 hisparc_sapphire-3.0.0/sapphire/data/trigger/305.tsv
+-rw-r--r--   0        0        0      663 2022-08-05 15:48:58.399081 hisparc_sapphire-3.0.0/sapphire/data/trigger/3101.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:58.475167 hisparc_sapphire-3.0.0/sapphire/data/trigger/3102.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:58.534216 hisparc_sapphire-3.0.0/sapphire/data/trigger/3103.tsv
+-rw-r--r--   0        0        0      510 2022-08-05 15:48:58.600515 hisparc_sapphire-3.0.0/sapphire/data/trigger/3104.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:58.678182 hisparc_sapphire-3.0.0/sapphire/data/trigger/3105.tsv
+-rw-r--r--   0        0        0      612 2022-08-05 15:48:58.889119 hisparc_sapphire-3.0.0/sapphire/data/trigger/3201.tsv
+-rw-r--r--   0        0        0      306 2022-08-05 15:48:58.963365 hisparc_sapphire-3.0.0/sapphire/data/trigger/3202.tsv
+-rw-r--r--   0        0        0      408 2022-08-05 15:48:59.033968 hisparc_sapphire-3.0.0/sapphire/data/trigger/3203.tsv
+-rw-r--r--   0        0        0      408 2022-08-05 15:48:59.213662 hisparc_sapphire-3.0.0/sapphire/data/trigger/3301.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:59.296528 hisparc_sapphire-3.0.0/sapphire/data/trigger/3302.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:59.419658 hisparc_sapphire-3.0.0/sapphire/data/trigger/3303.tsv
+-rw-r--r--   0        0        0       98 2022-08-05 15:48:59.540143 hisparc_sapphire-3.0.0/sapphire/data/trigger/3304.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:59.615930 hisparc_sapphire-3.0.0/sapphire/data/trigger/3401.tsv
+-rw-r--r--   0        0        0      306 2022-08-05 15:48:59.835804 hisparc_sapphire-3.0.0/sapphire/data/trigger/3501.tsv
+-rw-r--r--   0        0        0      251 2022-08-05 15:49:00.074015 hisparc_sapphire-3.0.0/sapphire/data/trigger/3601.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:49:00.150911 hisparc_sapphire-3.0.0/sapphire/data/trigger/3701.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:49:00.294325 hisparc_sapphire-3.0.0/sapphire/data/trigger/3702.tsv
+-rw-r--r--   0        0        0      239 2022-08-05 15:48:42.355517 hisparc_sapphire-3.0.0/sapphire/data/trigger/4.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:49:11.683731 hisparc_sapphire-3.0.0/sapphire/data/trigger/40001.tsv
+-rw-r--r--   0        0        0      867 2022-08-05 15:49:00.382336 hisparc_sapphire-3.0.0/sapphire/data/trigger/4001.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:00.453557 hisparc_sapphire-3.0.0/sapphire/data/trigger/4002.tsv
+-rw-r--r--   0        0        0      306 2022-08-05 15:49:00.516633 hisparc_sapphire-3.0.0/sapphire/data/trigger/4003.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:00.595359 hisparc_sapphire-3.0.0/sapphire/data/trigger/4004.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:48.448562 hisparc_sapphire-3.0.0/sapphire/data/trigger/401.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:42.587215 hisparc_sapphire-3.0.0/sapphire/data/trigger/5.tsv
+-rw-r--r--   0        0        0     1006 2022-08-05 15:48:48.837365 hisparc_sapphire-3.0.0/sapphire/data/trigger/501.tsv
+-rw-r--r--   0        0        0      200 2022-08-05 15:48:49.131576 hisparc_sapphire-3.0.0/sapphire/data/trigger/502.tsv
+-rw-r--r--   0        0        0      306 2022-08-05 15:48:49.388425 hisparc_sapphire-3.0.0/sapphire/data/trigger/503.tsv
+-rw-r--r--   0        0        0       98 2022-08-05 15:48:49.658164 hisparc_sapphire-3.0.0/sapphire/data/trigger/504.tsv
+-rw-r--r--   0        0        0      380 2022-08-05 15:48:49.917168 hisparc_sapphire-3.0.0/sapphire/data/trigger/505.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:50.013121 hisparc_sapphire-3.0.0/sapphire/data/trigger/506.tsv
+-rw-r--r--   0        0        0      358 2022-08-05 15:48:50.386670 hisparc_sapphire-3.0.0/sapphire/data/trigger/507.tsv
+-rw-r--r--   0        0        0      666 2022-08-05 15:48:50.669849 hisparc_sapphire-3.0.0/sapphire/data/trigger/508.tsv
+-rw-r--r--   0        0        0      149 2022-08-05 15:48:50.922092 hisparc_sapphire-3.0.0/sapphire/data/trigger/509.tsv
+-rw-r--r--   0        0        0      290 2022-08-05 15:48:51.305298 hisparc_sapphire-3.0.0/sapphire/data/trigger/510.tsv
+-rw-r--r--   0        0        0       98 2022-08-05 15:48:51.536794 hisparc_sapphire-3.0.0/sapphire/data/trigger/511.tsv
+-rw-r--r--   0        0        0       94 2022-08-05 15:48:51.763505 hisparc_sapphire-3.0.0/sapphire/data/trigger/512.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:48:51.995579 hisparc_sapphire-3.0.0/sapphire/data/trigger/513.tsv
+-rw-r--r--   0        0        0      231 2022-08-05 15:48:52.203020 hisparc_sapphire-3.0.0/sapphire/data/trigger/514.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:48:52.267666 hisparc_sapphire-3.0.0/sapphire/data/trigger/521.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:48:52.326956 hisparc_sapphire-3.0.0/sapphire/data/trigger/522.tsv
+-rw-r--r--   0        0        0     1069 2022-08-05 15:48:54.171325 hisparc_sapphire-3.0.0/sapphire/data/trigger/599.tsv
+-rw-r--r--   0        0        0      412 2022-08-05 15:48:43.011063 hisparc_sapphire-3.0.0/sapphire/data/trigger/6.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:49:11.759238 hisparc_sapphire-3.0.0/sapphire/data/trigger/60001.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:48:54.439788 hisparc_sapphire-3.0.0/sapphire/data/trigger/601.tsv
+-rw-r--r--   0        0        0      141 2022-08-05 15:48:54.675992 hisparc_sapphire-3.0.0/sapphire/data/trigger/602.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:48:54.850876 hisparc_sapphire-3.0.0/sapphire/data/trigger/603.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:48:54.943685 hisparc_sapphire-3.0.0/sapphire/data/trigger/604.tsv
+-rw-r--r--   0        0        0      541 2022-08-05 15:48:43.173189 hisparc_sapphire-3.0.0/sapphire/data/trigger/7.tsv
+-rw-r--r--   0        0        0       50 2022-01-17 10:27:57.385239 hisparc_sapphire-3.0.0/sapphire/data/trigger/70001.tsv
+-rw-r--r--   0        0        0      255 2022-08-05 15:49:00.841729 hisparc_sapphire-3.0.0/sapphire/data/trigger/7001.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:01.064095 hisparc_sapphire-3.0.0/sapphire/data/trigger/7002.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:01.311580 hisparc_sapphire-3.0.0/sapphire/data/trigger/7003.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:01.391142 hisparc_sapphire-3.0.0/sapphire/data/trigger/7101.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:01.619955 hisparc_sapphire-3.0.0/sapphire/data/trigger/7102.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:49:01.699202 hisparc_sapphire-3.0.0/sapphire/data/trigger/7201.tsv
+-rw-r--r--   0        0        0      772 2022-08-05 15:49:01.941580 hisparc_sapphire-3.0.0/sapphire/data/trigger/7301.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:02.141358 hisparc_sapphire-3.0.0/sapphire/data/trigger/7401.tsv
+-rw-r--r--   0        0        0      102 2022-01-17 10:27:57.385655 hisparc_sapphire-3.0.0/sapphire/data/trigger/7501.tsv
+-rw-r--r--   0        0        0       47 2022-08-05 15:49:02.413253 hisparc_sapphire-3.0.0/sapphire/data/trigger/7601.tsv
+-rw-r--r--   0        0        0      408 2022-08-05 15:49:02.708171 hisparc_sapphire-3.0.0/sapphire/data/trigger/8001.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:02.796689 hisparc_sapphire-3.0.0/sapphire/data/trigger/8002.tsv
+-rw-r--r--   0        0        0     1632 2022-08-05 15:49:03.066642 hisparc_sapphire-3.0.0/sapphire/data/trigger/8003.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:03.489572 hisparc_sapphire-3.0.0/sapphire/data/trigger/8004.tsv
+-rw-r--r--   0        0        0      510 2022-08-05 15:49:03.727440 hisparc_sapphire-3.0.0/sapphire/data/trigger/8005.tsv
+-rw-r--r--   0        0        0      510 2022-08-05 15:49:03.842205 hisparc_sapphire-3.0.0/sapphire/data/trigger/8006.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:03.919073 hisparc_sapphire-3.0.0/sapphire/data/trigger/8007.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:04.308824 hisparc_sapphire-3.0.0/sapphire/data/trigger/8008.tsv
+-rw-r--r--   0        0        0      102 2022-08-05 15:49:04.720744 hisparc_sapphire-3.0.0/sapphire/data/trigger/8009.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:49:04.812376 hisparc_sapphire-3.0.0/sapphire/data/trigger/8101.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:04.883998 hisparc_sapphire-3.0.0/sapphire/data/trigger/8102.tsv
+-rw-r--r--   0        0        0      357 2022-08-05 15:49:04.965905 hisparc_sapphire-3.0.0/sapphire/data/trigger/8103.tsv
+-rw-r--r--   0        0        0      153 2022-08-05 15:49:05.031604 hisparc_sapphire-3.0.0/sapphire/data/trigger/8104.tsv
+-rw-r--r--   0        0        0      667 2022-08-05 15:49:05.213161 hisparc_sapphire-3.0.0/sapphire/data/trigger/8105.tsv
+-rw-r--r--   0        0        0      357 2022-08-05 15:49:05.363950 hisparc_sapphire-3.0.0/sapphire/data/trigger/8201.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:05.432341 hisparc_sapphire-3.0.0/sapphire/data/trigger/8301.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:05.496336 hisparc_sapphire-3.0.0/sapphire/data/trigger/8302.tsv
+-rw-r--r--   0        0        0      204 2022-08-05 15:49:07.791388 hisparc_sapphire-3.0.0/sapphire/data/trigger/8303.tsv
+-rw-r--r--   0        0        0       51 2022-08-05 15:49:07.965111 hisparc_sapphire-3.0.0/sapphire/data/trigger/8401.tsv
+-rw-r--r--   0        0        0      971 2022-08-05 15:48:43.449726 hisparc_sapphire-3.0.0/sapphire/data/trigger/9.tsv
+-rw-r--r--   0        0        0     6064 2024-05-04 20:10:01.318021 hisparc_sapphire-3.0.0/sapphire/data/update_local_data.py
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:21.805140 hisparc_sapphire-3.0.0/sapphire/data/voltage/10.tsv
+-rw-r--r--   0        0        0      684 2022-08-05 15:49:33.928247 hisparc_sapphire-3.0.0/sapphire/data/voltage/1001.tsv
+-rw-r--r--   0        0        0       56 2022-08-05 15:49:33.983937 hisparc_sapphire-3.0.0/sapphire/data/voltage/1002.tsv
+-rw-r--r--   0        0        0      111 2022-08-05 15:49:34.045191 hisparc_sapphire-3.0.0/sapphire/data/voltage/1003.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:49:34.094349 hisparc_sapphire-3.0.0/sapphire/data/voltage/1005.tsv
+-rw-r--r--   0        0        0      363 2022-08-05 15:49:34.295215 hisparc_sapphire-3.0.0/sapphire/data/voltage/1006.tsv
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:34.462120 hisparc_sapphire-3.0.0/sapphire/data/voltage/1007.tsv
+-rw-r--r--   0        0        0      244 2022-08-05 15:49:34.599430 hisparc_sapphire-3.0.0/sapphire/data/voltage/1008.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:34.686345 hisparc_sapphire-3.0.0/sapphire/data/voltage/1009.tsv
+-rw-r--r--   0        0        0      541 2022-08-05 15:49:23.520132 hisparc_sapphire-3.0.0/sapphire/data/voltage/101.tsv
+-rw-r--r--   0        0        0      411 2022-08-05 15:49:34.775155 hisparc_sapphire-3.0.0/sapphire/data/voltage/1010.tsv
+-rw-r--r--   0        0        0      347 2022-08-05 15:49:24.072190 hisparc_sapphire-3.0.0/sapphire/data/voltage/102.tsv
+-rw-r--r--   0        0        0       54 2022-08-05 15:49:24.137930 hisparc_sapphire-3.0.0/sapphire/data/voltage/103.tsv
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:24.389515 hisparc_sapphire-3.0.0/sapphire/data/voltage/104.tsv
+-rw-r--r--   0        0        0      621 2022-08-05 15:49:24.587104 hisparc_sapphire-3.0.0/sapphire/data/voltage/105.tsv
+-rw-r--r--   0        0        0      168 2022-08-05 15:49:24.758678 hisparc_sapphire-3.0.0/sapphire/data/voltage/106.tsv
+-rw-r--r--   0        0        0      324 2022-08-05 15:49:35.130658 hisparc_sapphire-3.0.0/sapphire/data/voltage/1101.tsv
+-rw-r--r--   0        0        0      297 2022-08-05 15:49:35.387021 hisparc_sapphire-3.0.0/sapphire/data/voltage/1102.tsv
+-rw-r--r--   0        0        0      270 2022-08-05 15:49:35.598630 hisparc_sapphire-3.0.0/sapphire/data/voltage/1103.tsv
+-rw-r--r--   0        0        0      687 2022-08-05 15:49:46.134661 hisparc_sapphire-3.0.0/sapphire/data/voltage/12001.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:21.885846 hisparc_sapphire-3.0.0/sapphire/data/voltage/13.tsv
+-rw-r--r--   0        0        0      298 2022-08-05 15:49:46.201216 hisparc_sapphire-3.0.0/sapphire/data/voltage/13001.tsv
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:46.263697 hisparc_sapphire-3.0.0/sapphire/data/voltage/13002.tsv
+-rw-r--r--   0        0        0      513 2022-08-05 15:49:46.345982 hisparc_sapphire-3.0.0/sapphire/data/voltage/13003.tsv
+-rw-r--r--   0        0        0      167 2022-08-05 15:49:46.402529 hisparc_sapphire-3.0.0/sapphire/data/voltage/13004.tsv
+-rw-r--r--   0        0        0      653 2022-08-05 15:49:46.498580 hisparc_sapphire-3.0.0/sapphire/data/voltage/13005.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:49:46.546250 hisparc_sapphire-3.0.0/sapphire/data/voltage/13006.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:49:46.595100 hisparc_sapphire-3.0.0/sapphire/data/voltage/13007.tsv
+-rw-r--r--   0        0        0       54 2022-08-05 15:49:46.641636 hisparc_sapphire-3.0.0/sapphire/data/voltage/13008.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:46.698408 hisparc_sapphire-3.0.0/sapphire/data/voltage/13009.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:46.758510 hisparc_sapphire-3.0.0/sapphire/data/voltage/13101.tsv
+-rw-r--r--   0        0        0      135 2022-08-05 15:49:46.816613 hisparc_sapphire-3.0.0/sapphire/data/voltage/13102.tsv
+-rw-r--r--   0        0        0       54 2022-08-05 15:49:46.869154 hisparc_sapphire-3.0.0/sapphire/data/voltage/13103.tsv
+-rw-r--r--   0        0        0      486 2022-08-05 15:49:47.038777 hisparc_sapphire-3.0.0/sapphire/data/voltage/13104.tsv
+-rw-r--r--   0        0        0      324 2022-08-05 15:49:47.112223 hisparc_sapphire-3.0.0/sapphire/data/voltage/13201.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:47.172130 hisparc_sapphire-3.0.0/sapphire/data/voltage/13301.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:49:47.220598 hisparc_sapphire-3.0.0/sapphire/data/voltage/13401.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:47.275271 hisparc_sapphire-3.0.0/sapphire/data/voltage/13501.tsv
+-rw-r--r--   0        0        0      109 2022-08-05 15:49:47.332311 hisparc_sapphire-3.0.0/sapphire/data/voltage/13601.tsv
+-rw-r--r--   0        0        0      972 2022-08-05 15:49:47.551193 hisparc_sapphire-3.0.0/sapphire/data/voltage/14001.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:47.646506 hisparc_sapphire-3.0.0/sapphire/data/voltage/14002.tsv
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:47.883067 hisparc_sapphire-3.0.0/sapphire/data/voltage/14003.tsv
+-rw-r--r--   0        0        0      216 2022-08-05 15:49:48.086385 hisparc_sapphire-3.0.0/sapphire/data/voltage/14004.tsv
+-rw-r--r--   0        0        0       81 2022-08-05 15:49:48.201612 hisparc_sapphire-3.0.0/sapphire/data/voltage/14005.tsv
+-rw-r--r--   0        0        0       81 2022-08-05 15:49:48.388013 hisparc_sapphire-3.0.0/sapphire/data/voltage/14006.tsv
+-rw-r--r--   0        0        0       54 2022-08-05 15:49:48.471076 hisparc_sapphire-3.0.0/sapphire/data/voltage/14007.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:48.667847 hisparc_sapphire-3.0.0/sapphire/data/voltage/14008.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:22.286924 hisparc_sapphire-3.0.0/sapphire/data/voltage/15.tsv
+-rw-r--r--   0        0        0      432 2022-08-05 15:49:48.754239 hisparc_sapphire-3.0.0/sapphire/data/voltage/15001.tsv
+-rw-r--r--   0        0        0      135 2022-08-05 15:49:48.812393 hisparc_sapphire-3.0.0/sapphire/data/voltage/15002.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:48.925971 hisparc_sapphire-3.0.0/sapphire/data/voltage/16001.tsv
+-rw-r--r--   0        0        0      135 2022-08-05 15:49:49.049028 hisparc_sapphire-3.0.0/sapphire/data/voltage/16101.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:49.204781 hisparc_sapphire-3.0.0/sapphire/data/voltage/17001.tsv
+-rw-r--r--   0        0        0      249 2022-08-05 15:49:19.471171 hisparc_sapphire-3.0.0/sapphire/data/voltage/2.tsv
+-rw-r--r--   0        0        0      324 2022-08-05 15:49:49.357249 hisparc_sapphire-3.0.0/sapphire/data/voltage/20001.tsv
+-rw-r--r--   0        0        0      498 2022-08-05 15:49:49.510536 hisparc_sapphire-3.0.0/sapphire/data/voltage/20002.tsv
+-rw-r--r--   0        0        0      382 2022-08-05 15:49:49.651087 hisparc_sapphire-3.0.0/sapphire/data/voltage/20003.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:35.665101 hisparc_sapphire-3.0.0/sapphire/data/voltage/2001.tsv
+-rw-r--r--   0        0        0      162 2022-08-05 15:49:35.730515 hisparc_sapphire-3.0.0/sapphire/data/voltage/2002.tsv
+-rw-r--r--   0        0        0      270 2022-08-05 15:49:35.804478 hisparc_sapphire-3.0.0/sapphire/data/voltage/2003.tsv
+-rw-r--r--   0        0        0      162 2022-08-05 15:49:35.876358 hisparc_sapphire-3.0.0/sapphire/data/voltage/2004.tsv
+-rw-r--r--   0        0        0      135 2022-08-05 15:49:35.938453 hisparc_sapphire-3.0.0/sapphire/data/voltage/2005.tsv
+-rw-r--r--   0        0        0       81 2022-08-05 15:49:36.007213 hisparc_sapphire-3.0.0/sapphire/data/voltage/2006.tsv
+-rw-r--r--   0        0        0       81 2022-08-05 15:49:36.080808 hisparc_sapphire-3.0.0/sapphire/data/voltage/2008.tsv
+-rw-r--r--   0        0        0      569 2022-08-05 15:49:24.964498 hisparc_sapphire-3.0.0/sapphire/data/voltage/201.tsv
+-rw-r--r--   0        0        0      893 2022-08-05 15:49:36.271493 hisparc_sapphire-3.0.0/sapphire/data/voltage/2010.tsv
+-rw-r--r--   0        0        0      500 2022-08-05 15:49:25.403487 hisparc_sapphire-3.0.0/sapphire/data/voltage/202.tsv
+-rw-r--r--   0        0        0      216 2022-08-05 15:49:25.660606 hisparc_sapphire-3.0.0/sapphire/data/voltage/203.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:22.573804 hisparc_sapphire-3.0.0/sapphire/data/voltage/21.tsv
+-rw-r--r--   0        0        0      604 2022-08-05 15:49:36.373789 hisparc_sapphire-3.0.0/sapphire/data/voltage/2101.tsv
+-rw-r--r--   0        0        0       54 2022-08-05 15:49:36.442566 hisparc_sapphire-3.0.0/sapphire/data/voltage/2102.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:49:36.496035 hisparc_sapphire-3.0.0/sapphire/data/voltage/2103.tsv
+-rw-r--r--   0        0        0      409 2022-08-05 15:49:22.797675 hisparc_sapphire-3.0.0/sapphire/data/voltage/22.tsv
+-rw-r--r--   0        0        0      595 2022-08-05 15:49:36.572484 hisparc_sapphire-3.0.0/sapphire/data/voltage/2201.tsv
+-rw-r--r--   0        0        0      729 2022-08-05 15:49:23.149242 hisparc_sapphire-3.0.0/sapphire/data/voltage/23.tsv
+-rw-r--r--   0        0        0      972 2022-08-05 15:49:23.399292 hisparc_sapphire-3.0.0/sapphire/data/voltage/24.tsv
+-rw-r--r--   0        0        0       27 2022-01-17 10:27:57.390264 hisparc_sapphire-3.0.0/sapphire/data/voltage/25.tsv
+-rw-r--r--   0        0        0     1232 2022-08-05 15:49:19.575440 hisparc_sapphire-3.0.0/sapphire/data/voltage/3.tsv
+-rw-r--r--   0        0        0      371 2022-08-05 15:49:36.827818 hisparc_sapphire-3.0.0/sapphire/data/voltage/3001.tsv
+-rw-r--r--   0        0        0      434 2022-08-05 15:49:37.043320 hisparc_sapphire-3.0.0/sapphire/data/voltage/3002.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:25.944368 hisparc_sapphire-3.0.0/sapphire/data/voltage/301.tsv
+-rw-r--r--   0        0        0      135 2022-08-05 15:49:26.036076 hisparc_sapphire-3.0.0/sapphire/data/voltage/303.tsv
+-rw-r--r--   0        0        0      162 2022-08-05 15:49:26.226658 hisparc_sapphire-3.0.0/sapphire/data/voltage/304.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:26.491972 hisparc_sapphire-3.0.0/sapphire/data/voltage/305.tsv
+-rw-r--r--   0        0        0      621 2022-08-05 15:49:37.129746 hisparc_sapphire-3.0.0/sapphire/data/voltage/3101.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:37.200763 hisparc_sapphire-3.0.0/sapphire/data/voltage/3102.tsv
+-rw-r--r--   0        0        0       54 2022-08-05 15:49:37.257174 hisparc_sapphire-3.0.0/sapphire/data/voltage/3103.tsv
+-rw-r--r--   0        0        0      405 2022-08-05 15:49:37.325919 hisparc_sapphire-3.0.0/sapphire/data/voltage/3104.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:37.405677 hisparc_sapphire-3.0.0/sapphire/data/voltage/3105.tsv
+-rw-r--r--   0        0        0      756 2022-08-05 15:49:37.622831 hisparc_sapphire-3.0.0/sapphire/data/voltage/3201.tsv
+-rw-r--r--   0        0        0      324 2022-08-05 15:49:37.698399 hisparc_sapphire-3.0.0/sapphire/data/voltage/3202.tsv
+-rw-r--r--   0        0        0      245 2022-08-05 15:49:37.762967 hisparc_sapphire-3.0.0/sapphire/data/voltage/3203.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:37.929869 hisparc_sapphire-3.0.0/sapphire/data/voltage/3301.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:38.007914 hisparc_sapphire-3.0.0/sapphire/data/voltage/3302.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:38.124624 hisparc_sapphire-3.0.0/sapphire/data/voltage/3303.tsv
+-rw-r--r--   0        0        0      378 2022-08-05 15:49:38.244146 hisparc_sapphire-3.0.0/sapphire/data/voltage/3304.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:38.315753 hisparc_sapphire-3.0.0/sapphire/data/voltage/3401.tsv
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:38.522652 hisparc_sapphire-3.0.0/sapphire/data/voltage/3501.tsv
+-rw-r--r--   0        0        0      270 2022-08-05 15:49:38.748802 hisparc_sapphire-3.0.0/sapphire/data/voltage/3601.tsv
+-rw-r--r--   0        0        0       81 2022-08-05 15:49:38.819057 hisparc_sapphire-3.0.0/sapphire/data/voltage/3701.tsv
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:38.954747 hisparc_sapphire-3.0.0/sapphire/data/voltage/3702.tsv
+-rw-r--r--   0        0        0      351 2022-08-05 15:49:20.766166 hisparc_sapphire-3.0.0/sapphire/data/voltage/4.tsv
+-rw-r--r--   0        0        0      108 2022-08-05 15:49:49.764730 hisparc_sapphire-3.0.0/sapphire/data/voltage/40001.tsv
+-rw-r--r--   0        0        0      778 2022-08-05 15:49:39.037988 hisparc_sapphire-3.0.0/sapphire/data/voltage/4001.tsv
+-rw-r--r--   0        0        0       81 2022-08-05 15:49:39.096930 hisparc_sapphire-3.0.0/sapphire/data/voltage/4002.tsv
+-rw-r--r--   0        0        0      168 2022-08-05 15:49:39.164750 hisparc_sapphire-3.0.0/sapphire/data/voltage/4003.tsv
+-rw-r--r--   0        0        0      224 2022-08-05 15:49:39.240273 hisparc_sapphire-3.0.0/sapphire/data/voltage/4004.tsv
+-rw-r--r--   0        0        0      662 2022-08-05 15:49:26.581637 hisparc_sapphire-3.0.0/sapphire/data/voltage/401.tsv
+-rw-r--r--   0        0        0      193 2022-08-05 15:49:20.998367 hisparc_sapphire-3.0.0/sapphire/data/voltage/5.tsv
+-rw-r--r--   0        0        0      972 2022-08-05 15:49:27.363338 hisparc_sapphire-3.0.0/sapphire/data/voltage/501.tsv
+-rw-r--r--   0        0        0      648 2022-08-05 15:49:27.663956 hisparc_sapphire-3.0.0/sapphire/data/voltage/502.tsv
+-rw-r--r--   0        0        0      795 2022-08-05 15:49:27.927965 hisparc_sapphire-3.0.0/sapphire/data/voltage/503.tsv
+-rw-r--r--   0        0        0      756 2022-08-05 15:49:28.213989 hisparc_sapphire-3.0.0/sapphire/data/voltage/504.tsv
+-rw-r--r--   0        0        0      814 2022-08-05 15:49:29.311237 hisparc_sapphire-3.0.0/sapphire/data/voltage/505.tsv
+-rw-r--r--   0        0        0      378 2022-08-05 15:49:29.391203 hisparc_sapphire-3.0.0/sapphire/data/voltage/506.tsv
+-rw-r--r--   0        0        0      702 2022-08-05 15:49:29.808749 hisparc_sapphire-3.0.0/sapphire/data/voltage/507.tsv
+-rw-r--r--   0        0        0      737 2022-08-05 15:49:30.082805 hisparc_sapphire-3.0.0/sapphire/data/voltage/508.tsv
+-rw-r--r--   0        0        0      378 2022-08-05 15:49:30.341000 hisparc_sapphire-3.0.0/sapphire/data/voltage/509.tsv
+-rw-r--r--   0        0        0      648 2022-08-05 15:49:30.727954 hisparc_sapphire-3.0.0/sapphire/data/voltage/510.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:30.946509 hisparc_sapphire-3.0.0/sapphire/data/voltage/511.tsv
+-rw-r--r--   0        0        0      297 2022-08-05 15:49:31.170223 hisparc_sapphire-3.0.0/sapphire/data/voltage/512.tsv
+-rw-r--r--   0        0        0      162 2022-08-05 15:49:31.397188 hisparc_sapphire-3.0.0/sapphire/data/voltage/513.tsv
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:31.590029 hisparc_sapphire-3.0.0/sapphire/data/voltage/514.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:49:31.647757 hisparc_sapphire-3.0.0/sapphire/data/voltage/521.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:49:31.700747 hisparc_sapphire-3.0.0/sapphire/data/voltage/522.tsv
+-rw-r--r--   0        0        0      569 2022-08-05 15:49:33.054111 hisparc_sapphire-3.0.0/sapphire/data/voltage/599.tsv
+-rw-r--r--   0        0        0      729 2022-08-05 15:49:21.323820 hisparc_sapphire-3.0.0/sapphire/data/voltage/6.tsv
+-rw-r--r--   0        0        0      297 2022-08-05 15:49:49.840230 hisparc_sapphire-3.0.0/sapphire/data/voltage/60001.tsv
+-rw-r--r--   0        0        0      336 2022-08-05 15:49:33.320812 hisparc_sapphire-3.0.0/sapphire/data/voltage/601.tsv
+-rw-r--r--   0        0        0      270 2022-08-05 15:49:33.554869 hisparc_sapphire-3.0.0/sapphire/data/voltage/602.tsv
+-rw-r--r--   0        0        0      162 2022-08-05 15:49:33.714777 hisparc_sapphire-3.0.0/sapphire/data/voltage/603.tsv
+-rw-r--r--   0        0        0       27 2022-08-05 15:49:33.797961 hisparc_sapphire-3.0.0/sapphire/data/voltage/604.tsv
+-rw-r--r--   0        0        0      866 2022-08-05 15:49:21.461556 hisparc_sapphire-3.0.0/sapphire/data/voltage/7.tsv
+-rw-r--r--   0        0        0      383 2022-08-05 15:49:39.473023 hisparc_sapphire-3.0.0/sapphire/data/voltage/7001.tsv
+-rw-r--r--   0        0        0      248 2022-08-05 15:49:39.688679 hisparc_sapphire-3.0.0/sapphire/data/voltage/7002.tsv
+-rw-r--r--   0        0        0      112 2022-08-05 15:49:39.904879 hisparc_sapphire-3.0.0/sapphire/data/voltage/7003.tsv
+-rw-r--r--   0        0        0       84 2022-08-05 15:49:39.972564 hisparc_sapphire-3.0.0/sapphire/data/voltage/7101.tsv
+-rw-r--r--   0        0        0      165 2022-08-05 15:49:40.176727 hisparc_sapphire-3.0.0/sapphire/data/voltage/7102.tsv
+-rw-r--r--   0        0        0       56 2022-08-05 15:49:40.246926 hisparc_sapphire-3.0.0/sapphire/data/voltage/7201.tsv
+-rw-r--r--   0        0        0      548 2022-08-05 15:49:40.855828 hisparc_sapphire-3.0.0/sapphire/data/voltage/7301.tsv
+-rw-r--r--   0        0        0      278 2022-08-05 15:49:41.038557 hisparc_sapphire-3.0.0/sapphire/data/voltage/7401.tsv
+-rw-r--r--   0        0        0       56 2022-01-17 10:27:57.393132 hisparc_sapphire-3.0.0/sapphire/data/voltage/7501.tsv
+-rw-r--r--   0        0        0      459 2022-08-05 15:49:41.294771 hisparc_sapphire-3.0.0/sapphire/data/voltage/7601.tsv
+-rw-r--r--   0        0        0      684 2022-08-05 15:49:41.685584 hisparc_sapphire-3.0.0/sapphire/data/voltage/8001.tsv
+-rw-r--r--   0        0        0      135 2022-08-05 15:49:41.757642 hisparc_sapphire-3.0.0/sapphire/data/voltage/8002.tsv
+-rw-r--r--   0        0        0     1083 2022-08-05 15:49:42.011004 hisparc_sapphire-3.0.0/sapphire/data/voltage/8003.tsv
+-rw-r--r--   0        0        0      334 2022-08-05 15:49:42.401388 hisparc_sapphire-3.0.0/sapphire/data/voltage/8004.tsv
+-rw-r--r--   0        0        0      487 2022-08-05 15:49:42.626469 hisparc_sapphire-3.0.0/sapphire/data/voltage/8005.tsv
+-rw-r--r--   0        0        0      540 2022-08-05 15:49:42.735154 hisparc_sapphire-3.0.0/sapphire/data/voltage/8006.tsv
+-rw-r--r--   0        0        0      224 2022-08-05 15:49:42.799330 hisparc_sapphire-3.0.0/sapphire/data/voltage/8007.tsv
+-rw-r--r--   0        0        0      327 2022-08-05 15:49:43.082608 hisparc_sapphire-3.0.0/sapphire/data/voltage/8008.tsv
+-rw-r--r--   0        0        0      189 2022-08-05 15:49:43.426228 hisparc_sapphire-3.0.0/sapphire/data/voltage/8009.tsv
+-rw-r--r--   0        0        0      270 2022-08-05 15:49:43.515396 hisparc_sapphire-3.0.0/sapphire/data/voltage/8101.tsv
+-rw-r--r--   0        0        0       54 2022-08-05 15:49:43.570424 hisparc_sapphire-3.0.0/sapphire/data/voltage/8102.tsv
+-rw-r--r--   0        0        0      216 2022-08-05 15:49:43.646875 hisparc_sapphire-3.0.0/sapphire/data/voltage/8103.tsv
+-rw-r--r--   0        0        0      243 2022-08-05 15:49:43.712121 hisparc_sapphire-3.0.0/sapphire/data/voltage/8104.tsv
+-rw-r--r--   0        0        0     1365 2022-08-05 15:49:43.913425 hisparc_sapphire-3.0.0/sapphire/data/voltage/8105.tsv
+-rw-r--r--   0        0        0      216 2022-08-05 15:49:44.060131 hisparc_sapphire-3.0.0/sapphire/data/voltage/8201.tsv
+-rw-r--r--   0        0        0      362 2022-08-05 15:49:44.130160 hisparc_sapphire-3.0.0/sapphire/data/voltage/8301.tsv
+-rw-r--r--   0        0        0      109 2022-08-05 15:49:44.188451 hisparc_sapphire-3.0.0/sapphire/data/voltage/8302.tsv
+-rw-r--r--   0        0        0      387 2022-08-05 15:49:45.882772 hisparc_sapphire-3.0.0/sapphire/data/voltage/8303.tsv
+-rw-r--r--   0        0        0      489 2022-08-05 15:49:46.057317 hisparc_sapphire-3.0.0/sapphire/data/voltage/8401.tsv
+-rw-r--r--   0        0        0      976 2022-08-05 15:49:21.735993 hisparc_sapphire-3.0.0/sapphire/data/voltage/9.tsv
+-rw-r--r--   0        0        0    32795 2024-04-27 09:50:00.426240 hisparc_sapphire-3.0.0/sapphire/esd.py
+-rw-r--r--   0        0        0    10520 2024-05-05 08:58:23.801413 hisparc_sapphire-3.0.0/sapphire/kascade.py
+-rw-r--r--   0        0        0     7915 2024-04-27 09:41:55.898509 hisparc_sapphire-3.0.0/sapphire/publicdb.py
+-rw-r--r--   0        0        0     3177 2024-04-27 11:47:39.908804 hisparc_sapphire-3.0.0/sapphire/qsub.py
+-rw-r--r--   0        0        0      854 2024-04-14 19:13:10.151502 hisparc_sapphire-3.0.0/sapphire/simulations/__init__.py
+-rw-r--r--   0        0        0    11666 2024-05-04 20:07:59.202526 hisparc_sapphire-3.0.0/sapphire/simulations/base.py
+-rw-r--r--   0        0        0    10234 2024-05-04 20:36:55.211130 hisparc_sapphire-3.0.0/sapphire/simulations/detector.py
+-rw-r--r--   0        0        0     8534 2024-05-04 20:07:59.202258 hisparc_sapphire-3.0.0/sapphire/simulations/gammas.py
+-rw-r--r--   0        0        0    23449 2024-05-04 20:36:28.217187 hisparc_sapphire-3.0.0/sapphire/simulations/groundparticles.py
+-rw-r--r--   0        0        0    15766 2024-05-04 20:07:59.201832 hisparc_sapphire-3.0.0/sapphire/simulations/ldf.py
+-rw-r--r--   0        0        0    10374 2024-04-27 10:49:08.675766 hisparc_sapphire-3.0.0/sapphire/simulations/showerfront.py
+-rw-r--r--   0        0        0     7619 2024-04-14 19:13:10.151241 hisparc_sapphire-3.0.0/sapphire/storage.py
+-rw-r--r--   0        0        0      691 2024-04-14 19:13:10.140335 hisparc_sapphire-3.0.0/sapphire/tests/__init__.py
+-rw-r--r--   0        0        0        0 2022-01-17 10:27:57.395981 hisparc_sapphire-3.0.0/sapphire/tests/analysis/__init__.py
+-rw-r--r--   0        0        0    15914 2024-05-04 20:38:26.962534 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_calibration.py
+-rw-r--r--   0        0        0     9829 2024-04-14 19:13:13.669273 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_coincidence_queries.py
+-rw-r--r--   0        0        0     9249 2024-05-05 10:05:20.882715 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_coincidences.py
+-rw-r--r--   0        0        0     1203 2024-04-14 19:13:10.147905 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_core_reconstruction.py
+-rw-r--r--   0        0        0     3445 2022-07-07 05:21:20.125889 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_data/README.md
+-rw-r--r--   0        0        0    51926 2022-01-17 10:27:57.396698 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_data/coincidences.h5
+-rw-r--r--   0        0        0    43894 2022-01-17 10:27:57.397793 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_data/esd_coincidences.h5
+-rw-r--r--   0        0        0   295955 2022-01-17 10:27:57.398070 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_data/process_events.h5
+-rw-r--r--   0        0        0    32757 2024-05-05 09:31:07.977391 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_direction_reconstruction.py
+-rw-r--r--   0        0        0    11557 2024-04-14 19:13:16.337983 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_event_utils.py
+-rw-r--r--   0        0        0     1695 2024-04-14 19:13:10.150390 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_find_mpv.py
+-rw-r--r--   0        0        0      759 2024-04-14 19:13:10.148194 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_landau.py
+-rw-r--r--   0        0        0    16899 2024-05-04 15:39:54.124426 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_process_events.py
+-rw-r--r--   0        0        0     9545 2024-04-27 10:50:00.606231 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_process_traces.py
+-rw-r--r--   0        0        0    17788 2024-05-04 20:27:30.526785 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_reconstructions.py
+-rw-r--r--   0        0        0     2395 2024-05-05 10:05:54.945976 hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_time_deltas.py
+-rw-r--r--   0        0        0        0 2022-01-17 10:27:57.398851 hisparc_sapphire-3.0.0/sapphire/tests/corsika/__init__.py
+-rw-r--r--   0        0        0     4625 2024-05-02 06:26:19.417800 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_blocks.py
+-rw-r--r--   0        0        0     3141 2024-05-02 10:26:00.696874 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_corsika.py
+-rw-r--r--   0        0        0     5619 2024-05-04 20:42:22.786488 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_corsika_queries.py
+-rw-r--r--   0        0        0  1101120 2022-01-17 10:27:57.403424 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/1_2/DAT000000
+-rw-r--r--   0        0        0  1581730 2022-01-17 10:27:57.410201 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/1_2/corsika.h5
+-rw-r--r--   0        0        0    78648 2022-01-17 10:27:57.410693 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/3_4/DAT000000
+-rw-r--r--   0        0        0   177555 2022-01-17 10:27:57.411344 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/3_4/corsika.h5
+-rw-r--r--   0        0        0     1601 2022-01-17 10:27:57.411432 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/README.md
+-rw-r--r--   0        0        0    72256 2022-01-17 10:27:57.411624 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/corsika_overview.h5
+-rw-r--r--   0        0        0     1228 2024-05-02 10:26:21.031722 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_generate_corsika_overview.py
+-rw-r--r--   0        0        0     1665 2024-04-27 10:04:56.734193 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_particles.py
+-rw-r--r--   0        0        0     9297 2024-04-14 19:13:16.333476 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_qsub_corsika.py
+-rw-r--r--   0        0        0     5100 2024-04-14 19:13:16.334317 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_qsub_store_corsika_data.py
+-rw-r--r--   0        0        0     2244 2024-05-02 10:26:35.193059 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_store_corsika_data.py
+-rw-r--r--   0        0        0     2744 2024-04-14 19:13:10.146733 hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_units.py
+-rw-r--r--   0        0        0      274 2024-04-15 07:34:12.348529 hisparc_sapphire-3.0.0/sapphire/tests/create_and_store_test_data.py
+-rw-r--r--   0        0        0        0 2022-01-17 10:27:57.398851 hisparc_sapphire-3.0.0/sapphire/tests/data/__init__.py
+-rw-r--r--   0        0        0      546 2024-04-14 19:13:10.147105 hisparc_sapphire-3.0.0/sapphire/tests/data/test_extend_local_data.py
+-rw-r--r--   0        0        0     1492 2024-05-04 20:33:07.704970 hisparc_sapphire-3.0.0/sapphire/tests/data/test_update_local_data.py
+-rw-r--r--   0        0        0     3987 2024-04-15 10:41:00.096843 hisparc_sapphire-3.0.0/sapphire/tests/esd_load_data.py
+-rw-r--r--   0        0        0        0 2022-01-17 10:27:57.412415 hisparc_sapphire-3.0.0/sapphire/tests/simulations/__init__.py
+-rw-r--r--   0        0        0     3200 2024-04-14 19:13:10.149596 hisparc_sapphire-3.0.0/sapphire/tests/simulations/perform_simulation.py
+-rw-r--r--   0        0        0    10701 2024-04-14 19:13:16.340556 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_base_simulation.py
+-rw-r--r--   0        0        0      497 2022-01-17 10:27:57.412657 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/README.md
+-rw-r--r--   0        0        0  1581730 2022-01-17 10:27:57.413653 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/corsika.h5
+-rw-r--r--   0        0        0    69174 2022-01-17 10:27:57.413914 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/flatfront_sim.h5
+-rw-r--r--   0        0        0    61258 2022-01-17 10:27:57.414558 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/gamma_sim.h5
+-rw-r--r--   0        0        0    67441 2022-01-17 10:27:57.414714 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/groundparticles_sim.h5
+-rw-r--r--   0        0        0    67318 2022-01-17 10:27:57.414862 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/nkgldf_sim.h5
+-rw-r--r--   0        0        0     5387 2024-05-04 21:12:40.766260 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_detectors.py
+-rw-r--r--   0        0        0     6047 2024-05-04 20:07:59.201516 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_gammas.py
+-rw-r--r--   0        0        0     9143 2024-05-04 20:36:28.219232 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_groundparticles.py
+-rw-r--r--   0        0        0     2134 2024-05-04 20:07:59.201398 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_ldf.py
+-rw-r--r--   0        0        0     1845 2024-05-02 10:39:20.229481 hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_simulation_acceptance.py
+-rw-r--r--   0        0        0    30408 2024-04-14 19:13:16.340552 hisparc_sapphire-3.0.0/sapphire/tests/test_api.py
+-rw-r--r--   0        0        0    29072 2024-04-14 19:13:16.337778 hisparc_sapphire-3.0.0/sapphire/tests/test_clusters.py
+-rw-r--r--   0        0        0     1192 2024-04-14 19:13:10.137534 hisparc_sapphire-3.0.0/sapphire/tests/test_clusters_acceptance.py
+-rw-r--r--   0        0        0     1678 2022-01-17 10:27:57.415806 hisparc_sapphire-3.0.0/sapphire/tests/test_data/README.md
+-rw-r--r--   0        0        0     4296 2022-08-05 18:00:28.017321 hisparc_sapphire-3.0.0/sapphire/tests/test_data/coincidences-20160310.tsv
+-rw-r--r--   0        0        0    81944 2022-08-05 17:53:06.291381 hisparc_sapphire-3.0.0/sapphire/tests/test_data/esd_coincidence_data.h5
+-rw-r--r--   0        0        0    29454 2022-08-05 17:53:02.527459 hisparc_sapphire-3.0.0/sapphire/tests/test_data/esd_load_data.h5
+-rw-r--r--   0        0        0     5975 2022-08-05 18:00:28.018084 hisparc_sapphire-3.0.0/sapphire/tests/test_data/events-s501-20120101.tsv
+-rw-r--r--   0        0        0     1832 2022-01-17 10:27:57.417643 hisparc_sapphire-3.0.0/sapphire/tests/test_data/kascade.dat
+-rw-r--r--   0        0        0    72676 2022-01-17 10:27:57.417838 hisparc_sapphire-3.0.0/sapphire/tests/test_data/kascade.h5
+-rw-r--r--   0        0        0     1324 2022-08-05 17:53:06.603707 hisparc_sapphire-3.0.0/sapphire/tests/test_data/lightning-knmi-20150717.tsv
+-rw-r--r--   0        0        0   416604 2022-01-17 10:27:57.418238 hisparc_sapphire-3.0.0/sapphire/tests/test_data/publicdb.h5
+-rw-r--r--   0        0        0   419051 2022-01-17 10:27:57.418508 hisparc_sapphire-3.0.0/sapphire/tests/test_data/publicdb_src.h5
+-rw-r--r--   0        0        0    38537 2022-10-26 22:37:20.848903 hisparc_sapphire-3.0.0/sapphire/tests/test_data/singles-s501-20170101.tsv
+-rw-r--r--   0        0        0     3014 2022-08-05 18:00:28.019179 hisparc_sapphire-3.0.0/sapphire/tests/test_data/weather-s501-20120101.tsv
+-rw-r--r--   0        0        0     6672 2024-04-14 19:13:10.146620 hisparc_sapphire-3.0.0/sapphire/tests/test_esd.py
+-rw-r--r--   0        0        0     1007 2024-05-02 10:27:26.533881 hisparc_sapphire-3.0.0/sapphire/tests/test_kascade.py
+-rw-r--r--   0        0        0     6077 2024-05-02 10:27:42.626839 hisparc_sapphire-3.0.0/sapphire/tests/test_publicdb.py
+-rw-r--r--   0        0        0     4043 2024-05-05 09:04:57.557032 hisparc_sapphire-3.0.0/sapphire/tests/test_qsub.py
+-rw-r--r--   0        0        0     1104 2024-04-14 19:12:48.719820 hisparc_sapphire-3.0.0/sapphire/tests/test_time_util.py
+-rw-r--r--   0        0        0     6850 2024-05-04 20:36:28.219487 hisparc_sapphire-3.0.0/sapphire/tests/test_utils.py
+-rw-r--r--   0        0        0        0 2022-01-17 10:27:57.419268 hisparc_sapphire-3.0.0/sapphire/tests/transformations/__init__.py
+-rw-r--r--   0        0        0     1333 2024-04-14 19:13:10.150711 hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_angles.py
+-rw-r--r--   0        0        0     4202 2024-04-27 10:01:32.138503 hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_axes.py
+-rw-r--r--   0        0        0      857 2024-04-14 19:13:10.150920 hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_base.py
+-rw-r--r--   0        0        0    11734 2024-04-27 11:40:36.789984 hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_celestial.py
+-rw-r--r--   0        0        0     7263 2024-05-04 20:36:28.219676 hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_clock.py
+-rw-r--r--   0        0        0     1822 2024-04-14 19:13:10.148191 hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_geographic.py
+-rw-r--r--   0        0        0     4462 2024-05-04 20:07:59.200947 hisparc_sapphire-3.0.0/sapphire/tests/validate_results.py
+-rw-r--r--   0        0        0     2374 2024-04-14 19:13:10.154926 hisparc_sapphire-3.0.0/sapphire/time_util.py
+-rw-r--r--   0        0        0      861 2024-04-14 19:13:10.151580 hisparc_sapphire-3.0.0/sapphire/transformations/__init__.py
+-rw-r--r--   0        0        0      917 2024-04-14 19:13:10.149970 hisparc_sapphire-3.0.0/sapphire/transformations/angles.py
+-rw-r--r--   0        0        0     4567 2024-04-14 19:13:10.153839 hisparc_sapphire-3.0.0/sapphire/transformations/axes.py
+-rw-r--r--   0        0        0     1048 2024-04-14 19:13:10.153806 hisparc_sapphire-3.0.0/sapphire/transformations/base.py
+-rw-r--r--   0        0        0    10670 2024-04-14 19:13:16.334846 hisparc_sapphire-3.0.0/sapphire/transformations/celestial.py
+-rw-r--r--   0        0        0    10435 2024-04-22 19:40:52.944382 hisparc_sapphire-3.0.0/sapphire/transformations/clock.py
+-rw-r--r--   0        0        0     5690 2024-04-14 19:13:13.665830 hisparc_sapphire-3.0.0/sapphire/transformations/geographic.py
+-rw-r--r--   0        0        0     5150 2024-05-04 20:27:34.306943 hisparc_sapphire-3.0.0/sapphire/utils.py
+-rw-r--r--   0        0        0      605 2022-01-17 10:27:57.420587 hisparc_sapphire-3.0.0/scripts/README.rst
+-rw-r--r--   0        0        0       54 2022-01-17 10:27:57.420661 hisparc_sapphire-3.0.0/scripts/aires/.gitignore
+-rw-r--r--   0        0        0      103 2022-01-17 10:27:57.420713 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e14-angle-22_5.sh
+-rw-r--r--   0        0        0      100 2022-01-17 10:27:57.420763 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e15-angle-0.sh
+-rw-r--r--   0        0        0      101 2022-01-17 10:27:57.420820 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e15-angle-10.sh
+-rw-r--r--   0        0        0      101 2022-01-17 10:27:57.420873 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e15-angle-15.sh
+-rw-r--r--   0        0        0      103 2022-01-17 10:27:57.420927 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e15-angle-22_5.sh
+-rw-r--r--   0        0        0      101 2022-01-17 10:27:57.420981 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e15-angle-30.sh
+-rw-r--r--   0        0        0      101 2022-01-17 10:27:57.421037 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e15-angle-35.sh
+-rw-r--r--   0        0        0      101 2022-01-17 10:27:57.421092 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e15-angle-45.sh
+-rw-r--r--   0        0        0      100 2022-01-17 10:27:57.421141 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e15-angle-5.sh
+-rw-r--r--   0        0        0      103 2022-01-17 10:27:57.421187 hisparc_sapphire-3.0.0/scripts/aires/do_aires_sim_e16-angle-22_5.sh
+-rw-r--r--   0        0        0      171 2022-01-17 10:27:57.421235 hisparc_sapphire-3.0.0/scripts/aires/sime14-angle-22_5.inp
+-rw-r--r--   0        0        0      165 2022-01-17 10:27:57.421291 hisparc_sapphire-3.0.0/scripts/aires/sime15-angle-0.inp
+-rw-r--r--   0        0        0      167 2022-01-17 10:27:57.421340 hisparc_sapphire-3.0.0/scripts/aires/sime15-angle-10.inp
+-rw-r--r--   0        0        0      167 2022-01-17 10:27:57.421388 hisparc_sapphire-3.0.0/scripts/aires/sime15-angle-15.inp
+-rw-r--r--   0        0        0      171 2022-01-17 10:27:57.421442 hisparc_sapphire-3.0.0/scripts/aires/sime15-angle-22_5.inp
+-rw-r--r--   0        0        0      167 2022-01-17 10:27:57.421501 hisparc_sapphire-3.0.0/scripts/aires/sime15-angle-30.inp
+-rw-r--r--   0        0        0      167 2022-01-17 10:27:57.421552 hisparc_sapphire-3.0.0/scripts/aires/sime15-angle-35.inp
+-rw-r--r--   0        0        0      167 2022-01-17 10:27:57.421602 hisparc_sapphire-3.0.0/scripts/aires/sime15-angle-45.inp
+-rw-r--r--   0        0        0      165 2022-01-17 10:27:57.421654 hisparc_sapphire-3.0.0/scripts/aires/sime15-angle-5.inp
+-rw-r--r--   0        0        0      170 2022-01-17 10:27:57.421711 hisparc_sapphire-3.0.0/scripts/aires/sime16-angle-22_5.inp
+-rwxr-xr-x   0        0        0     1080 2024-04-14 19:13:10.140090 hisparc_sapphire-3.0.0/scripts/corsika/ground_particles.py
+-rw-r--r--   0        0        0     4895 2024-04-27 11:47:11.151104 hisparc_sapphire-3.0.0/scripts/corsika/qsub_sort_stored_corsika_data.py
+-rwxr-xr-x   0        0        0      350 2024-04-14 19:12:48.719418 hisparc_sapphire-3.0.0/scripts/corsika/summary.py
+-rw-r--r--   0        0        0     1994 2024-04-14 19:13:10.139533 hisparc_sapphire-3.0.0/scripts/data/demo_mpv_fit.py
+-rwxr-xr-x   0        0        0     2169 2024-04-14 19:13:10.138958 hisparc_sapphire-3.0.0/scripts/data/hdf5_coincidences_to_csv.py
+-rw-r--r--   0        0        0       55 2022-01-17 10:27:57.422165 hisparc_sapphire-3.0.0/scripts/kascade/.gitignore
+-rw-r--r--   0        0        0    25138 2024-04-14 19:13:13.656360 hisparc_sapphire-3.0.0/scripts/kascade/direction_reconstruction.py
+-rw-r--r--   0        0        0     2331 2024-04-14 19:13:13.665771 hisparc_sapphire-3.0.0/scripts/kascade/event_generator.py
+-rw-r--r--   0        0        0     1601 2024-04-14 19:13:16.336879 hisparc_sapphire-3.0.0/scripts/kascade/fit.py
+-rw-r--r--   0        0        0      758 2022-01-17 10:27:57.422516 hisparc_sapphire-3.0.0/scripts/kascade/make_test_data.py
+-rw-r--r--   0        0        0     3701 2024-04-14 19:13:10.137586 hisparc_sapphire-3.0.0/scripts/kascade/master.py
+lrwxr-xr-x   0        0        0        0 2022-01-17 10:27:57.422617 hisparc_sapphire-3.0.0/scripts/kascade/myshowerfront.py -> ../simulations/myshowerfront.py
+-rw-r--r--   0        0        0     4685 2024-04-14 19:13:10.142392 hisparc_sapphire-3.0.0/scripts/kascade/plot_matching_events.py
+-rw-r--r--   0        0        0     1825 2024-04-14 19:13:10.146449 hisparc_sapphire-3.0.0/scripts/kascade/plot_pulseheight_histogram.py
+-rw-r--r--   0        0        0     5440 2024-04-14 19:13:10.141234 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/CIC.py
+-rw-r--r--   0        0        0      575 2024-04-14 19:13:10.141066 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/Event.py
+-rw-r--r--   0        0        0     7170 2024-04-14 19:13:10.139399 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/EventExportValues.py
+-rw-r--r--   0        0        0     3917 2024-04-14 19:13:13.659048 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/HiSparc2Event.py
+-rw-r--r--   0        0        0     4402 2024-04-14 19:13:10.140344 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/legacy.py
+-rw-r--r--   0        0        0     1907 2024-04-14 19:13:10.137466 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/read_sqldump.py
+-rw-r--r--   0        0        0     9017 2024-04-14 19:13:10.144674 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/storage.py
+-rw-r--r--   0        0        0     4066 2024-04-14 19:13:13.657486 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/store_events.py
+-rw-r--r--   0        0        0     5716 2024-04-14 19:13:10.137493 hisparc_sapphire-3.0.0/scripts/kascade/read_sqldump/upload_codes.py
+-rw-r--r--   0        0        0    14527 2024-04-14 19:13:13.671024 hisparc_sapphire-3.0.0/scripts/kascade/reconstruction_efficiency.py
+-rw-r--r--   0        0        0     3460 2024-04-14 19:13:10.141432 hisparc_sapphire-3.0.0/scripts/kascade/rel_gauss.py
+-rw-r--r--   0        0        0      556 2022-01-17 10:27:57.423641 hisparc_sapphire-3.0.0/scripts/kascade/run_test.sh
+-rw-r--r--   0        0        0     7585 2024-04-14 19:13:16.337303 hisparc_sapphire-3.0.0/scripts/kascade/test_tcc.py
+-rw-r--r--   0        0        0      897 2024-04-14 19:13:10.146743 hisparc_sapphire-3.0.0/scripts/kascade/utils.py
+-rw-r--r--   0        0        0       15 2022-01-17 10:27:57.423854 hisparc_sapphire-3.0.0/scripts/sciencepark/.gitignore
+-rw-r--r--   0        0        0   239304 2022-01-17 10:27:57.424857 hisparc_sapphire-3.0.0/scripts/sciencepark/backgrounds/ScienceParkMap_0.365.png
+-rw-r--r--   0        0        0     1908 2024-04-14 19:13:10.142268 hisparc_sapphire-3.0.0/scripts/sciencepark/detector_locations.py
+-rw-r--r--   0        0        0    28146 2024-04-14 19:13:16.343861 hisparc_sapphire-3.0.0/scripts/sciencepark/direction_analysis_plots.py
+-rw-r--r--   0        0        0     3348 2024-04-14 19:13:10.141599 hisparc_sapphire-3.0.0/scripts/sciencepark/master-simulations.py
+-rw-r--r--   0        0        0    14574 2024-04-14 19:13:16.340631 hisparc_sapphire-3.0.0/scripts/sciencepark/master-single-station.py
+-rw-r--r--   0        0        0    14798 2024-04-14 19:13:16.338812 hisparc_sapphire-3.0.0/scripts/sciencepark/master.py
+-rw-r--r--   0        0        0     1167 2024-04-14 19:13:10.139038 hisparc_sapphire-3.0.0/scripts/sciencepark/plot_trace.py
+-rw-r--r--   0        0        0      897 2024-04-14 19:13:10.144646 hisparc_sapphire-3.0.0/scripts/sciencepark/utils.py
+-rw-r--r--   0        0        0       89 2022-01-17 10:27:57.425582 hisparc_sapphire-3.0.0/scripts/simulations/.gitignore
+-rw-r--r--   0        0        0     5060 2024-04-14 19:13:10.148088 hisparc_sapphire-3.0.0/scripts/simulations/analyze_shower_front.py
+-rw-r--r--   0        0        0     1518 2024-04-14 19:13:16.334227 hisparc_sapphire-3.0.0/scripts/simulations/cluster_sim.py
+-rw-r--r--   0        0        0     6754 2024-04-14 19:13:10.142524 hisparc_sapphire-3.0.0/scripts/simulations/core_reconstruction.py
+-rw-r--r--   0        0        0     1523 2024-04-14 19:13:16.333853 hisparc_sapphire-3.0.0/scripts/simulations/detector_sim.py
+-rw-r--r--   0        0        0    36190 2024-04-14 19:13:16.336855 hisparc_sapphire-3.0.0/scripts/simulations/direction_reconstruction.py
+-rw-r--r--   0        0        0     4361 2024-04-14 19:13:10.140841 hisparc_sapphire-3.0.0/scripts/simulations/discrete_directions.py
+-rw-r--r--   0        0        0     1521 2024-04-14 19:13:16.333273 hisparc_sapphire-3.0.0/scripts/simulations/ldf_sim.py
+-rw-r--r--   0        0        0     2959 2024-04-14 19:26:01.691160 hisparc_sapphire-3.0.0/scripts/simulations/ldf_sim_to_model.py
+-rw-r--r--   0        0        0     3746 2024-04-14 19:13:10.145882 hisparc_sapphire-3.0.0/scripts/simulations/master.py
+-rw-r--r--   0        0        0     4548 2024-05-04 20:37:40.962598 hisparc_sapphire-3.0.0/scripts/simulations/myshowerfront.py
+-rw-r--r--   0        0        0     2563 2024-04-14 19:13:10.142391 hisparc_sapphire-3.0.0/scripts/simulations/plot_coordinate_systems.py
+-rw-r--r--   0        0        0      450 2024-04-14 19:29:25.622612 hisparc_sapphire-3.0.0/scripts/simulations/random_energy.py
+-rw-r--r--   0        0        0     2287 2024-04-14 19:13:16.332229 hisparc_sapphire-3.0.0/scripts/simulations/store_aires_data.py
+-rw-r--r--   0        0        0     1447 2024-04-14 19:13:10.139188 hisparc_sapphire-3.0.0/scripts/simulations/test_coordinate_transform.py
+-rw-r--r--   0        0        0     1817 2024-04-14 19:13:10.138692 hisparc_sapphire-3.0.0/scripts/simulations/toy_energy_densities.py
+-rw-r--r--   0        0        0     1079 2024-04-14 19:13:10.144863 hisparc_sapphire-3.0.0/scripts/simulations/utils.py
+-rw-r--r--   0        0        0        5 2022-01-17 10:27:57.426787 hisparc_sapphire-3.0.0/scripts/tests/.gitignore
+-rw-r--r--   0        0        0      180 2022-01-17 10:27:57.426848 hisparc_sapphire-3.0.0/scripts/tests/README.rst
+-rw-r--r--   0        0        0     1253 2024-04-14 19:13:10.144866 hisparc_sapphire-3.0.0/scripts/tests/check_timings.py
+-rw-r--r--   0        0        0    14807 2024-05-04 20:37:40.963152 hisparc_sapphire-3.0.0/scripts/tests/coordinate_transform_benchmarks.py
+-rw-r--r--   0        0        0      743 2024-04-14 19:13:10.138406 hisparc_sapphire-3.0.0/scripts/tests/process_events_without_traces.py
+-rw-r--r--   0        0        0      876 2024-04-14 19:13:10.137453 hisparc_sapphire-3.0.0/scripts/tests/search_coincidences.py
+-rw-r--r--   0        0        0     4871 1970-01-01 00:00:00.000000 hisparc_sapphire-3.0.0/PKG-INFO
```

### Comparing `hisparc-sapphire-2.0.0/LICENSE` & `hisparc_sapphire-3.0.0/LICENSE`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/PKG-INFO` & `hisparc_sapphire-3.0.0/README.rst`

 * *Files 20% similar despite different names*

```diff
@@ -1,45 +1,22 @@
-Metadata-Version: 2.1
-Name: hisparc-sapphire
-Version: 2.0.0
-Summary: A framework for the HiSPARC experiment
-Home-page: https://github.com/hisparc/sapphire/
-Author: David Fokkema, Arne de Laat, Tom Kooij, and others
-Author-email: davidf@nikhef.nl, arne@delaat.net
-License: GPLv3
-Keywords: HiSPARC,Nikhef,cosmic rays
-Classifier: Intended Audience :: Science/Research
-Classifier: Intended Audience :: Education
-Classifier: Operating System :: OS Independent
-Classifier: Programming Language :: Python
-Classifier: Programming Language :: Python :: 3
-Classifier: Topic :: Scientific/Engineering
-Classifier: Topic :: Education
-Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
-Provides-Extra: dev
-Provides-Extra: astropy
-License-File: LICENSE
-
 SAPPHiRE  A Framework for HiSPARC
 ===================================
 
 Introduction
 ------------
 
 .. image:: https://img.shields.io/pypi/v/hisparc-sapphire
    :target: https://pypi.python.org/pypi/hisparc-sapphire/
 .. image:: https://img.shields.io/badge/license-GPLv3-blue
    :target: https://github.com/HiSPARC/sapphire/blob/master/LICENSE
-.. image:: https://img.shields.io/github/workflow/status/HiSPARC/sapphire/Run%20tests
+.. image:: https://img.shields.io/github/actions/workflow/status/HiSPARC/sapphire/tests.yml?branch=master
    :target: https://github.com/HiSPARC/sapphire/actions
-.. image:: https://img.shields.io/codecov/c/github/HiSPARC/sapphire/master
-   :target: https://codecov.io/github/HiSPARC/sapphire
 
 SAPPHiRE is a Simulation and Analysis Program Package for `HiSPARC
-<http://www.hisparc.nl/>`_ Research and Education.  It was created in the
+<https://www.hisparc.nl/>`_ Research and Education.  It was created in the
 process of completing the PhD research of David Fokkema.  The history of this
 repository contains the complete simulation, analysis and plot generation code
 that formed the basis for David's `thesis
 <https://www.nikhef.nl/pub/services/biblio/theses_pdf/thesis_D_Fokkema.pdf>`_.
 Arne de Laat took over development of SAPPHiRE while working on his own PhD
 research.
 
@@ -55,15 +32,15 @@
 Installation
 ------------
 
 Required: Python. pip will take care of dependencies, but installing
 numpy, scipy and pytables from a python distribution is preferred. We use
 miniconda, which includes the conda package manager.
 
-First, `install conda <https://conda.pydata.org/docs/install/quick.html>`_
+First, `install conda <https://docs.conda.io/en/latest/miniconda.html>`_
 and optionally create a virtualenv::
 
     $ conda create --name hisparc python numpy scipy pytables
     $ source activate hisparc
 
 or alternatively just install the dependencies::
 
@@ -91,15 +68,15 @@
 -----------
 
 Install python (preferably using conda) as described above but clone
 the sapphire repo instead of installing using pip::
 
     $ git clone https://github.com/HiSPARC/sapphire.git
     $ cd sapphire
-    $ python setup.py develop
+    $ pip install -e .[dev]
 
 
 Version release
 ---------------
 
 Important: First check if the last commit passes the tests on GitHub Actions!
 
@@ -107,15 +84,15 @@
 create a commit for the new release with a title like 'Bump version to vX.Y.Z'
 and a message that contains a summary of the most important changes since the
 last release. Then tag the commit and push it to GitHub::
 
    $ git tag vX.Y.Z
    $ git push --tags
 
-Then upload the new version to PyPI (this requires the ``wheel`` and ``twine``
+Then upload the new version to PyPI (this requires the ``build``, ``wheel`` and ``twine``
 packages)::
 
-   $ python setup.py sdist bdist_wheel
+   $ python -m build
    $ twine upload dist/hisparc-sapphire-X.Y.Z.tar.gz
-   $ twine upload dist/hisparc_sapphire-X.Y.Z-py2.py3-none-any.whl
+   $ twine upload dist/hisparc_sapphire-X.Y.Z-py3-none-any.whl
 
 The latest version is then available from PyPI.
```

### Comparing `hisparc-sapphire-2.0.0/README.rst` & `hisparc_sapphire-3.0.0/PKG-INFO`

 * *Files 23% similar despite different names*

```diff
@@ -1,24 +1,57 @@
+Metadata-Version: 2.1
+Name: hisparc-sapphire
+Version: 3.0.0
+Summary: A framework for the HiSPARC experiment
+Keywords: cosmic rays,detectors,astrophysics,HiSPARC,Nikhef,University of Utah
+Author: David Fokkema, Tom Kooij
+Author-email: Arne de Laat <arne@delaat.net>
+Maintainer-email: Arne de Laat <arne@delaat.net>
+Requires-Python: >=3.9
+Description-Content-Type: text/x-rst
+Classifier: Intended Audience :: Education
+Classifier: Intended Audience :: Science/Research
+Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python
+Classifier: Topic :: Education
+Classifier: Topic :: Scientific/Engineering
+Requires-Dist: numpy>=1.25.2
+Requires-Dist: scipy>=1.13.0
+Requires-Dist: tables>=3.9.2
+Requires-Dist: progressbar2>=4.4.2
+Requires-Dist: astropy>=5.0.0 ; extra == "astropy"
+Requires-Dist: Sphinx ; extra == "dev"
+Requires-Dist: coverage==7.4.4 ; extra == "dev"
+Requires-Dist: ruff==0.4.1 ; extra == "dev"
+Requires-Dist: flit==3.9.0 ; extra == "publish"
+Project-URL: Documentation, https://docs.hisparc.nl/sapphire/
+Project-URL: Homepage, https://data.hisparc.nl
+Project-URL: Issues, https://github.com/HiSPARC/sapphire/issues
+Project-URL: Repository, https://github.com/hisparc/sapphire/
+Provides-Extra: astropy
+Provides-Extra: dev
+Provides-Extra: publish
+
 SAPPHiRE  A Framework for HiSPARC
 ===================================
 
 Introduction
 ------------
 
 .. image:: https://img.shields.io/pypi/v/hisparc-sapphire
    :target: https://pypi.python.org/pypi/hisparc-sapphire/
 .. image:: https://img.shields.io/badge/license-GPLv3-blue
    :target: https://github.com/HiSPARC/sapphire/blob/master/LICENSE
-.. image:: https://img.shields.io/github/workflow/status/HiSPARC/sapphire/Run%20tests
+.. image:: https://img.shields.io/github/actions/workflow/status/HiSPARC/sapphire/tests.yml?branch=master
    :target: https://github.com/HiSPARC/sapphire/actions
-.. image:: https://img.shields.io/codecov/c/github/HiSPARC/sapphire/master
-   :target: https://codecov.io/github/HiSPARC/sapphire
 
 SAPPHiRE is a Simulation and Analysis Program Package for `HiSPARC
-<http://www.hisparc.nl/>`_ Research and Education.  It was created in the
+<https://www.hisparc.nl/>`_ Research and Education.  It was created in the
 process of completing the PhD research of David Fokkema.  The history of this
 repository contains the complete simulation, analysis and plot generation code
 that formed the basis for David's `thesis
 <https://www.nikhef.nl/pub/services/biblio/theses_pdf/thesis_D_Fokkema.pdf>`_.
 Arne de Laat took over development of SAPPHiRE while working on his own PhD
 research.
 
@@ -34,15 +67,15 @@
 Installation
 ------------
 
 Required: Python. pip will take care of dependencies, but installing
 numpy, scipy and pytables from a python distribution is preferred. We use
 miniconda, which includes the conda package manager.
 
-First, `install conda <https://conda.pydata.org/docs/install/quick.html>`_
+First, `install conda <https://docs.conda.io/en/latest/miniconda.html>`_
 and optionally create a virtualenv::
 
     $ conda create --name hisparc python numpy scipy pytables
     $ source activate hisparc
 
 or alternatively just install the dependencies::
 
@@ -70,15 +103,15 @@
 -----------
 
 Install python (preferably using conda) as described above but clone
 the sapphire repo instead of installing using pip::
 
     $ git clone https://github.com/HiSPARC/sapphire.git
     $ cd sapphire
-    $ python setup.py develop
+    $ pip install -e .[dev]
 
 
 Version release
 ---------------
 
 Important: First check if the last commit passes the tests on GitHub Actions!
 
@@ -86,15 +119,16 @@
 create a commit for the new release with a title like 'Bump version to vX.Y.Z'
 and a message that contains a summary of the most important changes since the
 last release. Then tag the commit and push it to GitHub::
 
    $ git tag vX.Y.Z
    $ git push --tags
 
-Then upload the new version to PyPI (this requires the ``wheel`` and ``twine``
+Then upload the new version to PyPI (this requires the ``build``, ``wheel`` and ``twine``
 packages)::
 
-   $ python setup.py sdist bdist_wheel
+   $ python -m build
    $ twine upload dist/hisparc-sapphire-X.Y.Z.tar.gz
-   $ twine upload dist/hisparc_sapphire-X.Y.Z-py2.py3-none-any.whl
+   $ twine upload dist/hisparc_sapphire-X.Y.Z-py3-none-any.whl
 
 The latest version is then available from PyPI.
+
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/__init__.py` & `hisparc_sapphire-3.0.0/sapphire/__init__.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """Simulation and Analysis Program Package for HiSPARC Research
 
 SAPPHiRE simplifies data access, simulations and analysis for the `HiSPARC
-<http://www.hisparc.nl>`_ experiment.  It was born out of a combination of the
+<https://www.hisparc.nl>`_ experiment.  It was born out of a combination of the
 old framework and the collection of simulation and analysis scripts developed
 by David Fokkema for his PhD thesis work.  Development is ongoing, while Arne
 de Laat is working on his PhD research.
 
 The following packages and modules are included:
 
 :mod:`~sapphire.analysis`
@@ -50,14 +50,15 @@
 :mod:`~sapphire.transformations`
     transformations between different systems
 
 :mod:`~sapphire.utils`
     commonly used functions such as a progressbar
 
 """
+
 from . import (
     analysis,
     api,
     clusters,
     corsika,
     data,
     esd,
@@ -96,48 +97,65 @@
 from .esd import download_coincidences, download_data, download_lightning, load_data, quick_download
 from .simulations.groundparticles import GroundParticlesSimulation, MultipleGroundParticlesSimulation
 from .simulations.ldf import KascadeLdfSimulation, NkgLdfSimulation
 from .simulations.showerfront import ConeFrontSimulation, FlatFrontSimulation
 from .tests import run_tests
 from .transformations.celestial import zenithazimuth_to_equatorial
 from .transformations.clock import datetime_to_gps, gps_to_datetime
-from .version import __version__  # noqa
 
-__all__ = ['analysis',
-           'api',
-           'clusters',
-           'corsika',
-           'data',
-           'esd',
-           'kascade',
-           'publicdb',
-           'qsub',
-           'simulations',
-           'storage',
-           'time_util',
-           'transformations',
-           'utils',
-           'determine_detector_timing_offsets',
-           'DetermineStationTimingOffsets',
-           'CoincidenceQuery',
-           'Coincidences', 'CoincidencesESD',
-           'FindMostProbableValueInSpectrum',
-           'ProcessEvents', 'ProcessEventsFromSource',
-           'ProcessEventsFromSourceWithTriggerOffset',
-           'ProcessWeather', 'ProcessWeatherFromSource',
-           'ProcessSingles', 'ProcessSinglesFromSource',
-           'TraceObservables', 'MeanFilter', 'DataReduction',
-           'ReconstructESDEvents', 'ReconstructESDEventsFromSource',
-           'ReconstructESDCoincidences',
-           'ProcessTimeDeltas',
-           'Network', 'Station',
-           'HiSPARCStations', 'HiSPARCNetwork', 'ScienceParkCluster',
-           'CorsikaQuery',
-           'quick_download', 'load_data', 'download_data',
-           'download_lightning', 'download_coincidences',
-           'GroundParticlesSimulation', 'MultipleGroundParticlesSimulation',
-           'KascadeLdfSimulation', 'NkgLdfSimulation',
-           'FlatFrontSimulation', 'ConeFrontSimulation',
-           'run_tests',
-           'zenithazimuth_to_equatorial',
-           'gps_to_datetime', 'datetime_to_gps'
-           ]
+__all__ = [
+    'analysis',
+    'api',
+    'clusters',
+    'corsika',
+    'data',
+    'esd',
+    'kascade',
+    'publicdb',
+    'qsub',
+    'simulations',
+    'storage',
+    'time_util',
+    'transformations',
+    'utils',
+    'determine_detector_timing_offsets',
+    'DetermineStationTimingOffsets',
+    'CoincidenceQuery',
+    'Coincidences',
+    'CoincidencesESD',
+    'FindMostProbableValueInSpectrum',
+    'ProcessEvents',
+    'ProcessEventsFromSource',
+    'ProcessEventsFromSourceWithTriggerOffset',
+    'ProcessWeather',
+    'ProcessWeatherFromSource',
+    'ProcessSingles',
+    'ProcessSinglesFromSource',
+    'TraceObservables',
+    'MeanFilter',
+    'DataReduction',
+    'ReconstructESDEvents',
+    'ReconstructESDEventsFromSource',
+    'ReconstructESDCoincidences',
+    'ProcessTimeDeltas',
+    'Network',
+    'Station',
+    'HiSPARCStations',
+    'HiSPARCNetwork',
+    'ScienceParkCluster',
+    'CorsikaQuery',
+    'quick_download',
+    'load_data',
+    'download_data',
+    'download_lightning',
+    'download_coincidences',
+    'GroundParticlesSimulation',
+    'MultipleGroundParticlesSimulation',
+    'KascadeLdfSimulation',
+    'NkgLdfSimulation',
+    'FlatFrontSimulation',
+    'ConeFrontSimulation',
+    'run_tests',
+    'zenithazimuth_to_equatorial',
+    'gps_to_datetime',
+    'datetime_to_gps',
+]
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/__init__.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -48,14 +48,15 @@
 :mod:`~sapphire.analysis.reconstructions`
     perform shower reconstructions
 
 :mod:`~sapphire.analysis.time_deltas`
     determine time deltas for station pairs
 
 """
+
 from . import (
     calibration,
     coincidence_queries,
     coincidences,
     core_reconstruction,
     direction_reconstruction,
     event_utils,
@@ -63,19 +64,21 @@
     landau,
     process_events,
     process_traces,
     reconstructions,
     time_deltas,
 )
 
-__all__ = ['calibration',
-           'coincidence_queries',
-           'coincidences',
-           'core_reconstruction',
-           'direction_reconstruction',
-           'event_utils',
-           'find_mpv',
-           'landau',
-           'process_events',
-           'process_traces',
-           'reconstructions',
-           'time_deltas']
+__all__ = [
+    'calibration',
+    'coincidence_queries',
+    'coincidences',
+    'core_reconstruction',
+    'direction_reconstruction',
+    'event_utils',
+    'find_mpv',
+    'landau',
+    'process_events',
+    'process_traces',
+    'reconstructions',
+    'time_deltas',
+]
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/calibration.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/calibration.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-""" Determine calibration values for data
+"""Determine calibration values for data
 
 This module can be used to determine calibration values from data.
 
 Determine timing offsets for detectors and stations to correct arrival times.
 Determine the PMT response curve to correct the detected number of MIPs.
 
 """
+
 from datetime import datetime, timedelta
 from itertools import chain, combinations, tee
 
 from numpy import abs, arange, histogram, isnan, linspace, nan, percentile, sqrt, std, sum
 from scipy.optimize import curve_fit
 
 from ..api import Station
@@ -35,32 +36,32 @@
     filters = []
     if station is not None:
         n_detectors = len(station.detectors)
         station.cluster.set_timestamp(events[0]['timestamp'])
         z = [d.get_coordinates()[2] for d in station.detectors]
     else:
         n_detectors = 4
-        z = [0., 0., 0., 0.]
+        z = [0.0, 0.0, 0.0, 0.0]
 
-    for id in range(n_detectors):
-        t.append(events.col('t%d' % (id + 1)))
-        filters.append((events.col('n%d' % (id + 1)) > 0.3) & (t[id] >= 0.))
+    for detector_id in range(n_detectors):
+        t.append(events.col(f't{detector_id + 1}'))
+        filters.append((events.col('n%d' % (detector_id + 1)) > 0.3) & (t[detector_id] >= 0.0))
 
     if n_detectors == 2:
         ref_id = 1
     else:
         ref_id = determine_best_reference(filters)
 
-    for id in range(n_detectors):
-        if id == ref_id:
-            offsets[id] = 0.
+    for detector_id in range(n_detectors):
+        if detector_id == ref_id:
+            offsets[detector_id] = 0.0
             continue
-        dt = (t[id] - t[ref_id]).compress(filters[id] & filters[ref_id])
-        dz = z[id] - z[ref_id]
-        offsets[id], _ = determine_detector_timing_offset(dt, dz)
+        dt = (t[detector_id] - t[ref_id]).compress(filters[detector_id] & filters[ref_id])
+        dz = z[detector_id] - z[ref_id]
+        offsets[detector_id], _ = determine_detector_timing_offset(dt, dz)
 
     # If all except reference are nan, make reference nan.
     if sum(isnan(offsets)) == 3:
         offsets = [nan, nan, nan, nan]
 
     # Try to make detector 2 the reference point, if it is not nan.
     if not isnan(offsets[1]):
@@ -97,101 +98,107 @@
     """Determine the timing offsets between stations"""
 
     # Maximum distance between station pairs that are included in analysis
     MAX_DISTANCE = 1000  # m
     # Minimum number of timedeltas required to attempt a fit
     MIN_LEN_DT = 200
 
-    def __init__(self, stations=None, data=None, progress=False,
-                 force_stale=False,
-                 time_deltas_group='/coincidences/time_deltas'):
+    def __init__(
+        self,
+        stations=None,
+        data=None,
+        progress=False,
+        force_stale=False,
+        time_deltas_group='/coincidences/time_deltas',
+    ):
         """Initialize the class
 
         :param stations: list of stations for which to determine offsets.
         :param data: the PyTables datafile with timedelta tables.
         :param progress: if True show progressbar when determining offsets.
         :param force_stale: if true: do not get network information from API.
         :param time_deltas_group: path to the time deltas group.
 
         """
         self.data = data
         self.progress = progress
         self.force_stale = force_stale
         self.time_deltas_group = time_deltas_group
         if stations is not None:
-            self.cluster = HiSPARCStations(stations, skip_missing=True,
-                                           force_stale=self.force_stale)
+            self.cluster = HiSPARCStations(stations, skip_missing=True, force_stale=self.force_stale)
         else:
             self.cluster = HiSPARCNetwork(force_stale=self.force_stale)
 
     def read_dt(self, station, ref_station, start, end):
         """Read timedeltas from HDF5 file"""
 
         pair = (ref_station, station)
         table_path = self.time_deltas_group + '/station_%d/station_%d' % pair
         table = self.data.get_node(table_path, 'time_deltas')
-        ts0 = datetime_to_gps(start)  # noqa
-        ts1 = datetime_to_gps(end)  # noqa
-        return table.read_where('(timestamp >= ts0) & (timestamp < ts1)',
-                                field='delta')
+        ts0 = datetime_to_gps(start)  # noqa: F841
+        ts1 = datetime_to_gps(end)  # noqa: F841
+        return table.read_where('(timestamp >= ts0) & (timestamp < ts1)', field='delta')
 
     @memoize
     def _get_gps_timestamps(self, station):
         """Get timestamps of station gps changes"""
-        return Station(station,
-                       force_stale=self.force_stale).gps_locations['timestamp']
+        return Station(station, force_stale=self.force_stale).gps_locations['timestamp']
 
     @memoize
     def _get_electronics_timestamps(self, station):
         """Get timestamps of station electronics (hardware) changes"""
-        return Station(station,
-                       force_stale=self.force_stale).electronics['timestamp']
+        return Station(station, force_stale=self.force_stale).electronics['timestamp']
 
     def _get_cuts(self, station, ref_station):
         """Get cuts for determination of offsets
 
         Get a list of events (new gps location, new electronics)
         that (may) cause a large shift in station timing offset
         :param station: station number
         :param ref_station: reference station number
         :return: list of datetime objects
 
         """
-        cuts = {self._datetime(gps_to_datetime(ts))
-                for ts in chain(self._get_gps_timestamps(station),
-                                self._get_gps_timestamps(ref_station),
-                                self._get_electronics_timestamps(station),
-                                self._get_electronics_timestamps(ref_station))}
+        cuts = {
+            self._datetime(gps_to_datetime(ts))
+            for ts in chain(
+                self._get_gps_timestamps(station),
+                self._get_gps_timestamps(ref_station),
+                self._get_electronics_timestamps(station),
+                self._get_electronics_timestamps(ref_station),
+            )
+        }
         today = self._datetime(datetime.now())
-        cuts = sorted(list(cuts) + [today])
+        cuts = sorted([*list(cuts), today])
         return cuts
 
     @memoize
     def _get_r_dz(self, date, station, ref_station):
         """Determine r and dz at date
 
         :param date: date for which to get the distances.
         :param station,ref_station: station numbers of the station pair.
         :return: tuple containing the horizontal and vertical distances.
 
         """
         self.cluster.set_timestamp(datetime_to_gps(date))
         r, _, dz = self.cluster.calc_rphiz_for_stations(
             self.cluster.get_station(ref_station).station_id,
-            self.cluster.get_station(station).station_id)
+            self.cluster.get_station(station).station_id,
+        )
         return r, dz
 
     def _determine_interval(self, r):
         """Determine interval (number of days) in which to fit timedelta's
 
         :param r: distrance between stations (m).
         :return: number of days in interval.
 
         """
-        return max(int(r ** 1.2 / 10), 7)
+        return max(int(r**1.2 / 10), 7)
 
     def _get_left_and_right_bounds(self, cuts, date, days):
         """Determine left and right bounds between cuts
 
         Offsets are determined per day, so intervals are based on days.
         Cuts are excluded. Start date (left side bound) is the day
         after a cut, end date (right side bound) is the day before a cut.
@@ -257,27 +264,25 @@
         :param date: date for which to determine offset as datetime.date.
         :param station: station number.
         :param ref_station: reference station number.
         :return: station offset and error.
 
         """
         date = self._datetime(date)
-        left, right = self.determine_first_and_last_date(date, station,
-                                                         ref_station)
+        left, right = self.determine_first_and_last_date(date, station, ref_station)
         r, dz = self._get_r_dz(date, station, ref_station)
         dt = self.read_dt(station, ref_station, left, right)
         if len(dt) < self.MIN_LEN_DT:
             s_off, error = nan, nan
         else:
             s_off, error = determine_station_timing_offset(dt, dz)
 
         return s_off, error
 
-    def determine_station_timing_offsets(self, station, ref_station,
-                                         start=None, end=None):
+    def determine_station_timing_offsets(self, station, ref_station, start=None, end=None):
         """Determine the timing offsets between a station pair
 
         :param station: station number.
         :param ref_station: reference station number.
         :param start: datetime.date object.
         :param end: datetime.date object.
         :return: list of station offsets as tuple (timestamp, offset, error).
@@ -287,35 +292,32 @@
             cuts = self._get_cuts(station, ref_station)
             start = self._datetime(cuts[0])
         if end is None:
             end = self._datetime(datetime.now())
 
         offsets = []
         length = (end - start).days
-        for date, _ in pbar(datetime_range(start, end), show=self.progress,
-                            length=length):
+        for date, _ in pbar(datetime_range(start, end), show=self.progress, length=length):
             ts0 = datetime_to_gps(date)
-            s_off, error = self.determine_station_timing_offset(date, station,
-                                                                ref_station)
+            s_off, error = self.determine_station_timing_offset(date, station, ref_station)
             offsets.append((ts0, s_off, error))
         return offsets
 
     def determine_station_timing_offsets_for_date(self, date):
         """Determine the timing offsets between a station pair
 
         :param date: date for which to determine offsets as datetime.date.
         :return: list of station offsets as tuple
                  (station, ref_station, offset, error).
 
         """
         station_pairs = self.get_station_pairs_within_max_distance(date)
         offsets = []
         for station, ref_station in station_pairs:
-            s_off, error = self.determine_station_timing_offset(date, station,
-                                                                ref_station)
+            s_off, error = self.determine_station_timing_offset(date, station, ref_station)
             offsets.append((station, ref_station, s_off, error))
         return offsets
 
     def get_station_pairs_within_max_distance(self, date=None):
         """Iterator that yields stations pairs that are close to each other"""
 
         if date is not None:
@@ -360,16 +362,15 @@
     :return: mean of a gaussian fit to the data and the error of the mean.
 
     """
     y, bins = histogram(dt, bins=bins)
     x = (bins[:-1] + bins[1:]) / 2
     sigma = sqrt(y + 1)
     try:
-        popt, pcov = curve_fit(gauss, x, y, p0=(len(dt), 0., std(dt)),
-                               sigma=sigma, absolute_sigma=False)
+        popt, pcov = curve_fit(gauss, x, y, p0=(len(dt), 0.0, std(dt)), sigma=sigma, absolute_sigma=False)
         offset = popt[1]
         width = popt[2]
         offset_error = width / sqrt(sum(y))
     except (RuntimeError, TypeError):
         offset, offset_error = nan, nan
     return offset, offset_error
 
@@ -382,18 +383,17 @@
     :return: index for the detector that has most rows in common with
              the other detectors.
 
     """
     lengths = []
     ids = range(len(filters))
 
-    for id in ids:
-        idx = [j for j in ids if j != id]
-        lengths.append(sum(filters[id] & (filters[idx[0]] |
-                                          filters[idx[1]] | filters[idx[2]])))
+    for detector_id in ids:
+        idx = [j for j in ids if j != detector_id]
+        lengths.append(sum(filters[detector_id] & (filters[idx[0]] | filters[idx[1]] | filters[idx[2]])))
     return lengths.index(max(lengths))
 
 
 def datetime_range(start, end, step=1):
     """Generator that splits a date range in (almost) equal intervals
 
     The yielded interval lengths are integer days
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/coincidence_queries.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/coincidence_queries.py`

 * *Files 1% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 
 import tables
 
 from .. import api
 
 
 class CoincidenceQuery:
-
     """Perform queries on an ESD file where coincidences have been analysed.
 
     Functions in this class build and perform queries to easily filter
     coincidences based on station participation and station
     organization. This assumes coincidences have been analysed using
     :class:`~sapphire.analysis.coincidences.CoincidencesESD`.
 
@@ -43,31 +42,28 @@
         :param coincidence_group: path to the coincidences group.
 
         """
         if not isinstance(data, tables.File):
             self.data = tables.open_file(data, 'r')
         else:
             self.data = data
-        self.coincidences = self.data.get_node(coincidence_group,
-                                               'coincidences')
+        self.coincidences = self.data.get_node(coincidence_group, 'coincidences')
         self.c_index = self.data.get_node(coincidence_group, 'c_index')
         self.s_index = self.data.get_node(coincidence_group, 's_index')
         self.s_nodes = []
         for s_path in self.s_index:
             try:
                 self.s_nodes.append(self.data.get_node(s_path.decode('utf-8')))
             except tables.NoSuchNodeError:
                 self.s_nodes.append(None)
         re_number = re.compile('[0-9]+$')
-        self.s_numbers = [int(re_number.search(s_path.decode('utf-8')).group())
-                          for s_path in self.s_index]
+        self.s_numbers = [int(re_number.search(s_path.decode('utf-8')).group()) for s_path in self.s_index]
 
         try:
-            self.reconstructions = self.data.get_node(coincidence_group,
-                                                      'reconstructions')
+            self.reconstructions = self.data.get_node(coincidence_group, 'reconstructions')
             self.reconstructed = True
         except tables.NoSuchNodeError:
             self.reconstructed = False
 
     def finish(self):
         """Clean-up after using
 
@@ -133,16 +129,15 @@
         :return: coincidences matching the query.
 
         """
         s_columns = self._get_allowed_s_columns(stations)
         if len(s_columns) < n:
             # No combinations possible because there are to few stations
             return []
-        s_combinations = ['(%s)' % (' & '.join(combo))
-                          for combo in itertools.combinations(s_columns, n)]
+        s_combinations = ['(%s)' % (' & '.join(combo)) for combo in itertools.combinations(s_columns, n)]
         query = '(%s)' % ' | '.join(s_combinations)
         query = self._add_timestamp_filter(query, start, stop)
         filtered_coincidences = self.perform_query(query, iterator)
         return filtered_coincidences
 
     def timerange(self, start, stop, iterator=False):
         """Query based on timestamps
@@ -218,16 +213,15 @@
         """
         events = []
         c_idx = self.c_index[coincidence['id']]
         for s_idx, e_idx in c_idx:
             station_number = self.s_numbers[s_idx]
             s_node = self.s_nodes[s_idx]
             if s_node is None:
-                warnings.warn('Missing station group for station id %d. '
-                              'Events from it are excluded.' % s_idx)
+                warnings.warn('Missing station group for station id %d. Events from it are excluded.' % s_idx)
                 continue
             events.append((station_number, s_node.events[e_idx]))
         return events
 
     def _get_reconstructions(self, coincidence):
         """Get event reconstructions belonging to a coincidence
 
@@ -238,16 +232,15 @@
         """
         reconstructions = []
         c_idx = self.c_index[coincidence['id']]
         for s_idx, e_idx in c_idx:
             station_number = self.s_numbers[s_idx]
             s_node = self.s_nodes[s_idx]
             if s_node is None:
-                warnings.warn(f'Missing station group for station id {s_idx}.'
-                              'Reconstructions from it are excluded.')
+                warnings.warn(f'Missing station group for station id {s_idx}. Reconstructions from it are excluded.')
                 continue
             rec_table = s_node.reconstructions
             reconstructions.append((station_number, rec_table[e_idx]))
         return reconstructions
 
     def _get_reconstruction(self, coincidence):
         """Get coincidence reconstruction belonging to a coincidence
@@ -256,80 +249,74 @@
         :return: reconstructed coincidence.
 
         """
         if self.reconstructed:
             reconstruction = self.reconstructions[coincidence['id']]
             return reconstruction
         else:
-            raise Exception('Coincidences are not (properly) reconstructed.'
-                            'Perform reconstructions and reinitialize this '
-                            'class.')
+            raise RuntimeError(
+                'Coincidences are not (properly) reconstructed.'
+                'Perform reconstructions and reinitialize this '
+                'class.',
+            )
 
     def all_events(self, coincidences, n=0):
         """Get all events for the given coincidences.
 
         :param coincidences: list of coincidence rows.
         :param n: minimum number of events per coincidence.
         :return: list of events for each coincidence.
 
         """
-        coincidence_events = (self._get_events(coincidence)
-                              for coincidence in coincidences)
+        coincidence_events = (self._get_events(coincidence) for coincidence in coincidences)
         return self.minimum_events_for_coincidence(coincidence_events, n)
 
     def all_reconstructions(self, coincidences, n=0):
         """Get all reconstructed events for the given coincidences.
 
         :param coincidences: list of coincidence rows.
         :param n: minimum number of events per coincidence.
         :return: list of reconstructed events for each coincidence.
 
         """
-        coincidence_recs = (self._get_reconstructions(coincidence)
-                            for coincidence in coincidences)
+        coincidence_recs = (self._get_reconstructions(coincidence) for coincidence in coincidences)
         return self.minimum_events_for_coincidence(coincidence_recs, n)
 
     def minimum_events_for_coincidence(self, coincidences_events, n=2):
         """Filter coincidences to only include those with at least n events.
 
         :param coincidences_events: list of events for each coincidence.
         :param n: minimum number of events per coincidence.
 
         """
-        filtered_coincidences = (coincidence
-                                 for coincidence in coincidences_events
-                                 if len(coincidence) >= n)
+        filtered_coincidences = (coincidence for coincidence in coincidences_events if len(coincidence) >= n)
         return filtered_coincidences
 
     def events_from_stations(self, coincidences, stations, n=2):
         """Only get events for specific stations for coincidences.
 
         :param coincidences: list of coincidence rows.
         :param stations: list of station numbers to filter events for.
         :return: list of filtered events for each coincidence.
 
         """
-        events_iterator = (self._get_events(coincidence)
-                           for coincidence in coincidences)
-        coincidences_events = (self._events_from_stations(events, stations)
-                               for events in events_iterator)
+        events_iterator = (self._get_events(coincidence) for coincidence in coincidences)
+        coincidences_events = (self._events_from_stations(events, stations) for events in events_iterator)
         return self.minimum_events_for_coincidence(coincidences_events, n)
 
     def reconstructions_from_stations(self, coincidences, stations, n=2):
         """Only get reconstructions for specific stations for coincidences.
 
         :param coincidences: list of coincidence rows.
         :param stations: list of station numbers to filter events for.
         :return: list of filtered reconstructed events for each coincidence.
 
         """
-        reconstructions_iterator = (self._get_reconstructions(coincidence)
-                                    for coincidence in coincidences)
-        coincidences_recs = (self._events_from_stations(recs, stations)
-                             for recs in reconstructions_iterator)
+        reconstructions_iterator = (self._get_reconstructions(coincidence) for coincidence in coincidences)
+        coincidences_recs = (self._events_from_stations(recs, stations) for recs in reconstructions_iterator)
         return self.minimum_events_for_coincidence(coincidences_recs, n)
 
     def _events_from_stations(self, events, stations):
         """Get only events from the chosen stations
 
         :param events: list of tuples containing a station number and an
                        event.
@@ -366,14 +353,10 @@
         stations = network.station_numbers(cluster=cluster)
         filtered_events = self.events_from_stations(coincidences, stations, n)
 
         return filtered_events
 
     def __repr__(self):
         try:
-            return "{}({!r}, {!r})".format(
-                self.__class__.__name__,
-                self.data.filename,
-                self.coincidences._v_parent._v_pathname
-            )
+            return f'{self.__class__.__name__}({self.data.filename!r}, {self.coincidences._v_parent._v_pathname!r})'
         except AttributeError:
-            return f"<finished {self.__class__.__name__}>"
+            return f'<finished {self.__class__.__name__}>'
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/coincidences.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/coincidences.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,39 +1,40 @@
-""" Search for coincidences between HiSPARC stations
+"""Search for coincidences between HiSPARC stations
 
-    This module can be used to search for coincidences between several
-    HiSPARC stations. To skip this and directly download coincidences
-    use :func:`~sapphire.esd.download_coincidences`, this is slightly
-    less flexible because you can not choose the coincidence window.
+This module can be used to search for coincidences between several
+HiSPARC stations. To skip this and directly download coincidences
+use :func:`~sapphire.esd.download_coincidences`, this is slightly
+less flexible because you can not choose the coincidence window.
 
-    For regular usage, download events from the ESD and use the
-    :class:`CoincidencesESD` class. Example usage::
+For regular usage, download events from the ESD and use the
+:class:`CoincidencesESD` class. Example usage::
 
-        import datetime
+    import datetime
 
-        import tables
+    import tables
 
-        from sapphire import CoincidencesESD, download_data
+    from sapphire import CoincidencesESD, download_data
 
-        STATIONS = [501, 503, 506]
-        START = datetime.datetime(2013, 1, 1)
-        END = datetime.datetime(2013, 1, 2)
+    STATIONS = [501, 503, 506]
+    START = datetime.datetime(2013, 1, 1)
+    END = datetime.datetime(2013, 1, 2)
 
 
-        if __name__ == '__main__':
-            station_groups = ['/s%d' % u for u in STATIONS]
+    if __name__ == '__main__':
+        station_groups = ['/s%d' % u for u in STATIONS]
 
-            data = tables.open_file('data.h5', 'w')
-            for station, group in zip(STATIONS, station_groups):
-                download_data(data, group, station, START, END)
+        data = tables.open_file('data.h5', 'w')
+        for station, group in zip(STATIONS, station_groups):
+            download_data(data, group, station, START, END)
 
-            coin = CoincidencesESD(data, '/coincidences', station_groups)
-            coin.search_and_store_coincidences()
+        coin = CoincidencesESD(data, '/coincidences', station_groups)
+        coin.search_and_store_coincidences()
 
 """
+
 import os.path
 
 import numpy as np
 import tables
 
 from progressbar import ETA, Bar, Percentage, ProgressBar
 
@@ -108,16 +109,15 @@
 
     The ``event`` is one of the source events, processed to determine particle
     arrival times from the raw traces (if available). It has a
     ``station_id`` attribute which is an index into ``station_groups``.
 
     """
 
-    def __init__(self, data, coincidence_group, station_groups,
-                 overwrite=False, progress=True):
+    def __init__(self, data, coincidence_group, station_groups, overwrite=False, progress=True):
         """Initialize the class.
 
         :param data: either a PyTables file or path to a HDF5 file.
         :param coincidence_group: the destination group. If None the results
             can not be stored, but coincidences can still be searched for.
         :param station_groups: a list of groups containing the station data.
         :param overwrite: if True overwrite a previous coincidences group.
@@ -135,20 +135,19 @@
             self.data = data
             self.opened = False
         if coincidence_group is not None:
             if coincidence_group in self.data:
                 if overwrite:
                     self.data.remove_node(coincidence_group, recursive=True)
                 else:
-                    raise RuntimeError("Group %s already exists in datafile, "
-                                       "and overwrite is False" %
-                                       coincidence_group)
+                    raise RuntimeError(
+                        'Group %s already exists in datafile, and overwrite is False' % coincidence_group,
+                    )
             head, tail = os.path.split(coincidence_group)
-            self.coincidence_group = self.data.create_group(head, tail,
-                                                            createparents=True)
+            self.coincidence_group = self.data.create_group(head, tail, createparents=True)
         self.station_groups = station_groups
 
         self.trig_threshold = 0.5
         self.overwrite = overwrite
         self.progress = progress
 
     def __enter__(self):
@@ -159,15 +158,15 @@
 
         Only close PyTables file if it was opened in the init.
 
         """
         if self.opened:
             self.data.close()
 
-    def search_and_store_coincidences(self, window=10000):
+    def search_and_store_coincidences(self, window=10_000):
         """Search, process and store coincidences.
 
         This is a semi-automatic method to search for coincidences,
         process the events making up the coincidences and then store the
         results in the coincidences group.
 
         If you want to make use of non-default parameters like time
@@ -175,15 +174,15 @@
         the individual methods.  See the class docstring.
 
         """
         self.search_coincidences(window=window)
         self.process_events()
         self.store_coincidences()
 
-    def search_coincidences(self, window=10000, shifts=None, limit=None):
+    def search_coincidences(self, window=10_000, shifts=None, limit=None):
         """Search for coincidences.
 
         Search all data in the station_groups for coincidences, and store
         rudimentary coincidence data in the coincidences group.  This data
         might be useful, but is very basic.  You can call the
         :meth:`store_coincidences` method to store the coincidences in an
         easier format in the coincidences group.
@@ -204,22 +203,18 @@
             can be useful if a station has a misconfigured GPS clock.
             Expects a list of shifts, one for each station, in seconds.
             Use 'None' for no shift.
         :param limit: optionally limit the search for this number of
             events.
 
         """
-        c_index, timestamps = \
-            self._search_coincidences(window, shifts, limit)
+        c_index, timestamps = self._search_coincidences(window, shifts, limit)
         timestamps = np.array(timestamps, dtype=np.uint64)
-        self.data.create_array(self.coincidence_group, '_src_timestamps',
-                               timestamps)
-        src_c_index = self.data.create_vlarray(self.coincidence_group,
-                                               '_src_c_index',
-                                               tables.UInt32Atom())
+        self.data.create_array(self.coincidence_group, '_src_timestamps', timestamps)
+        src_c_index = self.data.create_vlarray(self.coincidence_group, '_src_c_index', tables.UInt32Atom())
         for coincidence in c_index:
             src_c_index.append(coincidence)
 
     def process_events(self, overwrite=None):
         """Process events using :mod:`~sapphire.analysis.process_events`
 
         Events making up the coincidences are processed to obtain
@@ -234,61 +229,50 @@
 
         c_index = self.coincidence_group._src_c_index.read()
         timestamps = self.coincidence_group._src_timestamps.read()
 
         if len(c_index) == 0:
             return
 
-        selected_timestamps = []
-        for coincidence in c_index:
-            for event in coincidence:
-                selected_timestamps.append(timestamps[event])
+        selected_timestamps = [timestamps[event] for coincidence in c_index for event in coincidence]
         full_index = np.array(selected_timestamps)
 
         for station_id, station_group in enumerate(self.station_groups):
             station_group = self.data.get_node(station_group)
-            selected = full_index.compress(full_index[:, 1] == station_id,
-                                           axis=0)
+            selected = full_index.compress(full_index[:, 1] == station_id, axis=0)
             index = selected[:, 2]
 
             if 'blobs' in station_group:
                 if self.progress:
-                    print("Processing coincidence events with traces")
+                    print('Processing coincidence events with traces')
                 processor = process_events.ProcessIndexedEventsWithLINT
             else:
                 if self.progress:
-                    print("Processing coincidence events without traces")
+                    print('Processing coincidence events without traces')
                 processor = process_events.ProcessIndexedEventsWithoutTraces
 
-            process = processor(self.data, station_group, index,
-                                progress=self.progress)
+            process = processor(self.data, station_group, index, progress=self.progress)
             process.process_and_store_results(overwrite=overwrite)
 
     def store_coincidences(self):
         """Store the previously found coincidences.
 
         After you have searched for coincidences, you can store the
         more user-friendly results in the coincidences group using this
         method.
 
         """
         self.c_index = []
-        self.coincidences = self.data.create_table(self.coincidence_group,
-                                                   'coincidences',
-                                                   storage.Coincidence)
-        self.observables = self.data.create_table(self.coincidence_group,
-                                                  'observables',
-                                                  storage.EventObservables)
+        self.coincidences = self.data.create_table(self.coincidence_group, 'coincidences', storage.Coincidence)
+        self.observables = self.data.create_table(self.coincidence_group, 'observables', storage.EventObservables)
 
-        for coincidence in pbar(self.coincidence_group._src_c_index,
-                                show=self.progress):
+        for coincidence in pbar(self.coincidence_group._src_c_index, show=self.progress):
             self._store_coincidence(coincidence)
 
-        c_index = self.data.create_vlarray(self.coincidence_group, 'c_index',
-                                           tables.UInt32Col())
+        c_index = self.data.create_vlarray(self.coincidence_group, 'c_index', tables.UInt32Col())
         for coincidence in self.c_index:
             c_index.append(coincidence)
         c_index.flush()
         self.c_index = c_index
 
     def _store_coincidence(self, coincidence):
         """Store a single coincidence in the coincidence group.
@@ -307,49 +291,44 @@
         for index in coincidence:
             event_desc = self.coincidence_group._src_timestamps[index]
             station_id = event_desc[1]
             event_index = int(event_desc[2])
 
             group = self.data.get_node(self.station_groups[station_id])
             event = group.events[event_index]
-            idx = self._store_event_in_observables(event, coincidence_id,
-                                                   station_id)
+            idx = self._store_event_in_observables(event, coincidence_id, station_id)
             observables_idx.append(idx)
-            timestamps.append((event['ext_timestamp'], event['timestamp'],
-                               event['nanoseconds']))
+            timestamps.append((event['ext_timestamp'], event['timestamp'], event['nanoseconds']))
 
         first_timestamp = sorted(timestamps)[0]
-        row['ext_timestamp'], row['timestamp'], row['nanoseconds'] = \
-            first_timestamp
+        row['ext_timestamp'], row['timestamp'], row['nanoseconds'] = first_timestamp
         row.append()
         self.c_index.append(observables_idx)
         self.coincidences.flush()
 
-    def _store_event_in_observables(self, event, coincidence_id,
-                                    station_id):
+    def _store_event_in_observables(self, event, coincidence_id, station_id):
         """Store a single event in the observables table."""
 
         row = self.observables.row
         event_id = len(self.observables)
         row['id'] = event_id
 
         row['station_id'] = station_id
-        for key in ('timestamp', 'nanoseconds', 'ext_timestamp',
-                    'n1', 'n2', 'n3', 'n4', 't1', 't2', 't3', 't4'):
+        for key in ('timestamp', 'nanoseconds', 'ext_timestamp', 'n1', 'n2', 'n3', 'n4', 't1', 't2', 't3', 't4'):
             row[key] = event[key]
 
         signals = [event[key] for key in ('n1', 'n2', 'n3', 'n4')]
         n = sum(1 if u > self.trig_threshold else 0 for u in signals)
         row['N'] = n
 
         row.append()
         self.observables.flush()
         return event_id
 
-    def _search_coincidences(self, window=10000, shifts=None, limit=None):
+    def _search_coincidences(self, window=10_000, shifts=None, limit=None):
         """Search for coincidences
 
         Search for coincidences in a set of PyTables event tables, optionally
         shifting the data in time.  This is necessary when one wants to
         compare the timestamps of stations who use a different time (as in
         GPS, UTC or local time).  This function searches for events which
         occured almost at the same time and thus might be the result of an
@@ -372,16 +351,15 @@
 
         """
         # get the 'events' tables from the groups or groupnames
         event_tables = []
         for station_group in self.station_groups:
             station_group = self.data.get_node(station_group)
             if 'events' in station_group:
-                event_tables.append(self.data.get_node(station_group,
-                                                       'events'))
+                event_tables.append(self.data.get_node(station_group, 'events'))
 
         timestamps = self._retrieve_timestamps(event_tables, shifts, limit)
         coincidences = self._do_search_coincidences(timestamps, window)
 
         return coincidences, timestamps
 
     def _retrieve_timestamps(self, event_tables, shifts=None, limit=None):
@@ -403,28 +381,25 @@
             station which measured the event, and finally an index of the
             event into the station's event table.
 
         """
         # calculate the shifts in nanoseconds and cast them to int.
         # (prevent upcasting timestamps to float64 further on)
         if shifts is not None:
-            shifts = [int(shift * 1e9) if shift is not None else shift
-                      for shift in shifts]
+            shifts = [int(shift * 1_000_000_000) if shift is not None else shift for shift in shifts]
 
         timestamps = []
         for s_id, event_table in enumerate(event_tables):
-            ts = [(x, s_id, j) for j, x in
-                  enumerate(event_table.col('ext_timestamp')[:limit])]
+            ts = [(x, s_id, j) for j, x in enumerate(event_table.col('ext_timestamp')[:limit])]
             try:
                 # shift data. carefully avoid upcasting (we're adding two
                 # ints, which is an int, and casting that back to uint64. if
                 # we're not careful, an intermediate value will be a float64,
                 # which doesn't hold the precision to store nanoseconds.
-                ts = [(np.uint64(int(x) + shifts[i]), i, j)
-                      for x, i, j in ts]
+                ts = [(np.uint64(int(x) + shifts[i]), i, j) for x, i, j in ts]
             except (TypeError, IndexError):
                 # shift is None or doesn't exist
                 pass
             timestamps.extend(ts)
 
         # sort the timestamps
         timestamps.sort()
@@ -451,19 +426,17 @@
         """
         coincidences = []
 
         # traverse all timestamps
         prev_coincidence = []
 
         if self.progress and len(timestamps):
-            pbar = ProgressBar(max_value=len(timestamps),
-                               widgets=[Percentage(), Bar(), ETA()]).start()
+            pbar = ProgressBar(max_value=len(timestamps), widgets=[Percentage(), Bar(), ETA()]).start()
 
         for i in range(len(timestamps)):
-
             # build coincidence, starting with the current timestamp
             c = [i]
             t0 = timestamps[i][0]
 
             # traverse the rest of the timestamps
             for j in range(i + 1, len(timestamps)):
                 # if a timestamp is within the coincidence window, add it
@@ -472,16 +445,15 @@
                 else:
                     # coincidence window has passed, break for-loop
                     break
 
             # if we have more than one event in the coincidence, save it
             if len(c) > 1:
                 # is this coincidence part of the previous coincidence?
-                is_part_of_prev = np.array([u in prev_coincidence
-                                            for u in c]).all()
+                is_part_of_prev = np.array([u in prev_coincidence for u in c]).all()
                 if not is_part_of_prev:
                     # no, so it's a new one
                     coincidences.append(c)
                     prev_coincidence = c
 
             if self.progress and not i % 5000:
                 pbar.update(i)
@@ -489,24 +461,33 @@
         if self.progress and len(timestamps):
             pbar.finish()
 
         return coincidences
 
     def __repr__(self):
         if not self.data.isopen:
-            return "<finished %s>" % self.__class__.__name__
+            return '<finished %s>' % self.__class__.__name__
         try:
-            return ("%s(%r, %r, %r, overwrite=%r, progress=%r)" %
-                    (self.__class__.__name__, self.data.filename,
-                     self.coincidences._v_parent._v_pathname,
-                     self.station_groups, self.overwrite, self.progress))
+            return '%s(%r, %r, %r, overwrite=%r, progress=%r)' % (
+                self.__class__.__name__,
+                self.data.filename,
+                self.coincidences._v_parent._v_pathname,
+                self.station_groups,
+                self.overwrite,
+                self.progress,
+            )
         except AttributeError:
-            return ("%s(%r, %r, %r, overwrite=%r, progress=%r)" %
-                    (self.__class__.__name__, self.data.filename,
-                     None, self.station_groups, self.overwrite, self.progress))
+            return '%s(%r, %r, %r, overwrite=%r, progress=%r)' % (
+                self.__class__.__name__,
+                self.data.filename,
+                None,
+                self.station_groups,
+                self.overwrite,
+                self.progress,
+            )
 
 
 class CoincidencesESD(Coincidences):
     """Store coincidences specifically using the ESD
 
     This is a subclass of :class:`Coincidences`. This subclass stores the paths
     to the station_groups that where used to look for coincidences in a
@@ -573,26 +554,25 @@
     The ``event`` is one of the events in the coincidence.
 
     Coincidences stored by this class can easily be searched by using
     a :class:`~sapphire.analysis.coincidence_queries.CoincidenceQuery` object.
 
     """
 
-    def search_and_store_coincidences(self, window=10000,
-                                      station_numbers=None):
+    def search_and_store_coincidences(self, window=10_000, station_numbers=None):
         """Search and store coincidences.
 
         This is a semi-automatic method to search for coincidences
         and then store the results in the coincidences group.
 
         """
         self.search_coincidences(window=window)
         self.store_coincidences(station_numbers=station_numbers)
 
-    def search_coincidences(self, window=10000, shifts=None, limit=None):
+    def search_coincidences(self, window=10_000, shifts=None, limit=None):
         """Search for coincidences.
 
         Search all data in the station_groups for coincidences, and store
         rudimentary coincidence data in attributes.  This data might be useful,
         but is very basic.  You can call the :meth:`store_coincidences` method
         to store the coincidences in an easier format in the coincidences
         group.
@@ -633,45 +613,51 @@
             they will simply be numbered by id. This list must be the
             same length as the station_groups.
 
         """
         n_coincidences = len(self._src_c_index)
         if station_numbers is not None:
             if len(station_numbers) != len(self.station_groups):
-                raise RuntimeError(
-                    "Number of station numbers must equal number of groups.")
+                raise RuntimeError('Number of station numbers must equal number of groups.')
             self.station_numbers = station_numbers
-            s_columns = {'s%d' % number: tables.BoolCol(pos=p)
-                         for p, number in enumerate(station_numbers, 12)}
+            s_columns = {'s%d' % number: tables.BoolCol(pos=p) for p, number in enumerate(station_numbers, 12)}
         else:
             self.station_numbers = None
-            s_columns = {'s%d' % n: tables.BoolCol(pos=(n + 12))
-                         for n, _ in enumerate(self.station_groups)}
+            s_columns = {'s%d' % n: tables.BoolCol(pos=(n + 12)) for n, _ in enumerate(self.station_groups)}
 
         description = storage.Coincidence
         description.columns.update(s_columns)
         self.coincidences = self.data.create_table(
-            self.coincidence_group, 'coincidences', description,
-            expectedrows=n_coincidences)
+            self.coincidence_group,
+            'coincidences',
+            description,
+            expectedrows=n_coincidences,
+        )
 
         self.c_index = []
 
         for coincidence in pbar(self._src_c_index, show=self.progress):
             self._store_coincidence(coincidence)
 
         c_index = self.data.create_vlarray(
-            self.coincidence_group, 'c_index', tables.UInt32Col(shape=2),
-            expectedrows=n_coincidences)
+            self.coincidence_group,
+            'c_index',
+            tables.UInt32Col(shape=2),
+            expectedrows=n_coincidences,
+        )
         for observables_idx in pbar(self.c_index, show=self.progress):
             c_index.append(observables_idx)
         c_index.flush()
 
         s_index = self.data.create_vlarray(
-            self.coincidence_group, 's_index', tables.VLStringAtom(),
-            expectedrows=len(self.station_groups))
+            self.coincidence_group,
+            's_index',
+            tables.VLStringAtom(),
+            expectedrows=len(self.station_groups),
+        )
         for station_group in self.station_groups:
             s_index.append(station_group.encode('utf-8'))
         s_index.flush()
 
     def _store_coincidence(self, coincidence):
         """Store a single coincidence in the coincidence group.
 
@@ -695,20 +681,18 @@
                 row['s%d' % station_number] = True
             else:
                 row['s%d' % station_id] = True
 
             group = self.data.get_node(self.station_groups[station_id])
             event = group.events[event_index]
             observables_idx.append((station_id, event_index))
-            timestamps.append((event['ext_timestamp'], event['timestamp'],
-                               event['nanoseconds']))
+            timestamps.append((event['ext_timestamp'], event['timestamp'], event['nanoseconds']))
 
         first_timestamp = sorted(timestamps)[0]
-        row['ext_timestamp'], row['timestamp'], row['nanoseconds'] = \
-            first_timestamp
+        row['ext_timestamp'], row['timestamp'], row['nanoseconds'] = first_timestamp
         row.append()
         self.c_index.append(observables_idx)
         self.coincidences.flush()
 
 
 def get_events(data, stations, coincidence, timestamps, get_raw_traces=False):
     """Get event data of a coincidence
@@ -732,16 +716,15 @@
     """
     events = []
     for event in coincidence:
         timestamp, station, index = timestamps[event]
         process = process_events.ProcessEvents(data, stations[station])
         event = process.source[index]
         if not get_raw_traces:
-            baseline = np.where(event['baseline'] != -999, event['baseline'],
-                                200)[np.where(event['traces'] >= 0)]
+            baseline = np.where(event['baseline'] != -999, event['baseline'], 200)[np.where(event['traces'] >= 0)]
             # transpose to get expected format
             traces = (process.get_traces_for_event(event) - baseline).T
         else:
             traces = [process.group.blobs[x] for x in event['traces']]
         events.append((stations[station], event, traces))
 
     return events
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/core_reconstruction.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/core_reconstruction.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-""" Core reconstruction
+"""Core reconstruction
 
-    This module contains two classes that can be used to reconstruct
-    HiSPARC events and coincidences. The classes know how to extract the
-    relevant information from the station and event or cluster and
-    coincidence. Various algorithms which do the reconstruction are also
-    defined here. The algorithms require positions and particle densties to
-    do the reconstruction.
-
-    Each algorithm has a :meth:`~BaseCoreAlgorithm.reconstruct_common`
-    method which always requires particle denisties, x, and y positions
-    and optionally z positions and previous reconstruction results. The
-    data is then prepared for the algorithm and passed to
-    the :meth:`~CenterMassAlgorithm.reconstruct` method which returns the
-    reconstructed x and y coordinates.
+This module contains two classes that can be used to reconstruct
+HiSPARC events and coincidences. The classes know how to extract the
+relevant information from the station and event or cluster and
+coincidence. Various algorithms which do the reconstruction are also
+defined here. The algorithms require positions and particle densties to
+do the reconstruction.
+
+Each algorithm has a :meth:`~BaseCoreAlgorithm.reconstruct_common`
+method which always requires particle denisties, x, and y positions
+and optionally z positions and previous reconstruction results. The
+data is then prepared for the algorithm and passed to
+the :meth:`~CenterMassAlgorithm.reconstruct` method which returns the
+reconstructed x and y coordinates.
 
 """
 
 import warnings
 
 from itertools import combinations, zip_longest
 
@@ -24,15 +24,14 @@
 
 from ..simulations import ldf
 from ..utils import pbar
 from .event_utils import detector_density, station_density
 
 
 class EventCoreReconstruction:
-
     """Reconstruct core for station events
 
     This class is aware of 'events' and 'stations'.  Initialize this class
     with a 'station' and you can reconstruct events using
     :meth:`reconstruct_event`.
 
     :param station: :class:`sapphire.clusters.Station` object.
@@ -58,31 +57,29 @@
 
         """
         p, x, y, z = ([], [], [], [])
         if detector_ids is None:
             detector_ids = range(4)
 
         self.station.cluster.set_timestamp(event['timestamp'])
-        for id in detector_ids:
-            p_detector = detector_density(event, id, self.station)
+        for detector_id in detector_ids:
+            p_detector = detector_density(event, detector_id, self.station)
             if not isnan(p_detector):
-                dx, dy, dz = self.station.detectors[id].get_coordinates()
+                dx, dy, dz = self.station.detectors[detector_id].get_coordinates()
                 p.append(p_detector)
                 x.append(dx)
                 y.append(dy)
                 z.append(dz)
         if len(p) >= 3:
-            core_x, core_y = self.estimator.reconstruct_common(p, x, y, z,
-                                                               initial)
+            core_x, core_y = self.estimator.reconstruct_common(p, x, y, z, initial)
         else:
             core_x, core_y = (nan, nan)
         return core_x, core_y
 
-    def reconstruct_events(self, events, detector_ids=None, progress=True,
-                           initials=None):
+    def reconstruct_events(self, events, detector_ids=None, progress=True, initials=None):
         """Reconstruct events
 
         :param events: the events table for the station from an ESD data
                        file.
         :param detector_ids: detectors which use for the reconstructions.
         :param progress: if True show a progress bar while reconstructing.
         :param initials: list of dictionaries with already reconstructed shower
@@ -91,45 +88,41 @@
 
         """
         if initials is None:
             initials = []
 
         events = pbar(events, show=progress)
         events_init = zip_longest(events, initials)
-        cores = [self.reconstruct_event(event, detector_ids, initial)
-                 for event, initial in events_init]
+        cores = [self.reconstruct_event(event, detector_ids, initial) for event, initial in events_init]
         if len(cores):
             core_x, core_y = zip(*cores)
         else:
             core_x, core_y = ((), ())
         return core_x, core_y
 
     def __repr__(self):
-        return ("<%s, station: %r, estimator: %r>" %
-                (self.__class__.__name__, self.station, self.estimator))
+        return '<%s, station: %r, estimator: %r>' % (self.__class__.__name__, self.station, self.estimator)
 
 
 class CoincidenceCoreReconstruction:
-
     """Reconstruct core for coincidences
 
     This class is aware of 'coincidences' and 'clusters'.  Initialize
     this class with a 'cluster' and you can reconstruct a coincidence
     using :meth:`reconstruct_coincidence`.
 
     :param cluster: :class:`sapphire.clusters.BaseCluster` object.
 
     """
 
     def __init__(self, cluster):
         self.estimator = CenterMassAlgorithm
         self.cluster = cluster
 
-    def reconstruct_coincidence(self, coincidence, station_numbers=None,
-                                initial=None):
+    def reconstruct_coincidence(self, coincidence, station_numbers=None, initial=None):
         """Reconstruct a single coincidence
 
         :param coincidence: a coincidence list consisting of
                             multiple (station_number, event) tuples
         :param station_numbers: list of station numbers, to only use
                                 events from those stations.
         :param initial: dictionary with already reconstructed shower
@@ -154,22 +147,20 @@
                 sx, sy, sz = station.calc_center_of_mass_coordinates()
                 p.append(p_station)
                 x.append(sx)
                 y.append(sy)
                 z.append(sz)
 
         if len(p) >= 3:
-            core_x, core_y = self.estimator.reconstruct_common(p, x, y, z,
-                                                               initial)
+            core_x, core_y = self.estimator.reconstruct_common(p, x, y, z, initial)
         else:
             core_x, core_y = (nan, nan)
         return core_x, core_y
 
-    def reconstruct_coincidences(self, coincidences, station_numbers=None,
-                                 progress=True, initials=None):
+    def reconstruct_coincidences(self, coincidences, station_numbers=None, progress=True, initials=None):
         """Reconstruct all coincidences
 
         :param coincidences: a list of coincidences, each consisting of
                              multiple (station_number, event) tuples.
         :param station_numbers: list of station numbers, to only use
                                 events from those stations.
         :param progress: if True show a progress bar while reconstructing.
@@ -179,40 +170,36 @@
 
         """
         if initials is None:
             initials = []
 
         coincidences = pbar(coincidences, show=progress)
         coin_init = zip_longest(coincidences, initials)
-        cores = [self.reconstruct_coincidence(coincidence, station_numbers,
-                                              initial)
-                 for coincidence, initial in coin_init]
+        cores = [
+            self.reconstruct_coincidence(coincidence, station_numbers, initial) for coincidence, initial in coin_init
+        ]
         if len(cores):
             core_x, core_y = list(zip(*cores))
         else:
             core_x, core_y = ((), ())
         return core_x, core_y
 
     def __repr__(self):
-        return ("<%s, cluster: %r, estimator: %r>" %
-                (self.__class__.__name__, self.cluster, self.estimator))
-
+        return '<%s, cluster: %r, estimator: %r>' % (self.__class__.__name__, self.cluster, self.estimator)
 
-class CoincidenceCoreReconstructionDetectors(
-        CoincidenceCoreReconstruction):
 
+class CoincidenceCoreReconstructionDetectors(CoincidenceCoreReconstruction):
     """Reconstruct core for coincidences using each detector
 
     Instead of using the average station particle density this class
     uses the particle density in each detector for the reconstruction.
 
     """
 
-    def reconstruct_coincidence(self, coincidence, station_numbers=None,
-                                initial=None):
+    def reconstruct_coincidence(self, coincidence, station_numbers=None, initial=None):
         """Reconstruct a single coincidence
 
         :param coincidence: a coincidence list consisting of
                             multiple (station_number, event) tuples
         :param station_numbers: list of station numbers, to only use
                                 events from those stations.
         :param initial: dictionary with already reconstructed shower
@@ -224,37 +211,34 @@
 
         try:
             self.cluster.set_timestamp(coincidence[0][1]['timestamp'])
         except IndexError:
             return (nan, nan)
 
         for station_number, event in coincidence:
-            if station_numbers is not None:
-                if station_number not in station_numbers:
-                    continue
+            if station_numbers is not None and station_number not in station_numbers:
+                continue
             station = self.cluster.get_station(station_number)
-            for id in range(4):
-                p_detector = detector_density(event, id, station)
+            for detector_id in range(4):
+                p_detector = detector_density(event, detector_id, station)
                 if not isnan(p_detector):
-                    dx, dy, dz = station.detectors[id].get_coordinates()
+                    dx, dy, dz = station.detectors[detector_id].get_coordinates()
                     p.append(p_detector)
                     x.append(dx)
                     y.append(dy)
                     z.append(dz)
 
         if len(p) >= 3:
-            core_x, core_y = self.estimator.reconstruct_common(p, x, y, z,
-                                                               initial)
+            core_x, core_y = self.estimator.reconstruct_common(p, x, y, z, initial)
         else:
             core_x, core_y = (nan, nan)
         return core_x, core_y
 
 
 class BaseCoreAlgorithm:
-
     """No actual core reconstruction algorithm
 
     Simply returns (nan, nan) as core.
 
     """
 
     @classmethod
@@ -278,15 +262,14 @@
         :return: reconstructed core position.
 
         """
         return (nan, nan)
 
 
 class CenterMassAlgorithm(BaseCoreAlgorithm):
-
     """Simple core estimator
 
     Estimates the core by center of mass of the measurements.
 
     """
 
     @classmethod
@@ -320,15 +303,14 @@
         """
         core_x = sum(density * xi for density, xi in zip(p, x)) / sum(p)
         core_y = sum(density * yi for density, yi in zip(p, y)) / sum(p)
         return core_x, core_y
 
 
 class AverageIntersectionAlgorithm(BaseCoreAlgorithm):
-
     """Core estimator
 
     To the densities in 3 stations correspond 2 possible cores. The line
     through these points is quite stable for the lateral distribution function.
     To each combination of 3 stations out of a set of at least 4
     stations hit corresponds a line. To each combinations of 2 lines out of
     the set of lines corresponds a point of intersection (if the 2 lines are
@@ -347,15 +329,15 @@
         :param z: height of detectors is ignored.
         :param initial: dictionary containing values from previous
                         reconstructions.
         :return: reconstructed core position.
 
         """
         if len(p) < 4 or len(x) < 4 or len(y) < 4:
-            raise Exception('This algorithm requires at least 4 detections.')
+            raise ValueError('This algorithm requires at least 4 detections.')
         if initial is None:
             initial = {}
 
         phit = []
         xhit = []
         yhit = []
         for i in range(len(p)):
@@ -367,16 +349,16 @@
         statindex = range(len(phit))
         subsets = combinations(statindex, 3)
         m = 3.0  # average value in powerlaw  r ^(-m)  for density
 
         linelist0 = []
         linelist1 = []
         for zero, one, two in subsets:
-            pp = (phit[zero] / phit[one]) ** (2. / m)
-            qq = (phit[zero] / phit[two]) ** (2. / m)
+            pp = (phit[zero] / phit[one]) ** (2.0 / m)
+            qq = (phit[zero] / phit[two]) ** (2.0 / m)
             if pp == 1:
                 pp = 1.000001
             if qq == 1:
                 qq = 1.000001
 
             x0 = xhit[zero]
             x1 = xhit[one]
@@ -395,16 +377,15 @@
             if d == b:
                 f = 0.000000001
             g = sqrt(e * e + f * f)
             k = 0.5 * (g * g + rsquare - ssquare) / g
             linelist0.append(-e / f)
             linelist1.append((a * e + b * f + g * k) / f)
 
-        newx, newy = CenterMassAlgorithm.reconstruct_common(p, x, y, z,
-                                                            initial)
+        newx, newy = CenterMassAlgorithm.reconstruct_common(p, x, y, z, initial)
         subsets = combinations(statindex, 2)
 
         xpointlist = []
         ypointlist = []
         for zero, one in subsets:
             a = linelist0[zero]
             b = linelist1[zero]
@@ -415,21 +396,19 @@
                 aminc = 0.000000001
             xint = (d - b) / aminc
             yint = (a * d - b * c) / aminc
             if a != c:
                 xpointlist.append(xint)
                 ypointlist.append(yint)
 
-        subxplist, subyplist = cls.select_newlist(
-            newx, newy, xpointlist, ypointlist, 120.)
+        subxplist, subyplist = cls.select_newlist(newx, newy, xpointlist, ypointlist, 120.0)
         if len(subxplist) > 3:
             newx = mean(subxplist)
             newy = mean(subyplist)
-            subxplist, subyplist = cls.select_newlist(
-                newx, newy, xpointlist, ypointlist, 100.)
+            subxplist, subyplist = cls.select_newlist(newx, newy, xpointlist, ypointlist, 100.0)
         if len(subxplist) > 2:
             newx = mean(subxplist)
             newy = mean(subyplist)
 
         return newx, newy
 
     @staticmethod
@@ -444,15 +423,14 @@
                 newxlist.append(xpoint)
                 newylist.append(ypoint)
 
         return newxlist, newylist
 
 
 class EllipsLdfAlgorithm(BaseCoreAlgorithm):
-
     """Simple core estimator
 
     Estimates the core by center of mass of the measurements.
 
     """
 
     @classmethod
@@ -465,68 +443,96 @@
         :param initial: dictionary containing values from previous
                         reconstructions: zenith and azimuth.
         :return: reconstructed core position.
 
         """
         if initial is None:
             initial = {}
-        theta = initial.get('theta', 0.)
-        phi = initial.get('phi', 0.)
+        theta = initial.get('theta', 0.0)
+        phi = initial.get('phi', 0.0)
         return cls.reconstruct(p, x, y, theta, phi)[:2]
 
     @classmethod
     def reconstruct(cls, p, x, y, theta, phi):
         """Reconstruct the number of electrons that fits best.
 
         :param p: detector particle density in m^-2.
         :param x,y: positions of detectors in m.
         :param theta,phi: zenith and azimuth angle in rad.
         :return: reconstructed core position, chi square, and shower size.
 
         """
         xcmass, ycmass = CenterMassAlgorithm.reconstruct_common(p, x, y)
-        chi2best = 10 ** 99
+        chi2best = 10**99
         xbest = xcmass
         ybest = ycmass
-        factorbest = 1.
-        gridsize = 5.
+        factorbest = 1.0
+        gridsize = 5.0
         xbest1, ybest1, chi2best1, factorbest1 = cls.selectbest(
-            p, x, y, xbest, ybest, factorbest, chi2best, gridsize, theta, phi)
+            p,
+            x,
+            y,
+            xbest,
+            ybest,
+            factorbest,
+            chi2best,
+            gridsize,
+            theta,
+            phi,
+        )
 
-        xlines, ylines = AverageIntersectionAlgorithm.reconstruct_common(p, x,
-                                                                         y)
-        chi2best = 10 ** 99
+        xlines, ylines = AverageIntersectionAlgorithm.reconstruct_common(p, x, y)
+        chi2best = 10**99
         xbest = xcmass
         ybest = ycmass
-        factorbest = 1.
+        factorbest = 1.0
         xbest2, ybest2, chi2best2, factorbest2 = cls.selectbest(
-            p, x, y, xbest, ybest, factorbest, chi2best, gridsize, theta, phi)
+            p,
+            x,
+            y,
+            xbest,
+            ybest,
+            factorbest,
+            chi2best,
+            gridsize,
+            theta,
+            phi,
+        )
 
         if chi2best1 < chi2best2:
             chi2best = chi2best1
             xbest = xbest1
             ybest = ybest1
             factorbest = factorbest1
         else:
             chi2best = chi2best2
             xbest = xbest2
             ybest = ybest2
             factorbest = factorbest2
 
-        gridsize = 2.
+        gridsize = 2.0
         core_x, core_y, chi2best, factorbest = cls.selectbest(
-            p, x, y, xbest, ybest, factorbest, chi2best, gridsize, theta, phi)
+            p,
+            x,
+            y,
+            xbest,
+            ybest,
+            factorbest,
+            chi2best,
+            gridsize,
+            theta,
+            phi,
+        )
 
         size = factorbest * ldf.EllipsLdf._n_electrons
 
         return core_x, core_y, chi2best, size
 
     @staticmethod
-    def selectbest(p, x, y, xstart, ystart, factorbest, chi2best, gridsize,
-                   theta, phi):
+    def selectbest(p, x, y, xstart, ystart, factorbest, chi2best, gridsize, theta, phi):
         """selects the best core position in grid around (xstart, ystart).
 
         :param p: detector particle density in m^-2.
         :param x,y: positions of detectors in m.
         :param xcmass,ycmass: start position of core in m.
 
         """
@@ -536,30 +542,29 @@
         a = ldf.EllipsLdf(zenith=theta, azimuth=phi)
         for i in range(41):
             xtry = xstart + (i - 20) * gridsize
             for j in range(11):
                 ytry = ystart + (i - 20) * gridsize
                 xstations = array(x)
                 ystations = array(y)
-                r, angle = a.calculate_core_distance_and_angle(
-                    xstations, ystations, xtry, ytry)
+                r, angle = a.calculate_core_distance_and_angle(xstations, ystations, xtry, ytry)
                 rho = a.calculate_ldf_value(r, angle)
 
-                mmdivk = 0.
-                m = 0.
-                k = 0.
+                mmdivk = 0.0
+                m = 0.0
+                k = 0.0
 
                 for i, j in zip(p, rho):
-                    mmdivk += 1. * i * i / j
+                    mmdivk += 1.0 * i * i / j
                     m += i
                     k += j
 
                 sizefactor = sqrt(mmdivk / k)
                 with warnings.catch_warnings(record=True):
-                    chi2 = 2. * (sizefactor * k - m)
+                    chi2 = 2.0 * (sizefactor * k - m)
                 if chi2 < chi2best:
                     factorbest = sizefactor
                     xbest = xtry
                     ybest = ytry
                     chi2best = chi2
 
         return xbest, ybest, chi2best, factorbest
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/direction_reconstruction.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/direction_reconstruction.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,30 @@
-""" Direction reconstruction
+"""Direction reconstruction
 
-    This module contains two classes that can be used to reconstruct
-    HiSPARC events and coincidences. The classes know how to extract the
-    relevant information from the station and event or cluster and
-    coincidence. Various algorithms which do the reconstruction are also
-    defined here. The algorithms require positions and arrival times to
-    do the reconstruction.
-
-    Each algorithm has a :meth:`~BaseDirectionAlgorithm.reconstruct_common`
-    method which always requires arrival times, x, and y positions and
-    optionally z positions and previous reconstruction results. The data
-    is then prepared for the algorithm and passed to
-    the :meth:`~BaseDirectionAlgorithm.reconstruct` method which returns the
-    reconstructed theta and phi coordinates.
+This module contains two classes that can be used to reconstruct
+HiSPARC events and coincidences. The classes know how to extract the
+relevant information from the station and event or cluster and
+coincidence. Various algorithms which do the reconstruction are also
+defined here. The algorithms require positions and arrival times to
+do the reconstruction.
+
+Each algorithm has a :meth:`~BaseDirectionAlgorithm.reconstruct_common`
+method which always requires arrival times, x, and y positions and
+optionally z positions and previous reconstruction results. The data
+is then prepared for the algorithm and passed to
+the :meth:`~BaseDirectionAlgorithm.reconstruct` method which returns the
+reconstructed theta and phi coordinates.
 
 """
+
 import warnings
 
 from itertools import combinations, zip_longest
 
-import numpy
+import numpy as np
 
 from numpy import (
     arccos,
     arcsin,
     arctan2,
     array,
     cos,
@@ -43,20 +44,19 @@
 from scipy.sparse.csgraph import shortest_path
 
 from ..api import Station
 from ..simulations.showerfront import CorsikaStationFront
 from ..utils import c, floor_in_base, make_relative, memoize, norm_angle, pbar, vector_length
 from . import event_utils
 
-NO_OFFSET = [0., 0., 0., 0.]
-NO_STATION_OFFSET = (0., 100.)
+NO_OFFSET = [0.0, 0.0, 0.0, 0.0]
+NO_STATION_OFFSET = (0.0, 100.0)
 
 
 class EventDirectionReconstruction:
-
     """Reconstruct direction for station events
 
     This class is aware of 'events' and 'stations'.  Initialize this class
     with a 'station' and you can reconstruct events using
     :meth:`reconstruct_event`. To use other algorithms overwrite the
     ``direct`` and ``fit`` attributes.
 
@@ -65,16 +65,15 @@
     """
 
     def __init__(self, station):
         self.direct = DirectAlgorithmCartesian3D
         self.fit = RegressionAlgorithm3D
         self.station = station
 
-    def reconstruct_event(self, event, detector_ids=None, offsets=NO_OFFSET,
-                          initial=None):
+    def reconstruct_event(self, event, detector_ids=None, offsets=NO_OFFSET, initial=None):
         """Reconstruct a single event
 
         :param event: an event (e.g. from an events table), or any
             dictionary-like object containing the keys necessary for
             reconstructing the direction of a shower (e.g. arrival times).
         :param detector_ids: list of the detectors to use for
             reconstruction. The detector ids are 0-based, unlike the
@@ -87,33 +86,32 @@
         """
         t, x, y, z, ids = ([], [], [], [], [])
         if detector_ids is None:
             detector_ids = range(4)
         self.station.cluster.set_timestamp(event['timestamp'])
         if isinstance(offsets, Station):
             offsets = offsets.detector_timing_offset(event['timestamp'])
-        for id in detector_ids:
-            t_detector = event_utils.detector_arrival_time(event, id, offsets)
+        for detector_id in detector_ids:
+            t_detector = event_utils.detector_arrival_time(event, detector_id, offsets)
             if not isnan(t_detector):
-                dx, dy, dz = self.station.detectors[id].get_coordinates()
+                dx, dy, dz = self.station.detectors[detector_id].get_coordinates()
                 t.append(t_detector)
                 x.append(dx)
                 y.append(dy)
                 z.append(dz)
                 ids.append(id)
         if len(t) == 3:
             theta, phi = self.direct.reconstruct_common(t, x, y, z, initial)
         elif len(t) > 3:
             theta, phi = self.fit.reconstruct_common(t, x, y, z, initial)
         else:
             theta, phi = (nan, nan)
         return theta, phi, ids
 
-    def reconstruct_events(self, events, detector_ids=None, offsets=NO_OFFSET,
-                           progress=True, initials=None):
+    def reconstruct_events(self, events, detector_ids=None, offsets=NO_OFFSET, progress=True, initials=None):
         """Reconstruct events
 
         :param events: the events table for the station from an ESD data file.
         :param detector_ids: detectors to use for the reconstructions.
         :param offsets: time offsets for each detector or a
             :class:`~sapphire.api.Station` object.
         :param progress: if True show a progress bar while reconstructing.
@@ -122,29 +120,26 @@
         :return: list of theta, phi, and detector ids.
 
         """
         if initials is None:
             initials = []
         events = pbar(events, show=progress)
         events_init = zip_longest(events, initials)
-        angles = [self.reconstruct_event(event, detector_ids, offsets, initial)
-                  for event, initial in events_init]
+        angles = [self.reconstruct_event(event, detector_ids, offsets, initial) for event, initial in events_init]
         if len(angles):
             theta, phi, ids = zip(*angles)
         else:
             theta, phi, ids = ((), (), ())
         return theta, phi, ids
 
     def __repr__(self):
-        return ("<%s, station: %r, direct: %r, fit: %r>" %
-                (self.__class__.__name__, self.station, self.direct, self.fit))
+        return '<%s, station: %r, direct: %r, fit: %r>' % (self.__class__.__name__, self.station, self.direct, self.fit)
 
 
 class CoincidenceDirectionReconstruction:
-
     """Reconstruct direction for coincidences
 
     This class is aware of 'coincidences' and 'clusters'.  Initialize
     this class with a 'cluster' and you can reconstruct a coincidence
     using :meth:`reconstruct_coincidence`. To use other algorithms
     overwrite the ``direct``,``fit``, and ``curved`` attributes.
 
@@ -154,16 +149,15 @@
 
     def __init__(self, cluster):
         self.direct = DirectAlgorithmCartesian3D
         self.fit = RegressionAlgorithm3D
         self.curved = CurvedRegressionAlgorithm3D()
         self.cluster = cluster
 
-    def reconstruct_coincidence(self, coincidence_events, station_numbers=None,
-                                offsets=None, initial=None):
+    def reconstruct_coincidence(self, coincidence_events, station_numbers=None, offsets=None, initial=None):
         """Reconstruct a single coincidence
 
         :param coincidence_events: a coincidence list consisting of three
             or more (station_number, event) tuples.
         :param station_numbers: list of station numbers, to only use
             events from those stations.
         :param offsets: a dictionary of either lists of detector timing
@@ -181,25 +175,23 @@
 
         # Subtract base timestamp to prevent loss of precision
         ts0 = int(coincidence_events[0][1]['timestamp'])
         ets0 = ts0 * 1_000_000_000
         self.cluster.set_timestamp(ts0)
         t, x, y, z, nums = ([], [], [], [], [])
 
-        offsets = self.get_station_offsets(coincidence_events, station_numbers,
-                                           offsets, ts0)
+        offsets = self.get_station_offsets(coincidence_events, station_numbers, offsets, ts0)
 
         for station_number, event in coincidence_events:
             if station_numbers is not None:
                 if station_number not in station_numbers:
                     continue
             t_off = offsets.get(station_number, NO_OFFSET)
             station = self.cluster.get_station(station_number)
-            t_first = event_utils.station_arrival_time(
-                event, ets0, offsets=t_off, station=station)
+            t_first = event_utils.station_arrival_time(event, ets0, offsets=t_off, station=station)
             if not isnan(t_first):
                 sx, sy, sz = station.calc_center_of_mass_coordinates()
                 t.append(t_first)
                 x.append(sx)
                 y.append(sy)
                 z.append(sz)
                 nums.append(station_number)
@@ -211,16 +203,15 @@
         elif len(t) > 3:
             theta, phi = self.fit.reconstruct_common(t, x, y, z, initial)
         else:
             theta, phi = (nan, nan)
 
         return theta, phi, nums
 
-    def reconstruct_coincidences(self, coincidences, station_numbers=None,
-                                 offsets=None, progress=True, initials=None):
+    def reconstruct_coincidences(self, coincidences, station_numbers=None, offsets=None, progress=True, initials=None):
         """Reconstruct all coincidences
 
         :param coincidences: a list of coincidence events, each consisting
                              of three or more (station_number, event) tuples.
         :param station_numbers: list of station numbers, to only use
                                 events from those stations.
         :param offsets: dictionary with detector offsets for each station.
@@ -234,34 +225,33 @@
         """
         if offsets is None:
             offsets = {}
         if initials is None:
             initials = []
         coincidences = pbar(coincidences, show=progress)
         coin_init = zip_longest(coincidences, initials)
-        angles = [self.reconstruct_coincidence(coincidence, station_numbers,
-                                               offsets, initial)
-                  for coincidence, initial in coin_init]
+        angles = [
+            self.reconstruct_coincidence(coincidence, station_numbers, offsets, initial)
+            for coincidence, initial in coin_init
+        ]
         if len(angles):
             theta, phi, nums = zip(*angles)
         else:
             theta, phi, nums = ((), (), ())
         return theta, phi, nums
 
-    def get_station_offsets(self, coincidence_events, station_numbers,
-                            offsets, ts0):
+    def get_station_offsets(self, coincidence_events, station_numbers, offsets, ts0):
         if offsets and isinstance(next(iter(offsets.values())), Station):
             if station_numbers is None:
                 # stations in the coincidence
                 stations = list({sn for sn, _ in coincidence_events})
             else:
                 stations = station_numbers
             midnight_ts = floor_in_base(ts0, 86400)
-            offsets = self.determine_best_offsets(stations, midnight_ts,
-                                                  offsets)
+            offsets = self.determine_best_offsets(stations, midnight_ts, offsets)
         return offsets
 
     @memoize
     def determine_best_offsets(self, station_numbers, midnight_ts, offsets):
         """Determine best combined station and detector offsets
 
         Check which station is best used as reference. Allow offsets via
@@ -274,61 +264,52 @@
         :param midnight_ts: timestamp of midnight before the coincidence.
         :param offsets: a dictionary of :class:`~sapphire.api.Station` objects
                         for each station.
         :return: combined detector and station offsets for given station,
                  relative to the reference station.
 
         """
-        offset_stations = station_numbers + [sn for sn in list(offsets.keys())
-                                             if sn not in station_numbers]
+        offset_stations = station_numbers + [sn for sn in list(offsets.keys()) if sn not in station_numbers]
 
         offset_matrix = zeros((len(offset_stations), len(offset_stations)))
         error_matrix = zeros((len(offset_stations), len(offset_stations)))
 
         for i, sn in enumerate(offset_stations):
             for j, ref_sn in enumerate(offset_stations):
                 try:
-                    o, e = offsets[sn].station_timing_offset(ref_sn,
-                                                             midnight_ts)
+                    o, e = offsets[sn].station_timing_offset(ref_sn, midnight_ts)
                 except Exception:
                     o, e = NO_STATION_OFFSET
                 else:
                     if isnan(o) and isnan(e):
                         o, e = NO_STATION_OFFSET
                 offset_matrix[i, j] = -o
                 offset_matrix[j, i] = o
-                error_matrix[i, j] = e ** 2
-                error_matrix[j, i] = e ** 2
+                error_matrix[i, j] = e**2
+                error_matrix[j, i] = e**2
 
-        ref_sn, predecessors = self.determine_best_reference(error_matrix,
-                                                             station_numbers)
+        ref_sn, predecessors = self.determine_best_reference(error_matrix, station_numbers)
 
         best_offsets = {}
         for sn in station_numbers:
-            best_offset = self._reconstruct_best_offset(
-                predecessors, sn, ref_sn, station_numbers, offset_matrix)
-            best_offsets[sn] = self._calculate_offsets(offsets[sn],
-                                                       midnight_ts,
-                                                       best_offset)
+            best_offset = self._reconstruct_best_offset(predecessors, sn, ref_sn, station_numbers, offset_matrix)
+            best_offsets[sn] = self._calculate_offsets(offsets[sn], midnight_ts, best_offset)
         return best_offsets
 
     def determine_best_reference(self, error_matrix, station_numbers):
-        paths, predecessors = shortest_path(error_matrix, method='FW',
-                                            directed=False,
-                                            return_predecessors=True)
+        paths, predecessors = shortest_path(error_matrix, method='FW', directed=False, return_predecessors=True)
         n = len(station_numbers)
         # Only consider station in coincidence for reference
         total_errors = paths[:n, :n].sum(axis=1)
         best_reference = station_numbers[total_errors.argmin()]
 
         return best_reference, predecessors
 
-    def _reconstruct_best_offset(self, predecessors, sn, ref_sn,
-                                 station_numbers, offset_matrix):
-        offset = 0.
+    def _reconstruct_best_offset(self, predecessors, sn, ref_sn, station_numbers, offset_matrix):
+        offset = 0.0
         if sn != ref_sn:
             i = station_numbers.index(sn)
             j = station_numbers.index(ref_sn)
             while j != i:
                 prev_j = j
                 j = predecessors[i, j]
                 offset += offset_matrix[prev_j, j]
@@ -344,31 +325,32 @@
                  relative to the reference station.
 
         """
         detector_offsets = station.detector_timing_offset(ts0)
         return [offset + d_off for d_off in detector_offsets]
 
     def __repr__(self):
-        return ("<%s, cluster: %r, direct: %r, fit: %r, curved: %r>" %
-                (self.__class__.__name__, self.cluster, self.direct, self.fit,
-                 self.curved))
-
+        return '<%s, cluster: %r, direct: %r, fit: %r, curved: %r>' % (
+            self.__class__.__name__,
+            self.cluster,
+            self.direct,
+            self.fit,
+            self.curved,
+        )
 
-class CoincidenceDirectionReconstructionDetectors(
-        CoincidenceDirectionReconstruction):
 
+class CoincidenceDirectionReconstructionDetectors(CoincidenceDirectionReconstruction):
     """Reconstruct direction for coincidences using each detector
 
     Instead of only the first arrival time per station this class
     uses the arrival time in each detector for the reconstruction.
 
     """
 
-    def reconstruct_coincidence(self, coincidence_events, station_numbers=None,
-                                offsets=None, initial=None):
+    def reconstruct_coincidence(self, coincidence_events, station_numbers=None, offsets=None, initial=None):
         """Reconstruct a single coincidence
 
         :param coincidence_events: a coincidence list consisting of one
                                    or more (station_number, event) tuples.
         :param station_numbers: list of station numbers, to only use
                                 events from those stations.
         :param offsets: dictionary with detector offsets for each station.
@@ -387,25 +369,23 @@
 
         # Subtract base timestamp to prevent loss of precision
         ts0 = int(coincidence_events[0][1]['timestamp'])
         ets0 = ts0 * 1_000_000_000
         self.cluster.set_timestamp(ts0)
         t, x, y, z, nums = ([], [], [], [], [])
 
-        offsets = self.get_station_offsets(coincidence_events, station_numbers,
-                                           offsets, ts0)
+        offsets = self.get_station_offsets(coincidence_events, station_numbers, offsets, ts0)
 
         for station_number, event in coincidence_events:
             if station_numbers is not None:
                 if station_number not in station_numbers:
                     continue
             t_off = offsets.get(station_number, NO_OFFSET)
             station = self.cluster.get_station(station_number)
-            t_detectors = event_utils.relative_detector_arrival_times(
-                event, ets0, offsets=t_off, station=station)
+            t_detectors = event_utils.relative_detector_arrival_times(event, ets0, offsets=t_off, station=station)
             for t_detector, detector in zip(t_detectors, station.detectors):
                 if not isnan(t_detector):
                     dx, dy, dz = detector.get_coordinates()
                     t.append(t_detector)
                     x.append(dx)
                     y.append(dy)
                     z.append(dz)
@@ -421,15 +401,14 @@
         else:
             theta, phi = (nan, nan)
 
         return theta, phi, nums
 
 
 class BaseDirectionAlgorithm:
-
     """No actual direction reconstruction algorithm
 
     Simply returns (nan, nan) as direction.
 
     """
 
     @classmethod
@@ -453,15 +432,14 @@
         :return: reconstructed theta and phi angles.
 
         """
         return (nan, nan)
 
 
 class DirectAlgorithm(BaseDirectionAlgorithm):
-
     """Reconstruct angles using direct analytical formula.
 
     This implements the equations derived in Fokkema2012 sec 4.2.
     (DOI: 10.3990/1.9789036534383)
 
     This algorithm assumes each detector is at the same altitude.
 
@@ -510,27 +488,26 @@
                  phi as given by Fokkema2012 eq 4.13.
 
         """
         if dt1 == 0 and dt2 == 0:
             # No time difference means shower came from zenith.
             return 0, 0
 
-        phi = arctan2(-(r1 * dt2 * cos(phi1) - r2 * dt1 * cos(phi2)),
-                      (r1 * dt2 * sin(phi1) - r2 * dt1 * sin(phi2)))
+        phi = arctan2(-(r1 * dt2 * cos(phi1) - r2 * dt1 * cos(phi2)), (r1 * dt2 * sin(phi1) - r2 * dt1 * sin(phi2)))
 
         # The directional vector c * dt should be negative,
         # not apparent in Fokkema2012 fig 4.4.
         theta = nan
         if r1 == 0 or r2 == 0:
             pass
-        elif not dt1 == 0 and not phi - phi1 == pi / 2:
+        elif dt1 != 0 and phi - phi1 != pi / 2:
             sintheta = c * -dt1 / (r1 * cos(phi - phi1))
             if abs(sintheta) <= 1:
                 theta = arcsin(sintheta)
-        elif not dt2 == 0 and not phi - phi2 == pi / 2:
+        elif dt2 != 0 and phi - phi2 != pi / 2:
             sintheta = c * -dt2 / (r2 * cos(phi - phi2))
             if abs(sintheta) <= 1:
                 theta = arcsin(sintheta)
 
         # We limit theta to positive values.  If theta is negative, we
         # make it positive, but need to rotate phi by 180 degrees.
         if isnan(theta):
@@ -545,115 +522,118 @@
     @classmethod
     def rel_theta1_errorsq(cls, theta, phi, phi1, phi2, r1=10, r2=10):
         """Fokkema2012, eq 4.23"""
 
         sintheta = sin(theta)
         sinphiphi1 = sin(phi - phi1)
 
-        den = r1 ** 2 * (1 - sintheta ** 2) * cos(phi - phi1) ** 2
+        den = r1**2 * (1 - sintheta**2) * cos(phi - phi1) ** 2
 
-        aa = (r1 ** 2 * sinphiphi1 ** 2 *
-              cls.rel_phi_errorsq(theta, phi, phi1, phi2, r1, r2))
-        bb = -(2 * r1 * c * sinphiphi1 *
-               (cls.dphi_dt0(theta, phi, phi1, phi2, r1, r2) -
-                cls.dphi_dt1(theta, phi, phi1, phi2, r1, r2)))
-        cc = 2 * c ** 2
+        aa = r1**2 * sinphiphi1**2 * cls.rel_phi_errorsq(theta, phi, phi1, phi2, r1, r2)
+        bb = -(
+            2
+            * r1
+            * c
+            * sinphiphi1
+            * (cls.dphi_dt0(theta, phi, phi1, phi2, r1, r2) - cls.dphi_dt1(theta, phi, phi1, phi2, r1, r2))
+        )
+        cc = 2 * c**2
 
-        errsq = (aa * sintheta ** 2 + bb * sintheta + cc) / den
+        errsq = (aa * sintheta**2 + bb * sintheta + cc) / den
 
         return where(isnan(errsq), inf, errsq)
 
     @classmethod
     def rel_theta2_errorsq(cls, theta, phi, phi1, phi2, r1=10, r2=10):
         """Fokkema2012, eq 4.23"""
 
         sintheta = sin(theta)
         sinphiphi2 = sin(phi - phi2)
 
-        den = r2 ** 2 * (1 - sintheta ** 2) * cos(phi - phi2) ** 2
+        den = r2**2 * (1 - sintheta**2) * cos(phi - phi2) ** 2
 
-        aa = (r2 ** 2 * sinphiphi2 ** 2 *
-              cls.rel_phi_errorsq(theta, phi, phi1, phi2, r1, r2))
-        bb = -(2 * r2 * c * sinphiphi2 *
-               (cls.dphi_dt0(theta, phi, phi1, phi2, r1, r2) -
-                cls.dphi_dt2(theta, phi, phi1, phi2, r1, r2)))
-        cc = 2 * c ** 2
+        aa = r2**2 * sinphiphi2**2 * cls.rel_phi_errorsq(theta, phi, phi1, phi2, r1, r2)
+        bb = -(
+            2
+            * r2
+            * c
+            * sinphiphi2
+            * (cls.dphi_dt0(theta, phi, phi1, phi2, r1, r2) - cls.dphi_dt2(theta, phi, phi1, phi2, r1, r2))
+        )
+        cc = 2 * c**2
 
-        errsq = (aa * sintheta ** 2 + bb * sintheta + cc) / den
+        errsq = (aa * sintheta**2 + bb * sintheta + cc) / den
 
         return where(isnan(errsq), inf, errsq)
 
     @staticmethod
     def rel_phi_errorsq(theta, phi, phi1, phi2, r1=10, r2=10):
         """Fokkema2012, eq 4.22"""
 
         tanphi = tan(phi)
         sinphi1 = sin(phi1)
         cosphi1 = cos(phi1)
         sinphi2 = sin(phi2)
         cosphi2 = cos(phi2)
 
-        den = ((1 + tanphi ** 2) ** 2 * r1 ** 2 * r2 ** 2 * sin(theta) ** 2 *
-               (sinphi1 * cos(phi - phi2) - sinphi2 * cos(phi - phi1)) ** 2 /
-               c ** 2)
-
-        aa = (r1 ** 2 * sinphi1 ** 2 +
-              r2 ** 2 * sinphi2 ** 2 -
-              r1 * r2 * sinphi1 * sinphi2)
-        bb = (2 * r1 ** 2 * sinphi1 * cosphi1 +
-              2 * r2 ** 2 * sinphi2 * cosphi2 -
-              r1 * r2 * (sinphi2 * cosphi1 + sinphi1 * cosphi2))
-        cc = (r1 ** 2 * cosphi1 ** 2 +
-              r2 ** 2 * cosphi2 ** 2 -
-              r1 * r2 * cosphi1 * cosphi2)
+        den = (
+            (1 + tanphi**2) ** 2
+            * r1**2
+            * r2**2
+            * sin(theta) ** 2
+            * (sinphi1 * cos(phi - phi2) - sinphi2 * cos(phi - phi1)) ** 2
+            / c**2
+        )
+
+        aa = r1**2 * sinphi1**2 + r2**2 * sinphi2**2 - r1 * r2 * sinphi1 * sinphi2
+        bb = (
+            2 * r1**2 * sinphi1 * cosphi1
+            + 2 * r2**2 * sinphi2 * cosphi2
+            - r1 * r2 * (sinphi2 * cosphi1 + sinphi1 * cosphi2)
+        )
+        cc = r1**2 * cosphi1**2 + r2**2 * cosphi2**2 - r1 * r2 * cosphi1 * cosphi2
 
-        return 2 * (aa * tanphi ** 2 + bb * tanphi + cc) / den
+        return 2 * (aa * tanphi**2 + bb * tanphi + cc) / den
 
     @classmethod
     def dphi_dt0(cls, theta, phi, phi1, phi2, r1=10, r2=10):
         """Fokkema2012, eq 4.19"""
 
-        return -(cls.dphi_dt1(theta, phi, phi1, phi2, r1, r2) +
-                 cls.dphi_dt2(theta, phi, phi1, phi2, r1, r2))
+        return -(cls.dphi_dt1(theta, phi, phi1, phi2, r1, r2) + cls.dphi_dt2(theta, phi, phi1, phi2, r1, r2))
 
     @staticmethod
     def dphi_dt1(theta, phi, phi1, phi2, r1=10, r2=10):
         """Fokkema2012, eq 4.20"""
 
         tanphi = tan(phi)
         sinphi1 = sin(phi1)
         sinphi2 = sin(phi2)
         cosphi2 = cos(phi2)
 
-        den = ((1 + tanphi ** 2) * r1 * r2 * sin(theta) *
-               (sinphi2 * cos(phi - phi1) - sinphi1 * cos(phi - phi2)) /
-               c)
+        den = (1 + tanphi**2) * r1 * r2 * sin(theta) * (sinphi2 * cos(phi - phi1) - sinphi1 * cos(phi - phi2)) / c
         num = -r2 * (sinphi2 * tanphi + cosphi2)
 
         return num / den
 
     @staticmethod
     def dphi_dt2(theta, phi, phi1, phi2, r1=10, r2=10):
         """Fokkema2012, eq 4.21"""
 
         tanphi = tan(phi)
         sinphi1 = sin(phi1)
         cosphi1 = cos(phi1)
         sinphi2 = sin(phi2)
 
-        den = ((1 + tanphi ** 2) * r1 * r2 * sin(theta) *
-               (sinphi2 * cos(phi - phi1) - sinphi1 * cos(phi - phi2)) /
-               c)
+        den = (1 + tanphi**2) * r1 * r2 * sin(theta) * (sinphi2 * cos(phi - phi1) - sinphi1 * cos(phi - phi2)) / c
         num = r1 * (sinphi1 * tanphi + cosphi1)
 
         return num / den
 
 
 class DirectAlgorithmCartesian(BaseDirectionAlgorithm):
-
     """Reconstruct angles using direct analytical formula.
 
     This implements the equations derived in Montanus2014.
     "Direction reconstruction of cosmic air showers with
     detectorstations at different altitudes"
 
     Here the 2D version is used, assuming each detector is at the same
@@ -700,27 +680,26 @@
         uy = c * (dt2 * dy1 - dt1 * dy2)
 
         vz = dx1 * dy2 - dx2 * dy1
 
         theta = nan
         phi = nan
 
-        if not vz == 0:
+        if vz != 0:
             usquared = ux * ux + uy * uy
             vzsquared = vz * vz
             uvzsqrt = sqrt(usquared / vzsquared)
             if uvzsqrt <= 1.0:
                 theta = arcsin(uvzsqrt)
                 phi = arctan2(-ux * vz, uy * vz)
 
         return theta, phi
 
 
 class DirectAlgorithmCartesian3D(BaseDirectionAlgorithm):
-
     """Reconstruct angles using direct analytical formula.
 
     This implements the equations derived in Montanus2014.
     "Direction reconstruction of cosmic air showers with
     detectorstations at different altitudes"
 
     Here the 3D version is used, assuming each detector is at the same
@@ -748,16 +727,15 @@
             warning_only_three()
 
         dt = make_relative(t)
         dx = make_relative(x)
         dy = make_relative(y)
         dz = make_relative(z)
 
-        return cls.reconstruct(dt[1], dt[2], dx[1], dx[2], dy[1], dy[2], dz[1],
-                               dz[2])
+        return cls.reconstruct(dt[1], dt[2], dx[1], dx[2], dy[1], dy[2], dz[1], dz[2])
 
     @staticmethod
     def reconstruct(dt1, dt2, dx1, dx2, dy1, dy2, dz1=0, dz2=0):
         """Reconstruct angles from 3 detections
 
         :param dt#: arrival times in detector 1 and 2 relative to
                     detector 0 in ns.
@@ -776,15 +754,15 @@
         usquared = dot(u, u)
         vsquared = dot(v, v)
         underroot = vsquared - usquared
 
         theta = nan
         phi = nan
 
-        if underroot > 0 and not vsquared == 0:
+        if underroot > 0 and vsquared != 0:
             term = v * sqrt(underroot)
             nplus = (uxv + term) / vsquared
             nmin = (uxv - term) / vsquared
 
             phiplus = arctan2(nplus[1], nplus[0])
             thetaplus = arccos(nplus[2])
 
@@ -794,26 +772,25 @@
             if isnan(thetaplus):
                 thetaplus = pi
 
             if isnan(thetamin):
                 thetamin = pi
 
             # Allow solution only if it is the only one above horizon
-            if thetaplus <= pi / 2. and thetamin > pi / 2.:
+            if thetaplus <= pi / 2.0 and thetamin > pi / 2.0:
                 theta = thetaplus
                 phi = phiplus
-            elif thetaplus > pi / 2. and thetamin <= pi / 2.:
+            elif thetaplus > pi / 2.0 and thetamin <= pi / 2.0:
                 theta = thetamin
                 phi = phimin
 
         return theta, phi
 
 
 class SphereAlgorithm:
-
     """Reconstruct the direction in equatorial coordinates
 
     Note: currently incompatible with the other algorithms!
 
     This class uses a different coordinate systems than the other
     algorithms. The location input is in ECEF coordinates and a
     timestamp is required to connect the direction to the equatorial
@@ -832,17 +809,15 @@
         :return: declination and right ascension of the source. The
                  apparent location of the cosmic ray source in the
                  Equatorial Coordinate System.
 
         """
         t_int = array([-1000, -10000]) + t[0]
         x_int, y_int, z_int = cls.interaction_curve(x, y, z, t, t_int)
-        dec = arctan2(z_int[1] - z_int[0],
-                      sqrt((x_int[1] - x_int[0]) ** 2. +
-                           (y_int[1] - y_int[0]) ** 2.))
+        dec = arctan2(z_int[1] - z_int[0], sqrt((x_int[1] - x_int[0]) ** 2.0 + (y_int[1] - y_int[0]) ** 2.0))
         ra = arctan2(x_int[1] - x_int[0], y_int[1] - y_int[0])
         return dec, ra
 
     @staticmethod
     def interaction_curve(x, y, z, t, t_int):
         """Calculates the curve of possible primary interactions
 
@@ -862,67 +837,60 @@
         y01 = y[0] - y[1]
         y02 = y[0] - y[2]
         z01 = z[0] - z[1]
         z02 = z[0] - z[2]
         t01 = t[0] - t[1]
         t02 = t[0] - t[2]
 
-        a = 2. * (x01 * y02 - x02 * y01)
-        b = 2. * (x02 * z01 - x01 * z02)
-        h = 2. * (x02 * t01 - x01 * t02) * c ** 2
-        d = (x02 * (x01 ** 2 + y01 ** 2 + z01 ** 2 - (t01 * c) ** 2) -
-             x01 * (x02 ** 2 + y02 ** 2 + z02 ** 2 - (t02 * c) ** 2))
-        e = 2. * (y01 * z02 - y02 * z01)
-        f = 2. * (y01 * t02 - y02 * t01) * c ** 2
-        g = (y01 * (x02 ** 2 + y02 ** 2 + z02 ** 2 - (t02 * c) ** 2) -
-             y02 * (x01 ** 2 + y01 ** 2 + z01 ** 2 - (t01 * c) ** 2))
+        a = 2.0 * (x01 * y02 - x02 * y01)
+        b = 2.0 * (x02 * z01 - x01 * z02)
+        h = 2.0 * (x02 * t01 - x01 * t02) * c**2
+        d = x02 * (x01**2 + y01**2 + z01**2 - (t01 * c) ** 2) - x01 * (x02**2 + y02**2 + z02**2 - (t02 * c) ** 2)
+        e = 2.0 * (y01 * z02 - y02 * z01)
+        f = 2.0 * (y01 * t02 - y02 * t01) * c**2
+        g = y01 * (x02**2 + y02**2 + z02**2 - (t02 * c) ** 2) - y02 * (x01**2 + y01**2 + z01**2 - (t01 * c) ** 2)
 
-        t = a ** 2 + b ** 2 + e ** 2
+        t = a**2 + b**2 + e**2
         v = (b * h + e * f) / t
         w = (b * d + e * g) / t
-        p = (d ** 2 + g ** 2) / t
+        p = (d**2 + g**2) / t
         q = 2 * (h * d + f * g) / t
-        r = (h ** 2 + f ** 2 - (a * c) ** 2) / t
+        r = (h**2 + f**2 - (a * c) ** 2) / t
 
         t_int0 = t_int - t[0]
 
         sign = 1
 
-        z = -v * t_int0 - w + sign * sqrt((v ** 2 - r) * t_int0 ** 2 +
-                                          (2 * v * w - q) * t_int0 +
-                                          w ** 2 - p)
+        z = -v * t_int0 - w + sign * sqrt((v**2 - r) * t_int0**2 + (2 * v * w - q) * t_int0 + w**2 - p)
         y = (b * z + h * t_int0 + d) / a
         x = (e * z + f * t_int0 + g) / a
 
         x_int = x[0] + x
         y_int = y[0] + y
         z_int = z[0] + z
 
         int_length = vector_length(x_int[0], y_int[0], z_int[0])
         det_length = vector_length(x[0], y[0], z[0])
 
         if det_length > int_length:
             # Select interaction above the earths surface.
 
             sign = -1
-            z = -v * t_int0 - w + sign * sqrt((v ** 2 - r) * t_int0 ** 2 +
-                                              (2 * v * w - q) * t_int0 +
-                                              w ** 2 - p)
+            z = -v * t_int0 - w + sign * sqrt((v**2 - r) * t_int0**2 + (2 * v * w - q) * t_int0 + w**2 - p)
             y = (b * z + h * t_int0 + d) / a
             x = (e * z + f * t_int0 + g) / a
 
             x_int = x[0] + x
             y_int = y[0] + y
             z_int = z[0] + z
 
         return x_int, y_int, z_int, t_int
 
 
 class FitAlgorithm3D(BaseDirectionAlgorithm):
-
     @classmethod
     def reconstruct_common(cls, t, x, y, z=None, initial=None):
         """Reconstruct angles from 3 or more detections
 
         This function converts the arguments to be suitable for the
         algorithm.
 
@@ -954,46 +922,54 @@
         dt = make_relative(t)[1:]
         dx = make_relative(x)[1:]
         dy = make_relative(y)[1:]
         dz = make_relative(z)[1:]
 
         cons = {'type': 'eq', 'fun': cls.constraint_normal_vector}
 
-        fit = minimize(cls.best_fit, x0=(0.1, 0.1, 0.989, 0.),
-                       args=(dt, dx, dy, dz), method="SLSQP",
-                       bounds=((-1, 1), (-1, 1), (-1, 1), (None, None)),
-                       constraints=cons,
-                       options={'ftol': 1e-9, 'eps': 1e-7, 'maxiter': 50})
+        fit = minimize(
+            cls.best_fit,
+            x0=(0.1, 0.1, 0.989, 0.0),
+            args=(dt, dx, dy, dz),
+            method='SLSQP',
+            bounds=((-1, 1), (-1, 1), (-1, 1), (None, None)),
+            constraints=cons,
+            options={'ftol': 1e-9, 'eps': 1e-7, 'maxiter': 50},
+        )
         if fit.success:
             phi1 = arctan2(fit.x[1], fit.x[0])
             theta1 = arccos(fit.x[2])
         else:
             phi1 = nan
             theta1 = nan
 
-        fit = minimize(cls.best_fit, x0=(-0.1, -0.1, -0.989, 0.),
-                       args=(dt, dx, dy, dz), method="SLSQP",
-                       bounds=((-1, 1), (-1, 1), (-1, 1), (None, None)),
-                       constraints=cons,
-                       options={'ftol': 1e-9, 'eps': 1e-7, 'maxiter': 50})
+        fit = minimize(
+            cls.best_fit,
+            x0=(-0.1, -0.1, -0.989, 0.0),
+            args=(dt, dx, dy, dz),
+            method='SLSQP',
+            bounds=((-1, 1), (-1, 1), (-1, 1), (None, None)),
+            constraints=cons,
+            options={'ftol': 1e-9, 'eps': 1e-7, 'maxiter': 50},
+        )
         if fit.success:
             phi2 = arctan2(fit.x[1], fit.x[0])
             theta2 = arccos(fit.x[2])
         else:
             phi2 = nan
             theta2 = nan
 
         # In case one of the theta's is smaller than pi/2 (shower from above)
         # and the other is either nan or larger than pi/2 (shower from below),
         # the first one is considered correct.
         # If both come from above (or from below), both theta's are rejected.
-        if theta1 <= pi / 2. and (isnan(theta2) or theta2 > pi / 2.):
+        if theta1 <= pi / 2.0 and (isnan(theta2) or theta2 > pi / 2.0):
             theta = theta1
             phi = phi1
-        elif (isnan(theta1) or theta1 > pi / 2.) and theta2 <= pi / 2.:
+        elif (isnan(theta1) or theta1 > pi / 2.0) and theta2 <= pi / 2.0:
             theta = theta2
             phi = phi2
         else:
             theta = nan
             phi = nan
 
         return theta, phi
@@ -1012,23 +988,19 @@
         :param dt: list of relative arrival times in the detectors in ns.
         :param dx,dy,dz: list of relative detector positions in m.
         :return: least sum of squares as in Montanus2014, eq 36
 
         """
         nx, ny, nz, m = n_xyz
 
-        slq = sum(
-            (nx * xi + ny * yi + zi * nz + c * ti + m) ** 2
-            for ti, xi, yi, zi in zip(dt, dx, dy, dz)
-        )
+        slq = sum((nx * xi + ny * yi + zi * nz + c * ti + m) ** 2 for ti, xi, yi, zi in zip(dt, dx, dy, dz))
         return slq + m * m
 
 
 class RegressionAlgorithm(BaseDirectionAlgorithm):
-
     """Reconstruct angles using an analytical regression formula.
 
     This implements the equations as for ISVHECRI (Montanus 2014).
     "Direction reconstruction of cosmic air showers with
     three or more detectorstations in a horizontal (for the
     moment) plane"
 
@@ -1060,58 +1032,54 @@
                  phi as derived by Montanus2014.
 
         """
         if not logic_checks(t, x, y, [0] * len(t)):
             return nan, nan
 
         k = len(t)
-        xs = numpy.sum(x)
-        ys = numpy.sum(y)
-        ts = numpy.sum(t)
-
-        xx = 0.
-        yy = 0.
-        tx = 0.
-        ty = 0.
-        xy = 0.
+        xs = np.sum(x)
+        ys = np.sum(y)
+        ts = np.sum(t)
+
+        xx = 0.0
+        yy = 0.0
+        tx = 0.0
+        ty = 0.0
+        xy = 0.0
 
         for ti, xi, yi in zip(t, x, y):
-            xx += xi ** 2
-            yy += yi ** 2
+            xx += xi**2
+            yy += yi**2
             tx += ti * xi
             ty += ti * yi
             xy += xi * yi
 
-        denom = (k * xy ** 2 + xs ** 2 * yy + ys ** 2 * xx - k * xx * yy -
-                 2 * xs * ys * xy)
+        denom = k * xy**2 + xs**2 * yy + ys**2 * xx - k * xx * yy - 2 * xs * ys * xy
         if denom == 0:
             denom = nan
 
-        numer = (tx * (k * yy - ys ** 2) + xy * (ts * ys - k * ty) +
-                 xs * ys * ty - ts * xs * yy)
+        numer = tx * (k * yy - ys**2) + xy * (ts * ys - k * ty) + xs * ys * ty - ts * xs * yy
         nx = c * numer / denom
 
-        numer = (ty * (k * xx - xs ** 2) + xy * (ts * xs - k * tx) +
-                 xs * ys * tx - ts * ys * xx)
+        numer = ty * (k * xx - xs**2) + xy * (ts * xs - k * tx) + xs * ys * tx - ts * ys * xx
         ny = c * numer / denom
 
-        horiz = nx ** 2 + ny ** 2
-        if horiz > 1.:
+        horiz = nx**2 + ny**2
+        if horiz > 1.0:
             theta = nan
             phi = nan
         else:
-            nz = sqrt(1 - nx ** 2 - ny ** 2)
+            nz = sqrt(1 - nx**2 - ny**2)
             phi = arctan2(ny, nx)
             theta = arccos(nz)
 
         return theta, phi
 
 
 class RegressionAlgorithm3D(BaseDirectionAlgorithm):
-
     """Reconstruct angles by iteratively applying a regression formula.
 
     This implements the equations as recently derived (Montanus 2014).
     "Direction reconstruction of cosmic air showers with
     three or more detectorstations at arbitrary altitudes"
 
     """
@@ -1149,15 +1117,15 @@
         """
         if not logic_checks(t, x, y, z):
             return nan, nan
 
         regress2d = RegressionAlgorithm()
         theta, phi = regress2d.reconstruct_common(t, x, y)
 
-        dtheta = 1.
+        dtheta = 1.0
         iteration = 0
         while dtheta > 0.001:
             iteration += 1
             if iteration > cls.MAX_ITERATIONS:
                 return nan, nan
             nxnz = tan(theta) * cos(phi)
             nynz = tan(theta) * sin(phi)
@@ -1169,15 +1137,14 @@
             theta, phi = regress2d.reconstruct_common(t_proj, x_proj, y_proj)
             dtheta = abs(theta - theta_prev)
 
         return theta, phi
 
 
 class CurvedMixin:
-
     """Provide methods to estimate the time delay due to front curvature
 
     Given a core location, detector position, and shower angle the radial core
     distance can be determined, which can be used to determine the expected
     time delay.
 
     """
@@ -1196,20 +1163,18 @@
         :return: radial core distance in m.
 
         """
         dx = core_x - x
         dy = core_y - y
         nx = sin(theta) * cos(phi)
         ny = sin(theta) * sin(phi)
-        return sqrt(dx ** 2 * (1 - nx ** 2) + dy ** 2 * (1 - ny ** 2) -
-                    2 * dx * dy * nx * ny)
+        return sqrt(dx**2 * (1 - nx**2) + dy**2 * (1 - ny**2) - 2 * dx * dy * nx * ny)
 
 
 class CurvedRegressionAlgorithm(CurvedMixin, BaseDirectionAlgorithm):
-
     """Reconstruct angles taking the shower front curvature into account.
 
     Take the shower front curvature into account. Assumes knowledge about the
     shower core position.
 
     """
 
@@ -1252,31 +1217,29 @@
         """
         if not logic_checks(t, x, y, [0] * len(t)):
             return nan, nan
 
         regress2d = RegressionAlgorithm()
         theta, phi = regress2d.reconstruct_common(t, x, y)
 
-        dtheta = 1.
+        dtheta = 1.0
         iteration = 0
         while dtheta > 0.001:
             iteration += 1
             if iteration > self.MAX_ITERATIONS:
                 return nan, nan
-            t_proj = [ti - self.time_delay(xi, yi, core_x, core_y, theta, phi)
-                      for ti, xi, yi in zip(t, x, y)]
+            t_proj = [ti - self.time_delay(xi, yi, core_x, core_y, theta, phi) for ti, xi, yi in zip(t, x, y)]
             theta_prev = theta
             theta, phi = regress2d.reconstruct_common(t_proj, x, y)
             dtheta = abs(theta - theta_prev)
 
         return theta, phi
 
 
 class CurvedRegressionAlgorithm3D(CurvedMixin, BaseDirectionAlgorithm):
-
     """Reconstruct angles accounting for front curvature and detector altitudes
 
     Take the shower front curvature and different detector heights into
     account. Assumes knowledge about the shower core position.
 
     """
 
@@ -1322,28 +1285,29 @@
         """
         if not logic_checks(t, x, y, z):
             return nan, nan
 
         regress2d = RegressionAlgorithm()
         theta, phi = regress2d.reconstruct_common(t, x, y)
 
-        dtheta = 1.
+        dtheta = 1.0
         iteration = 0
         while dtheta > 0.001:
             iteration += 1
             if iteration > self.MAX_ITERATIONS:
                 return nan, nan
             nxnz = tan(theta) * cos(phi)
             nynz = tan(theta) * sin(phi)
             nz = cos(theta)
             x_proj = [xi - zi * nxnz for xi, zi in zip(x, z)]
             y_proj = [yi - zi * nynz for yi, zi in zip(y, z)]
-            t_proj = [ti + zi / (c * nz) -
-                      self.time_delay(xpi, ypi, core_x, core_y, theta, phi)
-                      for ti, xpi, ypi, zi in zip(t, x_proj, y_proj, z)]
+            t_proj = [
+                ti + zi / (c * nz) - self.time_delay(xpi, ypi, core_x, core_y, theta, phi)
+                for ti, xpi, ypi, zi in zip(t, x_proj, y_proj, z)
+            ]
             theta_prev = theta
             theta, phi = regress2d.reconstruct_common(t_proj, x_proj, y_proj)
             dtheta = abs(theta - theta_prev)
 
         return theta, phi
 
 
@@ -1365,15 +1329,15 @@
     :param x,y,z: positions of the detectors in m.
     :return: True if the checks pass, False otherwise.
 
     """
     # Check for identical positions
     if len(t) == 3:
         xyz = list(zip(x, y, z))
-        if not len(xyz) == len(set(xyz)):
+        if len(xyz) != len(set(xyz)):
             return False
 
     txyz = list(zip(t, x, y, z))
 
     # Check if the time difference it larger than expected by c
     if len(t) == 3:
         for txyz0, txyz1 in combinations(txyz, 2):
@@ -1398,32 +1362,30 @@
         dy3 = dy2 - dy1
         dz3 = dz2 - dz1
         lenvec01 = vector_length(dx1, dy1, dz1)
         lenvec02 = vector_length(dx2, dy2, dz2)
         lenvec12 = vector_length(dx3, dy3, dz3)
 
         # area triangle is |cross product|
-        area = abs(dx1 * dy2 - dx2 * dy1 + dy1 * dz2 - dy2 * dz1 +
-                   dz1 * dx2 - dz2 * dx1)
+        area = abs(dx1 * dy2 - dx2 * dy1 + dy1 * dz2 - dy2 * dz1 + dz1 * dx2 - dz2 * dx1)
 
         # prevent floating point errors
         if area < 1e-7:
             return False
 
         # sine of angle is area divided by two sides
         sin1 = area / lenvec01 / lenvec02
         sin2 = area / lenvec01 / lenvec12
         sin3 = area / lenvec02 / lenvec12
 
         # smallest sine
         smallest_angle = min(sin1, sin2, sin3)
 
         # remember largest of smallest sines
-        largest_of_smallest_angles = max(largest_of_smallest_angles,
-                                         smallest_angle)
+        largest_of_smallest_angles = max(largest_of_smallest_angles, smallest_angle)
 
     # discard reconstruction if the largest of the smallest angles of each
     # triangle is smaller than 0.1 rad (5.73 degrees)
     if largest_of_smallest_angles < 0.1:
         return False
 
     return True
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/event_utils.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/event_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,21 +1,22 @@
-""" Get data from HiSPARC events
+"""Get data from HiSPARC events
 
 This module contains functions to derive data from HiSPARC events.
 Common tasks for data reconstruction are getting the particle density
 and shower arrival time in detectors or a station. These functions are
 aware of processed events (i.e. reconstructed number of MIPs, arrival
 times and trigger time) and stations.
 
 """
+
 from numpy import nan, nanmean, nanmin
 
 from ..utils import ERR
 
-NO_OFFSET = [0., 0., 0., 0.]
+NO_OFFSET = [0.0, 0.0, 0.0, 0.0]
 
 
 def station_density(event, detector_ids=None, station=None):
     """Get particle density in a station
 
     Detectors with error values will be ignored.
 
@@ -24,16 +25,15 @@
         detectors in the station object will be used.
     :param station: :class:`sapphire.clusters.Station` object.
     :return: average density over the chosen detectors.
 
     """
     if detector_ids is None:
         detector_ids = get_detector_ids(station, event)
-    p = nanmean(detector_densities(event, detector_ids=detector_ids,
-                                   station=station))
+    p = nanmean(detector_densities(event, detector_ids=detector_ids, station=station))
     return p
 
 
 def detector_densities(event, detector_ids=None, station=None):
     """Get particle density in station detectors
 
     :param event: Processed event row.
@@ -41,15 +41,15 @@
         densities.
     :param station: :class:`sapphire.clusters.Station` object.
     :return: density in each chosen detector.
 
     """
     if detector_ids is None:
         detector_ids = get_detector_ids(station, event)
-    p = [detector_density(event, id, station) for id in detector_ids]
+    p = [detector_density(event, detector_id, station) for detector_id in detector_ids]
     return p
 
 
 def detector_density(event, detector_id, station=None):
     """Get particle density in station detector
 
     :param event: Processed event row.
@@ -67,16 +67,15 @@
     if number_of_particles not in ERR:
         p = number_of_particles / area
     else:
         p = nan
     return p
 
 
-def station_arrival_time(event, reference_ext_timestamp,
-                         detector_ids=None, offsets=NO_OFFSET, station=None):
+def station_arrival_time(event, reference_ext_timestamp, detector_ids=None, offsets=NO_OFFSET, station=None):
     """Get station arrival time, i.e. first detector hit
 
     Arrival time of first detector hit in the station. The returned time
     is relative to reference_ext_timestamp, because floats do not have
     enough precision to represent large timestamps in nanoseconds.
 
     :param event: Processed event row.
@@ -92,24 +91,20 @@
 
     """
     if detector_ids is None:
         detector_ids = get_detector_ids(station, event)
     if event['t_trigger'] in ERR:
         t = nan
     else:
-        t_first = nanmin(detector_arrival_times(event, detector_ids, offsets,
-                                                station))
-        t = ((int(event['ext_timestamp']) - int(reference_ext_timestamp)) -
-             event['t_trigger'] + t_first)
+        t_first = nanmin(detector_arrival_times(event, detector_ids, offsets, station))
+        t = (int(event['ext_timestamp']) - int(reference_ext_timestamp)) - event['t_trigger'] + t_first
     return t
 
 
-def relative_detector_arrival_times(event, reference_ext_timestamp,
-                                    detector_ids=None, offsets=NO_OFFSET,
-                                    station=None):
+def relative_detector_arrival_times(event, reference_ext_timestamp, detector_ids=None, offsets=NO_OFFSET, station=None):
     """Get relative arrival times for all detectors
 
     :param event: Processed event row.
     :param reference_ext_timestamp: reference extended timestamp (in ns).
         The returned station arrival time will be relative to this timestamp.
         Often best to use the timestamp of the first event in a coincidence.
     :param detector_ids: list of detectors ids for which to get arrival times.
@@ -120,37 +115,36 @@
 
     """
     if detector_ids is None:
         detector_ids = get_detector_ids(station, event)
     if event['t_trigger'] in ERR:
         t = [nan] * len(detector_ids)
     else:
-        arrival_times = detector_arrival_times(event, detector_ids,
-                                               offsets, station)
-        t = [(int(event['ext_timestamp']) - int(reference_ext_timestamp)) -
-             event['t_trigger'] + arrival_time
-             for arrival_time in arrival_times]
+        arrival_times = detector_arrival_times(event, detector_ids, offsets, station)
+        t = [
+            (int(event['ext_timestamp']) - int(reference_ext_timestamp)) - event['t_trigger'] + arrival_time
+            for arrival_time in arrival_times
+        ]
     return t
 
 
-def detector_arrival_times(event, detector_ids=None, offsets=NO_OFFSET,
-                           station=None):
+def detector_arrival_times(event, detector_ids=None, offsets=NO_OFFSET, station=None):
     """Get corrected arrival times for all detectors
 
     :param event: Processed event row.
     :param detector_ids: list of detectors ids for which to get arrival times.
     :param offsets: list of detector time offsets.
     :param station: :class:`sapphire.clusters.Station` object, used to
         determine the number of detectors.
     :return: list of shower arrival times relative to the start of the trace.
 
     """
     if detector_ids is None:
         detector_ids = get_detector_ids(station, event)
-    t = [detector_arrival_time(event, id, offsets) for id in detector_ids]
+    t = [detector_arrival_time(event, detector_id, offsets) for detector_id in detector_ids]
     return t
 
 
 def detector_arrival_time(event, detector_id, offsets=NO_OFFSET):
     """Get corrected arrival time for a detector
 
     :param event: Event row.
@@ -179,12 +173,11 @@
     :param station: :class:`sapphire.clusters.Station` object.
     :return: list of detector_ids.
 
     """
     if station is not None:
         detector_ids = list(range(len(station.detectors)))
     elif event is not None:
-        detector_ids = [i for i, ph in enumerate(event['pulseheights'])
-                        if ph != -1]
+        detector_ids = [i for i, ph in enumerate(event['pulseheights']) if ph != -1]
     else:
         detector_ids = list(range(4))
     return detector_ids
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/find_mpv.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/find_mpv.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """Find the most probable value in a HiSPARC spectrum.
 
 :class:`FindMostProbableValueInSpectrum`
    find the most probable value in a HiSPARC spectrum
 
 """
+
 import warnings
 
 from scipy.optimize import curve_fit
 
 from ..utils import gauss
 
 MPV_FIT_WIDTH_FACTOR = 0.4
@@ -58,15 +59,15 @@
         :return boolean is_fitted: indicates if the fit was successful.
 
         """
         first_guess = self.find_first_guess_mpv()
         try:
             mpv = self.fit_mpv(first_guess)
         except RuntimeError:
-            warnings.warn("Fit failed")
+            warnings.warn('Fit failed')
             return -999, False
         else:
             return mpv, True
 
     def find_first_guess_mpv(self):
         """First guess of most probable value.
 
@@ -97,15 +98,15 @@
         cut_cut_n = cut_n[idx_greatest_decrease:]
 
         # estimate most probable value with maximum in bracketed data
         idx_right_max = cut_cut_n.argmax()
 
         # calculate position of most probable value
         idx_mpv = idx_right_max + idx_greatest_decrease + left_idx
-        mpv = (bins[idx_mpv] + bins[idx_mpv + 1]) / 2.
+        mpv = (bins[idx_mpv] + bins[idx_mpv + 1]) / 2.0
 
         return mpv
 
     def fit_mpv(self, first_guess, width_factor=MPV_FIT_WIDTH_FACTOR):
         """Fit a normal distribution to the MIP peak to obtain the MPV.
 
         A normal distribution is fitted to the spectrum in a restricted
@@ -119,33 +120,32 @@
             ``[(1. - width_factor) * first_guess, (1. + width_factor) *
             first_guess]``.
         :return mpv: mpv value obtained from the fit.
 
         """
         n, bins = self.n, self.bins
 
-        bins_x = (bins[:-1] + bins[1:]) / 2.
+        bins_x = (bins[:-1] + bins[1:]) / 2.0
 
         # calculate fit domain
-        left = (1. - width_factor) * first_guess
-        right = (1. + width_factor) * first_guess
+        left = (1.0 - width_factor) * first_guess
+        right = (1.0 + width_factor) * first_guess
 
         # bracket histogram data
         x = bins_x.compress((left <= bins_x) & (bins_x < right))
         y = n.compress((left <= bins_x) & (bins_x < right))
 
         # sanity check: number of data points must be at least equal to
         # the number of fit parameters
         if len(x) < 3:
-            raise RuntimeError("Number of data points not sufficient")
+            raise RuntimeError('Number of data points not sufficient')
 
         # fit to a normal distribution
-        popt, pcov = curve_fit(gauss, x, y,
-                               p0=(y.max(), first_guess, first_guess))
+        popt, pcov = curve_fit(gauss, x, y, p0=(y.max(), first_guess, first_guess))
         mpv = popt[1]
 
         # sanity check: if MPV is outside domain, the MIP peak was not
         # bracketed correctly
         if mpv < x[0] or mpv > x[-1]:
-            raise RuntimeError("Fitted MPV value outside range")
+            raise RuntimeError('Fitted MPV value outside range')
 
         return mpv
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/landau.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/landau.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,57 +1,59 @@
-""" Landau distribution function
+"""Landau distribution function
 
-    This module computes the Landau distribution, which governs the
-    fluctuations in energy loss of particles travelling through a
-    relatively thin layer of matter.
-
-    Currently, this module only contains functions to calculate the exact
-    function using two integral representations of the defining complex
-    integral.  This should be extended by approximations when the need for
-    doing serious work arises.
+This module computes the Landau distribution, which governs the
+fluctuations in energy loss of particles travelling through a
+relatively thin layer of matter.
+
+Currently, this module only contains functions to calculate the exact
+function using two integral representations of the defining complex
+integral.  This should be extended by approximations when the need for
+doing serious work arises.
 
-    References are made to Fokkema2012, DOI: 10.3990/1.9789036534383.
+References are made to Fokkema2012, DOI: 10.3990/1.9789036534383.
 
 """
+
 import warnings
 
-from numpy import Inf, arctan, convolve, cos, exp, interp, linspace, log, pi, sin, vectorize
+from numpy import arctan, convolve, cos, exp, inf, interp, linspace, log, pi, sin, vectorize
 from scipy import integrate, stats
 
 
 @vectorize
 def pdf(lf):
     """The Landau probability density function
 
     Fokkema2012, eq 2.13.
 
     """
     if lf < -10:
-        return 0.
+        return 0.0
     elif lf < 0:
         sf = exp(-lf - 1)
-        integrant = integrate.quad(pdf_kernel, 0, Inf, args=(sf,))[0]
+        integrant = integrate.quad(pdf_kernel, 0, inf, args=(sf,))[0]
         return 1 / pi * exp(-sf) * integrant
     else:
-        integrant = integrate.quad(pdf_kernel2, 0, Inf, args=(lf,))[0]
+        integrant = integrate.quad(pdf_kernel2, 0, inf, args=(lf,))[0]
         return 1 / pi * integrant
 
 
 def pdf_kernel(y, sf):
-    return (exp(sf / 2 * log(1 + y ** 2 / sf ** 2) - y * arctan(y / sf)) *
-            cos(.5 * y * log(1 + y ** 2 / sf ** 2) - y + sf * arctan(y / sf)))
+    return exp(sf / 2 * log(1 + y**2 / sf**2) - y * arctan(y / sf)) * cos(
+        0.5 * y * log(1 + y**2 / sf**2) - y + sf * arctan(y / sf),
+    )
 
 
 def pdf_kernel2(u, lf):
     """The Landau kernel
 
     Fokkema2012, eq 2.13.
 
     """
-    return exp(-lf * u) * u ** -u * sin(pi * u)
+    return exp(-lf * u) * u**-u * sin(pi * u)
 
 
 class Scintillator:
     thickness = 0.02  # m
     xi = 0.172018  # MeV, Fokkema2012, eq 2.12.
     epsilon = 3.10756e-11  # Fokkema2012, eq 2.11.
     delta = 2.97663  # Delta
@@ -103,16 +105,15 @@
         if self.pdf_values is not None:
             return interp(lf, self.pdf_domain, self.pdf_values)
         else:
             # Generate pre-computed values for Landau PDF
             self.pdf_values = pdf(self.pdf_domain)
             return self.pdf(lf)
 
-    def conv_landau_for_x(self, x, count_scale=1, mev_scale=None,
-                          gauss_scale=None):
+    def conv_landau_for_x(self, x, count_scale=1, mev_scale=None, gauss_scale=None):
         """Landau convolved with Gaussian
 
         Fokkema2012, eq 5.4.
 
         :param x: energy loss(es) for which to get the probability.
         :param count_scale: total number of counts.
         :param mev_scale: number of MeV per unit of x.
@@ -131,16 +132,15 @@
 
         y_calc = count_scale * discrete_convolution(f, g, x_domain)
         x_calc = x_domain / mev_scale
 
         y = interp(x, x_calc, y_calc)
         return y
 
-    def conv_landau(self, x, count_scale=1, mev_scale=None,
-                    gauss_scale=None):
+    def conv_landau(self, x, count_scale=1, mev_scale=None, gauss_scale=None):
         """Bare-bones convoluted landau function
 
         This thing is fragile.  Use with great care!  First and foremost,
         x must be symmetrical around zero.  Second, x must contain most of
         the Landau function (including a significant part of the tail).
         If not, the results cannot be trusted!
 
@@ -159,29 +159,25 @@
         return count_scale * discrete_convolution(f, g, mev_scale * x)
 
     def residuals(self, p, xdata, ydata, a, b):
         count_scale, mev_scale, gauss_scale = p
         self.mev_scale = mev_scale
         self.gauss_scale = gauss_scale
 
-        return self._residuals(xdata, ydata, mev_scale, count_scale,
-                               gauss_scale, a, b)
+        return self._residuals(xdata, ydata, mev_scale, count_scale, gauss_scale, a, b)
 
     def constrained_residuals(self, p, xdata, ydata, a, b):
         count_scale = p
         mev_scale = self.mev_scale
         gauss_scale = self.gauss_scale
 
-        return self._residuals(xdata, ydata, mev_scale, count_scale,
-                               gauss_scale, a, b)
+        return self._residuals(xdata, ydata, mev_scale, count_scale, gauss_scale, a, b)
 
-    def _residuals(self, xdata, ydata, mev_scale, count_scale,
-                   gauss_scale, a, b):
-        yfit = self.conv_landau_for_x(xdata, count_scale, mev_scale,
-                                      gauss_scale)
+    def _residuals(self, xdata, ydata, mev_scale, count_scale, gauss_scale, a, b):
+        yfit = self.conv_landau_for_x(xdata, count_scale, mev_scale, gauss_scale)
 
         yfit = yfit.compress((a <= xdata) & (xdata < b))
         ydata = ydata.compress((a <= xdata) & (xdata < b))
         return ((yfit - ydata) ** 2 / ydata).sum()
 
 
 def discrete_convolution(f, g, t):
@@ -190,11 +186,11 @@
     :param f,g: two functions that take one argument (t).
     :param t: values for which the functions will be evaluated, and the along
               which the convolution will be performed.
     :return: convolution of the two functions.
 
     """
     if abs(min(t) + max(t)) > 1e-6:
-        raise RuntimeError("Range needs to be symmetrical around zero.")
+        raise RuntimeError('Range needs to be symmetrical around zero.')
 
     dt = t[1] - t[0]
     return dt * convolve(f(t), g(t), mode='same')
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/process_events.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/process_events.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,62 +1,62 @@
-""" Process HiSPARC events
+"""Process HiSPARC events
 
-    This module can be used analyse data to get observables like arrival
-    times and particle count in each detector for each event.
+This module can be used analyse data to get observables like arrival
+times and particle count in each detector for each event.
 
-    Example usage::
+Example usage::
 
-        import datetime
+    import datetime
 
-        import tables
+    import tables
 
-        from sapphire.publicdb import download_data
-        from sapphire import ProcessEvents
+    from sapphire.publicdb import download_data
+    from sapphire import ProcessEvents
 
-        STATIONS = [501, 503, 506]
-        START = datetime.datetime(2013, 1, 1)
-        END = datetime.datetime(2013, 1, 2)
+    STATIONS = [501, 503, 506]
+    START = datetime.datetime(2013, 1, 1)
+    END = datetime.datetime(2013, 1, 2)
 
 
-        if __name__ == '__main__':
-            station_groups = ['/s%d' % u for u in STATIONS]
+    if __name__ == '__main__':
+        station_groups = ['/s%d' % u for u in STATIONS]
 
-            with tables.open_file('data.h5', 'w') as data:
-                for station, group in zip(STATIONS, station_groups):
-                    download_data(data, group, station, START, END, True)
-                    proc = ProcessEvents(data, group)
-                    proc.process_and_store_results()
+        with tables.open_file('data.h5', 'w') as data:
+            for station, group in zip(STATIONS, station_groups):
+                download_data(data, group, station, START, END, True)
+                proc = ProcessEvents(data, group)
+                proc.process_and_store_results()
 
 """
+
 import operator
 import os
 import warnings
 import zlib
 
 import numpy as np
 import tables
 
 from ..api import Station
 from ..utils import ERR, pbar
 from .find_mpv import FindMostProbableValueInSpectrum
 from .process_traces import ADC_HIGH_THRESHOLD, ADC_LOW_THRESHOLD, ADC_TIME_PER_SAMPLE
 
 ADC_THRESHOLD = 20  #: Threshold for arrival times, relative to the baseline
-ADC_LIMIT = 2 ** 12
+ADC_LIMIT = 2**12
 
 #: Default trigger for 2-detector station
 #: 2 low and no high, no external
 TRIGGER_2 = (2, 0, False, 0)
 #: Default trigger for 4-detector station
 #: 3 low or 2 high, no external
 TRIGGER_4 = (3, 2, True, 0)
 
 
 class ProcessEvents:
-
     """Process HiSPARC events to obtain several observables.
 
     This class can be used to process a set of HiSPARC events and adds a
     few observables like particle arrival time and number of particles in
     the detector to a copy of the event table.
 
     """
@@ -79,15 +79,16 @@
         't2': tables.Float32Col(pos=14, dflt=-1),
         't3': tables.Float32Col(pos=15, dflt=-1),
         't4': tables.Float32Col(pos=16, dflt=-1),
         'n1': tables.Float32Col(pos=17, dflt=-1),
         'n2': tables.Float32Col(pos=18, dflt=-1),
         'n3': tables.Float32Col(pos=19, dflt=-1),
         'n4': tables.Float32Col(pos=20, dflt=-1),
-        't_trigger': tables.Float32Col(pos=21, dflt=-1)}
+        't_trigger': tables.Float32Col(pos=21, dflt=-1),
+    }
 
     def __init__(self, data, group, source=None, progress=True):
         """Initialize the class.
 
         :param data: the PyTables datafile
         :param group: the group containing the station data.  In normal
             cases, this is simply the group containing the events table.
@@ -99,16 +100,15 @@
         """
         self.data = data
         self.group = data.get_node(group)
         self.source = self._get_source(source)
         self.progress = progress
         self.limit = None
 
-    def process_and_store_results(self, destination=None, overwrite=False,
-                                  limit=None):
+    def process_and_store_results(self, destination=None, overwrite=False, limit=None):
         """Process events and store the results.
 
         :param destination: name of the table where the results will be
             written.  The default, None, corresponds to 'events'.
         :param overwrite: if True, overwrite previously obtained results.
         :param limit: the maximum number of events that will be stored.
             The default, None, corresponds to no limit.
@@ -128,16 +128,15 @@
     def get_traces_for_event(self, event):
         """Return the traces from an event.
 
         :param event: a row from the events table.
         :return: the traces: an array of pulseheight values.
 
         """
-        traces = [list(self._get_trace(idx)) for idx in event['traces']
-                  if idx >= 0]
+        traces = [list(self._get_trace(idx)) for idx in event['traces'] if idx >= 0]
 
         # Make traces follow NumPy conventions
         traces = np.array(traces).T
         return traces
 
     def get_traces_for_event_index(self, idx):
         """Return the traces from event #idx.
@@ -167,25 +166,23 @@
             source = self.data.get_node(self.group, source)
         return source
 
     def _check_destination(self, destination, overwrite):
         """Check if the destination is valid"""
 
         if destination == '_events':
-            raise RuntimeError("The _events table is reserved for internal "
-                               "use.  Choose another destination.")
+            raise RuntimeError('The _events table is reserved for internal use.  Choose another destination.')
         elif destination is None:
             destination = 'events'
 
         # If destination == source, source will be moved out of the way.  Don't
         # worry.  Otherwise, destination may not exist or will be overwritten
         if self.source.name != destination:
             if destination in self.group and not overwrite:
-                raise RuntimeError("I will not overwrite previous results "
-                                   "(unless you specify overwrite=True)")
+                raise RuntimeError('I will not overwrite previous results (unless you specify overwrite=True)')
 
         self.destination = destination
 
     def _clean_events_table(self):
         """Clean the events table.
 
         Remove duplicate events and sort the table by ext_timestamp.
@@ -194,16 +191,15 @@
         events = self.source
 
         enumerated_timestamps = list(enumerate(events.col('ext_timestamp')))
         enumerated_timestamps.sort(key=operator.itemgetter(1))
 
         unique_sorted_ids = self._find_unique_row_ids(enumerated_timestamps)
 
-        new_events = self._replace_table_with_selected_rows(events,
-                                                            unique_sorted_ids)
+        new_events = self._replace_table_with_selected_rows(events, unique_sorted_ids)
         self.source = new_events
         self._normalize_event_ids(new_events)
 
     def _find_unique_row_ids(self, enumerated_timestamps):
         """Find the unique row_ids from enumerated timestamps."""
 
         prev_timestamp = 0
@@ -220,16 +216,15 @@
         """Replace events table with selected rows.
 
         :param table: original table to be replaced.
         :param row_ids: row ids of the selected rows which should go in
             the destination table.
 
         """
-        tmptable = self.data.create_table(self.group, 't__events',
-                                          description=table.description)
+        tmptable = self.data.create_table(self.group, 't__events', description=table.description)
         selected_rows = table.read_coordinates(row_ids)
         tmptable.append(selected_rows)
         tmptable.flush()
         self.data.rename_node(tmptable, table.name, overwrite=True)
         return tmptable
 
     def _normalize_event_ids(self, events):
@@ -258,31 +253,28 @@
         if self.limit:
             length = self.limit
         else:
             length = len(self.source)
 
         if '_t_events' in self.group:
             self.data.remove_node(self.group, '_t_events')
-        table = self.data.create_table(self.group, '_t_events',
-                                       self.processed_events_description,
-                                       expectedrows=length)
+        table = self.data.create_table(self.group, '_t_events', self.processed_events_description, expectedrows=length)
 
         for _ in range(length):
             table.row.append()
         table.flush()
 
         return table
 
     def _copy_events_into_table(self):
         table = self._tmp_events
         source = self.source
 
         for col in pbar(source.colnames, show=self.progress):
-            table.modify_column(stop=self.limit, colname=col,
-                                column=getattr(source.cols, col)[:self.limit])
+            table.modify_column(stop=self.limit, colname=col, column=getattr(source.cols, col)[: self.limit])
         table.flush()
 
     def _store_results_from_traces(self):
         table = self._tmp_events
 
         timings = self.process_traces()
 
@@ -296,16 +288,15 @@
         """Process traces to yield pulse timing information."""
 
         if self.limit is not None:
             events = self.source.iterrows(stop=self.limit)
         else:
             events = self.source
 
-        timings = self._process_traces_from_event_list(events,
-                                                       length=self.limit)
+        timings = self._process_traces_from_event_list(events, length=self.limit)
         return timings
 
     def _process_traces_from_event_list(self, events, length=None):
         """Process traces from a list of events.
 
         This is the method looping over all events.
 
@@ -329,29 +320,24 @@
 
         :param event: row from the events table.
         :return: arrival times in the detectors relative to trace start
                  in ns.
 
         """
         timings = []
-        for baseline, pulseheight, trace_idx in zip(event['baseline'],
-                                                    event['pulseheights'],
-                                                    event['traces']):
+        for baseline, pulseheight, trace_idx in zip(event['baseline'], event['pulseheights'], event['traces']):
             if pulseheight < 0:
                 # retain -1, -999 status flags in timing
                 timings.append(pulseheight)
             elif pulseheight < ADC_THRESHOLD:
                 timings.append(-999)
             else:
                 trace = self._get_trace(trace_idx)
-                timings.append(self._reconstruct_time_from_trace(trace,
-                                                                 baseline))
-        timings = [time * ADC_TIME_PER_SAMPLE
-                   if time not in ERR else time
-                   for time in timings]
+                timings.append(self._reconstruct_time_from_trace(trace, baseline))
+        timings = [time * ADC_TIME_PER_SAMPLE if time not in ERR else time for time in timings]
         return timings
 
     def _get_trace(self, idx):
         """Returns a trace given an index into the blobs array.
 
         Decompress a trace from the blobs array.
 
@@ -360,16 +346,15 @@
 
         """
         blobs = self._get_blobs()
 
         try:
             trace = zlib.decompress(blobs[idx]).decode('utf-8').split(',')
         except zlib.error:
-            trace = (zlib.decompress(blobs[idx][1:-1])
-                     .decode('utf-8').split(','))
+            trace = zlib.decompress(blobs[idx][1:-1]).decode('utf-8').split(',')
         if trace[-1] == '':
             del trace[-1]
         trace = (int(x) for x in trace)
         return trace
 
     def _get_blobs(self):
         return self.group.blobs
@@ -429,33 +414,29 @@
 
         integrals = self.source.col('integrals')
         all_mpv = []
         for detector_integrals in integrals.T:
             if (detector_integrals < 0).all():
                 all_mpv.append(np.nan)
             else:
-                n, bins = np.histogram(detector_integrals,
-                                       bins=np.linspace(0, 50000, 201))
+                n, bins = np.histogram(detector_integrals, bins=np.linspace(0, 50_000, 201))
                 find_mpv = FindMostProbableValueInSpectrum(n, bins)
                 mpv, is_fitted = find_mpv.find_mpv()
                 if is_fitted:
                     all_mpv.append(mpv)
                 else:
                     all_mpv.append(np.nan)
         all_mpv = np.array(all_mpv)
 
-        for event in self.source[:self.limit]:
+        for event in self.source[: self.limit]:
             pulseintegrals = event['integrals']
             # retain -1, -999 status flags
-            pulseintegrals = np.where(pulseintegrals >= 0,
-                                      pulseintegrals / all_mpv,
-                                      pulseintegrals)
+            pulseintegrals = np.where(pulseintegrals >= 0, pulseintegrals / all_mpv, pulseintegrals)
             # if mpv fit failed, value is nan.  Make it -999
-            pulseintegrals = np.where(np.isnan(pulseintegrals), -999,
-                                      pulseintegrals)
+            pulseintegrals = np.where(np.isnan(pulseintegrals), -999, pulseintegrals)
             n_particles.append(pulseintegrals)
 
         return np.array(n_particles)
 
     def _move_results_table_into_destination(self):
         if self.source.name == 'events':
             self.source.rename('_events')
@@ -463,24 +444,26 @@
 
         if self.destination in self.group:
             self.data.remove_node(self.group, self.destination)
         self._tmp_events.rename(self.destination)
 
     def __repr__(self):
         if not self.data.isopen:
-            return "<finished %s>" % self.__class__.__name__
+            return '<finished %s>' % self.__class__.__name__
         else:
-            return ("%s(%r, %r, source=%r, progress=%r)" %
-                    (self.__class__.__name__, self.data.filename,
-                     self.group._v_pathname, self.source._v_pathname,
-                     self.progress))
+            return '%s(%r, %r, source=%r, progress=%r)' % (
+                self.__class__.__name__,
+                self.data.filename,
+                self.group._v_pathname,
+                self.source._v_pathname,
+                self.progress,
+            )
 
 
 class ProcessIndexedEvents(ProcessEvents):
-
     """Process a subset of events using an index.
 
     This is a subclass of :class:`ProcessEvents`.  Using an index, this
     class will only process a subset of events, thus saving time.  For
     example, this class can only process events making up a coincidence.
 
     """
@@ -529,15 +512,14 @@
 
     def get_traces_for_indexed_event_index(self, idx):
         idx = self.indexes[idx]
         return self.get_traces_for_event_index(idx)
 
 
 class ProcessEventsWithLINT(ProcessEvents):
-
     """Process events using LInear INTerpolation for arrival times.
 
     This is a subclass of :class:`ProcessEvents`.  Use a linear
     interpolation method to determine the arrival times of particles.
 
     """
 
@@ -553,72 +535,62 @@
         """
         threshold = baseline + ADC_THRESHOLD
         trace = list(trace)
         i = self.first_above_threshold(trace, threshold)
 
         if i == 0:
             value = i
-        elif not i == -999:
+        elif i != -999:
             x0, x1 = i - 1, i
             y0, y1 = trace[x0], trace[x1]
-            value = 1. * (threshold - y0) / (y1 - y0) + x0
+            value = 1.0 * (threshold - y0) / (y1 - y0) + x0
         else:
             value = -999
 
         return value
 
 
 class ProcessIndexedEventsWithLINT(ProcessIndexedEvents, ProcessEventsWithLINT):
-
     """Process a subset of events using LInear INTerpolation.
 
     This is a subclass of :class:`ProcessIndexedEvents` and
     :class:`ProcessEventsWithLINT`.
 
     """
 
-    pass
-
 
 class ProcessEventsWithoutTraces(ProcessEvents):
-
     """Process events without traces
 
     This is a subclass of :class:`ProcessEvents`.  Processing events
     without considering traces will invalidate the arrival time
     information.  However, for some analyses it is not necessary to obtain
     this information.  Ignoring the traces will then greatly decrease
     processing time and data size.
 
     """
 
     def _store_results_from_traces(self):
         """Fake storing results from traces."""
 
-        pass
-
 
 class ProcessIndexedEventsWithoutTraces(ProcessEventsWithoutTraces, ProcessIndexedEvents):
-
     """Process a subset of events without traces
 
     This is a subclass of :class:`ProcessIndexedEvents` and
     :class:`ProcessEventsWithoutTraces`.  Processing events without
     considering traces will invalidate the arrival time information.
     However, for some analyses it is not necessary to obtain this
     information.  Ignoring the traces will then greatly decrease
     processing time and data size.
 
     """
 
-    pass
-
 
 class ProcessEventsWithTriggerOffset(ProcessEvents):
-
     """Process events and reconstruct trigger time from traces
 
     The trigger times are stored in the columnt_trigger, they are
     relative to the start of traces, just like the t# columns.
 
     If no trigger can be found, possibly due to the data filter,
     a value of -999 will be entered.
@@ -644,15 +616,15 @@
             self.thresholds = [(ADC_LOW_THRESHOLD, ADC_HIGH_THRESHOLD)] * 4
             n = sum(1 for idx in self.source[0]['traces'] if idx != -1)
             if n == 2:
                 self.trigger = TRIGGER_2
             elif n == 4:
                 self.trigger = TRIGGER_4
             else:
-                raise Exception('No trigger settings available')
+                raise ValueError('No trigger settings available')
         else:
             self.station = Station(station)
 
     def _store_results_from_traces(self):
         table = self._tmp_events
 
         timings = self.process_traces()
@@ -689,16 +661,19 @@
             # Do not reconstruct thresholds if external trigger is involved
             self.thresholds = [(ADC_LIMIT, ADC_LIMIT)] * 4
 
         timings = []
         low_idx = []
         high_idx = []
         for baseline, pulseheight, trace_idx, trig_thresholds in zip(
-                event['baseline'], event['pulseheights'], event['traces'],
-                self.thresholds):
+            event['baseline'],
+            event['pulseheights'],
+            event['traces'],
+            self.thresholds,
+        ):
             if pulseheight < 0:
                 # Retain -1 and -999 status flags in timing
                 timings.append(pulseheight)
                 low_idx.append(-999)
                 high_idx.append(-999)
                 continue
             if pulseheight < ADC_THRESHOLD or baseline > trig_thresholds[0]:
@@ -720,25 +695,23 @@
             if n_high and max_signal >= trig_thresholds[1]:
                 thresholds.append(trig_thresholds[1])
             else:
                 thresholds.append(ADC_LIMIT)
 
             trace = self._get_trace(trace_idx)
 
-            t, l, h = self._first_above_thresholds(trace, thresholds,
-                                                   max_signal)
-            timings.append(t)
-            low_idx.append(l)
-            high_idx.append(h)
+            time, low, high = self._first_above_thresholds(trace, thresholds, max_signal)
+            timings.append(time)
+            low_idx.append(low)
+            high_idx.append(high)
 
         t_trigger = self._reconstruct_trigger(low_idx, high_idx)
         timings.append(t_trigger)
 
-        timings = [time * ADC_TIME_PER_SAMPLE if time not in ERR else time
-                   for time in timings]
+        timings = [time * ADC_TIME_PER_SAMPLE if time not in ERR else time for time in timings]
         return timings
 
     @classmethod
     def _first_above_thresholds(cls, trace, thresholds, max_signal):
         """Check for multiple thresholds when the traces crosses it
 
         First the thresholds are sorted to make sure they are looked for
@@ -777,16 +750,15 @@
         :param trace: iterable trace.
         :param threshold: value the trace has to be greater or equal to.
         :param t: index of first value in trace.
         :return: index in trace where a value is greater or equal to
                  threshold, and the value.
 
         """
-        return next(((i, x) for i, x in enumerate(trace, t) if x >= threshold),
-                    (-999, 0))
+        return next(((i, x) for i, x in enumerate(trace, t) if x >= threshold), (-999, 0))
 
     def _reconstruct_trigger(self, low_idx, high_idx):
         """Reconstruct the moment of trigger from the threshold info
 
         :param low_idx,high_idx: list of trace indexes when a detector
                                  crossed a given threshold.
         :return: index in trace where the trigger happened.
@@ -794,69 +766,74 @@
         """
         n_low, n_high, and_or, external = self.trigger
 
         # External trigger not supported
         if external:
             return -999
 
-        low_idx = sorted(idx for idx in low_idx if not idx == -999)
-        high_idx = sorted(idx for idx in high_idx if not idx == -999)
+        low_idx = sorted(idx for idx in low_idx if idx != -999)
+        high_idx = sorted(idx for idx in high_idx if idx != -999)
 
         if and_or:
             # low or high, which ever is first
             if n_low and n_high and len(low_idx) >= n_low and len(high_idx) >= n_high:
                 return min(low_idx[n_low - 1], high_idx[n_high - 1])
             elif n_high and len(high_idx) >= n_high:
                 return high_idx[n_high - 1]
             elif n_low and len(low_idx) >= n_low:
                 return low_idx[n_low - 1]
-        else:
-            if n_low and n_high:
-                # low and high
-                if len(low_idx) >= n_low + n_high and len(high_idx) >= n_high:
-                    return max(low_idx[n_low + n_high - 1], high_idx[n_high - 1])
-            elif n_high:
-                # 0 low and high
-                if len(high_idx) >= n_high:
-                    return high_idx[n_high - 1]
-            elif n_low:
-                # low and 0 high
-                if len(low_idx) >= n_low:
-                    return low_idx[n_low - 1]
+        elif n_low and n_high:
+            # low and high
+            if len(low_idx) >= n_low + n_high and len(high_idx) >= n_high:
+                return max(low_idx[n_low + n_high - 1], high_idx[n_high - 1])
+        elif n_high:
+            # 0 low and high
+            if len(high_idx) >= n_high:
+                return high_idx[n_high - 1]
+        elif n_low:
+            # low and 0 high
+            if len(low_idx) >= n_low:
+                return low_idx[n_low - 1]
 
         return -999
 
     def __repr__(self):
         if not self.data.isopen:
-            return "<finished %s>" % self.__class__.__name__
+            return f'<finished {self.__class__.__name__}>'
         elif self.station is None:
-            return ("%s(%r, %r, source=%r, progress=%r, Station=%r)" %
-                    (self.__class__.__name__, self.data.filename,
-                     self.group._v_pathname, self.source._v_pathname,
-                     self.progress, None))
+            return '%s(%r, %r, source=%r, progress=%r, Station=%r)' % (
+                self.__class__.__name__,
+                self.data.filename,
+                self.group._v_pathname,
+                self.source._v_pathname,
+                self.progress,
+                None,
+            )
         else:
-            return ("%s(%r, %r, source=%r, progress=%r, station=%d)" %
-                    (self.__class__.__name__, self.data.filename,
-                     self.group._v_pathname, self.source._v_pathname,
-                     self.progress, self.station.number))
+            return '%s(%r, %r, source=%r, progress=%r, station=%d)' % (
+                self.__class__.__name__,
+                self.data.filename,
+                self.group._v_pathname,
+                self.source._v_pathname,
+                self.progress,
+                self.station.number,
+            )
 
 
 class ProcessEventsFromSource(ProcessEvents):
-
     """Process HiSPARC events from a different source.
 
     This class is a subclass of ProcessEvents.  The difference is that in
     this class, the source and destination are assumed to be different
     files.  This also means that the source is untouched (no renaming of
     original event tables) and the destination is assumed to be empty.
 
     """
 
-    def __init__(self, source_file, dest_file, source_group, dest_group,
-                 progress=False):
+    def __init__(self, source_file, dest_file, source_group, dest_group, progress=False):
         """Initialize the class.
 
         :param source_file,dest_file: PyTables source and destination files.
         :param source_group,dest_group: the pathname of the source and
                                         destination group.
         :param progress: if True show a progressbar while copying and
                          processing events.
@@ -893,42 +870,43 @@
             source = self.source_group._events
         else:
             source = self.source_group.events
         return source
 
     def _check_destination(self, destination, overwrite):
         """Override method, the destination is empty"""
-        pass
 
     def _replace_table_with_selected_rows(self, table, row_ids):
         """Replace events table with selected rows.
 
         :param table: original table to be replaced.
         :param row_ids: row ids of the selected rows which should go in
             the destination table.
 
         """
-        new_events = self.dest_file.create_table(self.dest_group, '_events',
-                                                 description=table.description)
+        new_events = self.dest_file.create_table(self.dest_group, '_events', description=table.description)
         selected_rows = table.read_coordinates(row_ids)
         new_events.append(selected_rows)
         new_events.flush()
         return new_events
 
     def _create_empty_results_table(self):
         """Create empty results table with correct length."""
 
         if self.limit:
             length = self.limit
         else:
             length = len(self.source)
 
-        table = self.dest_file.create_table(self.dest_group, 'events',
-                                            self.processed_events_description,
-                                            expectedrows=length)
+        table = self.dest_file.create_table(
+            self.dest_group,
+            'events',
+            self.processed_events_description,
+            expectedrows=length,
+        )
 
         for _ in range(length):
             table.row.append()
         table.flush()
 
         return table
 
@@ -939,36 +917,37 @@
     def _get_blobs(self):
         """Return blobs node"""
 
         return self.source_group.blobs
 
     def __repr__(self):
         if not self.source_file.isopen or not self.dest_file.isopen:
-            return f"<finished {self.__class__.__name__}>"
+            return f'<finished {self.__class__.__name__}>'
         else:
-            return ("%s(%r, %r, %r, %r, progress=%r)" %
-                    (self.__class__.__name__, self.source_file.filename,
-                     self.dest_file.filename, self.source_group._v_pathname,
-                     self.dest_group._v_pathname, self.progress))
+            return '%s(%r, %r, %r, %r, progress=%r)' % (
+                self.__class__.__name__,
+                self.source_file.filename,
+                self.dest_file.filename,
+                self.source_group._v_pathname,
+                self.dest_group._v_pathname,
+                self.progress,
+            )
 
 
-class ProcessEventsFromSourceWithTriggerOffset(ProcessEventsFromSource,
-                                               ProcessEventsWithTriggerOffset):
-
+class ProcessEventsFromSourceWithTriggerOffset(ProcessEventsFromSource, ProcessEventsWithTriggerOffset):
     """Process events from a different source and find trigger.
 
     This is a subclass of :class:`ProcessEventsFromSource` and
     :class:`ProcessEventsWithTriggerOffset`.  Processing events and
     finding the trigger time in the traces. And storing the results in a
     different file than the source.
 
     """
 
-    def __init__(self, source_file, dest_file, source_group, dest_group,
-                 station=None, progress=False):
+    def __init__(self, source_file, dest_file, source_group, dest_group, station=None, progress=False):
         """Initialize the class.
 
         :param source_file,dest_file: PyTables source and destination files.
         :param source_group,dest_group: the pathname of the source and
                                         destination group.
         :param station: station number of station to which the data belongs.
         :param progress: if True show a progressbar while copying and
@@ -991,44 +970,52 @@
             self.thresholds = [(ADC_LOW_THRESHOLD, ADC_HIGH_THRESHOLD)] * 4
             n = sum(1 for idx in self.source[0]['traces'] if idx != -1)
             if n == 2:
                 self.trigger = TRIGGER_2
             elif n == 4:
                 self.trigger = TRIGGER_4
             else:
-                raise Exception('No trigger settings available')
+                raise ValueError('No trigger settings available')
         else:
             self.station = Station(station)
 
     def __repr__(self):
         if not self.source_file.isopen or not self.dest_file.isopen:
-            return "<finished %s>" % self.__class__.__name__
+            return f'<finished {self.__class__.__name__}>'
         elif self.station is None:
-            return ("%s(%r, %r, %r, %r, progress=%r)" %
-                    (self.__class__.__name__, self.source_file.filename,
-                     self.dest_file.filename, self.source_group._v_pathname,
-                     self.dest_group._v_pathname, self.progress))
+            return '%s(%r, %r, %r, %r, progress=%r)' % (
+                self.__class__.__name__,
+                self.source_file.filename,
+                self.dest_file.filename,
+                self.source_group._v_pathname,
+                self.dest_group._v_pathname,
+                self.progress,
+            )
         else:
-            return ("%s(%r, %r, %r, %r, station=%d, progress=%r)" %
-                    (self.__class__.__name__, self.source_file.filename,
-                     self.dest_file.filename, self.source_group._v_pathname,
-                     self.dest_group._v_pathname, self.station.number,
-                     self.progress))
+            return '%s(%r, %r, %r, %r, station=%d, progress=%r)' % (
+                self.__class__.__name__,
+                self.source_file.filename,
+                self.dest_file.filename,
+                self.source_group._v_pathname,
+                self.dest_group._v_pathname,
+                self.station.number,
+                self.progress,
+            )
 
 
 class ProcessDataTable(ProcessEvents):
-
     """Process HiSPARC abstract data table to clean the data.
 
     Abstract data is a PyTables table containing a timestamp for each row.
     Weather and singles data are examples of such tables. This class can be
     used to process a set of abstract HiSPARC data, to remove duplicates and
     sort the data by timestamp to store it in to a copy of the table.
 
     """
+
     table_name = 'abstract_data'  # overwrite with 'weather' or 'singles'
 
     def process_and_store_results(self, destination=None, overwrite=False, limit=None):
         """Process table and store the results.
 
         :param destination: name of the table where the results will be
             written.  The default, None, corresponds to the value stored
@@ -1058,24 +1045,22 @@
             source = self.data.get_node(self.group, source)
         return source
 
     def _check_destination(self, destination, overwrite):
         """Check if the destination is valid"""
 
         if destination == f'_t_{self.table_name}':
-            raise RuntimeError(f"The _t_{self.table_name} table is for internal use. Choose "
-                               "another destination.")
+            raise RuntimeError(f'The _t_{self.table_name} table is for internal use. Choose another destination.')
         elif destination is None:
             destination = self.table_name
 
         # If destination == source, source will be overwritten.
         if self.source.name != destination:
             if destination in self.group and not overwrite:
-                raise RuntimeError("I will not overwrite previous results "
-                                   "(unless you specify overwrite=True)")
+                raise RuntimeError('I will not overwrite previous results (unless you specify overwrite=True)')
 
         self.destination = destination
 
     def _clean_data_table(self):
         """Clean the table.
 
         Remove duplicate events and sort the table by timestamp.
@@ -1084,39 +1069,35 @@
         data = self.source
 
         enumerated_timestamps = list(enumerate(data.col('timestamp')))
         enumerated_timestamps.sort(key=operator.itemgetter(1))
 
         unique_sorted_ids = self._find_unique_row_ids(enumerated_timestamps)
 
-        new_data = self._replace_table_with_selected_rows(data,
-                                                          unique_sorted_ids)
+        new_data = self._replace_table_with_selected_rows(data, unique_sorted_ids)
         self.source = new_data
         self._normalize_event_ids(new_data)
 
     def _replace_table_with_selected_rows(self, table, row_ids):
         """Replace data table with selected rows.
 
         :param table: original table to be replaced.
         :param row_ids: row ids of the selected rows which should go in
             the destination table.
 
         """
-        tmptable = self.data.create_table(self.group,
-                                          f'_t_{self.table_name}',
-                                          description=table.description)
+        tmptable = self.data.create_table(self.group, f'_t_{self.table_name}', description=table.description)
         selected_rows = table.read_coordinates(row_ids)
         tmptable.append(selected_rows)
         tmptable.flush()
         self.data.rename_node(tmptable, self.destination, overwrite=True)
         return tmptable
 
 
 class ProcessDataTableFromSource(ProcessDataTable):
-
     """Process HiSPARC abstract data table from a different source.
 
     This class is a subclass of ProcessDataTable. The difference is that in
     this class, the source and destination are assumed to be different
     files.  This also means that the source is untouched (no renaming of
     original event tables) and the destination is assumed to be empty.
 
@@ -1149,87 +1130,88 @@
 
         """
         source = self.source_file.get_node(self.source_group, self.table_name)
         return source
 
     def _check_destination(self, destination, overwrite):
         """Override method, the destination should be empty"""
-        pass
 
     def _replace_table_with_selected_rows(self, table, row_ids):
         """Replace data table with selected rows.
 
         :param table: original table to be replaced.
         :param row_ids: row ids of the selected rows which should go in
             the destination table.
 
         """
-        new_table = self.dest_file.create_table(self.dest_group,
-                                                self.table_name,
-                                                description=table.description)
+        new_table = self.dest_file.create_table(self.dest_group, self.table_name, description=table.description)
         selected_rows = table.read_coordinates(row_ids)
         new_table.append(selected_rows)
         new_table.flush()
         return new_table
 
     def __repr__(self):
         if not self.source_file.isopen or not self.dest_file.isopen:
-            return "<finished %s>" % self.__class__.__name__
+            return f'<finished {self.__class__.__name__}>'
         else:
-            return ("%s(%r, %r, %r, %r, progress=%r)" %
-                    (self.__class__.__name__, self.source_file.filename,
-                     self.dest_file.filename, self.source_group._v_pathname,
-                     self.dest_group._v_pathname, self.progress))
+            return '%s(%r, %r, %r, %r, progress=%r)' % (
+                self.__class__.__name__,
+                self.source_file.filename,
+                self.dest_file.filename,
+                self.source_group._v_pathname,
+                self.dest_group._v_pathname,
+                self.progress,
+            )
 
 
 class ProcessWeather(ProcessDataTable):
-
     """Process HiSPARC weather to clean the data.
 
     This class can be used to process a set of HiSPARC weather, to
     remove duplicates and sort the data by timestamp to store it in to a
     copy of the weather table.
 
     """
+
     table_name = 'weather'
 
 
 class ProcessWeatherFromSource(ProcessDataTableFromSource):
-
     """Process HiSPARC weather from a different source.
 
     This class behaves like a subclass of ProcessWeather because of a common
     ancestor (ProcessDataTable). The difference between this class
     and ProcessWeather is that in this class, the source and destination are
     assumed to be different files. This also means that the source is
     untouched (no renaming of original event tables) and the destination is
     assumed to be empty.
 
     """
+
     table_name = 'weather'
 
 
 class ProcessSingles(ProcessDataTable):
-
     """Process HiSPARC singles data to clean the data.
 
     This class can be used to process a set of HiSPARC singles data, to
     remove duplicates and sort the data by timestamp to store it in to a
     copy of the singles data table.
 
     """
+
     table_name = 'singles'
 
 
 class ProcessSinglesFromSource(ProcessDataTableFromSource):
-
     """Process HiSPARC singles data from a different source.
 
     This class behaves like a subclass of ProcessSingles because of a common
     ancestor (ProcessDataTable). The difference between this class
     and ProcessSingles is that in this class, the source and destination are
     assumed to be different files. This also means that the source is
     untouched (no renaming of original event tables) and the destination is
     assumed to be empty.
 
     """
+
     table_name = 'singles'
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/process_traces.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/process_traces.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,16 +1,17 @@
-""" Process HiSPARC traces
+"""Process HiSPARC traces
 
-    This module can be used analyse (raw) traces. It implements the same
-    algorithms as are implemented in the HiSPARC DAQ.
+This module can be used analyse (raw) traces. It implements the same
+algorithms as are implemented in the HiSPARC DAQ.
 
-    The :class:`MeanFilter` is meant to mimic the filter in the HiSPARC DAQ.
-    It is reproduced here to make it easy to read the algorithm.
+The :class:`MeanFilter` is meant to mimic the filter in the HiSPARC DAQ.
+It is reproduced here to make it easy to read the algorithm.
 
 """
+
 from functools import cached_property
 
 from numpy import around, convolve, ones, where
 
 ADC_TIME_PER_SAMPLE = 2.5  # in ns
 
 # Trigger windows in number of samples (default windows)
@@ -31,15 +32,14 @@
 ADC_LOW_THRESHOLD_III = 82  #: Default low ADC threshold for HiSPARC III
 ADC_HIGH_THRESHOLD_III = 150  #: Default high ADC threshold for HiSPARC III
 
 DATA_REDUCTION_PADDING = 26  #: Padding to allow later baseline determination
 
 
 class TraceObservables:
-
     """Reconstruct trace observables
 
     If one wants to reconstruct trace observables from existing data some
     caveats apply. If the station applied the Mean Filter the trace values
     will no longer match the raw values used to determine the observables
     on the station. Additionally, if data reduction was active the trace
     may be missing samples without a significant signal, this complicates
@@ -52,16 +52,15 @@
     threshold.
 
     Each returned list contains at least 4 elements, if there are less than
     4 traces the list is padded with the code for missing detectors: -1.
 
     """
 
-    def __init__(self, traces, threshold=ADC_BASELINE_THRESHOLD,
-                 padding=DATA_REDUCTION_PADDING):
+    def __init__(self, traces, threshold=ADC_BASELINE_THRESHOLD, padding=DATA_REDUCTION_PADDING):
         """Initialize the class
 
         :param traces: a NumPy array of traces, ordered such that the first
                        element is the first sample of each trace.
         :param threshold: value of the threshold to use, in ADC counts.
         :param padding: number of samples which should be usuable to determine
                         the baseline.
@@ -69,15 +68,15 @@
         """
         self.traces = traces
         self.threshold = threshold
         self.padding = padding
         self.n = self.traces.shape[1]
         self.missing = [-1] * (4 - self.n)
         if self.n not in [2, 4]:
-            raise Exception('Unsupported number of detectors')
+            raise ValueError('Unsupported number of detectors')
 
     @cached_property
     def baselines(self):
         """Mean value of the first part of the trace
 
         This does not perfectly match the implementation in the DAQ which
         is more complicated, this does provide the correct value in most
@@ -85,67 +84,70 @@
 
         Usually this value is either around 200 or 30, depending on the used
         version of the DAQ.
 
         :return: the baseline in ADC count.
 
         """
-        baselines = around(self.traces[:self.padding].mean(axis=0))
+        baselines = around(self.traces[: self.padding].mean(axis=0))
         return baselines.astype('int').tolist() + self.missing
 
     @cached_property
     def std_dev(self):
         """Standard deviation of the first part of the trace
 
         :return: the standard deviation in milli ADC count.
 
         """
-        std_dev = around(self.traces[:self.padding].std(axis=0) * 1000)
+        std_dev = around(self.traces[: self.padding].std(axis=0) * 1000)
         return std_dev.astype('int').tolist() + self.missing
 
     @cached_property
     def pulseheights(self):
         """Maximum peak to baseline value in trace
 
         :return: the pulseheights in ADC count.
 
         """
-        pulseheights = self.traces.max(axis=0) - self.baselines[:self.n]
+        pulseheights = self.traces.max(axis=0) - self.baselines[: self.n]
         return pulseheights.tolist() + self.missing
 
     @cached_property
     def integrals(self):
         """Integral of trace for all values over threshold
 
         The threshold is defined by ADC_BASELINE_THRESHOLD
 
         :return: the pulse integral in ADC count * sample.
 
         """
         threshold = self.threshold
-        integrals = where(self.traces - self.baselines[:self.n] > threshold,
-                          self.traces - self.baselines[:self.n], 0).sum(axis=0)
+        integrals = where(
+            self.traces - self.baselines[: self.n] > threshold,
+            self.traces - self.baselines[: self.n],
+            0,
+        ).sum(axis=0)
         return integrals.tolist() + self.missing
 
     @cached_property
     def n_peaks(self):
         """Number of peaks in the trace
 
         The peak threshold is defined by ADC_LOW_THRESHOLD
 
         :return: the pulse integral in ADC count * sample.
 
         """
         # Make rough guess at the baseline/threshold to expect
-        if all(b < 100 for b in self.baselines[:self.n]):
+        if all(b < 100 for b in self.baselines[: self.n]):
             peak_threshold = ADC_LOW_THRESHOLD_III - 30
         else:
             peak_threshold = ADC_LOW_THRESHOLD - 200
 
-        traces = self.traces - self.baselines[:self.n]
+        traces = self.traces - self.baselines[: self.n]
 
         n_peaks = []
         for trace in traces.T:
             n_peak = 0
             in_peak = False
             local_minimum = 0
             for value in trace:
@@ -153,28 +155,26 @@
                     if value < local_minimum:
                         local_minimum = value if value > 0 else 0
                     elif value - local_minimum > peak_threshold:
                         # enough signal over local minimum to be in a peak
                         in_peak = True
                         local_maximum = value
                         n_peak += 1
-                else:
-                    if value > local_maximum:
-                        local_maximum = value
-                    elif local_maximum - value > peak_threshold:
-                        # enough signal decrease to be out of peak
-                        in_peak = False
-                        local_minimum = value if value > 0 else 0
+                elif value > local_maximum:
+                    local_maximum = value
+                elif local_maximum - value > peak_threshold:
+                    # enough signal decrease to be out of peak
+                    in_peak = False
+                    local_minimum = value if value > 0 else 0
             n_peaks.append(n_peak)
 
         return n_peaks + self.missing
 
 
 class MeanFilter:
-
     """Filter raw traces
 
     This class replicates the behavior of the Mean_Filter.vi in the HiSPARC
     DAQ. A sawtooth-like pattern may be visible in traces due to ADC
     misalignment and the synchronization pulse (?). This filter removes such
     small oscillations but keeps significant pulses.
 
@@ -221,31 +221,29 @@
         """
         even_trace = raw_trace[::2]
         odd_trace = raw_trace[1::2]
 
         filtered_even = self.filter(even_trace)
         filtered_odd = self.filter(odd_trace)
 
-        recombined_trace = [v
-                            for eo in zip(filtered_even, filtered_odd)
-                            for v in eo]
+        recombined_trace = [v for eo in zip(filtered_even, filtered_odd) for v in eo]
         filtered_trace = self.filter(recombined_trace)
         return filtered_trace
 
     def mean_filter_with_threshold(self, trace):
         """The mean filter in case use_threshold is True"""
 
         moving_average = convolve(trace, ones(4) / 4)
         rounded_average = around(moving_average).astype(int)
 
         filtered_trace = []
         local_mean = moving_average[3]
         local_mean_rounded = rounded_average[3]
 
-        if all([abs(v - local_mean) <= self.threshold for v in trace[:4]]):
+        if all(abs(v - local_mean) <= self.threshold for v in trace[:4]):
             filtered_trace.extend([local_mean_rounded] * 4)
         else:
             filtered_trace.extend(trace[:4])
 
         for i in range(4, len(trace)):
             local_mean = moving_average[i]
             if abs(trace[i] - trace[i - 1]) > 2 * self.threshold:
@@ -279,35 +277,32 @@
             else:
                 filtered_trace.append(rounded_average[i])
 
         return filtered_trace
 
     def __repr__(self):
         try:
-            return ("%s(use_threshold=%s, threshold=%r)" %
-                    (self.__class__.__name__, True, self.threshold))
+            return '%s(use_threshold=%s, threshold=%r)' % (self.__class__.__name__, True, self.threshold)
         except AttributeError:
-            return f"{self.__class__.__name__}(use_threshold={False})"
+            return f'{self.__class__.__name__}(use_threshold={False})'
 
 
 class DataReduction:
-
     """Data reduce traces
 
     This class replicates the behavior also implemented in the HiSPARC DAQ.
     The threshold and padding values used by the DAQ may be slightly
     different, but these should closely match the defaults.
 
     The default padding of 25 samples matches the number of samples used by
     the :class:`TraceObservables` to determine the baseline.
 
     """
 
-    def __init__(self, threshold=ADC_BASELINE_THRESHOLD,
-                 padding=DATA_REDUCTION_PADDING):
+    def __init__(self, threshold=ADC_BASELINE_THRESHOLD, padding=DATA_REDUCTION_PADDING):
         """Initialize the class
 
         :param threshold: value of the threshold to use, in ADC counts.
         :param padding: number of samples to keep around the determined cuts.
 
         """
         self.threshold = threshold
@@ -322,15 +317,15 @@
             baselines will be determined using :class:`TraceObservables`.
         :param return_offset: if True the left cut will also be returned.
         :return: data reduced traces, including the left cut if return_offset
                  is True.
 
         """
         if baselines is None:
-            baselines = TraceObservables(traces).baselines[:len(traces[0])]
+            baselines = TraceObservables(traces).baselines[: len(traces[0])]
         left, right = self.determine_cuts(traces, baselines)
         left, right = self.add_padding(left, right, len(traces))
         if return_offset:
             return traces[left:right], left
         else:
             return traces[left:right]
 
@@ -342,18 +337,19 @@
         :param traces: a NumPy array of traces, ordered such that the first
                        element is the first sample of each trace.
         :param baselines: list of baselines for the traces.
         :return: indices into traces where the first signals from left and
                  right cross the threshold.
 
         """
-        left = next((i for i, t in enumerate(traces)
-                     if max(t - baselines) > self.threshold), 0)
-        right = len(traces) - next((i for i, t in enumerate(reversed(traces))
-                                    if max(t - baselines) > self.threshold), 0)
+        left = next((i for i, t in enumerate(traces) if max(t - baselines) > self.threshold), 0)
+        right = len(traces) - next(
+            (i for i, t in enumerate(reversed(traces)) if max(t - baselines) > self.threshold),
+            0,
+        )
         return left, right
 
     def add_padding(self, left, right, length=None):
         """Add padding around the cuts to allow later baseline determination
 
         The right value may be larger than the length of the traces if length
         is not given. This is only an issues if the actual value is of
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/reconstructions.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/reconstructions.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,27 +1,28 @@
-""" Reconstruct HiSPARC events and coincidences
+"""Reconstruct HiSPARC events and coincidences
 
-    This module contains classes that can be used to reconstruct
-    HiSPARC events and coincidences. These classes can be used to automate
-    the tasks of reconstructing directions and/or cores.
+This module contains classes that can be used to reconstruct
+HiSPARC events and coincidences. These classes can be used to automate
+the tasks of reconstructing directions and/or cores.
 
-    The classes can reconstruct measured data from the ESD as well as
-    simulated data from :mod:`sapphire.simulations`.
+The classes can reconstruct measured data from the ESD as well as
+simulated data from :mod:`sapphire.simulations`.
 
-    The classes read data stored in HDF5 files and extract station metadata
-    (cluster and detector layout, station and detector offsets) from
-    various sources:
+The classes read data stored in HDF5 files and extract station metadata
+(cluster and detector layout, station and detector offsets) from
+various sources:
 
-    - from the public database using :class:`sapphire.api.Station` objects
-    - from stored or provided :class`sappire.cluster.Station` objects,
-      usually cluster or station layout stored by :mod:`sapphire.simulations`
+- from the public database using :class:`sapphire.api.Station` objects
+- from stored or provided :class`sappire.cluster.Station` objects,
+  usually cluster or station layout stored by :mod:`sapphire.simulations`
 
-     Reconstructed data is stored in HDF5 files.
+ Reconstructed data is stored in HDF5 files.
 
 """
+
 import os
 import warnings
 
 from itertools import zip_longest
 
 import tables
 
@@ -32,15 +33,14 @@
 from .calibration import determine_detector_timing_offsets
 from .coincidence_queries import CoincidenceQuery
 from .core_reconstruction import CoincidenceCoreReconstruction, EventCoreReconstruction
 from .direction_reconstruction import CoincidenceDirectionReconstruction, EventDirectionReconstruction
 
 
 class ReconstructESDEvents:
-
     """Reconstruct events from single stations
 
     Example usage::
 
         >>> import tables
         >>> from sapphire import ReconstructESDEvents
 
@@ -58,18 +58,26 @@
     or::
 
         >>> plt.polar(rec.reconstructions.col('azimuth'),
         ...           rec.reconstructions.col('zenith'), 'ko', alpha=0.2)
 
     """
 
-    def __init__(self, data, station_group, station,
-                 overwrite=False, progress=True, verbose=False,
-                 destination='reconstructions',
-                 force_fresh=False, force_stale=False):
+    def __init__(
+        self,
+        data,
+        station_group,
+        station,
+        overwrite=False,
+        progress=True,
+        verbose=False,
+        destination='reconstructions',
+        force_fresh=False,
+        force_stale=False,
+    ):
         """Initialize the class.
 
         :param data: the PyTables datafile.
         :param station_group: the group containing the event table,
             the results will also be stored in this group.
         :param station: either a station number or
             :class:`sapphire.clusters.Station` object. If it is a number the
@@ -88,15 +96,15 @@
         self.overwrite = overwrite
         self.progress = progress
         self.verbose = verbose
         self.destination = destination
         self.force_fresh = force_fresh
         self.force_stale = force_stale
 
-        self.offsets = [0., 0., 0., 0.]
+        self.offsets = [0.0, 0.0, 0.0, 0.0]
 
         self._get_or_create_station_object(station)
 
         self.direction = EventDirectionReconstruction(self.station)
         self.core = EventCoreReconstruction(self.station)
 
         self.theta = []
@@ -117,52 +125,49 @@
     def reconstruct_directions(self, detector_ids=None):
         """Reconstruct direction for all events
 
         :param detector_ids: list of detector ids to use for reconstructions.
 
         """
         if len(self.core_x) and len(self.core_y):
-            initials = ({'core_x': x, 'core_y': y}
-                        for x, y in zip(self.core_x, self.core_y))
+            initials = ({'core_x': x, 'core_y': y} for x, y in zip(self.core_x, self.core_y))
         else:
             initials = []
-        angles = self.direction.reconstruct_events(self.events, detector_ids,
-                                                   self.offsets, self.progress,
-                                                   initials)
+        angles = self.direction.reconstruct_events(self.events, detector_ids, self.offsets, self.progress, initials)
         self.theta, self.phi, self.detector_ids = angles
 
     def reconstruct_cores(self, detector_ids=None):
         """Reconstruct core for all events
 
         :param detector_ids: list of detector ids to use for reconstructions.
 
         """
         if len(self.theta) and len(self.phi):
-            initials = ({'theta': theta, 'phi': phi}
-                        for theta, phi in zip(self.theta, self.phi))
+            initials = ({'theta': theta, 'phi': phi} for theta, phi in zip(self.theta, self.phi))
         else:
             initials = []
-        cores = self.core.reconstruct_events(self.events, detector_ids,
-                                             self.progress, initials)
+        cores = self.core.reconstruct_events(self.events, detector_ids, self.progress, initials)
         self.core_x, self.core_y = cores
 
     def prepare_output(self):
         """Prepare output table"""
 
         if self.destination in self.station_group:
             if self.overwrite:
-                self.data.remove_node(self.station_group, self.destination,
-                                      recursive=True)
+                self.data.remove_node(self.station_group, self.destination, recursive=True)
             else:
-                raise RuntimeError("Reconstructions table already exists for "
-                                   "%s, and overwrite is False" %
-                                   self.station_group)
+                raise RuntimeError(
+                    'Reconstructions table already exists for %s, and overwrite is False' % self.station_group,
+                )
         self.reconstructions = self.data.create_table(
-            self.station_group, self.destination, ReconstructedEvent,
-            expectedrows=self.events.nrows)
+            self.station_group,
+            self.destination,
+            ReconstructedEvent,
+            expectedrows=self.events.nrows,
+        )
         try:
             self.reconstructions._v_attrs.station = self.station
         except tables.HDF5ExtError:
             warnings.warn('Unable to store station object, to large for HDF.')
 
     def get_detector_offsets(self):
         """Get or determine detector offsets
@@ -187,98 +192,107 @@
         """
         try:
             self.offsets = [d.offset for d in self.station.detectors]
             if self.verbose:
                 print('Read detector offsets from station object.')
         except AttributeError:
             if self.station_number is not None:
-                self.offsets = api.Station(self.station_number,
-                                           force_fresh=self.force_fresh,
-                                           force_stale=self.force_stale)
+                self.offsets = api.Station(
+                    self.station_number,
+                    force_fresh=self.force_fresh,
+                    force_stale=self.force_stale,
+                )
                 if self.verbose:
                     print('Reading detector offsets from public database.')
             else:
-                self.offsets = determine_detector_timing_offsets(self.events,
-                                                                 self.station)
+                self.offsets = determine_detector_timing_offsets(self.events, self.station)
                 self.store_offsets()
                 if self.verbose:
                     print('Determined offsets from event data: ', self.offsets)
 
     def store_offsets(self):
         """Store the determined offset in a table."""
 
         if 'detector_offsets' in self.station_group:
             if self.overwrite:
-                self.data.remove_node(self.station_group.detector_offsets,
-                                      recursive=True)
+                self.data.remove_node(self.station_group.detector_offsets, recursive=True)
             else:
-                raise RuntimeError("Detector offset table already exists for "
-                                   "%s, and overwrite is False" %
-                                   self.station_group)
-        self.detector_offsets = self.data.create_array(
-            self.station_group, 'detector_offsets', self.offsets)
+                raise RuntimeError(
+                    'Detector offset table already exists for %s, and overwrite is False' % self.station_group,
+                )
+        self.detector_offsets = self.data.create_array(self.station_group, 'detector_offsets', self.offsets)
         self.detector_offsets.flush()
 
     def store_reconstructions(self):
         """Loop over list of reconstructed data and store results
 
         Unsuccessful reconstructions are also stored but with the NumPy
         NaN as reconstructed value.
 
         """
         for event, core_x, core_y, theta, phi, detector_ids in zip_longest(
-                self.events, self.core_x, self.core_y,
-                self.theta, self.phi, self.detector_ids):
-            self._store_reconstruction(event, core_x, core_y, theta, phi,
-                                       detector_ids)
+            self.events,
+            self.core_x,
+            self.core_y,
+            self.theta,
+            self.phi,
+            self.detector_ids,
+        ):
+            self._store_reconstruction(event, core_x, core_y, theta, phi, detector_ids)
         self.reconstructions.flush()
 
-    def _store_reconstruction(self, event, core_x, core_y, theta, phi,
-                              detector_ids):
+    def _store_reconstruction(self, event, core_x, core_y, theta, phi, detector_ids):
         """Store single reconstruction"""
 
         row = self.reconstructions.row
         row['id'] = event['event_id']
         row['ext_timestamp'] = event['ext_timestamp']
         try:
-            row['min_n'] = min(event['n%d' % (id + 1)] for id in detector_ids)
+            row['min_n'] = min(event['n%d' % (detector_id + 1)] for detector_id in detector_ids)
         except ValueError:
             # sometimes, all arrival times are -999 or -1, and then
             # detector_ids = []. So min([]) gives a ValueError.
-            row['min_n'] = -999.
+            row['min_n'] = -999.0
         row['x'] = core_x
         row['y'] = core_y
         row['zenith'] = theta
         row['azimuth'] = phi
-        for id in detector_ids:
-            row['d%d' % (id + 1)] = True
+        for detector_id in detector_ids:
+            row['d%d' % (detector_id + 1)] = True
         row.append()
 
     def _get_or_create_station_object(self, station):
         if isinstance(station, Station):
             self.station = station
             self.station_number = None
             if self.verbose:
-                print('Using object %s for metadata.' % self.station)
+                print(f'Using object {self.station} for metadata.')
         else:
             self.station_number = station
-            cluster = HiSPARCStations([station],
-                                      force_fresh=self.force_fresh,
-                                      force_stale=self.force_stale)
+            cluster = HiSPARCStations([station], force_fresh=self.force_fresh, force_stale=self.force_stale)
             self.station = cluster.get_station(station)
             if self.verbose:
                 print(f'Constructed object {self.station} from public database.')
 
 
 class ReconstructESDEventsFromSource(ReconstructESDEvents):
-
-    def __init__(self, source_data, dest_data, source_group, dest_group,
-                 station, overwrite=False, progress=True, verbose=False,
-                 destination='reconstructions',
-                 force_fresh=False, force_stale=False):
+    def __init__(
+        self,
+        source_data,
+        dest_data,
+        source_group,
+        dest_group,
+        station,
+        overwrite=False,
+        progress=True,
+        verbose=False,
+        destination='reconstructions',
+        force_fresh=False,
+        force_stale=False,
+    ):
         """Initialize the class.
 
         :param data: the PyTables datafile.
         :param station_group: the group containing the event table,
             the results will also be stored in this group.
         :param station: either a station number or
             :class:`sapphire.clusters.Station` object. If number the
@@ -287,42 +301,53 @@
         :param overwrite: if True overwrite existing reconstruction table.
         :param progress: if True show a progressbar while reconstructing.
         :param verbose: if True be verbose about station metadata usage.
         :param destination: alternative name for reconstruction table.
 
         """
         super().__init__(
-            source_data, source_group, station, overwrite, progress, verbose,
-            destination, force_fresh, force_stale)
+            source_data,
+            source_group,
+            station,
+            overwrite,
+            progress,
+            verbose,
+            destination,
+            force_fresh,
+            force_stale,
+        )
         self.dest_data = dest_data
         self.dest_group = dest_group
 
     def prepare_output(self):
         """Prepare output table"""
 
         dest_path = os.path.join(self.dest_group, self.destination)
 
         if dest_path in self.dest_data:
             if self.overwrite:
                 self.dest_data.remove_node(dest_path, recursive=True)
             else:
-                raise RuntimeError("Reconstructions table already exists for "
-                                   "%s, and overwrite is False" %
-                                   self.dest_group)
+                raise RuntimeError(
+                    'Reconstructions table already exists for %s, and overwrite is False' % self.dest_group,
+                )
         self.reconstructions = self.dest_data.create_table(
-            self.dest_group, self.destination, ReconstructedEvent,
-            expectedrows=self.events.nrows, createparents=True)
+            self.dest_group,
+            self.destination,
+            ReconstructedEvent,
+            expectedrows=self.events.nrows,
+            createparents=True,
+        )
         try:
             self.reconstructions._v_attrs.station = self.station
         except tables.HDF5ExtError:
             warnings.warn('Unable to store station object, to large for HDF.')
 
 
 class ReconstructSimulatedEvents(ReconstructESDEvents):
-
     """Reconstruct simulated events from single stations
 
     Simulated events use simulated meta-data (e.g. timing offsets)
     which are stored as a :class:`~sapphire.clusters.BaseCluster` object
     The object is stored as an node attribute of '/coincidences' in the
     HDF5 file. This class will try to read that object and use it's meta-data
     in reconstructions.
@@ -363,41 +388,47 @@
                 print('Using object %s for metadata.' % self.station)
         else:
             self.station_number = station
             try:
                 cluster = self.data.get_node_attr('/coincidences', 'cluster')
                 self.station = cluster.get_station(station)
                 if self.station is None:
-                    raise RuntimeError('Station %d not found in cluster'
-                                       ' object.' % self.station_number)
+                    raise RuntimeError('Station %d not found in cluster object.' % self.station_number)
                 if self.verbose:
                     print('Read object %s from datafile.' % self.station)
             except (tables.NoSuchNodeError, AttributeError):
                 raise RuntimeError('Unable to read cluster object from HDF')
 
 
 class ReconstructESDCoincidences:
-
     """Reconstruct coincidences, e.g. event between multiple stations
 
     Example usage::
 
         >>> import tables
         >>> from sapphire import ReconstructESDCoincidences
 
         >>> data = tables.open_file('2014_1_1.h5', 'a')
         >>> rec = ReconstructESDCoincidences(data, overwrite=True)
         >>> rec.reconstruct_and_store()
 
     """
 
-    def __init__(self, data, coincidences_group='/coincidences',
-                 overwrite=False, progress=True, verbose=False,
-                 destination='reconstructions', cluster=None,
-                 force_fresh=False, force_stale=False):
+    def __init__(
+        self,
+        data,
+        coincidences_group='/coincidences',
+        overwrite=False,
+        progress=True,
+        verbose=False,
+        destination='reconstructions',
+        cluster=None,
+        force_fresh=False,
+        force_stale=False,
+    ):
         """Initialize the class.
 
         :param data: the PyTables datafile.
         :param coincidences_group: the destination group.
         :param overwrite: if True overwrite existing reconstruction table.
         :param progress: if True show a progressbar while reconstructing.
         :param verbose: if True be verbose about station metadata usage.
@@ -440,62 +471,68 @@
     def reconstruct_directions(self, station_numbers=None):
         """Reconstruct direction for all events
 
         :param station_numbers: list of stations to use for reconstructions.
 
         """
         if len(self.core_x) and len(self.core_y):
-            initials = ({'core_x': x, 'core_y': y}
-                        for x, y in zip(self.core_x, self.core_y))
+            initials = ({'core_x': x, 'core_y': y} for x, y in zip(self.core_x, self.core_y))
         else:
             initials = []
-        coincidences = pbar(self.cq.all_coincidences(iterator=True),
-                            length=self.coincidences.nrows, show=self.progress)
+        coincidences = pbar(self.cq.all_coincidences(iterator=True), length=self.coincidences.nrows, show=self.progress)
         angles = self.direction.reconstruct_coincidences(
-            self.cq.all_events(coincidences, n=0), station_numbers,
-            self.offsets, progress=False, initials=initials)
+            self.cq.all_events(coincidences, n=0),
+            station_numbers,
+            self.offsets,
+            progress=False,
+            initials=initials,
+        )
         self.theta, self.phi, self.station_numbers = angles
 
     def reconstruct_cores(self, station_numbers=None):
         """Reconstruct core for all events
 
         :param station_numbers: list of stations to use for reconstructions.
 
         """
         if len(self.theta) and len(self.phi):
-            initials = ({'theta': theta, 'phi': phi}
-                        for theta, phi in zip(self.theta, self.phi))
+            initials = ({'theta': theta, 'phi': phi} for theta, phi in zip(self.theta, self.phi))
         else:
             initials = []
-        coincidences = pbar(self.cq.all_coincidences(iterator=True),
-                            length=self.coincidences.nrows, show=self.progress)
+        coincidences = pbar(self.cq.all_coincidences(iterator=True), length=self.coincidences.nrows, show=self.progress)
         cores = self.core.reconstruct_coincidences(
-            self.cq.all_events(coincidences, n=0), station_numbers,
-            progress=False, initials=initials)
+            self.cq.all_events(coincidences, n=0),
+            station_numbers,
+            progress=False,
+            initials=initials,
+        )
         self.core_x, self.core_y = cores
 
     def prepare_output(self):
         """Prepare output table"""
 
         if self.destination in self.coincidences_group:
             if self.overwrite:
-                self.data.remove_node(self.coincidences_group,
-                                      self.destination, recursive=True)
+                self.data.remove_node(self.coincidences_group, self.destination, recursive=True)
             else:
-                raise RuntimeError("Reconstructions table already exists for "
-                                   "%s, and overwrite is False" %
-                                   self.coincidences_group)
-
-        s_columns = {'s%d' % station.number: tables.BoolCol(pos=p)
-                     for p, station in enumerate(self.cluster.stations, 26)}
+                raise RuntimeError(
+                    'Reconstructions table already exists for %s, and overwrite is False' % self.coincidences_group,
+                )
+
+        s_columns = {
+            's%d' % station.number: tables.BoolCol(pos=p) for p, station in enumerate(self.cluster.stations, 26)
+        }
         description = ReconstructedCoincidence
         description.columns.update(s_columns)
         self.reconstructions = self.data.create_table(
-            self.coincidences_group, self.destination, description,
-            expectedrows=self.coincidences.nrows)
+            self.coincidences_group,
+            self.destination,
+            description,
+            expectedrows=self.coincidences.nrows,
+        )
         try:
             self.reconstructions._v_attrs.cluster = self.cluster
         except tables.HDF5ExtError:
             warnings.warn('Unable to store cluster object, to large for HDF.')
 
     def get_station_timing_offsets(self):
         """Construct a dict of :class:`~sapphire.api.Station` objects
@@ -503,44 +540,47 @@
         Try to extract offsets from provided cluster objects into a dictionary,
         to be used by the reconstructions.
         If the cluster is not available create a :class:`~sapphire.api.Station`
         object for each station in the cluster.
 
         """
         try:
-            self.offsets = {station.number: [station.gps_offset + d.offset
-                                             for d in station.detectors]
-                            for station in self.cluster.stations}
+            self.offsets = {
+                station.number: [station.gps_offset + d.offset for d in station.detectors]
+                for station in self.cluster.stations
+            }
             if self.verbose:
                 print('Using timing offsets from cluster object.')
         except AttributeError:
-            self.offsets = {station.number:
-                            api.Station(station.number,
-                                        force_fresh=self.force_fresh,
-                                        force_stale=self.force_stale)
-                            for station in self.cluster.stations}
+            self.offsets = {
+                station.number: api.Station(station.number, force_fresh=self.force_fresh, force_stale=self.force_stale)
+                for station in self.cluster.stations
+            }
             if self.verbose:
                 print('Using timing offsets from public database.')
 
     def store_reconstructions(self):
         """Loop over list of reconstructed data and store results
 
         Unsuccessful reconstructions are also stored but with the NumPy
         NaN as reconstructed value.
 
         """
         for coincidence, x, y, theta, phi, station_numbers in zip_longest(
-                self.coincidences, self.core_x, self.core_y,
-                self.theta, self.phi, self.station_numbers):
-            self._store_reconstruction(coincidence, x, y, theta, phi,
-                                       station_numbers)
+            self.coincidences,
+            self.core_x,
+            self.core_y,
+            self.theta,
+            self.phi,
+            self.station_numbers,
+        ):
+            self._store_reconstruction(coincidence, x, y, theta, phi, station_numbers)
         self.reconstructions.flush()
 
-    def _store_reconstruction(self, coincidence, core_x, core_y, theta, phi,
-                              station_numbers):
+    def _store_reconstruction(self, coincidence, core_x, core_y, theta, phi, station_numbers):
         """Store single reconstruction"""
 
         row = self.reconstructions.row
 
         row['id'] = coincidence['id']
         row['ext_timestamp'] = coincidence['ext_timestamp']
         row['x'] = core_x
@@ -561,50 +601,53 @@
         row.append()
 
     def _get_or_create_cluster_object(self, cluster):
         """Create cluster object from public database"""
 
         if cluster is None:
             s_active = self._get_active_stations()
-            cluster = HiSPARCStations(s_active,
-                                      force_fresh=self.force_fresh,
-                                      force_stale=self.force_stale)
+            cluster = HiSPARCStations(s_active, force_fresh=self.force_fresh, force_stale=self.force_stale)
             if self.verbose:
-                print('Constructed cluster %s from public database.'
-                      % self.cluster)
-        else:
-            # TODO: check cluster object isinstance
-            if self.verbose:
-                print('Using cluster %s for metadata.' % self.cluster)
+                print('Constructed cluster %s from public database.' % self.cluster)
+        elif self.verbose:
+            print('Using cluster %s for metadata.' % self.cluster)
         return cluster
 
     def _get_active_stations(self):
         """Return station numbers with non-empty event table in datafile"""
 
         active_stations = []
 
         for s_path in self.coincidences_group.s_index:
             try:
-                station_event_table = self.data.get_node(s_path.decode() +
-                                                         '/events')
+                station_event_table = self.data.get_node(s_path.decode() + '/events')
             except tables.NoSuchNodeError:
                 continue
             if not station_event_table.nrows:
                 continue
             active_stations.append(int(s_path.split(b'station_')[-1]))
 
         return active_stations
 
 
 class ReconstructESDCoincidencesFromSource(ReconstructESDCoincidences):
-
-    def __init__(self, source_data, dest_data, source_group, dest_group,
-                 overwrite=False, progress=True, verbose=False,
-                 destination='reconstructions', cluster=None,
-                 force_fresh=False, force_stale=False):
+    def __init__(
+        self,
+        source_data,
+        dest_data,
+        source_group,
+        dest_group,
+        overwrite=False,
+        progress=True,
+        verbose=False,
+        destination='reconstructions',
+        cluster=None,
+        force_fresh=False,
+        force_stale=False,
+    ):
         """Initialize the class.
 
         :param data: the PyTables datafile.
         :param station_group: the group containing the event table,
             the results will also be stored in this group.
         :param station: either a station number or
             :class:`sapphire.clusters.Station` object. If number the
@@ -613,47 +656,59 @@
         :param overwrite: if True overwrite existing reconstruction table.
         :param progress: if True show a progressbar while reconstructing.
         :param verbose: if True be verbose about station metadata usage.
         :param destination: alternative name for reconstruction table.
 
         """
         super().__init__(
-            source_data, source_group, overwrite, progress, verbose,
-            destination, cluster, force_fresh, force_stale)
+            source_data,
+            source_group,
+            overwrite,
+            progress,
+            verbose,
+            destination,
+            cluster,
+            force_fresh,
+            force_stale,
+        )
         self.dest_data = dest_data
         self.dest_group = dest_group
 
     def prepare_output(self):
         """Prepare output table"""
 
         dest_path = os.path.join(self.dest_group, self.destination)
 
         if dest_path in self.dest_data:
             if self.overwrite:
                 self.dest_data.remove_node(dest_path, recursive=True)
             else:
-                raise RuntimeError("Reconstructions table already exists for "
-                                   "%s, and overwrite is False" %
-                                   self.dest_group)
-
-        s_columns = {'s%d' % station.number: tables.BoolCol(pos=p)
-                     for p, station in enumerate(self.cluster.stations, 26)}
+                raise RuntimeError(
+                    'Reconstructions table already exists for %s, and overwrite is False' % self.dest_group,
+                )
+
+        s_columns = {
+            's%d' % station.number: tables.BoolCol(pos=p) for p, station in enumerate(self.cluster.stations, 26)
+        }
         description = ReconstructedCoincidence
         description.columns.update(s_columns)
         self.reconstructions = self.dest_data.create_table(
-            self.dest_group, self.destination, description,
-            expectedrows=self.coincidences.nrows, createparents=True)
+            self.dest_group,
+            self.destination,
+            description,
+            expectedrows=self.coincidences.nrows,
+            createparents=True,
+        )
         try:
             self.reconstructions._v_attrs.cluster = self.cluster
         except tables.HDF5ExtError:
             warnings.warn('Unable to store cluster object, to large for HDF.')
 
 
 class ReconstructSimulatedCoincidences(ReconstructESDCoincidences):
-
     """Reconstruct simulated coincidences.
 
     Simulated coincidences use simulated meta-data (e.g. timing offsets)
     which are stored as a :class:`~sapphire.clusters.BaseCluster` object
     The object is stored as an node attribute of '/coincidences' in the
     HDF5 file. This class will try to read that object and use it's meta-data
     in reconstructions.
@@ -683,18 +738,15 @@
 
         :param cluster: a :class:`~sapphire.clusters.BaseCluster` object or
             `None`.
 
         """
         if cluster is None:
             try:
-                cluster = self.data.get_node_attr(self.coincidences_group,
-                                                  'cluster')
+                cluster = self.data.get_node_attr(self.coincidences_group, 'cluster')
                 if self.verbose:
                     print('Read cluster %s from datafile.' % self.cluster)
             except (tables.NoSuchNodeError, AttributeError):
                 raise RuntimeError('Unable to read cluster object from HDF')
-        else:
-            # TODO: check cluster object
-            if self.verbose:
-                print('Using cluster %s for metadata.' % self.cluster)
+        elif self.verbose:
+            print('Using cluster %s for metadata.' % self.cluster)
         return cluster
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/analysis/time_deltas.py` & `hisparc_sapphire-3.0.0/sapphire/analysis/time_deltas.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,30 +1,31 @@
-""" Determine time differences between coincident events
+"""Determine time differences between coincident events
 
-    Determine time delta between coincidence events from station pairs.
+Determine time delta between coincidence events from station pairs.
 
-    Example usage::
+Example usage::
 
-        import datetime
+    import datetime
 
-        import tables
+    import tables
 
-        from sapphire import download_coincidences
-        from sapphire import ProcessTimeDeltas
+    from sapphire import download_coincidences
+    from sapphire import ProcessTimeDeltas
 
-        START = datetime.datetime(2015, 2, 1)
-        END = datetime.datetime(2015, 2, 5)
+    START = datetime.datetime(2015, 2, 1)
+    END = datetime.datetime(2015, 2, 5)
 
-        if __name__ == '__main__':
-            with tables.open_file('data.h5', 'w') as data:
-                download_coincidences(data, start=START, end=END)
-                td = ProcessTimeDeltas(data)
-                td.determine_and_store_time_deltas()
+    if __name__ == '__main__':
+        with tables.open_file('data.h5', 'w') as data:
+            download_coincidences(data, start=START, end=END)
+            td = ProcessTimeDeltas(data)
+            td.determine_and_store_time_deltas()
 
 """
+
 import posixpath
 import re
 
 from itertools import combinations
 
 import tables
 
@@ -34,24 +35,22 @@
 from ..storage import TimeDelta
 from ..utils import pbar
 from .coincidence_queries import CoincidenceQuery
 from .event_utils import station_arrival_time
 
 
 class ProcessTimeDeltas:
-
     """Process HiSPARC event coincidences to obtain time deltas.
 
     Use this to determine arrival time differences between station pairs which
     have coincident events.
 
     """
 
-    def __init__(self, data, coincidence_group='/coincidences', progress=True,
-                 destination='time_deltas'):
+    def __init__(self, data, coincidence_group='/coincidences', progress=True, destination='time_deltas'):
         """Initialize the class.
 
         :param data: the PyTables datafile.
         :param coincidence_group: path to the coincidences group.
         :param progress: if True show a progressbar while determining and
                          storing offsets.
         :param destination: group name for the time_deltas, as subgroup of
@@ -82,48 +81,45 @@
         """Find all unique station pairs which are in a coincidence together
 
         Assumes the stations in the s_index are sorted by station number.
 
         """
         s_index = self.cq.s_index
         re_number = re.compile('[0-9]+$')
-        s_numbers = [int(re_number.search(s_path.decode('utf-8')).group())
-                     for s_path in s_index]
+        s_numbers = [int(re_number.search(s_path.decode('utf-8')).group()) for s_path in s_index]
 
         c_index = self.cq.c_index
-        self.pairs = {(s_numbers[s1], s_numbers[s2])
-                      for c_idx in c_index
-                      for s1, s2 in combinations(sorted(c_idx[:, 0]), 2)}
+        self.pairs = {
+            (s_numbers[s1], s_numbers[s2]) for c_idx in c_index for s1, s2 in combinations(sorted(c_idx[:, 0]), 2)
+        }
 
     def get_detector_offsets(self):
         """Retrieve the API detector_timing_offset method for all pairs
 
         The detector_timing_offset methods accept a single timestamp as
         argument, and return the detector offsets for this timestamp.
 
         """
         station_numbers = {station for pair in self.pairs for station in pair}
-        self.detector_timing_offsets = {sn: Station(sn).detector_timing_offset
-                                        for sn in station_numbers}
+        self.detector_timing_offsets = {sn: Station(sn).detector_timing_offset for sn in station_numbers}
 
     def determine_time_deltas_for_pair(self, ref_station, station):
         """Determine the arrival time differences between two stations.
 
         :param ref_station,station: station numbers.
         :return: extended timestamp of the first event and time difference,
                  t - t_ref. Not corrected for altitude differences.
 
         """
         dt = []
         ets = []
         previous_ets = 0
 
         coincidences = self.cq.all([ref_station, station], iterator=True)
-        coin_events = self.cq.events_from_stations(coincidences,
-                                                   [ref_station, station])
+        coin_events = self.cq.events_from_stations(coincidences, [ref_station, station])
 
         ref_offsets = self.detector_timing_offsets[ref_station]
         offsets = self.detector_timing_offsets[station]
 
         for events in coin_events:
             ref_ets = events[0][1]['ext_timestamp']
             # Filter coincidence which is subset of previous coincidence
@@ -132,28 +128,26 @@
             else:
                 previous_ets = ref_ets
             # Filter for possibility of same station twice in coincidence
             if len(events) != 2:
                 continue
             if events[0][0] == ref_station:
                 ref_id = 0
-                id = 1
+                other_id = 1
             else:
                 ref_id = 1
-                id = 0
+                other_id = 0
 
             ref_event = events[ref_id][1]
             ref_detector_offsets = ref_offsets(ref_event['timestamp'])
-            event = events[id][1]
+            event = events[other_id][1]
             detector_offsets = offsets(event['timestamp'])
 
-            ref_t = station_arrival_time(ref_event, ref_ets, [0, 1, 2, 3],
-                                         ref_detector_offsets)
-            t = station_arrival_time(event, ref_ets, [0, 1, 2, 3],
-                                     detector_offsets)
+            ref_t = station_arrival_time(ref_event, ref_ets, [0, 1, 2, 3], ref_detector_offsets)
+            t = station_arrival_time(event, ref_ets, [0, 1, 2, 3], detector_offsets)
             if isnan(t) or isnan(ref_t):
                 continue
             dt.append(t - ref_t)
             ets.append(ref_ets)
         return ets, dt
 
     def store_time_deltas(self, ext_timestamps, time_deltas, pair):
@@ -161,24 +155,32 @@
 
         table_path = self.destination + '/station_%d/station_%d' % pair
         try:
             dt_table = self.data.get_node(table_path, 'time_deltas')
             dt_table.remove()
         except tables.NoSuchNodeError:
             pass
-        delta_data = [(ets, int(ets) / 1_000_000_000, int(ets) % 1_000_000_000,
-                       time_delta)
-                      for ets, time_delta in zip(ext_timestamps, time_deltas)]
-        table = self.data.create_table(table_path, 'time_deltas', TimeDelta,
-                                       createparents=True,
-                                       expectedrows=len(delta_data))
+        delta_data = [
+            (ets, int(ets) / 1_000_000_000, int(ets) % 1_000_000_000, time_delta)
+            for ets, time_delta in zip(ext_timestamps, time_deltas)
+        ]
+        table = self.data.create_table(
+            table_path,
+            'time_deltas',
+            TimeDelta,
+            createparents=True,
+            expectedrows=len(delta_data),
+        )
         table.append(delta_data)
         table.flush()
 
     def __repr__(self):
         if not self.data.isopen:
-            return "<finished %s>" % self.__class__.__name__
+            return '<finished %s>' % self.__class__.__name__
         coincidence_group = self.cq.coincidences._v_parent._v_pathname
-        return ("<%s, data: %r, coincidence_group: %r, progress: %r, "
-                "destination: %r>" %
-                (self.__class__.__name__, self.data.filename,
-                 coincidence_group, self.progress, self.destination))
+        return '<%s, data: %r, coincidence_group: %r, progress: %r, destination: %r>' % (
+            self.__class__.__name__,
+            self.data.filename,
+            coincidence_group,
+            self.progress,
+            self.destination,
+        )
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/api.py` & `hisparc_sapphire-3.0.0/sapphire/api.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,87 +1,87 @@
-""" Access the HiSPARC public database API.
+"""Access the HiSPARC public database API.
 
-    This provides easy classes and functions to access the HiSPARC
-    publicdb API. This takes care of the url retrieval and conversion
-    from JSON to Python dictionaries.
-
-    Example usage:
-
-    .. code-block:: python
-
-        >>> from sapphire import Station
-        >>> stations = [5, 3102, 504, 7101, 8008, 13005]
-        >>> clusters = [Station(station).cluster for station in stations]
-        >>> for station, cluster in zip(stations, clusters):
-        ...     print('Station %d is in cluster %s.' % (station, cluster))
-        Station 5 is in cluster Amsterdam.
-        Station 3102 is in cluster Leiden.
-        Station 504 is in cluster Amsterdam.
-        Station 7101 is in cluster Enschede.
-        Station 8008 is in cluster Eindhoven.
-        Station 13005 is in cluster Bristol.
+This provides easy classes and functions to access the HiSPARC
+publicdb API. This takes care of the url retrieval and conversion
+from JSON to Python dictionaries.
+
+Example usage:
+
+.. code-block:: python
+
+    >>> from sapphire import Station
+    >>> stations = [5, 3102, 504, 7101, 8008, 13005]
+    >>> clusters = [Station(station).cluster for station in stations]
+    >>> for station, cluster in zip(stations, clusters):
+    ...     print('Station %d is in cluster %s.' % (station, cluster))
+    Station 5 is in cluster Amsterdam.
+    Station 3102 is in cluster Leiden.
+    Station 504 is in cluster Amsterdam.
+    Station 7101 is in cluster Enschede.
+    Station 8008 is in cluster Eindhoven.
+    Station 13005 is in cluster Bristol.
 
 """
+
 import datetime
 import json
 import logging
 import warnings
 
 from functools import cached_property
 from io import BytesIO
-from os import extsep, path
+from pathlib import Path
 from urllib.error import HTTPError, URLError
 from urllib.parse import urljoin
 from urllib.request import urlopen
 
 from numpy import atleast_1d, count_nonzero, genfromtxt, logical_and, negative, ones, zeros
 
 from .transformations.clock import process_time
 from .utils import get_active_index, get_publicdb_base, memoize
 
 logger = logging.getLogger(__name__)
 
-LOCAL_BASE = path.join(path.dirname(__file__), 'data')
+LOCAL_BASE = Path(__file__).parent / 'data'
 
 
 def get_api_base():
     return urljoin(get_publicdb_base(), 'api/')
 
 
 def get_src_base():
     return urljoin(get_publicdb_base(), 'show/source/')
 
 
 class API:
-
     """Base API class
 
     This provided the methods to retrieve data from the API. The results
     are converted from JSON data to Python objects (dict/list/etc).
     Support is also provided for the retrieval of Source TSV data, which
     is returned as NumPy arrays.
 
     """
 
     urls = {
-        "stations": 'stations/',
-        "stations_in_subcluster": 'subclusters/{subcluster_number}/',
-        "subclusters": 'subclusters/',
-        "subclusters_in_cluster": 'clusters/{cluster_number}/',
-        "clusters": 'clusters/',
-        "clusters_in_country": 'countries/{country_number}/',
-        "countries": 'countries/',
-        "stations_with_data": 'stations/data/{year}/{month}/{day}/',
-        "stations_with_weather": 'stations/weather/{year}/{month}/{day}/',
-        "station_info": 'station/{station_number}/',
-        "has_data": 'station/{station_number}/data/{year}/{month}/{day}/',
-        "has_weather": 'station/{station_number}/weather/{year}/{month}/{day}/',
-        "configuration": 'station/{station_number}/config/{year}/{month}/{day}/',
-        "number_of_events": 'station/{station_number}/num_events/{year}/{month}/{day}/{hour}/',
-        "event_trace": 'station/{station_number}/trace/{ext_timestamp}/'
+        'stations': 'stations/',
+        'stations_in_subcluster': 'subclusters/{subcluster_number}/',
+        'subclusters': 'subclusters/',
+        'subclusters_in_cluster': 'clusters/{cluster_number}/',
+        'clusters': 'clusters/',
+        'clusters_in_country': 'countries/{country_number}/',
+        'countries': 'countries/',
+        'stations_with_data': 'stations/data/{year}/{month}/{day}/',
+        'stations_with_weather': 'stations/weather/{year}/{month}/{day}/',
+        'station_info': 'station/{station_number}/',
+        'has_data': 'station/{station_number}/data/{year}/{month}/{day}/',
+        'has_weather': 'station/{station_number}/weather/{year}/{month}/{day}/',
+        'configuration': 'station/{station_number}/config/{year}/{month}/{day}/',
+        'number_of_events': 'station/{station_number}/num_events/{year}/{month}/{day}/{hour}/',
+        'event_trace': 'station/{station_number}/trace/{ext_timestamp}/',
     }
 
     src_urls = {
         'coincidencetime': 'coincidencetime/{year}/{month}/{day}/',
         'coincidencenumber': 'coincidencenumber/{year}/{month}/{day}/',
         'eventtime': 'eventtime/{station_number}/{year}/{month}/{day}/',
         'pulseheight': 'pulseheight/{station_number}/{year}/{month}/{day}/',
@@ -93,15 +93,15 @@
         'electronics': 'electronics/{station_number}/',
         'voltage': 'voltage/{station_number}/',
         'current': 'current/{station_number}/',
         'gps': 'gps/{station_number}/',
         'trigger': 'trigger/{station_number}/',
         'layout': 'layout/{station_number}/',
         'detector_timing_offsets': 'detector_timing_offsets/{station_number}/',
-        'station_timing_offsets': 'station_timing_offsets/{station_1}/{station_2}/'
+        'station_timing_offsets': 'station_timing_offsets/{station_1}/{station_2}/',
     }
 
     def __init__(self, force_fresh=False, force_stale=False):
         """Initialize API class
 
         :param force_fresh,force_stale: if either of these is set to True the
             data must either loaded from server or from local data. Be default
@@ -116,31 +116,31 @@
 
         :param urlpath: api urlpath to retrieve (i.e. after get_api_base).
         :return: the data returned by the api as dictionary or integer.
 
         """
         urlpath = urlpath.rstrip('/')
         if self.force_fresh and self.force_stale:
-            raise Exception('Can not force fresh and stale simultaneously.')
+            raise ValueError('Can not force fresh and stale simultaneously.')
         try:
             if self.force_stale:
-                raise Exception
+                raise ValueError('Should not get data from server')
             json_data = self._retrieve_url(urlpath, base=get_api_base())
             data = json.loads(json_data)
-        except Exception:
+        except Exception as remote_error:
             if self.force_fresh:
-                raise Exception('Couldn\'t get requested data from server.')
-            localpath = path.join(LOCAL_BASE, urlpath + extsep + 'json')
+                raise RuntimeError("Couldn't get requested data from server.") from remote_error
+            localpath = LOCAL_BASE / f'{urlpath}.json'
             try:
-                with open(localpath) as localdata:
+                with localpath.open() as localdata:
                     data = json.load(localdata)
-            except Exception:
+            except Exception as local_error:
                 if self.force_stale:
-                    raise Exception('Couldn\'t find requested data locally.')
-                raise Exception('Couldn\'t get requested data from server nor find it locally.')
+                    raise RuntimeError("Couldn't find requested data locally.") from local_error
+                raise RuntimeError("Couldn't get requested data from server nor find it locally.") from remote_error
             if not self.force_stale:
                 warnings.warn('Using local data. Possibly outdated.')
 
         return data
 
     def _get_tsv(self, urlpath, names=None):
         """Retrieve a Source TSV from the HiSPARC Public Database
@@ -148,38 +148,37 @@
         :param urlpath: tsv urlpath to retrieve (i.e. path after get_src_base).
         :param names: data column names.
         :return: the data returned as array.
 
         """
         urlpath = urlpath.rstrip('/')
         if self.force_fresh and self.force_stale:
-            raise Exception('Can not force fresh and stale simultaneously.')
+            raise ValueError('Can not force fresh and stale simultaneously.')
         try:
             if self.force_stale:
-                raise Exception
+                raise ValueError('Should not get data from server')
             tsv_data = self._retrieve_url(urlpath, base=get_src_base())
-        except Exception:
+        except Exception as remote_error:
             if self.force_fresh:
-                raise Exception('Couldn\'t get requested data from server.')
-            localpath = path.join(LOCAL_BASE, urlpath + extsep + 'tsv')
+                raise RuntimeError("Couldn't get requested data from server.") from remote_error
+            localpath = LOCAL_BASE / f'{urlpath}.tsv'
             try:
                 with warnings.catch_warnings():
                     warnings.filterwarnings('ignore')
                     data = genfromtxt(localpath, delimiter='\t', dtype=None, names=names)
-            except Exception:
+            except Exception as local_error:
                 if self.force_stale:
-                    raise Exception('Couldn\'t find requested data locally.')
-                raise Exception('Couldn\'t get requested data from server nor find it locally.')
+                    raise RuntimeError("Couldn't find requested data locally.") from local_error
+                raise RuntimeError("Couldn't get requested data from server nor find it locally.") from remote_error
             if not self.force_stale:
                 warnings.warn('Using local data. Possibly outdated.')
         else:
             with warnings.catch_warnings():
                 warnings.filterwarnings('ignore')
-                data = genfromtxt(BytesIO(tsv_data.encode('utf-8')),
-                                  delimiter='\t', dtype=None, names=names)
+                data = genfromtxt(BytesIO(tsv_data.encode('utf-8')), delimiter='\t', dtype=None, names=names)
 
         return atleast_1d(data)
 
     @staticmethod
     def _retrieve_url(urlpath, base=None):
         """Open a HiSPARC API URL and read the data
 
@@ -188,21 +187,21 @@
         :return: the data returned by the api as a string
 
         """
         if base is None:
             base = get_api_base()
 
         url = urljoin(base, urlpath + '/' if urlpath else '')
-        logging.debug('Getting: ' + url)
+        logging.debug(f'Getting: {url}')
         try:
             result = urlopen(url).read().decode('utf-8')
-        except HTTPError as e:
-            raise Exception('A HTTP %d error occured for the url: %s' % (e.code, url))
+        except HTTPError as error:
+            raise RuntimeError(f'A HTTP {error.code} error occured for the url: {url}')
         except URLError:
-            raise Exception('An URL error occured.')
+            raise RuntimeError('An URL error occured.')
 
         return result
 
     @staticmethod
     def check_connection():
         """Open the API man page URL to test the connection
 
@@ -214,26 +213,25 @@
         except URLError:
             return False
         return True
 
     @staticmethod
     def validate_partial_date(year='', month='', day='', hour=''):
         if year == '' and (month != '' or day != '' or hour != ''):
-            raise Exception('You must also specify the year')
+            raise ValueError('You must also specify the year')
         elif month == '' and (day != '' or hour != ''):
-            raise Exception('You must also specify the month')
+            raise ValueError('You must also specify the month')
         elif day == '' and hour != '':
-            raise Exception('You must also specify the day')
+            raise ValueError('You must also specify the day')
 
     def __repr__(self):
-        return f"{self.__class__.__name__}(force_fresh={self.force_fresh}, force_stale={self.force_stale})"
+        return f'{self.__class__.__name__}(force_fresh={self.force_fresh}, force_stale={self.force_stale})'
 
 
 class Network(API):
-
     """Get info about the network (countries/clusters/subclusters/stations)"""
 
     @cached_property
     def _all_countries(self):
         """All countries data"""
 
         path = self.urls['countries']
@@ -428,20 +426,20 @@
         """
         columns = ('n', 'counts')
         path = self.src_urls['coincidencenumber'].format(year=year, month=month, day=day)
         return self._get_tsv(path, names=columns)
 
     @staticmethod
     def validate_numbers(country=None, cluster=None, subcluster=None):
-        if country is not None and country % 10000:
-            raise Exception('Invalid country number, must be multiple of 10000.')
+        if country is not None and country % 10_000:
+            raise ValueError('Invalid country number, must be multiple of 10000.')
         if cluster is not None and cluster % 1000:
-            raise Exception('Invalid cluster number, must be multiple of 1000.')
+            raise ValueError('Invalid cluster number, must be multiple of 1000.')
         if subcluster is not None and subcluster % 100:
-            raise Exception('Invalid subcluster number, must be multiple of 100.')
+            raise ValueError('Invalid subcluster number, must be multiple of 100.')
 
     def uptime(self, stations, start=None, end=None):
         """Get number of hours for which the given stations have been simultaneously active
 
         Using hourly eventrate data the number of hours in which the given
         stations all had data is determined. Only hours in which each station
         had a reasonable eventrate are counted, to exclude likely bad data.
@@ -453,28 +451,32 @@
         """
         data = {}
 
         if not hasattr(stations, '__len__'):
             stations = [stations]
 
         for station in stations:
-            data[station] = Station(station, force_fresh=self.force_fresh,
-                                    force_stale=self.force_stale).event_time()
+            data[station] = Station(station, force_fresh=self.force_fresh, force_stale=self.force_stale).event_time()
 
         first = min(values['timestamp'][0] for values in data.values())
         last = max(values['timestamp'][-1] for values in data.values())
 
         len_array = (last - first) // 3600 + 1
         all_active = ones(len_array)
 
-        for station in data.keys():
+        minimum_events_per_hour = 500
+        maximum_events_per_hour = 5_000
+
+        for station in data:
             is_active = zeros(len_array)
             start_i = (data[station]['timestamp'][0] - first) // 3600
             end_i = start_i + len(data[station])
-            is_active[start_i:end_i] = (data[station]['counts'] > 500) & (data[station]['counts'] < 5000)
+            is_active[start_i:end_i] = (data[station]['counts'] > minimum_events_per_hour) & (
+                data[station]['counts'] < maximum_events_per_hour
+            )
             all_active = logical_and(all_active, is_active)
 
         # filter start, end
         if start is not None:
             start_index = max(0, process_time(start) - first) // 3600
         else:
             start_index = 0
@@ -484,28 +486,27 @@
         else:
             end_index = len(all_active)
 
         return count_nonzero(all_active[start_index:end_index])
 
 
 class Station(API):
-
     """Access data about a single station"""
 
     def __init__(self, station, force_fresh=False, force_stale=False):
         """Initialize station
 
         :param station: station number.
         :param force_fresh: set to True to require data to be fresh from the server.
         :param force_stale: set to True to require data to be taken from local
                             data, not valid for all methods.
 
         """
         if force_fresh and force_stale:
-            raise Exception('Can not force fresh and stale simultaneously.')
+            raise ValueError('Can not force fresh and stale simultaneously.')
         if station not in Network(force_fresh=force_fresh, force_stale=force_stale).station_numbers():
             warnings.warn('Possibly invalid station, or without config.')
         self.force_fresh = force_fresh
         self.force_stale = force_stale
         self.station = station
 
     @cached_property
@@ -535,16 +536,20 @@
 
         :param date: date object for which to get the config
         :return: the full config for the station
 
         """
         if date is None:
             date = datetime.date.today()
-        path = (self.urls['configuration']
-                .format(station_number=self.station, year=date.year, month=date.month, day=date.day))
+        path = self.urls['configuration'].format(
+            station_number=self.station,
+            year=date.year,
+            month=date.month,
+            day=date.day,
+        )
 
         return self._get_json(path)
 
     def n_events(self, year='', month='', day='', hour=''):
         """Get number of events
 
         Note that it is possible to give only the year to get the total
@@ -554,16 +559,21 @@
         :param year,month,day,hour: the date and time for which to
             get the number. It is possible to be less specific.
         :return: the number of events recorded by the station on date.
 
         """
         self.validate_partial_date(year, month, day, hour)
 
-        path = (self.urls['number_of_events']
-                .format(station_number=self.station, year=year, month=month, day=day, hour=hour))
+        path = self.urls['number_of_events'].format(
+            station_number=self.station,
+            year=year,
+            month=month,
+            day=day,
+            hour=hour,
+        )
         return self._get_json(path)
 
     def has_data(self, year='', month='', day=''):
         """Check for HiSPARC data
 
         :param year,month,day: the date for which to check. It is
             possible to be less specific.
@@ -630,16 +640,15 @@
         """Get the pulseheight histogram
 
         :param year,month,day: the date for which to get the histogram.
         :return: array of bins and counts.
 
         """
         columns = ('pulseheight', 'ph1', 'ph2', 'ph3', 'ph4')
-        path = self.src_urls['pulseheight'].format(station_number=self.station,
-                                                   year=year, month=month, day=day)
+        path = self.src_urls['pulseheight'].format(station_number=self.station, year=year, month=month, day=day)
         return self._get_tsv(path, names=columns)
 
     def pulse_integral(self, year, month, day):
         """Get the pulseintegral histogram
 
         :param year,month,day: the date for which to get the histogram.
         :return: array of bins and counts.
@@ -675,38 +684,36 @@
         """Get the barometer dataset
 
         :param year,month,day: the date for which to get the dataset.
         :return: array of timestamps and values.
 
         """
         columns = ('timestamp', 'air_pressure')
-        path = self.src_urls['barometer'].format(station_number=self.station,
-                                                 year=year, month=month, day=day)
+        path = self.src_urls['barometer'].format(station_number=self.station, year=year, month=month, day=day)
         return self._get_tsv(path, names=columns)
 
     def temperature(self, year, month, day):
         """Get the temperature dataset
 
         :param year,month,day: the date for which to get the dataset.
         :return: array of timestamps and values.
 
         """
         columns = ('timestamp', 'temperature')
-        path = self.src_urls['temperature'].format(station_number=self.station,
-                                                   year=year, month=month, day=day)
+        path = self.src_urls['temperature'].format(station_number=self.station, year=year, month=month, day=day)
         return self._get_tsv(path, names=columns)
 
     @cached_property
     def electronics(self):
         """Get the electronics version data
 
         :return: array of timestamps and values.
 
         """
-        columns = ('timestamp', 'master', 'slave', 'master_fpga', 'slave_fpga')
+        columns = ('timestamp', 'primary', 'secondary', 'primary_fpga', 'secondary_fpga')
         path = self.src_urls['electronics'].format(station_number=self.station)
         return self._get_tsv(path, names=columns)
 
     def electronic(self, timestamp=None):
         """Get electronics version data for specific timestamp
 
         :param timestamp: timestamp for which the values are valid.
@@ -714,16 +721,15 @@
 
         """
         electronics = self.electronics
         if timestamp is None:
             idx = -1
         else:
             idx = get_active_index(electronics['timestamp'], timestamp)
-        electronic = [electronics[idx][field] for field in
-                      ('master', 'slave', 'master_fpga', 'slave_fpga')]
+        electronic = [electronics[idx][field] for field in ('primary', 'secondary', 'primary_fpga', 'secondary_fpga')]
         return electronic
 
     @cached_property
     def voltages(self):
         """Get the PMT voltage data
 
         :return: array of timestamps and values.
@@ -741,15 +747,15 @@
 
         """
         voltages = self.voltages
         if timestamp is None:
             idx = -1
         else:
             idx = get_active_index(voltages['timestamp'], timestamp)
-        voltage = [voltages[idx]['voltage%d' % i] for i in range(1, 5)]
+        voltage = [voltages[idx][f'voltage{detector_id}'] for detector_id in range(1, 5)]
         return voltage
 
     @cached_property
     def currents(self):
         """Get the PMT current data
 
         :return: array of timestamps and values.
@@ -767,15 +773,15 @@
 
         """
         currents = self.currents
         if timestamp is None:
             idx = -1
         else:
             idx = get_active_index(currents['timestamp'], timestamp)
-        current = [currents[idx]['current%d' % i] for i in range(1, 5)]
+        current = [currents[idx][f'current{detector_id}'] for detector_id in range(1, 5)]
         return current
 
     @cached_property
     def gps_locations(self):
         """Get the GPS location data
 
         :return: array of timestamps and values.
@@ -795,30 +801,43 @@
         """
         if timestamp is None:
             timestamp = process_time(datetime.date.today())
         else:
             timestamp = process_time(timestamp)
         locations = self.gps_locations
         idx = get_active_index(locations['timestamp'], timestamp)
-        location = {'latitude': locations[idx]['latitude'],
-                    'longitude': locations[idx]['longitude'],
-                    'altitude': locations[idx]['altitude']}
+        location = {
+            'latitude': locations[idx]['latitude'],
+            'longitude': locations[idx]['longitude'],
+            'altitude': locations[idx]['altitude'],
+        }
         return location
 
     @cached_property
     def triggers(self):
         """Get the trigger config data
 
         :return: array of timestamps and values.
 
         """
-        columns = ('timestamp',
-                   'low1', 'low2', 'low3', 'low4',
-                   'high1', 'high2', 'high3', 'high4',
-                   'n_low', 'n_high', 'and_or', 'external')
+        columns = (
+            'timestamp',
+            'low1',
+            'low2',
+            'low3',
+            'low4',
+            'high1',
+            'high2',
+            'high3',
+            'high4',
+            'n_low',
+            'n_high',
+            'and_or',
+            'external',
+        )
         path = self.src_urls['trigger'].format(station_number=self.station)
         return self._get_tsv(path, names=columns)
 
     def trigger(self, timestamp=None):
         """Get trigger config for specific timestamp
 
         :param timestamp: timestamp for which the values are valid.
@@ -826,32 +845,46 @@
 
         """
         triggers = self.triggers
         if timestamp is None:
             idx = -1
         else:
             idx = get_active_index(triggers['timestamp'], timestamp)
-        thresholds = [[triggers[idx]['%s%d' % (t, i)]
-                       for t in ('low', 'high')]
-                      for i in range(1, 5)]
-        trigger = [triggers[idx][t] for t in ('n_low', 'n_high', 'and_or', 'external')]
+        thresholds = [
+            [triggers[idx][f'{threshold}{detector_id}'] for threshold in ('low', 'high')] for detector_id in range(1, 5)
+        ]
+        trigger = [triggers[idx][trigger_option] for trigger_option in ('n_low', 'n_high', 'and_or', 'external')]
         return thresholds, trigger
 
     @cached_property
     def station_layouts(self):
         """Get the station layout data
 
         :return: array of timestamps and values.
 
         """
-        columns = ('timestamp',
-                   'radius1', 'alpha1', 'height1', 'beta1',
-                   'radius2', 'alpha2', 'height2', 'beta2',
-                   'radius3', 'alpha3', 'height3', 'beta3',
-                   'radius4', 'alpha4', 'height4', 'beta4')
+        columns = (
+            'timestamp',
+            'radius1',
+            'alpha1',
+            'height1',
+            'beta1',
+            'radius2',
+            'alpha2',
+            'height2',
+            'beta2',
+            'radius3',
+            'alpha3',
+            'height3',
+            'beta3',
+            'radius4',
+            'alpha4',
+            'height4',
+            'beta4',
+        )
         base = self.src_urls['layout']
         path = base.format(station_number=self.station)
         return self._get_tsv(path, names=columns)
 
     def station_layout(self, timestamp=None):
         """Get station layout data for specific timestamp
 
@@ -860,17 +893,18 @@
 
         """
         station_layouts = self.station_layouts
         if timestamp is None:
             idx = -1
         else:
             idx = get_active_index(station_layouts['timestamp'], timestamp)
-        station_layout = [[station_layouts[idx]['%s%d' % (c, i)]
-                           for c in ('radius', 'alpha', 'height', 'beta')]
-                          for i in range(1, 5)]
+        station_layout = [
+            [station_layouts[idx][f'{coordinate}{detector_id}'] for coordinate in ('radius', 'alpha', 'height', 'beta')]
+            for detector_id in range(1, 5)
+        ]
         return station_layout
 
     @cached_property
     def detector_timing_offsets(self):
         """Get the detector timing offsets data
 
         :return: array of timestamps and values.
@@ -889,28 +923,28 @@
 
         """
         detector_timing_offsets = self.detector_timing_offsets
         if timestamp is None:
             idx = -1
         else:
             idx = get_active_index(detector_timing_offsets['timestamp'], timestamp)
-        detector_timing_offset = [detector_timing_offsets[idx]['offset%d' % i] for i in range(1, 5)]
+        detector_timing_offset = [detector_timing_offsets[idx][f'offset{detector_id}'] for detector_id in range(1, 5)]
 
         return detector_timing_offset
 
     @memoize
     def station_timing_offsets(self, reference_station):
         """Get the station timing offset relative to reference_station
 
         :param reference_station: reference station
         :return: array of timestamps and values.
 
         """
         if reference_station == self.station:
-            raise Exception('Reference station cannot be the same station')
+            raise ValueError('Reference station cannot be the same station')
         if reference_station > self.station:
             station_1, station_2 = self.station, reference_station
             toggle_sign = True
         else:
             station_2, station_1 = self.station, reference_station
             toggle_sign = False
 
@@ -927,21 +961,25 @@
 
         :param reference_station: reference station
         :param timestamp: timestamp for which the value is valid.
         :return: the offset and error for given timestamp.
 
         """
         if self.station == reference_station:
-            return (0., 0.)
+            return (0.0, 0.0)
 
         station_timing_offsets = self.station_timing_offsets(reference_station)
         if timestamp is None:
             idx = -1
         else:
             idx = get_active_index(station_timing_offsets['timestamp'], timestamp)
         station_timing_offset = (station_timing_offsets[idx]['offset'], station_timing_offsets[idx]['error'])
 
         return station_timing_offset
 
     def __repr__(self):
-        return ("%s(%d, force_fresh=%s, force_stale=%s)" %
-                (self.__class__.__name__, self.station, self.force_fresh, self.force_stale))
+        return '%s(%d, force_fresh=%s, force_stale=%s)' % (
+            self.__class__.__name__,
+            self.station,
+            self.force_fresh,
+            self.force_stale,
+        )
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/clusters.py` & `hisparc_sapphire-3.0.0/sapphire/clusters.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-""" Define HiSPARC detectors, stations and clusters.
+"""Define HiSPARC detectors, stations and clusters.
 
-    The :class:`BaseCluster` defines a HiSPARC cluster consisting of one or
-    more stations.  The :class:`Station` defines a HiSPARC station,
-    consisting of one or more :class:`Detector` objects.
+The :class:`BaseCluster` defines a HiSPARC cluster consisting of one or
+more stations.  The :class:`Station` defines a HiSPARC station,
+consisting of one or more :class:`Detector` objects.
 
-    To easily create a cluster object for a specific set of real HiSPARC
-    stations the :class:`HiSPARCStations` can be used, for example::
+To easily create a cluster object for a specific set of real HiSPARC
+stations the :class:`HiSPARCStations` can be used, for example::
 
-    >>> from sapphire import HiSPARCStations
-    >>> cluster = HiSPARCStations([102, 104, 105], force_stale=True)
+>>> from sapphire import HiSPARCStations
+>>> cluster = HiSPARCStations([102, 104, 105], force_stale=True)
 
-    The use of ``force_stale`` forces the use of local data, which
-    is much faster to load than data from the server.
+The use of ``force_stale`` forces the use of local data, which
+is much faster to load than data from the server.
 
-    These cluster objects are mainly used by simulations and reconstructions.
+These cluster objects are mainly used by simulations and reconstructions.
 
 """
 
 import warnings
 
 from math import atan2, cos, pi, sin, sqrt
 
@@ -27,15 +27,15 @@
 from .transformations import axes, geographic
 from .utils import distance_between, get_active_index
 
 
 class Detector:
     """A HiSPARC detector"""
 
-    _detector_size = (.5, 1.)
+    _detector_size = (0.5, 1.0)
 
     def __init__(self, station, position, orientation='UD', detector_timestamps=None):
         """Initialize detector
 
         :param station: station instance this detector is part of.
         :param position: x,y,z position of the center of the detectors
             relative to the station center. z is optional. Multiple positions
@@ -47,35 +47,34 @@
         :param detector_timestamps: list of timestamps, the timestamp at
             which each of the layouts became active.
 
         """
         if detector_timestamps is None:
             detector_timestamps = [0]
         self.station = station
-        if hasattr(position[0], "__len__"):
+        if hasattr(position[0], '__len__'):
             self.x = position[0]
             self.y = position[1]
-            self.z = position[2] if len(position) == 3 else [0.] * len(self.x)
+            self.z = position[2] if len(position) == 3 else [0.0] * len(self.x)
         else:
             self.x = [position[0]]
             self.y = [position[1]]
-            self.z = [position[2]] if len(position) == 3 else [0.]
+            self.z = [position[2]] if len(position) == 3 else [0.0]
         if isinstance(orientation, str) and orientation == 'UD':
             self.orientation = [0] * len(self.x)
         elif isinstance(orientation, str) and orientation == 'LR':
             self.orientation = [pi / 2] * len(self.x)
+        elif hasattr(orientation, '__len__'):
+            self.orientation = orientation
         else:
-            if hasattr(orientation, "__len__"):
-                self.orientation = orientation
-            else:
-                self.orientation = [orientation]
+            self.orientation = [orientation]
         if len(detector_timestamps) == len(self.x):
             self.timestamps = detector_timestamps
         else:
-            raise Exception('Number of timestamps must equal number of postions')
+            raise ValueError('Number of timestamps must equal number of postions')
         self.index = -1
 
     def _update_timestamp(self, timestamp):
         """Get the position index valid for the given timestamp
 
         :param timestamp: timestamp in seconds.
 
@@ -157,32 +156,39 @@
         coso = cos(-o)
         sino = sin(-o)
         corners = [(x + cx * coso - cy * sino, y + cx * sino + cy * coso) for cx, cy in corners]
 
         # cluster frame
         sina = sin(alpha_station)
         cosa = cos(alpha_station)
-        corners = [(x_station + xc * cosa - yc * sina, y_station + xc * sina + yc * cosa)
-                   for xc, yc in corners]
+        corners = [(x_station + xc * cosa - yc * sina, y_station + xc * sina + yc * cosa) for xc, yc in corners]
 
         return corners
 
     def __repr__(self):
-        id = next(i for i, d in enumerate(self.station.detectors) if self is d)
-        return "<%s, id: %d, station: %r>" % (self.__class__.__name__, id, self.station)
+        detector_id = next(i for i, d in enumerate(self.station.detectors) if self is d)
+        return '<%s, id: %d, station: %r>' % (self.__class__.__name__, detector_id, self.station)
 
 
 class Station:
     """A HiSPARC station"""
 
     _detectors = None
 
-    def __init__(self, cluster, station_id, position, angle=None,
-                 detectors=None, station_timestamps=None,
-                 detector_timestamps=None, number=None):
+    def __init__(
+        self,
+        cluster,
+        station_id,
+        position,
+        angle=None,
+        detectors=None,
+        station_timestamps=None,
+        detector_timestamps=None,
+        number=None,
+    ):
         """Initialize station
 
         :param cluster: cluster this station is a part of
         :param station_id: int (unique identifier)
         :param position: x,y,z position of the station center relative
             to the cluster center, z is optional.
         :param angle: angle of rotation of the station in radians
@@ -204,42 +210,41 @@
         """
         if station_timestamps is None:
             station_timestamps = [0]
         if detector_timestamps is None:
             detector_timestamps = [0]
         self.cluster = cluster
         self.station_id = station_id
-        if hasattr(position[0], "__len__"):
+        if hasattr(position[0], '__len__'):
             self.x = position[0]
             self.y = position[1]
-            self.z = position[2] if len(position) == 3 else [0.] * len(self.x)
+            self.z = position[2] if len(position) == 3 else [0.0] * len(self.x)
         else:
             self.x = [position[0]]
             self.y = [position[1]]
-            self.z = [position[2]] if len(position) == 3 else [0.]
+            self.z = [position[2]] if len(position) == 3 else [0.0]
         if angle is None:
-            self.angle = [0.] * len(self.x)
-        elif hasattr(angle, "__len__"):
+            self.angle = [0.0] * len(self.x)
+        elif hasattr(angle, '__len__'):
             self.angle = angle
         else:
             self.angle = [angle]
         self.number = number if number else station_id
 
         if len(station_timestamps) == len(self.x):
             self.timestamps = station_timestamps
         else:
-            raise Exception('Number of timestamps must equal number of postions')
+            raise ValueError('Number of timestamps must equal number of postions')
 
         if detectors is None:
             # detector positions for a standard station
             station_size = 10
             a = station_size / 2
             b = a * sqrt(3)
-            detectors = [((0, b, 0), 'UD'), ((0, b / 3, 0), 'UD'),
-                         ((-a, 0, 0), 'LR'), ((a, 0, 0), 'LR')]
+            detectors = [((0, b, 0), 'UD'), ((0, b / 3, 0), 'UD'), ((-a, 0, 0), 'LR'), ((a, 0, 0), 'LR')]
 
         for position, orientation in detectors:
             self._add_detector(position, orientation, detector_timestamps)
         self.index = -1
 
     def _update_timestamp(self, timestamp):
         """Get the position index valid for the given timestamp
@@ -273,15 +278,15 @@
         """Get the total area covered by the detectors
 
         :param detector_ids: list of detectors for which to get the total area.
         :return: total area of the detectors in m^2.
 
         """
         if detector_ids is not None:
-            return sum(self._detectors[id].get_area() for id in detector_ids)
+            return sum(self._detectors[detector_id].get_area() for detector_id in detector_ids)
         else:
             return sum(d.get_area() for d in self._detectors)
 
     def get_xy_coordinates(self):
         """Same as get_coordinates but without the z and alpha"""
         x, y, _, _ = self.get_coordinates()
         return x, y
@@ -330,17 +335,17 @@
         """
         lla = self.cluster.lla
         x, y, z, alpha = self.get_coordinates()
         enu = (x, y, z)
 
         transform = geographic.FromWGS84ToENUTransformation(lla)
         latitude, longitude, altitude = transform.enu_to_lla(enu)
-        latitude = latitude if abs(latitude) > 1e-7 else 0.
-        longitude = longitude if abs(longitude) > 1e-7 else 0.
-        altitude = altitude if abs(altitude) > 1e-7 else 0.
+        latitude = latitude if abs(latitude) > 1e-7 else 0.0
+        longitude = longitude if abs(longitude) > 1e-7 else 0.0
+        altitude = altitude if abs(altitude) > 1e-7 else 0.0
 
         return latitude, longitude, altitude
 
     def calc_r_and_phi_for_detectors(self, d0, d1):
         r, phi, _ = self.calc_rphiz_for_detectors(d0, d1)
         return r, phi
 
@@ -376,16 +381,20 @@
         x0 = np.nanmean(x)
         y0 = np.nanmean(y)
         z0 = np.nanmean(z)
 
         return x0, y0, z0
 
     def __repr__(self):
-        return ("<%s, id: %d, number: %d, cluster: %r>" %
-                (self.__class__.__name__, self.station_id, self.number, self.cluster))
+        return '<%s, id: %d, number: %d, cluster: %r>' % (
+            self.__class__.__name__,
+            self.station_id,
+            self.number,
+            self.cluster,
+        )
 
 
 class BaseCluster:
     """Base class for HiSPARC clusters"""
 
     _stations = None
 
@@ -396,15 +405,15 @@
         :param angle: rotation of the cluster in the x,y-plane.
         :param lla: Reference WGS84 location of the cluster origin.
                     Defaults to (old) GPS location of station 501 (Nikhef).
 
         """
         self.x = position[0]
         self.y = position[1]
-        self.z = position[2] if len(position) == 3 else 0.
+        self.z = position[2] if len(position) == 3 else 0.0
         self.alpha = angle
         self.lla = lla
         # Set initial timestamp in the future to use latest positions
         # 2 ** 31 - 1 == 19 Jan 2038
         self._timestamp = 2147483647
 
     def set_timestamp(self, timestamp):
@@ -413,17 +422,23 @@
         :param timestamp: timestamp in seconds.
 
         """
         self._timestamp = timestamp
         for station in self.stations:
             station._update_timestamp(self._timestamp)
 
-    def _add_station(self, position, angle=None, detectors=None,
-                     station_timestamps=None, detector_timestamps=None,
-                     number=None):
+    def _add_station(
+        self,
+        position,
+        angle=None,
+        detectors=None,
+        station_timestamps=None,
+        detector_timestamps=None,
+        number=None,
+    ):
         """Add a station to the cluster
 
         :param position: x,y,z position of the station relative to
             cluster center. z is optional.
         :param angle: angle of rotation of the station in radians
         :param detectors: list of tuples.  Each tuple consists of (dx, dy,
             dz, orientation) where dx, dy and dz are the positions of the
@@ -450,17 +465,17 @@
         """
         # Need to make _stations an instance variable to be able to
         # pickle it.  An assignment takes care of that.
         if self._stations is None:
             self._stations = []
 
         station_id = len(self._stations)
-        self._stations.append(Station(self, station_id, position, angle,
-                                      detectors, station_timestamps,
-                                      detector_timestamps, number))
+        self._stations.append(
+            Station(self, station_id, position, angle, detectors, station_timestamps, detector_timestamps, number),
+        )
 
     def set_center_off_mass_at_origin(self):
         """Set the cluster center of mass to (0, 0, 0)"""
         self.x = 0
         self.y = 0
         self.z = 0
         x, y, z = self.calc_center_of_mass_coordinates()
@@ -580,17 +595,15 @@
     def calc_center_of_mass_coordinates(self):
         """Calculate center of mass coordinates of all detectors in cluster
 
         :return: x, y, z; coordinates of cluster center relative to
             absolute coordinate system
 
         """
-        x, y, z = zip(*[detector.get_coordinates()
-                      for station in self.stations
-                      for detector in station.detectors])
+        x, y, z = zip(*[detector.get_coordinates() for station in self.stations for detector in station.detectors])
 
         x0 = np.nanmean(x)
         y0 = np.nanmean(y)
         z0 = np.nanmean(z)
 
         return x0, y0, z0
 
@@ -636,32 +649,30 @@
             return None
 
         xy = [np.array(s.calc_center_of_mass_coordinates()[:-1]) for s in pair]
 
         return self._distance(*xy)
 
     def __repr__(self):
-        return "<%s>" % self.__class__.__name__
+        return '<%s>' % self.__class__.__name__
 
 
 class CompassStations(BaseCluster):
-
     """Add detectors to stations using compass coordinates
 
     Compass coordinates consist of r, alpha, z, beta. These define
     the location and orientation of detectors. For more information
     see `Coordinate systems and units in HiSPARC`.
 
     This is meant for data from the Publicdb Database API, which
     uses that coordinate system.
 
     """
 
-    def _add_station(self, position, detectors, station_timestamps=None,
-                     detector_timestamps=None, number=None):
+    def _add_station(self, position, detectors, station_timestamps=None, detector_timestamps=None, number=None):
         """Add a station to the cluster
 
         :param position: x,y,z coordinates of the station relative
             to cluster center (ENU), can be list of multiple positions.
         :param detectors: list of r,alpha,z,beta coordinates, these
             define the position of the detector relative to the GPS and
             the orientation of the detector. r is the distance between
@@ -687,23 +698,20 @@
         Example::
 
             >>> cluster = CompassStations()
             >>> cluster._add_station((0, 0, 0), [(7, 0, 1, 0), (7, 90, 0, 0)],
             ...                      number=104)
 
         """
-        detectors = [(axes.compass_to_cartesian(r, alpha, z), np.radians(beta))
-                     for r, alpha, z, beta in detectors]
+        detectors = [(axes.compass_to_cartesian(r, alpha, z), np.radians(beta)) for r, alpha, z, beta in detectors]
 
-        super()._add_station(
-            position, None, detectors, station_timestamps, detector_timestamps, number)
+        super()._add_station(position, None, detectors, station_timestamps, detector_timestamps, number)
 
 
 class SimpleCluster(BaseCluster):
-
     """Define a simple cluster containing four stations
 
     :param size: This value is the distance between the three outer stations.
 
     """
 
     def __init__(self, size=250):
@@ -747,37 +755,34 @@
 
         detectors = [((-5, 0, 0), 'UD'), ((5, 0, 0), 'UD')]
 
         self._add_station((0, 0, 0), 0, detectors)
 
 
 class SingleDiamondStation(BaseCluster):
-
     """Define a cluster containing a single diamond shaped station
 
     Detectors 1, 3 and 4 are in the usual position for a 4 detector
     layout, detector 2 is moved out of the center and positioned to
     create a second equilateral triangle with detectors 1, 2 and 4.
 
     """
 
     def __init__(self):
         super().__init__()
 
         station_size = 10
         a = station_size / 2
         b = a * sqrt(3)
-        detectors = [((0., b, 0), 'UD'), ((a * 2, b, 0), 'UD'),
-                     ((-a, 0., 0), 'LR'), ((a, 0., 0), 'LR')]
+        detectors = [((0.0, b, 0), 'UD'), ((a * 2, b, 0), 'UD'), ((-a, 0.0, 0), 'LR'), ((a, 0.0, 0), 'LR')]
 
         self._add_station((0, 0, 0), 0, detectors)
 
 
 class HiSPARCStations(CompassStations):
-
     """A cluster containing any real station from the HiSPARC network
 
     The gps position and number of detectors are taken from the API.
     The detector positions are retrieved if available, otherwise
     default values are used!
 
     :param stations: A list of station numbers to include. The
@@ -826,84 +831,82 @@
             # Station locations in ENU
             enu = [transformation.transform(lla) for lla in llas]
             enu = [list(coordinate) for coordinate in zip(*enu)]
 
             try:
                 detectors = station_info.station_layouts
                 fields = ('radius', 'alpha', 'height', 'beta')
-                razbs = [[detectors['%s%d' % (field, i)] for field in fields]
-                         for i in range(1, n_detectors + 1)]
+                razbs = [[detectors['%s%d' % (field, i)] for field in fields] for i in range(1, n_detectors + 1)]
                 detector_ts = detectors['timestamp']
             except Exception:
                 missing_detectors.append(station)
                 # Fallback detector positions in (r, alpha, z, beta)
                 if n_detectors == 2:
                     razbs = [(5, 90, 0, 0), (5, 270, 0, 0)]
                 elif n_detectors == 4:
                     d = 10 / sqrt(3)
                     razbs = [(d, 0, 0, 0), (0, 0, 0, 0), (d, -120, 0, 90), (d, 120, 0, 90)]
                 else:
-                    raise RuntimeError("Detector count unknown for station %d." % station)
+                    raise RuntimeError('Detector count unknown for station %d.' % station)
                 detector_ts = [0]
 
             self._add_station(enu, razbs, station_ts, detector_ts, station)
 
         self.set_center_off_mass_at_origin()
 
         if len(missing_gps):
-            warnings.warn('Could not get GPS location for stations: %s. '
-                          'Those stations are excluded.' % str(missing_gps))
+            warnings.warn(
+                'Could not get GPS location for stations: %s. Those stations are excluded.' % str(missing_gps),
+            )
         if len(missing_detectors):
-            warnings.warn('Could not get detector layout for stations %s, '
-                          'defaults will be used!' % str(missing_detectors))
+            warnings.warn(
+                'Could not get detector layout for stations %s, defaults will be used!' % str(missing_detectors),
+            )
 
     def __repr__(self):
-        return f"{self.__class__.__name__}({[s.number for s in self.stations]!r})"
+        return f'{self.__class__.__name__}({[s.number for s in self.stations]!r})'
 
 
 class ScienceParkCluster(HiSPARCStations):
-
     """A cluster containing stations from the Science Park subcluster
 
     :param stations: A list of station numbers to include. Only stations
         from the Science Park subcluster (5xx) are supported. By default 507
         is excluded.
 
     """
 
-    def __init__(self, stations=None, skip_missing=False, force_fresh=False,
-                 force_stale=False):
+    def __init__(self, stations=None, skip_missing=False, force_fresh=False, force_stale=False):
         if stations is None:
             network = api.Network(force_fresh, force_stale)
             stations = [sn for sn in network.station_numbers(subcluster=500) if sn != 507]
         else:
             stations = [sn for sn in stations if 500 < sn < 600]
         super().__init__(stations, skip_missing, force_fresh, force_stale)
 
 
 class HiSPARCNetwork(HiSPARCStations):
-
     """A cluster containing all station from the HiSPARC network"""
 
     def __init__(self, force_fresh=False, force_stale=False):
         network = api.Network(force_fresh, force_stale)
         stations = network.station_numbers()
         skip_missing = True  # Likely some station without GPS location
         super().__init__(stations, skip_missing, force_fresh, force_stale)
 
     def __repr__(self):
-        return "<%s>" % self.__class__.__name__
+        return '<%s>' % self.__class__.__name__
 
 
 def flatten_cluster(cluster):
     """Set the altitudes for all detectors in a cluster object to z=0
 
     Modify the given cluster by setting the z coordinates of the stations
     and detectors to 0.
 
     :param cluster: :class:`BaseCluster` object.
 
     """
     for station in cluster.stations:
-        station.z = [0.] * len(station.z)
+        station.z = [0.0] * len(station.z)
         for detector in station.detectors:
-            detector.z = [0.] * len(detector.z)
+            detector.z = [0.0] * len(detector.z)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/LICENSE` & `hisparc_sapphire-3.0.0/sapphire/corsika/LICENSE`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/__init__.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -26,13 +26,11 @@
 :mod:`~sapphire.corsika.store_corsika_data`
     convert CORSIKA data files to HDF5 files
 
 :mod:`~sapphire.corsika.units`
     convert values in units used by CORSIKA to HiSPARC units
 
 """
+
 from . import corsika_queries, particles, reader, units
 
-__all__ = ['corsika_queries',
-           'particles',
-           'reader',
-           'units']
+__all__ = ['corsika_queries', 'particles', 'reader', 'units']
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/blocks.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/blocks.py`

 * *Files 9% similar despite different names*

```diff
@@ -6,29 +6,30 @@
 
 Author: Javier Gonzalez
 """
 
 import math
 import struct
 
-import numpy
+import numpy as np
 
 from . import particles, units
 
 try:
     from numba import jit
 except ImportError:
+
     def jit(func):
         return func
 
 
 # All sizes are in bytes
 
-class Format:
 
+class Format:
     """The binary format information of the file.
 
     As specified in the CORSIKA user manual, Section 10.2.1.
 
     """
 
     def __init__(self):
@@ -53,81 +54,80 @@
         # for a total of 39 records per sub block
         self.fields_per_particle = 7
         self.particle_format = '%df' % self.fields_per_particle
         self.particle_size = struct.calcsize(self.particle_format)
         self.particles_per_subblock = 39
 
         # Full particle sub block
-        self.particles_format = (self.particle_format *
-                                 self.particles_per_subblock)
+        self.particles_format = self.particle_format * self.particles_per_subblock
         self.particles_size = self.particle_size * self.particles_per_subblock
 
     def __repr__(self):
         return '%s()' % self.__class__.__name__
 
 
 # From here on, things should not depend on the field size as everything is
 
-class RunHeader:
 
+class RunHeader:
     """The run header sub-block
 
     As specified in the CORSIKA user manual, Table 7.
 
     """
 
     def __init__(self, subblock):
         self.id = subblock[0]
         self.run_number = subblock[1]
         self.date_start = subblock[2]
         self.version = subblock[3]
 
         self.observation_levels = subblock[4]
-        self.observation_heights = numpy.array(subblock[5:15]) * units.cm
+        self.observation_heights = np.array(subblock[5:15]) * units.cm
 
         self.spectral_slope = subblock[15]
         self.min_energy = subblock[16] * units.GeV
         self.max_energy = subblock[17] * units.GeV
 
         self.flag_EGS4 = subblock[18]
         self.flag_NKG = subblock[19]
 
         self.cutoff_hadrons = subblock[20] * units.GeV
         self.cutoff_muons = subblock[21] * units.GeV
         self.cutoff_electrons = subblock[22] * units.GeV
         self.cutoff_photons = subblock[23] * units.GeV
 
-        self.C = numpy.array(subblock[24:74])
+        self.C = np.array(subblock[24:74])
 
         self.x_inclined = subblock[74]
         self.y_inclined = subblock[75]
         self.z_inclined = subblock[76]
         self.theta_inclined = subblock[77]
         self.phi_inclined = subblock[78]
 
         self.n_showers = subblock[92]
-        self.CKA = numpy.array(subblock[94:134])
-        self.CETA = numpy.array(subblock[134:139])
-        self.CSTRBA = numpy.array(subblock[139:150])
+        self.CKA = np.array(subblock[94:134])
+        self.CETA = np.array(subblock[134:139])
+        self.CSTRBA = np.array(subblock[139:150])
 
         self.x_scatter_Cherenkov = subblock[247]
         self.y_scatter_Cherenkov = subblock[248]
-        self.atmospheric_layer_boundaries = numpy.array(subblock[249:254])
-        self.a_atmospheric = numpy.array(subblock[254:259])
-        self.b_atmospheric = numpy.array(subblock[259:264])
-        self.c_atmospheric = numpy.array(subblock[264:269])
+        self.atmospheric_layer_boundaries = np.array(subblock[249:254])
+        self.a_atmospheric = np.array(subblock[254:259])
+        self.b_atmospheric = np.array(subblock[259:264])
+        self.c_atmospheric = np.array(subblock[264:269])
         self.NFLAIN = subblock[269]
         self.NFLDIF = subblock[270]
-        self.NFLPIF = numpy.floor(subblock[271] / 100)
+        self.NFLPIF = np.floor(subblock[271] / 100)
         self.NFLPI0 = subblock[271] % 100
-        self.NFRAGM = numpy.floor(subblock[272] / 100)
+        self.NFRAGM = np.floor(subblock[272] / 100)
         self.NFLCHE = subblock[272] % 100
 
     def thickness_to_height(self, thickness):
-        """"Calculate height (m) for given thickness (gramms/cm**2)
+        """ "Calculate height (m) for given thickness (gramms/cm**2)
 
         As specified in the CORSIKA user manual, Appendix D.
 
         """
         a, b, c = self.a_atmospheric, self.b_atmospheric, self.c_atmospheric
 
         layers = [layer * units.cm for layer in self.atmospheric_layer_boundaries]
@@ -170,15 +170,14 @@
             # >100 km
             thickness = a[4] - b[4] * height / c[4]
 
         return thickness
 
 
 class EventHeader:
-
     """The event header sub-block
 
     As specified in the CORSIKA user manual, Table 8.
 
     """
 
     def __init__(self, subblock):
@@ -188,44 +187,42 @@
         self.particle = particles.name(subblock[2])
         self.energy = subblock[3] * units.GeV
         self.starting_altitude = subblock[4] * units.g / units.cm2
         self.first_target = subblock[5]
         self.first_interaction_altitude = subblock[6] * units.cm
         self.p_x = subblock[7] * units.GeV
         self.p_y = subblock[8] * units.GeV
-        self.p_z = - subblock[9] * units.GeV  # Same direction as axis
+        self.p_z = -subblock[9] * units.GeV  # Same direction as axis
         self.zenith = subblock[10] * units.rad
 
         # CORSIKA coordinate conventions are shown in Figure 1 of the manual.
         # CORSIKA defines azimuth as the direction the shower points to,
         # HiSPARC defines azimuth as the direction the shower comes from.
         # CORSIKA allows azimuths in [-2pi, 2pi], HiSPARC uses [-pi, pi).
         # CORSIKA defines North as 0 rad, HiSPARC defines East as 0 rad.
         # So finally we need to subtract pi/2 rad from the azimuth and
         # normalize its range.
         azimuth_corsika = subblock[11] * units.rad
-        azimuth = azimuth_corsika - (math.pi / 2.)
+        azimuth = azimuth_corsika - (math.pi / 2.0)
         if azimuth >= math.pi:
             self.azimuth = azimuth - (2 * math.pi)
         elif azimuth < -math.pi:
             self.azimuth = azimuth + (2 * math.pi)
         else:
             self.azimuth = azimuth
 
         self.n_seeds = subblock[12]
-        self.seeds = numpy.array(list(zip(subblock[13:41:3],
-                                          subblock[14:42:3],
-                                          subblock[15:43:3])))
+        self.seeds = np.array(list(zip(subblock[13:41:3], subblock[14:42:3], subblock[15:43:3])))
 
         self.run_number = subblock[43]
         self.date_start = subblock[44]
         self.version = subblock[45]
 
         self.n_observation_levels = subblock[46]
-        self.observation_heights = numpy.array(subblock[47:57]) * units.cm
+        self.observation_heights = np.array(subblock[47:57]) * units.cm
 
         self.spectral_slope = subblock[57]
         self.min_energy = subblock[58] * units.GeV
         self.max_energy = subblock[59] * units.GeV
 
         self.cutoff_hadrons = subblock[60] * units.GeV
         self.cutoff_muons = subblock[61] * units.GeV
@@ -267,16 +264,16 @@
         self.array_rotation = subblock[92] * units.rad
         self.flag_extra_muon_information = subblock[93]
 
         self.multiple_scattering_step_length_factor = subblock[94]
         self.Cherenkov_wavelength_min = subblock[95] * units.nanometer
         self.Cherenkov_wavelength_max = subblock[96] * units.nanometer
         self.uses_of_Cherenkov_event = subblock[97]
-        self.core_x = numpy.array(subblock[98:118]) * units.cm
-        self.core_y = numpy.array(subblock[118:138]) * units.cm
+        self.core_x = np.array(subblock[98:118]) * units.cm
+        self.core_y = np.array(subblock[118:138]) * units.cm
 
         self.flag_SIBYLL = subblock[138]
         self.flag_SIBYLL_cross = subblock[139]
         self.flag_QGSJET = subblock[140]
         self.flag_QGSJET_cross = subblock[141]
         self.flag_DPMJET = subblock[142]
         self.flag_DPMJET_cross = subblock[143]
@@ -316,55 +313,49 @@
     @property
     def hadron_model_low(self):
         hadron_models_low = {1: 'GHEISHA', 2: 'UrQMD', 3: 'FLUKA'}
         return hadron_models_low.get(self.flag_hadron_model_low, 'unknown')
 
     @property
     def hadron_model_high(self):
-        hadron_models_high = {0: 'HDPM', 1: 'VENUS', 2: 'SIBYLL', 3: 'QGSJET',
-                              4: 'DPMJET', 5: 'NEXUS', 6: 'EPOS'}
+        hadron_models_high = {0: 'HDPM', 1: 'VENUS', 2: 'SIBYLL', 3: 'QGSJET', 4: 'DPMJET', 5: 'NEXUS', 6: 'EPOS'}
         return hadron_models_high.get(self.flag_hadron_model_high, 'unknown')
 
     @property
     def computer(self):
         computers = {3: 'UNIX', 4: 'Macintosh'}
         return computers.get(self.flag_computer, 'unknown')
 
     def __repr__(self):
-        return ('<%s, particle: %r, energy: 10**%.1f eV, zenith: %r deg,'
-                ' azimuth: %r deg>' %
-                (self.__class__.__name__, self.particle,
-                 math.log10(self.energy), math.degrees(self.zenith),
-                 math.degrees(self.azimuth)))
+        return '<%s, particle: %r, energy: 10**%.1f eV, zenith: %r deg, azimuth: %r deg>' % (
+            self.__class__.__name__,
+            self.particle,
+            math.log10(self.energy),
+            math.degrees(self.zenith),
+            math.degrees(self.azimuth),
+        )
 
 
 class RunEnd:
-
     """The run end sub-block
 
     As specified in the CORSIKA user manual, Table 14.
 
     """
 
     def __init__(self, subblock):
         self.id = subblock[0]
         self.run_number = subblock[1]
         self.n_events_processed = subblock[2]
 
     def __repr__(self):
-        return '{}(({!r}, {!r}, {!r}))'.format(
-            self.__class__.__name__,
-            self.id,
-            self.run_number,
-            self.n_events_processed
-        )
+        return f'{self.__class__.__name__}(({self.id!r}, {self.run_number!r}, {self.n_events_processed!r}))'
 
 
 class EventEnd:
-
     """The event end sub-block
 
     As specified in the CORSIKA user manual, Table 13.
 
     """
 
     def __init__(self, subblock):
@@ -374,37 +365,36 @@
         self.n_photons_levels = subblock[2]
         self.n_electrons_levels = subblock[3]
         self.n_hadrons_levels = subblock[4]
         self.n_muons_levels = subblock[5]
         self.n_particles_levels = subblock[6]
 
         # NKG output
-        self.NKG_lateral_1_x = numpy.array(subblock[7:28]) / units.cm2
-        self.NKG_lateral_1_y = numpy.array(subblock[28:49]) / units.cm2
-        self.NKG_lateral_1_xy = numpy.array(subblock[49:70]) / units.cm2
-        self.NKG_lateral_1_yx = numpy.array(subblock[70:91]) / units.cm2
-
-        self.NKG_lateral_2_x = numpy.array(subblock[91:112]) / units.cm2
-        self.NKG_lateral_2_y = numpy.array(subblock[112:133]) / units.cm2
-        self.NKG_lateral_2_xy = numpy.array(subblock[133:154]) / units.cm2
-        self.NKG_lateral_2_yx = numpy.array(subblock[154:175]) / units.cm2
-
-        self.NKG_electron_number = numpy.array(subblock[175:185])
-        self.NKG_pseudo_age = numpy.array(subblock[185:195])
-        self.NKG_electron_distances = numpy.array(subblock[195:205]) * units.cm
-        self.NKG_local_pseudo_age_1 = numpy.array(subblock[205:215])
-
-        self.NKG_level_height_mass = numpy.array(subblock[215:225])
-        self.NKG_level_height_distance = numpy.array(subblock[225:235])
-        self.NKG_distance_bins_local_pseudo_age = \
-            numpy.array(subblock[235:245]) * units.cm
-        self.NKG_local_pseudo_age_2 = numpy.array(subblock[245:255])
+        self.NKG_lateral_1_x = np.array(subblock[7:28]) / units.cm2
+        self.NKG_lateral_1_y = np.array(subblock[28:49]) / units.cm2
+        self.NKG_lateral_1_xy = np.array(subblock[49:70]) / units.cm2
+        self.NKG_lateral_1_yx = np.array(subblock[70:91]) / units.cm2
+
+        self.NKG_lateral_2_x = np.array(subblock[91:112]) / units.cm2
+        self.NKG_lateral_2_y = np.array(subblock[112:133]) / units.cm2
+        self.NKG_lateral_2_xy = np.array(subblock[133:154]) / units.cm2
+        self.NKG_lateral_2_yx = np.array(subblock[154:175]) / units.cm2
+
+        self.NKG_electron_number = np.array(subblock[175:185])
+        self.NKG_pseudo_age = np.array(subblock[185:195])
+        self.NKG_electron_distances = np.array(subblock[195:205]) * units.cm
+        self.NKG_local_pseudo_age_1 = np.array(subblock[205:215])
+
+        self.NKG_level_height_mass = np.array(subblock[215:225])
+        self.NKG_level_height_distance = np.array(subblock[225:235])
+        self.NKG_distance_bins_local_pseudo_age = np.array(subblock[235:245]) * units.cm
+        self.NKG_local_pseudo_age_2 = np.array(subblock[245:255])
 
         # Longitudinal distribution
-        self.longitudinal_parameters = numpy.array(subblock[255:261])
+        self.longitudinal_parameters = np.array(subblock[255:261])
         self.chi2_longitudinal_fit = subblock[261]
 
         self.n_photons_output = subblock[262]
         self.n_electrons_output = subblock[263]
         self.n_hadrons_output = subblock[264]
         self.n_muons_output = subblock[265]
         self.n_preshower_EM_particles = subblock[266]
@@ -434,23 +424,22 @@
     p_x = subblock[1] * units.GeV
     p_y = subblock[2] * units.GeV
     p_z = -p_z_corsika
     x = -y_corsika
     y = x_corsika
     t = subblock[6] * units.ns  # or z for additional muon info
 
-    id = description // 1000
+    particle_id = description // 1000
     hadron_generation = description // 10 % 100
     observation_level = description % 10
 
-    r = math.sqrt(x ** 2 + y ** 2)
+    r = math.sqrt(x**2 + y**2)
     phi = math.atan2(y, x)
 
-    return (p_x, p_y, p_z, x, y, t, id, r, hadron_generation,
-            observation_level, phi)
+    return (p_x, p_y, p_z, x, y, t, particle_id, r, hadron_generation, observation_level, phi)
 
 
 @jit
 def particle_data_thin(subblock):
     """Get thinned particle data.
 
     Similar to :func:`particle_data`, but includes particle weight.
@@ -459,25 +448,34 @@
              observation_level, phi, weight data.
 
     """
     return particle_data(subblock[:7]) + (subblock[7],)
 
 
 class ParticleData:
-
     """The particle data sub-block
 
     As specified in the CORSIKA user manual, Table 10.
 
     """
 
     def __init__(self, subblock):
-        self.p_x, self.p_y, self.p_z, self.x, self.y, self.t, self.id, \
-            self.r, self.hadron_generation, self.observation_level, \
-            self.phi = particle_data(subblock)
+        (
+            self.p_x,
+            self.p_y,
+            self.p_z,
+            self.x,
+            self.y,
+            self.t,
+            self.id,
+            self.r,
+            self.hadron_generation,
+            self.observation_level,
+            self.phi,
+        ) = particle_data(subblock)
 
     @property
     def is_detectable(self):
         """Get True or False if the particle is detectable
 
         Note: gamma particles are currently not included.
 
@@ -494,15 +492,15 @@
 
     @property
     def is_nucleus(self):
         return 200 <= self.id < 9900 or self.id == 14
 
     @property
     def is_cherenkov(self):
-        return 9900 <= self.id
+        return self.id >= 9900
 
     @property
     def atomic_number(self):
         if self.is_nucleus:
             if self.id == 14:
                 return 1
             else:
@@ -514,21 +512,24 @@
     def atom(self):
         if self.is_nucleus:
             return particles.name(self.atomic_number)
         else:
             return None
 
     def __repr__(self):
-        return ('<%s, particle: %r, x: %r m, y: %r m, t: %r ns>' %
-                (self.__class__.__name__, self.particle, self.x, self.y,
-                 self.t))
+        return '<%s, particle: %r, x: %r m, y: %r m, t: %r ns>' % (
+            self.__class__.__name__,
+            self.particle,
+            self.x,
+            self.y,
+            self.t,
+        )
 
 
 class CherenkovData:
-
     """The cherenkov photon sub-block
 
     As specified in CORSIKA user manual, Table 11.
 
     The number of CherenkovData records in a sub-block depends on
     compilation options.
 
@@ -542,16 +543,16 @@
         self.v = subblock[4]
         self.t = subblock[5] * units.ns
         self.production_height = subblock[6] * units.cm
 
 
 # THIN versions
 
-class FormatThin(Format):
 
+class FormatThin(Format):
     """The format information of the thinned file
 
     As specified in CORSIKA user manual, Section 10.2.2.
 
     """
 
     def __init__(self):
@@ -572,35 +573,43 @@
         # With the thinned option, each of these is 8 fields long
         # for a total of 39 records per sub block
         self.fields_per_particle = 8
         self.particle_format = '%df' % self.fields_per_particle
         self.particle_size = struct.calcsize(self.particle_format)
 
         # Full particle sub block
-        self.particles_format = (self.particle_format *
-                                 self.particles_per_subblock)
+        self.particles_format = self.particle_format * self.particles_per_subblock
         self.particles_size = self.particle_size * self.particles_per_subblock
 
 
 class ParticleDataThin(ParticleData):
-
     """The thinned particle data sub-block
 
     As specified in the CORSIKA user manual, Table 10.
 
     """
 
     def __init__(self, subblock):
-        self.p_x, self.p_y, self.p_z, self.x, self.y, self.t, self.id, \
-            self.r, self.hadron_generation, self.observation_level, \
-            self.phi, self.weight = particle_data_thin(subblock)
+        (
+            self.p_x,
+            self.p_y,
+            self.p_z,
+            self.x,
+            self.y,
+            self.t,
+            self.id,
+            self.r,
+            self.hadron_generation,
+            self.observation_level,
+            self.phi,
+            self.weight,
+        ) = particle_data_thin(subblock)
 
 
 class CherenkovDataThin(CherenkovData):
-
     """The thinned cherenkov photon sub-block
 
     As specified in CORSIKA user manual, Table 11.
 
     The number of CherenkovData records in a sub-block depends on
     compilation options.
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/corsika_queries.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/corsika_queries.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 
 from numpy import degrees, log10, radians
 
 from .particles import name, particle_id
 
 
 class CorsikaQuery:
-
     def __init__(self, data, simulations_group='/simulations'):
         """Setup variables to point to the tables
 
         :param data: either a PyTables file or path to a HDF5 file
         :param simulations_group: path to the simulations group
 
         """
@@ -102,16 +101,15 @@
         """All available zeniths
 
         :return: set of available simulation zeniths.
 
         """
         return {degrees(zenith) for zenith in set(self.sims.col('zenith'))}
 
-    def simulations(self, particle='proton', energy=None, zenith=None,
-                    azimuth=None, iterator=False):
+    def simulations(self, particle='proton', energy=None, zenith=None, azimuth=None, iterator=False):
         """Set of available energies given the requirements
 
         :param particle: primary particle must be this kind, name of particle.
                          Defaults to proton.
         :param energy: primary energy must be this value, in log10(eV).
         :param zenith: shower zenith must be this value, in degrees.
         :param azimuth: shower azimuth must be this value, in degrees.
@@ -180,27 +178,27 @@
         :return: query.
 
         """
         query = f'(abs({key} - {value}) < 1e-4)'
 
         return query
 
-    def range_filter(self, key, min=None, max=None):
+    def range_filter(self, key, min_value=None, max_value=None):
         """Filter to be in a range
 
         :param key: variable to filter.
-        :param min,max: limits on the value.
+        :param min_value,max_value: limits on the value.
         :return: query.
 
         """
         queries = []
-        if min is not None:
-            queries.append(f'({key} >= {min})')
-        if max is not None:
-            queries.append(f'({key} <= {max})')
+        if min_value is not None:
+            queries.append(f'({key} >= {min_value})')
+        if max_value is not None:
+            queries.append(f'({key} <= {max_value})')
         query = ' & '.join(queries)
 
         return query
 
     def perform_query(self, query, iterator=False):
         """Perform a query on the simulations table
 
@@ -216,11 +214,9 @@
         else:
             filtered_simulations = self.all_simulations(iterator)
 
         return filtered_simulations
 
     def __repr__(self):
         if not self.data.isopen:
-            return "<finished %s>" % self.__class__.__name__
-        return ("%s(%r, simulations_group=%r)" %
-                (self.__class__.__name__, self.data.filename,
-                 self.sims._v_pathname))
+            return '<finished %s>' % self.__class__.__name__
+        return '%s(%r, simulations_group=%r)' % (self.__class__.__name__, self.data.filename, self.sims._v_pathname)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/generate_corsika_overview.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/generate_corsika_overview.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,21 @@
-""" Generate an overview table of the CORSIKA simulations
+"""Generate an overview table of the CORSIKA simulations
 
-    This script will look for all completed and converted CORSIKA
-    simulations in the given data path. Information about each
-    simulation is collected and then summarized in a new h5 file as an
-    overview.
-
-    The given source path should contain subdirectories named after the
-    seeds used for the simulation in the format ``{seed1}_{seed2}``,
-    e.g. ``821280921_182096636``. These in turn should contain converted
-    CORSIKA simulation results called ``corsika.h5``.
+This script will look for all completed and converted CORSIKA
+simulations in the given data path. Information about each
+simulation is collected and then summarized in a new h5 file as an
+overview.
+
+The given source path should contain subdirectories named after the
+seeds used for the simulation in the format ``{seed1}_{seed2}``,
+e.g. ``821280921_182096636``. These in turn should contain converted
+CORSIKA simulation results called ``corsika.h5``.
 
 """
+
 import argparse
 import glob
 import logging
 import os
 import shutil
 import tempfile
 
@@ -117,16 +118,15 @@
     :param n: the number of simulations, i.e. expected number of rows.
     :return: path to the temporary file and a PyTables handler for the file.
 
     """
     os.umask(0o02)
     tmp_path = create_tempfile_path()
     overview = tables.open_file(tmp_path, 'w')
-    overview.create_table('/', 'simulations', Simulations,
-                          'Simulations overview', expectedrows=n)
+    overview.create_table('/', 'simulations', Simulations, 'Simulations overview', expectedrows=n)
     return tmp_path, overview
 
 
 def create_tempfile_path():
     fd, path = tempfile.mkstemp('.h5')
     os.close(fd)
     return path
@@ -135,16 +135,16 @@
 def move_tempfile_to_destination(tmp_path, destination):
     shutil.move(tmp_path, destination)
 
 
 def all_seeds(source):
     """Get set of all seeds in the corsika data directory"""
 
-    dirs = glob.glob(os.path.join(source, '*_*'))
-    seeds = [os.path.basename(dir) for dir in dirs]
+    directories = glob.glob(os.path.join(source, '*_*'))
+    seeds = [os.path.basename(directory) for directory in directories]
     return sorted(set(seeds))
 
 
 def generate_corsika_overview(source, destination, progress=False):
     """Create an overview of CORSIKA simulations for use by CorsikaQuery
 
     :param source: directory containing the CORSIKA simulations.
@@ -159,39 +159,34 @@
     get_simulations(source, simulations, overview, progress=progress)
     overview.close()
     move_tempfile_to_destination(tmp_path, destination)
     logger.info('Finished generating overview.')
 
 
 def main():
-    parser = argparse.ArgumentParser(description='Generate an overview of '
-                                                 'CORSIKA simulations.')
-    parser.add_argument('source', nargs='?', default=DATA_PATH,
-                        help="directory path containing CORSIKA simulations")
-    parser.add_argument('destination', nargs='?', default=OUTPUT_PATH,
-                        help="path of the HDF5 output file")
-    parser.add_argument('--progress', action='store_true',
-                        help='show progressbar during generation')
-    parser.add_argument('--log', action='store_true',
-                        help='write logs to file, only for use on server')
-    parser.add_argument('--lazy', action='store_true',
-                        help='only run if the overview is outdated')
+    parser = argparse.ArgumentParser(description='Generate an overview of CORSIKA simulations.')
+    parser.add_argument('source', nargs='?', default=DATA_PATH, help='directory path containing CORSIKA simulations')
+    parser.add_argument('destination', nargs='?', default=OUTPUT_PATH, help='path of the HDF5 output file')
+    parser.add_argument('--progress', action='store_true', help='show progressbar during generation')
+    parser.add_argument('--log', action='store_true', help='write logs to file, only for use on server')
+    parser.add_argument('--lazy', action='store_true', help='only run if the overview is outdated')
     args = parser.parse_args()
     if args.log:
-        logging.basicConfig(filename=LOGFILE, filemode='a',
-                            format='%(asctime)s %(name)s %(levelname)s: '
-                                   '%(message)s',
-                            datefmt='%y%m%d_%H%M%S', level=logging.INFO)
+        logging.basicConfig(
+            filename=LOGFILE,
+            filemode='a',
+            format='%(asctime)s %(name)s %(levelname)s: %(message)s',
+            datefmt='%y%m%d_%H%M%S',
+            level=logging.INFO,
+        )
     if args.lazy:
         last_store = os.path.getmtime(args.source)
         last_overview = os.path.getmtime(args.destination)
         if last_overview > last_store:
             logger.info('Overview up to date.')
             return
 
-    generate_corsika_overview(source=args.source,
-                              destination=args.destination,
-                              progress=args.progress)
+    generate_corsika_overview(source=args.source, destination=args.destination, progress=args.progress)
 
 
 if __name__ == '__main__':
     main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/mergesort.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/mergesort.py`

 * *Files 3% similar despite different names*

```diff
@@ -5,26 +5,32 @@
 
 import tables
 
 from sapphire.utils import pbar
 
 
 class TableMergeSort:
-
-    """ Sort a PyTables HDF5 table either in memory or on-disk """
+    """Sort a PyTables HDF5 table either in memory or on-disk"""
 
     _iterators = []
-    _BUFSIZE = 100000
+    _BUFSIZE = 100_000
     hdf5_temp = None
 
-    def __init__(self, key, inputfile, outputfile=None, tempfile=None,
-                 tablename='groundparticles', destination=None,
-                 overwrite=False, progress=True):
-
-        """ Initialize the class
+    def __init__(
+        self,
+        key,
+        inputfile,
+        outputfile=None,
+        tempfile=None,
+        tablename='groundparticles',
+        destination=None,
+        overwrite=False,
+        progress=True,
+    ):
+        """Initialize the class
 
         :param key: the name of the column which is to be sorted.
         :param inputfile: PyTables HDF5 input file.
         :param outputfile: optional PyTables HDF5 output file. If None the
             inputfile will be used for output.
         :param tempfile: optional PyTables HDF5 tempfile. If not specified
              a temp file will be created and removed when finished.
@@ -44,49 +50,44 @@
         self.tempfile = tempfile
 
         if outputfile is None:
             if destination is not None:
                 self.hdf5_out = inputfile
                 self.destination = destination
             else:
-                raise RuntimeError("Must specify either an outputfile or a "
-                                   "destination table")
+                raise RuntimeError('Must specify either an outputfile or a destination table')
         else:
             self.hdf5_out = outputfile
             if destination is not None:
                 self.destination = destination
             else:
                 self.destination = tablename  # PATH OR NAME ?
 
         try:
             self.hdf5_out.get_node('/%s' % destination)
             if self.overwrite:
                 self.hd5_out.remove_nove('/', self.destination, recursive=True)
             else:
-                raise RuntimeError("Destination table exists and overwrite "
-                                   "is False")
+                raise RuntimeError('Destination table exists and overwrite is False')
         except tables.NoSuchNodeError:
-            self.outtable = self.hdf5_out.create_table('/', self.destination,
-                                                       self.description,
-                                                       expectedrows=self.nrows)
+            self.outtable = self.hdf5_out.create_table('/', self.destination, self.description, expectedrows=self.nrows)
 
         self._calc_nrows_in_chunk()
 
         if self.nrows > self.nrows_in_chunk:
             if self.tempfile is None:
                 self.tempfile_path = self._create_tempfile_path()
                 self.hdf5_temp = tables.open_file(self.tempfile_path, 'w')
             else:
                 self.hdf5_temp = tempfile
             if self.progress:
                 parts = int(len(self.table) / self.nrows_in_chunk) + 1
-                print("On disk mergesort in %d parts." % parts)
-        else:
-            if self.progress:
-                print("Table can be sorted in memory.")
+                print('On disk mergesort in %d parts.' % parts)
+        elif self.progress:
+            print('Table can be sorted in memory.')
 
     def __enter__(self):
         return self
 
     def __exit__(self, exc_type, exc_value, exc_traceback):
         try:
             self.tempfile_path
@@ -100,37 +101,33 @@
         """Sort the table"""
 
         chunk = self.nrows_in_chunk
         nrows = self.nrows
         parts = int(nrows / chunk) + 1
         if parts == 1:
             if self.progress:
-                print("Sorting table in memory and writing to disk.")
+                print('Sorting table in memory and writing to disk.')
             self._sort_chunk(self.outtable, 0, nrows)
         else:
             if self.progress:
-                print("Sorting in %d chunks of %d rows:" % (parts, chunk))
+                print('Sorting in %d chunks of %d rows:' % (parts, chunk))
 
-            for idx, start in pbar(enumerate(range(0, nrows, chunk)),
-                                   length=parts, show=self.progress):
+            for idx, start in pbar(enumerate(range(0, nrows, chunk)), length=parts, show=self.progress):
                 table_name = 'temp_table_%d' % idx
-                table = self.hdf5_temp.create_table('/', table_name,
-                                                    self.description,
-                                                    expectedrows=chunk)
+                table = self.hdf5_temp.create_table('/', table_name, self.description, expectedrows=chunk)
                 iterator = self._sort_chunk(table, start, start + chunk)
                 self._iterators.append(iterator)
 
             rowbuf = self.outtable._get_container(self._BUFSIZE)
             idx = 0
 
             if self.progress:
-                print("Merging:")
+                print('Merging:')
 
-            for keyedrow in pbar(merge(*self._iterators), length=nrows,
-                                 show=self.progress):
+            for keyedrow in pbar(merge(*self._iterators), length=nrows, show=self.progress):
                 x, row = keyedrow
 
                 if idx == self._BUFSIZE:
                     self.outtable.append(rowbuf)
                     self.outtable.flush()
                     idx = 0
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/particles.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/particles.py`

 * *Files 8% similar despite different names*

```diff
@@ -19,30 +19,30 @@
 
     particle.id = 1206
     if particle.id > 200:
         print('atom: %s' % particles.ATOMIC_NUMBER[particle.id % 100])
 
 
 """
+
 import re
 
 
 def name(particle_id):
     """Get the name for a CORSIKA particle code
 
     :param particle_id: code for the particle
     :return: name of the particle. In case of atoms the weight is added
              to the name.
 
     """
     try:
         return ID[particle_id]
     except KeyError:
-        return (ATOMIC_NUMBER[int(particle_id) % 100] +
-                str(int(particle_id // 100)))
+        return ATOMIC_NUMBER[int(particle_id) % 100] + str(int(particle_id // 100))
 
 
 def particle_id(name):
     """Get the CORSIKA particle code for a partice name
 
     :param name: name of the particle/atom, for atoms the mass
                  (neutrons + protons) can be appended to the name.
@@ -54,276 +54,268 @@
         if name == particle_name:
             return pid
     for z, atom_name in ATOMIC_NUMBER.items():
         # Note; the mass number assumes no neutrons. To get a correct
         # weight append the weight to the name, e.g. helium4 or carbon14
         if name == atom_name:
             return z * 100 + z
-    atom = re.match(r"^([a-z]+)(\d+)$", name)
+    atom = re.match(r'^([a-z]+)(\d+)$', name)
     if atom is not None:
         return int(atom.group(2)) * 100 + (particle_id(atom.group(1)) % 100)
 
 
-ID = {1: 'gamma',
-      2: 'positron',
-      3: 'electron',
-      4: 'neutrino',  # No longer used?
-      5: 'muon_p',
-      6: 'muon_m',
-      7: 'pion_0',
-      8: 'pion_p',
-      9: 'pion_m',
-      10: 'Kaon_0_long',
-      11: 'Kaon_p',
-      12: 'Kaon_m',
-      13: 'neutron',
-      14: 'proton',
-      15: 'anti_proton',
-      16: 'Kaon_0_short',
-      17: 'eta',
-      18: 'Lambda',
-      19: 'Sigma_p',
-      20: 'Sigma_0',
-      21: 'Sigma_m',
-      22: 'Xi_0',
-      23: 'Xi_m',
-      24: 'Omega_m',
-      25: 'anti_neutron',
-      26: 'anti_Lambda',
-      27: 'anti_Sigma_m',
-      28: 'anti_Sigma_0',
-      29: 'anti_Sigma_p',
-      30: 'anti_Xi_0',
-      31: 'anti_Xi_p',
-      32: 'anti_Omega_p',
-      50: 'omega',
-      51: 'rho_0',
-      52: 'rho_p',
-      53: 'rho_m',
-      54: 'Delta_pp',
-      55: 'Delta_p',
-      56: 'Delta_0',
-      57: 'Delta_m',
-      58: 'anti_Delta_mm',
-      59: 'anti_Delta_m',
-      60: 'anti_Delta_0',
-      61: 'anti_Delta_p',
-      62: 'Kaon_star_0',
-      63: 'Kaon_star_p',
-      64: 'Kaon_star_m',
-      65: 'anti_Kaon_star_0',
-      66: 'electron_neutrino',
-      67: 'anti_electron_neutrino',
-      68: 'muon_neutrino',
-      69: 'anti_muon_neutrino',
-
-      71: 'eta__2_gamma',
-      72: 'eta__3_pion_0',
-      73: 'eta__pion_p_pion_m_pion_0',
-      74: 'eta__pion_p_pion_m_gamma',
-      75: 'additional_muon_p',
-      76: 'additional_muon_m',
-
-      85: 'decay_start_muon_p',
-      86: 'decay_start_muon_m',
-
-      95: 'decay_end_muon_p',
-      96: 'decay_end_muon_m',
-
-      116: 'D_0',
-      117: 'D_p',
-      118: 'anti_D_m',
-      119: 'anti_D_0',
-      120: 'D_p_short',
-      121: 'anti_D_m_short',
-      122: 'eta_c',
-      123: 'D_star_0',
-      124: 'D_star_p',
-      125: 'anti_D_star_m',
-      126: 'anti_D_star_0',
-      127: 'D_star_p_short',
-      128: 'anti_D_star_m_short',
-
-      130: 'j_psi',
-      131: 'tau_p',
-      132: 'tau_m',
-      133: 'tau_neutrino',
-      134: 'anti_tau_neutrino',
-
-      137: 'Lambda_c_p',
-      138: 'Xi_c_p',
-      139: 'Xi_c_0',
-      140: 'Sigma_c_pp',
-      141: 'Sigma_c_',
-      142: 'Sigma_c_0',
-      143: 'Xi_c_prime_p',
-      144: 'Xi_c_prime_0',
-      145: 'Omega_c_0',
-
-      149: 'anti_Lambda_c_m',
-      150: 'anti_Xi_c_m',
-      151: 'anti_Xi_c_0',
-      152: 'anti_Sigma_c_mm',
-      153: 'anti_Sigma_c_m',
-      154: 'anti_Sigma_c_0',
-      155: 'anti_Xi_c_prime_m',
-      156: 'anti_Xi_c_prime_0',
-      157: 'anti_Omega_c_0',
-
-      161: 'Sigma_c_star_pp',
-      162: 'Sigma_c_star_p',
-      163: 'Sigma_c_star_0',
-
-      171: 'anti_Sigma_c_star_mm',
-      172: 'anti_Sigma_c_star_m',
-      173: 'anti_Sigma_c_star_0',
-
-      176: 'B_0',
-      177: 'B_p',
-      178: 'anti_B_m',
-      179: 'anti_B_0',
-      180: 'B_s_0',
-      181: 'anti_B_s_0',
-      182: 'B_c_p',
-      183: 'anti_B_c_m',
-      184: 'Lambda_b_0',
-      185: 'Sigma_b_m',
-      186: 'Sigma_b_p',
-      187: 'Xi_b_0',
-      188: 'Xi_b_m',
-      189: 'Omega_b_m',
-      190: 'anti_Lambda_b_0',
-      191: 'anti_Sigma_b_p',
-      192: 'anti_Sigma_b_m',
-      193: 'anti_Xi_b_0',
-      194: 'anti_Xi_b_p',
-      195: 'anti_Omega_b_p',
-
-      # A x 100 + Z
-      101: 'hydrogen',
-      201: 'deuteron',
-      301: 'tritium',
-      302: 'helium3',
-      402: 'alpha',
-      703: 'lithium',
-      904: 'beryllium',
-      1105: 'boron',
-      1206: 'carbon',
-      1407: 'nitrogen',
-      1608: 'oxygen',
-      2713: 'aluminium',
-      2814: 'silicon',
-      3216: 'sulfur',
-      4020: 'calcium',
-      5626: 'iron',
-      5828: 'nickel',
-
-      9900: 'cherenkov_photons'}
+ID = {
+    1: 'gamma',
+    2: 'positron',
+    3: 'electron',
+    4: 'neutrino',  # No longer used?
+    5: 'muon_p',
+    6: 'muon_m',
+    7: 'pion_0',
+    8: 'pion_p',
+    9: 'pion_m',
+    10: 'Kaon_0_long',
+    11: 'Kaon_p',
+    12: 'Kaon_m',
+    13: 'neutron',
+    14: 'proton',
+    15: 'anti_proton',
+    16: 'Kaon_0_short',
+    17: 'eta',
+    18: 'Lambda',
+    19: 'Sigma_p',
+    20: 'Sigma_0',
+    21: 'Sigma_m',
+    22: 'Xi_0',
+    23: 'Xi_m',
+    24: 'Omega_m',
+    25: 'anti_neutron',
+    26: 'anti_Lambda',
+    27: 'anti_Sigma_m',
+    28: 'anti_Sigma_0',
+    29: 'anti_Sigma_p',
+    30: 'anti_Xi_0',
+    31: 'anti_Xi_p',
+    32: 'anti_Omega_p',
+    50: 'omega',
+    51: 'rho_0',
+    52: 'rho_p',
+    53: 'rho_m',
+    54: 'Delta_pp',
+    55: 'Delta_p',
+    56: 'Delta_0',
+    57: 'Delta_m',
+    58: 'anti_Delta_mm',
+    59: 'anti_Delta_m',
+    60: 'anti_Delta_0',
+    61: 'anti_Delta_p',
+    62: 'Kaon_star_0',
+    63: 'Kaon_star_p',
+    64: 'Kaon_star_m',
+    65: 'anti_Kaon_star_0',
+    66: 'electron_neutrino',
+    67: 'anti_electron_neutrino',
+    68: 'muon_neutrino',
+    69: 'anti_muon_neutrino',
+    71: 'eta__2_gamma',
+    72: 'eta__3_pion_0',
+    73: 'eta__pion_p_pion_m_pion_0',
+    74: 'eta__pion_p_pion_m_gamma',
+    75: 'additional_muon_p',
+    76: 'additional_muon_m',
+    85: 'decay_start_muon_p',
+    86: 'decay_start_muon_m',
+    95: 'decay_end_muon_p',
+    96: 'decay_end_muon_m',
+    116: 'D_0',
+    117: 'D_p',
+    118: 'anti_D_m',
+    119: 'anti_D_0',
+    120: 'D_p_short',
+    121: 'anti_D_m_short',
+    122: 'eta_c',
+    123: 'D_star_0',
+    124: 'D_star_p',
+    125: 'anti_D_star_m',
+    126: 'anti_D_star_0',
+    127: 'D_star_p_short',
+    128: 'anti_D_star_m_short',
+    130: 'j_psi',
+    131: 'tau_p',
+    132: 'tau_m',
+    133: 'tau_neutrino',
+    134: 'anti_tau_neutrino',
+    137: 'Lambda_c_p',
+    138: 'Xi_c_p',
+    139: 'Xi_c_0',
+    140: 'Sigma_c_pp',
+    141: 'Sigma_c_',
+    142: 'Sigma_c_0',
+    143: 'Xi_c_prime_p',
+    144: 'Xi_c_prime_0',
+    145: 'Omega_c_0',
+    149: 'anti_Lambda_c_m',
+    150: 'anti_Xi_c_m',
+    151: 'anti_Xi_c_0',
+    152: 'anti_Sigma_c_mm',
+    153: 'anti_Sigma_c_m',
+    154: 'anti_Sigma_c_0',
+    155: 'anti_Xi_c_prime_m',
+    156: 'anti_Xi_c_prime_0',
+    157: 'anti_Omega_c_0',
+    161: 'Sigma_c_star_pp',
+    162: 'Sigma_c_star_p',
+    163: 'Sigma_c_star_0',
+    171: 'anti_Sigma_c_star_mm',
+    172: 'anti_Sigma_c_star_m',
+    173: 'anti_Sigma_c_star_0',
+    176: 'B_0',
+    177: 'B_p',
+    178: 'anti_B_m',
+    179: 'anti_B_0',
+    180: 'B_s_0',
+    181: 'anti_B_s_0',
+    182: 'B_c_p',
+    183: 'anti_B_c_m',
+    184: 'Lambda_b_0',
+    185: 'Sigma_b_m',
+    186: 'Sigma_b_p',
+    187: 'Xi_b_0',
+    188: 'Xi_b_m',
+    189: 'Omega_b_m',
+    190: 'anti_Lambda_b_0',
+    191: 'anti_Sigma_b_p',
+    192: 'anti_Sigma_b_m',
+    193: 'anti_Xi_b_0',
+    194: 'anti_Xi_b_p',
+    195: 'anti_Omega_b_p',
+    # A x 100 + Z
+    101: 'hydrogen',
+    201: 'deuteron',
+    301: 'tritium',
+    302: 'helium3',
+    402: 'alpha',
+    703: 'lithium',
+    904: 'beryllium',
+    1105: 'boron',
+    1206: 'carbon',
+    1407: 'nitrogen',
+    1608: 'oxygen',
+    2713: 'aluminium',
+    2814: 'silicon',
+    3216: 'sulfur',
+    4020: 'calcium',
+    5626: 'iron',
+    5828: 'nickel',
+    9900: 'cherenkov_photons',
+}
 
 
 # Z numbers
-ATOMIC_NUMBER = {1: 'hydrogen',
-                 2: 'helium',
-                 3: 'lithium',
-                 4: 'beryllium',
-                 5: 'boron',
-                 6: 'carbon',
-                 7: 'nitrogen',
-                 8: 'oxygen',
-                 9: 'fluorine',
-                 10: 'neon',
-                 11: 'sodium',
-                 12: 'magnesium',
-                 13: 'aluminium',
-                 14: 'silicon',
-                 15: 'phosphorus',
-                 16: 'sulfur',
-                 17: 'chlorine',
-                 18: 'argon',
-                 19: 'potassium',
-                 20: 'calcium',
-                 21: 'scandium',
-                 22: 'titanium',
-                 23: 'vanadium',
-                 24: 'chromium',
-                 25: 'manganese',
-                 26: 'iron',
-                 27: 'cobalt',
-                 28: 'nickel',
-                 29: 'copper',
-                 30: 'zinc',
-                 31: 'gallium',
-                 32: 'germanium',
-                 33: 'arsenic',
-                 34: 'selenium',
-                 35: 'bromine',
-                 36: 'krypton',
-                 37: 'rubidium',
-                 38: 'strontium',
-                 39: 'yttrium',
-                 40: 'zirconium',
-                 41: 'niobium',
-                 42: 'molybdenum',
-                 43: 'technetium',
-                 44: 'ruthenium',
-                 45: 'rhodium',
-                 46: 'palladium',
-                 47: 'silver',
-                 48: 'cadmium',
-                 49: 'indium',
-                 50: 'tin',
-                 51: 'antimony',
-                 52: 'tellurium',
-                 53: 'iodine',
-                 54: 'xenon',
-                 55: 'caesium',
-                 56: 'barium',
-                 57: 'lanthanum',
-                 58: 'cerium',
-                 59: 'praseodym.',
-                 60: 'neodymium',
-                 61: 'promethium',
-                 62: 'samarium',
-                 63: 'europium',
-                 64: 'gadolinium',
-                 65: 'terbium',
-                 66: 'dysprosium',
-                 67: 'holmium',
-                 68: 'erbium',
-                 69: 'thulium',
-                 70: 'ytterbium',
-                 71: 'lutetium',
-                 72: 'hafnium',
-                 73: 'tantalum',
-                 74: 'tungsten',
-                 75: 'rhenium',
-                 76: 'osmium',
-                 77: 'iridium',
-                 78: 'platinum',
-                 79: 'gold',
-                 80: 'mercury',
-                 81: 'thallium',
-                 82: 'lead',
-                 83: 'bismuth',
-                 84: 'polonium',
-                 85: 'astatine',
-                 86: 'radon',
-                 87: 'francium',
-                 88: 'radium',
-                 89: 'actinium',
-                 90: 'thorium',
-                 91: 'protactin.',
-                 92: 'uranium',
-                 93: 'neptunium',
-                 94: 'plutonium',
-                 95: 'americium',
-                 96: 'curium',
-                 97: 'berkelium',
-                 98: 'californium',
-                 99: 'einsteinium'}
+ATOMIC_NUMBER = {
+    1: 'hydrogen',
+    2: 'helium',
+    3: 'lithium',
+    4: 'beryllium',
+    5: 'boron',
+    6: 'carbon',
+    7: 'nitrogen',
+    8: 'oxygen',
+    9: 'fluorine',
+    10: 'neon',
+    11: 'sodium',
+    12: 'magnesium',
+    13: 'aluminium',
+    14: 'silicon',
+    15: 'phosphorus',
+    16: 'sulfur',
+    17: 'chlorine',
+    18: 'argon',
+    19: 'potassium',
+    20: 'calcium',
+    21: 'scandium',
+    22: 'titanium',
+    23: 'vanadium',
+    24: 'chromium',
+    25: 'manganese',
+    26: 'iron',
+    27: 'cobalt',
+    28: 'nickel',
+    29: 'copper',
+    30: 'zinc',
+    31: 'gallium',
+    32: 'germanium',
+    33: 'arsenic',
+    34: 'selenium',
+    35: 'bromine',
+    36: 'krypton',
+    37: 'rubidium',
+    38: 'strontium',
+    39: 'yttrium',
+    40: 'zirconium',
+    41: 'niobium',
+    42: 'molybdenum',
+    43: 'technetium',
+    44: 'ruthenium',
+    45: 'rhodium',
+    46: 'palladium',
+    47: 'silver',
+    48: 'cadmium',
+    49: 'indium',
+    50: 'tin',
+    51: 'antimony',
+    52: 'tellurium',
+    53: 'iodine',
+    54: 'xenon',
+    55: 'caesium',
+    56: 'barium',
+    57: 'lanthanum',
+    58: 'cerium',
+    59: 'praseodym.',
+    60: 'neodymium',
+    61: 'promethium',
+    62: 'samarium',
+    63: 'europium',
+    64: 'gadolinium',
+    65: 'terbium',
+    66: 'dysprosium',
+    67: 'holmium',
+    68: 'erbium',
+    69: 'thulium',
+    70: 'ytterbium',
+    71: 'lutetium',
+    72: 'hafnium',
+    73: 'tantalum',
+    74: 'tungsten',
+    75: 'rhenium',
+    76: 'osmium',
+    77: 'iridium',
+    78: 'platinum',
+    79: 'gold',
+    80: 'mercury',
+    81: 'thallium',
+    82: 'lead',
+    83: 'bismuth',
+    84: 'polonium',
+    85: 'astatine',
+    86: 'radon',
+    87: 'francium',
+    88: 'radium',
+    89: 'actinium',
+    90: 'thorium',
+    91: 'protactin.',
+    92: 'uranium',
+    93: 'neptunium',
+    94: 'plutonium',
+    95: 'americium',
+    96: 'curium',
+    97: 'berkelium',
+    98: 'californium',
+    99: 'einsteinium',
+}
 
 
 # From the CORSIKA `corsikaread.cpp` program
 #
 #    naming conventions of corsika particles:
 #     1   gamma           24   Omega           64   K* -
 #     2   positron        25   anti neutron    65   anti K* 0
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/qsub_corsika.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/qsub_corsika.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-""" Run CORSIKA simulations on Stoomboot
+"""Run CORSIKA simulations on Stoomboot
 
-    In order to quickly get a good sample of simulated showers we use the
-    Nikhef computer cluster Stoomboot to run multiple jobs simultaneously.
-    For this purpose a script has been written that will make this easy.
-    The :mod:`~sapphire.corsika.qsub_corsika` script can submit as many
-    jobs as you want with the parameters that you desire. It automatically
-    ensures that a unique combination of seeds for the random number
-    sequences are used for each simulation.
+In order to quickly get a good sample of simulated showers we use the
+Nikhef computer cluster Stoomboot to run multiple jobs simultaneously.
+For this purpose a script has been written that will make this easy.
+The :mod:`~sapphire.corsika.qsub_corsika` script can submit as many
+jobs as you want with the parameters that you desire. It automatically
+ensures that a unique combination of seeds for the random number
+sequences are used for each simulation.
 
-    To run this file correctly do it in the correct env::
+To run this file correctly do it in the correct env::
 
-        $ source activate corsika
+    $ source activate corsika
 
-    The syntax for calling the script can be seen by calling its help::
+The syntax for calling the script can be seen by calling its help::
 
-        $ qsub_corsika --help
+    $ qsub_corsika --help
 
-    For example, running 100 showers with proton primaries of 1e16 eV
-    coming in at 22.5 degrees zenith and 90 degrees azimuth on the
-    standard Stoomboot queue with the default CORSIKA configuration::
+For example, running 100 showers with proton primaries of 1e16 eV
+coming in at 22.5 degrees zenith and 90 degrees azimuth on the
+standard Stoomboot queue with the default CORSIKA configuration::
 
-        $ qsub_corsika 100 16 proton 22.5 -q generic -a 90
+    $ qsub_corsika 100 16 proton 22.5 -q generic -a 90
 
 """
 
 import argparse
 import os
 import random
 import subprocess
@@ -70,15 +70,15 @@
     OBSLEV    10.E2                    observation level -maaiveld -3.7m (cm)
     MAXPRT    1                        max. number of printed events
     ECTMAP    1.E4                     cut on gamma factor for printout
     DATDIR    {tablesdir}              location of the input data tables
     DIRECT    ./                       output directory
     USER      hisparc                  user
     DEBUG     F  6  F  1000000         debug flag and log.unit for out
-    EXIT                               terminates input""")  # noqa: E501
+    EXIT                               terminates input""")
 SCRIPT_TEMPLATE = textwrap.dedent("""\
     #!/usr/bin/env bash
 
     umask 002
 
     # Run CORSIKA
     /usr/bin/time -o time.log {corsika} < input-hisparc > corsika-output.log
@@ -91,15 +91,14 @@
     else
         mv {rundir} {faildir}
         exit 1
     fi""")
 
 
 class CorsikaBatch:
-
     """Run many simultaneous CORSIKA simulations using Stoomboot
 
     Stoomboot is the Nikhef computer cluster.
 
     :param energy: the energy of the primary particle in log10(E[eV]),
                    so an energy of 16 (10**16 eV) corresponds to 10**7 GeV,
                    integer values and values ending in .5 are allowed.
@@ -117,16 +116,23 @@
                     corsika74000Linux_EPOS_gheisha
                     corsika74000Linux_QGSII_gheisha
                     corsika74000Linux_QGSJET_gheisha
                     corsika74000Linux_SIBYLL_gheisha
 
     """
 
-    def __init__(self, energy=16, particle='proton', zenith=22.5, azimuth=180,
-                 queue='generic', corsika='corsika74000Linux_QGSII_gheisha'):
+    def __init__(
+        self,
+        energy=16,
+        particle='proton',
+        zenith=22.5,
+        azimuth=180,
+        queue='generic',
+        corsika='corsika74000Linux_QGSII_gheisha',
+    ):
         self.energy_pre, self.energy_pow = self.corsika_energy(energy)
         self.particle = particles.particle_id(particle)  # Store as particle id
         self.theta = zenith
         self.phi = (azimuth + 90) % 360  # Stored as Phi defined by CORSIKA
         self.queue = queue
         self.corsika = corsika
         self.seed1 = None
@@ -139,16 +145,16 @@
         Convert from log10(E/eV) to E[GeV] and split value to multiplier
         and power.
 
         :param energy: primary particle energy as log10(E/eV).
         :return: separate multiplier and power
 
         """
-        if modf(energy)[0] == 0.:
-            return (1., int(energy - 9))
+        if modf(energy)[0] == 0.0:
+            return (1.0, int(energy - 9))
         elif modf(energy)[0] == 0.5:
             return (3.16228, int(modf(energy)[1] - 9))
         else:
             raise ValueError('Energy must either be an integer or end in .5.')
 
     def run(self):
         self.prepare_env()
@@ -169,18 +175,18 @@
         # Create/copy files
         self.create_input()
         self.copy_config()
 
     def submit_job(self):
         """Submit job to Stoomboot"""
 
-        name = f"cor_{self.seed1}_{self.seed2}"
-        extra = f"-d {self.get_rundir()}"
+        name = f'cor_{self.seed1}_{self.seed2}'
+        extra = f'-d {self.get_rundir()}'
         if self.queue == 'long':
-            extra += " -l walltime=96:00:00"
+            extra += ' -l walltime=96:00:00'
         script = self.create_script()
 
         qsub.submit_job(script, name, self.queue, extra)
 
     def taken_seeds(self):
         """Get list of seeds already used"""
 
@@ -191,17 +197,17 @@
     def generate_random_seeds(self, taken):
         """Get unused combination of two seeds for CORSIKA
 
         :param taken: List of seed combinations already taken
                       each is formatted like this: 'seed1_seed2'
 
         """
-        seed1 = random.randint(1, 900000000)
-        seed2 = random.randint(1, 900000000)
-        seed = f"{seed1}_{seed2}"
+        seed1 = random.randint(1, 900_000_000)
+        seed2 = random.randint(1, 900_000_000)
+        seed = f'{seed1}_{seed2}'
         if seed not in taken:
             self.seed1 = seed1
             self.seed2 = seed2
             self.rundir = seed + '/'
         else:
             self.generate_random_seeds(taken)
 
@@ -220,55 +226,63 @@
 
         return os.path.join(TEMPDIR, self.rundir)
 
     def create_input(self):
         """Make CORSIKA steering file"""
 
         input_path = os.path.join(self.get_rundir(), 'input-hisparc')
-        input = INPUT_TEMPLATE.format(seed1=self.seed1, seed2=self.seed2,
-                                      particle=self.particle, phi=self.phi,
-                                      energy_pre=self.energy_pre,
-                                      energy_pow=self.energy_pow,
-                                      theta=self.theta, tablesdir=CORSIKADIR)
+        input_content = INPUT_TEMPLATE.format(
+            seed1=self.seed1,
+            seed2=self.seed2,
+            particle=self.particle,
+            phi=self.phi,
+            energy_pre=self.energy_pre,
+            energy_pow=self.energy_pow,
+            theta=self.theta,
+            tablesdir=CORSIKADIR,
+        )
         with open(input_path, 'w') as input_file:
-            input_file.write(input)
+            input_file.write(input_content)
 
     def create_script(self):
         """Make Stoomboot script file"""
 
         exec_path = os.path.join(CORSIKADIR, self.corsika)
         run_path = self.get_rundir()
 
-        script = SCRIPT_TEMPLATE.format(corsika=exec_path, rundir=run_path,
-                                        datadir=DATADIR, faildir=FAILDIR)
+        script = SCRIPT_TEMPLATE.format(corsika=exec_path, rundir=run_path, datadir=DATADIR, faildir=FAILDIR)
         return script
 
     def copy_config(self):
         """Copy the CORSIKA config file to the output directory
 
         This way we can always check how CORSIKA was configured for each
         run.
 
         """
         source = os.path.join(CORSIKADIR, self.corsika + '.log')
         destination = self.get_rundir()
         subprocess.check_output(['cp', source, destination])
 
     def __repr__(self):
-        energy = round(log10(self.energy_pre * 10 ** self.energy_pow) + 9, 1)
+        energy = round(log10(self.energy_pre * 10**self.energy_pow) + 9, 1)
         particle = particles.name(self.particle)
         azimuth = self.phi - 90
-        return ('%s(energy=%r, particle=%r, zenith=%r, azimuth=%r, queue=%r, '
-                'corsika=%r)' %
-                (self.__class__.__name__, energy, particle, self.theta,
-                 azimuth, self.queue, self.corsika))
+        return '%s(energy=%r, particle=%r, zenith=%r, azimuth=%r, queue=%r, corsika=%r)' % (
+            self.__class__.__name__,
+            energy,
+            particle,
+            self.theta,
+            azimuth,
+            self.queue,
+            self.corsika,
+        )
 
 
-def multiple_jobs(n, energy, particle, zenith, azimuth, queue, corsika,
-                  progress=True):
+def multiple_jobs(n, energy, particle, zenith, azimuth, queue, corsika, progress=True):
     """Use this to sumbit multiple jobs to Stoomboot
 
     :param n: Number of jobs to submit
     :param energy: log10(E[eV]) energy of primary particle
     :param particle: Particle kind (as string, see
                      :mod:`~sapphire.corsika.particles` for possibilities)
     :param zenith: Zenith angle in degrees of the primary particle
@@ -276,71 +290,88 @@
     :param queue: Stoomboot queue to submit to
     :param corsika: Name of the CORSIKA executable to use
     :param progress: if True print an overview of the chosen paramters and
                      show a progressbar of the job submission progress.
 
     """
     if progress:
-        print(textwrap.dedent("""\
+        print(
+            textwrap.dedent(f"""\
             Batch submitting jobs to Stoomboot:
             Number of jobs      {n}
-            Particle energy     10^{e} eV
-            Primary particle    {p}
-            Zenith angle        {z} degrees
-            Azimuth angle       {a} degrees
-            Stoomboot queue     {q}
-            CORSIKA executable  {c}
-            """.format(n=n, e=energy, p=particle, z=zenith, a=azimuth, q=queue,
-                       c=corsika)))
+            Particle energy     10^{energy} eV
+            Primary particle    {particle}
+            Zenith angle        {zenith} degrees
+            Azimuth angle       {azimuth} degrees
+            Stoomboot queue     {queue}
+            CORSIKA executable  {corsika}
+            """),
+        )
 
     available_slots = qsub.check_queue(queue)
     if available_slots <= 0:
-        raise Exception('Submitting no jobs because selected queue is full.')
+        raise RuntimeError('Submitting no jobs because selected queue is full.')
     elif available_slots < n:
         n = available_slots
-        warnings.warn('Submitting {n} jobs because queue almost full.'
-                      .format(n=n))
+        warnings.warn(f'Submitting {n} jobs because queue almost full.')
 
     for _ in pbar(range(n), show=progress):
-        batch = CorsikaBatch(energy=energy, particle=particle, zenith=zenith,
-                             azimuth=azimuth, queue=queue, corsika=corsika)
+        batch = CorsikaBatch(
+            energy=energy,
+            particle=particle,
+            zenith=zenith,
+            azimuth=azimuth,
+            queue=queue,
+            corsika=corsika,
+        )
         batch.run()
 
 
 def main():
-    parser = argparse.ArgumentParser(description='Submit CORSIKA jobs to '
-                                                 'Stoomboot, only at Nikhef.')
-    parser.add_argument('n', type=int, help="number of jobs to submit")
-    parser.add_argument('energy', metavar='energy', type=float,
-                        help="energy of the primary particle in range 11..17, "
-                             "in steps of .5 (log10(E[eV]))",
-                        choices=[11, 11.5, 12, 12.5, 13, 13.5, 14, 14.5,
-                                 15, 15.5, 16, 16.5, 17, 17.5, 18, 18.5])
-    parser.add_argument('particle', help="primary particle kind (e.g. proton "
-                                         "or iron)")
-    parser.add_argument('zenith', metavar='zenith',
-                        help="zenith angle of primary particle in range 0..60,"
-                             " in steps of 7.5 [degrees]",
-                        type=float,
-                        choices=[0, 7.5, 15, 22.5, 30, 37.5, 45, 52.5, 60])
-    parser.add_argument('-a', '--azimuth', metavar='angle',
-                        help="azimuth angle of primary particle in range "
-                             "0..315, in steps of 45 [degrees]",
-                        type=int,
-                        default=0,
-                        choices=[0, 45, 90, 135, 180, 225, 270, 315])
-    parser.add_argument('-q', '--queue', metavar='name',
-                        help="name of the Stoomboot queue to use, choose from "
-                             "express, short, generic (default), and long",
-                        default='generic',
-                        choices=['express', 'short', 'generic', 'long'])
-    parser.add_argument('-c', '--corsika', metavar='exec',
-                        help="name of the CORSIKA executable to use",
-                        default="corsika74000Linux_QGSII_gheisha")
+    parser = argparse.ArgumentParser(description='Submit CORSIKA jobs to Stoomboot, only at Nikhef.')
+    parser.add_argument('n', type=int, help='number of jobs to submit')
+    parser.add_argument(
+        'energy',
+        metavar='energy',
+        type=float,
+        help='energy of the primary particle in range 11..17, in steps of .5 (log10(E[eV]))',
+        choices=[11, 11.5, 12, 12.5, 13, 13.5, 14, 14.5, 15, 15.5, 16, 16.5, 17, 17.5, 18, 18.5],
+    )
+    parser.add_argument('particle', help='primary particle kind (e.g. proton or iron)')
+    parser.add_argument(
+        'zenith',
+        metavar='zenith',
+        help='zenith angle of primary particle in range 0..60, in steps of 7.5 [degrees]',
+        type=float,
+        choices=[0, 7.5, 15, 22.5, 30, 37.5, 45, 52.5, 60],
+    )
+    parser.add_argument(
+        '-a',
+        '--azimuth',
+        metavar='angle',
+        help='azimuth angle of primary particle in range 0..315, in steps of 45 [degrees]',
+        type=int,
+        default=0,
+        choices=[0, 45, 90, 135, 180, 225, 270, 315],
+    )
+    parser.add_argument(
+        '-q',
+        '--queue',
+        metavar='name',
+        help='name of the Stoomboot queue to use, choose from express, short, generic (default), and long',
+        default='generic',
+        choices=['express', 'short', 'generic', 'long'],
+    )
+    parser.add_argument(
+        '-c',
+        '--corsika',
+        metavar='exec',
+        help='name of the CORSIKA executable to use',
+        default='corsika74000Linux_QGSII_gheisha',
+    )
     args = parser.parse_args()
 
-    multiple_jobs(args.n, args.energy, args.particle, args.zenith,
-                  args.azimuth, args.queue, args.corsika)
+    multiple_jobs(args.n, args.energy, args.particle, args.zenith, args.azimuth, args.queue, args.corsika)
 
 
 if __name__ == '__main__':
     main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/qsub_store_corsika_data.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/qsub_store_corsika_data.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,19 +1,20 @@
-""" Convert CORSIKA stored showers to HDF5 on Stoomboot
+"""Convert CORSIKA stored showers to HDF5 on Stoomboot
 
-    Automatically submits Stoomboot jobs to convert corsika data. The
-    script ``store_corsika_data`` can be used to convert a DAT000000
-    CORSIKA file to a HDF5 file. This script checks our data folder for
-    new or unconverted simulations and creates Stoomboot jobs to perform
-    the conversion.
+Automatically submits Stoomboot jobs to convert corsika data. The
+script ``store_corsika_data`` can be used to convert a DAT000000
+CORSIKA file to a HDF5 file. This script checks our data folder for
+new or unconverted simulations and creates Stoomboot jobs to perform
+the conversion.
 
-    This job is run as a cron job to ensure the simulations remain up to
-    date.
+This job is run as a cron job to ensure the simulations remain up to
+date.
 
 """
+
 import argparse
 import glob
 import logging
 import os
 import textwrap
 
 from .. import qsub
@@ -34,16 +35,16 @@
 
 logger = logging.getLogger(__name__)
 
 
 def all_seeds():
     """Get set of all seeds in the corsika data directory"""
 
-    dirs = glob.glob(os.path.join(DATADIR, '*_*'))
-    seeds = [os.path.basename(dir) for dir in dirs]
+    directories = glob.glob(os.path.join(DATADIR, '*_*'))
+    seeds = [os.path.basename(directory) for directory in directories]
     return set(seeds)
 
 
 def seeds_processed():
     """Get the seeds of simulations for which the h5 is already created"""
 
     files = glob.glob(os.path.join(DATADIR, '*_*/corsika.h5'))
@@ -90,41 +91,38 @@
     return seeds.difference(processed).difference(queued)
 
 
 def filter_large_seeds(seeds_todo):
     """Exclude seeds for data files that are to large"""
 
     limit = 70e9  # larger than 70 GB has not been tested yet
-    return {s for s in seeds_todo
-            if os.path.getsize(os.path.join(DATADIR, s, SOURCE_FILE)) < limit}
+    return {s for s in seeds_todo if os.path.getsize(os.path.join(DATADIR, s, SOURCE_FILE)) < limit}
 
 
 def store_command(seed):
     """Write queued seeds to file"""
 
     source = os.path.join(DATADIR, seed, SOURCE_FILE)
     destination = os.path.join(DATADIR, seed, DESTINATION_FILE)
-    command = ('{bin_path}python {bin_path}store_corsika_data {source} '
-               '{destination}'.format(bin_path=BIN_PATH, source=source,
-                                      destination=destination))
+    command = f'{BIN_PATH}python {BIN_PATH}store_corsika_data {source} {destination}'
 
     return command
 
 
 def run(queue):
     """Get list of seeds to process, then submit jobs to process them"""
 
     os.umask(0o02)
     logger.info('Getting todo list of seeds to convert.')
     seeds = get_seeds_todo()
     # seeds = filter_large_seeds(seeds)
     n_jobs_to_submit = min(len(seeds), qsub.check_queue(queue), 50)
     extra = ''
     if queue == 'long':
-        extra += " -l walltime=96:00:00"
+        extra += ' -l walltime=96:00:00'
 
     logger.info('Submitting jobs for %d simulations.' % n_jobs_to_submit)
     try:
         for _ in range(n_jobs_to_submit):
             seed = seeds.pop()
             command = store_command(seed)
             script = SCRIPT_TEMPLATE.format(command=command, datadir=DATADIR)
@@ -132,26 +130,31 @@
             qsub.submit_job(script, seed, queue, extra)
             append_queued_seeds([seed])
     except KeyError:
         logger.error('Out of seeds!')
 
 
 def main():
-    parser = argparse.ArgumentParser(description='Submit jobs to Stoomboot to '
-                                                 'store CORSIKA data as HDF5.')
-    parser.add_argument('-q', '--queue', metavar='name',
-                        help="name of the Stoomboot queue to use, choose from "
-                             "express, short, generic, and long (default)",
-                        default='long',
-                        choices=['express', 'short', 'generic', 'long'])
+    parser = argparse.ArgumentParser(description='Submit jobs to Stoomboot to store CORSIKA data as HDF5.')
+    parser.add_argument(
+        '-q',
+        '--queue',
+        metavar='name',
+        help='name of the Stoomboot queue to use, choose from express, short, generic, and long (default)',
+        default='long',
+        choices=['express', 'short', 'generic', 'long'],
+    )
     args = parser.parse_args()
     logger.debug('Starting to submit new jobs.')
     run(args.queue)
     logger.info('Finished submitting jobs.')
 
 
 if __name__ == '__main__':
     logging.basicConfig(
-        filename=LOGFILE, filemode='a',
+        filename=LOGFILE,
+        filemode='a',
         format='%(asctime)s %(name)s %(levelname)s: %(message)s',
-        datefmt='%y%m%d_%H%M%S', level=logging.INFO)
+        datefmt='%y%m%d_%H%M%S',
+        level=logging.INFO,
+    )
     main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/reader.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/reader.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,71 +1,71 @@
-""" Read CORSIKA data files.
+"""Read CORSIKA data files.
 
-    This provides functionality to read CORSIKA output
-    files with `Python <www.python.org>`_. It provides the following main
-    classes:
+This provides functionality to read CORSIKA output
+files with `Python <www.python.org>`_. It provides the following main
+classes:
 
-    * :class:`~sapphire.corsika.reader.CorsikaFile`: The file class provides a
-      generator over all events in the file.
-    * :class:`~sapphire.corsika.reader.CorsikaEvent`: The event class that
-      provides a generator over all particles at ground.
+* :class:`~sapphire.corsika.reader.CorsikaFile`: The file class provides a
+  generator over all events in the file.
+* :class:`~sapphire.corsika.reader.CorsikaEvent`: The event class that
+  provides a generator over all particles at ground.
 
-    and the following classes that correspond to the sub-blocks defined in
-    the CORSIKA manual:
+and the following classes that correspond to the sub-blocks defined in
+the CORSIKA manual:
 
-    * :class:`~sapphire.corsika.blocks.RunHeader`
-    * :class:`~sapphire.corsika.blocks.RunEnd`
-    * :class:`~sapphire.corsika.blocks.EventHeader`
-    * :class:`~sapphire.corsika.blocks.EventEnd`
-    * :class:`~sapphire.corsika.blocks.ParticleData`
-    * :class:`~sapphire.corsika.blocks.CherenkovData`
+* :class:`~sapphire.corsika.blocks.RunHeader`
+* :class:`~sapphire.corsika.blocks.RunEnd`
+* :class:`~sapphire.corsika.blocks.EventHeader`
+* :class:`~sapphire.corsika.blocks.EventEnd`
+* :class:`~sapphire.corsika.blocks.ParticleData`
+* :class:`~sapphire.corsika.blocks.CherenkovData`
 
-    Additionally version for thinned showers are available:
+Additionally version for thinned showers are available:
 
-    * :class:`CorsikaFileThin`
-    * :class:`~sapphire.corsika.blocks.ParticleDataThin`
-    * :class:`~sapphire.corsika.blocks.CherenkovDataThin`
+* :class:`CorsikaFileThin`
+* :class:`~sapphire.corsika.blocks.ParticleDataThin`
+* :class:`~sapphire.corsika.blocks.CherenkovDataThin`
 
 
-    Issues
-    ======
+Issues
+======
 
-    This module does not handle platform dependent issues such as byte
-    ordering (endianness) and field size. This was the result of an
-    afternoon hack and has only been tested with files generated using
-    32 bit CORSIKA files on a linux system compiled with gfortran.
+This module does not handle platform dependent issues such as byte
+ordering (endianness) and field size. This was the result of an
+afternoon hack and has only been tested with files generated using
+32 bit CORSIKA files on a linux system compiled with gfortran.
 
-    * **Field Size**: According to the CORSIKA user manual section 10.2
-      all quantities are written as single precision real numbers
-      independently of 32-bit or 64-bit, so each field in the file
-      should be 4 bytes long.
-    * **Endianness**: There is no check for byte ordering. It can be added
-      using Python's `struct module
-      <http://docs.python.org/library/struct.html#struct-alignment>`_.
-    * **Special Particles**: This module currently ignores all special
-      (book-keeping) particles like for muon additional information and
-      history.
+* **Field Size**: According to the CORSIKA user manual section 10.2
+  all quantities are written as single precision real numbers
+  independently of 32-bit or 64-bit, so each field in the file
+  should be 4 bytes long.
+* **Endianness**: There is no check for byte ordering. It can be added
+  using Python's `struct module
+  <http://docs.python.org/library/struct.html#struct-alignment>`_.
+* **Special Particles**: This module currently ignores all special
+  (book-keeping) particles like for muon additional information and
+  history.
 
 
-    More Info
-    =========
+More Info
+=========
 
-    For short information on fortran unformatted binary files, take a look
-    at http://paulbourke.net/dataformats/reading/
+For short information on fortran unformatted binary files, take a look
+at http://paulbourke.net/dataformats/reading/
 
-    For detailed information on the CORSIKA format, check the 'Outputs'
-    chapter in the CORSIKA user manual. In particular, check the 'Normal
-    Particle Output' section.
+For detailed information on the CORSIKA format, check the 'Outputs'
+chapter in the CORSIKA user manual. In particular, check the 'Normal
+Particle Output' section.
 
 
-    Authors
-    =======
+Authors
+=======
 
-    - Javier Gonzalez
-    - Arne de Laat <adelaat@nikhef.nl>
+- Javier Gonzalez
+- Arne de Laat <adelaat@nikhef.nl>
 
 """
 
 import os
 import warnings
 
 from struct import unpack
@@ -135,16 +135,15 @@
 
             for particle in event.get_particles():
                 pass
 
         :yield: each particle in the event
 
         """
-        for sub_block_index in self._raw_file._subblocks_indices(
-                self._header_index, self._end_index):
+        for sub_block_index in self._raw_file._subblocks_indices(self._header_index, self._end_index):
             for particle in self._raw_file._get_particles(sub_block_index):
                 particle_type = particle[6]
                 observation_level = particle[9]
 
                 # skip padding, used to fill a subblock
                 if particle_type == 0:
                     continue
@@ -156,24 +155,18 @@
                 if observation_level != 1:
                     warnings.warn('Only observation level 1 will be read!')
                     continue
 
                 yield particle
 
     def __repr__(self):
-        return "{}({!r}, {!r}, {!r})".format(
-            self.__class__.__name__,
-            self._raw_file,
-            self._header_index,
-            self._end_index
-        )
+        return f'{self.__class__.__name__}({self._raw_file!r}, {self._header_index!r}, {self._end_index!r})'
 
 
 class CorsikaFile:
-
     """CORSIKA output file handler
 
     This class will probide an interface for CORSIKA output files.
     Allowing you go get at the events and particles in the file.
     This class is meant for unthinned simulations.
 
     """
@@ -197,15 +190,15 @@
         """Close the opened CORSIKA data file"""
 
         self._file.close()
 
     def __enter__(self):
         return self
 
-    def __exit__(self, type, value, traceback):
+    def __exit__(self, exc_type, exc_value, traceback):
         self.finish()
 
     def check(self):
         """Check DAT file format
 
         Some basic sanity checks.
 
@@ -217,45 +210,42 @@
         blocks in the file and if the header and end are equal.
 
         Here would be the place to dynamically check for endiannes and
         field size.
 
         """
         if self._size % self.format.block_size != 0:
-            raise Exception('File "{name}" does not have an integer number '
-                            'of blocks!'.format(name=self._filename))
+            raise ValueError(f'File "{self._filename}" does not have an integer number of blocks!')
         block_size = self.format.block_size
         padding = self.format.block_padding_size
         n_blocks = self._size // block_size
         for block in range(n_blocks):
             self._file.seek(block * block_size)
             a = unpack('i', self._file.read(padding))[0]
             self._file.seek((block + 1) * block_size - padding)
             b = unpack('i', self._file.read(padding))[0]
             if a != b:
-                raise Exception('Block #{block} is not right: ({head}, {tail})'
-                                .format(block=block, head=a, tail=b))
+                raise ValueError(f'Block #{block} is not right: ({a}, {b})')
         return True
 
     def get_sub_blocks(self):
         """Get the sub-blocks in the file.
 
         Normally one would not need this function but it is here because
         I have used it.
 
         """
         block_size = self.format.block_size
         subblock_size = self.format.subblock_size
         n_blocks = self._size / block_size
         for b in range(0, n_blocks * block_size, block_size):
-            for s in range(0, self.format.subblocks_per_block):
+            for s in range(self.format.subblocks_per_block):
                 pos = b + s * subblock_size + self.format.block_padding_size
                 self._file.seek(pos)
-                yield unpack(self.format.subblock_format,
-                             self._file.read(subblock_size))
+                yield unpack(self.format.subblock_format, self._file.read(subblock_size))
 
     def get_header(self):
         """Get the Run header
 
         :return: an instance of RunHeader
 
         """
@@ -306,18 +296,19 @@
         beginning and end of the events. It does not unpack the data.
 
         """
         block_size = self.format.block_size
         subblock_size = self.format.subblock_size
         n_blocks = self._size // block_size
         for b in range(0, n_blocks * block_size, block_size):
-            for s in range(0, self.format.subblocks_per_block):
+            for s in range(self.format.subblocks_per_block):
                 pos = b + s * subblock_size + self.format.block_padding_size
-                if ((min_sub_block is not None and pos <= min_sub_block) or
-                        (max_sub_block is not None and pos >= max_sub_block)):
+                if (min_sub_block is not None and pos <= min_sub_block) or (
+                    max_sub_block is not None and pos >= max_sub_block
+                ):
                     continue
                 yield pos
 
     def _get_events(self):
         """Get the start and end blocks indices for all events"""
 
         heads = []
@@ -372,54 +363,49 @@
 
         return particle_data(self._unpack_particle(word))
 
     def _get_particles(self, word):
         """Get subblock of particles from the contents as tuples"""
 
         unpacked_particles = self._unpack_particles(word)
-        particles = zip(*[iter(unpacked_particles)] *
-                        self.format.fields_per_particle)
+        particles = zip(*[iter(unpacked_particles)] * self.format.fields_per_particle)
         return (particle_data(particle) for particle in particles)
 
     def _unpack_subblock(self, word):
         """Unpack a subblock block
 
         :param word: the index where the subblock starts
 
         """
         self._file.seek(word)
-        return unpack(self.format.subblock_format,
-                      self._file.read(self.format.subblock_size))
+        return unpack(self.format.subblock_format, self._file.read(self.format.subblock_size))
 
     def _unpack_particle(self, word):
         """Unpack a particle block
 
         :param word: the index where the particle subblock starts
 
         """
         self._file.seek(word)
-        return unpack(self.format.particle_format,
-                      self._file.read(self.format.particle_size))
+        return unpack(self.format.particle_format, self._file.read(self.format.particle_size))
 
     def _unpack_particles(self, word):
         """Unpack a particles subblock
 
         :param word: the index where the particle subblock starts
 
         """
         self._file.seek(word)
-        return unpack(self.format.particles_format,
-                      self._file.read(self.format.particles_size))
+        return unpack(self.format.particles_format, self._file.read(self.format.particles_size))
 
     def __repr__(self):
-        return f"{self.__class__.__name__}({self._filename!r})"
+        return f'{self.__class__.__name__}({self._filename!r})'
 
 
 class CorsikaFileThin(CorsikaFile):
-
     """CORSIKA thinned output file handler
 
     Same as the unthinned output handler, but with support for
     the different format, particles also have the weight property.
     This class is meant for thinned simulations.
 
     """
@@ -443,10 +429,9 @@
 
         return particle_data_thin(self._unpack_particle(word))
 
     def _get_particles(self, word):
         """Get subblock of thinned particles from the contents as tuples"""
 
         unpacked_particles = self._unpack_particles(word)
-        particles = zip(*[iter(unpacked_particles)] *
-                        self.format.fields_per_particle)
+        particles = zip(*[iter(unpacked_particles)] * self.format.fields_per_particle)
         return (particle_data_thin(particle) for particle in particles)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/store_corsika_data.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/store_corsika_data.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-""" Store CORSIKA simulation data in HDF5 file
+"""Store CORSIKA simulation data in HDF5 file
 
-    This module reads the CORSIKA binary ground particles file and stores
-    each particle individually in a HDF5 file, using PyTables.  This file
-    can then be used as input for the detector simulation.
+This module reads the CORSIKA binary ground particles file and stores
+each particle individually in a HDF5 file, using PyTables.  This file
+can then be used as input for the detector simulation.
 
-    The syntax and options for calling this script can be seen with::
+The syntax and options for calling this script can be seen with::
 
-        $ store_corsika_data --help
+    $ store_corsika_data --help
 
-    For example to convert a CORSIKA file in the current directory called
-    DAT000000 to a HDF5 called corsika.h5 with a progress bar run::
+For example to convert a CORSIKA file in the current directory called
+DAT000000 to a HDF5 called corsika.h5 with a progress bar run::
 
-        $ store_corsika_data --progress DAT000000 corsika.h5
+    $ store_corsika_data --progress DAT000000 corsika.h5
 
 """
 
 import argparse
 import os
 import tempfile
 
@@ -40,34 +40,32 @@
     p_y = tables.Float32Col(pos=7)
     p_z = tables.Float32Col(pos=8)
     hadron_generation = tables.UInt8Col(pos=9)
     observation_level = tables.UInt8Col(pos=10)
 
 
 class ThinnedGroundParticles(GroundParticles):
-
     """Store information about thinned shower particles
 
     .. attribute:: weight
 
         Weight of the particle, indicating the number of particles it
         represents.
 
     """
 
     weight = tables.Float32Col(pos=11)
 
 
-def save_particle(row, p):
+def save_particle(row, particle):
     """Write the information of a particle into a row"""
 
-    (p_x, p_y, p_z, x, y, t, id, r, hadron_generation, observation_level,
-     phi) = p
+    (p_x, p_y, p_z, x, y, t, particle_id, r, hadron_generation, observation_level, phi) = particle
 
-    row['particle_id'] = id
+    row['particle_id'] = particle_id
     row['r'] = r
     row['phi'] = phi
     row['x'] = x
     row['y'] = y
     row['t'] = t
     row['p_x'] = p_x
     row['p_y'] = p_y
@@ -81,46 +79,43 @@
     """Write the information of a thinned particle into a row"""
 
     row['weight'] = p[-1]
 
     save_particle(row, p[:-1])
 
 
-def store_and_sort_corsika_data(source, destination, overwrite=False,
-                                progress=False, thin=False):
+def store_and_sort_corsika_data(source, destination, overwrite=False, progress=False, thin=False):
     """First convert the data to HDF5 and create a sorted version"""
 
     if os.path.exists(destination):
         if not overwrite:
             if progress:
-                raise Exception("Destination already exists, doing nothing")
+                raise RuntimeError('Destination already exists, doing nothing')
             return
         else:
             os.remove(destination)
 
     if not thin:
         corsika_reader = CorsikaFile
     else:
         corsika_reader = CorsikaFileThin
 
     temp_dir = os.path.dirname(destination)
     unsorted = create_tempfile_path(temp_dir)
     temp_path = create_tempfile_path(temp_dir)
 
-    with corsika_reader(source) as corsika_data, \
-            tables.open_file(unsorted, 'a') as hdf_temp:
-        store_corsika_data(corsika_data, hdf_temp, progress=progress,
-                           thin=thin)
-
-    with tables.open_file(unsorted, 'r') as hdf_unsorted, \
-            tables.open_file(destination, 'w') as hdf_data, \
-            tables.open_file(temp_path, 'w') as hdf_temp:
+    with corsika_reader(source) as corsika_data, tables.open_file(unsorted, 'a') as hdf_temp:
+        store_corsika_data(corsika_data, hdf_temp, progress=progress, thin=thin)
 
-        with TableMergeSort('x', hdf_unsorted, hdf_data, hdf_temp,
-                            progress=progress) as mergesort:
+    with (
+        tables.open_file(unsorted, 'r') as hdf_unsorted,
+        tables.open_file(destination, 'w') as hdf_data,
+        tables.open_file(temp_path, 'w') as hdf_temp,
+    ):
+        with TableMergeSort('x', hdf_unsorted, hdf_data, hdf_temp, progress=progress) as mergesort:
             mergesort.sort()
 
             event_header = hdf_unsorted.get_node_attr('/', 'event_header')
             run_header = hdf_unsorted.get_node_attr('/', 'run_header')
             event_end = hdf_unsorted.get_node_attr('/', 'event_end')
             run_end = hdf_unsorted.get_node_attr('/', 'run_end')
             hdf_data.set_node_attr('/', 'event_header', event_header)
@@ -131,59 +126,61 @@
     os.remove(unsorted)
     os.remove(temp_path)
 
     with tables.open_file(destination, 'a') as hdf_data:
         create_index(hdf_data, progress=progress)
 
 
-def store_corsika_data(source, destination, table_name='groundparticles',
-                       progress=False, thin=False):
+def store_corsika_data(source, destination, table_name='groundparticles', progress=False, thin=False):
     """Store particles from a CORSIKA simulation in a HDF5 file
 
     :param source: CorsikaFile instance of the source DAT file.
     :param destination: PyTables file instance of the destination file.
     :param table_name: table name in which particles are stored.
     :param progress: if True show progressbar when saving particles.
     :param thin: if True assume the data contains thinned particles.
 
     """
     if progress:
-        print("Converting CORSIKA data (%s) to HDF5 format" % source._filename)
+        print('Converting CORSIKA data (%s) to HDF5 format' % source._filename)
     source.check()
 
     if not thin:
         description = GroundParticles
         save_particle_to_row = save_particle
     else:
         description = ThinnedGroundParticles
         save_particle_to_row = save_thinned_particle
 
     for event in source.get_events():
         n_particles = event.get_end().n_particles_levels
         progress = progress and n_particles > 1
         try:
-            table = destination.create_table('/', table_name, description,
-                                             'All groundparticles',
-                                             expectedrows=n_particles)
+            table = destination.create_table(
+                '/',
+                table_name,
+                description,
+                'All groundparticles',
+                expectedrows=n_particles,
+            )
         except tables.NodeError:
             if progress:
                 print('%s already exists, doing nothing' % table_name)
                 return
             else:
                 raise
         if progress:
-            pbar = ProgressBar(max_value=n_particles - 1,
-                               widgets=[Percentage(), Bar(), ETA()]).start()
+            pbar = ProgressBar(max_value=n_particles - 1, widgets=[Percentage(), Bar(), ETA()]).start()
 
         particle_row = table.row
         for row, particle in enumerate(event.get_particles()):
             save_particle_to_row(particle_row, particle)
-            if progress and not row % 5000:
+            if progress and not row % 5_000:
                 pbar.update(row)
-            if not row % 1000000:
+            if not row % 1_000_000:
                 table.flush()
 
         if progress:
             pbar.finish()
 
     table.flush()
 
@@ -210,16 +207,15 @@
         print('Ensuring the x column for table %s is indexed.' % table_name)
     try:
         table.cols.x.create_csindex()
     except ValueError:
         table.reindex_dirty()
 
 
-def copy_and_sort_node(hdf_temp, hdf_data, table_name='groundparticles',
-                       progress=False):
+def copy_and_sort_node(hdf_temp, hdf_data, table_name='groundparticles', progress=False):
     """Sort the data in the tables by the x column
 
     This speeds up queries to select data based on the x column.
 
     """
     target_root = hdf_data.get_node('/')
     source_table = hdf_temp.get_node('/', table_name)
@@ -235,24 +231,19 @@
     f, path = tempfile.mkstemp(suffix='.h5', dir=temp_dir)
     os.close(f)
     return path
 
 
 def main():
     parser = argparse.ArgumentParser(description='Store CORSIKA data as HDF5.')
-    parser.add_argument('source', help="path of the CORSIKA source file")
-    parser.add_argument('destination',
-                        help="path of the HDF5 destination file")
-    parser.add_argument('--overwrite', action='store_true',
-                        help='overwrite destination file it is already exists')
-    parser.add_argument('--progress', action='store_true',
-                        help='show progressbar during conversion')
-    parser.add_argument('--thin', action='store_true',
-                        help='indicate if thinning was active in CORSIKA')
+    parser.add_argument('source', help='path of the CORSIKA source file')
+    parser.add_argument('destination', help='path of the HDF5 destination file')
+    parser.add_argument('--overwrite', action='store_true', help='overwrite destination file it is already exists')
+    parser.add_argument('--progress', action='store_true', help='show progressbar during conversion')
+    parser.add_argument('--thin', action='store_true', help='indicate if thinning was active in CORSIKA')
     args = parser.parse_args()
 
-    store_and_sort_corsika_data(args.source, args.destination, args.overwrite,
-                                args.progress, args.thin)
+    store_and_sort_corsika_data(args.source, args.destination, args.overwrite, args.progress, args.thin)
 
 
 if __name__ == '__main__':
     main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/corsika/units.py` & `hisparc_sapphire-3.0.0/sapphire/corsika/units.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-""" Defines units in terms of HiSPARC standard units
+"""Defines units in terms of HiSPARC standard units
 
 You should use the units defined in this file whenever you
 have a dimensional quantity in your code.  For example:
 
 Do:
 
 .. code-block:: python
@@ -82,15 +82,15 @@
 tera = 1e12
 peta = 1e15
 exa = 1e18
 zetta = 1e21
 yotta = 1e24
 
 # Length [L]
-meter = 1.
+meter = 1.0
 meter2 = meter * meter
 meter3 = meter * meter * meter
 
 millimeter = milli * meter
 millimeter2 = millimeter * millimeter
 millimeter3 = millimeter * millimeter * millimeter
 
@@ -131,53 +131,53 @@
 m3 = meter3
 
 km = kilometer
 km2 = kilometer2
 km3 = kilometer3
 
 # Angle
-radian = 1.
+radian = 1.0
 milliradian = milli * radian
-degree = (3.14159265358979323846 / 180.) * radian
+degree = (3.14159265358979323846 / 180.0) * radian
 
-steradian = 1.
+steradian = 1.0
 
 # symbols
 rad = radian
 mrad = milliradian
 sr = steradian
 deg = degree
 
 # Time [T]
-nanosecond = 1.
+nanosecond = 1.0
 nanosecond2 = nanosecond * nanosecond
 second = giga * nanosecond
 millisecond = milli * second
 microsecond = micro * second
 picosecond = pico * second
 minute = 60 * second
 hour = 60 * minute
 day = 24 * hour
 
-hertz = 1. / second
+hertz = 1.0 / second
 kilohertz = kilo * hertz
 megahertz = mega * hertz
 
 # symbols
 ns = nanosecond
 s = second
 ms = millisecond
 
 # Electric charge [Q]
-eplus = 1.  # positron charge
+eplus = 1.0  # positron charge
 eSI = 1.602176462e-19  # positron charge in coulomb
 coulomb = eplus / eSI  # coulomb = 6.24150e18 * eplus
 
 # Energy [E]
-electronvolt = 1.
+electronvolt = 1.0
 megaelectronvolt = mega * electronvolt
 kiloelectronvolt = kilo * electronvolt
 gigaelectronvolt = giga * electronvolt
 teraelectronvolt = tera * electronvolt
 petaelectronvolt = peta * electronvolt
 exaelectronvolt = exa * electronvolt
 zettaelectronvolt = zetta * electronvolt
@@ -248,28 +248,28 @@
 gauss = 1e-4 * tesla
 kilogauss = kilo * gauss
 
 # Inductance [T^2][E][Q^-2]
 henry = weber / ampere  # henry = 1.60217e-7 * MeV * (ns / eplus) ** 2
 
 # Temperature
-kelvin = 1.
+kelvin = 1.0
 
 # Amount of substance
-mole = 1.
+mole = 1.0
 
 # Activity [T^-1]
-becquerel = 1. / second
+becquerel = 1.0 / second
 curie = 3.7e10 * becquerel
 
 # Absorbed dose [L^2][T^-2]
 gray = joule / kilogram
 
 # Luminous intensity [I]
-candela = 1.
+candela = 1.0
 
 # Luminous flux [I]
 lumen = candela * steradian
 
 # Illuminance [I][L^-2]
 lux = lumen / meter2
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/clusters/3000.json` & `hisparc_sapphire-3.0.0/sapphire/data/clusters/3000.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/clusters.json` & `hisparc_sapphire-3.0.0/sapphire/data/clusters.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/countries.json` & `hisparc_sapphire-3.0.0/sapphire/data/countries.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1006.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1006.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1007.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1007.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1009.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1009.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1010.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1010.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/104.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/104.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/106.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/106.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/1103.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/1103.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/12001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/12001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13009.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13009.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13104.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13104.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/13201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/13201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/14001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/14001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/14002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/14002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/14003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/14003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/14004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/14004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/14005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/14005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/14006.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/14006.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/14007.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/14007.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/14008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/14008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/15.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/15.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/15001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/15001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/16001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/16001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/16101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/16101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/17001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/17001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/20001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/20001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/20002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/20002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/20003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/20003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/2002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/2002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/2003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/2003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/2010.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/2010.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/202.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/202.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/203.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/203.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/21.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/21.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/2101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/2101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/2102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/2102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/22.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/22.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/2201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/2201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/23.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/23.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/24.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/24.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/303.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/303.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/304.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/304.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/305.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/305.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3104.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3104.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3202.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3202.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3203.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3203.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3303.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3303.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3304.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3304.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3601.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3601.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/3702.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/3702.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/4.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/4.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/40001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/40001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/4001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/4001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/401.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/401.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/5.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/5.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/502.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/502.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/503.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/503.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/504.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/504.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/505.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/505.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/506.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/506.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/512.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/512.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/513.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/513.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/514.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/514.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/599.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/599.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/6.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/6.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/60001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/60001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/601.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/601.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/602.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/602.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/603.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/603.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/604.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/604.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/7.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/7.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/7001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/7001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/7002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/7002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/7003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/7003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/7102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/7102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/7301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/7301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/7401.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/7401.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/7601.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/7601.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8006.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8006.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8009.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8009.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8303.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8303.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/8401.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/8401.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/current/9.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/current/9.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/10.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/10.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1006.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1006.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1007.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1007.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1009.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1009.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1010.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1010.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/103.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/103.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/104.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/104.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/106.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/106.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/1103.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/1103.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13007.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13007.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13103.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13103.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13104.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13104.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/13601.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/13601.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14006.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14006.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/14007.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/14007.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/15.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/15.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/15001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/15001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/15002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/15002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/16001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/16001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/16101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/16101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/17001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/17001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/20001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/20001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/20002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/20002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/20003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/20003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2006.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2006.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2010.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2010.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/202.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/202.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/203.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/203.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/21.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/21.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/22.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/22.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/2201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/2201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/23.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/23.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/24.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/24.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/303.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/303.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/304.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/304.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/305.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/305.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3103.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3103.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3104.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3104.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3202.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3202.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3203.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3203.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3302.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3302.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3303.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3303.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3304.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3304.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3401.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3401.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3601.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3601.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3701.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3701.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/3702.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/3702.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/40001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/40001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/4004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/4004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/401.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/401.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/5.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/5.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/502.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/502.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/503.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/503.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/504.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/504.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/505.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/505.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/506.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/506.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/512.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/512.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/513.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/513.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/514.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/514.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/6.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/6.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/60001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/60001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/601.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/601.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/602.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/602.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/603.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/603.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/604.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/604.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7401.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7401.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/7601.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/7601.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8006.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8006.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8007.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8007.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8009.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8009.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8102.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8102.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8103.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8103.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8104.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8104.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8302.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8302.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8303.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8303.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/8401.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/8401.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/detector_timing_offsets/9.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/detector_timing_offsets/9.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/electronics/599.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/electronics/599.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/electronics/9.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/electronics/9.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/extend_local_data.py` & `hisparc_sapphire-3.0.0/sapphire/data/extend_local_data.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-""" Add more local JSON and TSV data
+"""Add more local JSON and TSV data
 
 Add additional local data, to be used by :mod:`~sapphire.api` if internet is
 unavailable. The use of local data can also be forced to skip calls to the
 server or prevented to require fresh data from the server.
 
 This data is not included by default because then the SAPPHiRE package would
 become to large. By running this script the data is added after installation.
@@ -13,14 +13,15 @@
     $ extend_local_data
 
 To make the script show information about what it will do add the help flag::
 
     $ extend_local_data --help
 
 """
+
 import argparse
 
 from ..api import Network
 from .update_local_data import update_sublevel_tsv
 
 
 def update_additional_local_tsv(progress=True):
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/1007.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/1007.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/1101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/1101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/14001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/14001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/14004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/14004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/15.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/15.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/15001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/15001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/17001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/17001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/202.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/202.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/203.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/203.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/2201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/2201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/24.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/24.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/3601.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/3601.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/4.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/4.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/40001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/40001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/505.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/505.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/512.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/512.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/599.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/599.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/gps/8004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/gps/8004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/layout/501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/layout/501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/10.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/10.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1003.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1003.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1005.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1005.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1006.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1006.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1007.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1007.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1008.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1008.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1009.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1009.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/101.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/101.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1010.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1010.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/102.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/102.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/103.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/103.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/104.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/104.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/105.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/105.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/106.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/106.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1101.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1101.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1102.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1102.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/1103.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/1103.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/12001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/12001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13003.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13003.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13004.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13004.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13005.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13005.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13006.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13006.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13007.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13007.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13008.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13008.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13009.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13009.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13101.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13101.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13102.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13102.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13103.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13103.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13104.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13104.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13201.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13201.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13301.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13301.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13401.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13401.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13501.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13501.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/13601.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/13601.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/14001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/14001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/14002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/14002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/14003.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/14003.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/14004.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/14004.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/14005.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/14005.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/14006.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/14006.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/14007.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/14007.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/14008.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/14008.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/15.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/15.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/15001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/15001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/15002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/15002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/16001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/16001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/16101.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/16101.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/17001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/17001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/20001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/20001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/20002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/20002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/20003.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/20003.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2003.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2003.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2004.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2004.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2005.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2005.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2006.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2006.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2008.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2008.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/201.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/201.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2010.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2010.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/202.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/202.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/203.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/203.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/21.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/21.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2101.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2101.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2102.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2102.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2103.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2103.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/22.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/22.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/2201.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/2201.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/23.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/23.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/24.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/24.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/25.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/25.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/301.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/301.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/303.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/303.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/304.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/304.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/305.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/305.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3101.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3101.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3102.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3102.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3103.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3103.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3104.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3104.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3105.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3105.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3201.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3201.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3202.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3202.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3203.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3203.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3301.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3301.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3302.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3302.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3303.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3303.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3304.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3304.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3401.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3401.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3501.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3501.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3601.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3601.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3701.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3701.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/3702.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/3702.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/4.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/4.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/40001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/40001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/4001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/4001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/4002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/4002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/4003.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/4003.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/4004.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/4004.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/401.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/401.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/5.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/5.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/501.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/501.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/502.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/502.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/503.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/503.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/504.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/504.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/505.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/505.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/506.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/506.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/507.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/507.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/508.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/508.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/509.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/509.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/510.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/510.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/511.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/511.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/512.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/512.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/513.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/513.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/514.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/514.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/521.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/521.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/522.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/522.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/599.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/599.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/6.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/6.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/60001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/60001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/601.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/601.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/602.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/602.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/603.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/603.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/604.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/604.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7003.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7003.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7101.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7101.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7102.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7102.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7201.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7201.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7301.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7301.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7401.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7401.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7501.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7501.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/7601.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/7601.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8001.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8001.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8002.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8002.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8003.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8003.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8004.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8004.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8005.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8005.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8006.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8006.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8007.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8007.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8008.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8008.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8009.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8009.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8101.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8101.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8102.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8102.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8103.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8103.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8104.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8104.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8105.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8105.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8201.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8201.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8301.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8301.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8302.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8302.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8303.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8303.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/8401.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/8401.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station/9.json` & `hisparc_sapphire-3.0.0/sapphire/data/station/9.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1003/1008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1003/1008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/1006/1007.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/1006/1007.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/102/104.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/102/104.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/102/105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/102/105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/104/105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/104/105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/13001/13003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/13001/13003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/14001/14003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/14001/14003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/20002/20003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/20002/20003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/22/23.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/22/23.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3/22.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3/22.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/304/305.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/304/305.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3201/3202.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3201/3202.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3201/3203.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3201/3203.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/3202/3203.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/3202/3203.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/502.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/502.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/503.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/503.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/504.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/504.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/505.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/505.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/506.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/506.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/501/offsets_ref501_s502.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/501/offsets_ref501_s502.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/503.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/503.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/504.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/504.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/505.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/505.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/506.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/506.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/502/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/502/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/504.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/504.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/505.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/505.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/506.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/506.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/503/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/503/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/505.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/505.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/506.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/506.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/504/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/504/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/506.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/506.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/505/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/505/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/506/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/506/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/507/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/507/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/509.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/509.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/508/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/508/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/509/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/509/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/510/511.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/510/511.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7001/7002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7001/7002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7001/7003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7001/7003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/7002/7003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/7002/7003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8001/8004.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8001/8004.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8001/8008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8001/8008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8001/8009.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8001/8009.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8004/8008.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8004/8008.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8004/8009.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8004/8009.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/station_timing_offsets/8008/8009.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/station_timing_offsets/8008/8009.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/stations.json` & `hisparc_sapphire-3.0.0/sapphire/data/stations.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/subclusters/0.json` & `hisparc_sapphire-3.0.0/sapphire/data/subclusters/0.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/subclusters/1000.json` & `hisparc_sapphire-3.0.0/sapphire/data/subclusters/1000.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/subclusters/13000.json` & `hisparc_sapphire-3.0.0/sapphire/data/subclusters/13000.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/subclusters/14000.json` & `hisparc_sapphire-3.0.0/sapphire/data/subclusters/14000.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/subclusters/2000.json` & `hisparc_sapphire-3.0.0/sapphire/data/subclusters/2000.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/subclusters/500.json` & `hisparc_sapphire-3.0.0/sapphire/data/subclusters/500.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/subclusters/8000.json` & `hisparc_sapphire-3.0.0/sapphire/data/subclusters/8000.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/subclusters.json` & `hisparc_sapphire-3.0.0/sapphire/data/subclusters.json`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/1001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/1001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/12001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/12001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/14001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/14001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/2003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/2003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/2010.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/2010.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/2101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/2101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/2201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/2201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/23.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/23.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/3002.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/3002.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/3101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/3101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/3201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/3201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/4001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/4001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/599.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/599.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/7.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/7.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/7301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/7301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/8003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/8003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/8105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/8105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/trigger/9.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/trigger/9.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/update_local_data.py` & `hisparc_sapphire-3.0.0/sapphire/data/update_local_data.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-""" Update local JSON and TSV data
+"""Update local JSON and TSV data
 
 This script updates the local copies of the JSON and TSV data from the Public
 Database API. If internet is unavailable the :mod:`~sapphire.api` uses these
 files. The use of local data can also be forced to skip calls to the server or
 prevented to require fresh data from the server.
 
 Not all available data is included by default because then the SAPPHiRE package
@@ -35,118 +35,113 @@
 
     toplevel_types = ['stations', 'subclusters', 'clusters', 'countries']
     if progress:
         print('Downloading JSONs: %s' % '/'.join(toplevel_types))
     for data_type in pbar(toplevel_types, show=progress):
         update_toplevel_json(data_type)
 
-    for arg_type, data_type in [('stations', 'station_info'),
-                                ('subclusters', 'stations_in_subcluster'),
-                                ('clusters', 'subclusters_in_cluster'),
-                                ('countries', 'clusters_in_country')]:
+    for arg_type, data_type in [
+        ('stations', 'station_info'),
+        ('subclusters', 'stations_in_subcluster'),
+        ('clusters', 'subclusters_in_cluster'),
+        ('countries', 'clusters_in_country'),
+    ]:
         if progress:
-            print('Downloading JSONs: %s' % data_type)
+            print(f'Downloading JSONs: {data_type}')
         update_sublevel_json(arg_type, data_type, progress)
 
 
 def update_local_tsv(progress=True):
     """Get configuration and calibration TSV data for all stations"""
 
     station_numbers = Network().station_numbers()
 
-    for data_type in ['gps', 'trigger', 'layout', 'voltage', 'current',
-                      'electronics', 'detector_timing_offsets']:
+    for data_type in ['gps', 'trigger', 'layout', 'voltage', 'current', 'electronics', 'detector_timing_offsets']:
         if progress:
-            print('Downloading TSVs: %s' % data_type)
-        update_sublevel_tsv(data_type, station_numbers)
+            print(f'Downloading TSVs: {data_type}')
+        update_sublevel_tsv(data_type, station_numbers, progress=progress)
 
     # GPS and layout data should now be up to date, local data can be used
     with warnings.catch_warnings(record=True):
         network = HiSPARCNetwork(force_stale=True)
 
     for data_type in ['station_timing_offsets']:
         if progress:
-            print('Downloading TSVs: %s' % data_type)
-        update_subsublevel_tsv(data_type, station_numbers, network)
+            print(f'Downloading TSVs: {data_type}')
+        update_subsublevel_tsv(data_type, station_numbers, network, progress=progress)
 
 
 def update_toplevel_json(data_type):
     url = API.urls[data_type]
     try:
         get_and_store_json(url)
     except Exception:
-        print('Failed to get %s data' % data_type)
+        print(f'Failed to get {data_type} data')
 
 
 def update_sublevel_json(arg_type, data_type, progress=True):
     subdir = API.urls[data_type].split('/')[0]
     try:
         mkdir(path.join(LOCAL_BASE, subdir))
     except OSError:
         pass
 
     url = API.urls[arg_type]
     try:
         numbers = [x['number'] for x in loads(API._retrieve_url(url))]
     except Exception:
         if progress:
-            print('Failed to get %s data' % data_type)
+            print(f'Failed to get {data_type} data')
         return
 
     kwarg = API.urls[data_type].split('/')[1].strip('{}')
     for number in pbar(numbers, show=progress):
-        url = API.urls[data_type].format(**{kwarg: number, 'year': '',
-                                            'month': '', 'day': ''})
+        url = API.urls[data_type].format(**{kwarg: number, 'year': '', 'month': '', 'day': ''})
         try:
             get_and_store_json(url.strip('/'))
         except Exception:
             if progress:
-                print('Failed to get %s data for %s %d' %
-                      (data_type, arg_type, number))
+                print('Failed to get %s data for %s %d' % (data_type, arg_type, number))
             return
 
 
 def update_sublevel_tsv(data_type, station_numbers, progress=True):
     subdir = API.src_urls[data_type].split('/')[0]
     try:
         mkdir(path.join(LOCAL_BASE, subdir))
     except OSError:
         pass
 
     for number in pbar(station_numbers, show=progress):
-        url = API.src_urls[data_type].format(station_number=number,
-                                             year='', month='', day='')
+        url = API.src_urls[data_type].format(station_number=number, year='', month='', day='')
         url = url.strip('/') + '/'
         try:
             get_and_store_tsv(url)
         except Exception:
             if progress and data_type != 'layout':
                 print('Failed to get %s for station %d' % (data_type, number))
             continue
 
 
 def update_subsublevel_tsv(data_type, station_numbers, network, progress=True):
     subdir = API.src_urls[data_type].split('/')[0]
-    for number1, number2 in pbar(list(combinations(station_numbers, 2)),
-                                 show=progress):
+    for number1, number2 in pbar(list(combinations(station_numbers, 2)), show=progress):
         distance = network.calc_distance_between_stations(number1, number2)
         if distance is None or distance > 1e3:
             continue
         try:
             makedirs(path.join(LOCAL_BASE, subdir, str(number1)))
         except OSError:
             pass
-        url = API.src_urls[data_type].format(station_1=number1,
-                                             station_2=number2)
+        url = API.src_urls[data_type].format(station_1=number1, station_2=number2)
         try:
             get_and_store_tsv(url)
         except Exception:
             if progress:
-                print('Failed to get %s data for station pair %d-%d' %
-                      (data_type, number1, number2))
+                print('Failed to get %s data for station pair %d-%d' % (data_type, number1, number2))
 
 
 def get_and_store_json(url):
     data = loads(API._retrieve_url(url))
     json_path = path.join(LOCAL_BASE, url.strip('/') + extsep + 'json')
     with open(json_path, 'w') as jsonfile:
         dump(data, jsonfile, indent=4, sort_keys=True)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/1001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/1001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/12001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/12001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/13003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/13003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/13005.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/13005.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/14001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/14001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/2010.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/2010.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/2101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/2101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/2201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/2201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/23.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/23.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/24.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/24.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/3.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/3.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/3101.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/3101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/3201.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/3201.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/4001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/4001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/401.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/401.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/501.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/501.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/502.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/502.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/503.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/503.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/504.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/504.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/505.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/505.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/507.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/507.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/508.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/508.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/510.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/510.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/599.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/599.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/6.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/6.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/7.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/7.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/7301.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/7301.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/8001.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/8001.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/8003.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/8003.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/8006.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/8006.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/8105.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/8105.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/data/voltage/9.tsv` & `hisparc_sapphire-3.0.0/sapphire/data/voltage/9.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/esd.py` & `hisparc_sapphire-3.0.0/sapphire/esd.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,22 @@
-""" Fetch events and other data from the event summary data (ESD).
+"""Fetch events and other data from the event summary data (ESD).
 
-    This module enables you to access the event summary data.
+This module enables you to access the event summary data.
 
-    If you are in a real hurry and know what you're doing (and took the
-    time to read this far), you can call the :func:`quick_download`
-    function like this::
+If you are in a real hurry and know what you're doing (and took the
+time to read this far), you can call the :func:`quick_download`
+function like this::
 
-        >>> from sapphire import quick_download
-        >>> data = quick_download(501)
+    >>> from sapphire import quick_download
+    >>> data = quick_download(501)
 
-    For regular use, look up :func:`download_data`.
+For regular use, look up :func:`download_data`.
 
 """
+
 import calendar
 import collections
 import csv
 import datetime
 import itertools
 import os.path
 import re
@@ -118,26 +119,26 @@
         >>> import sapphire.esd
         >>> data = tables.open_file('data.h5', 'w')
         >>> sapphire.esd.load_data(data, '/s501', 'events-s501-20130910.tsv')
 
     """
     if type == 'events':
         table = _get_or_create_events_table(file, group)
-        read_and_store_class = _read_line_and_store_event_class
+        read_and_store_class = ReadLineAndStoreEventClass
     elif type == 'weather':
         table = _get_or_create_weather_table(file, group)
-        read_and_store_class = _read_line_and_store_weather_class
+        read_and_store_class = ReadLineAndStoreWeatherClass
     elif type == 'singles':
         table = _get_or_create_singles_table(file, group)
-        read_and_store_class = _read_line_and_store_singles_class
+        read_and_store_class = ReadLineAndStoreSinglesClass
     elif type == 'lightning':
         table = _get_or_create_lightning_table(file, group)
-        read_and_store_class = _read_line_and_store_lightning_class
+        read_and_store_class = ReadLineAndStoreLightningClass
     else:
-        raise ValueError("Data type not recognized.")
+        raise ValueError('Data type not recognized.')
 
     with open(tsv_file, 'rb') as data:
         reader = csv.reader(iterdecode(data, 'utf-8'), delimiter='\t')
         with read_and_store_class(table) as writer:
             for line in reader:
                 writer.store_line(line)
 
@@ -185,67 +186,67 @@
         end = start + datetime.timedelta(days=1)
 
     # build and open url, create tables and set read function
     query = urlencode({'start': start, 'end': end})
     if type == 'events':
         url = get_events_url().format(station_number=station_number, query=query)
         table = _get_or_create_events_table(file, group)
-        read_and_store = _read_line_and_store_event_class
+        read_and_store = ReadLineAndStoreEventClass
     elif type == 'weather':
         url = get_weather_url().format(station_number=station_number, query=query)
         table = _get_or_create_weather_table(file, group)
-        read_and_store = _read_line_and_store_weather_class
+        read_and_store = ReadLineAndStoreWeatherClass
     elif type == 'singles':
         url = get_singles_url().format(station_number=station_number, query=query)
         table = _get_or_create_singles_table(file, group)
-        read_and_store = _read_line_and_store_singles_class
+        read_and_store = ReadLineAndStoreSinglesClass
     elif type == 'lightning':
         url = get_lightning_url().format(lightning_type=station_number, query=query)
         table = _get_or_create_lightning_table(file, group)
-        read_and_store = _read_line_and_store_lightning_class
+        read_and_store = ReadLineAndStoreLightningClass
     else:
-        raise ValueError("Data type not recognized.")
+        raise ValueError('Data type not recognized.')
 
     try:
         data = urlopen(url)
     except BadStatusLine:
         # Unexplained transient error, retry once
         data = urlopen(url)
 
     # keep track of event timestamp within [start, end] interval for
     # progressbar
     t_start = calendar.timegm(start.utctimetuple())
     t_end = calendar.timegm(end.utctimetuple())
     t_delta = t_end - t_start
     if progress:
-        pbar = ProgressBar(max_value=1., widgets=[Percentage(), Bar(), ETA()]).start()
+        pbar = ProgressBar(max_value=1.0, widgets=[Percentage(), Bar(), ETA()]).start()
 
     # loop over lines in tsv as they come streaming in
     prev_update = time.time()
     reader = csv.reader(iterdecode(data, 'utf-8'), delimiter='\t')
     with read_and_store(table) as writer:
         for line in reader:
             timestamp = writer.store_line(line)
             # update progressbar every 0.5 seconds
-            if progress and time.time() - prev_update > 0.5 and not timestamp == 0.:
-                pbar.update((1. * timestamp - t_start) / t_delta)
+            if progress and time.time() - prev_update > 0.5 and timestamp != 0.0:
+                pbar.update((1.0 * timestamp - t_start) / t_delta)
                 prev_update = time.time()
     if progress:
         pbar.finish()
 
     if line[0][0] == '#':
         if len(line[0]) == 1:
             # No events recieved, and no success line
-            raise Exception('Failed to download data, no data recieved.')
+            raise ValueError('Failed to download data, no data recieved.')
         else:
             # Successful download because last line is a non-empty comment
             return
     else:
         # Last line is data, report failed download and date/time of last line
-        raise Exception('Failed to complete download, last received data from: %s %s.' % tuple(line[:2]))
+        raise ValueError('Failed to complete download, last received data from: %s %s.' % tuple(line[:2]))
 
 
 def download_lightning(file, group, lightning_type=4, start=None, end=None, progress=True):
     """Download KNMI lightning data
 
     :param file: the PyTables datafile handler.
     :param group: the PyTables destination group, which need not exist.
@@ -265,15 +266,15 @@
 
     """
     # sensible default for group name
     if group is None:
         group = '/l%d' % lightning_type
 
     if lightning_type not in range(6):
-        raise ValueError("Invalid lightning type.")
+        raise ValueError('Invalid lightning type.')
 
     download_data(file, group, lightning_type, start=start, end=end, type='lightning', progress=progress)
 
 
 def load_coincidences(file, tsv_file, group=''):
     """Load downloaded event summary data into PyTables file.
 
@@ -319,28 +320,26 @@
         if len(coincidence):
             # Store last coincidence
             _read_lines_and_store_coincidence(file, c_group, coincidence, station_groups)
 
         if line[0][0] == '#':
             if len(line[0]) == 1:
                 # No events to load, and no success line
-                raise Exception('No data to load, source contains no data.')
+                raise ValueError('No data to load, source contains no data.')
             else:
                 # Successful download because last line is a non-empty comment
                 pass
         else:
             # Last line is data, report possible fail and last date/time
-            raise Exception('Source file seems incomplete, last received data '
-                            'from: %s %s.' % tuple(line[2:4]))
+            raise ValueError('Source file seems incomplete, last received data from: %s %s.' % tuple(line[2:4]))
 
         file.flush()
 
 
-def download_coincidences(file, group='', cluster=None, stations=None,
-                          start=None, end=None, n=2, progress=True):
+def download_coincidences(file, group='', cluster=None, stations=None, start=None, end=None, n=2, progress=True):
     """Download event summary data coincidences
 
     :param file: PyTables datafile handler.
     :param group: path of destination group, which need not exist yet.
     :param cluster: HiSPARC cluster name for which to get data.
     :param stations: a list of HiSPARC station numbers for which to get data.
     :param start: a datetime instance defining the start of the search interval.
@@ -373,15 +372,15 @@
         else:
             yesterday = datetime.date.today() - datetime.timedelta(days=1)
             start = datetime.datetime.combine(yesterday, datetime.time(0, 0))
     if end is None:
         end = start + datetime.timedelta(days=1)
 
     if stations is not None and len(stations) < n:
-        raise Exception('To few stations in query, give at least n.')
+        raise ValueError('To few stations in query, give at least n.')
 
     # build and open url, create tables and set read function
     query = urlencode({'cluster': cluster, 'stations': stations, 'start': start, 'end': end, 'n': n})
     url = get_coincidences_url().format(query=query)
     station_groups = _read_or_get_station_groups(file, group)
     c_group = _get_or_create_coincidences_tables(file, group, station_groups)
 
@@ -393,15 +392,15 @@
 
     # keep track of event timestamp within [start, end] interval for
     # progressbar
     t_start = calendar.timegm(start.utctimetuple())
     t_end = calendar.timegm(end.utctimetuple())
     t_delta = t_end - t_start
     if progress:
-        pbar = ProgressBar(max_value=1., widgets=[Percentage(), Bar(), ETA()]).start()
+        pbar = ProgressBar(max_value=1.0, widgets=[Percentage(), Bar(), ETA()]).start()
 
     # loop over lines in tsv as they come streaming in, keep temporary
     # lists until a full coincidence is in.
     prev_update = time.time()
     reader = csv.reader(iterdecode(data, 'utf-8'), delimiter='\t')
     current_coincidence = 0
     coincidence = []
@@ -410,38 +409,37 @@
             continue
         elif int(line[0]) == current_coincidence:
             coincidence.append(line)
         else:
             # Full coincidence has been received, store it.
             timestamp = _read_lines_and_store_coincidence(file, c_group, coincidence, station_groups)
             # update progressbar every 0.5 seconds
-            if progress and time.time() - prev_update > 0.5 and not timestamp == 0.:
-                pbar.update((1. * timestamp - t_start) / t_delta)
+            if progress and time.time() - prev_update > 0.5 and timestamp != 0.0:
+                pbar.update((1.0 * timestamp - t_start) / t_delta)
                 prev_update = time.time()
             coincidence = [line]
             current_coincidence = int(line[0])
             file.flush()
 
     if len(coincidence):
         # Store last coincidence
         _read_lines_and_store_coincidence(file, c_group, coincidence, station_groups)
     if progress:
         pbar.finish()
 
     if line[0][0] == '#':
         if len(line[0]) == 1:
             # No events recieved, and no success line
-            raise Exception('Failed to download data, no data recieved.')
+            raise ValueError('Failed to download data, no data recieved.')
         else:
             # Successful download because last line is a non-empty comment
             pass
     else:
         # Last line is data, report failed download and date/time of last line
-        raise Exception('Failed to complete download, last received data '
-                        'from: %s %s.' % tuple(line[2:4]))
+        raise ValueError('Failed to complete download, last received data from: %s %s.' % tuple(line[2:4]))
 
     file.flush()
 
 
 def _read_or_get_station_groups(file, group):
     """Get station numbers from existing cluster attribute or a new set
 
@@ -454,16 +452,16 @@
     try:
         s_index = file.get_node(group + '/coincidences', 's_index').read()
     except tables.NoSuchNodeError:
         return _get_station_groups(group)
     else:
         re_number = re.compile('[0-9]+$')
         groups = collections.OrderedDict()
-        for sid, station_group in enumerate(s_index):
-            station_group = station_group.decode()
+        for sid, encoded_station_group in enumerate(s_index):
+            station_group = encoded_station_group.decode()
             station = int(re_number.search(station_group).group())
             groups[station] = {'group': station_group, 's_index': sid}
         return groups
 
 
 def _get_station_groups(group):
     """Generate groups names for all stations
@@ -477,17 +475,18 @@
     groups = collections.OrderedDict()
     network = api.Network()
     clusters = network.clusters()
     s_index = 0
     for cluster in clusters:
         stations = network.station_numbers(cluster=cluster['number'])
         for station in stations:
-            groups[station] = {'group': ('%s/hisparc/cluster_%s/station_%d' %
-                                         (group, cluster['name'].lower(), station)),
-                               's_index': s_index}
+            groups[station] = {
+                'group': ('%s/hisparc/cluster_%s/station_%d' % (group, cluster['name'].lower(), station)),
+                's_index': s_index,
+            }
             s_index += 1
     return groups
 
 
 def _get_or_create_coincidences_tables(file, group, station_groups):
     """Get or create event table in PyTables file
 
@@ -506,16 +505,18 @@
     :return: the created coincidences group.
 
     """
     coin_group = group + '/coincidences'
 
     # Create coincidences table
     description = storage.Coincidence
-    s_columns = {'s%d' % station: tables.BoolCol(pos=p)
-                 for p, station in enumerate(station_groups, 12)}
+    start_position = len(storage.Coincidence.columns) + 1
+    s_columns = {
+        f's{station}': tables.BoolCol(pos=position) for position, station in enumerate(station_groups, start_position)
+    }
     description.columns.update(s_columns)
     coincidences = file.create_table(coin_group, 'coincidences', description, createparents=True)
 
     # Create c_index
     file.create_vlarray(coin_group, 'c_index', tables.UInt32Col(shape=2))
 
     # Create and fill s_index
@@ -542,29 +543,31 @@
     available in the TSV download.
 
     :param file: PyTables file.
     :param group: the group to contain the events table, which need not
                   exist.
 
     """
-    description = {'event_id': tables.UInt32Col(pos=0),
-                   'timestamp': tables.Time32Col(pos=1),
-                   'nanoseconds': tables.UInt32Col(pos=2),
-                   'ext_timestamp': tables.UInt64Col(pos=3),
-                   'pulseheights': tables.Int16Col(pos=4, shape=4),
-                   'integrals': tables.Int32Col(pos=5, shape=4),
-                   'n1': tables.Float32Col(pos=6),
-                   'n2': tables.Float32Col(pos=7),
-                   'n3': tables.Float32Col(pos=8),
-                   'n4': tables.Float32Col(pos=9),
-                   't1': tables.Float32Col(pos=10),
-                   't2': tables.Float32Col(pos=11),
-                   't3': tables.Float32Col(pos=12),
-                   't4': tables.Float32Col(pos=13),
-                   't_trigger': tables.Float32Col(pos=14)}
+    description = {
+        'event_id': tables.UInt32Col(pos=0),
+        'timestamp': tables.Time32Col(pos=1),
+        'nanoseconds': tables.UInt32Col(pos=2),
+        'ext_timestamp': tables.UInt64Col(pos=3),
+        'pulseheights': tables.Int16Col(pos=4, shape=4),
+        'integrals': tables.Int32Col(pos=5, shape=4),
+        'n1': tables.Float32Col(pos=6),
+        'n2': tables.Float32Col(pos=7),
+        'n3': tables.Float32Col(pos=8),
+        'n4': tables.Float32Col(pos=9),
+        't1': tables.Float32Col(pos=10),
+        't2': tables.Float32Col(pos=11),
+        't3': tables.Float32Col(pos=12),
+        't4': tables.Float32Col(pos=13),
+        't_trigger': tables.Float32Col(pos=14),
+    }
 
     return file.create_table(group, 'events', description, createparents=True)
 
 
 def _get_or_create_weather_table(file, group):
     """Get or create event table in PyTables file"""
 
@@ -581,30 +584,32 @@
     available in the TSV download.
 
     :param file: PyTables file.
     :param group: the group to contain the weather table, which need not
                   exist.
 
     """
-    description = {'event_id': tables.UInt32Col(pos=0),
-                   'timestamp': tables.Time32Col(pos=1),
-                   'temp_inside': tables.Float32Col(pos=2),
-                   'temp_outside': tables.Float32Col(pos=3),
-                   'humidity_inside': tables.Int16Col(pos=4),
-                   'humidity_outside': tables.Int16Col(pos=5),
-                   'barometer': tables.Float32Col(pos=6),
-                   'wind_dir': tables.Int16Col(pos=7),
-                   'wind_speed': tables.Int16Col(pos=8),
-                   'solar_rad': tables.Int16Col(pos=9),
-                   'uv': tables.Int16Col(pos=10),
-                   'evapotranspiration': tables.Float32Col(pos=11),
-                   'rain_rate': tables.Float32Col(pos=12),
-                   'heat_index': tables.Int16Col(pos=13),
-                   'dew_point': tables.Float32Col(pos=14),
-                   'wind_chill': tables.Float32Col(pos=15)}
+    description = {
+        'event_id': tables.UInt32Col(pos=0),
+        'timestamp': tables.Time32Col(pos=1),
+        'temp_inside': tables.Float32Col(pos=2),
+        'temp_outside': tables.Float32Col(pos=3),
+        'humidity_inside': tables.Int16Col(pos=4),
+        'humidity_outside': tables.Int16Col(pos=5),
+        'barometer': tables.Float32Col(pos=6),
+        'wind_dir': tables.Int16Col(pos=7),
+        'wind_speed': tables.Int16Col(pos=8),
+        'solar_rad': tables.Int16Col(pos=9),
+        'uv': tables.Int16Col(pos=10),
+        'evapotranspiration': tables.Float32Col(pos=11),
+        'rain_rate': tables.Float32Col(pos=12),
+        'heat_index': tables.Int16Col(pos=13),
+        'dew_point': tables.Float32Col(pos=14),
+        'wind_chill': tables.Float32Col(pos=15),
+    }
 
     return file.create_table(group, 'weather', description, createparents=True)
 
 
 def _get_or_create_singles_table(file, group):
     """Get or create singles table in PyTables file"""
 
@@ -621,24 +626,26 @@
     available in the TSV download.
 
     :param file: PyTables file.
     :param group: the group to contain the singles table, which need not
                   exist.
 
     """
-    description = {'event_id': tables.UInt32Col(pos=0),
-                   'timestamp': tables.Time32Col(pos=1),
-                   'mas_ch1_low': tables.Int32Col(pos=2),
-                   'mas_ch1_high': tables.Int32Col(pos=3),
-                   'mas_ch2_low': tables.Int32Col(pos=4),
-                   'mas_ch2_high': tables.Int32Col(pos=5),
-                   'slv_ch1_low': tables.Int32Col(pos=6),
-                   'slv_ch1_high': tables.Int32Col(pos=7),
-                   'slv_ch2_low': tables.Int32Col(pos=8),
-                   'slv_ch2_high': tables.Int32Col(pos=9)}
+    description = {
+        'event_id': tables.UInt32Col(pos=0),
+        'timestamp': tables.Time32Col(pos=1),
+        'mas_ch1_low': tables.Int32Col(pos=2),
+        'mas_ch1_high': tables.Int32Col(pos=3),
+        'mas_ch2_low': tables.Int32Col(pos=4),
+        'mas_ch2_high': tables.Int32Col(pos=5),
+        'slv_ch1_low': tables.Int32Col(pos=6),
+        'slv_ch1_high': tables.Int32Col(pos=7),
+        'slv_ch2_low': tables.Int32Col(pos=8),
+        'slv_ch2_high': tables.Int32Col(pos=9),
+    }
 
     return file.create_table(group, 'singles', description, createparents=True)
 
 
 def _get_or_create_lightning_table(file, group):
     """Get or create lightning table in PyTables file"""
 
@@ -655,21 +662,23 @@
     available in the TSV download.
 
     :param file: PyTables file.
     :param group: the group to contain the lightning table, which need not
                   exist.
 
     """
-    description = {'event_id': tables.UInt32Col(pos=0),
-                   'timestamp': tables.Time32Col(pos=1),
-                   'nanoseconds': tables.UInt32Col(pos=2),
-                   'ext_timestamp': tables.UInt64Col(pos=3),
-                   'latitude': tables.Float32Col(pos=4),
-                   'longitude': tables.Float32Col(pos=5),
-                   'current': tables.Float32Col(pos=6)}
+    description = {
+        'event_id': tables.UInt32Col(pos=0),
+        'timestamp': tables.Time32Col(pos=1),
+        'nanoseconds': tables.UInt32Col(pos=2),
+        'ext_timestamp': tables.UInt64Col(pos=3),
+        'latitude': tables.Float32Col(pos=4),
+        'longitude': tables.Float32Col(pos=5),
+        'current': tables.Float32Col(pos=6),
+    }
 
     return file.create_table(group, 'lightning', description, createparents=True)
 
 
 def _read_lines_and_store_coincidence(file, c_group, coincidence, station_groups):
     """Read TSV lines and store coincidence
 
@@ -691,36 +700,36 @@
     row['timestamp'] = int(coincidence[0][4])
     row['nanoseconds'] = int(coincidence[0][5])
     row['ext_timestamp'] = int(coincidence[0][4]) * 1_000_000_000 + int(coincidence[0][5])
 
     for event in coincidence:
         station_number = int(event[1])
         try:
-            row['s%d' % station_number] = True
+            row[f's{station_number}'] = True
             group_path = station_groups[station_number]['group']
         except KeyError:
             # Can not add new column, so user should make a new data file.
-            raise Exception('Unexpected station number: %d, no column and/or '
-                            'station group path available.' % station_number)
+            raise KeyError(
+                f'Unexpected station number: {station_number}, no column and/or station group path available.',
+            )
         event_group = _get_or_create_events_table(file, group_path)
-        with _read_line_and_store_event_class(event_group) as writer:
+        with ReadLineAndStoreEventClass(event_group) as writer:
             s_idx = station_groups[station_number]['s_index']
             e_idx = len(event_group)
             c_idx.append((s_idx, e_idx))
             writer.store_line(event[2:])
 
     row.append()
     c_index = file.get_node(c_group, 'c_index')
     c_index.append(c_idx)
 
     return int(coincidence[0][4])
 
 
-class _read_line_and_store_event_class:
-
+class ReadLineAndStoreEventClass:
     """Store lines of event data from the ESD
 
     Use this contextmanager to store events from a TSV file into a PyTables
     table.
 
     :param table: a PyTables Table object in which to store the data.
 
@@ -739,20 +748,42 @@
         :param line: the line to store as a tuple of strings (one element per column).
         :return: timestamp of the stored event, or 0 if the given line was a
                  comment line starting with a '#'.
 
         """
         # ignore comment lines
         if line[0][0] == '#':
-            return 0.
+            return 0.0
 
         # break up TSV line
-        (date, time_str, timestamp, nanoseconds, ph1, ph2, ph3, ph4, int1,
-         int2, int3, int4, n1, n2, n3, n4, t1, t2, t3, t4, t_trigger, zenith,
-         azimuth) = line[:23]
+        (
+            date,
+            time_str,
+            timestamp,
+            nanoseconds,
+            ph1,
+            ph2,
+            ph3,
+            ph4,
+            int1,
+            int2,
+            int3,
+            int4,
+            n1,
+            n2,
+            n3,
+            n4,
+            t1,
+            t2,
+            t3,
+            t4,
+            t_trigger,
+            zenith,
+            azimuth,
+        ) = line[:23]
 
         row = self.table.row
 
         # convert string values to correct data types or calculate values
         row['event_id'] = self.event_counter
         row['timestamp'] = int(timestamp)
         row['nanoseconds'] = int(nanoseconds)
@@ -770,38 +801,51 @@
         row['t_trigger'] = float(t_trigger)
 
         # store event
         row.append()
 
         self.event_counter += 1
         # force flush every 1e6 rows to free buffers
-        if not self.event_counter % 1000000:
+        if not self.event_counter % 1_000_000:
             self.table.flush()
 
         return int(timestamp)
 
     def __exit__(self, type, value, traceback):
         self.table.flush()
 
 
-class _read_line_and_store_weather_class(_read_line_and_store_event_class):
-
+class ReadLineAndStoreWeatherClass(ReadLineAndStoreEventClass):
     """Store lines of weather data from the ESD"""
 
     def store_line(self, line):
         # ignore comment lines
         if line[0][0] == '#':
-            return 0.
+            return 0.0
 
         # break up TSV line
-        (date, time, timestamp, temperature_inside, temperature_outside,
-         humidity_inside, humidity_outside, atmospheric_pressure,
-         wind_direction, wind_speed, solar_radiation, uv_index,
-         evapotranspiration, rain_rate, heat_index, dew_point,
-         wind_chill) = line
+        (
+            date,
+            time,
+            timestamp,
+            temperature_inside,
+            temperature_outside,
+            humidity_inside,
+            humidity_outside,
+            atmospheric_pressure,
+            wind_direction,
+            wind_speed,
+            solar_radiation,
+            uv_index,
+            evapotranspiration,
+            rain_rate,
+            heat_index,
+            dew_point,
+            wind_chill,
+        ) = line
 
         row = self.table.row
 
         # convert string values to correct data types
         row['event_id'] = self.event_counter
         row['timestamp'] = int(timestamp)
         row['temp_inside'] = float(temperature_inside)
@@ -820,33 +864,42 @@
         row['wind_chill'] = float(wind_chill)
 
         # store event
         row.append()
 
         self.event_counter += 1
         # force flush every 1e6 rows to free buffers
-        if not self.event_counter % 1000000:
+        if not self.event_counter % 1_000_000:
             self.table.flush()
 
         return int(timestamp)
 
 
-class _read_line_and_store_singles_class(_read_line_and_store_event_class):
-
+class ReadLineAndStoreSinglesClass(ReadLineAndStoreEventClass):
     """Store lines of singles data from the ESD"""
 
     def store_line(self, line):
         # ignore comment lines
         if line[0][0] == '#':
-            return 0.
+            return 0.0
 
         # break up TSV line
-        (date, time, timestamp,
-         mas_ch1_low, mas_ch1_high, mas_ch2_low, mas_ch2_high,
-         slv_ch1_low, slv_ch1_high, slv_ch2_low, slv_ch2_high) = line
+        (
+            date,
+            time,
+            timestamp,
+            mas_ch1_low,
+            mas_ch1_high,
+            mas_ch2_low,
+            mas_ch2_high,
+            slv_ch1_low,
+            slv_ch1_high,
+            slv_ch2_low,
+            slv_ch2_high,
+        ) = line
 
         row = self.table.row
 
         # convert string values to correct data types
         row['event_id'] = self.event_counter
         row['timestamp'] = int(timestamp)
         row['mas_ch1_low'] = int(mas_ch1_low)
@@ -859,28 +912,27 @@
         row['slv_ch2_high'] = int(slv_ch2_high)
 
         # store event
         row.append()
 
         self.event_counter += 1
         # force flush every 1e6 rows to free buffers
-        if not self.event_counter % 1000000:
+        if not self.event_counter % 1_000_000:
             self.table.flush()
 
         return int(timestamp)
 
 
-class _read_line_and_store_lightning_class(_read_line_and_store_event_class):
-
+class ReadLineAndStoreLightningClass(ReadLineAndStoreEventClass):
     """Store lines of lightning data from the ESD"""
 
     def store_line(self, line):
         # ignore comment lines
         if line[0][0] == '#':
-            return 0.
+            return 0.0
 
         # break up TSV line
         (date, time_str, timestamp, nanoseconds, latitude, longitude, current) = line[:7]
 
         row = self.table.row
 
         # convert string values to correct data types or calculate values
@@ -893,11 +945,11 @@
         row['current'] = float(current)
 
         # store event
         row.append()
 
         self.event_counter += 1
         # force flush every 1e6 rows to free buffers
-        if not self.event_counter % 1000000:
+        if not self.event_counter % 1_000_000:
             self.table.flush()
 
         return int(timestamp)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/kascade.py` & `hisparc_sapphire-3.0.0/sapphire/kascade.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-""" Read and store KASCADE data.
+"""Read and store KASCADE data.
 
-    Read data files provided by the KASCADE collaboration and store them
-    in a format compatible with HiSPARC data.
+Read data files provided by the KASCADE collaboration and store them
+in a format compatible with HiSPARC data.
 
-    This module contains the following class:
+This module contains the following class:
 
-    :class:`StoreKascadeData`
-        Read and store KASCADE data files.
+:class:`StoreKascadeData`
+    Read and store KASCADE data files.
 
-    :class:`KascadeCoincidences`
-        Find HiSPARC and KASCADE events that belong together.
+:class:`KascadeCoincidences`
+    Find HiSPARC and KASCADE events that belong together.
 
 """
 
 import gzip
 import time
 
 from os.path import splitext
@@ -21,16 +21,15 @@
 import numpy as np
 
 from .storage import KascadeEvent
 from .transformations import clock
 
 
 class StoreKascadeData:
-    def __init__(self, data, kascade_filename, kascade_path='/kascade',
-                 hisparc_path=None, force=False, progress=True):
+    def __init__(self, data, kascade_filename, kascade_path='/kascade', hisparc_path=None, force=False, progress=True):
         """Initialize the class.
 
         :param data: the PyTables datafile
         :param hisparc_path: path to the group containing HiSPARC station data.
         :param kascade_path: path of group where KASCADE data wil be stored.
         :param kascade_filename: filename of the KASCADE data source.
         :param force: overwrite existing KASCADE group if it already exists.
@@ -43,20 +42,19 @@
         if hisparc_path is not None:
             self.hisparc = data.get_node(hisparc_path, 'events')
         else:
             self.hisparc = None
 
         if kascade_path in data:
             if not force:
-                raise RuntimeError(f"Cancelling data storage; {kascade_path} already exists")
+                raise RuntimeError(f'Cancelling data storage; {kascade_path} already exists')
             else:
                 data.remove_node(kascade_path, recursive=True)
 
-        self.kascade = data.create_table(kascade_path, 'events', KascadeEvent,
-                                         "KASCADE events", createparents=True)
+        self.kascade = data.create_table(kascade_path, 'events', KascadeEvent, 'KASCADE events', createparents=True)
         self.kascade_filename = kascade_filename
 
     def read_and_store_data(self):
         """Read and store KASCADE data matching HiSPARC data
 
         This function looks at the HiSPARC event data in the specified
         datafile and then processes and adds KASCADE data surrounding
@@ -66,23 +64,23 @@
         if self.hisparc is not None:
             # Determine start and end timestamps from HiSPARC data
             try:
                 timestamps = self.hisparc.col('timestamp')
                 start = clock.gps_to_utc(min(timestamps)) - 5
                 stop = clock.gps_to_utc(max(timestamps)) + 5
             except IndexError:
-                raise RuntimeError("HiSPARC event table is empty")
+                raise RuntimeError('HiSPARC event table is empty')
 
             if self.progress:
-                print(f"Processing data from {time.ctime(start)} to {time.ctime(stop)}")
+                print(f'Processing data from {time.ctime(start)} to {time.ctime(stop)}')
         else:
             start = None
             stop = None
             if self.progress:
-                print("Processing all data")
+                print('Processing all data')
 
         self._process_events_in_range(start, stop)
 
     def _process_events_in_range(self, start=None, stop=None):
         """Process KASCADE events in timestamp range
 
         This function unzips the data file on the fly, reads the data and
@@ -134,16 +132,37 @@
         :param data: a list of KASCADE reconstructed shower variables for one
                      event.
 
         """
         tablerow = self.kascade.row
 
         # read all columns into KASCADE-named variables
-        (Irun, Ieve, Gt, Mmn, EnergyArray, Xc, Yc, Ze, Az, Size, Nmu, He0,  # noqa: N806
-            Hmu0, He1, Hmu1, He2, Hmu2, He3, Hmu3, T200, P200) = data
+        (
+            Irun,
+            Ieve,
+            Gt,
+            Mmn,
+            EnergyArray,
+            Xc,
+            Yc,
+            Ze,
+            Az,
+            Size,
+            Nmu,
+            He0,
+            Hmu0,
+            He1,
+            Hmu1,
+            He2,
+            Hmu2,
+            He3,
+            Hmu3,
+            T200,
+            P200,
+        ) = data
 
         tablerow['run_id'] = Irun
         tablerow['event_id'] = Ieve
         tablerow['timestamp'] = Gt
         tablerow['nanoseconds'] = Mmn
         tablerow['ext_timestamp'] = Gt * 1_000_000_000 + Mmn
         tablerow['energy'] = EnergyArray
@@ -164,15 +183,15 @@
     def __init__(self, data, hisparc_group, kascade_group, overwrite=False, ignore_existing=False):
         self.data = data
         self.hisparc_group = data.get_node(hisparc_group)
         self.kascade_group = data.get_node(kascade_group)
 
         if 'c_index' in self.kascade_group:
             if not overwrite and not ignore_existing:
-                raise RuntimeError("I found existing coincidences stored in the KASCADE group")
+                raise RuntimeError('I found existing coincidences stored in the KASCADE group')
             elif overwrite:
                 data.remove_node(kascade_group, 'c_index')
 
     def search_coincidences(self, timeshift=0, dtlimit=None, limit=None):
         """Search for coincidences
 
         This function does the actual searching of coincidences. It uses
@@ -192,34 +211,34 @@
         :param limit: limit on the number of KASCADE events investigated.
 
         """
         h, k = self._get_cached_sorted_id_and_timestamp_arrays()
 
         # Shift the kascade data instead of the hisparc data. There is less of
         # it, so this is much faster.
-        k['ext_timestamp'] += int(-1e9) * timeshift
+        k['ext_timestamp'] += -1_000_000_000 * timeshift
 
         if dtlimit:
             # dtlimit in ns
-            dtlimit *= 1e9
+            dtlimit *= 1_000_000_000
 
         coinc_dt, coinc_h_idx, coinc_k_idx = [], [], []
 
         # First loop through kascade data until we have the first event that
         # occurs _after_ the first hisparc event.
         h_idx = 0
         for k_idx in range(len(k)):
             if k[k_idx][1] > h[h_idx][1]:
                 break
 
         # Limit number of KASCADE events investigated
         if limit:
             max_k_idx = k_idx + limit - 1
         else:
-            max_k_idx = np.Inf
+            max_k_idx = np.inf
 
         while k_idx <= max_k_idx:
             # Try to get the timestamps of the kascade event and the
             # neighbouring hisparc events.
             try:
                 h_t = int(h[h_idx][1])
                 k_t = int(k[k_idx][1])
@@ -253,27 +272,25 @@
                     coinc_h_idx.append(h_idx + 1)
                 coinc_k_idx.append(k_idx)
 
             # Found a match for this kascade event, so continue with the next
             # one.
             k_idx += 1
 
-        self.coincidences = np.rec.fromarrays(
-            [coinc_dt, coinc_h_idx, coinc_k_idx], names='dt, h_idx, k_idx')
+        self.coincidences = np.rec.fromarrays([coinc_dt, coinc_h_idx, coinc_k_idx], names='dt, h_idx, k_idx')
 
     def store_coincidences(self):
         self.data.create_table(self.kascade_group, 'c_index', self.coincidences)
 
     def _get_cached_sorted_id_and_timestamp_arrays(self):
         if not hasattr(self, '_h'):
             self._h = self._get_sorted_id_and_timestamp_array(self.hisparc_group)
         if not hasattr(self, '_k'):
             self._k = self._get_sorted_id_and_timestamp_array(self.kascade_group)
         return self._h.copy(), self._k.copy()
 
     def _get_sorted_id_and_timestamp_array(self, group):
         timestamps = group.events.col('ext_timestamp')
         ids = group.events.col('event_id')
-        data = np.rec.fromarrays([ids, timestamps],
-                                 names='event_id, ext_timestamp')
+        data = np.rec.fromarrays([ids, timestamps], names='event_id, ext_timestamp')
         data.sort(order='ext_timestamp')
         return data
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/publicdb.py` & `hisparc_sapphire-3.0.0/sapphire/publicdb.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-""" Fetch raw events and other data from the public database
+"""Fetch raw events and other data from the public database
 
-    This module enables you to access the public database and even the raw
-    event data. This is intended for specialized use only. For most uses, it is
-    faster and more convenient to access the event summary data (ESD) using
-    :mod:`~sapphire.esd`.
+This module enables you to access the public database and even the raw
+event data. This is intended for specialized use only. For most uses, it is
+faster and more convenient to access the event summary data (ESD) using
+:mod:`~sapphire.esd`.
 
 """
+
 import datetime
 import logging
 import os
 import re
 
 from urllib.parse import urljoin
 from urllib.request import urlretrieve
@@ -58,29 +59,29 @@
         INFO:sapphire.publicdb:Storing data...
         INFO:sapphire.publicdb:Done.
 
     """
     server = ServerProxy(get_publicdb_xmlrpc_url())
 
     for t0, t1 in datetimerange(start, end):
-        logger.info(f"{t0} {t1}")
-        logger.info(f"Getting server data URL {t0}")
+        logger.info(f'{t0} {t1}')
+        logger.info(f'Getting server data URL {t0}')
         try:
             url = server.hisparc.get_data_url(station_id, t0, get_blobs)
-        except Exception as exc:
-            if re.search("No data", str(exc)):
-                logger.warning(f"No data for {t0}")
+        except Exception as error:
+            if re.search('No data', str(error)):
+                logger.warning(f'No data for {t0}')
                 continue
             else:
                 raise
-        logger.info("Downloading data...")
+        logger.info('Downloading data...')
         tmp_datafile, headers = urlretrieve(url)
-        logger.info("Storing data...")
+        logger.info('Storing data...')
         _store_data(file, group, tmp_datafile, t0, t1)
-        logger.info("Done.")
+        logger.info('Done.')
 
 
 def _store_data(dst_file, dst_group, src_filename, t0, t1):
     """Copy data from a temporary file to the destination file
 
     This function takes a file containing downloaded data and copies it to
     the destination file, based on start and end timestamps.
@@ -98,22 +99,29 @@
         for node in src_file.list_nodes(src_group):
             dst_node = _get_or_create_node(dst_file, dst_group, node)
 
             if node.name == 'blobs':
                 for row in node:
                     dst_node.append(row)
 
-            elif node.name in ['events', 'errors', 'config', 'comparator',
-                               'singles', 'satellites', 'weather',
-                               'weather_error', 'weather_config']:
+            elif node.name in [
+                'events',
+                'errors',
+                'config',
+                'comparator',
+                'singles',
+                'satellites',
+                'weather',
+                'weather_error',
+                'weather_config',
+            ]:
                 if t1 is None:
-                    cond = 'timestamp >= %d' % datetime_to_gps(t0)
+                    cond = f'timestamp >= {datetime_to_gps(t0)}'
                 else:
-                    cond = ('(%d <= timestamp) & (timestamp <= %d)' %
-                            (datetime_to_gps(t0), datetime_to_gps(t1)))
+                    cond = f'({datetime_to_gps(t0)} <= timestamp) & (timestamp <= {datetime_to_gps(t1)})'
 
                 rows = node.read_where(cond)
 
                 if len_blobs:
                     if node.name == 'events':
                         rows['traces'] += len_blobs
                     elif node.name in ['errors', 'weather_error']:
@@ -172,15 +180,15 @@
         (datetime.datetime(2010, 1, 2, 0, 0), None)
         (datetime.datetime(2010, 1, 3, 0, 0), None)
         (datetime.datetime(2010, 1, 4, 0, 0), None)
         (datetime.datetime(2010, 1, 5, 0, 0), datetime.datetime(2010, 1, 5, 13, 0))
 
     """
     if start > stop:
-        raise Exception('Start can not be after stop.')
+        raise ValueError('Start can not be after stop.')
     elif start.date() == stop.date():
         yield start, stop
         return
     else:
         yield start, None
         cur = start.replace(hour=0, minute=0, second=0, microsecond=0) + datetime.timedelta(days=1)
         while cur.date() < stop.date():
@@ -210,10 +218,10 @@
         node = file.get_node(group, src_node.name)
     except tables.NoSuchNodeError:
         if isinstance(src_node, tables.Table):
             node = file.create_table(group, src_node.name, src_node.description, src_node.title)
         elif isinstance(src_node, tables.VLArray):
             node = file.create_vlarray(group, src_node.name, src_node.atom, src_node.title)
         else:
-            raise Exception("Unknown node class: %s" % type(src_node))
+            raise TypeError(f'Unknown node class: {type(src_node)}')
 
     return node
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/qsub.py` & `hisparc_sapphire-3.0.0/sapphire/qsub.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,29 @@
-""" Access the Nikhef Stoomboot cluster.
+"""Access the Nikhef Stoomboot cluster.
 
-    .. note::
-        This module is only for use at Nikhef. The Stoomboot cluster is only
-        accessible for Nikhef users.
-
-    Easy to use functions to make use of the Nikhef Stoomboot facilities.
-    This checks the available slots on the requested queue, creates the
-    scripts to submit, submits the jobs, and cleans up afterwards.
-
-    Example usage::
-
-        >>> from sapphire import qsub
-        >>> qsub.check_queue('long')
-        340
-        >>> qsub.submit_job('touch /data/hisparc/test', 'job_1', 'express')
+.. note::
+    This module is only for use at Nikhef. The Stoomboot cluster is only
+    accessible for Nikhef users.
+
+Easy to use functions to make use of the Nikhef Stoomboot facilities.
+This checks the available slots on the requested queue, creates the
+scripts to submit, submits the jobs, and cleans up afterwards.
+
+Example usage::
+
+    >>> from sapphire import qsub
+    >>> qsub.check_queue('long')
+    340
+    >>> qsub.submit_job('touch /data/hisparc/test', 'job_1', 'express')
 
 """
+
 import os
 import subprocess
+import tempfile
 
 from . import utils
 
 
 def check_queue(queue):
     """Check for available job slots on the selected queue for current user
 
@@ -69,24 +71,24 @@
     # -z: do not print the job_identifier of the created job
     # -j oe: merge standard error into the standard output
     # -N: a recognizable name for the job
     qsub = f'qsub -q {queue} -V -z -j oe -N {script_name} {extra} {script_path}'
 
     result = subprocess.check_output(qsub, stderr=subprocess.STDOUT, shell=True)
     if not result == b'':
-        raise Exception(f'{name} - Error occured: {result}')
+        raise RuntimeError(f'{name} - Error occured: {result}')
 
     delete_script(script_path)
 
 
 def create_script(script, name):
     """Create script as temp file to be run on Stoomboot"""
 
     script_name = f'his_{name}.sh'
-    script_path = os.path.join('/tmp', script_name)
+    script_path = os.path.join(tempfile.gettempdir(), script_name)
 
     with open(script_path, 'w') as script_file:
         script_file.write(script)
     os.chmod(script_path, 0o774)
 
     return script_path, script_name
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/simulations/__init__.py` & `hisparc_sapphire-3.0.0/sapphire/simulations/__init__.py`

 * *Files 15% similar despite different names*

```diff
@@ -18,15 +18,11 @@
 :mod:`~sapphire.simulations.showerfront`
     simple simulations of a shower front
 
 :mod:`~sapphire.simulations.gammas`
     simulation of detector response due to gammas
 
 """
+
 from . import base, detector, gammas, groundparticles, ldf, showerfront
 
-__all__ = ['base',
-           'detector',
-           'groundparticles',
-           'ldf',
-           'showerfront',
-           'gammas']
+__all__ = ['base', 'detector', 'groundparticles', 'ldf', 'showerfront', 'gammas']
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/simulations/base.py` & `hisparc_sapphire-3.0.0/sapphire/simulations/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -16,41 +16,40 @@
     >>> data = tables.open_file('/tmp/test_base_simulation.h5', 'w')
     >>> cluster = ScienceParkCluster()
 
     >>> sim = BaseSimulation(cluster, data, '/simulations/this_run', 10)
     >>> sim.run()
 
 """
+
 import random
 import warnings
 
 import numpy as np
 import tables
 
 from .. import storage
 from ..analysis.process_events import ProcessEvents
 from ..utils import pbar
 
 
 class BaseSimulation:
-
     """Base class for simulations.
 
     :param cluster: :class:`~sapphire.clusters.BaseCluster` instance.
     :param data: writeable PyTables file handle.
     :param output_path: path (as string) to the PyTables group (need not
                         exist) in which the result tables will be created.
     :param n: number of simulations to perform.
     :param seed: seed for the pseudo-random number generators.
     :param progress: if True show a progressbar while simulating.
 
     """
 
-    def __init__(self, cluster, data, output_path='/', n=1, seed=None,
-                 progress=True):
+    def __init__(self, cluster, data, output_path='/', n=1, seed=None, progress=True):
         self.cluster = cluster
         self.data = data
         self.output_path = output_path
         self.n = n
         self.progress = progress
 
         self._prepare_output_tables()
@@ -72,88 +71,79 @@
         self._prepare_coincidence_tables()
         self._prepare_station_tables()
         self._store_station_index()
 
     def run(self):
         """Run the simulations."""
 
-        for (shower_id, shower_parameters) in enumerate(
-                self.generate_shower_parameters()):
-
+        for shower_id, shower_parameters in enumerate(self.generate_shower_parameters()):
             station_events = self.simulate_events_for_shower(shower_parameters)
-            self.store_coincidence(shower_id, shower_parameters,
-                                   station_events)
+            self.store_coincidence(shower_id, shower_parameters, station_events)
 
     def generate_shower_parameters(self):
         """Generate shower parameters like core position, energy, etc."""
 
-        shower_parameters = {'core_pos': (None, None),
-                             'zenith': None,
-                             'azimuth': None,
-                             'size': None,
-                             'energy': None,
-                             'ext_timestamp': None}
+        shower_parameters = {
+            'core_pos': (None, None),
+            'zenith': None,
+            'azimuth': None,
+            'size': None,
+            'energy': None,
+            'ext_timestamp': None,
+        }
 
         for _ in pbar(range(self.n), show=self.progress):
             yield shower_parameters
 
     def simulate_events_for_shower(self, shower_parameters):
         """Simulate station events for a single shower"""
 
         station_events = []
         for station_id, station in enumerate(self.cluster.stations):
-            has_triggered, station_observables = \
-                self.simulate_station_response(station,
-                                               shower_parameters)
+            has_triggered, station_observables = self.simulate_station_response(station, shower_parameters)
             if has_triggered:
-                event_index = \
-                    self.store_station_observables(station_id,
-                                                   station_observables)
+                event_index = self.store_station_observables(station_id, station_observables)
                 station_events.append((station_id, event_index))
         return station_events
 
     def simulate_station_response(self, station, shower_parameters):
         """Simulate station response to a shower."""
 
-        detector_observables = self.simulate_all_detectors(
-            station.detectors, shower_parameters)
+        detector_observables = self.simulate_all_detectors(station.detectors, shower_parameters)
         has_triggered = self.simulate_trigger(detector_observables)
-        station_observables = \
-            self.process_detector_observables(detector_observables)
-        station_observables = self.simulate_gps(station_observables,
-                                                shower_parameters, station)
+        station_observables = self.process_detector_observables(detector_observables)
+        station_observables = self.simulate_gps(station_observables, shower_parameters, station)
 
         return has_triggered, station_observables
 
     def simulate_all_detectors(self, detectors, shower_parameters):
         """Simulate response of all detectors in a station.
 
         :param detectors: list of detectors
         :param shower_parameters: parameters of the shower
 
         """
         detector_observables = []
         for detector in detectors:
-            observables = self.simulate_detector_response(detector,
-                                                          shower_parameters)
+            observables = self.simulate_detector_response(detector, shower_parameters)
             detector_observables.append(observables)
 
         return detector_observables
 
     def simulate_detector_response(self, detector, shower_parameters):
         """Simulate detector response to a shower.
 
         :param detector: :class:`~sapphire.clusters.Detector` instance
         :param shower_parameters: shower parameters
         :return: dictionary with keys 'n' (number of particles in
             detector) and 't' (time of arrival of first detected particle).
 
         """
         # implement this!
-        observables = {'n': 0., 't': -999}
+        observables = {'n': 0.0, 't': -999}
 
         return observables
 
     def simulate_trigger(self, detector_observables):
         """Simulate a trigger response."""
 
         return True
@@ -175,16 +165,15 @@
 
         :param detector_observables: list of observables of the detectors
                                      making up a station.
         :return: dictionary containing the familiar station observables
                  like n1, n2, n3, etc.
 
         """
-        station_observables = {'pulseheights': 4 * [-1.],
-                               'integrals': 4 * [-1.]}
+        station_observables = {'pulseheights': 4 * [-1.0], 'integrals': 4 * [-1.0]}
 
         for detector_id, observables in enumerate(detector_observables, 1):
             for key, value in observables.items():
                 if key in ['n', 't']:
                     key = key + str(detector_id)
                     station_observables[key] = value
                 elif key in ['pulseheights', 'integrals']:
@@ -211,16 +200,15 @@
             else:
                 warnings.warn('Unsupported variable')
         row.append()
         events_table.flush()
 
         return events_table.nrows - 1
 
-    def store_coincidence(self, shower_id, shower_parameters,
-                          station_events):
+    def store_coincidence(self, shower_id, shower_parameters, station_events):
         """Store coincidence.
 
         Store the information to find events of different stations
         belonging to the same simulated shower in the coincidences
         tables.
 
         :param shower_id: The shower number for the coincidence id.
@@ -242,86 +230,78 @@
 
         timestamps = []
         for station_id, event_index in station_events:
             station = self.cluster.stations[station_id]
             row['s%d' % station.number] = True
             station_group = self.station_groups[station_id]
             event = station_group.events[event_index]
-            timestamps.append((event['ext_timestamp'], event['timestamp'],
-                               event['nanoseconds']))
+            timestamps.append((event['ext_timestamp'], event['timestamp'], event['nanoseconds']))
 
         try:
             first_timestamp = sorted(timestamps)[0]
         except IndexError:
             first_timestamp = (0, 0, 0)
 
-        row['ext_timestamp'], row['timestamp'], row['nanoseconds'] = \
-            first_timestamp
+        row['ext_timestamp'], row['timestamp'], row['nanoseconds'] = first_timestamp
         row.append()
         self.coincidences.flush()
 
         self.c_index.append(station_events)
         self.c_index.flush()
 
     def _prepare_coincidence_tables(self):
         """Create coincidence tables
 
         These are the same as the tables created by
         :class:`~sapphire.analysis.coincidences.CoincidencesESD`.
         This makes it easy to link events detected by multiple stations.
 
         """
-        self.coincidence_group = self.data.create_group(self.output_path,
-                                                        'coincidences',
-                                                        createparents=True)
+        self.coincidence_group = self.data.create_group(self.output_path, 'coincidences', createparents=True)
         try:
             self.coincidence_group._v_attrs.cluster = self.cluster
         except tables.HDF5ExtError:
             warnings.warn('Unable to store cluster object, to large for HDF.')
 
         description = storage.Coincidence
-        s_columns = {'s%d' % station.number: tables.BoolCol(pos=p)
-                     for p, station in enumerate(self.cluster.stations, 12)}
+        s_columns = {
+            's%d' % station.number: tables.BoolCol(pos=p) for p, station in enumerate(self.cluster.stations, 12)
+        }
         description.columns.update(s_columns)
 
-        self.coincidences = self.data.create_table(
-            self.coincidence_group, 'coincidences', description)
+        self.coincidences = self.data.create_table(self.coincidence_group, 'coincidences', description)
 
-        self.c_index = self.data.create_vlarray(
-            self.coincidence_group, 'c_index', tables.UInt32Col(shape=2))
+        self.c_index = self.data.create_vlarray(self.coincidence_group, 'c_index', tables.UInt32Col(shape=2))
 
-        self.s_index = self.data.create_vlarray(
-            self.coincidence_group, 's_index', tables.VLStringAtom())
+        self.s_index = self.data.create_vlarray(self.coincidence_group, 's_index', tables.VLStringAtom())
 
     def _prepare_station_tables(self):
         """Create the groups and events table to store the observables
 
         :param id: the station number, used for the group name
         :param station: a :class:`sapphire.clusters.Station` object
 
         """
-        self.cluster_group = self.data.create_group(self.output_path,
-                                                    'cluster_simulations',
-                                                    createparents=True)
+        self.cluster_group = self.data.create_group(self.output_path, 'cluster_simulations', createparents=True)
         self.station_groups = []
         for station in self.cluster.stations:
-            station_group = self.data.create_group(self.cluster_group,
-                                                   'station_%d' %
-                                                   station.number)
+            station_group = self.data.create_group(self.cluster_group, 'station_%d' % station.number)
             description = ProcessEvents.processed_events_description
-            self.data.create_table(station_group, 'events', description,
-                                   expectedrows=self.n)
+            self.data.create_table(station_group, 'events', description, expectedrows=self.n)
             self.station_groups.append(station_group)
 
     def _store_station_index(self):
         """Stores the references to the station groups for coincidences"""
 
         for station_group in self.station_groups:
             self.s_index.append(station_group._v_pathname.encode('utf-8'))
         self.s_index.flush()
 
     def __repr__(self):
         if not self.data.isopen:
-            return "<finished %s>" % self.__class__.__name__
-        return ('<%s, cluster: %r, data: %r, output_path: %r>' %
-                (self.__class__.__name__, self.cluster, self.data.filename,
-                 self.output_path))
+            return '<finished %s>' % self.__class__.__name__
+        return '<%s, cluster: %r, data: %r, output_path: %r>' % (
+            self.__class__.__name__,
+            self.cluster,
+            self.data.filename,
+            self.output_path,
+        )
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/simulations/detector.py` & `hisparc_sapphire-3.0.0/sapphire/simulations/detector.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 """Common HiSPARC station response simulations
 
 These are some common simulations for HiSPARC detectors.
 
 """
+
 import warnings
 
 from math import acos, cos, pi, sin, sqrt
 
 import numpy as np
 import tables
 
 from ..utils import ceil_in_base
 from .base import BaseSimulation
 
 
 class HiSPARCSimulation(BaseSimulation):
-
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
         self.simulate_and_store_offsets()
 
     def simulate_and_store_offsets(self):
         """Simulate and store station and detector offsets"""
@@ -99,20 +99,19 @@
 
         :param n: number of times to simulate
         :return: list of signal transport times
 
         """
         numbers = np.random.random(n)
         if n < 20:
-            dt = np.array([2.5507 + 2.39885 * number if number < 0.39377 else
-                           1.56764 + 4.89536 * number for number in numbers])
+            dt = np.array(
+                [2.5507 + 2.39885 * number if number < 0.39377 else 1.56764 + 4.89536 * number for number in numbers],
+            )
         else:
-            dt = np.where(numbers < 0.39377,
-                          2.5507 + 2.39885 * numbers,
-                          1.56764 + 4.89536 * numbers)
+            dt = np.where(numbers < 0.39377, 2.5507 + 2.39885 * numbers, 1.56764 + 4.89536 * numbers)
         return dt
 
     @classmethod
     def simulate_detector_mips(cls, n, theta):
         """Simulate the detector signal for particles
 
         Simulation of convoluted distribution of electron and
@@ -140,15 +139,15 @@
         :param theta: angle of incidence of the particles. Either a single
                       value valid for all particles, or an array with an angle
                       for each particle.
         :return: signal strength in number of mips.
 
         """
         # Limit cos theta to maximum length though the detector.
-        min_costheta = 2. / 112.
+        min_costheta = 2.0 / 112.0
         costheta = np.cos(theta)
         if isinstance(costheta, float):
             costheta = max(costheta, min_costheta)
         else:
             costheta[costheta < min_costheta] = min_costheta
 
         y = np.random.random(n)
@@ -163,21 +162,17 @@
             elif y < 0.9041:
                 mips = (1.7752 - 1.0336 * sqrt(0.9267 - y)) / costheta
             else:
                 mips = (2.28 - 2.1316 * sqrt(1 - y)) / costheta
             if not isinstance(costheta, float):
                 mips = sum(mips)
         else:
-            mips = np.where(y < 0.3394,
-                            (0.48 + 0.8583 * np.sqrt(y)) / costheta,
-                            (0.73 + 0.7366 * y) / costheta)
-            mips = np.where(y < 0.4344, mips,
-                            (1.7752 - 1.0336 * np.sqrt(0.9267 - y)) / costheta)
-            mips = np.where(y < 0.9041, mips,
-                            (2.28 - 2.1316 * np.sqrt(1 - y)) / costheta)
+            mips = np.where(y < 0.3394, (0.48 + 0.8583 * np.sqrt(y)) / costheta, (0.73 + 0.7366 * y) / costheta)
+            mips = np.where(y < 0.4344, mips, (1.7752 - 1.0336 * np.sqrt(0.9267 - y)) / costheta)
+            mips = np.where(y < 0.9041, mips, (2.28 - 2.1316 * np.sqrt(1 - y)) / costheta)
             mips = sum(mips)
         warnings.resetwarnings()
         return mips
 
     @classmethod
     def generate_core_position(cls, r_max):
         """Generate a random core position within a circle
@@ -189,22 +184,22 @@
         slow, because of an if-statement, and despite some optimizations
         suggested by HM).
 
         :param r: Maximum core distance, in meters.
         :return: Random x, y position in the disc with radius r_max.
 
         """
-        r = sqrt(np.random.uniform(0, r_max ** 2))
+        r = sqrt(np.random.uniform(0, r_max**2))
         phi = np.random.uniform(-pi, pi)
         x = r * cos(phi)
         y = r * sin(phi)
         return x, y
 
     @classmethod
-    def generate_zenith(cls, min=0, max=pi / 3.):
+    def generate_zenith(cls, min_value=0, max_value=pi / 3.0):
         """Generate a random zenith
 
         Generate a random zenith for a uniform distribution on a sphere.
         For a random position on a sphere the zenith should not be chosen
         from a uniform [0, pi/2] distribution.
 
         Source: http://mathworld.wolfram.com/SpherePointPicking.html
@@ -214,15 +209,15 @@
         the angle. CORSIKA simulated showers already contain the atmospheric
         attenuation and precise positions for each particle.
 
         :param min,max: minimum and maximum zenith angles, in radians.
         :return: random zenith position on a sphere, in radians.
 
         """
-        p = np.random.uniform(cos(max), cos(min))
+        p = np.random.uniform(cos(max_value), cos(min_value))
         return acos(p)
 
     @classmethod
     def generate_attenuated_zenith(cls):
         """Generate a random zenith
 
         Pick from the expected zenith distribution.
@@ -245,15 +240,15 @@
         Derrived from Schultheiss "The acceptancy of the HiSPARC Network",
         (internal note), eq 2.4 from Rossi.
 
         :param p: probability value between 0 and 1.
         :return: zenith with corresponding cumulative probability, in radians.
 
         """
-        return acos((1 - p) ** (1 / 8.))
+        return acos((1 - p) ** (1 / 8.0))
 
     @classmethod
     def generate_azimuth(cls):
         """Generate a random azimuth
 
         Showers from each azimuth have equal probability
 
@@ -273,48 +268,40 @@
 
         :param e_min,e_max: Energy bounds for the distribution (in eV).
         :param alpha: Steepness of the power law distribution.
         :return: primary particle energy, in eV.
 
         """
         x = np.random.random()
-        a1 = alpha + 1.
-        energy = (e_min ** a1 + x * (e_max ** a1 - e_min ** a1)) ** (1 / a1)
+        a1 = alpha + 1.0
+        energy = (e_min**a1 + x * (e_max**a1 - e_min**a1)) ** (1 / a1)
         return energy
 
 
 class ErrorlessSimulation(HiSPARCSimulation):
-
     @classmethod
     def simulate_detector_offsets(cls, n_detectors):
-
-        return [0.] * n_detectors
+        return [0.0] * n_detectors
 
     @classmethod
     def simulate_detector_offset(cls):
-
-        return 0.
+        return 0.0
 
     @classmethod
     def simulate_station_offset(cls):
-
-        return 0.
+        return 0.0
 
     @classmethod
     def simulate_gps_uncertainty(cls):
-
-        return 0.
+        return 0.0
 
     @classmethod
     def simulate_adc_sampling(cls, t):
-
         return t
 
     @classmethod
     def simulate_signal_transport_time(cls, n=1):
-
-        return np.array([0.] * n)
+        return np.array([0.0] * n)
 
     @classmethod
     def simulate_detector_mips(cls, n, theta):
-
         return n
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/simulations/gammas.py` & `hisparc_sapphire-3.0.0/sapphire/simulations/gammas.py`

 * *Files 18% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 """
 
 from random import expovariate
 
 import numpy as np
 
 SCINTILLATOR_THICKNESS = 2.0  # cm
-MAX_DEPTH = 112.  # longest straight path in scintillator in cm
+MAX_DEPTH = 112.0  # longest straight path in scintillator in cm
 ENERGY_LOSS = 2.0  # 2 MeV per cm
 MAX_E = ENERGY_LOSS * SCINTILLATOR_THICKNESS
 MIP = 3.38  # MeV
 
 ELECTRON_REST_MASS_MeV = 0.5109989  # MeV
 
 
@@ -43,22 +43,19 @@
     :return: transfered energy [MeV].
 
     """
     edge = compton_edge(gamma_energy)
     recoil_energies = np.linspace(0, edge, 1000)
 
     # electron energy distribution
-    electron_energy = [energy_transfer_cross_section(gamma_energy,
-                                                     recoil_energy)
-                       for recoil_energy in recoil_energies]
+    electron_energy = [energy_transfer_cross_section(gamma_energy, recoil_energy) for recoil_energy in recoil_energies]
 
     cumulative_energy = np.cumsum(electron_energy)
 
-    normalised_energy_distribution = (cumulative_energy /
-                                      cumulative_energy[-1])
+    normalised_energy_distribution = cumulative_energy / cumulative_energy[-1]
 
     r = np.random.random()
     conversion_factor = normalised_energy_distribution.searchsorted(r) / 1000
     return compton_edge(gamma_energy) * conversion_factor
 
 
 def energy_transfer_cross_section(gamma_energy, recoil_energy):
@@ -75,17 +72,20 @@
     """
     r_e = 2.82e-15  # classical electron radius [m]
 
     gamma = gamma_energy / ELECTRON_REST_MASS_MeV
 
     s = recoil_energy / gamma_energy
 
-    return (np.pi * (r_e ** 2) / (ELECTRON_REST_MASS_MeV * gamma ** 2) *
-            (2 + (s ** 2 / ((gamma ** 2) * ((1 - s) ** 2))) +
-            (s / (1 - s)) * (s - 2 / gamma)))
+    return (
+        np.pi
+        * (r_e**2)
+        / (ELECTRON_REST_MASS_MeV * gamma**2)
+        * (2 + (s**2 / ((gamma**2) * ((1 - s) ** 2))) + (s / (1 - s)) * (s - 2 / gamma))
+    )
 
 
 def max_energy_deposit_in_mips(depth, scintillator_depth):
     """Maximum energy transfer from electron to scintillator
 
     Determine maximum energy transfer based on remaining scinitillator
     depth.
@@ -110,45 +110,41 @@
     """
     # p [eV] and E [MeV]
     energies = p / 1e6
 
     mips = 0
     for energy, angle in zip(energies, theta):
         # project depth onto direction of incident particle
-        scintillator_depth = min(SCINTILLATOR_THICKNESS / np.cos(angle),
-                                 MAX_DEPTH)
+        scintillator_depth = min(SCINTILLATOR_THICKNESS / np.cos(angle), MAX_DEPTH)
 
         # Calculate interaction point in units of scinitlator depth.
         # If depth > 1 there is no interaction.
         depth_compton = expovariate(1 / compton_mean_free_path(energy))
         depth_pair = expovariate(1 / pair_mean_free_path(energy))
 
-        if ((depth_pair > scintillator_depth) &
-                (depth_compton > scintillator_depth)):
+        if (depth_pair > scintillator_depth) & (depth_compton > scintillator_depth):
             # no interaction
             continue
 
         # Interactions in scintillator
         elif depth_compton < depth_pair:
             # Compton scattering
 
             # kinetic energy transfered to electron by compton scattering
             energy_deposit = compton_energy_transfer(energy) / MIP
-            max_deposit = max_energy_deposit_in_mips(depth_compton,
-                                                     scintillator_depth)
+            max_deposit = max_energy_deposit_in_mips(depth_compton, scintillator_depth)
             mips += min(max_deposit, energy_deposit)
 
         elif energy > 1.022:
             # Pair production: Two "electrons"
 
             # 1.022 MeV used for creation of two particles
             # all the rest is electron kinetic energy
             energy_deposit = (energy - 1.022) / MIP
-            max_deposit = max_energy_deposit_in_mips(depth_pair,
-                                                     scintillator_depth)
+            max_deposit = max_energy_deposit_in_mips(depth_pair, scintillator_depth)
             mips += min(max_deposit, energy_deposit)
 
     return mips
 
 
 def pair_mean_free_path(gamma_energy):
     """Mean free path pair production
@@ -159,32 +155,67 @@
 
     table generated by @tomkooij/lio-project/photons/nist.py
 
     :param gamma_energy: photon energy [MeV].
     :return: mean free path [cm].
 
     """
-    energy_path_pair_production = np.array([
-        (4, 689.31), (5, 504.52), (6, 404.96),
-        (7, 343.56), (8, 302.00), (9, 271.84),
-        (10, 249.03), (11, 231.28), (12, 217.04),
-        (13, 205.23), (14, 195.32), (15, 186.88),
-        (16, 179.47), (18, 167.40), (20, 157.85),
-        (22, 149.97), (24, 143.51), (26, 138.00),
-        (28, 133.30), (30, 129.20), (40, 114.65),
-        (50, 105.64), (60, 99.37), (80, 91.17),
-        (100, 85.90), (150, 78.25), (200, 74.07),
-        (300, 69.44), (400, 66.93), (500, 65.34),
-        (600, 64.21), (800, 62.73), (1000, 61.82),
-        (1500, 60.47), (2000, 59.72), (3000, 58.97),
-        (4000, 58.53), (5000, 58.28), (6000, 58.09),
-        (8000, 57.85), (10000, 57.70), (15000, 57.51),
-        (20000, 57.41), (30000, 57.27), (40000, 57.21),
-        (50000, 57.17), (60000, 57.13), (80000, 57.12),
-        (100000, 57.08)])
+    energy_path_pair_production = np.array(
+        [
+            (4, 689.31),
+            (5, 504.52),
+            (6, 404.96),
+            (7, 343.56),
+            (8, 302.00),
+            (9, 271.84),
+            (10, 249.03),
+            (11, 231.28),
+            (12, 217.04),
+            (13, 205.23),
+            (14, 195.32),
+            (15, 186.88),
+            (16, 179.47),
+            (18, 167.40),
+            (20, 157.85),
+            (22, 149.97),
+            (24, 143.51),
+            (26, 138.00),
+            (28, 133.30),
+            (30, 129.20),
+            (40, 114.65),
+            (50, 105.64),
+            (60, 99.37),
+            (80, 91.17),
+            (100, 85.90),
+            (150, 78.25),
+            (200, 74.07),
+            (300, 69.44),
+            (400, 66.93),
+            (500, 65.34),
+            (600, 64.21),
+            (800, 62.73),
+            (1000, 61.82),
+            (1500, 60.47),
+            (2000, 59.72),
+            (3000, 58.97),
+            (4000, 58.53),
+            (5000, 58.28),
+            (6000, 58.09),
+            (8000, 57.85),
+            (10000, 57.70),
+            (15000, 57.51),
+            (20000, 57.41),
+            (30000, 57.27),
+            (40000, 57.21),
+            (50000, 57.17),
+            (60000, 57.13),
+            (80000, 57.12),
+            (100000, 57.08),
+        ],
+    )
 
     gamma_energies = energy_path_pair_production[:, 0]
     mean_free_paths = energy_path_pair_production[:, 1]
 
     idx = gamma_energies.searchsorted(gamma_energy, side='left')
     return mean_free_paths[idx]
 
@@ -198,31 +229,66 @@
 
     table generated by @tomkooij/lio-project/photons/nist.py
 
     :param gamma_energy: photon energy [MeV].
     :return: mean free path [cm].
 
     """
-    energy_path_compton_scattering = np.array([
-        (4, 31.88), (5, 36.90), (6, 41.75),
-        (7, 46.47), (8, 51.05), (9, 55.52),
-        (10, 59.95), (11, 64.27), (12, 68.54),
-        (13, 72.73), (14, 76.86), (15, 80.97),
-        (16, 85.03), (18, 93.02), (20, 100.92),
-        (22, 108.60), (24, 116.23), (26, 123.81),
-        (28, 131.23), (30, 138.64), (40, 174.40),
-        (50, 208.94), (60, 242.54), (80, 307.50),
-        (100, 370.51), (150, 520.29), (200, 663.57),
-        (300, 936.33), (400, 1195.46), (500, 1444.04),
-        (600, 1686.34), (800, 2159.36), (1000, 2624.67),
-        (1500, 3757.99), (2000, 4856.73), (3000, 6983.24),
-        (4000, 9049.77), (5000, 11063.17), (6000, 13048.02),
-        (8000, 16940.54), (10000, 20746.89), (15000, 30021.01),
-        (20000, 39047.25), (30000, 56625.14), (40000, 73746.31),
-        (50000, 90579.71), (60000, 107146.68), (80000, 139684.31),
-        (100000, 171791.79)])
+    energy_path_compton_scattering = np.array(
+        [
+            (4, 31.88),
+            (5, 36.90),
+            (6, 41.75),
+            (7, 46.47),
+            (8, 51.05),
+            (9, 55.52),
+            (10, 59.95),
+            (11, 64.27),
+            (12, 68.54),
+            (13, 72.73),
+            (14, 76.86),
+            (15, 80.97),
+            (16, 85.03),
+            (18, 93.02),
+            (20, 100.92),
+            (22, 108.60),
+            (24, 116.23),
+            (26, 123.81),
+            (28, 131.23),
+            (30, 138.64),
+            (40, 174.40),
+            (50, 208.94),
+            (60, 242.54),
+            (80, 307.50),
+            (100, 370.51),
+            (150, 520.29),
+            (200, 663.57),
+            (300, 936.33),
+            (400, 1195.46),
+            (500, 1444.04),
+            (600, 1686.34),
+            (800, 2159.36),
+            (1000, 2624.67),
+            (1500, 3757.99),
+            (2000, 4856.73),
+            (3000, 6983.24),
+            (4000, 9049.77),
+            (5000, 11063.17),
+            (6000, 13048.02),
+            (8000, 16940.54),
+            (10000, 20746.89),
+            (15000, 30021.01),
+            (20000, 39047.25),
+            (30000, 56625.14),
+            (40000, 73746.31),
+            (50000, 90579.71),
+            (60000, 107146.68),
+            (80000, 139684.31),
+            (100000, 171791.79),
+        ],
+    )
 
     gamma_energies = energy_path_compton_scattering[:, 0]
     mean_free_paths = energy_path_compton_scattering[:, 1]
 
     idx = gamma_energies.searchsorted(gamma_energy, side='left')
     return mean_free_paths[idx]
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/simulations/groundparticles.py` & `hisparc_sapphire-3.0.0/sapphire/simulations/groundparticles.py`

 * *Files 2% similar despite different names*

```diff
@@ -25,15 +25,14 @@
 from ..corsika.corsika_queries import CorsikaQuery
 from ..utils import c, closest_in_list, norm_angle, pbar, vector_length
 from .detector import ErrorlessSimulation, HiSPARCSimulation
 from .gammas import simulate_detector_mips_gammas
 
 
 class GroundParticlesSimulation(HiSPARCSimulation):
-
     def __init__(self, corsikafile_path, max_core_distance, *args, **kwargs):
         """Simulation initialization
 
         :param corsikafile_path: path to the corsika.h5 file containing
                                  the groundparticles.
         :param max_core_distance: maximum distance of shower core to
                                   center of cluster.
@@ -66,28 +65,28 @@
 
         """
         r_max = self.max_core_distance
         now = int(time())
 
         event_header = self.corsikafile.get_node_attr('/', 'event_header')
         event_end = self.corsikafile.get_node_attr('/', 'event_end')
-        corsika_parameters = {'zenith': event_header.zenith,
-                              'size': event_end.n_electrons_levels,
-                              'energy': event_header.energy,
-                              'particle': event_header.particle}
+        corsika_parameters = {
+            'zenith': event_header.zenith,
+            'size': event_end.n_electrons_levels,
+            'energy': event_header.energy,
+            'particle': event_header.particle,
+        }
         self.corsika_azimuth = event_header.azimuth
 
         for i in pbar(range(self.n), show=self.progress):
             ext_timestamp = (now + i) * 1_000_000_000
             x, y = self.generate_core_position(r_max)
             shower_azimuth = self.generate_azimuth()
 
-            shower_parameters = {'ext_timestamp': ext_timestamp,
-                                 'core_pos': (x, y),
-                                 'azimuth': shower_azimuth}
+            shower_parameters = {'ext_timestamp': ext_timestamp, 'core_pos': (x, y), 'azimuth': shower_azimuth}
 
             # Subtract CORSIKA shower azimuth from desired shower azimuth
             # make it fit in (-pi, pi] to get rotation angle of the cluster.
             alpha = shower_azimuth - self.corsika_azimuth
             alpha = norm_angle(alpha)
             self._prepare_cluster_for_shower(x, y, alpha)
 
@@ -128,32 +127,29 @@
 
         if n_detected:
             mips = self.simulate_detector_mips_for_particles(particles)
             particles['t'] += self.simulate_signal_transport_time(n_detected)
             nz = cos(shower_parameters['zenith'])
             tproj = detector.get_coordinates()[-1] / (c * nz)
             first_signal = particles['t'].min() + detector.offset - tproj
-            observables = {'n': round(mips, 3),
-                           't': self.simulate_adc_sampling(first_signal)}
+            observables = {'n': round(mips, 3), 't': self.simulate_adc_sampling(first_signal)}
         else:
-            observables = {'n': 0., 't': -999}
+            observables = {'n': 0.0, 't': -999}
 
         return observables
 
     def simulate_detector_mips_for_particles(self, particles):
         """Simulate the detector signal for particles
 
         :param particles: particle rows with the p_[x, y, z]
                           components of the particle momenta.
 
         """
         # determination of lepton angle of incidence
-        theta = np.arccos(abs(particles['p_z']) /
-                          vector_length(particles['p_x'], particles['p_y'],
-                                        particles['p_z']))
+        theta = np.arccos(abs(particles['p_z']) / vector_length(particles['p_x'], particles['p_y'], particles['p_z']))
         n = len(particles)
         mips = self.simulate_detector_mips(n, theta)
 
         return mips
 
     def simulate_trigger(self, detector_observables):
         """Simulate a trigger response.
@@ -164,59 +160,53 @@
 
         :param detector_observables: list of dictionaries, each containing
                                      the observables of one detector.
         :return: True if the station triggers, False otherwise.
 
         """
         n_detectors = len(detector_observables)
-        detectors_low = sum(
-            True for observables in detector_observables
-            if observables['n'] > 0.3
-        )
-        detectors_high = sum(
-            True for observables in detector_observables
-            if observables['n'] > 0.5
-        )
+        detectors_low = sum(True for observables in detector_observables if observables['n'] > 0.3)
+        detectors_high = sum(True for observables in detector_observables if observables['n'] > 0.5)
 
-        if n_detectors == 4 and (detectors_high >= 2 or detectors_low >= 3):
-            return True
-        elif n_detectors == 2 and detectors_low >= 2:
-            return True
-        else:
-            return False
+        return (
+            n_detectors == 4 and (detectors_high >= 2 or detectors_low >= 3) or n_detectors == 2 and detectors_low >= 2
+        )
 
     def simulate_gps(self, station_observables, shower_parameters, station):
         """Simulate gps timestamp.
 
         :param station_observables: dictionary containing the observables
                                     of the station.
         :param shower_parameters: dictionary with the shower parameters.
         :param station: :class:`sapphire.clusters.Station` for which
                          to simulate the gps timestamp.
         :return: station_observables updated with gps timestamp and
                  trigger time.
 
         """
-        arrival_times = [station_observables['t%d' % id]
-                         for id in range(1, 5)
-                         if station_observables.get('n%d' % id, -1) > 0]
+        arrival_times = [
+            station_observables[f't{detector_id}']
+            for detector_id in range(1, 5)
+            if station_observables.get(f'n{detector_id}', -1) > 0
+        ]
 
         if len(arrival_times) > 1:
             trigger_time = sorted(arrival_times)[1]
 
             ext_timestamp = shower_parameters['ext_timestamp']
-            ext_timestamp += int(trigger_time + station.gps_offset +
-                                 self.simulate_gps_uncertainty())
+            ext_timestamp += int(trigger_time + station.gps_offset + self.simulate_gps_uncertainty())
             timestamp = int(ext_timestamp / 1_000_000_000)
             nanoseconds = int(ext_timestamp % 1_000_000_000)
 
-            gps_timestamp = {'ext_timestamp': ext_timestamp,
-                             'timestamp': timestamp,
-                             'nanoseconds': nanoseconds,
-                             't_trigger': trigger_time}
+            gps_timestamp = {
+                'ext_timestamp': ext_timestamp,
+                'timestamp': timestamp,
+                'nanoseconds': nanoseconds,
+                't_trigger': trigger_time,
+            }
             station_observables.update(gps_timestamp)
 
         return station_observables
 
     def get_particles_in_detector(self, detector, shower_parameters):
         """Get particles that hit a detector.
 
@@ -234,29 +224,31 @@
         simulation frame the CORSIKA shower azimuth remains unchanged.
 
         :param detector: :class:`~sapphire.clusters.Detector` for which
                          to get particles.
         :param shower_parameters: dictionary with the shower parameters.
 
         """
-        detector_boundary = sqrt(0.5) / 2.
+        detector_boundary = sqrt(0.5) / 2.0
 
         x, y, z = detector.get_coordinates()
         zenith = shower_parameters['zenith']
         azimuth = self.corsika_azimuth
 
         nxnz = tan(zenith) * cos(azimuth)
         nynz = tan(zenith) * sin(azimuth)
         xproj = x - z * nxnz
         yproj = y - z * nynz
 
-        query = ('(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f)'
-                 ' & (particle_id >= 2) & (particle_id <= 6)' %
-                 (xproj - detector_boundary, xproj + detector_boundary,
-                  yproj - detector_boundary, yproj + detector_boundary))
+        query = '(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f) & (particle_id >= 2) & (particle_id <= 6)' % (
+            xproj - detector_boundary,
+            xproj + detector_boundary,
+            yproj - detector_boundary,
+            yproj + detector_boundary,
+        )
         return self.groundparticles.read_where(query)
 
 
 class GroundParticlesGammaSimulation(GroundParticlesSimulation):
     """Simulation which includes signals from gamma particles in the shower"""
 
     def simulate_detector_response(self, detector, shower_parameters):
@@ -267,16 +259,15 @@
         particle passing the detector.
 
         :param detector: :class:`~sapphire.clusters.Detector` for which
                          the observables will be determined.
         :param shower_parameters: dictionary with the shower parameters.
 
         """
-        leptons, gammas = self.get_particles_in_detector(detector,
-                                                         shower_parameters)
+        leptons, gammas = self.get_particles_in_detector(detector, shower_parameters)
         n_leptons = len(leptons)
         n_gammas = len(gammas)
 
         if not n_leptons + n_gammas:
             return {'n': 0, 't': -999}
 
         if n_leptons:
@@ -296,16 +287,15 @@
         if n_leptons and n_gammas:
             first_signal = min(first_lepton, first_gamma) + detector.offset
         elif n_leptons:
             first_signal = first_lepton + detector.offset
         elif n_gammas:
             first_signal = first_gamma + detector.offset
 
-        return {'n': mips_lepton + mips_gamma,
-                't': self.simulate_adc_sampling(first_signal)}
+        return {'n': mips_lepton + mips_gamma, 't': self.simulate_adc_sampling(first_signal)}
 
     def get_particles_in_detector(self, detector, shower_parameters):
         """Get particles that hit a detector.
 
         Particle ids 2, 3, 5, 6 are electrons and muons,
         id 4 is no longer used (were neutrino's).
 
@@ -317,61 +307,59 @@
         *Detector height is ignored!*
 
         :param detector: :class:`~sapphire.clusters.Detector` for which
                          to get particles.
         :param shower_parameters: dictionary with the shower parameters.
 
         """
-        detector_boundary = sqrt(.5) / 2.
+        detector_boundary = sqrt(0.5) / 2.0
 
         x, y, z = detector.get_coordinates()
         zenith = shower_parameters['zenith']
         azimuth = self.corsika_azimuth
 
         nxnz = tan(zenith) * cos(azimuth)
         nynz = tan(zenith) * sin(azimuth)
         xproj = x - z * nxnz
         yproj = y - z * nynz
 
-        query_leptons = \
-            ('(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f)'
-             ' & (particle_id >= 2) & (particle_id <= 6)' %
-             (xproj - detector_boundary, xproj + detector_boundary,
-              yproj - detector_boundary, yproj + detector_boundary))
-
-        query_gammas = \
-            ('(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f)'
-             ' & (particle_id == 1)' %
-             (xproj - detector_boundary, xproj + detector_boundary,
-              yproj - detector_boundary, yproj + detector_boundary))
+        query_leptons = '(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f) & (particle_id >= 2) & (particle_id <= 6)' % (
+            xproj - detector_boundary,
+            xproj + detector_boundary,
+            yproj - detector_boundary,
+            yproj + detector_boundary,
+        )
+
+        query_gammas = '(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f) & (particle_id == 1)' % (
+            xproj - detector_boundary,
+            xproj + detector_boundary,
+            yproj - detector_boundary,
+            yproj + detector_boundary,
+        )
 
-        return (self.groundparticles.read_where(query_leptons),
-                self.groundparticles.read_where(query_gammas))
+        return (self.groundparticles.read_where(query_leptons), self.groundparticles.read_where(query_gammas))
 
     def simulate_detector_mips_for_gammas(self, particles):
         """Simulate the detector signal for gammas
 
         :param particles: particle rows with the p_[x, y, z]
                           components of the particle momenta.
 
         """
-        p_gamma = np.sqrt(particles['p_x'] ** 2 + particles['p_y'] ** 2 +
-                          particles['p_z'] ** 2)
+        p_gamma = np.sqrt(particles['p_x'] ** 2 + particles['p_y'] ** 2 + particles['p_z'] ** 2)
 
         # determination of lepton angle of incidence
-        theta = np.arccos(abs(particles['p_z']) /
-                          p_gamma)
+        theta = np.arccos(abs(particles['p_z']) / p_gamma)
 
         mips = simulate_detector_mips_gammas(p_gamma, theta)
 
         return mips
 
 
 class DetectorBoundarySimulation(GroundParticlesSimulation):
-
     """More accuratly simulate the detection area of the detectors.
 
     Take the orientation of the detectors into account and use the
     exact detector boundaries. This requires a slightly more complex
     query which is a bit slower.
 
     """
@@ -403,20 +391,29 @@
         xproj = x - znxnz
         yproj = y - znynz
 
         cproj = [(cx - znxnz, cy - znynz) for cx, cy in corners]
 
         b11, line1, b12 = self.get_line_boundary_eqs(*cproj[0:3])
         b21, line2, b22 = self.get_line_boundary_eqs(*cproj[1:4])
-        query = ("(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f) & "
-                 "(b11 < %s) & (%s < b12) & (b21 < %s) & (%s < b22) & "
-                 "(particle_id >= 2) & (particle_id <= 6)" %
-                 (xproj - detector_boundary, xproj + detector_boundary,
-                  yproj - detector_boundary, yproj + detector_boundary,
-                  line1, line1, line2, line2))
+        query = (
+            '(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f) & '
+            '(b11 < %s) & (%s < b12) & (b21 < %s) & (%s < b22) & '
+            '(particle_id >= 2) & (particle_id <= 6)'
+            % (
+                xproj - detector_boundary,
+                xproj + detector_boundary,
+                yproj - detector_boundary,
+                yproj + detector_boundary,
+                line1,
+                line1,
+                line2,
+                line2,
+            )
+        )
 
         return self.groundparticles.read_where(query)
 
     def get_line_boundary_eqs(self, p0, p1, p2):
         """Get line equations using three points
 
         Given three points, this function computes the equations for two
@@ -438,45 +435,43 @@
 
         """
         (x0, y0), (x1, y1), (x2, y2) = p0, p1, p2
 
         # Compute the general equation for the lines
         if x0 == x1:
             # line is exactly vertical
-            line = "x"
+            line = 'x'
             b1, b2 = x0, x2
         else:
             # First, compute the slope
             a = (y1 - y0) / (x1 - x0)
 
             # Calculate the y-intercepts of both lines
             b1 = y0 - a * x0
             b2 = y2 - a * x2
 
-            line = "y - %f * x" % a
+            line = 'y - %f * x' % a
 
         # And order the y-intercepts
         if b1 > b2:
             b1, b2 = b2, b1
 
         return b1, line, b2
 
 
 class ParticleCounterSimulation(GroundParticlesSimulation):
-
     """Do not simulate mips, just count the number of particles."""
 
     def simulate_detector_mips(self, n, theta):
         """A mip for a mip, count number of particles in a detector."""
 
         return n
 
 
 class FixedCoreDistanceSimulation(GroundParticlesSimulation):
-
     """Shower core at a fixed core distance (from cluster origin).
 
     :param core_distance: distance of shower core to center of cluster.
 
     """
 
     @classmethod
@@ -489,29 +484,24 @@
         """
         phi = np.random.uniform(-pi, pi)
         x = r_max * cos(phi)
         y = r_max * sin(phi)
         return x, y
 
 
-class GroundParticlesSimulationWithoutErrors(ErrorlessSimulation,
-                                             GroundParticlesSimulation):
-
+class GroundParticlesSimulationWithoutErrors(ErrorlessSimulation, GroundParticlesSimulation):
     """This simulation does not simulate errors/uncertainties
 
     This results in perfect timing (first particle through detector)
     and particle counting for the detectors.
 
     """
 
-    pass
-
 
 class MultipleGroundParticlesSimulation(GroundParticlesSimulation):
-
     """Use multiple CORSIKA simulated air showers in one run.
 
     Simulations will be selected from the set of available showers.
     Each time an energy and zenith angle is generated a shower is selected
     from the CORSIKA overview. Each shower is reused multiple times to
     take advantage of caching, and to reduce IO stress.
 
@@ -522,16 +512,15 @@
         of these simulations simultaneously!
 
     """
 
     # CORSIKA data location at Nikhef
     DATA = '/data/hisparc/corsika/data/{seeds}/corsika.h5'
 
-    def __init__(self, corsikaoverview_path, max_core_distance, min_energy,
-                 max_energy, *args, **kwargs):
+    def __init__(self, corsikaoverview_path, max_core_distance, min_energy, max_energy, *args, **kwargs):
         """Simulation initialization
 
         :param corsikaoverview_path: path to the corsika_overview.h5 file
                                      containing the available simulations.
         :param max_core_distance: maximum distance of shower core to
                                   center of cluster.
         :param min_energy,max_energy: upper and lower shower energy limits,
@@ -541,19 +530,16 @@
         # Super of the super class.
         super(GroundParticlesSimulation, self).__init__(*args, **kwargs)
 
         self.cq = CorsikaQuery(corsikaoverview_path)
         self.max_core_distance = max_core_distance
         self.min_energy = min_energy
         self.max_energy = max_energy
-        self.available_energies = {e for e in self.cq.all_energies
-                                   if min_energy <= 10 ** e <= max_energy}
-        self.available_zeniths = {e: self.cq.available_parameters('zenith',
-                                                                  energy=e)
-                                  for e in self.available_energies}
+        self.available_energies = {e for e in self.cq.all_energies if min_energy <= 10**e <= max_energy}
+        self.available_zeniths = {e: self.cq.available_parameters('zenith', energy=e) for e in self.available_energies}
 
     def finish(self):
         """Clean-up after simulation"""
 
         self.cq.finish()
 
     def generate_shower_parameters(self):
@@ -573,18 +559,20 @@
         now = int(time())
 
         for i in pbar(range(self.n), show=self.progress):
             sim = self.select_simulation()
             if sim is None:
                 continue
 
-            corsika_parameters = {'zenith': sim['zenith'],
-                                  'size': sim['n_electron'],
-                                  'energy': sim['energy'],
-                                  'particle': sim['particle_id']}
+            corsika_parameters = {
+                'zenith': sim['zenith'],
+                'size': sim['n_electron'],
+                'energy': sim['energy'],
+                'particle': sim['particle_id'],
+            }
             self.corsika_azimuth = sim['azimuth']
 
             seeds = self.cq.seeds([sim])[0]
             with tables.open_file(self.DATA.format(seeds=seeds), 'r') as data:
                 try:
                     self.groundparticles = data.get_node('/groundparticles')
                 except tables.NoSuchNodeError:
@@ -592,17 +580,15 @@
                     continue
 
                 for j in range(n_reuse):
                     ext_timestamp = (now + i + (float(j) / n_reuse)) * 1_000_000_000
                     x, y = self.generate_core_position(r)
                     shower_azimuth = self.generate_azimuth()
 
-                    shower_parameters = {'ext_timestamp': ext_timestamp,
-                                         'core_pos': (x, y),
-                                         'azimuth': shower_azimuth}
+                    shower_parameters = {'ext_timestamp': ext_timestamp, 'core_pos': (x, y), 'azimuth': shower_azimuth}
 
                     # Subtract CORSIKA shower azimuth from desired shower
                     # azimuth to get rotation angle of the cluster.
                     alpha = shower_azimuth - self.corsika_azimuth
                     alpha = norm_angle(alpha)
                     self._prepare_cluster_for_shower(x, y, alpha)
 
@@ -615,15 +601,14 @@
         :return: simulation row from a CORSIKA Simulations table.
 
         """
         energy = self.generate_energy(self.min_energy, self.max_energy)
         shower_energy = closest_in_list(log10(energy), self.available_energies)
 
         zenith = self.generate_zenith()
-        shower_zenith = closest_in_list(np.degrees(zenith),
-                                        self.available_zeniths[shower_energy])
+        shower_zenith = closest_in_list(np.degrees(zenith), self.available_zeniths[shower_energy])
 
         sims = self.cq.simulations(energy=shower_energy, zenith=shower_zenith)
         if not len(sims):
             return None
         sim = np.random.choice(sims)
         return sim
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/simulations/ldf.py` & `hisparc_sapphire-3.0.0/sapphire/simulations/ldf.py`

 * *Files 4% similar despite different names*

```diff
@@ -13,27 +13,26 @@
 
     >>> sim = NkgLdfSimulation(max_core_distance=400, min_energy=1e15,
     ...                        max_energy=1e21, cluster=cluster,
     ...                        datafile=data, n=200)
     >>> sim.run()
 
 """
+
 import warnings
 
 from numpy import arctan2, cos, log10, pi, random, sin, sqrt
 from scipy.special import gamma
 
 from ..utils import pbar, vector_length
 from .detector import ErrorlessSimulation, HiSPARCSimulation
 
 
 class BaseLdfSimulation(HiSPARCSimulation):
-
-    def __init__(self, max_core_distance, min_energy, max_energy, *args,
-                 **kwargs):
+    def __init__(self, max_core_distance, min_energy, max_energy, *args, **kwargs):
         """Simulation initialization
 
         :param max_core_distance: maximum distance of shower core to
                                   center of cluster (in meters).
         :param min_energy,max_energy: Minimum and maximum energy of the
                                       shower (in eV).
 
@@ -62,42 +61,43 @@
         """
         r = self.max_core_distance
         giga = 1_000_000_000
 
         for i in pbar(range(self.n), show=self.progress):
             energy = self.generate_energy(self.min_energy, self.max_energy)
             size = 10 ** (log10(energy) - 15 + 4.8)
-            shower_parameters = {'ext_timestamp': (giga + i) * giga,
-                                 'azimuth': self.generate_azimuth(),
-                                 'zenith': 0.,
-                                 'core_pos': self.generate_core_position(r),
-                                 'size': size,
-                                 'energy': energy}
+            shower_parameters = {
+                'ext_timestamp': (giga + i) * giga,
+                'azimuth': self.generate_azimuth(),
+                'zenith': 0.0,
+                'core_pos': self.generate_core_position(r),
+                'size': size,
+                'energy': energy,
+            }
 
             yield shower_parameters
 
     def simulate_detector_response(self, detector, shower_parameters):
         """Simulate detector response to a shower
 
         Get the mips in a detector from the LDF.
 
         :param detector: :class:`~sapphire.clusters.Detector` for which
                          the observables will be determined.
         :param shower_parameters: dictionary with the shower parameters.
 
         """
-        n_detected = self.get_num_particles_in_detector(detector,
-                                                        shower_parameters)
+        n_detected = self.get_num_particles_in_detector(detector, shower_parameters)
         theta = shower_parameters['zenith']
 
         if n_detected:
             mips = self.simulate_detector_mips(n_detected, theta)
             observables = {'n': mips}
         else:
-            observables = {'n': 0.}
+            observables = {'n': 0.0}
         return observables
 
     def get_num_particles_in_detector(self, detector, shower_parameters):
         """Get the number of particles in a detector
 
         :param detector: :class:`~sapphire.clusters.Detector` for which
                          the number of particles will be determined.
@@ -106,21 +106,19 @@
         """
         x, y = detector.xy_coordinates
         core_x, core_y = shower_parameters['core_pos']
         zenith = shower_parameters['zenith']
         azimuth = shower_parameters['azimuth']
         size = shower_parameters['size']
 
-        r = self.ldf.calculate_core_distance(x, y, core_x, core_y, zenith,
-                                             azimuth)
+        r = self.ldf.calculate_core_distance(x, y, core_x, core_y, zenith, azimuth)
 
         p_shower = self.ldf.calculate_ldf_value(r, n_electrons=size)
         p_ground = p_shower * cos(zenith)
-        num_particles = self.simulate_particles_for_density(
-            p_ground * detector.get_area())
+        num_particles = self.simulate_particles_for_density(p_ground * detector.get_area())
 
         return num_particles
 
     @staticmethod
     def simulate_particles_for_density(p):
         """Get number of particles in detector given a particle density
 
@@ -128,66 +126,54 @@
         :return: random number from Poisson distribution.
 
         """
         return random.poisson(p)
 
 
 class BaseLdfSimulationWithoutErrors(ErrorlessSimulation, BaseLdfSimulation):
-
     """This simulation does not simulate errors/uncertainties
 
     This should result in perfect particle counting for the detectors.
 
     """
 
     @staticmethod
     def simulate_particles_for_density(p):
         """Exact number"""
 
         return p
 
 
 class NkgLdfSimulation(BaseLdfSimulation):
-
     """Same as the BaseLdfSimulation but uses the NkgLdf as LDF"""
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
         self.ldf = NkgLdf()
 
 
-class NkgLdfSimulationWithoutErrors(NkgLdfSimulation,
-                                    BaseLdfSimulationWithoutErrors):
-
+class NkgLdfSimulationWithoutErrors(NkgLdfSimulation, BaseLdfSimulationWithoutErrors):
     """Same as the NkgLdfSimulation but without error simulation"""
 
-    pass
-
 
 class KascadeLdfSimulation(BaseLdfSimulation):
-
     """Same as the BaseLdfSimulation but uses the KascadeLdf as LDF"""
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
         self.ldf = KascadeLdf()
 
 
-class KascadeLdfSimulationWithoutErrors(KascadeLdfSimulation,
-                                        BaseLdfSimulationWithoutErrors):
-
+class KascadeLdfSimulationWithoutErrors(KascadeLdfSimulation, BaseLdfSimulationWithoutErrors):
     """Same as the KascadeLdfSimulation but without error simulation"""
 
-    pass
-
 
 class EllipsLdfSimulation(BaseLdfSimulation):
-
     """Same as BaseLdfSimulation but uses the EllipsLdF as LDF"""
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
         self.ldf = EllipsLdf()
 
@@ -203,20 +189,22 @@
         """
         r = self.max_core_distance
         giga = 1_000_000_000
 
         for i in pbar(range(self.n), show=self.progress):
             energy = self.generate_energy(self.min_energy, self.max_energy)
             size = 10 ** (log10(energy) - 15 + 4.8)
-            shower_parameters = {'ext_timestamp': (giga + i) * giga,
-                                 'azimuth': self.generate_azimuth(),
-                                 'zenith': self.generate_zenith(),
-                                 'core_pos': self.generate_core_position(r),
-                                 'size': size,
-                                 'energy': energy}
+            shower_parameters = {
+                'ext_timestamp': (giga + i) * giga,
+                'azimuth': self.generate_azimuth(),
+                'zenith': self.generate_zenith(),
+                'core_pos': self.generate_core_position(r),
+                'size': size,
+                'energy': energy,
+            }
 
             yield shower_parameters
 
     def get_num_particles_in_detector(self, detector, shower_parameters):
         """Get the number of particles in a detector
 
         :param detector: :class:`~sapphire.clusters.Detector` for which
@@ -226,34 +214,31 @@
         """
         x, y = detector.xy_coordinates
         core_x, core_y = shower_parameters['core_pos']
         zenith = shower_parameters['zenith']
         azimuth = shower_parameters['azimuth']
         size = shower_parameters['size']
 
-        r, phi = self.ldf.calculate_core_distance_and_angle(x, y, core_x,
-                                                            core_y)
+        r, phi = self.ldf.calculate_core_distance_and_angle(x, y, core_x, core_y)
 
         p_ground = self.ldf.calculate_ldf_value(r, phi, size, zenith, azimuth)
-        num_particles = self.simulate_particles_for_density(
-            p_ground * detector.get_area())
+        num_particles = self.simulate_particles_for_density(p_ground * detector.get_area())
 
         return num_particles
 
 
 class BaseLdf:
-
     """Base LDF class
 
     No particles! Always returns a particle density of 0.
 
     """
 
     def calculate_ldf_value(self, r, n_electrons=None, s=None):
-        return 0.
+        return 0.0
 
     def calculate_core_distance(self, x, y, x0, y0, theta, phi):
         """Calculate core distance
 
         The core distance is the distance of the detector to the shower core,
         measured *on the shower front*.  For derivations, see logbook.
 
@@ -263,27 +248,25 @@
         :return: distance from detector to the shower core in shower
                  front plane in m.
 
         """
         x = x - x0
         y = y - y0
 
-        return sqrt(x ** 2 + y ** 2 -
-                    (x * cos(phi) + y * sin(phi)) ** 2 * sin(theta) ** 2)
+        return sqrt(x**2 + y**2 - (x * cos(phi) + y * sin(phi)) ** 2 * sin(theta) ** 2)
 
 
 class NkgLdf(BaseLdf):
-
     """The Nishimura-Kamata-Greisen function"""
 
     # shower parameters
     # Age parameter and Moliere radius from Thoudam2012 sec 5.6.
-    _n_electrons = 10 ** 4.8
+    _n_electrons = 10**4.8
     _s = 1.7
-    _r0 = 30.
+    _r0 = 30.0
 
     def __init__(self, n_electrons=None, s=None):
         """NKG LDF setup
 
         :param n_electrons: Shower size (number of electrons).
         :param s: Shower age parameter.
 
@@ -332,40 +315,37 @@
         """
         if s == self._s:
             c_s = self._c_s
         else:
             c_s = self._c(s)
         r0 = self._r0
 
-        return (n_electrons * c_s * (r / r0) ** (s - 2) *
-                (1 + r / r0) ** (s - 4.5))
+        return n_electrons * c_s * (r / r0) ** (s - 2) * (1 + r / r0) ** (s - 4.5)
 
     def _c(self, s):
         """Part of the LDF
 
         As given in Fokkema2012 eq 7.3.
 
         :param s: shower age parameter.
         :return: c(s)
 
         """
         r0 = self._r0
-        return (gamma(4.5 - s) /
-                (2 * pi * r0 ** 2 * gamma(s) * gamma(4.5 - 2 * s)))
+        return gamma(4.5 - s) / (2 * pi * r0**2 * gamma(s) * gamma(4.5 - 2 * s))
 
 
 class KascadeLdf(NkgLdf):
-
     """The KASCADE modified NKG function"""
 
     # shower parameters
     # Values from Fokkema2012 sec 7.1.
-    _n_electrons = 10 ** 4.8
+    _n_electrons = 10**4.8
     _s = 0.94  # Shape parameter
-    _r0 = 40.
+    _r0 = 40.0
     _alpha = 1.5
     _beta = 3.6
 
     def ldf_value(self, r, n_electrons, s):
         """Calculate the LDF value
 
         Given a core distance, shower size, and shower age.
@@ -381,49 +361,44 @@
             c_s = self._c_s
         else:
             c_s = self._c(s)
         r0 = self._r0
         alpha = self._alpha
         beta = self._beta
 
-        return (n_electrons * c_s * (r / r0) ** (s - alpha) *
-                (1 + r / r0) ** (s - beta))
+        return n_electrons * c_s * (r / r0) ** (s - alpha) * (1 + r / r0) ** (s - beta)
 
     def _c(self, s):
         """Part of the LDF
 
         As given in Fokkema2012 eq 7.5.
 
         :param s: shower shape parameter.
         :return: c(s)
 
         """
         r0 = self._r0
         beta = self._beta
         alpha = self._alpha
-        return (gamma(beta - s) /
-                (2 * pi * r0 ** 2 * gamma(s - alpha + 2) *
-                 gamma(alpha + beta - 2 * s - 2)))
+        return gamma(beta - s) / (2 * pi * r0**2 * gamma(s - alpha + 2) * gamma(alpha + beta - 2 * s - 2))
 
 
 class EllipsLdf(KascadeLdf):
-
     """The NKG function modified for leptons and azimuthal asymmetry"""
 
     # shower parameters
     # Values from Montanus, paper to follow.
-    _n_electrons = 10 ** 4.8
-    _s1 = -.5  # Shape parameter
+    _n_electrons = 10**4.8
+    _s1 = -0.5  # Shape parameter
     _s2 = -2.6  # Shape parameter
-    _r0 = 30.
-    _zenith = 0.
-    _azimuth = 0.
+    _r0 = 30.0
+    _zenith = 0.0
+    _azimuth = 0.0
 
-    def __init__(self, n_electrons=None, zenith=None, azimuth=None, s1=None,
-                 s2=None):
+    def __init__(self, n_electrons=None, zenith=None, azimuth=None, s1=None, s2=None):
         if n_electrons is not None:
             self._n_electrons = n_electrons
         if zenith is not None:
             self._zenith = zenith
         if azimuth is not None:
             self._azimuth = azimuth
         if s1 is not None:
@@ -437,32 +412,30 @@
         """Store the c_s value
 
         The c_s value does not change if s1, s2 and r0 are fixed.
 
         """
         self._c_s = self._c(self._s1, self._s2)
 
-    def calculate_ldf_value(self, r, phi, n_electrons=None, zenith=None,
-                            azimuth=None):
+    def calculate_ldf_value(self, r, phi, n_electrons=None, zenith=None, azimuth=None):
         """Calculate the LDF value for a given core distance and polar angle
 
         :param r: core distance in m.
         :param phi: polar angle in rad.
         :param n_electrons: number of electrons in the shower.
         :return: particle density in m ** -2.
 
         """
         if n_electrons is None:
             n_electrons = self._n_electrons
         if zenith is None:
             zenith = self._zenith
         if azimuth is None:
             azimuth = self._azimuth
-        return self.ldf_value(r, phi, n_electrons, zenith, azimuth, self._s1,
-                              self._s2)
+        return self.ldf_value(r, phi, n_electrons, zenith, azimuth, self._s1, self._s2)
 
     def ldf_value(self, r, phi, n_electrons, zenith, azimuth, s1, s2):
         """Calculate the LDF value
 
         Given a core distance, core polar angle, zenith angle, azimuth angle,
         shower size and three shape parameters (r0, s1, s2) .
         As given by Montanus, paper to follow.
@@ -492,31 +465,29 @@
         ell = sqrt(1 - sin(zenith) * sin(zenith) * relcos * relcos)
         shift = -0.0575 * sin(2 * zenith) * r * relcos
         k = shift + r * ell
         term1 = k / r0
         term2 = 1 + k / r0
         muoncorr = 1 + k / (11.24 * r0)  # See warning in docstring.
         with warnings.catch_warnings(record=True):
-            p = (n_electrons * c_s * cos(zenith) * term1 ** s1 * term2 ** s2 *
-                 muoncorr)
+            p = n_electrons * c_s * cos(zenith) * term1**s1 * term2**s2 * muoncorr
         return p
 
     def _c(self, s1, s2):
         """Normalization of the LDF
 
         As given in Montanus, paper to follow.
 
         :param s1: shower shape parameter.
         :param s2: shower shape parameter.
         :return: c(s1,s2)
 
         """
         r0 = self._r0
-        return (gamma(-s2) /
-                (2 * pi * r0 ** 2 * gamma(s1 + 2) * gamma(-s1 - s2 - 2)))
+        return gamma(-s2) / (2 * pi * r0**2 * gamma(s1 + 2) * gamma(-s1 - s2 - 2))
 
     def calculate_core_distance_and_angle(self, x, y, x0, y0):
         """Calculate core distance
 
         The core distance is the distance of the detector to the shower core,
         measured *in the horizontal observation plane*.
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/simulations/showerfront.py` & `hisparc_sapphire-3.0.0/sapphire/simulations/showerfront.py`

 * *Files 3% similar despite different names*

```diff
@@ -22,57 +22,58 @@
 import numpy as np
 
 from ..utils import c, pbar, vector_length
 from .detector import ErrorlessSimulation, HiSPARCSimulation
 
 
 class FlatFrontSimulation(HiSPARCSimulation):
-
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
         # Since the cluster is not rotated detector positions can be cached.
         for station in self.cluster.stations:
             for detector in station.detectors:
-                detector.cylindrical_coordinates = \
-                    detector.get_cylindrical_coordinates()
+                detector.cylindrical_coordinates = detector.get_cylindrical_coordinates()
 
     def generate_shower_parameters(self):
         """Generate shower parameters, i.e. azimuth and zenith angles.
 
         For this groundparticles simulation, only the shower core position
         and rotation angle of the shower are generated.  Do *not*
         interpret these parameters as the position of the cluster, or the
         rotation of the cluster!  Interpret them as *shower* parameters.
 
         :return: dictionary with shower parameters: core_pos
                  (x, y-tuple) and azimuth.
 
         """
         for i in pbar(range(self.n), show=self.progress):
-            shower_parameters = {'ext_timestamp': (1_000_000_000 + i) * 1_000_000_000,
-                                 'azimuth': self.generate_azimuth(),
-                                 'zenith': self.generate_attenuated_zenith(),
-                                 'core_pos': (None, None),
-                                 'size': None,
-                                 'energy': None}
+            shower_parameters = {
+                'ext_timestamp': (1_000_000_000 + i) * 1_000_000_000,
+                'azimuth': self.generate_azimuth(),
+                'zenith': self.generate_attenuated_zenith(),
+                'core_pos': (None, None),
+                'size': None,
+                'energy': None,
+            }
 
             yield shower_parameters
 
     def simulate_detector_response(self, detector, shower_parameters):
         """Simulate detector response to a shower.
 
         Return the arrival time of shower front passing the center of
         the detector.
 
         """
         arrival_time = self.simulate_adc_sampling(
-            self.get_arrival_time(detector, shower_parameters) +
-            self.simulate_signal_transport_time(1)[0] +
-            detector.offset)
+            self.get_arrival_time(detector, shower_parameters)
+            + self.simulate_signal_transport_time(1)[0]
+            + detector.offset,
+        )
         observables = {'t': arrival_time}
 
         return observables
 
     def get_arrival_time(self, detector, shower_parameters):
         """Calculate arrival time
 
@@ -88,64 +89,60 @@
         :return: Shower front arrival time in ns.
 
         """
         r1, phi1, z1 = detector.cylindrical_coordinates
         phi = shower_parameters['azimuth']
         theta = shower_parameters['zenith']
         r = r1 * cos(phi - phi1) - z1 * tan(theta)
-        cdt = - (r * sin(theta) + z1 / cos(theta))
+        cdt = -(r * sin(theta) + z1 / cos(theta))
         dt = cdt / c
         return dt
 
     def simulate_gps(self, station_observables, shower_parameters, station):
         """Simulate gps timestamp
 
         Ensure that all detector arrival times are positive.
 
         """
         n_detectors = len(station.detectors)
-        ids = list(range(1, n_detectors + 1))
-        arrival_times = [station_observables['t%d' % id] for id in ids]
+        detector_ids = list(range(1, n_detectors + 1))
+        arrival_times = [station_observables[f't{detector_id}'] for detector_id in detector_ids]
         ext_timestamp = shower_parameters['ext_timestamp']
 
         first_time = sorted(arrival_times)[0]
-        for id in ids:
-            station_observables['t%d' % id] -= first_time
+        for detector_id in detector_ids:
+            station_observables[f't{detector_id}'] -= first_time
 
-        arrival_times = [station_observables['t%d' % id] for id in ids]
+        arrival_times = [station_observables[f't{detector_id}'] for detector_id in detector_ids]
         trigger_time = sorted(arrival_times)[1]
 
-        ext_timestamp += int(first_time + trigger_time + station.gps_offset +
-                             self.simulate_gps_uncertainty())
+        ext_timestamp += int(first_time + trigger_time + station.gps_offset + self.simulate_gps_uncertainty())
         timestamp = int(ext_timestamp / 1_000_000_000)
         nanoseconds = int(ext_timestamp % 1_000_000_000)
 
-        gps_timestamp = {'ext_timestamp': ext_timestamp,
-                         'timestamp': timestamp,
-                         'nanoseconds': nanoseconds,
-                         't_trigger': trigger_time}
+        gps_timestamp = {
+            'ext_timestamp': ext_timestamp,
+            'timestamp': timestamp,
+            'nanoseconds': nanoseconds,
+            't_trigger': trigger_time,
+        }
         station_observables.update(gps_timestamp)
 
         return station_observables
 
 
-class FlatFrontSimulationWithoutErrors(ErrorlessSimulation,
-                                       FlatFrontSimulation):
-
+class FlatFrontSimulationWithoutErrors(ErrorlessSimulation, FlatFrontSimulation):
     """This simulation does not simulate errors/uncertainties
 
     This should result in perfect timing for the detectors.
 
     """
 
-    pass
-
 
 class FlatFrontSimulation2D(FlatFrontSimulation):
-
     """This simulation ignores detector altitudes."""
 
     def get_arrival_time(self, detector, shower_parameters):
         """Calculate arrival time
 
         Ignore detector altitudes
 
@@ -158,24 +155,19 @@
         theta = shower_parameters['zenith']
         r = r1 * cos(phi - phi1)
         cdt = -r * sin(theta)
         dt = cdt / c
         return dt
 
 
-class FlatFrontSimulation2DWithoutErrors(FlatFrontSimulation2D,
-                                         FlatFrontSimulationWithoutErrors):
-
+class FlatFrontSimulation2DWithoutErrors(FlatFrontSimulation2D, FlatFrontSimulationWithoutErrors):
     """Ignore altitude of detectors and do not simulate errors."""
 
-    pass
-
 
 class ConeFrontSimulation(FlatFrontSimulation):
-
     """This simulation uses a cone shaped shower front.
 
     The opening angle of the cone is given in the init
 
     Example usage::
 
         >>> import tables
@@ -212,20 +204,22 @@
         """
         r_max = self.max_core_distance
 
         for i in pbar(range(self.n), show=self.progress):
             x, y = self.generate_core_position(r_max)
             azimuth = self.generate_azimuth()
 
-            shower_parameters = {'ext_timestamp': (1_000_000_000 + i) * 1_000_000_000,
-                                 'azimuth': azimuth,
-                                 'zenith': self.generate_attenuated_zenith(),
-                                 'core_pos': (x, y),
-                                 'size': None,
-                                 'energy': self.generate_energy(1e15, 1e17)}
+            shower_parameters = {
+                'ext_timestamp': (1_000_000_000 + i) * 1_000_000_000,
+                'azimuth': azimuth,
+                'zenith': self.generate_attenuated_zenith(),
+                'core_pos': (x, y),
+                'size': None,
+                'energy': self.generate_energy(1e15, 1e17),
+            }
 
             self._prepare_cluster_for_shower(x, y, azimuth)
 
             yield shower_parameters
 
     def _prepare_cluster_for_shower(self, x, y, alpha):
         """Prepare the cluster object for the simulation of a shower.
@@ -247,41 +241,38 @@
         x, y, z = detector.get_coordinates()
         r1 = vector_length(x, y)
         phi1 = atan2(y, x)
 
         phi = shower_parameters['azimuth']
         theta = shower_parameters['zenith']
         r = r1 * cos(phi - phi1) - z * tan(theta)
-        cdt = - (r * sin(theta) + z / cos(theta))
+        cdt = -(r * sin(theta) + z / cos(theta))
 
         nx = sin(theta) * cos(phi)
         ny = sin(theta) * sin(phi)
         nz = cos(theta)
 
-        r_core = sqrt(x ** 2 + y ** 2 + z ** 2 -
-                      (x * nx + y * ny + z * nz) ** 2)
+        r_core = sqrt(x**2 + y**2 + z**2 - (x * nx + y * ny + z * nz) ** 2)
         t_shape = self.delay_at_r(r_core)
         dt = t_shape + (cdt / c)
 
         return dt
 
 
 class FlatFront:
-
     """Simple flat shower front"""
 
     def delay_at_r(self, r):
-        return 0.
+        return 0.0
 
     def front_shape(self, r):
-        return 0.
+        return 0.0
 
 
 class ConeFront:
-
     """Simple cone shaped shower front"""
 
     def delay_at_r(self, r):
         return self.front_shape(r)
 
     def front_shape(self, r):
         """Delay of the showerfront relative to flat as function of distance
@@ -290,15 +281,14 @@
         :return: delay time of shower front.
 
         """
         return r * 0.2
 
 
 class CorsikaStationFront:
-
     """Shower front shape derrived from CORSIKA simulations on a station.
 
     A set of CORSIKA generated showers were used to determine the median
     detected arrival time in a 4-detector station as a function of core
     distance.
 
     At large core distances the detection probability decreases and the
@@ -327,8 +317,8 @@
 
         a = np.interp(np.log10(energy), energies, param_a)
         b = np.interp(np.log10(energy), energies, param_b)
 
         return self._front_shape(r, a, b)
 
     def _front_shape(self, r, a, b):
-        return a * r ** b
+        return a * r**b
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/storage.py` & `hisparc_sapphire-3.0.0/sapphire/storage.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-""" PyTables table descriptions for data storage
+"""PyTables table descriptions for data storage
 
-    This module contains the table descriptions used by the detector
-    simulation to store intermediate and final data in a HDF5 file.
+This module contains the table descriptions used by the detector
+simulation to store intermediate and final data in a HDF5 file.
 
 """
+
 import tables
 
 
 class EventObservables(tables.IsDescription):
-
     """Store information about the observables of an event.
 
     The observables are described for each station independently.  So, for each
     event (with a unique :attr:`id`), there is a table row for each station
     (with a unique :attr:`station_id`), such that only the (id, station_id)
     combinations are unique in the table.
 
@@ -36,14 +36,15 @@
         rotation of the station around its center
 
     .. attribute:: N
 
         number of detectors with at least one particle
 
     """
+
     id = tables.UInt32Col()
     station_id = tables.UInt8Col()
     timestamp = tables.Time32Col()
     nanoseconds = tables.UInt32Col()
     ext_timestamp = tables.UInt64Col()
 
     r = tables.Float32Col()
@@ -59,15 +60,14 @@
     n1 = tables.Float32Col()
     n2 = tables.Float32Col()
     n3 = tables.Float32Col()
     n4 = tables.Float32Col()
 
 
 class Coincidence(tables.IsDescription):
-
     """Store information about a coincidence of stations within a cluster.
 
     An extensive air shower can trigger multiple stations, resulting in a set
     of events which are from the same shower.  This is called a coincidence.
 
     This table assigns an :attr:`id` to a coincidence and provides some
     additional information.  The events making up the coincidence can be looked
@@ -119,14 +119,15 @@
         The size (number of leptons) of the (simulated) shower.
 
     .. attribute:: energy
 
         The primary particle energy of the (simulated) shower.
 
     """
+
     id = tables.UInt32Col(pos=0)
     timestamp = tables.Time32Col(pos=1)
     nanoseconds = tables.UInt32Col(pos=2)
     ext_timestamp = tables.UInt64Col(pos=3)
 
     N = tables.UInt8Col(pos=4)
     x = tables.Float32Col(pos=5)
@@ -134,25 +135,23 @@
     zenith = tables.Float32Col(pos=7)
     azimuth = tables.Float32Col(pos=8)
     size = tables.Float32Col(pos=9)
     energy = tables.Float32Col(pos=10)
 
 
 class TimeDelta(tables.IsDescription):
-
     """Store time differences"""
 
     ext_timestamp = tables.UInt64Col(pos=0)
     timestamp = tables.UInt32Col(pos=1)
     nanoseconds = tables.UInt32Col(pos=2)
     delta = tables.FloatCol(pos=3)
 
 
 class ReconstructedCoincidence(tables.IsDescription):
-
     """Store information about reconstructed coincidences"""
 
     id = tables.UInt32Col(pos=1)
     ext_timestamp = tables.UInt64Col(pos=2)
     min_n = tables.Float32Col(pos=3)
 
     x = tables.Float32Col(pos=4)
@@ -173,15 +172,14 @@
     reference_zenith = tables.Float32Col(pos=18)
     reference_azimuth = tables.Float32Col(pos=19)
     reference_size = tables.Float32Col(pos=20)
     reference_energy = tables.Float32Col(pos=21)
 
 
 class ReconstructedEvent(ReconstructedCoincidence):
-
     """Store information about reconstructed events
 
     .. attribute:: id
 
         Index referring to the id of the event that was reconstructed.
 
     .. attribute:: d1,d2,d3,d4
@@ -194,15 +192,14 @@
     d1 = tables.BoolCol(pos=22)
     d2 = tables.BoolCol(pos=23)
     d3 = tables.BoolCol(pos=24)
     d4 = tables.BoolCol(pos=25)
 
 
 class KascadeEvent(tables.IsDescription):
-
     """Store events from KASCADE"""
 
     run_id = tables.IntCol(pos=0)
     event_id = tables.Int64Col(pos=1)
     timestamp = tables.Time32Col(pos=2)
     nanoseconds = tables.UInt32Col(pos=3)
     ext_timestamp = tables.UInt64Col(pos=4)
@@ -216,15 +213,14 @@
     dens_e = tables.FloatCol(pos=11, shape=4)
     dens_mu = tables.FloatCol(pos=12, shape=4)
     P200 = tables.FloatCol(pos=13)
     T200 = tables.FloatCol(pos=14)
 
 
 class ReconstructedKascadeEvent(tables.IsDescription):
-
     """Store information about reconstructed events"""
 
     # r, phi is core position
 
     id = tables.UInt32Col()
     station_id = tables.UInt8Col()
     r = tables.Float32Col()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/__init__.py` & `hisparc_sapphire-3.0.0/sapphire/tests/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 """Perform code tests.
 
 This package contains all tests which verify the proper working of all
 SAPPHiRE code. These tests can also be used to verify if SAPPHiRE was
 installed correctly. Simply call the :func:`run_tests` function.
 
 """
+
 import os
 
 from unittest import TestSuite, TextTestRunner, defaultTestLoader
 
 
 def run_tests():
     """Collect and run all SAPPHiRE tests
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_calibration.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_calibration.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,33 +1,30 @@
-import os
 import unittest
 import warnings
 
 from datetime import date, datetime
+from pathlib import Path
 from unittest.mock import MagicMock, Mock, call, patch, sentinel
 
 import tables
 
-from numpy import all, array, isnan, nan, std
-from numpy.random import normal, uniform
+from numpy import all, array, isnan, nan, random, std
 
 from sapphire import HiSPARCNetwork, HiSPARCStations
 from sapphire.analysis import calibration
 from sapphire.clusters import SingleStation
 from sapphire.transformations.clock import datetime_to_gps
 from sapphire.utils import c
 
 TEST_DATA_ESD = 'test_data/esd_coincidences.h5'
 
 
 class DetectorTimingTests(unittest.TestCase):
-
     def get_testdata_path(self):
-        dir_path = os.path.dirname(__file__)
-        return os.path.join(dir_path, TEST_DATA_ESD)
+        return Path(__file__).parent / TEST_DATA_ESD
 
     def test_determine_detector_timing_offsets(self):
         with tables.open_file(self.get_testdata_path(), 'r') as data:
             events = data.get_node('/station_501', 'events')
             station = SingleStation().get_station(0)
             offsets = calibration.determine_detector_timing_offsets(events, station)
         for expected, actual in zip([-7.7415, 0.0, -1.6725, -7.43484], offsets):
@@ -40,102 +37,96 @@
         self.assertTrue(all(isnan(offset)))
 
         dt = array([-10, 0, 10])
         dz = 0.6
         dzc = dz / c
 
         # Good result
-        mock_fit.return_value = (1., 2.)
+        mock_fit.return_value = (1.0, 2.0)
         offset, _ = calibration.determine_detector_timing_offset(dt)
-        self.assertEqual(offset, 1.)
+        self.assertEqual(offset, 1.0)
         offset, _ = calibration.determine_detector_timing_offset(dt, dz=dz)
-        self.assertEqual(offset, 1. + dzc)
+        self.assertEqual(offset, 1.0 + dzc)
 
-        mock_fit.return_value = (-1.5, 5.)
+        mock_fit.return_value = (-1.5, 5.0)
         offset, _ = calibration.determine_detector_timing_offset(dt)
         self.assertEqual(offset, -1.5)
         offset, _ = calibration.determine_detector_timing_offset(dt, dz=dz)
         self.assertEqual(offset, -1.5 + dzc)
 
-        mock_fit.return_value = (250., 100.)
+        mock_fit.return_value = (250.0, 100.0)
         offset, _ = calibration.determine_detector_timing_offset(dt, dz=dz)
         self.assertTrue(isnan(offset))
-        mock_fit.return_value = (-150., 100.)
+        mock_fit.return_value = (-150.0, 100.0)
         offset, _ = calibration.determine_detector_timing_offset(dt, dz=dz)
         self.assertTrue(isnan(offset))
 
         mock_fit.return_value = (nan, nan)
         offset, _ = calibration.determine_detector_timing_offset(dt, dz=dz)
         self.assertTrue(isnan(offset))
 
 
 class StationTimingTests(unittest.TestCase):
-
     @patch.object(calibration, 'percentile')
     @patch.object(calibration, 'fit_timing_offset')
     def test_determine_station_timing_offset(self, mock_fit, mock_percentile):
-        mock_percentile.return_value = (-50., 50.)
+        mock_percentile.return_value = (-50.0, 50.0)
         dz = 0.6
         dzc = dz / c
 
         # Empty list
         offset = calibration.determine_station_timing_offset([])
         self.assertTrue(all(isnan(offset)))
 
         # Good result
-        mock_fit.return_value = (1., 5.)
+        mock_fit.return_value = (1.0, 5.0)
         offset, _ = calibration.determine_station_timing_offset([sentinel.dt])
-        self.assertEqual(offset, 1.)
+        self.assertEqual(offset, 1.0)
         mock_percentile.assert_called_once_with([sentinel.dt], [0.5, 99.5])
         offset, _ = calibration.determine_station_timing_offset([sentinel.dt], dz=dz)
-        self.assertEqual(offset, 1. + dzc)
+        self.assertEqual(offset, 1.0 + dzc)
 
-        mock_fit.return_value = (-1.5, 5.)
+        mock_fit.return_value = (-1.5, 5.0)
         offset, _ = calibration.determine_station_timing_offset([sentinel.dt])
         self.assertEqual(offset, -1.5)
         offset, _ = calibration.determine_station_timing_offset([sentinel.dt], dz=dz)
         self.assertEqual(offset, -1.5 + dzc)
 
-        mock_fit.return_value = (2500., 100.)
+        mock_fit.return_value = (2500.0, 100.0)
         offset, _ = calibration.determine_station_timing_offset([sentinel.dt])
         self.assertTrue(isnan(offset))
-        mock_fit.return_value = (-1500., 100.)
+        mock_fit.return_value = (-1500.0, 100.0)
         offset, _ = calibration.determine_station_timing_offset([sentinel.dt])
         self.assertTrue(isnan(offset))
 
         mock_fit.return_value = (nan, nan)
         offset, _ = calibration.determine_station_timing_offset([sentinel.dt])
         self.assertTrue(isnan(offset))
 
 
 class BestReferenceTests(unittest.TestCase):
-
     def test_determine_best_reference(self):
         # Tie
-        filters = array([[True, True, False], [True, False, True],
-                         [False, True, True], [True, True, False]])
+        filters = array([[True, True, False], [True, False, True], [False, True, True], [True, True, False]])
         self.assertEqual(calibration.determine_best_reference(filters), 0)
 
         # 1 has most matches
-        filters = array([[True, False, False], [True, True, True],
-                         [False, False, False], [True, True, False]])
+        filters = array([[True, False, False], [True, True, True], [False, False, False], [True, True, False]])
         self.assertEqual(calibration.determine_best_reference(filters), 1)
 
         # Another winner
-        filters = array([[True, True, False], [True, False, True],
-                         [False, True, True], [True, True, True]])
+        filters = array([[True, True, False], [True, False, True], [False, True, True], [True, True, True]])
         self.assertEqual(calibration.determine_best_reference(filters), 3)
 
         # Not yet support number of detectors
         filters = array([[True, True, False], [True, False, True]])
         self.assertRaises(IndexError, calibration.determine_best_reference, filters)
 
 
 class SplitDatetimeRangeTests(unittest.TestCase):
-
     def test_split_range(self):
         # 101 days
         start = date(2016, 1, 1)
         end_5days = date(2016, 1, 6)
         end_100days = date(2016, 4, 11)
 
         # no step, dates:
@@ -184,43 +175,43 @@
 
     def test_pairwise(self):
         result = list(calibration.pairwise([1, 2, 3, 4]))
         self.assertEqual(result, [(1, 2), (2, 3), (3, 4)])
 
 
 class FitTimingOffsetTests(unittest.TestCase):
-
     def test_fit_timing_offset(self):
         deviations = []
         for _ in range(50):
-            center = uniform(-40, 40)
-            sigma = uniform(10, 30)
+            center = random.uniform(-40, 40)
+            sigma = random.uniform(10, 30)
             n = int(4e4)
             lower = center - 3 * sigma
             upper = center + 3 * sigma
             bins = list(range(int(lower), int(upper), 1))
-            dt = normal(center, sigma, n)
+            dt = random.normal(center, sigma, n)
             offset, error = calibration.fit_timing_offset(dt, bins)
             deviations.append((center - offset) / error)
             # Test if determined offset close to the actual center.
             self.assertLess(abs(center - offset), 5 * error)
         # Test if estimated error correctly represents the errors in offsets.
         self.assertLess(abs(std(deviations) - 1), 0.35)
 
 
 class DetermineStationTimingOffsetsTests(unittest.TestCase):
-
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         stations = [501, 102, 105, 8001]
-        self.off = calibration.DetermineStationTimingOffsets(stations=stations, data=sentinel.data,
-                                                             progress=sentinel.progress, force_stale=True)
-
-    def tearDown(self):
-        warnings.resetwarnings()
+        self.off = calibration.DetermineStationTimingOffsets(
+            stations=stations,
+            data=sentinel.data,
+            progress=sentinel.progress,
+            force_stale=True,
+        )
 
     def test_init(self):
         self.assertEqual(self.off.progress, sentinel.progress)
         self.assertEqual(self.off.data, sentinel.data)
         self.assertIsInstance(self.off.cluster, HiSPARCStations)
 
     def test_init_network(self):
@@ -232,28 +223,32 @@
         table_mock = MagicMock()
         self.off.data.get_node.return_value = table_mock
         station = 502
         ref_station = 501
         start = datetime(2014, 1, 1)
         end = datetime(2016, 12, 31)
         self.off.read_dt(station, ref_station, start, end)
-        table_path = ('/coincidences/time_deltas/station_%d/station_%d' % (ref_station, station))
+        table_path = '/coincidences/time_deltas/station_%d/station_%d' % (ref_station, station)
         table_name = 'time_deltas'
         self.off.data.get_node.assert_called_once_with(table_path, table_name)
         self.assertTrue(table_mock.read_where.called)
 
     def test_station_pairs_within_max_distance(self):
         results = list(self.off.get_station_pairs_within_max_distance())
         self.assertEqual([(102, 105)], results)
         # force unsorted order of stations:
 
     def test_station_pairs_wrong_order(self):
         stations = [105, 102, 8001, 501]
-        self.off = calibration.DetermineStationTimingOffsets(stations=stations, data=sentinel.data,
-                                                             progress=sentinel.progress, force_stale=True)
+        self.off = calibration.DetermineStationTimingOffsets(
+            stations=stations,
+            data=sentinel.data,
+            progress=sentinel.progress,
+            force_stale=True,
+        )
         results = list(self.off.get_station_pairs_within_max_distance())
         self.assertEqual([(102, 105)], results)
 
     @patch.object(calibration, 'Station')
     def test_get_gps_timestamps(self, mock_station):
         self.off._get_gps_timestamps(sentinel.station)
         mock_station.assert_called_once_with(sentinel.station, force_stale=self.off.force_stale)
@@ -267,30 +262,32 @@
         r_102_105 = 88.11877198608  # 2014,1,1
         dz_102_105 = -4.13568408095
         r, dz = self.off._get_r_dz(datetime(2014, 1, 1).date(), 102, 105)
         self.assertAlmostEqual(r, r_102_105, places=6)
         self.assertAlmostEqual(dz, dz_102_105, places=5)
 
     def test_determine_interval(self):
-        combinations = ((0., 7),
-                        (50., 10),
-                        (200., 57),
-                        (1000., 398))
+        combinations = ((0.0, 7), (50.0, 10), (200.0, 57), (1000.0, 398))
         for r, ref_int in combinations:
             self.assertEqual(self.off._determine_interval(r), ref_int)
 
     def test_get_cuts(self):
-        gps_station = (datetime_to_gps(datetime(2014, 1, 1, 10, 3)),
-                       datetime_to_gps(datetime(2014, 3, 1, 11, 32)))
-        gps_ref_station = (datetime_to_gps(datetime(2014, 1, 5, 0, 1, 1)),
-                           datetime_to_gps(datetime(2014, 3, 5, 3, 34, 4)))
-        elec_station = (datetime_to_gps(datetime(2014, 1, 3, 3, 34, 3)),
-                        datetime_to_gps(datetime(2014, 3, 5, 23, 59, 59)))
-        elec_ref_station = (datetime_to_gps(datetime(2014, 1, 9, 0, 0, 0)),
-                            datetime_to_gps(datetime(2014, 3, 15, 1, 2, 3)))
+        gps_station = (datetime_to_gps(datetime(2014, 1, 1, 10, 3)), datetime_to_gps(datetime(2014, 3, 1, 11, 32)))
+        gps_ref_station = (
+            datetime_to_gps(datetime(2014, 1, 5, 0, 1, 1)),
+            datetime_to_gps(datetime(2014, 3, 5, 3, 34, 4)),
+        )
+        elec_station = (
+            datetime_to_gps(datetime(2014, 1, 3, 3, 34, 3)),
+            datetime_to_gps(datetime(2014, 3, 5, 23, 59, 59)),
+        )
+        elec_ref_station = (
+            datetime_to_gps(datetime(2014, 1, 9, 0, 0, 0)),
+            datetime_to_gps(datetime(2014, 3, 15, 1, 2, 3)),
+        )
         gps_mock = Mock()
         elec_mock = Mock()
 
         gps_mock.side_effect = [array(gps_station), array(gps_ref_station)]
         elec_mock.side_effect = [array(elec_station), array(elec_ref_station)]
 
         self.off._get_electronics_timestamps = elec_mock
@@ -304,23 +301,22 @@
         self.assertEqual(len(cuts), 8)
         self.assertCountEqual(sorted(cuts), cuts)
         self.assertEqual(cuts[0], datetime(2014, 1, 1))
         today = datetime.now()
         self.assertEqual(cuts[-1], datetime(today.year, today.month, today.day))
 
     def test_get_left_and_right_bounds(self):
-        cuts = (datetime(2014, 1, 1),
-                datetime(2015, 1, 1),
-                datetime(2015, 1, 5),
-                datetime(2015, 1, 10))
-        combinations = [(datetime(2015, 1, 1), 7, datetime(2015, 1, 1), datetime(2015, 1, 4)),
-                        (datetime(2015, 1, 3), 7, datetime(2015, 1, 1), datetime(2015, 1, 4)),
-                        (datetime(2015, 1, 3).date(), 7, datetime(2015, 1, 1), datetime(2015, 1, 4)),
-                        (datetime(2015, 1, 5), 7, datetime(2015, 1, 5), datetime(2015, 1, 9)),
-                        (datetime(2015, 1, 10), 7, datetime(2015, 1, 5), datetime(2015, 1, 10))]
+        cuts = (datetime(2014, 1, 1), datetime(2015, 1, 1), datetime(2015, 1, 5), datetime(2015, 1, 10))
+        combinations = [
+            (datetime(2015, 1, 1), 7, datetime(2015, 1, 1), datetime(2015, 1, 4)),
+            (datetime(2015, 1, 3), 7, datetime(2015, 1, 1), datetime(2015, 1, 4)),
+            (datetime(2015, 1, 3).date(), 7, datetime(2015, 1, 1), datetime(2015, 1, 4)),
+            (datetime(2015, 1, 5), 7, datetime(2015, 1, 5), datetime(2015, 1, 9)),
+            (datetime(2015, 1, 10), 7, datetime(2015, 1, 5), datetime(2015, 1, 10)),
+        ]
         for d, days, ref_left, ref_right in combinations:
             left, right = self.off._get_left_and_right_bounds(cuts, d, days)
             self.assertEqual(left, ref_left)
             self.assertEqual(right, ref_right)
 
     def test_determine_first_and_last_date(self):
         date = datetime(2015, 1, 2)
@@ -362,24 +358,20 @@
         date = datetime(2015, 1, 2)
         self.off._get_r_dz = Mock()
         self.off.determine_first_and_last_date = Mock()
         self.off.read_dt = Mock()
 
         self.off._get_r_dz.return_value = sentinel.r, sentinel.dz
         self.off.determine_first_and_last_date.return_value = (0, 0)
-        self.off.read_dt.return_value = 1000 * [0.]
-        mock_det_offset.return_value = (10., 1.)
+        self.off.read_dt.return_value = 1000 * [0.0]
+        mock_det_offset.return_value = (10.0, 1.0)
 
         offsets = self.off.determine_station_timing_offset(date, sentinel.station, sentinel.ref_station)
 
         self.off._get_r_dz.assert_called_once_with(date, sentinel.station, sentinel.ref_station)
         self.off.determine_first_and_last_date.assert_called_once_with(date, sentinel.station, sentinel.ref_station)
 
-        self.assertEqual(offsets, (10., 1.))
+        self.assertEqual(offsets, (10.0, 1.0))
 
-        self.off.read_dt.return_value = 90 * [0.]
+        self.off.read_dt.return_value = 90 * [0.0]
         offsets = self.off.determine_station_timing_offset(date, sentinel.station, sentinel.ref_station)
         self.assertEqual(offsets, (nan, nan))
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_coincidence_queries.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_coincidence_queries.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,30 +2,30 @@
 
 from unittest.mock import call, patch, sentinel
 
 from sapphire.analysis import coincidence_queries
 
 
 class BaseCoincidenceQueryTest(unittest.TestCase):
-
     @patch.object(coincidence_queries.tables, 'open_file')
     def setUp(self, mock_open_file):
         self.mock_open_file = mock_open_file
         self.data_path = sentinel.data_path
         self.coincidences_group = sentinel.coincidences_group
 
-        self.cq = coincidence_queries.CoincidenceQuery(
-            self.data_path, self.coincidences_group)
+        self.cq = coincidence_queries.CoincidenceQuery(self.data_path, self.coincidences_group)
 
     def test_init_opens_file_and_gets_nodes(self):
         self.mock_open_file.assert_called_once_with(self.data_path, 'r')
-        expected = [call(self.coincidences_group, 'coincidences'),
-                    call(self.coincidences_group, 'c_index'),
-                    call(self.coincidences_group, 's_index'),
-                    call(self.coincidences_group, 'reconstructions')]
+        expected = [
+            call(self.coincidences_group, 'coincidences'),
+            call(self.coincidences_group, 'c_index'),
+            call(self.coincidences_group, 's_index'),
+            call(self.coincidences_group, 'reconstructions'),
+        ]
         call_list = self.mock_open_file.return_value.get_node.call_args_list
         self.assertEqual(call_list, expected)
 
         a_node = self.mock_open_file.return_value.get_node.return_value
         self.assertEqual(self.cq.coincidences, a_node)
         self.assertEqual(self.cq.s_index, a_node)
         self.assertEqual(self.cq.c_index, a_node)
@@ -66,16 +66,15 @@
     @patch.object(coincidence_queries.CoincidenceQuery, 'perform_query')
     @patch.object(coincidence_queries.CoincidenceQuery, '_get_allowed_s_columns')
     def test_at_least(self, mock_columns, mock_query):
         mock_columns.return_value = ['s501', 's502', 's503']
         n = 2
         self.cq.at_least(sentinel.stations, n)
         mock_columns.assert_called_once_with(sentinel.stations)
-        mock_query.assert_called_once_with('((s501 & s502) | (s501 & s503) | '
-                                           '(s502 & s503))', False)
+        mock_query.assert_called_once_with('((s501 & s502) | (s501 & s503) | (s502 & s503))', False)
 
     @patch.object(coincidence_queries.CoincidenceQuery, 'perform_query')
     def test_timerange(self, mock_query):
         mock_query.return_value = sentinel.coincidences
         result = self.cq.timerange(1, 2)
         mock_query.assert_called_once_with('(1 <= timestamp) & (timestamp < 2)', False)
         self.assertEqual(result, sentinel.coincidences)
@@ -149,16 +148,15 @@
         coincidences = [sentinel.coincidence]
         self.cq.reconstructions_from_stations(coincidences, sentinel.stations)
         # mock_get_events.assert_called_once_with(sentinel.coincidence)
         # mock_events_from.assert_called_once_with(sentinel.events, sentinel.stations)
         # mock_minimum.assert_called_once_with([sentinel.coincidence_events])
 
     def test__events_from_stations(self):
-        events = ([sentinel.station1, sentinel.event1],
-                  [sentinel.station2, sentinel.event2])
+        events = ([sentinel.station1, sentinel.event1], [sentinel.station2, sentinel.event2])
         stations = [sentinel.station2]
         result = self.cq._events_from_stations(events, stations)
         self.assertEqual(result, [[sentinel.station2, sentinel.event2]])
 
     @patch.object(coincidence_queries.CoincidenceQuery, 'events_from_stations')
     @patch.object(coincidence_queries.api, 'Network')
     def test_events_in_subcluster(self, mock_network, mock_events_from):
@@ -176,11 +174,7 @@
         mock_network.return_value.station_numbers.return_value = sentinel.numbers
         mock_events_from.return_value = sentinel.coincidence_events
         result = self.cq.events_in_cluster(sentinel.coincidences, sentinel.cluster)
         mock_network.assert_called_once_with()
         mock_network.return_value.station_numbers.assert_called_once_with(cluster=sentinel.cluster)
         mock_events_from.assert_called_once_with(sentinel.coincidences, sentinel.numbers, 2)
         self.assertEqual(result, sentinel.coincidence_events)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_coincidences.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_coincidences.py`

 * *Files 11% similar despite different names*

```diff
@@ -13,88 +13,122 @@
 from sapphire.tests.validate_results import validate_results
 
 TEST_DATA = 'test_data/coincidences.h5'
 TEST_DATA_ESD = 'test_data/esd_coincidences.h5'
 
 
 class CoincidencesTests(unittest.TestCase):
-
     @patch.object(coincidences.tables, 'open_file')
     def setUp(self, mock_open_file):
         self.mock_open_file = mock_open_file
         self.c = coincidences.Coincidences(sentinel.data, None, sentinel.station_groups, progress=False)
 
     def test_init(self):
         self.mock_open_file.assert_called_once_with(sentinel.data, 'r')
         self.assertFalse(self.c.data.create_group.called)
 
     @patch.object(coincidences.Coincidences, 'search_coincidences')
     @patch.object(coincidences.Coincidences, 'process_events')
     @patch.object(coincidences.Coincidences, 'store_coincidences')
     def test_search_and_store_coincidences(self, mock_store, mock_process, mock_search):
         self.c.search_and_store_coincidences()
-        mock_search.assert_called_with(window=10000)
+        mock_search.assert_called_with(window=10_000)
         mock_process.assert_called_with()
         mock_store.assert_called_with()
         self.c.search_and_store_coincidences(sentinel.window)
         mock_search.assert_called_with(window=sentinel.window)
         mock_process.assert_called_with()
         mock_store.assert_called_with()
 
     def test__retrieve_timestamps(self):
         station1 = Mock()
         station2 = Mock()
         # Station 2 timestamps are not already correctly sorted.
-        station1.col.return_value = [uint64(1400000002000000050), uint64(1400000018000000500)]
-        station2.col.return_value = [uint64(1400000002000000510), uint64(1400000030000000000)][::-1]
+        station1.col.return_value = [uint64(1400000002_000000050), uint64(1400000018_000000500)]
+        station2.col.return_value = [uint64(1400000002_000000510), uint64(1400000030_000000000)][::-1]
         stations = [station1, station2]
         timestamps = self.c._retrieve_timestamps(stations)
-        self.assertEqual(timestamps,
-                         [(uint64(1400000002000000050), 0, 0), (uint64(1400000002000000510), 1, 1),
-                          (uint64(1400000018000000500), 0, 1), (uint64(1400000030000000000), 1, 0)])
+        self.assertEqual(
+            timestamps,
+            [
+                (uint64(1400000002_000000050), 0, 0),
+                (uint64(1400000002_000000510), 1, 1),
+                (uint64(1400000018_000000500), 0, 1),
+                (uint64(1400000030_000000000), 1, 0),
+            ],
+        )
         # Shift both
         timestamps = self.c._retrieve_timestamps(stations, shifts=[1, 17])
-        self.assertEqual(timestamps,
-                         [(uint64(1400000003000000050), 0, 0), (uint64(1400000019000000500), 0, 1),
-                          (uint64(1400000019000000510), 1, 1), (uint64(1400000047000000000), 1, 0)])
+        self.assertEqual(
+            timestamps,
+            [
+                (uint64(1400000003_000000050), 0, 0),
+                (uint64(1400000019_000000500), 0, 1),
+                (uint64(1400000019_000000510), 1, 1),
+                (uint64(1400000047_000000000), 1, 0),
+            ],
+        )
         # Wrong value type shifts
-        self.assertRaises(TypeError, self.c._retrieve_timestamps, stations, shifts=['', ''])
-        self.assertRaises(TypeError, self.c._retrieve_timestamps, stations, shifts=['', 90])
+        self.assertRaises(ValueError, self.c._retrieve_timestamps, stations, shifts=['', ''])
+        self.assertRaises(ValueError, self.c._retrieve_timestamps, stations, shifts=['', 90])
         # Different length shifts
         timestamps = self.c._retrieve_timestamps(stations, shifts=[110])
-        self.assertEqual(timestamps,
-                         [(uint64(1400000002000000510), 1, 1), (uint64(1400000030000000000), 1, 0),
-                          (uint64(1400000112000000050), 0, 0), (uint64(1400000128000000500), 0, 1)])
+        self.assertEqual(
+            timestamps,
+            [
+                (uint64(1400000002_000000510), 1, 1),
+                (uint64(1400000030_000000000), 1, 0),
+                (uint64(1400000112_000000050), 0, 0),
+                (uint64(1400000128_000000500), 0, 1),
+            ],
+        )
         timestamps = self.c._retrieve_timestamps(stations, shifts=[None, 60])
-        self.assertEqual(timestamps,
-                         [(uint64(1400000002000000050), 0, 0), (uint64(1400000018000000500), 0, 1),
-                          (uint64(1400000062000000510), 1, 1), (uint64(1400000090000000000), 1, 0)])
+        self.assertEqual(
+            timestamps,
+            [
+                (uint64(1400000002_000000050), 0, 0),
+                (uint64(1400000018_000000500), 0, 1),
+                (uint64(1400000062_000000510), 1, 1),
+                (uint64(1400000090_000000000), 1, 0),
+            ],
+        )
         # Subsecond shifts
         timestamps = self.c._retrieve_timestamps(stations, shifts=[3e-9, 5e-9])
-        self.assertEqual(timestamps,
-                         [(uint64(1400000002000000053), 0, 0), (uint64(1400000002000000515), 1, 1),
-                          (uint64(1400000018000000503), 0, 1), (uint64(1400000030000000005), 1, 0)])
+        self.assertEqual(
+            timestamps,
+            [
+                (uint64(1400000002_000000053), 0, 0),
+                (uint64(1400000002_000000515), 1, 1),
+                (uint64(1400000018_000000503), 0, 1),
+                (uint64(1400000030_000000005), 1, 0),
+            ],
+        )
         # Using limits
         timestamps = self.c._retrieve_timestamps(stations, limit=1)
-        self.assertEqual(timestamps,
-                         [(uint64(1400000002000000050), 0, 0), (uint64(1400000030000000000), 1, 0)])
-        # This should fail but does not
-        self.assertEqual(timestamps,
-                         [(1400000002000000049, 0, 0), (1400000030000000000, 1, 0)])
-        # Using uint64 does work correctly
-        self.assertNotEqual(timestamps,
-                            [(uint64(1400000002000000049), 0, 0), (uint64(1400000030000000000), 1, 0)])
-        self.assertNotEqual(timestamps,
-                            [(uint64(1400000002000000051), 0, 0), (uint64(1400000030000000001), 1, 0)])
+
+        # Check accuracy of comparisons between different types
+        self.assertEqual(timestamps, [(1400000002_000000050, 0, 0), (1400000030_000000000, 1, 0)])
+        self.assertEqual(timestamps, [(uint64(1400000002_000000050), 0, 0), (uint64(1400000030_000000000), 1, 0)])
+        self.assertNotEqual(timestamps, [(1400000002_000000049, 0, 0), (1400000030_000000000, 1, 0)])
+        self.assertNotEqual(timestamps, [(1400000002_000000051, 0, 0), (1400000030_000000000, 1, 0)])
+        self.assertNotEqual(timestamps, [(uint64(1400000002_000000049), 0, 0), (uint64(1400000030_000000000), 1, 0)])
+        self.assertNotEqual(timestamps, [(uint64(1400000002_000000051), 0, 0), (uint64(1400000030_000000001), 1, 0)])
 
     def test__do_search_coincidences(self):
         # [(timestamp, station_idx, event_idx), ..]
-        timestamps = [(uint64(0), 0, 0), (uint64(0), 1, 0), (uint64(10), 1, 1),
-                      (uint64(15), 2, 0), (uint64(100), 1, 2), (uint64(200), 2, 1),
-                      (uint64(250), 0, 1), (uint64(251), 0, 2)]
+        timestamps = [
+            (uint64(0), 0, 0),
+            (uint64(0), 1, 0),
+            (uint64(10), 1, 1),
+            (uint64(15), 2, 0),
+            (uint64(100), 1, 2),
+            (uint64(200), 2, 1),
+            (uint64(250), 0, 1),
+            (uint64(251), 0, 2),
+        ]
 
         c = self.c._do_search_coincidences(timestamps, window=6)
         expected_coincidences = [[0, 1], [2, 3], [6, 7]]
         self.assertEqual(c, expected_coincidences)
 
         c = self.c._do_search_coincidences(timestamps, window=150)
         expected_coincidences = [[0, 1, 2, 3, 4], [4, 5], [5, 6, 7]]
@@ -102,15 +136,14 @@
 
         c = self.c._do_search_coincidences(timestamps, window=300)
         expected_coincidences = [[0, 1, 2, 3, 4, 5, 6, 7]]
         self.assertEqual(c, expected_coincidences)
 
 
 class CoincidencesESDTests(CoincidencesTests):
-
     @patch.object(coincidences.tables, 'open_file')
     def setUp(self, mock_open_file):
         self.mock_open_file = mock_open_file
         self.c = coincidences.CoincidencesESD(sentinel.data, None, sentinel.station_groups, progress=False)
 
     @patch.object(coincidences.CoincidencesESD, 'search_coincidences')
     @patch.object(coincidences.CoincidencesESD, 'store_coincidences')
@@ -131,27 +164,22 @@
         self.assertEqual(self.c._src_c_index, sentinel.c_index)
 
         self.c.search_coincidences(sentinel.window, sentinel.shifts, sentinel.limit)
         mock__search.assert_called_with(sentinel.window, sentinel.shifts, sentinel.limit)
 
 
 class CoincidencesDataTests(unittest.TestCase):
-
     def setUp(self):
         self.data_path = self.create_tempfile_from_testdata()
-
-    def tearDown(self):
-        os.remove(self.data_path)
+        self.addCleanup(os.remove, self.data_path)
 
     def test_coincidencesesd_output(self):
         with tables.open_file(self.data_path, 'a') as data:
             with patch('sapphire.analysis.process_events.ProcessIndexedEventsWithoutTraces'):
-                c = coincidences.Coincidences(data, '/coincidences',
-                                              ['/station_501', '/station_502'],
-                                              progress=False)
+                c = coincidences.Coincidences(data, '/coincidences', ['/station_501', '/station_502'], progress=False)
                 c.search_and_store_coincidences()
 
         validate_results(self, self.get_testdata_path(), self.data_path)
 
     def create_tempfile_from_testdata(self):
         tmp_path = self.create_tempfile_path()
         data_path = self.get_testdata_path()
@@ -170,24 +198,17 @@
 
     def remove_existing_coincidences(self, path):
         with tables.open_file(path, 'a') as data:
             data.remove_node('/coincidences', recursive=True)
 
 
 class CoincidencesESDDataTests(CoincidencesDataTests):
-
     def test_coincidencesesd_output(self):
         with tables.open_file(self.data_path, 'a') as data:
-            c = coincidences.CoincidencesESD(data, '/coincidences',
-                                             ['/station_501', '/station_502'],
-                                             progress=False)
+            c = coincidences.CoincidencesESD(data, '/coincidences', ['/station_501', '/station_502'], progress=False)
             self.assertRaises(RuntimeError, c.search_and_store_coincidences, station_numbers=[501])
             c.search_and_store_coincidences(station_numbers=[501, 502])
         validate_results(self, self.get_testdata_path(), self.data_path)
 
     def get_testdata_path(self):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_DATA_ESD)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_core_reconstruction.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_core_reconstruction.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,49 +1,41 @@
 import unittest
 
 from sapphire.analysis import core_reconstruction
 
 
 class BaseAlgorithm:
-
     """Use this class to check the different algorithms
 
     They should give similar results and errors in some cases.
 
     """
 
     def call_reconstruct(self, t, x, y, z):
         return self.algorithm.reconstruct_common(t, x, y, z)
 
     def test_stations_square(self):
         """Four detection points in a square shape."""
 
         # Same density
-        p = (1., 1., 1., 1.)
-        x = (0., 0., 10., 10.)
-        y = (0., 10., 10., 0.)
-        z = (0., 0., 0., 0.)
+        p = (1.0, 1.0, 1.0, 1.0)
+        x = (0.0, 0.0, 10.0, 10.0)
+        y = (0.0, 10.0, 10.0, 0.0)
+        z = (0.0, 0.0, 0.0, 0.0)
         result = self.call_reconstruct(p, x, y, z)
-        self.assertAlmostEqual(result[0], 5.)
-        self.assertAlmostEqual(result[1], 5.)
+        self.assertAlmostEqual(result[0], 5.0)
+        self.assertAlmostEqual(result[1], 5.0)
 
 
 class CenterMassAlgorithmTest(unittest.TestCase, BaseAlgorithm):
-
     def setUp(self):
         self.algorithm = core_reconstruction.CenterMassAlgorithm()
 
 
 class AverageIntersectionAlgorithmTest(unittest.TestCase, BaseAlgorithm):
-
     def setUp(self):
         self.algorithm = core_reconstruction.AverageIntersectionAlgorithm()
 
 
 class EllipsLdfAlgorithmTest(unittest.TestCase, BaseAlgorithm):
-
     def setUp(self):
         self.algorithm = core_reconstruction.EllipsLdfAlgorithm()
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_data/coincidences.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_data/coincidences.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_data/esd_coincidences.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_data/esd_coincidences.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_data/process_events.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_data/process_events.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_direction_reconstruction.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_direction_reconstruction.py`

 * *Files 17% similar despite different names*

```diff
@@ -6,15 +6,14 @@
 from numpy import arcsin, arctan, array, isnan, nan, pi, sqrt
 
 from sapphire.analysis import direction_reconstruction
 from sapphire.simulations.showerfront import ConeFront
 
 
 class EventDirectionReconstructionTest(unittest.TestCase):
-
     def test_init(self):
         dirrec = direction_reconstruction.EventDirectionReconstruction(sentinel.station)
         self.assertEqual(dirrec.direct, direction_reconstruction.DirectAlgorithmCartesian3D)
         self.assertEqual(dirrec.fit, direction_reconstruction.RegressionAlgorithm3D)
         self.assertEqual(dirrec.station, sentinel.station)
 
     def test_set_cluster_timestamp(self):
@@ -32,15 +31,15 @@
         dirrec = direction_reconstruction.EventDirectionReconstruction(station)
         theta, phi, ids = dirrec.reconstruct_event({'timestamp': sentinel.timestamp}, detector_ids=[0, 1])
         self.assertTrue(isnan(theta))
         self.assertTrue(isnan(phi))
 
     @patch.object(direction_reconstruction.event_utils, 'detector_arrival_time')
     def test_reconstruct_event(self, mock_detector_arrival_time):
-        mock_detector_arrival_time.return_value = 0.
+        mock_detector_arrival_time.return_value = 0.0
         station = MagicMock()
         detector = Mock()
         detector.get_coordinates.return_value = [sentinel.x, sentinel.y, sentinel.z]
         station.detectors.__getitem__.side_effect = lambda name: detector
         dirrec = direction_reconstruction.EventDirectionReconstruction(station)
         dirrec.direct = Mock()
         dirrec.fit = Mock()
@@ -54,56 +53,78 @@
         self.assertTrue(isnan(theta))
         self.assertTrue(isnan(phi))
         self.assertEqual(len(ids), 2)
 
         # Three detections, direct reconstruction
         theta, phi, ids = dirrec.reconstruct_event(event, detector_ids=[0, 1, 2])
         dirrec.direct.reconstruct_common.assert_called_once_with(
-            [0.] * 3, [sentinel.x] * 3, [sentinel.y] * 3, [sentinel.z] * 3, None)
+            [0.0] * 3,
+            [sentinel.x] * 3,
+            [sentinel.y] * 3,
+            [sentinel.z] * 3,
+            None,
+        )
         dirrec.fit.reconstruct_common.assert_not_called()
         self.assertEqual(theta, sentinel.theta)
         self.assertEqual(phi, sentinel.phi)
         self.assertEqual(len(ids), 3)
 
         # Four detections, fit reconstruction
         theta, phi, ids = dirrec.reconstruct_event(event, detector_ids=[0, 1, 2, 3])
         self.assertEqual(dirrec.direct.reconstruct_common.call_count, 1)
         dirrec.fit.reconstruct_common.assert_called_once_with(
-            [0.] * 4, [sentinel.x] * 4, [sentinel.y] * 4, [sentinel.z] * 4, None)
+            [0.0] * 4,
+            [sentinel.x] * 4,
+            [sentinel.y] * 4,
+            [sentinel.z] * 4,
+            None,
+        )
         self.assertEqual(theta, sentinel.theta)
         self.assertEqual(phi, sentinel.phi)
         self.assertEqual(len(ids), 4)
         theta, phi, ids = dirrec.reconstruct_event(event, detector_ids=None)
         dirrec.fit.reconstruct_common.assert_called_with(
-            [0.] * 4, [sentinel.x] * 4, [sentinel.y] * 4, [sentinel.z] * 4, None)
+            [0.0] * 4,
+            [sentinel.x] * 4,
+            [sentinel.y] * 4,
+            [sentinel.z] * 4,
+            None,
+        )
         self.assertEqual(dirrec.fit.reconstruct_common.call_count, 2)
 
         # Four detections, fit reconstruction with offsets
         offsets = MagicMock(spec=direction_reconstruction.Station)
         offsets.detector_timing_offset.return_value = [sentinel.offset] * 4
         theta, phi, ids = dirrec.reconstruct_event(event, detector_ids=[0, 1, 2, 3], offsets=offsets)
         offsets.detector_timing_offset.assert_called_once_with(sentinel.timestamp)
         mock_detector_arrival_time.assert_called_with(event, 3, offsets.detector_timing_offset.return_value)
 
     @patch.object(direction_reconstruction.EventDirectionReconstruction, 'reconstruct_event')
     def test_reconstruct_events(self, mock_reconstruct_event):
         mock_reconstruct_event.return_value = [sentinel.theta, sentinel.phi, sentinel.ids]
         dirrec = direction_reconstruction.EventDirectionReconstruction(sentinel.station)
-        self.assertEqual(dirrec.reconstruct_events([sentinel.event, sentinel.event],
-                                                   sentinel.detector_ids, sentinel.offsets, progress=False),
-                         ((sentinel.theta, sentinel.theta), (sentinel.phi, sentinel.phi), (sentinel.ids, sentinel.ids)))
+        self.assertEqual(
+            dirrec.reconstruct_events(
+                [sentinel.event, sentinel.event],
+                sentinel.detector_ids,
+                sentinel.offsets,
+                progress=False,
+            ),
+            ((sentinel.theta, sentinel.theta), (sentinel.phi, sentinel.phi), (sentinel.ids, sentinel.ids)),
+        )
         self.assertEqual(mock_reconstruct_event.call_count, 2)
         mock_reconstruct_event.assert_called_with(sentinel.event, sentinel.detector_ids, sentinel.offsets, None)
-        self.assertEqual(dirrec.reconstruct_events([], sentinel.detector_ids, sentinel.offsets, progress=False),
-                         ((), (), ()))
+        self.assertEqual(
+            dirrec.reconstruct_events([], sentinel.detector_ids, sentinel.offsets, progress=False),
+            ((), (), ()),
+        )
         self.assertEqual(mock_reconstruct_event.call_count, 2)
 
 
 class CoincidenceDirectionReconstructionTest(unittest.TestCase):
-
     def setUp(self):
         self.dirrec = direction_reconstruction.CoincidenceDirectionReconstruction(sentinel.cluster)
 
     def test_init(self):
         dirrec = direction_reconstruction.CoincidenceDirectionReconstruction(sentinel.cluster)
         self.assertEqual(dirrec.direct, direction_reconstruction.DirectAlgorithmCartesian3D)
         self.assertEqual(dirrec.fit, direction_reconstruction.RegressionAlgorithm3D)
@@ -118,31 +139,34 @@
         cluster.set_timestamp.assert_called_with(1)
         self.assertTrue(isnan(theta))
         self.assertTrue(isnan(phi))
 
     @patch.object(direction_reconstruction.event_utils, 'station_arrival_time')
     def test_reconstruct_coincidence(self, mock_station_arrival_time):
         dirrec = self.dirrec
-        mock_station_arrival_time.return_value = 0.
+        mock_station_arrival_time.return_value = 0.0
         cluster = MagicMock()
         station = MagicMock()
         cluster.get_station.return_value = station
         station.calc_center_of_mass_coordinates.return_value = [sentinel.x, sentinel.y, sentinel.z]
         dirrec.cluster = cluster
         dirrec.direct = Mock()
         dirrec.fit = Mock()
         dirrec.curved = Mock()
         dirrec.direct.reconstruct_common.return_value = (sentinel.theta, sentinel.phi)
         dirrec.fit.reconstruct_common.return_value = (sentinel.theta, sentinel.phi)
         dirrec.curved.reconstruct_common.return_value = (sentinel.theta, sentinel.phi)
         coincidence_2 = [[sentinel.station_number, {'timestamp': 1}], [1, sentinel.event]]
-        coincidence_3 = [[sentinel.station_number, {'timestamp': 1}], [1, sentinel.event],
-                         [2, sentinel.event]]
-        coincidence_4 = [[sentinel.station_number, {'timestamp': 1}], [1, sentinel.event],
-                         [2, sentinel.event], [3, sentinel.event]]
+        coincidence_3 = [[sentinel.station_number, {'timestamp': 1}], [1, sentinel.event], [2, sentinel.event]]
+        coincidence_4 = [
+            [sentinel.station_number, {'timestamp': 1}],
+            [1, sentinel.event],
+            [2, sentinel.event],
+            [3, sentinel.event],
+        ]
 
         # To few events
         theta, phi, nums = dirrec.reconstruct_coincidence(coincidence_2)
         self.assertTrue(isnan(theta))
         self.assertTrue(isnan(phi))
         self.assertEqual(len(nums), 0)
 
@@ -153,25 +177,35 @@
         self.assertTrue(isnan(phi))
         self.assertEqual(len(nums), 2)
 
         # Three events, no initial core, direct reconstruction
         theta, phi, nums = dirrec.reconstruct_coincidence(coincidence_3)
         cluster.set_timestamp.assert_called_with(1)
         dirrec.direct.reconstruct_common.assert_called_once_with(
-            [0.] * 3, [sentinel.x] * 3, [sentinel.y] * 3, [sentinel.z] * 3, {})
+            [0.0] * 3,
+            [sentinel.x] * 3,
+            [sentinel.y] * 3,
+            [sentinel.z] * 3,
+            {},
+        )
         dirrec.fit.reconstruct_common.assert_not_called()
         self.assertEqual(theta, sentinel.theta)
         self.assertEqual(phi, sentinel.phi)
         self.assertEqual(len(nums), 3)
 
         # Four events, no initial core, fit reconstruction
         theta, phi, nums = dirrec.reconstruct_coincidence(coincidence_4)
         cluster.set_timestamp.assert_called_with(1)
         dirrec.fit.reconstruct_common.assert_called_once_with(
-            [0.] * 4, [sentinel.x] * 4, [sentinel.y] * 4, [sentinel.z] * 4, {})
+            [0.0] * 4,
+            [sentinel.x] * 4,
+            [sentinel.y] * 4,
+            [sentinel.z] * 4,
+            {},
+        )
         self.assertEqual(dirrec.direct.reconstruct_common.call_count, 1)
         dirrec.curved.reconstruct_common.assert_not_called()
         self.assertEqual(theta, sentinel.theta)
         self.assertEqual(phi, sentinel.phi)
         self.assertEqual(len(nums), 4)
 
         # Four events, with initial core, curved reconstruction
@@ -193,124 +227,118 @@
         self.assertTrue(isnan(theta))
         self.assertTrue(isnan(phi))
         self.assertEqual(len(nums), 0)
 
     @patch.object(direction_reconstruction.CoincidenceDirectionReconstruction, 'reconstruct_coincidence')
     def test_reconstruct_coincidences(self, mock_reconstruct_coincidence):
         mock_reconstruct_coincidence.return_value = [sentinel.theta, sentinel.phi, sentinel.nums]
-        self.assertEqual(self.dirrec.reconstruct_coincidences([sentinel.coincidence, sentinel.coincidence],
-                                                              sentinel.station_numbers, sentinel.offsets, progress=False),
-                         ((sentinel.theta, sentinel.theta), (sentinel.phi, sentinel.phi), (sentinel.nums, sentinel.nums)))
+        self.assertEqual(
+            self.dirrec.reconstruct_coincidences(
+                [sentinel.coincidence, sentinel.coincidence],
+                sentinel.station_numbers,
+                sentinel.offsets,
+                progress=False,
+            ),
+            ((sentinel.theta, sentinel.theta), (sentinel.phi, sentinel.phi), (sentinel.nums, sentinel.nums)),
+        )
         self.assertEqual(mock_reconstruct_coincidence.call_count, 2)
-        mock_reconstruct_coincidence.assert_called_with(sentinel.coincidence, sentinel.station_numbers, sentinel.offsets, None)
-        self.assertEqual(self.dirrec.reconstruct_coincidences([], sentinel.station_numbers, sentinel.offsets, progress=False),
-                         ((), (), ()))
+        mock_reconstruct_coincidence.assert_called_with(
+            sentinel.coincidence,
+            sentinel.station_numbers,
+            sentinel.offsets,
+            None,
+        )
+        self.assertEqual(
+            self.dirrec.reconstruct_coincidences([], sentinel.station_numbers, sentinel.offsets, progress=False),
+            ((), (), ()),
+        )
         self.assertEqual(mock_reconstruct_coincidence.call_count, 2)
 
     def test_get_station_offsets(self):
         dirrec = self.dirrec
         mock_offsets = Mock()
         mock_offsets.return_value = sentinel.best_offset
         dirrec.determine_best_offsets = mock_offsets
         coincidence_events = [(sentinel.sn1, None)]
         station_numbers = None
         offsets = {}
         ts0 = 86400
-        result = dirrec.get_station_offsets(coincidence_events, station_numbers,
-                                            offsets, ts0)
+        result = dirrec.get_station_offsets(coincidence_events, station_numbers, offsets, ts0)
         self.assertEqual(result, offsets)
 
         offsets = {1: MagicMock(spec=direction_reconstruction.Station)}
-        result = dirrec.get_station_offsets(coincidence_events, station_numbers,
-                                            offsets, ts0)
+        result = dirrec.get_station_offsets(coincidence_events, station_numbers, offsets, ts0)
         self.assertEqual(result, sentinel.best_offset)
         mock_offsets.assert_called_once_with([sentinel.sn1], ts0, offsets)
 
         ts0 = 864000 + 12345
-        result = dirrec.get_station_offsets(coincidence_events, station_numbers,
-                                            offsets, ts0)
+        result = dirrec.get_station_offsets(coincidence_events, station_numbers, offsets, ts0)
         self.assertEqual(result, sentinel.best_offset)
         mock_offsets.assert_called_with([sentinel.sn1], 864000, offsets)
 
         station_numbers = sentinel.station_numbers
-        result = dirrec.get_station_offsets(coincidence_events, station_numbers,
-                                            offsets, ts0)
+        result = dirrec.get_station_offsets(coincidence_events, station_numbers, offsets, ts0)
         self.assertEqual(result, sentinel.best_offset)
         mock_offsets.assert_called_with(sentinel.station_numbers, 864000, offsets)
 
     def test_determine_best_offsets(self):
         dirrec = self.dirrec
         mock_offsets = Mock()
         mock_offsets.station_timing_offset.return_value = (1, 2)
         mock_offsets.detector_timing_offset.return_value = [1, 0, 2, 3]
         offsets = {sn: mock_offsets for sn in [1, 2, 3]}
         station_numbers = [1, 2]
         midnight_ts = sentinel.midnight_ts
         best_offsets = dirrec.determine_best_offsets(station_numbers, midnight_ts, offsets)
         self.assertEqual(list(best_offsets.keys()), station_numbers)
-        self.assertEqual(list(best_offsets.values()), [[1.0, 0.0, 2.0, 3.0],
-                                                       [2.0, 1.0, 3.0, 4.0]])
+        self.assertEqual(list(best_offsets.values()), [[1.0, 0.0, 2.0, 3.0], [2.0, 1.0, 3.0, 4.0]])
 
     def test_determine_best_reference(self):
         # last station would be best reference, but not in station_numbers
         # second and third station are tied, so second is best reference
-        error_matrix = array([[0, 5, 2, 1],
-                              [5, 0, 1, 1],
-                              [2, 1, 0, 1],
-                              [1, 1, 1, 0]])
+        error_matrix = array([[0, 5, 2, 1], [5, 0, 1, 1], [2, 1, 0, 1], [1, 1, 1, 0]])
         station_numbers = [1, 2, 3]
         ref, pred = self.dirrec.determine_best_reference(error_matrix, station_numbers)
         self.assertEqual(ref, 2)
-        predecessors = array([[-9999, 3, 0, 0],
-                              [3, -9999, 1, 1],
-                              [2, 2, -9999, 2],
-                              [3, 3, 3, -9999]])
+        predecessors = array([[-9999, 3, 0, 0], [3, -9999, 1, 1], [2, 2, -9999, 2], [3, 3, 3, -9999]])
         self.assertEqual(pred.tolist(), predecessors.tolist())
 
     def test__reconstruct_best_offset(self):
         offset = self.dirrec._reconstruct_best_offset([], 1, 1, [], [])
         self.assertEqual(offset, 0)
 
-        predecessors = array([[-9999, 0, 1],
-                              [1, -9999, 1],
-                              [1, 2, -9999]])
-        offset_matrix = array([[0, -1, -1],
-                               [1, 0, -1],
-                               [1, 1, 0]])
+        predecessors = array([[-9999, 0, 1], [1, -9999, 1], [1, 2, -9999]])
+        offset_matrix = array([[0, -1, -1], [1, 0, -1], [1, 1, 0]])
         station_numbers = [1, 2, 3]
 
-        combinations = [(1, 1, 0),
-                        (1, 2, 1),
-                        (1, 3, 2),
-                        (2, 3, 1)]
+        combinations = [(1, 1, 0), (1, 2, 1), (1, 3, 2), (2, 3, 1)]
         for sn1, sn2, offset in combinations:
             o12 = self.dirrec._reconstruct_best_offset(predecessors, sn1, sn2, station_numbers, offset_matrix)
             o21 = self.dirrec._reconstruct_best_offset(predecessors, sn2, sn1, station_numbers, offset_matrix)
             self.assertEqual(offset, o12)
             self.assertEqual(o21, -o12)
 
     def test__calculate_offsets(self):
         mock_station = Mock()
-        mock_station.detector_timing_offset.return_value = [0., 1., 2., 3.]
-        offset = 1.
+        mock_station.detector_timing_offset.return_value = [0.0, 1.0, 2.0, 3.0]
+        offset = 1.0
         ts0 = sentinel.timestamp
         offsets = self.dirrec._calculate_offsets(mock_station, ts0, offset)
         mock_station.detector_timing_offset.assert_called_once_with(ts0)
-        self.assertEqual(offsets, [1., 2., 3., 4.])
+        self.assertEqual(offsets, [1.0, 2.0, 3.0, 4.0])
 
 
 class CoincidenceDirectionReconstructionDetectorsTest(CoincidenceDirectionReconstructionTest):
-
     def setUp(self):
         self.dirrec = direction_reconstruction.CoincidenceDirectionReconstructionDetectors(sentinel.cluster)
 
     @patch.object(direction_reconstruction.event_utils, 'relative_detector_arrival_times')
     def test_reconstruct_coincidence(self, mock_arrival_times):
         dirrec = self.dirrec
-        mock_arrival_times.return_value = [0., 0., nan, nan]
+        mock_arrival_times.return_value = [0.0, 0.0, nan, nan]
         cluster = MagicMock()
         station = MagicMock()
         cluster.get_station.return_value = station
         detector = MagicMock()
         detector.get_coordinates.return_value = [sentinel.x, sentinel.y, sentinel.z]
         station.detectors = [detector] * 4
         dirrec.cluster = cluster
@@ -319,18 +347,21 @@
         dirrec.curved = Mock()
         dirrec.direct.reconstruct_common.return_value = (sentinel.theta, sentinel.phi)
         dirrec.fit.reconstruct_common.return_value = (sentinel.theta, sentinel.phi)
         dirrec.curved.reconstruct_common.return_value = (sentinel.theta, sentinel.phi)
         coincidence_0 = []
         coincidence_1 = [[sentinel.station_number, {'timestamp': 1}]]
         coincidence_2 = [[sentinel.station_number, {'timestamp': 1}], [1, sentinel.event]]
-        coincidence_3 = [[sentinel.station_number, {'timestamp': 1}], [1, sentinel.event],
-                         [2, sentinel.event]]
-        coincidence_4 = [[sentinel.station_number, {'timestamp': 1}], [1, sentinel.event],
-                         [2, sentinel.event], [3, sentinel.event]]
+        coincidence_3 = [[sentinel.station_number, {'timestamp': 1}], [1, sentinel.event], [2, sentinel.event]]
+        coincidence_4 = [
+            [sentinel.station_number, {'timestamp': 1}],
+            [1, sentinel.event],
+            [2, sentinel.event],
+            [3, sentinel.event],
+        ]
 
         # To few detection points, no reconstruction
         theta, phi, nums = dirrec.reconstruct_coincidence(coincidence_0)
         self.assertTrue(isnan(theta))
         self.assertTrue(isnan(phi))
         self.assertEqual(len(nums), 0)
 
@@ -347,15 +378,20 @@
         self.assertTrue(isnan(phi))
         self.assertEqual(len(nums), 1)
 
         # Two stations with four detection points, fit reconstruction
         theta, phi, nums = dirrec.reconstruct_coincidence(coincidence_2)
         cluster.set_timestamp.assert_called_with(1)
         dirrec.fit.reconstruct_common.assert_called_once_with(
-            [0.] * 4, [sentinel.x] * 4, [sentinel.y] * 4, [sentinel.z] * 4, {})
+            [0.0] * 4,
+            [sentinel.x] * 4,
+            [sentinel.y] * 4,
+            [sentinel.z] * 4,
+            {},
+        )
         self.assertEqual(dirrec.fit.reconstruct_common.call_count, 1)
         self.assertEqual(theta, sentinel.theta)
         self.assertEqual(phi, sentinel.phi)
         self.assertEqual(len(nums), 2)
 
         # Four events with eight detection points and initial core,
         # curved reconstruction
@@ -363,21 +399,26 @@
         theta, phi, nums = dirrec.reconstruct_coincidence(coincidence_4, initial=initial)
         cluster.set_timestamp.assert_called_with(1)
         self.assertEqual(dirrec.curved.reconstruct_common.call_count, 1)
         self.assertEqual(theta, sentinel.theta)
         self.assertEqual(phi, sentinel.phi)
         self.assertEqual(len(nums), 4)
 
-        mock_arrival_times.return_value = [0., nan, nan, nan]
+        mock_arrival_times.return_value = [0.0, nan, nan, nan]
 
         # Three stations with three detection points, direct reconstruction
         theta, phi, nums = dirrec.reconstruct_coincidence(coincidence_3)
         cluster.set_timestamp.assert_called_with(1)
         dirrec.direct.reconstruct_common.assert_called_once_with(
-            [0.] * 3, [sentinel.x] * 3, [sentinel.y] * 3, [sentinel.z] * 3, {})
+            [0.0] * 3,
+            [sentinel.x] * 3,
+            [sentinel.y] * 3,
+            [sentinel.z] * 3,
+            {},
+        )
         self.assertEqual(dirrec.direct.reconstruct_common.call_count, 1)
         self.assertEqual(theta, sentinel.theta)
         self.assertEqual(phi, sentinel.phi)
         self.assertEqual(len(nums), 3)
 
         mock_arrival_times.return_value = [nan] * 4
 
@@ -390,405 +431,395 @@
         self.assertTrue(isnan(theta))
         self.assertTrue(isnan(phi))
         self.assertEqual(len(nums), 0)
 
     @patch.object(direction_reconstruction.CoincidenceDirectionReconstructionDetectors, 'reconstruct_coincidence')
     def test_reconstruct_coincidences(self, mock_reconstruct_coincidence):
         mock_reconstruct_coincidence.return_value = [sentinel.theta, sentinel.phi, sentinel.nums]
-        self.assertEqual(self.dirrec.reconstruct_coincidences([sentinel.coincidence, sentinel.coincidence],
-                                                              sentinel.station_numbers, sentinel.offsets, progress=False),
-                         ((sentinel.theta, sentinel.theta), (sentinel.phi, sentinel.phi), (sentinel.nums, sentinel.nums)))
+        self.assertEqual(
+            self.dirrec.reconstruct_coincidences(
+                [sentinel.coincidence, sentinel.coincidence],
+                sentinel.station_numbers,
+                sentinel.offsets,
+                progress=False,
+            ),
+            ((sentinel.theta, sentinel.theta), (sentinel.phi, sentinel.phi), (sentinel.nums, sentinel.nums)),
+        )
         self.assertEqual(mock_reconstruct_coincidence.call_count, 2)
-        mock_reconstruct_coincidence.assert_called_with(sentinel.coincidence, sentinel.station_numbers, sentinel.offsets, None)
-        self.assertEqual(self.dirrec.reconstruct_coincidences([], sentinel.station_numbers, sentinel.offsets, progress=False),
-                         ((), (), ()))
+        mock_reconstruct_coincidence.assert_called_with(
+            sentinel.coincidence,
+            sentinel.station_numbers,
+            sentinel.offsets,
+            None,
+        )
+        self.assertEqual(
+            self.dirrec.reconstruct_coincidences([], sentinel.station_numbers, sentinel.offsets, progress=False),
+            ((), (), ()),
+        )
         self.assertEqual(mock_reconstruct_coincidence.call_count, 2)
 
 
 class BaseAlgorithm:
-
     """Use this class to check the different algorithms
 
     This provides a shortcut to call the reconstruct_common method.
 
     """
 
     def call_reconstruct(self, t, x, y, z, initial=None):
         return self.algorithm.reconstruct_common(t, x, y, z, initial)
 
 
 class FlatAlgorithm(BaseAlgorithm):
-
     """Use this class to test algorithms for flat shower fronts.
 
     They should give similar results and errors in some cases.
     These tests use three detections at same height.
 
     """
 
     def test_stations_in_line(self):
         """Three detection points on a line do not provide a solution."""
 
         # On a line in x
-        t = (0., 2., 3.)
-        x = (0., 0., 0.)  # same x
-        y = (0., 5., 10.)
-        z = (0., 0., 0.)  # same z
+        t = (0.0, 2.0, 3.0)
+        x = (0.0, 0.0, 0.0)  # same x
+        y = (0.0, 5.0, 10.0)
+        z = (0.0, 0.0, 0.0)  # same z
         result = self.call_reconstruct(t, x, y, z)
         self.assertTrue(isnan(result).all())
 
         # Diagonal line
-        t = (0., 2., 3.)
-        x = (0., 5., 10.)
-        y = (0., 5., 10.)
-        z = (0., 0., 0.)  # same z
+        t = (0.0, 2.0, 3.0)
+        x = (0.0, 5.0, 10.0)
+        y = (0.0, 5.0, 10.0)
+        z = (0.0, 0.0, 0.0)  # same z
         result = self.call_reconstruct(t, x, y, z)
         self.assertTrue(isnan(result).all())
 
     def test_same_stations(self):
         """Multiple detections at same point make reconstruction impossible.
 
         With different arrival time.
 
         """
         # Two at same location
-        t = (0., 2., 3.)
-        x = (0., 0., 1.)
-        y = (5., 5., 6.)
-        z = (0., 0., 1.)
+        t = (0.0, 2.0, 3.0)
+        x = (0.0, 0.0, 1.0)
+        y = (5.0, 5.0, 6.0)
+        z = (0.0, 0.0, 1.0)
         result = self.call_reconstruct(t, x, y, z)
         self.assertTrue(isnan(result).all())
 
-        t = (0., 2., 3.)
-        x = (0., 1., 0.)
-        y = (5., 6., 5.)
-        z = (0., 1., 0.)
+        t = (0.0, 2.0, 3.0)
+        x = (0.0, 1.0, 0.0)
+        y = (5.0, 6.0, 5.0)
+        z = (0.0, 1.0, 0.0)
         result = self.call_reconstruct(t, x, y, z)
         self.assertTrue(isnan(result).all())
 
-        t = (0., 2., 3.)
-        x = (1., 0., 0.)
-        y = (6., 5., 5.)
-        z = (1., 0., 0.)
+        t = (0.0, 2.0, 3.0)
+        x = (1.0, 0.0, 0.0)
+        y = (6.0, 5.0, 5.0)
+        z = (1.0, 0.0, 0.0)
         result = self.call_reconstruct(t, x, y, z)
         self.assertTrue(isnan(result).all())
 
         # Three at same location
-        t = (0., 2., 3.)
-        x = (0., 0., 0.)  # same x
-        y = (5., 5., 5.)  # same y
-        z = (0., 0., 0.)  # same z
+        t = (0.0, 2.0, 3.0)
+        x = (0.0, 0.0, 0.0)  # same x
+        y = (5.0, 5.0, 5.0)  # same y
+        z = (0.0, 0.0, 0.0)  # same z
         result = self.call_reconstruct(t, x, y, z)
         self.assertTrue(isnan(result).all())
 
     def test_shower_from_above(self):
         """Simple shower from zenith, azimuth can be any allowed value."""
 
-        t = (0., 0., 0.)  # same t
-        x = (0., 10., 0.)
-        y = (0., 0., 10.)
-        z = (0., 0., 0.)  # same z
+        t = (0.0, 0.0, 0.0)  # same t
+        x = (0.0, 10.0, 0.0)
+        y = (0.0, 0.0, 10.0)
+        z = (0.0, 0.0, 0.0)  # same z
         theta, phi = self.call_reconstruct(t, x, y, z)
-        self.assertAlmostEqual(theta, 0., 4)
+        self.assertAlmostEqual(theta, 0.0, 4)
         # azimuth can be any value between -pi and pi
         self.assertTrue(-pi <= phi < pi)
 
     def test_to_large_dt(self):
         """Time difference larger than expected by speed of light."""
 
         # TODO: Add better test with smaller tolerance
 
-        x = (0., -5., 5.)
-        y = (sqrt(100 - 25), 0., 0.)
-        z = (0., 0., 0.)
+        x = (0.0, -5.0, 5.0)
+        y = (sqrt(100 - 25), 0.0, 0.0)
+        z = (0.0, 0.0, 0.0)
 
-        t = (35., 0., 0.)
+        t = (35.0, 0.0, 0.0)
         theta, phi = self.call_reconstruct(t, x, y, z)
         self.assertTrue(isnan(theta))
 
     def test_showers_at_various_angles(self):
         """Simple shower from specific zenith angles."""
 
         c = 0.299792458
 
-        x = (0., -5., 5.)
-        y = (sqrt(100 - 25), 0., 0.)
-        z = (0., 0., 0.)
+        x = (0.0, -5.0, 5.0)
+        y = (sqrt(100 - 25), 0.0, 0.0)
+        z = (0.0, 0.0, 0.0)
 
         # triangle height
         h = sqrt(100 - 25)
 
-        times = (2.5, 5., 7.5, 10., 12.5, 15., 17.5, 20., 22.5, 25., 27.5)
+        times = (2.5, 5.0, 7.5, 10.0, 12.5, 15.0, 17.5, 20.0, 22.5, 25.0, 27.5)
 
         for time in times:
             for i in range(3):
                 zenith = arcsin((time * c) / h)
 
-                t = [0., 0., 0.]
+                t = [0.0, 0.0, 0.0]
                 t[i] = time
                 azimuths = [-pi / 2, pi / 6, pi * 5 / 6]
                 theta, phi = self.call_reconstruct(t, x, y, z)
                 self.assertAlmostEqual(phi, azimuths[i], 4)
                 self.assertAlmostEqual(theta, zenith, 4)
                 # Compare with z=None, should default to 0
                 theta_no_z, phi_no_z = self.call_reconstruct(t, x, y, None)
                 self.assertEqual((theta, phi), (theta_no_z, phi_no_z))
 
                 t = [time] * 3
-                t[i] = 0.
+                t[i] = 0.0
                 azimuths = [pi / 2, -pi * 5 / 6, -pi / 6]
                 theta, phi = self.call_reconstruct(t, x, y, z)
                 self.assertAlmostEqual(phi, azimuths[i], 4)
                 self.assertAlmostEqual(theta, zenith, 4)
                 # Compare with z=None, should default to 0
                 theta_no_z, phi_no_z = self.call_reconstruct(t, x, y, None)
                 self.assertEqual((theta, phi), (theta_no_z, phi_no_z))
 
 
 class DirectAlgorithm(FlatAlgorithm):
-
     """Use this class to check algorithms that only support three detections
 
     They should give similar warnings in some cases.
 
     """
 
     def test_to_many_stations(self):
         """To many stations should issue a warning.
 
         Moreover, the result should be based on the first three detections
 
         """
         # Shower from above (for first three detectors)
-        x = (0., 10., 0., 10.)
-        y = (0., 0., 10., 10.)
-        z = (0., 0., 0., 0.)
-        t = (0., 0., 0., 10.)
+        x = (0.0, 10.0, 0.0, 10.0)
+        y = (0.0, 0.0, 10.0, 10.0)
+        z = (0.0, 0.0, 0.0, 0.0)
+        t = (0.0, 0.0, 0.0, 10.0)
 
         with warnings.catch_warnings(record=True) as w:
-            warnings.simplefilter("always")
+            warnings.simplefilter('always')
             theta, phi = self.call_reconstruct(t, x, y, z)
             self.assertTrue(issubclass(w[0].category, UserWarning))
-            self.assertAlmostEqual(theta, 0., 4)
+            self.assertAlmostEqual(theta, 0.0, 4)
             self.assertTrue(-pi <= phi < pi)
 
 
 class AltitudeAlgorithm(FlatAlgorithm):
-
     """Use this class to check the altitude support
 
     They should give similar results and errors in some cases.
 
     """
 
     def test_stations_altitude(self):
         """Simple shower on a non horizontal square."""
 
-        x = (0., 10., 10.)
-        y = (0, 0., 10.)
-        z = (2., 0., -2.)
+        x = (0.0, 10.0, 10.0)
+        y = (0, 0.0, 10.0)
+        z = (2.0, 0.0, -2.0)
 
-        zenith = arctan(4. / 10. / sqrt(2))
+        zenith = arctan(4.0 / 10.0 / sqrt(2))
 
-        t = [0., 0., 0.]
-        azimuth = pi / 4.
+        t = [0.0, 0.0, 0.0]
+        azimuth = pi / 4.0
         theta, phi = self.call_reconstruct(t, x, y, z)
 
         self.assertAlmostEqual(phi, azimuth, 5)
         self.assertAlmostEqual(theta, zenith, 5)
 
 
 class DirectAltitudeAlgorithm(DirectAlgorithm, AltitudeAlgorithm):
-
     """Test algorithm that uses only 3 detectors and has altitude support."""
 
-    pass
-
 
 class MultiAlgorithm(FlatAlgorithm):
-
     """Use this class to check the different algorithms for more stations
 
     They should give similar results and errors in some cases.
 
     """
 
     def test_diamond_stations(self):
         """Simple shower from specific zenith angles."""
 
         c = 0.299792458
 
-        x = (0., -5., 5., 10.)
-        y = (sqrt(100 - 25), 0., 0., sqrt(100 - 25))
-        z = (0., 0., 0., 0.)
+        x = (0.0, -5.0, 5.0, 10.0)
+        y = (sqrt(100 - 25), 0.0, 0.0, sqrt(100 - 25))
+        z = (0.0, 0.0, 0.0, 0.0)
 
         # triangle height
         h = sqrt(100 - 25)
 
-        times = (2.5, 5., 7.5, 10., 12.5, 15., 17.5, 20., 22.5, 25., 27.5)
+        times = (2.5, 5.0, 7.5, 10.0, 12.5, 15.0, 17.5, 20.0, 22.5, 25.0, 27.5)
 
         for time in times:
             zenith = arcsin((time * c) / h)
             azimuth = pi / 6
 
-            t = [0., 0., 0., 0.]
+            t = [0.0, 0.0, 0.0, 0.0]
             t[1] = time
             t[3] = -time
             theta, phi = self.call_reconstruct(t, x, y, z)
             self.assertAlmostEqual(phi, azimuth, 5)
             self.assertAlmostEqual(theta, zenith, 5)
 
     def test_square_stations(self):
         """Simple shower from specific zenith angles."""
 
         c = 0.299792458
 
-        x = (0., 5., 5., 0.)
-        y = (0, 0., 5., 5.)
-        z = (0., 0., 0., 0.)
+        x = (0.0, 5.0, 5.0, 0.0)
+        y = (0, 0.0, 5.0, 5.0)
+        z = (0.0, 0.0, 0.0, 0.0)
 
         # triangle height
-        h = sqrt(50. / 4.)
+        h = sqrt(50.0 / 4.0)
 
-        times = (2.5, 5., 7.5, 10.)
+        times = (2.5, 5.0, 7.5, 10.0)
 
         for time in times:
             zenith = arcsin((time * c) / h)
-            azimuth = - 3 * pi / 4
+            azimuth = -3 * pi / 4
 
-            t = [0., 0., 0., 0.]
+            t = [0.0, 0.0, 0.0, 0.0]
             t[0] = -time
             t[2] = time
             theta, phi = self.call_reconstruct(t, x, y, z)
             self.assertAlmostEqual(phi, azimuth, 5)
             self.assertAlmostEqual(theta, zenith, 5)
 
 
 class MultiAltitudeAlgorithm(MultiAlgorithm, AltitudeAlgorithm):
-
     """Check some algorithms for multiple stations at different altitudes.
 
     They should give similar results and errors in some cases.
 
     """
 
     def test_hexagon_altitude(self):
         """Simple shower on a non horizontal square."""
 
-        x = (-5., 5., 10., 5., -5., -10.)
-        y = (-5. * sqrt(3), -5. * sqrt(3), 0., 5. * sqrt(3), 5. * sqrt(3), 0.)
-        z = (0., -3., -5., -3., 0., 4.)
+        x = (-5.0, 5.0, 10.0, 5.0, -5.0, -10.0)
+        y = (-5.0 * sqrt(3), -5.0 * sqrt(3), 0.0, 5.0 * sqrt(3), 5.0 * sqrt(3), 0.0)
+        z = (0.0, -3.0, -5.0, -3.0, 0.0, 4.0)
 
         zenith = 0.38333
         azimuth = 0.00000
 
-        t = [0., 0., 0., 0., 0., 0.]
+        t = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
         theta, phi = self.call_reconstruct(t, x, y, z)
 
         self.assertAlmostEqual(phi, azimuth, 4)
         self.assertAlmostEqual(theta, zenith, 4)
 
 
 class CurvedAlgorithm(BaseAlgorithm):
-
     """Check some algorithms supporting a curved shower front.
 
     They should give similar results and errors in some cases.
 
     """
 
     def test_curved_shower(self):
         """Simple curved shower on three detectors."""
 
-        t = (0., 0., 10.)
-        x = (0., 100., 50.)
-        y = (0., 0., 100.)
-        z = (0., 0., 0.)
+        t = (0.0, 0.0, 10.0)
+        x = (0.0, 100.0, 50.0)
+        y = (0.0, 0.0, 100.0)
+        z = (0.0, 0.0, 0.0)
         init = {'core_x': 50, 'core_y': 0}
 
         theta, phi = self.call_reconstruct(t, x, y, z, initial=init)
 
-        self.assertAlmostEqual(theta, 0., 4)
+        self.assertAlmostEqual(theta, 0.0, 4)
         self.assertTrue(-pi <= phi < pi)
 
 
 class CurvedAltitudeAlgorithm(CurvedAlgorithm):
-
     """Check algorithms for curved fronts and stations at different altitudes.
 
     They should give similar results and errors in some cases.
 
     """
 
     def test_curved_shower_on_stations_with_altitude(self):
         """Simple curved shower on three stations at different altitudes."""
 
         c = 0.299792458
 
-        z = (10, 0., 40.)
-        t = (-z[0] / c, 0., 10. - z[2] / c)
-        x = (0., 100., 50.)
-        y = (0., 0., 100.)
+        z = (10, 0.0, 40.0)
+        t = (-z[0] / c, 0.0, 10.0 - z[2] / c)
+        x = (0.0, 100.0, 50.0)
+        y = (0.0, 0.0, 100.0)
         init = {'core_x': 50, 'core_y': 0}
 
         theta, phi = self.call_reconstruct(t, x, y, z, initial=init)
 
-        self.assertAlmostEqual(theta, 0., 4)
+        self.assertAlmostEqual(theta, 0.0, 4)
         self.assertTrue(-pi <= phi < pi)
 
 
 class DirectAlgorithmTest(unittest.TestCase, DirectAlgorithm):
-
     def setUp(self):
         self.algorithm = direction_reconstruction.DirectAlgorithm()
 
 
 class DirectAlgorithmCartesianTest(unittest.TestCase, DirectAlgorithm):
-
     def setUp(self):
         self.algorithm = direction_reconstruction.DirectAlgorithmCartesian()
 
 
 class DirectAlgorithmCartesian3DTest(unittest.TestCase, DirectAltitudeAlgorithm):
-
     def setUp(self):
         self.algorithm = direction_reconstruction.DirectAlgorithmCartesian3D()
 
 
 class FitAlgorithm3DTest(unittest.TestCase, MultiAltitudeAlgorithm):
-
     def setUp(self):
         self.algorithm = direction_reconstruction.FitAlgorithm3D()
 
-    @unittest.expectedFailure
+    @unittest.skip('Fails on CI')
     def test_square_stations(self):
         super().test_square_stations()
 
 
 class RegressionAlgorithmTest(unittest.TestCase, MultiAlgorithm):
-
     def setUp(self):
         self.algorithm = direction_reconstruction.RegressionAlgorithm()
 
 
 class RegressionAlgorithm3DTest(unittest.TestCase, MultiAltitudeAlgorithm):
-
     def setUp(self):
         self.algorithm = direction_reconstruction.RegressionAlgorithm3D()
 
 
 class CurvedRegressionAlgorithmTest(unittest.TestCase, CurvedAlgorithm):
-
     def setUp(self):
         self.algorithm = direction_reconstruction.CurvedRegressionAlgorithm()
         self.algorithm.front = ConeFront()
 
 
 class CurvedRegressionAlgorithm3DTest(unittest.TestCase, CurvedAltitudeAlgorithm):
-
     def setUp(self):
         self.algorithm = direction_reconstruction.CurvedRegressionAlgorithm3D()
         self.algorithm.front = ConeFront()
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_event_utils.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_event_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 import unittest
 import warnings
 
+from itertools import repeat
 from unittest.mock import MagicMock, patch, sentinel
 
 from numpy import isnan, nan
 
 from sapphire.analysis import event_utils
 
 
 class StationDensityTests(unittest.TestCase):
-
     @patch.object(event_utils, 'detector_densities')
     @patch.object(event_utils, 'get_detector_ids')
     def test_station_density(self, mock_detector_ids, mock_detector_densities):
         mock_detector_ids.return_value = list(range(4))
         mock_detector_densities.return_value = [1, 1, 2, 2]
         self.assertEqual(event_utils.station_density(sentinel.event, list(range(4)), sentinel.station), 1.5)
         mock_detector_densities.return_value = [1, 1, nan, nan]
@@ -22,195 +22,214 @@
         self.assertEqual(event_utils.station_density(sentinel.event), 1)
         mock_detector_ids.assert_called_once_with(None, sentinel.event)
         self.assertEqual(event_utils.station_density(sentinel.event, station=sentinel.station), 1)
         mock_detector_ids.assert_called_with(sentinel.station, sentinel.event)
 
 
 class DetectorDensitiesTests(unittest.TestCase):
-
     @patch.object(event_utils, 'detector_density')
     @patch.object(event_utils, 'get_detector_ids')
     def test_detector_densities(self, mock_detector_ids, mock_detector_density):
         mock_detector_ids.return_value = list(range(4))
         mock_detector_density.return_value = sentinel.density
-        self.assertEqual(event_utils.detector_densities(sentinel.event, list(range(4))),
-                         [sentinel.density] * 4)
-        self.assertEqual(event_utils.detector_densities(sentinel.event, list(range(2))),
-                         [sentinel.density] * 2)
+        self.assertEqual(event_utils.detector_densities(sentinel.event, list(range(4))), [sentinel.density] * 4)
+        self.assertEqual(event_utils.detector_densities(sentinel.event, list(range(2))), [sentinel.density] * 2)
         mock_detector_ids.assert_not_called()
-        self.assertEqual(event_utils.detector_densities(sentinel.event),
-                         [sentinel.density] * 4)
+        self.assertEqual(event_utils.detector_densities(sentinel.event), [sentinel.density] * 4)
         mock_detector_ids.assert_called_once_with(None, sentinel.event)
-        self.assertEqual(event_utils.detector_densities(sentinel.event, station=sentinel.station),
-                         [sentinel.density] * 4)
+        self.assertEqual(
+            event_utils.detector_densities(sentinel.event, station=sentinel.station),
+            [sentinel.density] * 4,
+        )
         mock_detector_ids.assert_called_with(sentinel.station, sentinel.event)
 
 
 class DetectorDensityTests(unittest.TestCase):
-
     def setUp(self):
         self.event = MagicMock()
         self.station = MagicMock()
 
     def test_detector_density(self):
-        self.event.__getitem__.side_effect = lambda name: 2
+        self.event.__getitem__.side_effect = repeat(2)
         self.assertEqual(event_utils.detector_density(self.event, 0), 4)
         self.event.__getitem__.assert_called_with('n1')
 
     def test_no_good_detector_density(self):
-        self.event.__getitem__.side_effect = lambda name: -999
+        self.event.__getitem__.side_effect = repeat(-999)
         self.assertTrue(isnan(event_utils.detector_density(self.event, 0)))
         self.event.__getitem__.assert_called_with('n1')
 
 
 class StationArrivalTimeTests(unittest.TestCase):
-
     @patch.object(event_utils, 'detector_arrival_times')
     @patch.object(event_utils, 'get_detector_ids')
     def test_station_arrival_time(self, mock_detector_ids, mock_detector_arrival_times):
         mock_detector_ids.return_value = list(range(4))
-        mock_detector_arrival_times.return_value = [7.5, 5., 2.5, 5.]
+        mock_detector_arrival_times.return_value = [7.5, 5.0, 2.5, 5.0]
         event_dict = {'t_trigger': 10, 'ext_timestamp': 1000}
         event = MagicMock()
         event.__getitem__.side_effect = lambda name: event_dict[name]
         ref_ets = 500
         rel_arrival_time = event_dict['ext_timestamp'] - ref_ets - event_dict['t_trigger']
 
-        self.assertEqual(event_utils.station_arrival_time(event, ref_ets, list(range(4)), sentinel.offsets, sentinel.station),
-                         rel_arrival_time + 2.5)
+        self.assertEqual(
+            event_utils.station_arrival_time(event, ref_ets, list(range(4)), sentinel.offsets, sentinel.station),
+            rel_arrival_time + 2.5,
+        )
         mock_detector_ids.assert_not_called()
-        self.assertEqual(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets),
-                         rel_arrival_time + 2.5)
+        self.assertEqual(
+            event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets),
+            rel_arrival_time + 2.5,
+        )
         mock_detector_ids.assert_called_once_with(None, event)
-        self.assertEqual(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station),
-                         rel_arrival_time + 2.5)
+        self.assertEqual(
+            event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station),
+            rel_arrival_time + 2.5,
+        )
         mock_detector_ids.assert_called_with(sentinel.station, event)
 
     @patch.object(event_utils, 'detector_arrival_times')
     @patch.object(event_utils, 'get_detector_ids')
     def test_nan_station_arrival_time(self, mock_detector_ids, mock_detector_arrival_times):
         mock_detector_ids.return_value = list(range(4))
-        mock_detector_arrival_times.return_value = [7.5, 5., nan, 5.]
+        mock_detector_arrival_times.return_value = [7.5, 5.0, nan, 5.0]
         event_dict = {'t_trigger': 10, 'ext_timestamp': 1000}
         event = MagicMock()
         event.__getitem__.side_effect = lambda name: event_dict[name]
         ref_ets = 500
         rel_arrival_time = event_dict['ext_timestamp'] - ref_ets - event_dict['t_trigger']
 
-        self.assertEqual(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station),
-                         rel_arrival_time + 5)
+        self.assertEqual(
+            event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station),
+            rel_arrival_time + 5,
+        )
         event_dict['t_trigger'] = -999
-        self.assertTrue(isnan(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station)))
+        self.assertTrue(
+            isnan(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station)),
+        )
         event_dict['t_trigger'] = nan
-        self.assertTrue(isnan(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station)))
+        self.assertTrue(
+            isnan(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station)),
+        )
         event_dict['t_trigger'] = 10
         mock_detector_arrival_times.return_value = [nan, nan, nan, nan]
         with warnings.catch_warnings(record=True) as warned:
-            self.assertTrue(isnan(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station)))
+            self.assertTrue(
+                isnan(event_utils.station_arrival_time(event, ref_ets, None, sentinel.offsets, sentinel.station)),
+            )
         self.assertEqual(len(warned), 1)
 
 
 class RelativeDetectorArrivalTimesTests(unittest.TestCase):
-
     @patch.object(event_utils, 'detector_arrival_times')
     @patch.object(event_utils, 'get_detector_ids')
     def test_relative_detector_arrival_times(self, mock_detector_ids, mock_detector_arrival_times):
         mock_detector_ids.return_value = list(range(4))
-        mock_detector_arrival_times.return_value = [7.5, 5., 2.5, 5.]
+        mock_detector_arrival_times.return_value = [7.5, 5.0, 2.5, 5.0]
         event_dict = {'t_trigger': 10, 'ext_timestamp': 1000}
         event = MagicMock()
         event.__getitem__.side_effect = lambda name: event_dict[name]
         ref_ets = 500
         rel_arrival_time = event_dict['ext_timestamp'] - ref_ets - event_dict['t_trigger']
 
-        self.assertEqual(event_utils.relative_detector_arrival_times(event, 500, list(range(4)), sentinel.offsets, sentinel.station),
-                         [rel_arrival_time + t for t in mock_detector_arrival_times()])
+        self.assertEqual(
+            event_utils.relative_detector_arrival_times(event, 500, list(range(4)), sentinel.offsets, sentinel.station),
+            [rel_arrival_time + t for t in mock_detector_arrival_times()],
+        )
         mock_detector_ids.assert_not_called()
-        self.assertEqual(event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets),
-                         [rel_arrival_time + t for t in mock_detector_arrival_times()])
+        self.assertEqual(
+            event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets),
+            [rel_arrival_time + t for t in mock_detector_arrival_times()],
+        )
         mock_detector_ids.assert_called_once_with(None, event)
-        self.assertEqual(event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station),
-                         [rel_arrival_time + t for t in mock_detector_arrival_times()])
+        self.assertEqual(
+            event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station),
+            [rel_arrival_time + t for t in mock_detector_arrival_times()],
+        )
         mock_detector_ids.assert_called_with(sentinel.station, event)
 
     @patch.object(event_utils, 'detector_arrival_times')
     @patch.object(event_utils, 'get_detector_ids')
     def test_nan_relative_detector_arrival_times(self, mock_detector_ids, mock_detector_arrival_times):
         mock_detector_ids.return_value = list(range(4))
-        mock_detector_arrival_times.return_value = [7.5, 5., 5., nan]
+        mock_detector_arrival_times.return_value = [7.5, 5.0, 5.0, nan]
         event_dict = {'t_trigger': 10, 'ext_timestamp': 1000}
         event = MagicMock()
         event.__getitem__.side_effect = lambda name: event_dict[name]
         ref_ets = 500
         rel_arrival_time = event_dict['ext_timestamp'] - ref_ets - event_dict['t_trigger']
 
         result = event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station)
         self.assertEqual(result[:-1], [rel_arrival_time + t for t in mock_detector_arrival_times()[:-1]])
         self.assertTrue(isnan(result[-1]))
         event_dict['t_trigger'] = -999
-        self.assertTrue(isnan(event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station)).all())
+        self.assertTrue(
+            isnan(
+                event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station),
+            ).all(),
+        )
         event_dict['t_trigger'] = nan
-        self.assertTrue(isnan(event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station)).all())
+        self.assertTrue(
+            isnan(
+                event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station),
+            ).all(),
+        )
         event_dict['t_trigger'] = 10
         mock_detector_arrival_times.return_value = [nan, nan, nan, nan]
-        self.assertTrue(isnan(event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station)).all())
+        self.assertTrue(
+            isnan(
+                event_utils.relative_detector_arrival_times(event, 500, None, sentinel.offsets, sentinel.station),
+            ).all(),
+        )
 
 
 class DetectorArrivalTimesTests(unittest.TestCase):
-
     @patch.object(event_utils, 'detector_arrival_time')
     @patch.object(event_utils, 'get_detector_ids')
     def test_detector_arrival_times(self, mock_detector_ids, mock_detector_arrival_time):
         mock_detector_ids.return_value = list(range(4))
 
         mock_detector_arrival_time.return_value = sentinel.time
-        self.assertEqual(event_utils.detector_arrival_times(sentinel.event, list(range(4))),
-                         [sentinel.time] * 4)
-        self.assertEqual(event_utils.detector_arrival_times(sentinel.event, list(range(2))),
-                         [sentinel.time] * 2)
+        self.assertEqual(event_utils.detector_arrival_times(sentinel.event, list(range(4))), [sentinel.time] * 4)
+        self.assertEqual(event_utils.detector_arrival_times(sentinel.event, list(range(2))), [sentinel.time] * 2)
         mock_detector_ids.assert_not_called()
-        self.assertEqual(event_utils.detector_arrival_times(sentinel.event),
-                         [sentinel.time] * 4)
+        self.assertEqual(event_utils.detector_arrival_times(sentinel.event), [sentinel.time] * 4)
         mock_detector_ids.assert_called_once_with(None, sentinel.event)
-        self.assertEqual(event_utils.detector_arrival_times(sentinel.event, station=sentinel.station),
-                         [sentinel.time] * 4)
+        self.assertEqual(
+            event_utils.detector_arrival_times(sentinel.event, station=sentinel.station),
+            [sentinel.time] * 4,
+        )
         mock_detector_ids.assert_called_with(sentinel.station, sentinel.event)
 
 
 class DetectorArrivalTimeTests(unittest.TestCase):
-
     def setUp(self):
         self.event = MagicMock()
         self.offsets = [1, 2, 3, 4]
 
     def test_detector_arrival_time(self):
-        self.event.__getitem__.side_effect = lambda name: 2.5
+        self.event.__getitem__.side_effect = repeat(2.5)
         self.assertEqual(event_utils.detector_arrival_time(self.event, 0), 2.5)
         self.event.__getitem__.assert_called_with('t1')
         self.assertEqual(event_utils.detector_arrival_time(self.event, 0, self.offsets), 1.5)
         self.event.__getitem__.assert_called_with('t1')
         self.assertEqual(event_utils.detector_arrival_time(self.event, 1, self.offsets), 0.5)
         self.event.__getitem__.assert_called_with('t2')
 
     def test_no_good_detector_arrival_time(self):
-        self.event.__getitem__.side_effect = lambda name: -999
+        self.event.__getitem__.side_effect = repeat(-999)
         self.assertTrue(isnan(event_utils.detector_arrival_time(self.event, 0)))
         self.event.__getitem__.assert_called_with('t1')
         self.assertTrue(isnan(event_utils.detector_arrival_time(self.event, 0, self.offsets)))
         self.event.__getitem__.assert_called_with('t1')
 
 
 class GetDetectorIdsTests(unittest.TestCase):
-
     def test_get_detector_ids(self):
         self.assertEqual(event_utils.get_detector_ids(), list(range(4)))
         station = MagicMock()
         station.detectors.__len__.return_value = 2
         self.assertEqual(event_utils.get_detector_ids(station=station), list(range(2)))
         event = MagicMock()
-        event.__getitem__.side_effect = lambda name: [10, 100, 40, -1]
+        event.__getitem__.side_effect = repeat([10, 100, 40, -1])
         self.assertEqual(event_utils.get_detector_ids(event=event), list(range(3)))
         self.assertEqual(event_utils.get_detector_ids(station=station, event=event), list(range(2)))
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_find_mpv.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_find_mpv.py`

 * *Files 18% similar despite different names*

```diff
@@ -3,47 +3,42 @@
 
 from numpy import array
 
 from sapphire.analysis import find_mpv
 
 
 class FindMostProbableValueInSpectrumTest(unittest.TestCase):
-
     def test_failing_fit(self):
         """Check for correct warnings/errors for failing fit"""
 
         n = array([0, 1, 1])
         bins = array([0, 10, 20])
         fmpv = find_mpv.FindMostProbableValueInSpectrum(n, bins)
 
         # Exception from the fit mpv function, to few points
         first_guess = fmpv.find_first_guess_mpv()
         with self.assertRaises(RuntimeError) as cm:
             fmpv.fit_mpv(first_guess)
-        self.assertEqual(str(cm.exception), "Number of data points not sufficient")
+        self.assertEqual(str(cm.exception), 'Number of data points not sufficient')
 
         # Warning from the find mpv function
         with warnings.catch_warnings(record=True) as w:
             # clear the warnings from find_mpv module
             # https://bugs.python.org/issue4180
             if hasattr(find_mpv, '__warningregistry__'):
                 find_mpv.__warningregistry__ = {}
-            warnings.simplefilter("always")
+            warnings.simplefilter('always')
             mpv, is_fitted = fmpv.find_mpv()
         self.assertTrue(issubclass(w[0].category, UserWarning))
         self.assertEqual(mpv, -999)
         self.assertFalse(is_fitted)
 
     @unittest.skip('Need better test, this has different error on Travis.')
     def test_bad_fit(self):
         """Exception from the fit mpv function, result outside range"""
 
         n = array([1, 3, 7, 70])
         bins = array([111.0, 111.1, 111.2, 111.3])
         fmpv = find_mpv.FindMostProbableValueInSpectrum(n, bins)
         with self.assertRaises(RuntimeError) as cm:
             fmpv.fit_mpv(111)
-        self.assertEqual(str(cm.exception), "Fitted MPV value outside range")
-
-
-if __name__ == '__main__':
-    unittest.main()
+        self.assertEqual(str(cm.exception), 'Fitted MPV value outside range')
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_landau.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_landau.py`

 * *Files 20% similar despite different names*

```diff
@@ -2,33 +2,27 @@
 
 from numpy import linspace
 
 from sapphire.analysis import landau
 
 
 class LandauTest(unittest.TestCase):
-
     def test_pdf_mpv(self):
         """Check if peak of Landau pdf is at correct place
 
         The peak of the Landau should be around -0.22
 
         """
-        x = linspace(-.4, 0, 100)
+        x = linspace(-0.4, 0, 100)
         self.assertAlmostEqual(x[landau.pdf(x).argmax()] + 0.222, 0, 2)
 
 
 class ScintillatorTest(unittest.TestCase):
-
     def setUp(self):
         self.scin = landau.Scintillator()
 
     def test_pdf(self):
         """Check if the integral of the Landau pdf is almost 1"""
 
         self.scin.pdf(0)
-        step_size = (self.scin.full_domain[-1] - self.scin.full_domain[-2])
+        step_size = self.scin.full_domain[-1] - self.scin.full_domain[-2]
         self.assertAlmostEqual(self.scin.pdf_values.sum() * step_size, 1, 1)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_process_events.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_process_events.py`

 * *Files 10% similar despite different names*

```diff
@@ -17,32 +17,30 @@
 TEST_DATA_FILE = 'test_data/process_events.h5'
 DATA_GROUP = '/s501'
 
 
 class ProcessEventsTests(unittest.TestCase):
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         self.data_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.data_path)
         self.data = tables.open_file(self.data_path, 'a')
+        self.addCleanup(self.data.close)
         self.proc = process_events.ProcessEvents(self.data, DATA_GROUP, progress=False)
 
-    def tearDown(self):
-        warnings.resetwarnings()
-        self.data.close()
-        os.remove(self.data_path)
-
     def test_get_traces_for_event(self):
         event = self.proc.source[0]
         self.assertEqual(self.proc.get_traces_for_event(event)[12][3], 1334)
 
     def test__find_unique_row_ids(self):
         ext_timestamps = self.proc.source.col('ext_timestamp')
         enumerated_timestamps = list(enumerate(ext_timestamps))
         enumerated_timestamps.sort(key=operator.itemgetter(1))
-        ids_in = [id for id, _ in enumerated_timestamps]
+        ids_in = [row_id for row_id, _ in enumerated_timestamps]
         ids = self.proc._find_unique_row_ids(enumerated_timestamps)
         self.assertEqual(ids, ids_in)
 
         enumerated_timestamps = [(0, 1), (1, 1), (3, 2), (2, 2)]
         ids = self.proc._find_unique_row_ids(enumerated_timestamps)
         self.assertEqual(ids, [0, 3])
 
@@ -70,20 +68,20 @@
     def test_first_above_threshold(self):
         trace = [0, 2, 4, 2, 0]
         self.assertEqual(self.proc.first_above_threshold(trace, 1), 1)
         self.assertEqual(self.proc.first_above_threshold(trace, 3), 2)
         self.assertEqual(self.proc.first_above_threshold(trace, 4), 2)
         self.assertEqual(self.proc.first_above_threshold(trace, 5), -999)
 
-#     @patch.object(process_events.FindMostProbableValueInSpectrum, 'find_mpv')
+    #     @patch.object(process_events.FindMostProbableValueInSpectrum, 'find_mpv')
     def test__process_pulseintegrals(self):
         self.proc.limit = 1
-#         mock_find_mpv.return_value = (-999, False)
+        #         mock_find_mpv.return_value = (-999, False)
         # Because of small data sample fit fails for detector 1
-        self.assertEqual(self.proc._process_pulseintegrals()[0][1], -999.)
+        self.assertEqual(self.proc._process_pulseintegrals()[0][1], -999.0)
         self.assertAlmostEqual(self.proc._process_pulseintegrals()[0][3], 3.98951741969)
         self.proc.limit = None
 
     def create_tempfile_from_testdata(self):
         tmp_path = self.create_tempfile_path()
         data_path = self.get_testdata_path()
         shutil.copyfile(data_path, tmp_path)
@@ -99,31 +97,36 @@
         return os.path.join(dir_path, TEST_DATA_FILE)
 
 
 class ProcessIndexedEventsTests(ProcessEventsTests):
     def setUp(self):
         warnings.filterwarnings('ignore')
         self.data_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.data_path)
         self.data = tables.open_file(self.data_path, 'a')
+        self.addCleanup(self.data.close)
         self.proc = process_events.ProcessIndexedEvents(self.data, DATA_GROUP, [0, 10], progress=False)
 
     def test_process_traces(self):
         timings = self.proc.process_traces()
         self.assertEqual(timings[1][0], 162.5)
         self.assertEqual(timings[1][1], -999)
 
     def test_get_traces_for_indexed_event_index(self):
         self.assertEqual(self.proc.get_traces_for_indexed_event_index(0)[12][3], 1334)
 
 
 class ProcessEventsWithLINTTests(ProcessEventsTests):
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         self.data_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.data_path)
         self.data = tables.open_file(self.data_path, 'a')
+        self.addCleanup(self.data.close)
         self.proc = process_events.ProcessEventsWithLINT(self.data, DATA_GROUP, progress=False)
 
     def test__reconstruct_time_from_traces(self):
         event = self.proc.source[10]
         times = self.proc._reconstruct_time_from_traces(event)
         self.assertAlmostEqual(times[0], 160.685483871)
         self.assertEqual(times[2], -999)
@@ -135,16 +138,19 @@
         self.assertEqual(self.proc._reconstruct_time_from_trace(trace, 200), 1)
         self.assertEqual(self.proc._reconstruct_time_from_trace(trace, 210), -999)
 
 
 class ProcessEventsWithTriggerOffsetTests(ProcessEventsTests):
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         self.data_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.data_path)
         self.data = tables.open_file(self.data_path, 'a')
+        self.addCleanup(self.data.close)
         self.proc = process_events.ProcessEventsWithTriggerOffset(self.data, DATA_GROUP, progress=False)
 
     def test__reconstruct_time_from_traces(self):
         event = self.proc.source[10]
         times = self.proc._reconstruct_time_from_traces(event)
         self.assertEqual(times[0], 162.5)
         self.assertEqual(times[2], -999)
@@ -158,21 +164,36 @@
         self.assertEqual(times[2], -999)
         self.assertEqual(times[4], -999)
 
     def test__first_above_thresholds(self):
         # 2 detectors
         self.assertEqual(self.proc._first_above_thresholds((x for x in [200, 200, 900]), [300, 400], 900), [2, 2, -999])
         self.assertEqual(self.proc._first_above_thresholds((x for x in [200, 200, 400]), [300, 400], 400), [2, 2, -999])
-        self.assertEqual(self.proc._first_above_thresholds((x for x in [200, 350, 450, 550]), [300, 400], 550), [1, 2, -999])
+        self.assertEqual(
+            self.proc._first_above_thresholds((x for x in [200, 350, 450, 550]), [300, 400], 550),
+            [1, 2, -999],
+        )
         # 4 detectors
-        self.assertEqual(self.proc._first_above_thresholds((x for x in [200, 200, 900]), [300, 400, 500], 900), [2, 2, 2])
-        self.assertEqual(self.proc._first_above_thresholds((x for x in [200, 200, 400]), [300, 400, 500], 400), [2, 2, -999])
-        self.assertEqual(self.proc._first_above_thresholds((x for x in [200, 350, 450, 550]), [300, 400, 500], 550), [1, 2, 3])
+        self.assertEqual(
+            self.proc._first_above_thresholds((x for x in [200, 200, 900]), [300, 400, 500], 900),
+            [2, 2, 2],
+        )
+        self.assertEqual(
+            self.proc._first_above_thresholds((x for x in [200, 200, 400]), [300, 400, 500], 400),
+            [2, 2, -999],
+        )
+        self.assertEqual(
+            self.proc._first_above_thresholds((x for x in [200, 350, 450, 550]), [300, 400, 500], 550),
+            [1, 2, 3],
+        )
         # No signal
-        self.assertEqual(self.proc._first_above_thresholds((x for x in [200, 250, 200, 2000]), [300, 400, 500], 250), [-999, -999, -999])
+        self.assertEqual(
+            self.proc._first_above_thresholds((x for x in [200, 250, 200, 2000]), [300, 400, 500], 250),
+            [-999, -999, -999],
+        )
 
     def test__first_value_above_threshold(self):
         trace = [200, 200, 300, 200]
         self.assertEqual(self.proc._first_value_above_threshold(trace, 200), (0, 200))
         self.assertEqual(self.proc._first_value_above_threshold(trace, 250), (2, 300))
         self.assertEqual(self.proc._first_value_above_threshold(trace, 250, 4), (6, 300))
         self.assertEqual(self.proc._first_value_above_threshold(trace, 500), (-999, 0))
@@ -243,82 +264,96 @@
         self.proc.trigger = (1, 3, False, 0)
         self.assertEqual(self.proc._reconstruct_trigger(low_idx, high_idx), result)
 
 
 class ProcessEventsFromSourceTests(ProcessEventsTests):
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         self.source_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.source_path)
         self.source_data = tables.open_file(self.source_path, 'r')
+        self.addCleanup(self.source_data.close)
         self.dest_path = self.create_tempfile_path()
+        self.addCleanup(os.remove, self.dest_path)
         self.dest_data = tables.open_file(self.dest_path, 'a')
-        self.proc = process_events.ProcessEventsFromSource(
-            self.source_data, self.dest_data, DATA_GROUP, DATA_GROUP)
-
-    def tearDown(self):
-        warnings.resetwarnings()
-        self.source_data.close()
-        os.remove(self.source_path)
-        self.dest_data.close()
-        os.remove(self.dest_path)
+        self.addCleanup(self.dest_data.close)
+        self.proc = process_events.ProcessEventsFromSource(self.source_data, self.dest_data, DATA_GROUP, DATA_GROUP)
 
     def test_process_and_store_results(self):
         self.proc.process_and_store_results()
 
 
-class ProcessEventsFromSourceWithTriggerOffsetTests(ProcessEventsFromSourceTests,
-                                                    ProcessEventsWithTriggerOffsetTests):
+class ProcessEventsFromSourceWithTriggerOffsetTests(ProcessEventsFromSourceTests, ProcessEventsWithTriggerOffsetTests):
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         self.source_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.source_path)
         self.source_data = tables.open_file(self.source_path, 'r')
+        self.addCleanup(self.source_data.close)
         self.dest_path = self.create_tempfile_path()
+        self.addCleanup(os.remove, self.dest_path)
         self.dest_data = tables.open_file(self.dest_path, 'a')
+        self.addCleanup(self.dest_data.close)
         self.proc = process_events.ProcessEventsFromSourceWithTriggerOffset(
-            self.source_data, self.dest_data, DATA_GROUP, DATA_GROUP)
+            self.source_data,
+            self.dest_data,
+            DATA_GROUP,
+            DATA_GROUP,
+        )
 
 
-class ProcessEventsFromSourceWithTriggerOffsetStationTests(ProcessEventsFromSourceTests,
-                                                           ProcessEventsWithTriggerOffsetTests):
+class ProcessEventsFromSourceWithTriggerOffsetStationTests(
+    ProcessEventsFromSourceTests,
+    ProcessEventsWithTriggerOffsetTests,
+):
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         self.source_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.source_path)
         self.source_data = tables.open_file(self.source_path, 'r')
+        self.addCleanup(self.source_data.close)
         self.dest_path = self.create_tempfile_path()
+        self.addCleanup(os.remove, self.dest_path)
         self.dest_data = tables.open_file(self.dest_path, 'a')
+        self.addCleanup(self.dest_data.close)
         self.proc = process_events.ProcessEventsFromSourceWithTriggerOffset(
-            self.source_data, self.dest_data, DATA_GROUP, DATA_GROUP,
-            station=501)
+            self.source_data,
+            self.dest_data,
+            DATA_GROUP,
+            DATA_GROUP,
+            station=501,
+        )
 
     def test__reconstruct_time_from_traces_with_external(self):
         mock_trigger = Mock()
-        mock_trigger.return_value = ([(process_events.ADC_LOW_THRESHOLD,
-                                       process_events.ADC_HIGH_THRESHOLD)] * 4,
-                                     [0, 0, 0, 1])
+        mock_trigger.return_value = (
+            [(process_events.ADC_LOW_THRESHOLD, process_events.ADC_HIGH_THRESHOLD)] * 4,
+            [0, 0, 0, 1],
+        )
         self.proc.station.trigger = mock_trigger
 
         event = self.proc.source[10]
         times = self.proc._reconstruct_time_from_traces(event)
         self.assertEqual(times[0], 162.5)
         self.assertEqual(times[2], -999)
         self.assertEqual(times[4], -999)
 
 
 class ProcessSinglesTests(unittest.TestCase):
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         self.data_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.data_path)
         self.data = tables.open_file(self.data_path, 'a')
-        self.proc = process_events.ProcessSingles(self.data, DATA_GROUP,
-                                                  progress=False)
-
-    def tearDown(self):
-        warnings.resetwarnings()
-        self.data.close()
-        os.remove(self.data_path)
+        self.addCleanup(self.data.close)
+        self.proc = process_events.ProcessSingles(self.data, DATA_GROUP, progress=False)
 
     def test_process_and_store_results(self):
         self.proc.process_and_store_results()
         # check for unique and sorted timestamps
         singles_table = self.data.get_node(DATA_GROUP, 'singles')
         ts = singles_table.col('timestamp')
         unique_ts = array(sorted(set(ts)))
@@ -339,32 +374,25 @@
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_DATA_FILE)
 
 
 class ProcessSinglesFromSourceTests(ProcessSinglesTests):
     def setUp(self):
         warnings.filterwarnings('ignore')
+        self.addCleanup(warnings.resetwarnings)
         self.source_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.source_path)
         self.source_data = tables.open_file(self.source_path, 'r')
+        self.addCleanup(self.source_data.close)
         self.dest_path = self.create_tempfile_path()
+        self.addCleanup(os.remove, self.dest_path)
         self.dest_data = tables.open_file(self.dest_path, 'a')
-        self.proc = process_events.ProcessSinglesFromSource(
-            self.source_data, self.dest_data, DATA_GROUP, '/')
-
-    def tearDown(self):
-        warnings.resetwarnings()
-        self.source_data.close()
-        os.remove(self.source_path)
-        self.dest_data.close()
-        os.remove(self.dest_path)
+        self.addCleanup(self.dest_data.close)
+        self.proc = process_events.ProcessSinglesFromSource(self.source_data, self.dest_data, DATA_GROUP, '/')
 
     def test_process_and_store_results(self):
         self.proc.process_and_store_results()
         # check for unique and sorted timestamps
         singles_table = self.dest_data.get_node('/', 'singles')
         ts = singles_table.col('timestamp')
         unique_ts = array(sorted(set(ts)))
         assert_array_equal(ts, unique_ts)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_process_traces.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_process_traces.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,14 @@
 
 from numpy import array
 
 from sapphire.analysis import process_traces
 
 
 class TraceObservablesTests(unittest.TestCase):
-
     def setUp(self):
         trace = [200] * 400 + [500] + [510] + [400] * 10 + [200] * 600 + [400] * 10 + [200]
         trace2 = [203, 199] * 200 + [500] + [510] + [398, 402] * 5 + [203, 199] * 300 + [400] * 10 + [200]
         self.traces = array([trace, trace2]).T
         self.to = process_traces.TraceObservables(self.traces)
 
     def test_baselines(self):
@@ -29,15 +28,14 @@
         self.assertEqual(self.to.integrals, [300 + 310 + 200 * 20, 299 + 309 + 199 * 20, -1, -1])
 
     def test_n_peaks(self):
         self.assertEqual(self.to.n_peaks, [2, 2, -1, -1])
 
 
 class MeanFilterTests(unittest.TestCase):
-
     def setUp(self):
         self.trace = [[200] * 400 + [500] + [400] * 20 + [200] * 600]
         self.traces = self.trace * 2
         self.mf = process_traces.MeanFilter()
 
     def test_init(self):
         self.mf = process_traces.MeanFilter(use_threshold=True, threshold=sentinel.threshold)
@@ -47,23 +45,22 @@
         self.mf = process_traces.MeanFilter(use_threshold=False)
         self.assertRaises(AttributeError, lambda: self.mf.threshold)
         self.assertEqual(self.mf.filter, self.mf.mean_filter_without_threshold)
 
     @patch.object(process_traces.MeanFilter, 'filter_trace')
     def test_filter_traces(self, mock_filter_trace):
         mock_filter_trace.return_value = sentinel.filtered_trace
-        self.assertEqual(self.mf.filter_traces(self.traces),
-                         [sentinel.filtered_trace, sentinel.filtered_trace])
+        self.assertEqual(self.mf.filter_traces(self.traces), [sentinel.filtered_trace, sentinel.filtered_trace])
 
     def test_filter_trace(self):
         mock_filter = MagicMock()
         self.mf.filter = mock_filter
-        mock_filter.side_effect = cycle([[sentinel.filtered_even] * 2,
-                                         [sentinel.filtered_odd] * 2,
-                                         [sentinel.filtered_recombined]])
+        mock_filter.side_effect = cycle(
+            [[sentinel.filtered_even] * 2, [sentinel.filtered_odd] * 2, [sentinel.filtered_recombined]],
+        )
         trace_segment = [sentinel.trace_even, sentinel.trace_odd]
 
         filtered_trace = self.mf.filter_trace(trace_segment * 4)
 
         self.assertEqual(filtered_trace, [sentinel.filtered_recombined])
         mock_filter.assert_any_call([sentinel.trace_even] * 4)
         mock_filter.assert_any_call([sentinel.trace_odd] * 4)
@@ -144,57 +141,74 @@
         exp_trace = [200, 200, 200, 200, 202]
         # mean/trace  m    m    m    m
         filtered_trace = self.mf.mean_filter_without_threshold(raw_trace)
         self.assertEqual(filtered_trace, exp_trace)
 
 
 class DataReductionTests(unittest.TestCase):
-
     def setUp(self):
         self.dr = process_traces.DataReduction()
 
     def test_init(self):
         dr = process_traces.DataReduction(sentinel.threshold, sentinel.padding)
         self.assertEqual(dr.threshold, sentinel.threshold)
         self.assertEqual(dr.padding, sentinel.padding)
 
     def test_reduce_traces(self):
         pre = 400
         post = 300
         baseline = 200
-        trace = ([baseline] * pre + [baseline + 50] + [baseline + 60] * 4 +
-                 [baseline] * 600 + [baseline + 90] * 5 + [baseline] * post)
+        trace = (
+            [baseline] * pre
+            + [baseline + 50]
+            + [baseline + 60] * 4
+            + [baseline] * 600
+            + [baseline + 90] * 5
+            + [baseline] * post
+        )
         traces = array([trace, [baseline] * len(trace)]).T
         reduced_traces = self.dr.reduce_traces(traces, [baseline] * 2)
         r_traces, left = self.dr.reduce_traces(traces, [baseline] * 2, True)
         r_traces_no_baseline = self.dr.reduce_traces(traces)
         self.assertTrue((reduced_traces == r_traces).all())
         self.assertTrue((reduced_traces == r_traces_no_baseline).all())
         self.assertEqual(len(reduced_traces), len(trace) - pre - post + self.dr.padding * 2)
         self.assertEqual(left, pre - self.dr.padding)
 
         pre = 10
         post = 10
         baseline = 200
-        trace = ([baseline] * pre + [baseline + 50] + [baseline + 60] * 4 +
-                 [baseline] * 600 + [baseline + 90] * 5 + [baseline] * post)
+        trace = (
+            [baseline] * pre
+            + [baseline + 50]
+            + [baseline + 60] * 4
+            + [baseline] * 600
+            + [baseline + 90] * 5
+            + [baseline] * post
+        )
         traces = array([trace, [baseline] * len(trace)]).T
         reduced_traces = self.dr.reduce_traces(traces, [baseline] * 2)
         r_traces, left = self.dr.reduce_traces(traces, [baseline] * 2, True)
         self.assertTrue((reduced_traces == traces).all())
         self.assertTrue((reduced_traces == r_traces).all())
         self.assertEqual(len(reduced_traces), len(trace))
         self.assertEqual(left, 0)
 
     def test_determine_cuts(self):
         pre = 400
         post = 300
         baseline = 200
-        trace = ([baseline] * pre + [baseline + 50] + [baseline + 60] * 4 +
-                 [baseline] * 600 + [baseline + 90] * 5 + [baseline] * post)
+        trace = (
+            [baseline] * pre
+            + [baseline + 50]
+            + [baseline + 60] * 4
+            + [baseline] * 600
+            + [baseline + 90] * 5
+            + [baseline] * post
+        )
         traces = array([trace, [baseline] * len(trace)]).T
         left, right = self.dr.determine_cuts(traces, [baseline] * 2)
         self.assertEqual(left, pre)
         self.assertEqual(right, len(trace) - post)
 
         # No signal, return entire trace
         length = 400
@@ -202,19 +216,17 @@
         trace = [baseline] * length
         traces = array([trace, trace]).T
         left, right = self.dr.determine_cuts(traces, [baseline] * 2)
         self.assertEqual(left, 0)
         self.assertEqual(right, length)
 
     def test_add_padding(self):
-        combinations = (((0, 20), (0, 46)),  # left at limit
-                        ((4, 20), (0, 46)),  # left close to limit
-                        ((50, 2400), (24, 2426)),  # left far from limit
-                        ((50, 2400, 2400), (24, 2400)),  # right at limit
-                        ((50, 2400, 2410), (24, 2410)),  # right close to limit
-                        ((0, 200, 2400), (0, 226)),)  # right far from limit
-        for input, expected in combinations:
-            self.assertEqual(self.dr.add_padding(*input), expected)
-
-
-if __name__ == '__main__':
-    unittest.main()
+        combinations = (
+            ((0, 20), (0, 46)),  # left at limit
+            ((4, 20), (0, 46)),  # left close to limit
+            ((50, 2400), (24, 2426)),  # left far from limit
+            ((50, 2400, 2400), (24, 2400)),  # right at limit
+            ((50, 2400, 2410), (24, 2410)),  # right close to limit
+            ((0, 200, 2400), (0, 226)),
+        )  # right far from limit
+        for args, expected in combinations:
+            self.assertEqual(self.dr.add_padding(*args), expected)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_reconstructions.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_reconstructions.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,42 +1,47 @@
 import os
 import unittest
 
+from itertools import repeat
 from unittest.mock import MagicMock, patch, sentinel
 
 import tables
 
 from sapphire.analysis import reconstructions
 
 TEST_DATA_FILE = '../simulations/test_data/groundparticles_sim.h5'
 
 
 class ReconstructESDEventsTest(unittest.TestCase):
-
     def setUp(self):
         self.data = MagicMock()
         self.station = MagicMock(spec=reconstructions.Station)
         self.rec = reconstructions.ReconstructESDEvents(
-            self.data, sentinel.station_group, self.station,
-            overwrite=sentinel.overwrite, progress=sentinel.progress,
-            verbose=False, destination=sentinel.destination)
+            self.data,
+            sentinel.station_group,
+            self.station,
+            overwrite=sentinel.overwrite,
+            progress=False,
+            verbose=False,
+            destination=sentinel.destination,
+        )
 
     def test_init(self):
         rec = self.rec
         self.assertEqual(rec.data, self.data)
 
         self.assertEqual(rec.station_group, self.data.get_node.return_value)
         self.data.get_node.assert_called_once_with(sentinel.station_group)
         self.assertEqual(rec.events, self.data.get_node.return_value.events)
 
         self.assertEqual(rec.overwrite, sentinel.overwrite)
-        self.assertEqual(rec.progress, sentinel.progress)
+        self.assertFalse(rec.progress)
         self.assertFalse(rec.verbose)
         self.assertEqual(rec.destination, sentinel.destination)
-        self.assertEqual(rec.offsets, [0.] * 4)
+        self.assertEqual(rec.offsets, [0.0] * 4)
 
         self.assertEqual(rec.station, self.station)
 
         self.assertTrue(isinstance(rec.direction, reconstructions.EventDirectionReconstruction))
         self.assertTrue(isinstance(rec.core, reconstructions.EventCoreReconstruction))
 
         self.assertEqual(rec.theta, [])
@@ -46,59 +51,77 @@
         self.assertEqual(rec.core_y, [])
 
     def test_reconstruct_directions(self):
         self.rec.direction = MagicMock()
         self.rec.direction.reconstruct_events.return_value = (sentinel.theta, sentinel.phi, sentinel.ids)
         self.rec.reconstruct_directions()
         self.rec.direction.reconstruct_events.assert_called_once_with(
-            self.rec.events, None, self.rec.offsets, self.rec.progress, [])
+            self.rec.events,
+            None,
+            self.rec.offsets,
+            self.rec.progress,
+            [],
+        )
         self.assertEqual(self.rec.theta, sentinel.theta)
         self.assertEqual(self.rec.phi, sentinel.phi)
         self.assertEqual(self.rec.detector_ids, sentinel.ids)
 
         self.rec.reconstruct_directions(sentinel.detector_ids)
         self.rec.direction.reconstruct_events.assert_called_with(
-            self.rec.events, sentinel.detector_ids, self.rec.offsets, self.rec.progress, [])
+            self.rec.events,
+            sentinel.detector_ids,
+            self.rec.offsets,
+            self.rec.progress,
+            [],
+        )
 
     def test_reconstruct_cores(self):
         self.rec.core = MagicMock()
         self.rec.core.reconstruct_events.return_value = (sentinel.core_x, sentinel.core_y)
         self.rec.reconstruct_cores()
-        self.rec.core.reconstruct_events.assert_called_once_with(
-            self.rec.events, None, self.rec.progress, [])
+        self.rec.core.reconstruct_events.assert_called_once_with(self.rec.events, None, self.rec.progress, [])
         self.assertEqual(self.rec.core_x, sentinel.core_x)
         self.assertEqual(self.rec.core_y, sentinel.core_y)
 
         self.rec.reconstruct_cores(sentinel.detector_ids)
         self.rec.core.reconstruct_events.assert_called_with(
-            self.rec.events, sentinel.detector_ids, self.rec.progress, [])
+            self.rec.events,
+            sentinel.detector_ids,
+            self.rec.progress,
+            [],
+        )
 
     def test_prepare_output(self):
         self.rec.events = MagicMock()
         self.rec.events.nrows = sentinel.nrows
         self.rec.prepare_output()
         self.data.create_table.assert_called_once_with(
-            self.rec.station_group, sentinel.destination,
-            reconstructions.ReconstructedEvent, expectedrows=sentinel.nrows)
+            self.rec.station_group,
+            sentinel.destination,
+            reconstructions.ReconstructedEvent,
+            expectedrows=sentinel.nrows,
+        )
         self.assertEqual(self.rec.reconstructions, self.data.create_table.return_value)
         self.assertEqual(self.rec.reconstructions._v_attrs.station, self.station)
 
     def test_prepare_output_existing(self):
         self.rec.events = MagicMock()
         self.rec.events.nrows = sentinel.nrows
         self.rec.station_group = [sentinel.destination]
 
         # Overwrite existing
         self.rec.overwrite = True
         self.rec.prepare_output()
-        self.data.remove_node.assert_called_once_with(
-            self.rec.station_group, sentinel.destination, recursive=True)
+        self.data.remove_node.assert_called_once_with(self.rec.station_group, sentinel.destination, recursive=True)
         self.data.create_table.assert_called_with(
-            self.rec.station_group, sentinel.destination,
-            reconstructions.ReconstructedEvent, expectedrows=sentinel.nrows)
+            self.rec.station_group,
+            sentinel.destination,
+            reconstructions.ReconstructedEvent,
+            expectedrows=sentinel.nrows,
+        )
         self.assertEqual(self.rec.reconstructions, self.data.create_table.return_value)
         self.assertEqual(self.rec.reconstructions._v_attrs.station, self.station)
 
         # Raise exception if table already exists
         self.rec.overwrite = False
         self.assertRaises(RuntimeError, self.rec.prepare_output)
 
@@ -108,16 +131,15 @@
         mock_station.return_value = sentinel.station
         self.rec.events = sentinel.events
         self.rec.station.detectors = [None, None]
 
         # no offsets in station object no station_number ->
         #  determine offsets from events
         self.rec.get_detector_offsets()
-        mock_determine_detctor_timing_offets.assert_called_with(
-            sentinel.events, self.station)
+        mock_determine_detctor_timing_offets.assert_called_with(sentinel.events, self.station)
 
         # no offsets in station object and station number -> api.Station
         self.rec.station_number = sentinel.station
         self.rec.get_detector_offsets()
         self.assertEqual(self.rec.offsets, sentinel.station)
 
         # offsets from cluster object (stored by simulation)
@@ -127,101 +149,111 @@
         self.assertEqual(self.rec.offsets, [sentinel.offset, sentinel.offset])
 
     def test__store_reconstruction(self):
         event = MagicMock()
         # _store_reconstruction calls  min(event['n1'], ...).
         # but MagicMock is unordered in python 3!
         # Mock a dict that always returns 42.
-        event.__getitem__.side_effect = lambda x: 42.
+        event.__getitem__.side_effect = repeat(42.0)
         self.rec.reconstructions = MagicMock()
-        self.rec._store_reconstruction(event, sentinel.core_x, sentinel.core_y,
-                                       sentinel.theta, sentinel.phi, [1, 3, 4])
+        self.rec._store_reconstruction(event, sentinel.core_x, sentinel.core_y, sentinel.theta, sentinel.phi, [1, 3, 4])
         self.rec.reconstructions.row.append.assert_called_once_with()
 
 
 class ReconstructESDEventsFromSourceTest(ReconstructESDEventsTest):
-
     def setUp(self):
         self.data = MagicMock()
         self.dest_data = MagicMock()
         self.station = MagicMock(spec=reconstructions.Station)
         self.rec = reconstructions.ReconstructESDEventsFromSource(
-            self.data, self.dest_data, sentinel.station_group,
-            sentinel.dest_group, self.station, overwrite=sentinel.overwrite,
-            progress=sentinel.progress, verbose=False,
-            destination=sentinel.destination)
+            self.data,
+            self.dest_data,
+            sentinel.station_group,
+            sentinel.dest_group,
+            self.station,
+            overwrite=sentinel.overwrite,
+            progress=False,
+            verbose=False,
+            destination=sentinel.destination,
+        )
 
     @unittest.skip('WIP')
     def test_prepare_output(self):
         pass
 
     @unittest.skip('WIP')
     def test_prepare_output_existing(self):
         pass
 
 
 class ReconstructSimulatedEventsTest(unittest.TestCase):
-
     def setUp(self):
         self.data = None
 
     def tearDown(self):
         if isinstance(self.data, tables.file.File):
             self.data.close()
 
     def test_station_is_object(self):
         self.data = MagicMock()
         station = MagicMock(spec=reconstructions.Station)
         rec = reconstructions.ReconstructSimulatedEvents(
-            self.data, sentinel.station_group, station,
-            overwrite=sentinel.overwrite, progress=sentinel.progress,
-            verbose=False, destination=sentinel.destination)
+            self.data,
+            sentinel.station_group,
+            station,
+            overwrite=sentinel.overwrite,
+            progress=False,
+            verbose=False,
+            destination=sentinel.destination,
+        )
         self.assertEqual(rec.station, station)
 
     def test_read_object_from_hdf5(self):
         fn = self.get_testdata_path(TEST_DATA_FILE)
         self.data = tables.open_file(fn, 'r')
         station_group = '/cluster_simulations/station_0'
-        rec = reconstructions.ReconstructSimulatedEvents(
-            self.data, station_group, 0)
+        rec = reconstructions.ReconstructSimulatedEvents(self.data, station_group, 0)
 
         # isinstance does not work on classes that are read from pickles.
         self.assertEqual(rec.station.station_id, 0)
 
         with self.assertRaises(RuntimeError):
-            rec = reconstructions.ReconstructSimulatedEvents(
-                self.data, station_group, -999)
+            rec = reconstructions.ReconstructSimulatedEvents(self.data, station_group, -999)
 
     def get_testdata_path(self, fn):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, fn)
 
 
 class ReconstructESDCoincidencesTest(unittest.TestCase):
-
     @patch.object(reconstructions, 'CoincidenceQuery')
     def setUp(self, mock_cq):
         self.data = MagicMock()
         self.cluster = MagicMock()
         self.cq = mock_cq
         self.rec = reconstructions.ReconstructESDCoincidences(
-            self.data, sentinel.coin_group, overwrite=sentinel.overwrite,
-            progress=sentinel.progress, verbose=False,
-            destination=sentinel.destination, cluster=self.cluster)
+            self.data,
+            sentinel.coin_group,
+            overwrite=sentinel.overwrite,
+            progress=False,
+            verbose=False,
+            destination=sentinel.destination,
+            cluster=self.cluster,
+        )
 
     def test_init(self):
         rec = self.rec
         self.assertEqual(rec.data, self.data)
 
         self.assertEqual(rec.coincidences_group, self.data.get_node.return_value)
         self.data.get_node.assert_called_once_with(sentinel.coin_group)
         self.assertEqual(rec.coincidences, self.data.get_node.return_value.coincidences)
 
         self.assertEqual(rec.overwrite, sentinel.overwrite)
-        self.assertEqual(rec.progress, sentinel.progress)
+        self.assertFalse(rec.progress)
         self.assertFalse(rec.verbose)
         self.assertEqual(rec.destination, sentinel.destination)
         self.assertEqual(rec.offsets, {})
 
         self.cq.assert_called_once_with(self.data, rec.coincidences_group)
         self.assertEqual(self.rec.cq, self.cq.return_value)
 
@@ -241,78 +273,100 @@
         mock_station.return_value = sentinel.station
         station = MagicMock(number=sentinel.number, spec=['number'])
         self.rec.cluster.stations = [station]
         self.rec.get_station_timing_offsets()
         self.assertEqual(list(self.rec.offsets.keys()), [sentinel.number])
         self.assertEqual(list(self.rec.offsets.values()), [sentinel.station])
 
-        detector = MagicMock(offset=1.)
-        station = MagicMock(number=sentinel.number, gps_offset=2., detectors=[detector],
-                            spec=['gps_offset', 'number'])
+        detector = MagicMock(offset=1.0)
+        station = MagicMock(number=sentinel.number, gps_offset=2.0, detectors=[detector], spec=['gps_offset', 'number'])
         self.rec.cluster.stations = [station]
         self.rec.get_station_timing_offsets()
         self.assertEqual(list(self.rec.offsets.keys()), [sentinel.number])
-        self.assertEqual(list(self.rec.offsets.values()), [[3.]])
+        self.assertEqual(list(self.rec.offsets.values()), [[3.0]])
 
     def test_reconstruct_directions(self):
         self.rec.coincidences = MagicMock()
         self.rec.coincidences.nrows = 1
         self.rec.direction = MagicMock()
         self.rec.direction.reconstruct_coincidences.return_value = (sentinel.theta, sentinel.phi, sentinel.nums)
         self.rec.reconstruct_directions()
         self.rec.direction.reconstruct_coincidences.assert_called_once_with(
-            self.rec.cq.all_events.return_value, None, self.rec.offsets, progress=False, initials=[])
+            self.rec.cq.all_events.return_value,
+            None,
+            self.rec.offsets,
+            progress=False,
+            initials=[],
+        )
         self.assertEqual(self.rec.theta, sentinel.theta)
         self.assertEqual(self.rec.phi, sentinel.phi)
         self.assertEqual(self.rec.station_numbers, sentinel.nums)
 
         self.rec.reconstruct_directions(sentinel.nums)
         self.rec.direction.reconstruct_coincidences.assert_called_with(
-            self.rec.cq.all_events.return_value, sentinel.nums, self.rec.offsets, progress=False, initials=[])
+            self.rec.cq.all_events.return_value,
+            sentinel.nums,
+            self.rec.offsets,
+            progress=False,
+            initials=[],
+        )
 
     def test_reconstruct_cores(self):
         self.rec.coincidences = MagicMock()
         self.rec.coincidences.nrows = 1
         self.rec.core = MagicMock()
         self.rec.core.reconstruct_coincidences.return_value = (sentinel.core_x, sentinel.core_y)
         self.rec.reconstruct_cores()
         self.rec.core.reconstruct_coincidences.assert_called_once_with(
-            self.rec.cq.all_events.return_value, None, progress=False, initials=[])
+            self.rec.cq.all_events.return_value,
+            None,
+            progress=False,
+            initials=[],
+        )
         self.assertEqual(self.rec.core_x, sentinel.core_x)
         self.assertEqual(self.rec.core_y, sentinel.core_y)
 
         self.rec.reconstruct_cores(sentinel.nums)
         self.rec.core.reconstruct_coincidences.assert_called_with(
-            self.rec.cq.all_events.return_value, sentinel.nums, progress=False, initials=[])
+            self.rec.cq.all_events.return_value,
+            sentinel.nums,
+            progress=False,
+            initials=[],
+        )
 
     def test_prepare_output(self):
         self.rec.coincidences = MagicMock()
         self.rec.coincidences.nrows = sentinel.nrows
         self.cluster.stations.return_value = []
         self.rec.prepare_output()
         self.data.create_table.assert_called_once_with(
-            self.rec.coincidences_group, sentinel.destination,
-            reconstructions.ReconstructedCoincidence, expectedrows=sentinel.nrows)
+            self.rec.coincidences_group,
+            sentinel.destination,
+            reconstructions.ReconstructedCoincidence,
+            expectedrows=sentinel.nrows,
+        )
         self.assertEqual(self.rec.reconstructions, self.data.create_table.return_value)
         self.assertEqual(self.rec.reconstructions._v_attrs.cluster, self.cluster)
 
     def test_prepare_output_existing(self):
         self.rec.coincidences = MagicMock()
         self.rec.coincidences.nrows = sentinel.nrows
         self.cluster.stations.return_value = []
         self.rec.coincidences_group = [sentinel.destination]
 
         # Overwrite existing
         self.rec.overwrite = True
         self.rec.prepare_output()
-        self.data.remove_node.assert_called_once_with(
-            self.rec.coincidences_group, sentinel.destination, recursive=True)
+        self.data.remove_node.assert_called_once_with(self.rec.coincidences_group, sentinel.destination, recursive=True)
         self.data.create_table.assert_called_with(
-            self.rec.coincidences_group, sentinel.destination,
-            reconstructions.ReconstructedCoincidence, expectedrows=sentinel.nrows)
+            self.rec.coincidences_group,
+            sentinel.destination,
+            reconstructions.ReconstructedCoincidence,
+            expectedrows=sentinel.nrows,
+        )
         self.assertEqual(self.rec.reconstructions, self.data.create_table.return_value)
         self.assertEqual(self.rec.reconstructions._v_attrs.cluster, self.cluster)
 
         # Raise exception if table already exists
         self.rec.overwrite = False
         self.assertRaises(RuntimeError, self.rec.prepare_output)
 
@@ -321,41 +375,47 @@
         self.rec.coincidences = MagicMock()
         self.rec.coincidences.nrows = sentinel.nrows
         station = MagicMock()
         station.number = 1
         self.rec.cluster.stations = [station]
 
         self.rec.prepare_output()
-        mock_description.columns.update.assert_called_once_with(
-            {'s1': reconstructions.tables.BoolCol(pos=26)})
+        mock_description.columns.update.assert_called_once_with({'s1': reconstructions.tables.BoolCol(pos=26)})
         self.data.create_table.assert_called_with(
-            self.rec.coincidences_group, sentinel.destination, mock_description,
-            expectedrows=sentinel.nrows)
+            self.rec.coincidences_group,
+            sentinel.destination,
+            mock_description,
+            expectedrows=sentinel.nrows,
+        )
 
     def test__store_reconstruction(self):
         coin = MagicMock()
         self.rec.reconstructions = MagicMock()
-        self.rec._store_reconstruction(coin, sentinel.core_x, sentinel.core_y,
-                                       sentinel.theta, sentinel.phi, [2, 3, 4])
+        self.rec._store_reconstruction(coin, sentinel.core_x, sentinel.core_y, sentinel.theta, sentinel.phi, [2, 3, 4])
         self.rec.reconstructions.row.append.assert_called_once_with()
 
 
 class ReconstructESDCoincidencesFromSourceTest(ReconstructESDCoincidencesTest):
-
     @patch.object(reconstructions, 'CoincidenceQuery')
     def setUp(self, mock_cq):
         self.data = MagicMock()
         self.dest_data = MagicMock()
         self.cluster = MagicMock()
         self.cq = mock_cq
         self.rec = reconstructions.ReconstructESDCoincidencesFromSource(
-            self.data, self.dest_data, sentinel.coin_group,
-            sentinel.dest_group, overwrite=sentinel.overwrite,
-            progress=sentinel.progress, verbose=False,
-            destination=sentinel.destination, cluster=self.cluster)
+            self.data,
+            self.dest_data,
+            sentinel.coin_group,
+            sentinel.dest_group,
+            overwrite=sentinel.overwrite,
+            progress=False,
+            verbose=False,
+            destination=sentinel.destination,
+            cluster=self.cluster,
+        )
 
     @unittest.skip('WIP')
     def test_prepare_output(self):
         pass
 
     @unittest.skip('WIP')
     def test_prepare_output_existing(self):
@@ -363,39 +423,39 @@
 
     @unittest.skip('WIP')
     def test_prepare_output_columns(self):
         pass
 
 
 class ReconstructSimulatedCoincidencesTest(unittest.TestCase):
-
     def setUp(self):
         self.data = MagicMock()
 
     def tearDown(self):
         if isinstance(self.data, tables.file.File):
             self.data.close()
 
     @patch.object(reconstructions, 'CoincidenceQuery')
     def test_cluster_is_object(self, mock_cq):
         cluster = MagicMock()
         rec = reconstructions.ReconstructSimulatedCoincidences(
-            self.data, sentinel.coin_group, overwrite=sentinel.overwrite,
-            progress=sentinel.progress, verbose=False,
-            destination=sentinel.destination, cluster=cluster)
+            self.data,
+            sentinel.coin_group,
+            overwrite=sentinel.overwrite,
+            progress=False,
+            verbose=False,
+            destination=sentinel.destination,
+            cluster=cluster,
+        )
         self.assertEqual(rec.cluster, cluster)
 
     def test_read_object_from_hdf5(self):
         fn = self.get_testdata_path(TEST_DATA_FILE)
         self.data = tables.open_file(fn, 'r')
         rec = reconstructions.ReconstructSimulatedCoincidences(self.data)
 
         # isinstance does not work on classes that are read from pickles.
         self.assertEqual(rec.cluster.stations[0].station_id, 0)
 
     def get_testdata_path(self, fn):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, fn)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/analysis/test_time_deltas.py` & `hisparc_sapphire-3.0.0/sapphire/tests/analysis/test_time_deltas.py`

 * *Files 13% similar despite different names*

```diff
@@ -11,21 +11,19 @@
 
 TEST_DATA_FILE = 'test_data/esd_coincidences.h5'
 
 
 class ProcessTimeDeltasTests(unittest.TestCase):
     def setUp(self):
         self.data_path = self.create_tempfile_from_testdata()
+        self.addCleanup(os.remove, self.data_path)
         self.data = tables.open_file(self.data_path, 'a')
+        self.addCleanup(self.data.close)
         self.td = time_deltas.ProcessTimeDeltas(self.data, progress=False)
 
-    def tearDown(self):
-        self.data.close()
-        os.remove(self.data_path)
-
     def test_init(self):
         self.assertEqual(self.td.progress, False)
         self.assertEqual(self.td.data, self.data)
 
     def test_find_station_pairs(self):
         self.td.find_station_pairs()
         self.assertEqual(self.td.pairs, {(501, 502)})
@@ -34,26 +32,30 @@
     def test_get_detector_offsets(self, mock_station):
         mock_offsets = Mock()
         mock_station.return_value = mock_offsets
 
         self.td.pairs = {(sentinel.station1, sentinel.station2), (sentinel.station1, sentinel.station3)}
         self.td.get_detector_offsets()
 
-        self.assertEqual(self.td.detector_timing_offsets,
-                         {sentinel.station1: mock_offsets.detector_timing_offset,
-                          sentinel.station2: mock_offsets.detector_timing_offset,
-                          sentinel.station3: mock_offsets.detector_timing_offset})
+        self.assertEqual(
+            self.td.detector_timing_offsets,
+            {
+                sentinel.station1: mock_offsets.detector_timing_offset,
+                sentinel.station2: mock_offsets.detector_timing_offset,
+                sentinel.station3: mock_offsets.detector_timing_offset,
+            },
+        )
 
     def test_store_time_deltas(self):
         pair = (501, 502)
         node_path = '/coincidences/time_deltas/station_%d/station_%d' % pair
         self.assertRaises(Exception, self.data.get_node, node_path, 'time_deltas')
-        self.td.store_time_deltas([12345678987654321], [2.5], pair)
+        self.td.store_time_deltas([12345678_987654321], [2.5], pair)
         stored_data = self.data.get_node(node_path, 'time_deltas')
-        self.assertEqual(list(stored_data[0]), [12345678987654321, 12345678, 987654321, 2.5])
+        self.assertEqual(list(stored_data[0]), [12345678_987654321, 12345678, 987654321, 2.5])
 
     def create_tempfile_from_testdata(self):
         tmp_path = self.create_tempfile_path()
         data_path = self.get_testdata_path()
         shutil.copyfile(data_path, tmp_path)
         return tmp_path
 
@@ -61,11 +63,7 @@
         fd, path = tempfile.mkstemp('.h5')
         os.close(fd)
         return path
 
     def get_testdata_path(self):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_DATA_FILE)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_blocks.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_blocks.py`

 * *Files 27% similar despite different names*

```diff
@@ -2,145 +2,138 @@
 
 from math import atan2, sqrt
 
 from sapphire.corsika import blocks
 
 try:
     import numba
+
     numba.__version__  # stop flake8 from complaining about unused module
 except ImportError:
     numba_available = False
 else:
     numba_available = True
 
 
 class CorsikaBlocksTests(unittest.TestCase):
     def setUp(self):
         self.format = blocks.Format()
 
-    def tearDown(self):
-        pass
-
     def test_validate_block_format(self):
         """Verify that the block format is logical"""
 
-        self.assertEqual((self.format.block_size - 2 * self.format.block_padding_size) / self.format.subblock_size,
-                         self.format.subblocks_per_block,
-                         msg=('The block format ({block}) and sub-block format '
-                              '({sub_block}) do not agree! block size is {block_size} '
-                              'and sub-block size is {sub_block_size}. Block size should'
-                              ' be {subblocks_per_block} times the sub-block size plus '
-                              'padding (usually 8 bytes).'
-                              .format(block=self.format.block_format,
-                                      sub_block=self.format.subblock_format,
-                                      block_size=self.format.block_size,
-                                      sub_block_size=self.format.subblock_size,
-                                      subblocks_per_block=self.format.subblocks_per_block)))
+        self.assertEqual(
+            (self.format.block_size - 2 * self.format.block_padding_size) / self.format.subblock_size,
+            self.format.subblocks_per_block,
+            msg=(
+                f'The block format ({self.format.block_format}) and sub-block format '
+                f'({self.format.subblock_format}) do not agree! block size is {self.format.block_size} '
+                f'and sub-block size is {self.format.subblock_size}. Block size should'
+                f' be {self.format.subblocks_per_block} times the sub-block size plus '
+                'padding (usually 8 bytes).'
+            ),
+        )
 
     def test_validate_subblock_format(self):
         """Verify that the subblock format is logical"""
 
-        self.assertEqual(self.format.subblock_size / self.format.particle_size,
-                         self.format.particles_per_subblock,
-                         msg=('The sub_block format ({sub_block}) and particle format '
-                              '({particle}) do not agree! sub-block size is '
-                              '{sub_block_size} and particle record size is '
-                              '{particle_size}. Sub-block size should be '
-                              '{particles_per_subblock} times the particle record size.'
-                              .format(sub_block=self.format.subblock_format,
-                                      particle=self.format.particle_format,
-                                      sub_block_size=self.format.subblock_size,
-                                      particle_size=self.format.particle_size,
-                                      particles_per_subblock=self.format.particles_per_subblock)))
+        self.assertEqual(
+            self.format.subblock_size / self.format.particle_size,
+            self.format.particles_per_subblock,
+            msg=(
+                f'The sub_block format ({self.format.subblock_format}) and particle format '
+                f'({self.format.particle_format}) do not agree! sub-block size is '
+                f'{self.format.subblock_size} and particle record size is '
+                f'{self.format.particle_size}. Sub-block size should be '
+                f'{self.format.particles_per_subblock} times the particle record size.'
+            ),
+        )
 
     def test_validate_particle_format(self):
         """Verify that the particle format is correct"""
 
-        self.assertEqual(self.format.particle_format, '7f',
-                         msg=('The particle format ({particle}) is incorrect.'
-                              .format(particle=self.format.particle_format)))
+        self.assertEqual(
+            self.format.particle_format,
+            '7f',
+            msg=(f'The particle format ({self.format.particle_format}) is incorrect.'),
+        )
 
 
 class CorsikaBlocksThinTests(CorsikaBlocksTests):
     def setUp(self):
         self.format = blocks.FormatThin()
 
     def test_validate_particle_format(self):
         """Verify that the particle format is correct"""
 
-        self.assertEqual(self.format.particle_format, '8f',
-                         msg=('The thinned particle format ({particle}) is incorrect.'
-                              .format(particle=self.format.particle_format)))
+        self.assertEqual(
+            self.format.particle_format,
+            '8f',
+            msg=(f'The thinned particle format ({self.format.particle_format}) is incorrect.'),
+        )
 
 
 class ParticleDataTests(unittest.TestCase):
-
     def setUp(self):
         # Input
-        id = 1000
-        p_x = 2.  # GeV
-        p_y = 1.  # GeV
-        p_z = 10.  # GeV
-        x = 300.  # cm
-        y = 400.  # cm
-        t = 12345678.  # ns
+        particle_id = 1000
+        p_x = 2.0  # GeV
+        p_y = 1.0  # GeV
+        p_z = 10.0  # GeV
+        x = 300.0  # cm
+        y = 400.0  # cm
+        t = 12345678.0  # ns
 
-        self.subblock = (id, p_x, p_y, p_z, x, y, t)
+        self.subblock = (particle_id, p_x, p_y, p_z, x, y, t)
 
         # Output
         p_x *= 1e9  # eV
         p_y *= 1e9
         p_z *= 1e9
         x *= 1e-2  # m
         y *= 1e-2
-        r = sqrt(x ** 2 + y ** 2)
+        r = sqrt(x**2 + y**2)
         phi = atan2(x, -y)
 
-        self.result = (p_x, p_y, -p_z, -y, x, t, id / 1000, r, id / 10 % 100,
-                       id % 10, phi)
+        self.result = (p_x, p_y, -p_z, -y, x, t, particle_id / 1000, r, particle_id / 10 % 100, particle_id % 10, phi)
 
     def test_particle_data(self):
         """Verify conversion of particle information by particle_data()"""
 
         self.assertAlmostEqual(blocks.particle_data(self.subblock), self.result)
 
-    @unittest.skipUnless(numba_available, "Numba required")
+    @unittest.skipUnless(numba_available, 'Numba required')
     def test_numba_jit(self):
         """Verify particle_data() with numba JIT disabled"""
 
         self.assertTrue(hasattr(blocks.particle_data, '__numba__'))
-        old_value = getattr(numba.config, 'DISABLE_JIT')
-        setattr(numba.config, 'DISABLE_JIT', 1)
+        old_value = numba.config.DISABLE_JIT
+        numba.config.DISABLE_JIT = 1
         self.assertAlmostEqual(blocks.particle_data(self.subblock), self.result)
-        setattr(numba.config, 'DISABLE_JIT', old_value)
+        numba.config.DISABLE_JIT = old_value
 
 
 class ParticleDataThinTests(ParticleDataTests):
-
     def setUp(self):
         super().setUp()
 
         # Input
-        weight = 9.
+        weight = 9.0
         self.subblock = self.subblock + (weight,)
 
         # Output
         self.result = self.result + (weight,)
 
     def test_particle_data(self):
         """Verify conversion of particle information by particle_data()"""
 
         self.assertAlmostEqual(blocks.particle_data_thin(self.subblock), self.result)
 
-    @unittest.skipUnless(numba_available, "Numba required")
+    @unittest.skipUnless(numba_available, 'Numba required')
     def test_numba_jit(self):
         """Verify particle_data() with numba JIT disabled"""
 
         self.assertTrue(hasattr(blocks.particle_data_thin, '__numba__'))
-        old_value = getattr(numba.config, 'DISABLE_JIT')
-        setattr(numba.config, 'DISABLE_JIT', 1)
+        old_value = numba.config.DISABLE_JIT
+        numba.config.DISABLE_JIT = 1
         self.assertAlmostEqual(blocks.particle_data_thin(self.subblock), self.result)
-        setattr(numba.config, 'DISABLE_JIT', old_value)
-
-
-if __name__ == '__main__':
-    unittest.main()
+        numba.config.DISABLE_JIT = old_value
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_corsika.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_corsika.py`

 * *Files 11% similar despite different names*

```diff
@@ -8,31 +8,29 @@
 data_file_dir = os.path.dirname(__file__)
 DATA_FILE = os.path.join(data_file_dir, 'test_data/1_2/DAT000000')
 
 
 class CorsikaFileTests(unittest.TestCase):
     def setUp(self):
         self.file = corsika.reader.CorsikaFile(DATA_FILE)
-
-    def tearDown(self):
-        self.file.finish()
+        self.addCleanup(self.file.finish)
 
     def test_validate_file(self):
         """Verify that the data file is valid"""
 
         self.assertTrue(self.file.check())
 
     def test_run_header(self):
         """Verify that the Run header is properly read"""
 
         header = self.file.get_header()
         self.assertIsInstance(header, corsika.blocks.RunHeader)
         self.assertEqual(header.id, b'RUNH')
         self.assertAlmostEqual(header.version, 7.4, 4)
-        for h in [10., 5000., 30000., 50000., 110000.]:
+        for h in [10.0, 5000.0, 30000.0, 50000.0, 110000.0]:
             t = header.height_to_thickness(h)
             self.assertAlmostEqual(header.thickness_to_height(t), h, 8)
 
     def test_run_end(self):
         """Verify that the Run end is properly read"""
 
         end = self.file.get_end()
@@ -54,15 +52,15 @@
         events = self.file.get_events()
         event = next(events)
         header = event.get_header()
         self.assertIsInstance(header, corsika.blocks.EventHeader)
         self.assertEqual(header.id, b'EVTH')
         self.assertEqual(corsika.particles.name(header.particle_id), 'proton')
         self.assertEqual(header.energy, 1e14)
-        self.assertEqual(header.azimuth, -pi / 2.)
+        self.assertEqual(header.azimuth, -pi / 2.0)
         self.assertEqual(header.zenith, 0.0)
         self.assertEqual(header.hadron_model_high, 'QGSJET')
 
     def test_event_end(self):
         """Verify that the Event end is properly read"""
 
         events = self.file.get_events()
@@ -83,11 +81,7 @@
         self.assertEqual(len(particle), 11)
         self.assertEqual(corsika.particles.name(int(particle[6])), 'muon_p')
         self.assertAlmostEqual(particle[3], -56.2846679688)
         self.assertAlmostEqual(particle[4], -172.535859375)
         self.assertAlmostEqual(particle[7], 181.484397728)
         particle = next(particles)
         self.assertEqual(corsika.particles.name(int(particle[6])), 'muon_m')
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_corsika_queries.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_corsika_queries.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,20 +7,17 @@
 
 from sapphire.corsika import corsika_queries
 
 TEST_OVERVIEW_FILE = 'test_data/corsika_overview.h5'
 
 
 class CorsikaQueryTest(unittest.TestCase):
-
     def setUp(self):
         self.cq = corsika_queries.CorsikaQuery(self.get_overview_path())
-
-    def tearDown(self):
-        self.cq.finish()
+        self.addCleanup(self.cq.finish)
 
     def test_seeds(self):
         result = self.cq.seeds(self.cq.all_simulations())
         self.assertEqual(result, ['1_2', '3_4'])
 
         result = self.cq.seeds(self.cq.all_simulations(), iterator=True)
         self.assertEqual(list(result), ['1_2', '3_4'])
@@ -30,57 +27,55 @@
         self.assertEqual(result, self.cq.sims[0])
         self.assertRaises(ValueError, self.cq.get_info, '1')
         self.assertRaises(ValueError, self.cq.get_info, '1_2_3')
         self.assertRaises(IndexError, self.cq.get_info, '1_3')
 
     def test_all_energies(self):
         energies = list(self.cq.all_energies)
-        assert_allclose(energies, [14.])
+        assert_allclose(energies, [14.0])
 
     def test_all_particles(self):
         particles = self.cq.all_particles
         self.assertEqual(particles, {'proton'})
 
     def test_all_azimuths(self):
         azimuths = self.cq.all_azimuths
-        self.assertEqual(azimuths, {-90.})
+        self.assertEqual(azimuths, {-90.0})
 
     def test_all_zeniths(self):
         zeniths = self.cq.all_zeniths
-        self.assertEqual(zeniths, {0.})
+        self.assertEqual(zeniths, {0.0})
 
     def test_available_parameters(self):
         result = list(self.cq.available_parameters('energy', particle='proton'))
         assert_allclose(result, [14.0])
-        result = self.cq.available_parameters('particle_id', zenith=0.)
+        result = self.cq.available_parameters('particle_id', zenith=0.0)
         self.assertEqual(result, {'proton'})
-        result = self.cq.available_parameters('zenith', azimuth=-90.)
-        self.assertEqual(result, {0.})
+        result = self.cq.available_parameters('zenith', azimuth=-90.0)
+        self.assertEqual(result, {0.0})
         self.assertRaises(RuntimeError, self.cq.available_parameters, 'zenith', energy=19)
         self.assertRaises(RuntimeError, self.cq.available_parameters, 'zenith', particle='iron')
 
     def get_overview_path(self):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_OVERVIEW_FILE)
 
 
 class MockCorsikaQueryTest(unittest.TestCase):
-
     @patch.object(corsika_queries.tables, 'open_file')
     def setUp(self, mock_open):
         self.mock_open = mock_open
         self.data_path = sentinel.data_path
         self.simulations_group = sentinel.simulations_group
 
         self.cq = corsika_queries.CorsikaQuery(self.data_path, self.simulations_group)
 
     def test_init(self):
         self.mock_open.assert_called_once_with(self.data_path, 'r')
-        self.mock_open.return_value.get_node.assert_called_once_with(
-            sentinel.simulations_group)
+        self.mock_open.return_value.get_node.assert_called_once_with(sentinel.simulations_group)
 
     @patch.object(corsika_queries.tables, 'open_file')
     def test_init_file(self, mock_open):
         data = MagicMock(spec=corsika_queries.tables.File)
         corsika_queries.CorsikaQuery(data, sentinel.simulations_group)
         data.get_node.assert_called_once_with(sentinel.simulations_group)
         self.assertFalse(mock_open.called)
@@ -94,40 +89,41 @@
         mock_perform.return_value = sentinel.simulations
         result = self.cq.simulations(particle=None)
         self.assertEqual(result, sentinel.simulations)
         mock_perform.assert_called_once_with('', False)
 
         self.cq.all_particles = ['electron']
         self.cq.all_energies = [15.5]
-        result = self.cq.simulations(particle='electron', energy=15.5,
-                                     zenith=0., azimuth=0.)
+        result = self.cq.simulations(particle='electron', energy=15.5, zenith=0.0, azimuth=0.0)
         self.assertEqual(result, sentinel.simulations)
         mock_perform.assert_called_with(
             '(particle_id == 3) & '
             '(abs(log10(energy) - 15.5) < 1e-4) & '
             '(abs(zenith - 0.0) < 1e-4) & '
-            '(abs(azimuth - 0.0) < 1e-4)', False)
+            '(abs(azimuth - 0.0) < 1e-4)',
+            False,
+        )
 
     def test_filter(self):
-        filter = self.cq.filter('foo', 123)
-        self.assertEqual(filter, '(foo == 123)')
+        tables_filter = self.cq.filter('foo', 123)
+        self.assertEqual(tables_filter, '(foo == 123)')
 
     def test_float_filter(self):
-        filter = self.cq.float_filter('foo', 12.3)
-        self.assertEqual(filter, '(abs(foo - 12.3) < 1e-4)')
+        tables_filter = self.cq.float_filter('foo', 12.3)
+        self.assertEqual(tables_filter, '(abs(foo - 12.3) < 1e-4)')
 
     def test_range_filter(self):
-        filter = self.cq.range_filter('foo', 12.3, 14.5)
-        self.assertEqual(filter, '(foo >= 12.3) & (foo <= 14.5)')
-        filter = self.cq.range_filter('foo', 12.3)
-        self.assertEqual(filter, '(foo >= 12.3)')
-        filter = self.cq.range_filter('foo', max=14.5)
-        self.assertEqual(filter, '(foo <= 14.5)')
-        filter = self.cq.range_filter('foo')
-        self.assertEqual(filter, '')
+        tables_filter = self.cq.range_filter('foo', 12.3, 14.5)
+        self.assertEqual(tables_filter, '(foo >= 12.3) & (foo <= 14.5)')
+        tables_filter = self.cq.range_filter('foo', 12.3)
+        self.assertEqual(tables_filter, '(foo >= 12.3)')
+        tables_filter = self.cq.range_filter('foo', max_value=14.5)
+        self.assertEqual(tables_filter, '(foo <= 14.5)')
+        tables_filter = self.cq.range_filter('foo')
+        self.assertEqual(tables_filter, '')
 
     def test_all_simulations(self):
         result = self.cq.all_simulations()
         self.cq.sims.read.assert_called_once_with()
         self.assertEqual(result, self.cq.sims.read.return_value)
 
         result = self.cq.all_simulations(iterator=True)
@@ -138,11 +134,7 @@
         result = self.cq.perform_query(sentinel.query, iterator=True)
         self.assertEqual(result, self.cq.sims.where.return_value)
         self.cq.sims.where.assert_called_once_with(sentinel.query)
 
         result = self.cq.perform_query(sentinel.query, iterator=False)
         self.assertEqual(result, self.cq.sims.read_where.return_value)
         self.cq.sims.read_where.assert_called_once_with(sentinel.query)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/1_2/DAT000000` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/1_2/DAT000000`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/1_2/corsika.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/1_2/corsika.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/3_4/DAT000000` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/3_4/DAT000000`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/3_4/corsika.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/3_4/corsika.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_data/corsika_overview.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_data/corsika_overview.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_generate_corsika_overview.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_generate_corsika_overview.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,59 +1,35 @@
 import os
-import subprocess
 import tempfile
 import unittest
 
 from sapphire.corsika.generate_corsika_overview import generate_corsika_overview
 from sapphire.tests.validate_results import validate_results
 
 TEST_DATA_PATH = 'test_data/'
 TEST_EXPECTED_FILE = 'test_data/corsika_overview.h5'
 STORE_SCRIPT = 'generate_corsika_overview {source} {destination}'
 
 
 class GenerateCorsikaOverviewTests(unittest.TestCase):
-
     def setUp(self):
         self.source_path = self.get_testdata_path()
         self.expected_path = self.get_expected_path()
         self.destination_path = self.create_tempfile_path()
-
-    def tearDown(self):
-        os.remove(self.destination_path)
+        self.addCleanup(os.remove, self.destination_path)
 
     def test_store_data(self):
-        generate_corsika_overview(source=self.source_path,
-                                  destination=self.destination_path)
+        generate_corsika_overview(source=self.source_path, destination=self.destination_path)
         validate_results(self, self.expected_path, self.destination_path)
 
     def create_tempfile_path(self):
         fd, path = tempfile.mkstemp('.h5')
         os.close(fd)
         return path
 
     def get_testdata_path(self):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_DATA_PATH)
 
     def get_expected_path(self):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_EXPECTED_FILE)
-
-
-class GenerateCorsikaOverviewCommandTests(GenerateCorsikaOverviewTests):
-
-    def setUp(self):
-        self.source_path = self.get_testdata_path()
-        self.expected_path = self.get_expected_path()
-        self.destination_path = self.create_tempfile_path()
-        self.command = STORE_SCRIPT.format(source=self.source_path,
-                                           destination=self.destination_path)
-
-    def test_store_data(self):
-        result = subprocess.check_output(self.command, shell=True)
-        self.assertEqual(result, b'')
-        validate_results(self, self.expected_path, self.destination_path)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_particles.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_particles.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,55 +1,49 @@
 import unittest
 
 from sapphire.corsika import particles
 
 
 class CorsikaParticlesTests(unittest.TestCase):
-
     def setUp(self):
-        self.pid_name = [(1, 'gamma'),
-                         (2, 'positron'),
-                         (3, 'electron'),
-                         (5, 'muon_p'),
-                         (6, 'muon_m'),
-                         (13, 'neutron'),
-                         (14, 'proton'),
-                         (201, 'deuteron'),
-                         (301, 'tritium'),
-                         (302, 'helium3'),
-                         (402, 'alpha'),
-                         (1206, 'carbon'),
-                         (1407, 'nitrogen'),
-                         (1608, 'oxygen'),
-                         (2713, 'aluminium'),
-                         (2814, 'silicon'),
-                         (3216, 'sulfur'),
-                         (5626, 'iron')]
-        self.massless_atoms = [(909, 'fluorine'),
-                               (3232, 'germanium'),
-                               (9999, 'einsteinium')]
-        self.atoms = [(1406, 'carbon14'),
-                      (9999, 'einsteinium99')]
+        self.pid_name = [
+            (1, 'gamma'),
+            (2, 'positron'),
+            (3, 'electron'),
+            (5, 'muon_p'),
+            (6, 'muon_m'),
+            (13, 'neutron'),
+            (14, 'proton'),
+            (201, 'deuteron'),
+            (301, 'tritium'),
+            (302, 'helium3'),
+            (402, 'alpha'),
+            (1206, 'carbon'),
+            (1407, 'nitrogen'),
+            (1608, 'oxygen'),
+            (2713, 'aluminium'),
+            (2814, 'silicon'),
+            (3216, 'sulfur'),
+            (5626, 'iron'),
+        ]
+        self.massless_atoms = [(909, 'fluorine'), (3232, 'germanium'), (9999, 'einsteinium')]
+        self.atoms = [(1406, 'carbon14'), (9999, 'einsteinium99')]
 
     def test_particle_ids(self):
         """Verify that the correct names belong to each ID"""
 
-        for id, name in self.pid_name:
-            self.assertEqual(particles.ID[id], name)
+        for particle_id, name in self.pid_name:
+            self.assertEqual(particles.ID[particle_id], name)
 
     def test_conversion_functions(self):
         """Verify that the functions correctly convert back and forth"""
 
-        for id, name in self.pid_name:
-            self.assertEqual(particles.name(id), name)
-            self.assertEqual(particles.particle_id(name), id)
-
-        for id, name in self.massless_atoms:
-            self.assertEqual(particles.particle_id(name), id)
-
-        for id, name in self.atoms:
-            self.assertEqual(particles.name(id), name)
-            self.assertEqual(particles.particle_id(name), id)
-
-
-if __name__ == '__main__':
-    unittest.main()
+        for particle_id, name in self.pid_name:
+            self.assertEqual(particles.name(particle_id), name)
+            self.assertEqual(particles.particle_id(name), particle_id)
+
+        for particle_id, name in self.massless_atoms:
+            self.assertEqual(particles.particle_id(name), particle_id)
+
+        for particle_id, name in self.atoms:
+            self.assertEqual(particles.name(particle_id), name)
+            self.assertEqual(particles.particle_id(name), particle_id)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_qsub_corsika.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_qsub_corsika.py`

 * *Files 3% similar despite different names*

```diff
@@ -4,24 +4,22 @@
 
 from unittest.mock import mock_open, patch, sentinel
 
 from sapphire.corsika import qsub_corsika
 
 
 class CorsikaBatchTest(unittest.TestCase):
-
     def setUp(self):
         self.cb = qsub_corsika.CorsikaBatch()
 
     @patch.object(qsub_corsika.particles, 'particle_id')
     def test_init(self, mock_particles):
         mock_particles.return_value = sentinel.particle_id
-        cb = qsub_corsika.CorsikaBatch(16, sentinel.particle, sentinel.zenith,
-                                       30, sentinel.queue, sentinel.corsika)
-        self.assertEqual(cb.energy_pre, 1.)
+        cb = qsub_corsika.CorsikaBatch(16, sentinel.particle, sentinel.zenith, 30, sentinel.queue, sentinel.corsika)
+        self.assertEqual(cb.energy_pre, 1.0)
         self.assertEqual(cb.energy_pow, 7)
         mock_particles.assert_called_once_with(sentinel.particle)
         self.assertEqual(cb.particle, sentinel.particle_id)
         self.assertEqual(cb.theta, sentinel.zenith)
         self.assertEqual(cb.phi, 120)
         self.assertEqual(cb.queue, sentinel.queue)
         self.assertEqual(cb.corsika, sentinel.corsika)
@@ -49,22 +47,24 @@
     @patch.object(qsub_corsika.CorsikaBatch, 'create_script')
     def test_submit_job(self, mock_create_script, mock_rundir, mock_submit_job):
         self.cb.seed1 = 123
         self.cb.seed2 = 456
         mock_rundir.return_value = '/data/123_456/'
         mock_create_script.return_value = sentinel.script
         self.cb.submit_job()
-        mock_submit_job.assert_called_once_with(sentinel.script, 'cor_123_456',
-                                                'generic', '-d /data/123_456/')
+        mock_submit_job.assert_called_once_with(sentinel.script, 'cor_123_456', 'generic', '-d /data/123_456/')
         # Check addition of walltime argument for long queue
         self.cb.queue = 'long'
         self.cb.submit_job()
-        mock_submit_job.assert_called_with(sentinel.script, 'cor_123_456',
-                                           'long',
-                                           '-d /data/123_456/ -l walltime=96:00:00')
+        mock_submit_job.assert_called_with(
+            sentinel.script,
+            'cor_123_456',
+            'long',
+            '-d /data/123_456/ -l walltime=96:00:00',
+        )
 
     @patch.object(qsub_corsika.os, 'listdir')
     def test_taken_seeds(self, mock_listdir):
         mock_listdir.return_value = [sentinel.dirs]
         taken = self.cb.taken_seeds()
         self.assertEqual(taken, [sentinel.dirs, sentinel.dirs])
         mock_listdir.assert_any_call(qsub_corsika.DATADIR)
@@ -112,86 +112,119 @@
             self.cb.create_input()
         mock_rundir.assert_called_once_with()
         mock_file.assert_called_once_with('/data/123_456/input-hisparc', 'w')
         self.assertTrue(mock_file().write.called)
 
 
 class MultipleJobsTest(unittest.TestCase):
-
     @patch.object(qsub_corsika.qsub, 'check_queue')
     def test_no_available_slots(self, mock_check_queue):
         """No slots available on queue"""
 
         mock_check_queue.return_value = 0
-        self.assertRaises(Exception, qsub_corsika.multiple_jobs, sentinel.n,
-                          sentinel.energy, sentinel.particle, sentinel.zenith,
-                          sentinel.azimuth, sentinel.queue, sentinel.corsika,
-                          progress=False)
+        self.assertRaises(
+            Exception,
+            qsub_corsika.multiple_jobs,
+            sentinel.n,
+            sentinel.energy,
+            sentinel.particle,
+            sentinel.zenith,
+            sentinel.azimuth,
+            sentinel.queue,
+            sentinel.corsika,
+            progress=False,
+        )
         mock_check_queue.assert_called_once_with(sentinel.queue)
 
     @patch.object(qsub_corsika, 'CorsikaBatch')
     @patch.object(qsub_corsika.qsub, 'check_queue')
     def test_one_available_wanted_more(self, mock_check_queue, mock_corsika_batch):
         """Only one slot available on queue"""
 
         mock_check_queue.return_value = 1
         with warnings.catch_warnings(record=True) as warned:
-            qsub_corsika.multiple_jobs(2, sentinel.energy, sentinel.particle,
-                                       sentinel.zenith, sentinel.azimuth,
-                                       sentinel.queue, sentinel.corsika,
-                                       progress=False)
+            qsub_corsika.multiple_jobs(
+                2,
+                sentinel.energy,
+                sentinel.particle,
+                sentinel.zenith,
+                sentinel.azimuth,
+                sentinel.queue,
+                sentinel.corsika,
+                progress=False,
+            )
         mock_check_queue.assert_called_once_with(sentinel.queue)
         mock_corsika_batch.assert_called_once_with(
-            energy=sentinel.energy, particle=sentinel.particle,
-            zenith=sentinel.zenith, azimuth=sentinel.azimuth,
-            queue=sentinel.queue, corsika=sentinel.corsika)
+            energy=sentinel.energy,
+            particle=sentinel.particle,
+            zenith=sentinel.zenith,
+            azimuth=sentinel.azimuth,
+            queue=sentinel.queue,
+            corsika=sentinel.corsika,
+        )
         mock_corsika_batch.return_value.run.assert_called_once_with()
         self.assertEqual(len(warned), 1)
 
     @patch.object(qsub_corsika, 'CorsikaBatch')
     @patch.object(qsub_corsika.qsub, 'check_queue')
     def test_two_available_wanted_more(self, mock_check_queue, mock_corsika_batch):
         """Only two slots available on queue"""
 
         mock_check_queue.return_value = 2
         with warnings.catch_warnings(record=True) as warned:
-            qsub_corsika.multiple_jobs(3, sentinel.energy, sentinel.particle,
-                                       sentinel.zenith, sentinel.azimuth,
-                                       sentinel.queue, sentinel.corsika,
-                                       progress=False)
+            qsub_corsika.multiple_jobs(
+                3,
+                sentinel.energy,
+                sentinel.particle,
+                sentinel.zenith,
+                sentinel.azimuth,
+                sentinel.queue,
+                sentinel.corsika,
+                progress=False,
+            )
         mock_check_queue.assert_called_once_with(sentinel.queue)
         mock_corsika_batch.assert_called_with(
-            energy=sentinel.energy, particle=sentinel.particle,
-            zenith=sentinel.zenith, azimuth=sentinel.azimuth,
-            queue=sentinel.queue, corsika=sentinel.corsika)
+            energy=sentinel.energy,
+            particle=sentinel.particle,
+            zenith=sentinel.zenith,
+            azimuth=sentinel.azimuth,
+            queue=sentinel.queue,
+            corsika=sentinel.corsika,
+        )
         mock_corsika_batch.return_value.run.assert_called_with()
         # This is twice as often because it includes the calls to run()
         self.assertEqual(len(mock_corsika_batch.mock_calls), 4)
         self.assertEqual(len(mock_corsika_batch.return_value.run.mock_calls), 2)
         self.assertEqual(len(warned), 1)
 
     @patch.object(qsub_corsika, 'CorsikaBatch')
     @patch.object(qsub_corsika.qsub, 'check_queue')
     def test_plenty_available(self, mock_check_queue, mock_corsika_batch):
         """Plenty of space on queue"""
 
         mock_check_queue.return_value = 50
         n = 10
         with warnings.catch_warnings(record=True) as warned:
-            qsub_corsika.multiple_jobs(n, sentinel.energy, sentinel.particle,
-                                       sentinel.zenith, sentinel.azimuth,
-                                       sentinel.queue, sentinel.corsika,
-                                       progress=False)
+            qsub_corsika.multiple_jobs(
+                n,
+                sentinel.energy,
+                sentinel.particle,
+                sentinel.zenith,
+                sentinel.azimuth,
+                sentinel.queue,
+                sentinel.corsika,
+                progress=False,
+            )
         mock_check_queue.assert_called_once_with(sentinel.queue)
         mock_corsika_batch.assert_called_with(
-            energy=sentinel.energy, particle=sentinel.particle,
-            zenith=sentinel.zenith, azimuth=sentinel.azimuth,
-            queue=sentinel.queue, corsika=sentinel.corsika)
+            energy=sentinel.energy,
+            particle=sentinel.particle,
+            zenith=sentinel.zenith,
+            azimuth=sentinel.azimuth,
+            queue=sentinel.queue,
+            corsika=sentinel.corsika,
+        )
         mock_corsika_batch.return_value.run.assert_called_with()
         # This is twice as often because it includes the calls to run()
         self.assertEqual(len(mock_corsika_batch.mock_calls), n * 2)
         self.assertEqual(len(mock_corsika_batch.return_value.run.mock_calls), n)
         self.assertEqual(len(warned), 0)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_qsub_store_corsika_data.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_qsub_store_corsika_data.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,15 +3,14 @@
 
 from unittest.mock import mock_open, patch, sentinel
 
 from sapphire.corsika import qsub_store_corsika_data
 
 
 class SeedsTest(unittest.TestCase):
-
     @patch.object(qsub_store_corsika_data.glob, 'glob')
     def test_all_seeds(self, mock_glob):
         mock_glob.return_value = ['/data/123_456', '/data/234_567']
         seeds = qsub_store_corsika_data.all_seeds()
         self.assertEqual(seeds, {'123_456', '234_567'})
         mock_glob.assert_called_once_with(qsub_store_corsika_data.DATADIR + '/*_*')
 
@@ -27,15 +26,15 @@
             seeds = qsub_store_corsika_data.seeds_in_queue()
         mock_file.assert_called_once_with(qsub_store_corsika_data.QUEUED_SEEDS)
         self.assertEqual(seeds, {'123_456', '234_567'})
         self.assertTrue(mock_file().read.called)
 
         # Empty set if log not available
         with patch.object(builtins, 'open', mock_open()) as mock_file:
-            mock_file.side_effect = IOError('no log!')
+            mock_file.side_effect = OSError('no log!')
             seeds = qsub_store_corsika_data.seeds_in_queue()
         mock_file.assert_called_with(qsub_store_corsika_data.QUEUED_SEEDS)
         self.assertEqual(seeds, set())
 
     def test_write_queued_seeds(self):
         mock_file = mock_open()
         seeds = {'123_456', '234_567'}
@@ -63,39 +62,46 @@
         mock_write.assert_called_once_with({sentinel.queued})
         self.assertEqual(seeds, {sentinel.unprocessed})
 
     def test_store_command(self):
         tmp = qsub_store_corsika_data.DATADIR
         qsub_store_corsika_data.DATADIR = '/data'
         command = qsub_store_corsika_data.store_command('123_456')
-        self.assertEqual(command, '/data/hisparc/env/miniconda/envs/corsika/bin/python '
-                                  '/data/hisparc/env/miniconda/envs/corsika/bin/store_corsika_data '
-                                  '/data/123_456/DAT000000 /data/123_456/corsika.h5')
+        self.assertEqual(
+            command,
+            '/data/hisparc/env/miniconda/envs/corsika/bin/python '
+            '/data/hisparc/env/miniconda/envs/corsika/bin/store_corsika_data '
+            '/data/123_456/DAT000000 /data/123_456/corsika.h5',
+        )
         qsub_store_corsika_data.DATADIR = tmp
 
     @patch.object(qsub_store_corsika_data.os.path, 'getsize')
     @patch.object(qsub_store_corsika_data.os, 'umask')
     @patch.object(qsub_store_corsika_data, 'get_seeds_todo')
     @patch.object(qsub_store_corsika_data.qsub, 'check_queue')
     @patch.object(qsub_store_corsika_data, 'store_command')
     @patch.object(qsub_store_corsika_data.qsub, 'submit_job')
     @patch.object(qsub_store_corsika_data, 'append_queued_seeds')
     @patch.object(qsub_store_corsika_data, 'SCRIPT_TEMPLATE')
-    def test_run(self, mock_template, mock_append, mock_submit, mock_store,
-                 mock_check, mock_get_seeds, mock_umask, mock_size):
+    def test_run(
+        self,
+        mock_template,
+        mock_append,
+        mock_submit,
+        mock_store,
+        mock_check,
+        mock_get_seeds,
+        mock_umask,
+        mock_size,
+    ):
         seeds = {'123_456', '234_567'}
         mock_size.return_value = 12355
         mock_get_seeds.return_value = seeds.copy()
         mock_check.return_value = 6
         mock_template.format.return_value = sentinel.script
         mock_store.return_value = sentinel.command
         qsub_store_corsika_data.run(sentinel.queue)
         for seed in seeds:
             mock_submit.assert_any_call(sentinel.script, seed, sentinel.queue, '')
             mock_append.assert_any_call([seed])
-        mock_template.format.assert_called_with(command=sentinel.command,
-                                                datadir=qsub_store_corsika_data.DATADIR)
+        mock_template.format.assert_called_with(command=sentinel.command, datadir=qsub_store_corsika_data.DATADIR)
         mock_umask.assert_called_once_with(0o02)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_store_corsika_data.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_store_corsika_data.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 import os
-import subprocess
 import tempfile
 import unittest
 
 from sapphire.corsika.store_corsika_data import store_and_sort_corsika_data
 from sapphire.tests.validate_results import validate_results
 
 TEST_DATA_FILE = 'test_data/1_2/DAT000000'
@@ -11,34 +10,35 @@
 STORE_CMD = 'store_corsika_data {source} {destination}'
 TEST_DATA_FILE_THIN = TEST_DATA_FILE.replace('1_2', '3_4')
 TEST_EXPECTED_FILE_THIN = TEST_EXPECTED_FILE.replace('1_2', '3_4')
 STORE_CMD_THIN = STORE_CMD + ' --thin'
 
 
 class StoreCorsikaDataTests(unittest.TestCase):
-
     """Store CORSIKA test using the function directly"""
 
     def setUp(self):
         self.source_path = self.get_testdata_path()
         self.expected_path = self.get_expected_path()
         self.destination_path = self.create_tempfile_path()
+        self.addCleanup(os.remove, self.destination_path)
         self.thin = False
 
-    def tearDown(self):
-        os.remove(self.destination_path)
-
     def test_store_data(self):
         # First with overwrite false
-        self.assertRaises(Exception, store_and_sort_corsika_data,
-                          self.source_path, self.destination_path,
-                          progress=True, thin=self.thin)
+        self.assertRaises(
+            Exception,
+            store_and_sort_corsika_data,
+            self.source_path,
+            self.destination_path,
+            progress=True,
+            thin=self.thin,
+        )
         # Now with overwrite true
-        store_and_sort_corsika_data(self.source_path, self.destination_path,
-                                    overwrite=True, thin=self.thin)
+        store_and_sort_corsika_data(self.source_path, self.destination_path, overwrite=True, thin=self.thin)
         validate_results(self, self.expected_path, self.destination_path)
 
     def create_tempfile_path(self):
         fd, path = tempfile.mkstemp('.h5')
         os.close(fd)
         return path
 
@@ -48,63 +48,20 @@
 
     def get_expected_path(self):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_EXPECTED_FILE)
 
 
 class StoreThinCorsikaDataTests(StoreCorsikaDataTests):
-
     """Store thinned CORSIKA test using the function directly"""
 
     def setUp(self):
         super().setUp()
         self.thin = True
 
     def get_testdata_path(self):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_DATA_FILE_THIN)
 
     def get_expected_path(self):
         dir_path = os.path.dirname(__file__)
         return os.path.join(dir_path, TEST_EXPECTED_FILE_THIN)
-
-
-class StoreCorsikaDataCommandTests(StoreCorsikaDataTests):
-
-    """Store CORSIKA test calling store command"""
-
-    def setUp(self):
-        self.source_path = self.get_testdata_path()
-        self.expected_path = self.get_expected_path()
-        self.destination_path = self.create_tempfile_path()
-        self.command = STORE_CMD.format(source=self.source_path,
-                                        destination=self.destination_path)
-
-    def test_store_data(self):
-        result = subprocess.check_output(self.command, shell=True)
-        self.assertEqual(result, b'')
-
-        self.assertRaises(subprocess.CalledProcessError,
-                          subprocess.check_output,
-                          self.command + ' --progress',
-                          stderr=subprocess.STDOUT, shell=True)
-
-        result = subprocess.check_output(self.command + ' --overwrite',
-                                         shell=True)
-        self.assertEqual(result, b'')
-
-        validate_results(self, self.expected_path, self.destination_path)
-
-
-class StoreThinCorsikaDataCommandTests(StoreCorsikaDataCommandTests,
-                                       StoreThinCorsikaDataTests):
-
-    """Store thinned CORSIKA test calling store command"""
-
-    def setUp(self):
-        super().setUp()
-        self.command = STORE_CMD_THIN.format(source=self.source_path,
-                                             destination=self.destination_path)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/corsika/test_units.py` & `hisparc_sapphire-3.0.0/sapphire/tests/corsika/test_units.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,49 +1,48 @@
 import math
 import unittest
 
 from sapphire.corsika import units
 
 
 class CorsikaUnitsTests(unittest.TestCase):
-
     def test_base_units(self):
         """Verify that the correct units are one"""
 
-        self.assertEqual(units.meter, 1.)
+        self.assertEqual(units.meter, 1.0)
         self.assertEqual(units.m, units.meter)
-        self.assertEqual(units.nanosecond, 1.)
+        self.assertEqual(units.nanosecond, 1.0)
         self.assertEqual(units.ns, units.nanosecond)
-        self.assertEqual(units.electronvolt, 1.)
+        self.assertEqual(units.electronvolt, 1.0)
         self.assertEqual(units.eV, units.electronvolt)
-        self.assertEqual(units.radian, 1.)
+        self.assertEqual(units.radian, 1.0)
         self.assertEqual(units.rad, units.radian)
-        self.assertEqual(units.eplus, 1.)
-        self.assertEqual(units.volt, 1.)
+        self.assertEqual(units.eplus, 1.0)
+        self.assertEqual(units.volt, 1.0)
         self.assertEqual(units.volt, units.electronvolt / units.eplus)
 
     def test_corsika_units(self):
         """Verify that other units used in CORSIKA are properly converted"""
 
         self.assertEqual(units.eSI, 1.602176462e-19)
         self.assertEqual(units.gigaelectronvolt, units.giga * units.eV)
         self.assertEqual(units.GeV, units.gigaelectronvolt)
         self.assertEqual(units.centimeter, units.centi * units.m)
         self.assertEqual(units.cm, units.centimeter)
         self.assertEqual(units.cm2, units.cm * units.cm)
         self.assertEqual(units.second, units.giga * units.ns)
         self.assertEqual(units.s, units.second)
         self.assertEqual(units.EeV, units.exa * units.eV)
-        self.assertEqual(units.degree, (math.pi / 180.) * units.rad)
+        self.assertEqual(units.degree, (math.pi / 180.0) * units.rad)
         self.assertEqual(units.joule, units.eV / units.eSI)
         self.assertEqual(units.joule, units.eV / units.eSI)
-        self.assertEqual(units.gram, units.peta * units.joule * units.ns ** 2 / units.m ** 2)
+        self.assertEqual(units.gram, units.peta * units.joule * units.ns**2 / units.m**2)
         self.assertEqual(units.g, units.gram)
 
-        self.assertEqual(units.tesla, units.giga * units.volt * units.ns / units.m ** 2)
+        self.assertEqual(units.tesla, units.giga * units.volt * units.ns / units.m**2)
 
     def test_prefixes(self):
         """Verify the values of the prefixes"""
 
         self.assertEqual(units.yocto, 1e-24)
         self.assertEqual(units.zepto, 1e-21)
         self.assertEqual(units.atto, 1e-18)
@@ -61,11 +60,7 @@
         self.assertEqual(units.mega, 1e6)
         self.assertEqual(units.giga, 1e9)
         self.assertEqual(units.tera, 1e12)
         self.assertEqual(units.peta, 1e15)
         self.assertEqual(units.exa, 1e18)
         self.assertEqual(units.zetta, 1e21)
         self.assertEqual(units.yotta, 1e24)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/esd_load_data.py` & `hisparc_sapphire-3.0.0/sapphire/tests/esd_load_data.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,27 +1,28 @@
 import datetime
 import os
 import tempfile
 
+from pathlib import Path
 from urllib.request import urlretrieve
 
 import tables
 
 from sapphire import esd
 
-self_path = os.path.dirname(__file__)
+self_path = Path(__file__).parent
 
-test_data_path = os.path.join(self_path, 'test_data/esd_load_data.h5')
-test_data_coincidences_path = os.path.join(self_path, 'test_data/esd_coincidence_data.h5')
+test_data_path = self_path / 'test_data/esd_load_data.h5'
+test_data_coincidences_path = self_path / 'test_data/esd_coincidence_data.h5'
 
-events_source = os.path.join(self_path, 'test_data/events-s501-20120101.tsv')
-weather_source = os.path.join(self_path, 'test_data/weather-s501-20120101.tsv')
-singles_source = os.path.join(self_path, 'test_data/singles-s501-20170101.tsv')
-lightning_source = os.path.join(self_path, 'test_data/lightning-knmi-20150717.tsv')
-coincidences_source = os.path.join(self_path, 'test_data/coincidences-20160310.tsv')
+events_source = self_path / 'test_data/events-s501-20120101.tsv'
+weather_source = self_path / 'test_data/weather-s501-20120101.tsv'
+singles_source = self_path / 'test_data/singles-s501-20170101.tsv'
+lightning_source = self_path / 'test_data/lightning-knmi-20150717.tsv'
+coincidences_source = self_path / 'test_data/coincidences-20160310.tsv'
 
 
 def create_tempfile_path():
     """Create a temporary file, close it, and return the path"""
 
     f, path = tempfile.mkstemp(suffix='.h5')
     os.close(f)
@@ -77,21 +78,31 @@
 
 
 def create_and_store_test_data():
     """Create test data for future acceptance testing"""
 
     perform_esd_download_data(test_data_path)
     perform_download_coincidences(test_data_coincidences_path)
-    urlretrieve(esd.get_weather_url().format(station_number=501, query='start=2012-01-01&end=2012-01-01+00:01:00'),
-                weather_source)
-    urlretrieve(esd.get_events_url().format(station_number=501, query='start=2012-01-01&end=2012-01-01+00:01:00'),
-                events_source)
-    urlretrieve(esd.get_singles_url().format(station_number=501, query='start=2017-01-01&end=2017-01-01+00:10:00'),
-                singles_source)
-    urlretrieve(esd.get_lightning_url().format(lightning_type=4, query='start=2015-07-17&end=2015-07-17+00:10:00'),
-                lightning_source)
-    urlretrieve(esd.get_coincidences_url().format(query='start=2016-03-10&end=2016-03-10+00:01:00&stations=501,+510&n=2'),
-                coincidences_source)
+    urlretrieve(
+        esd.get_weather_url().format(station_number=501, query='start=2012-01-01&end=2012-01-01+00:01:00'),
+        weather_source,
+    )
+    urlretrieve(
+        esd.get_events_url().format(station_number=501, query='start=2012-01-01&end=2012-01-01+00:01:00'),
+        events_source,
+    )
+    urlretrieve(
+        esd.get_singles_url().format(station_number=501, query='start=2017-01-01&end=2017-01-01+00:10:00'),
+        singles_source,
+    )
+    urlretrieve(
+        esd.get_lightning_url().format(lightning_type=4, query='start=2015-07-17&end=2015-07-17+00:10:00'),
+        lightning_source,
+    )
+    urlretrieve(
+        esd.get_coincidences_url().format(query='start=2016-03-10&end=2016-03-10+00:01:00&stations=501,+510&n=2'),
+        coincidences_source,
+    )
 
 
 if __name__ == '__main__':
     create_and_store_test_data()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/perform_simulation.py` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/perform_simulation.py`

 * *Files 2% similar despite different names*

```diff
@@ -26,53 +26,49 @@
 
     mock_time.return_value = 1_000_000_000
 
     corsika_data_path = os.path.join(self_path, 'test_data/corsika.h5')
     cluster = sapphire.clusters.SimpleCluster(size=40)
     filters = tables.Filters(complevel=1)
     with tables.open_file(filename, 'w', filters=filters) as data:
-        sim = GroundParticlesSimulation(corsika_data_path, 70, cluster,
-                                        data, n=10, seed=1, progress=False)
+        sim = GroundParticlesSimulation(corsika_data_path, 70, cluster, data, n=10, seed=1, progress=False)
         sim.run()
 
 
 @patch('sapphire.simulations.groundparticles.time')
 def perform_groundparticlesgammasimulation(filename, mock_time):
     """Perform a small simulation and store results in filename"""
 
     mock_time.return_value = 1_000_000_000
 
     corsika_data_path = os.path.join(self_path, 'test_data/corsika.h5')
     cluster = sapphire.clusters.SimpleCluster(size=40)
     filters = tables.Filters(complevel=1)
     with tables.open_file(filename, 'w', filters=filters) as data:
-        sim = GroundParticlesGammaSimulation(corsika_data_path, 70, cluster,
-                                             data, n=10, seed=42, progress=False)
+        sim = GroundParticlesGammaSimulation(corsika_data_path, 70, cluster, data, n=10, seed=42, progress=False)
         sim.run()
 
 
 def perform_flatfrontsimulation(filename):
     """Perform a small simulation and store results in filename"""
 
     cluster = sapphire.clusters.SimpleCluster(size=40)
     filters = tables.Filters(complevel=1)
     with tables.open_file(filename, 'w', filters=filters) as data:
-        sim = FlatFrontSimulation(cluster, data, '/', 10, seed=1,
-                                  progress=False)
+        sim = FlatFrontSimulation(cluster, data, '/', 10, seed=1, progress=False)
         sim.run()
 
 
 def perform_nkgldfsimulation(filename):
     """Perform a small simulation and store results in filename"""
 
     cluster = sapphire.clusters.SimpleCluster(size=40)
     filters = tables.Filters(complevel=1)
     with tables.open_file(filename, 'w', filters=filters) as data:
-        sim = NkgLdfSimulation(400, 1e15, 1e19, cluster, data, '/', 10,
-                               seed=1, progress=False)
+        sim = NkgLdfSimulation(400, 1e15, 1e19, cluster, data, '/', 10, seed=1, progress=False)
         sim.run()
 
 
 def create_tempfile_path():
     """Create a temporary file, close it, and return the path"""
 
     f, path = tempfile.mkstemp(suffix='.h5')
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_base_simulation.py` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_base_simulation.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,41 +7,37 @@
 import tables
 
 from sapphire import storage
 from sapphire.simulations.base import BaseSimulation
 
 
 class BaseSimulationTest(unittest.TestCase):
-
     @patch.object(BaseSimulation, '_prepare_output_tables')
     def setUp(self, mock_method):
         self.mock_prepare_output_tables = mock_method
         self.cluster = sentinel.cluster
         self.data = sentinel.data
         self.output_path = sentinel.output_path
         self.n = sentinel.n
 
-        self.simulation = BaseSimulation(self.cluster, self.data,
-                                         self.output_path, self.n,
-                                         progress=False)
+        self.simulation = BaseSimulation(self.cluster, self.data, self.output_path, self.n, progress=False)
 
     def test_init_sets_attributes(self):
         self.assertIs(self.simulation.cluster, self.cluster)
         self.assertIs(self.simulation.data, self.data)
         self.assertIs(self.simulation.output_path, self.output_path)
         self.assertIs(self.simulation.n, self.n)
 
     def test_init_calls_prepare_output_tables(self):
         self.mock_prepare_output_tables.assert_called_once_with()
 
     @patch.object(BaseSimulation, '_prepare_coincidence_tables')
     @patch.object(BaseSimulation, '_prepare_station_tables')
     @patch.object(BaseSimulation, '_store_station_index')
-    def test_prepare_output_tables_calls(self, mock_method3, mock_method2,
-                                         mock_method1):
+    def test_prepare_output_tables_calls(self, mock_method3, mock_method2, mock_method1):
         self.simulation._prepare_output_tables()
         mock_method1.assert_called_once_with()
         mock_method2.assert_called_once_with()
         mock_method3.assert_called_once_with()
 
     @patch.object(BaseSimulation, 'generate_shower_parameters')
     @patch.object(BaseSimulation, 'simulate_events_for_shower')
@@ -54,108 +50,102 @@
         # test simulate_events_for_shower called two times with
         # shower_parameters
         expected = [call(sentinel.params1), call(sentinel.params2)]
         self.assertEqual(mock_simulate.call_args_list, expected)
 
         # test store_coincidence called 2nd time with shower_id 1,
         # parameters and events
-        mock_store.assert_called_with(1, sentinel.params2,
-                                      sentinel.events)
+        mock_store.assert_called_with(1, sentinel.params2, sentinel.events)
 
     def test_generate_shower_parameters(self):
         self.simulation.n = 10
         output = self.simulation.generate_shower_parameters()
         self.assertIsInstance(output, types.GeneratorType)
 
         output = list(output)
         self.assertEqual(len(output), 10)
 
-        expected = {'core_pos': (None, None), 'zenith': None, 'azimuth': None,
-                    'size': None, 'energy': None, 'ext_timestamp': None}
+        expected = {
+            'core_pos': (None, None),
+            'zenith': None,
+            'azimuth': None,
+            'size': None,
+            'energy': None,
+            'ext_timestamp': None,
+        }
         self.assertEqual(output[0], expected)
 
     @patch.object(BaseSimulation, 'simulate_station_response')
     @patch.object(BaseSimulation, 'store_station_observables')
     def test_simulate_events_for_shower(self, mock_store, mock_simulate):
         self.simulation.cluster = Mock()
-        self.simulation.cluster.stations = [sentinel.station1,
-                                            sentinel.station2,
-                                            sentinel.station3]
+        self.simulation.cluster.stations = [sentinel.station1, sentinel.station2, sentinel.station3]
 
-        mock_simulate.side_effect = [(True, sentinel.obs1), (False, None),
-                                     (True, sentinel.obs3)]
+        mock_simulate.side_effect = [(True, sentinel.obs1), (False, None), (True, sentinel.obs3)]
         mock_store.side_effect = [sentinel.index1, sentinel.index2]
-        events = self.simulation.simulate_events_for_shower(
-            sentinel.params)
+        events = self.simulation.simulate_events_for_shower(sentinel.params)
 
         # test simulate_station_response called for each station, with
         # shower parameters
-        expected = [call(sentinel.station1, sentinel.params),
-                    call(sentinel.station2, sentinel.params),
-                    call(sentinel.station3, sentinel.params)]
+        expected = [
+            call(sentinel.station1, sentinel.params),
+            call(sentinel.station2, sentinel.params),
+            call(sentinel.station3, sentinel.params),
+        ]
         self.assertEqual(mock_simulate.call_args_list, expected)
 
         # test store_station_observables called only for triggered
         # stations, with observables
         expected = [call(0, sentinel.obs1), call(2, sentinel.obs3)]
         self.assertEqual(mock_store.call_args_list, expected)
 
         # test returned events consists of list of station indexes and
         # stored event indexes
-        self.assertEqual(events, [(0, sentinel.index1),
-                                  (2, sentinel.index2)])
+        self.assertEqual(events, [(0, sentinel.index1), (2, sentinel.index2)])
 
     @patch.object(BaseSimulation, 'simulate_all_detectors')
     @patch.object(BaseSimulation, 'simulate_trigger')
     @patch.object(BaseSimulation, 'process_detector_observables')
     @patch.object(BaseSimulation, 'simulate_gps')
-    def test_simulate_station_response(self, mock_gps, mock_process,
-                                       mock_trigger, mock_detectors):
+    def test_simulate_station_response(self, mock_gps, mock_process, mock_trigger, mock_detectors):
         mock_detectors.return_value = sentinel.detector_observables
         mock_trigger.return_value = sentinel.has_triggered
         mock_process.return_value = sentinel.station_observables
         mock_gps.return_value = sentinel.gps_observables
 
         mock_station = Mock()
         mock_station.detectors = sentinel.detectors
 
-        has_triggered, station_observables = \
-            self.simulation.simulate_station_response(mock_station,
-                                                      sentinel.parameters)
+        has_triggered, station_observables = self.simulation.simulate_station_response(
+            mock_station,
+            sentinel.parameters,
+        )
 
         # Tests
-        mock_detectors.assert_called_once_with(sentinel.detectors,
-                                               sentinel.parameters)
+        mock_detectors.assert_called_once_with(sentinel.detectors, sentinel.parameters)
         mock_trigger.assert_called_once_with(sentinel.detector_observables)
         mock_process.assert_called_once_with(sentinel.detector_observables)
-        mock_gps.assert_called_once_with(sentinel.station_observables,
-                                         sentinel.parameters,
-                                         mock_station)
+        mock_gps.assert_called_once_with(sentinel.station_observables, sentinel.parameters, mock_station)
         self.assertIs(has_triggered, sentinel.has_triggered)
         self.assertIs(station_observables, sentinel.gps_observables)
 
     @patch.object(BaseSimulation, 'simulate_detector_response')
     def test_simulate_all_detectors(self, mock_response):
         detectors = [sentinel.detector1, sentinel.detector2]
-        mock_response.side_effect = [sentinel.observables1,
-                                     sentinel.observables2]
+        mock_response.side_effect = [sentinel.observables1, sentinel.observables2]
 
-        observables = self.simulation.simulate_all_detectors(
-            detectors, sentinel.parameters)
+        observables = self.simulation.simulate_all_detectors(detectors, sentinel.parameters)
 
-        expected = [call(sentinel.detector1, sentinel.parameters),
-                    call(sentinel.detector2, sentinel.parameters)]
+        expected = [call(sentinel.detector1, sentinel.parameters), call(sentinel.detector2, sentinel.parameters)]
         self.assertEqual(mock_response.call_args_list, expected)
 
-        self.assertEqual(observables, [sentinel.observables1,
-                                       sentinel.observables2])
+        self.assertEqual(observables, [sentinel.observables1, sentinel.observables2])
 
     def test_simulate_detector_response(self):
-        observables = self.simulation.simulate_detector_response(Mock(),
-                                                                 Mock())
+        observables = self.simulation.simulate_detector_response(Mock(), Mock())
         self.assertIsInstance(observables, dict)
         self.assertIn('n', observables)
         self.assertIn('t', observables)
 
     def test_simulate_trigger(self):
         has_triggered = self.simulation.simulate_trigger(Mock())
         self.assertIsInstance(has_triggered, bool)
@@ -168,97 +158,98 @@
         gps_dict = args[0]
         self.assertIsInstance(gps_dict, dict)
         self.assertIn('ext_timestamp', gps_dict)
         self.assertIn('timestamp', gps_dict)
         self.assertIn('nanoseconds', gps_dict)
 
     def test_process_detector_observables(self):
-        detector_observables = [{'n': 1., 't': 2., 'pulseheights': 3.,
-                                 'integrals': 4.},
-                                {'n': 5., 't': 6., 'pulseheights': 7.,
-                                 'integrals': 8.},
-                                {'foo': -999.}]
-
-        expected = {'n1': 1., 'n2': 5., 't1': 2., 't2': 6.,
-                    'pulseheights': [3., 7., -1., -1.],
-                    'integrals': [4., 8., -1, -1]}
-        actual = self.simulation.process_detector_observables(
-            detector_observables)
+        detector_observables = [
+            {'n': 1.0, 't': 2.0, 'pulseheights': 3.0, 'integrals': 4.0},
+            {'n': 5.0, 't': 6.0, 'pulseheights': 7.0, 'integrals': 8.0},
+            {'foo': -999.0},
+        ]
+
+        expected = {
+            'n1': 1.0,
+            'n2': 5.0,
+            't1': 2.0,
+            't2': 6.0,
+            'pulseheights': [3.0, 7.0, -1.0, -1.0],
+            'integrals': [4.0, 8.0, -1, -1],
+        }
+        actual = self.simulation.process_detector_observables(detector_observables)
 
         self.assertEqual(expected, actual)
 
     def test_store_station_observables(self):
         station_groups = MagicMock()
         self.simulation.station_groups = station_groups
         table = station_groups.__getitem__.return_value.events
         table.nrows = 123
 
-        observables = {'key1': 1., 'key2': 2.}
+        observables = {'key1': 1.0, 'key2': 2.0}
         table.colnames = ['key1', 'key2']
-        idx = self.simulation.store_station_observables(
-            sentinel.station_id, observables)
+        idx = self.simulation.store_station_observables(sentinel.station_id, observables)
 
         # tests
         station_groups.__getitem__.assert_called_once_with(sentinel.station_id)
 
-        calls = [call('event_id', table.nrows), call('key2', 2.),
-                 call('key1', 1.)]
+        calls = [call('event_id', table.nrows), call('key2', 2.0), call('key1', 1.0)]
         station_groups.asser_has_calls(calls, any_order=True)
         table.row.append.assert_called_once_with()
         table.flush.assert_called_once_with()
         self.assertEqual(idx, table.nrows - 1)
 
     def test_store_station_observables_raises_warning(self):
         station_groups = MagicMock()
         self.simulation.station_groups = station_groups
         table = station_groups.__getitem__.return_value.events
-        observables = {'key1': 1., 'key2': 2.}
+        observables = {'key1': 1.0, 'key2': 2.0}
         table.colnames = ['key1']
 
         with warnings.catch_warnings(record=True) as warned:
             warnings.simplefilter('always')
-            self.simulation.store_station_observables(sentinel.station_id,
-                                                      observables)
+            self.simulation.store_station_observables(sentinel.station_id, observables)
         self.assertEqual(len(warned), 1)
 
-    @unittest.skip("WIP")
+    @unittest.skip('WIP')
     def test_store_coincidence(self, shower_id, shower_parameters, station_events):
         pass
 
-    @unittest.skip("WIP")
+    @unittest.skip('WIP')
     def test_prepare_coincidence_tables(self):
         pass
 
-    @unittest.skip("WIP")
+    @unittest.skip('WIP')
     def test_prepare_station_tables(self):
         pass
 
-    @unittest.skip("WIP")
+    @unittest.skip('WIP')
     def test_store_station_index(self):
         pass
 
-    @unittest.skip("Does not test this unit")
+    @unittest.skip('Does not test this unit')
     def test_init_creates_coincidences_output_group(self):
-        self.data.create_group.assert_any_call(
-            self.output_path, 'coincidences', createparents=True)
+        self.data.create_group.assert_any_call(self.output_path, 'coincidences', createparents=True)
         self.data.create_table.assert_called_with(
-            self.simulation.coincidence_group, 'coincidences', storage.Coincidence)
+            self.simulation.coincidence_group,
+            'coincidences',
+            storage.Coincidence,
+        )
         self.assertEqual(self.data.create_vlarray.call_count, 2)
         self.data.create_vlarray.assert_any_call(
-            self.simulation.coincidence_group, 'c_index', tables.UInt32Col(shape=2))
+            self.simulation.coincidence_group,
+            'c_index',
+            tables.UInt32Col(shape=2),
+        )
 
-    @unittest.skip("Does not test this unit")
+    @unittest.skip('Does not test this unit')
     def test_init_creates_cluster_output_group(self):
-        self.data.create_group.assert_any_call(
-            self.output_path, 'cluster_simulations', createparents=True)
+        self.data.create_group.assert_any_call(self.output_path, 'cluster_simulations', createparents=True)
         # The following tests need a better mock of cluster in order to work.
         # self.data.create_group.assert_any_call(self.simulation.cluster_group, 'station_0')
         # self.data.create_table.assert_any_call(
         #     station_group, 'events', storage.ProcessedHisparcEvent, expectedrows=self.n)
 
-    @unittest.skip("Does not test this unit")
+    @unittest.skip('Does not test this unit')
     def test_init_stores_cluster_in_attrs(self):
         self.assertIs(self.simulation.coincidence_group._v_attrs.cluster, self.cluster)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/corsika.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/corsika.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/flatfront_sim.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/flatfront_sim.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/gamma_sim.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/gamma_sim.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/groundparticles_sim.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/groundparticles_sim.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_data/nkgldf_sim.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_data/nkgldf_sim.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_detectors.py` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_detectors.py`

 * *Files 8% similar despite different names*

```diff
@@ -8,96 +8,93 @@
 
 from sapphire.simulations.detector import ErrorlessSimulation, HiSPARCSimulation
 
 self_path = os.path.dirname(__file__)
 
 
 class HiSPARCSimulationTest(unittest.TestCase):
-
     def setUp(self):
         self.simulation = HiSPARCSimulation
         random.seed(1)
         np.random.seed(1)
 
     def test_simulate_detector_offsets(self):
-        self.assertEqual(self.simulation.simulate_detector_offsets(1),
-                         [4.49943665734718])
+        self.assertEqual(self.simulation.simulate_detector_offsets(1), [4.49943665734718])
         offsets = self.simulation.simulate_detector_offsets(10000)
-        assert_almost_equal(np.mean(offsets), 0., 1)
+        assert_almost_equal(np.mean(offsets), 0.0, 1)
         assert_almost_equal(np.std(offsets), 2.77, 2)
 
     def test_simulate_detector_offset(self):
-        self.assertEqual(self.simulation.simulate_detector_offset(),
-                         4.49943665734718)
+        self.assertEqual(self.simulation.simulate_detector_offset(), 4.49943665734718)
 
     def test_simulate_station_offset(self):
-        self.assertEqual(self.simulation.simulate_station_offset(),
-                         25.989525818611867)
+        self.assertEqual(self.simulation.simulate_station_offset(), 25.989525818611867)
 
     def test_simulate_gps_uncertainty(self):
-        self.assertEqual(self.simulation.simulate_gps_uncertainty(),
-                         7.3095541364845875)
+        self.assertEqual(self.simulation.simulate_gps_uncertainty(), 7.3095541364845875)
 
     def test_simulate_adc_sampling(self):
         self.assertEqual(self.simulation.simulate_adc_sampling(0), 0)
         self.assertEqual(self.simulation.simulate_adc_sampling(0.1), 2.5)
         self.assertEqual(self.simulation.simulate_adc_sampling(1.25), 2.5)
         self.assertEqual(self.simulation.simulate_adc_sampling(2.5), 2.5)
-        self.assertEqual(self.simulation.simulate_adc_sampling(4), 5.)
+        self.assertEqual(self.simulation.simulate_adc_sampling(4), 5.0)
 
     def test_simulate_signal_transport_time(self):
-        self.assertEqual(list(self.simulation.simulate_signal_transport_time()),
-                         [3.6091128409407927])
-        self.assertEqual(list(self.simulation.simulate_signal_transport_time(1)),
-                         [5.0938877122170032])
-        self.assertEqual(list(self.simulation.simulate_signal_transport_time(11)),
-                         [2.5509743680305879, 3.2759504918578886,
-                          2.9027453686866318, 2.7722064380611307,
-                          2.9975103080633256, 3.3796483500672148,
-                          3.5099596226498524, 4.2053418869706736,
-                          3.6197480580293133, 4.9220361334622806,
-                          3.0411502792684506])
+        self.assertEqual(list(self.simulation.simulate_signal_transport_time()), [3.6091128409407927])
+        self.assertEqual(list(self.simulation.simulate_signal_transport_time(1)), [5.0938877122170032])
+        self.assertEqual(
+            list(self.simulation.simulate_signal_transport_time(11)),
+            [
+                2.5509743680305879,
+                3.2759504918578886,
+                2.9027453686866318,
+                2.7722064380611307,
+                2.9975103080633256,
+                3.3796483500672148,
+                3.5099596226498524,
+                4.2053418869706736,
+                3.6197480580293133,
+                4.9220361334622806,
+                3.0411502792684506,
+            ],
+        )
 
     def test_simulate_detector_mips(self):
         # Test with single angle
-        assert_almost_equal(self.simulation.simulate_detector_mips(1, 0.5),
-                            1.1818585)
-        assert_almost_equal(self.simulation.simulate_detector_mips(2, 0.2),
-                            1.8313342374)
+        assert_almost_equal(self.simulation.simulate_detector_mips(1, 0.5), 1.1818585)
+        assert_almost_equal(self.simulation.simulate_detector_mips(2, 0.2), 1.8313342374)
 
         # Test with multiple angles
-        assert_almost_equal(self.simulation.simulate_detector_mips(2, np.array([0.5, 1])),
-                            2.58167027)
-        assert_almost_equal(self.simulation.simulate_detector_mips(1, np.array([0.5, 1])),
-                            2.21526297)
+        assert_almost_equal(self.simulation.simulate_detector_mips(2, np.array([0.5, 1])), 2.58167027)
+        assert_almost_equal(self.simulation.simulate_detector_mips(1, np.array([0.5, 1])), 2.21526297)
 
         # Test limiting detector length
-        assert_almost_equal(self.simulation.simulate_detector_mips(1, np.radians(90)),
-                            47.6237460)
-        assert_almost_equal(self.simulation.simulate_detector_mips(2, np.array([np.radians(90), np.radians(87)])),
-                            74.6668728)
+        assert_almost_equal(self.simulation.simulate_detector_mips(1, np.radians(90)), 47.6237460)
+        assert_almost_equal(
+            self.simulation.simulate_detector_mips(2, np.array([np.radians(90), np.radians(87)])),
+            74.6668728,
+        )
 
     def test_generate_core_position(self):
         x, y = self.simulation.generate_core_position(500)
         assert_almost_equal(x, 59.85605947801825)
         assert_almost_equal(y, 317.2896993591305)
 
     def test_generate_azimuth(self):
-        self.assertEqual(self.simulation.generate_azimuth(),
-                         -0.521366120872004)
+        self.assertAlmostEqual(self.simulation.generate_azimuth(), -0.521366120872004)
 
     def test_generate_energy(self):
         self.assertEqual(self.simulation.generate_energy(), 136117213526167.64)
         io = 1e17
-        assert_almost_equal(self.simulation.generate_energy(io, io) / io, 1.)
+        assert_almost_equal(self.simulation.generate_energy(io, io) / io, 1.0)
         self.assertEqual(self.simulation.generate_energy(alpha=-3), 100005719231473.97)
 
 
 class ErrorlessSimulationTest(HiSPARCSimulationTest):
-
     def setUp(self):
         self.simulation = ErrorlessSimulation
         random.seed(1)
         np.random.seed(1)
 
     def test_simulate_detector_offsets(self):
         self.assertEqual(self.simulation.simulate_detector_offsets(1), [0])
@@ -113,21 +110,17 @@
         self.assertEqual(self.simulation.simulate_gps_uncertainty(), 0)
 
     def test_simulate_adc_sampling(self):
         self.assertEqual(self.simulation.simulate_adc_sampling(0), 0)
         self.assertEqual(self.simulation.simulate_adc_sampling(0.1), 0.1)
         self.assertEqual(self.simulation.simulate_adc_sampling(1.25), 1.25)
         self.assertEqual(self.simulation.simulate_adc_sampling(2.5), 2.5)
-        self.assertEqual(self.simulation.simulate_adc_sampling(4), 4.)
+        self.assertEqual(self.simulation.simulate_adc_sampling(4), 4.0)
 
     def test_simulate_signal_transport_time(self):
         self.assertEqual(list(self.simulation.simulate_signal_transport_time()), [0])
         self.assertEqual(list(self.simulation.simulate_signal_transport_time(1)), [0])
         self.assertEqual(list(self.simulation.simulate_signal_transport_time(11)), [0] * 11)
 
     def test_simulate_detector_mips(self):
         self.assertEqual(self.simulation.simulate_detector_mips(1, 0.5), 1)
         self.assertEqual(self.simulation.simulate_detector_mips(2, 0.2), 2)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_gammas.py` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_gammas.py`

 * *Files 10% similar despite different names*

```diff
@@ -4,124 +4,121 @@
 
 import numpy as np
 
 from sapphire.simulations import gammas
 
 
 class GammasTest(unittest.TestCase):
-
     def test_compton_edge(self):
         # Compton edges of well known gammas sources
         # http://web.mit.edu/lululiu/Public/8.13/xray/TKA%20files/annihilation-Na.pdf
         # Na-22
         # 0.511 MeV: 0.344 MeV
         # 1.27 MeV: 1.06 MeV
         # http://www.spectrumtechniques.com/PDF/Compton%20Scattering%20Experiment%20by%20Prutchi.pdf
         # Cs-137
         # 0.662 MeV : 482 MeV
         # Co-60
         # 1.17 MeV: 0.96 MeV
         # 1.33 MeV: 1.12 MeV
-        combinations = ((0.511, 0.340), (1.27, 1.06),
-                        (0.662, 0.482),
-                        (1.17, 0.96), (1.33, 1.12))
+        combinations = ((0.511, 0.340), (1.27, 1.06), (0.662, 0.482), (1.17, 0.96), (1.33, 1.12))
 
         for E, edge in combinations:
             self.assertAlmostEqual(gammas.compton_edge(E), edge, places=2)
 
     def test_compton_mean_free_path(self):
         # Relevant mean-free-paths in vinyltoluene scintillator
         # Values checked with: Jos Steijer, Nikhef internal note, 16 juni 2010, figure 3
-        combinations = ((1., 32.), (10., 60.))
+        combinations = ((1.0, 32.0), (10.0, 60.0))
 
         for E, edge in combinations:
             self.assertAlmostEqual(gammas.compton_mean_free_path(E), edge, places=0)
 
     def test_pair_mean_free_path(self):
         # Relevant mean-free-paths in vinyltoluene scintillator
         # Values checked with: Jos Steijer, Nikhef internal note, 16 juni 2010, figure 5
-        combinations = ((10, 249.), (1000., 62.))
+        combinations = ((10, 249.0), (1000.0, 62.0))
 
         for E, edge in combinations:
             self.assertAlmostEqual(gammas.pair_mean_free_path(E), edge, places=0)
 
     @patch.object(np.random, 'random')
     def test_compton_energy_transfer(self, mock_random):
         # if random() return 1, energy should approach the kinematic maximum (compton edge)
         mock_random.return_value = 1.0
-        for gamma_energy in [3., 10., 100.]:
+        for gamma_energy in [3.0, 10.0, 100.0]:
             expected = gammas.compton_edge(gamma_energy)
             self.assertAlmostEqual(gammas.compton_energy_transfer(gamma_energy), expected, places=0)
 
         # if random() returns 0, energy should approach 0
         mock_random.return_value = 0.0
-        for gamma_energy in [3., 10., 100.]:
-            self.assertAlmostEqual(gammas.compton_energy_transfer(gamma_energy), 0.)
+        for gamma_energy in [3.0, 10.0, 100.0]:
+            self.assertAlmostEqual(gammas.compton_energy_transfer(gamma_energy), 0.0)
 
     def test_energy_transfer_cross_section(self):
         # The plot from github.com/tomkooij/lio-project/photons/check_sapphire_gammas.py
         # has been checked with Evans (1955) p. 693 figure 5.1
         # Peaks from this plot: (E [MeV], cross_section [barn])
         combinations = ((0.511, 1.6), (1.2, 0.52), (2.76, 0.22))
 
         barn = 1e-28  # m**2. Note that the figure in Evans is in centibarn!
         for E, cross_section in combinations:
             edge = gammas.compton_edge(E)
             self.assertAlmostEqual(gammas.energy_transfer_cross_section(E, edge) / barn, cross_section, places=1)
 
     def test_max_energy_transfer(self):
-        self.assertAlmostEqual(gammas.max_energy_deposit_in_mips(0., 1.), gammas.MAX_E / gammas.MIP)
-        self.assertAlmostEqual(gammas.max_energy_deposit_in_mips(0.5, 1.), 0.5 * gammas.MAX_E / gammas.MIP)
-        self.assertAlmostEqual(gammas.max_energy_deposit_in_mips(1., 1.), 0.)
+        self.assertAlmostEqual(gammas.max_energy_deposit_in_mips(0.0, 1.0), gammas.MAX_E / gammas.MIP)
+        self.assertAlmostEqual(gammas.max_energy_deposit_in_mips(0.5, 1.0), 0.5 * gammas.MAX_E / gammas.MIP)
+        self.assertAlmostEqual(gammas.max_energy_deposit_in_mips(1.0, 1.0), 0.0)
 
     @patch.object(gammas, 'compton_energy_transfer')
     @patch.object(gammas, 'pair_mean_free_path')
     @patch.object(gammas, 'compton_mean_free_path')
     def test_simulate_detector_mips_gammas_compton(self, mock_l_compton, mock_l_pair, mock_compton):
         # Force compton scattering
         mock_l_compton.return_value = 1e-3
         mock_l_pair.return_value = 1e50
 
-        mock_compton.return_value = 1.
+        mock_compton.return_value = 1.0
         p = np.array([10])
-        theta = np.array([0.])
+        theta = np.array([0.0])
 
         mips = gammas.simulate_detector_mips_gammas(p, theta)
-        mock_compton.assert_called_once_with(10. / 1e6)
+        mock_compton.assert_called_once_with(10.0 / 1e6)
         self.assertLessEqual(mips, gammas.MAX_E)
 
     @patch.object(gammas, 'compton_energy_transfer')
     @patch.object(gammas, 'pair_mean_free_path')
     @patch.object(gammas, 'compton_mean_free_path')
     def test_simulate_detector_mips_gammas_pair(self, mock_l_compton, mock_l_pair, mock_compton):
         # Force pair production
         mock_l_compton.return_value = 1e50
         mock_l_pair.return_value = 1e-3
 
-        mock_compton.return_value = 42.
-        energies = np.array([10., 7.])  # MeV
+        mock_compton.return_value = 42.0
+        energies = np.array([10.0, 7.0])  # MeV
         p = energies * 1e6  # eV
-        theta = np.array([0.])
+        theta = np.array([0.0])
 
         for _ in range(100):
             mips = gammas.simulate_detector_mips_gammas(p, theta)
             self.assertFalse(mock_compton.called)
             self.assertLessEqual(mips, gammas.MAX_E)
 
         # not enough energy for pair production
         energies = np.array([0.5, 0.7])  # MeV
         p = energies * 1e6  # eV
-        theta = np.array([0., 0.])
+        theta = np.array([0.0, 0.0])
         for _ in range(100):
             self.assertEqual(gammas.simulate_detector_mips_gammas(p, theta), 0)
 
     @patch('sapphire.simulations.gammas.expovariate')
     def test_simulate_detector_mips_no_interaction(self, mock_expovariate):
         p = np.array([10e6])
-        theta = np.array([0.])
+        theta = np.array([0.0])
 
         # force no interaction
         mock_expovariate.side_effect = [1e6, 1e3]
         self.assertEqual(gammas.simulate_detector_mips_gammas(p, theta), 0)
 
         # no interaction because after projected depth
         mock_expovariate.side_effect = [4, 5]
@@ -135,13 +132,9 @@
 
         # no interaction with multiple inclined gammas each with to long
         # interaction depth.
         # test mostly to prevent accidental growing of depth in loop
         n = 30
         mock_expovariate.side_effect = [4, 5] * n
         p = np.array([10e6] * n)
-        theta = np.array([1.] * n)  # projected depth would be 126 cm
+        theta = np.array([1.0] * n)  # projected depth would be 126 cm
         self.assertEqual(gammas.simulate_detector_mips_gammas(p, theta), 0)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_groundparticles.py` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_groundparticles.py`

 * *Files 3% similar despite different names*

```diff
@@ -10,184 +10,180 @@
 from sapphire.clusters import SingleDiamondStation
 from sapphire.simulations import groundparticles
 
 self_path = os.path.dirname(__file__)
 
 
 class GroundParticlesSimulationTest(unittest.TestCase):
-
     def setUp(self):
-
-        self.simulation = groundparticles.GroundParticlesSimulation.__new__(
-            groundparticles.GroundParticlesSimulation)
+        self.simulation = groundparticles.GroundParticlesSimulation.__new__(groundparticles.GroundParticlesSimulation)
 
         corsika_data_path = os.path.join(self_path, 'test_data/corsika.h5')
         self.corsika_data = tables.open_file(corsika_data_path, 'r')
         self.simulation.corsikafile = self.corsika_data
+        self.addCleanup(self.corsika_data.close)
 
         self.simulation.cluster = SingleDiamondStation()
         self.detectors = self.simulation.cluster.stations[0].detectors
 
-    def tearDown(self):
-        self.corsika_data.close()
-
     def test__prepare_cluster_for_shower(self):
-
         # Combinations of shower parameters and detector after transformations
-        combinations = (((0, 0, 0), (-0, -0, -0)),
-                        ((10, -60, 0), (-10, 60, -0)),
-                        ((10, -60, pi / 2), (60, 10, -pi / 2)))
+        combinations = (
+            ((0, 0, 0), (-0, -0, -0)),
+            ((10, -60, 0), (-10, 60, -0)),
+            ((10, -60, pi / 2), (60, 10, -pi / 2)),
+        )
 
-        for input, expected in combinations:
-            self.simulation._prepare_cluster_for_shower(*input)
+        for args, expected in combinations:
+            self.simulation._prepare_cluster_for_shower(*args)
             self.assertAlmostEqual(self.simulation.cluster.x, expected[0])
             self.assertAlmostEqual(self.simulation.cluster.y, expected[1])
             self.assertAlmostEqual(self.simulation.cluster.alpha, expected[2])
 
     def test_get_particles_query_string(self):
         self.simulation.groundparticles = Mock()
 
         # Combinations of shower parameters and detector after transformations
         shower_parameters = {'zenith': 0}
         self.simulation.corsika_azimuth = 0
-        combinations = ((0, 0, 0),
-                        (10, -60, 0),
-                        (10, -60, pi / 2))
+        combinations = ((0, 0, 0), (10, -60, 0), (10, -60, pi / 2))
 
-        for input in combinations:
-            self.simulation._prepare_cluster_for_shower(*input)
+        for args in combinations:
+            self.simulation._prepare_cluster_for_shower(*args)
             self.simulation.get_particles_in_detector(self.detectors[0], shower_parameters)
             x, y = self.detectors[0].get_xy_coordinates()
-            size = sqrt(.5) / 2.
+            size = sqrt(0.5) / 2.0
             self.simulation.groundparticles.read_where.assert_called_with(
                 '(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f) & '
-                '(particle_id >= 2) & (particle_id <= 6)' %
-                (x - size, x + size, y - size, y + size))
+                '(particle_id >= 2) & (particle_id <= 6)' % (x - size, x + size, y - size, y + size),
+            )
 
     def test_get_particles(self):
         self.groundparticles = self.corsika_data.root.groundparticles
         self.simulation.groundparticles = self.groundparticles
 
         shower_parameters = {'zenith': 0}
         self.simulation.corsika_azimuth = 0
-        combinations = (((0, 0, 0), (1, 0, 0, 0)),
-                        ((1, -1, 0), (0, 1, 0, 3)),
-                        ((1, -1, pi / 2), (1, 1, 0, 1)))
+        combinations = (
+            ((0, 0, 0), (1, 0, 0, 0)),
+            ((1, -1, 0), (0, 1, 0, 3)),
+            ((1, -1, pi / 2), (1, 1, 0, 1)),
+        )
 
-        for input, expected in combinations:
-            self.simulation._prepare_cluster_for_shower(*input)
+        for args, expected in combinations:
+            self.simulation._prepare_cluster_for_shower(*args)
             for d, e in zip(self.detectors, expected):
                 self.assertEqual(len(self.simulation.get_particles_in_detector(d, shower_parameters)), e)
 
 
 class GroundParticlesGammaSimulationTest(unittest.TestCase):
-
     def setUp(self):
         self.simulation = groundparticles.GroundParticlesGammaSimulation.__new__(
-            groundparticles.GroundParticlesGammaSimulation)
+            groundparticles.GroundParticlesGammaSimulation,
+        )
 
         corsika_data_path = os.path.join(self_path, 'test_data/corsika.h5')
         self.corsika_data = tables.open_file(corsika_data_path, 'r')
+        self.addCleanup(self.corsika_data.close)
         self.simulation.corsikafile = self.corsika_data
 
         self.simulation.cluster = SingleDiamondStation()
         self.detectors = self.simulation.cluster.stations[0].detectors
 
-    def tearDown(self):
-        self.corsika_data.close()
-
     def test_get_particles(self):
         self.groundparticles = self.corsika_data.root.groundparticles
         self.simulation.groundparticles = self.groundparticles
 
         shower_parameters = {'zenith': 0}
         self.simulation.corsika_azimuth = 0
-        combinations = (((0, 0, 0), (1, 0, 0, 0), (5, 0, 2, 4)),
-                        ((1, -1, 0), (0, 1, 0, 3), (1, 1, 4, 8)),
-                        ((1, -1, pi / 2), (1, 1, 0, 1), (1, 3, 6, 1)))
+        combinations = (
+            ((0, 0, 0), (1, 0, 0, 0), (5, 0, 2, 4)),
+            ((1, -1, 0), (0, 1, 0, 3), (1, 1, 4, 8)),
+            ((1, -1, pi / 2), (1, 1, 0, 1), (1, 3, 6, 1)),
+        )
 
-        for input, n1, n2 in combinations:
-            self.simulation._prepare_cluster_for_shower(*input)
+        for args, n1, n2 in combinations:
+            self.simulation._prepare_cluster_for_shower(*args)
             for d, n_lep, n_gam in zip(self.detectors, n1, n2):
                 lep, gamma = self.simulation.get_particles_in_detector(d, shower_parameters)
                 self.assertEqual(len(lep), n_lep)
                 self.assertEqual(len(gamma), n_gam)
 
 
 class DetectorBoundarySimulationTest(GroundParticlesSimulationTest):
-
     def setUp(self):
-        self.simulation = groundparticles.DetectorBoundarySimulation.__new__(
-            groundparticles.DetectorBoundarySimulation)
+        self.simulation = groundparticles.DetectorBoundarySimulation.__new__(groundparticles.DetectorBoundarySimulation)
 
         corsika_data_path = os.path.join(self_path, 'test_data/corsika.h5')
         self.corsika_data = tables.open_file(corsika_data_path, 'r')
         self.simulation.corsikafile = self.corsika_data
 
         self.simulation.cluster = SingleDiamondStation()
         self.detectors = self.simulation.cluster.stations[0].detectors
 
     def test_get_particles_query_string(self):
         self.simulation.groundparticles = Mock()
 
         # Combinations of shower parameters and detector after transformations
         shower_parameters = {'zenith': 0}
         self.simulation.corsika_azimuth = 0
-        combinations = ((0, 0, 0),
-                        (10, -60, 0))
+        combinations = ((0, 0, 0), (10, -60, 0))
 
-        for input in combinations:
-            self.simulation._prepare_cluster_for_shower(*input)
+        for args in combinations:
+            self.simulation._prepare_cluster_for_shower(*args)
             self.simulation.get_particles_in_detector(self.detectors[0], shower_parameters)
             x, y = self.detectors[0].get_xy_coordinates()
             size = 0.6
             self.simulation.groundparticles.read_where.assert_called_with(
                 '(x >= %f) & (x <= %f) & (y >= %f) & (y <= %f) & '
                 '(b11 < y - 0.000000 * x) & (y - 0.000000 * x < b12) & '
                 '(b21 < x) & (x < b22) & '
-                '(particle_id >= 2) & (particle_id <= 6)' %
-                (x - size, x + size, y - size, y + size))
+                '(particle_id >= 2) & (particle_id <= 6)' % (x - size, x + size, y - size, y + size),
+            )
 
     def test_get_particles(self):
         self.groundparticles = self.corsika_data.root.groundparticles
         self.simulation.groundparticles = self.groundparticles
 
         shower_parameters = {'zenith': 0}
         self.simulation.corsika_azimuth = 0
-        combinations = (((0, 0, 0), (1, 0, 1, 0)),
-                        ((1, -1, 0), (0, 1, 1, 3)),
-                        ((1, -1, pi / 2), (1, 1, 0, 1)))
+        combinations = (
+            ((0, 0, 0), (1, 0, 1, 0)),
+            ((1, -1, 0), (0, 1, 1, 3)),
+            ((1, -1, pi / 2), (1, 1, 0, 1)),
+        )
 
-        for input, expected in combinations:
-            self.simulation._prepare_cluster_for_shower(*input)
+        for args, expected in combinations:
+            self.simulation._prepare_cluster_for_shower(*args)
             for d, e in zip(self.detectors, expected):
                 self.assertEqual(len(self.simulation.get_particles_in_detector(d, shower_parameters)), e)
 
     def test_get_line_boundary_eqs(self):
-        combos = ((((0, 0), (1, 1), (0, 2)), (0.0, 'y - 1.000000 * x', 2.0)),
-                  (((0, 0), (0, 1), (1, 2)), (0.0, 'x', 1)))
+        combinations = (
+            (((0, 0), (1, 1), (0, 2)), (0.0, 'y - 1.000000 * x', 2.0)),
+            (((0, 0), (0, 1), (1, 2)), (0.0, 'x', 1)),
+        )
 
-        for input, expected in combos:
-            result = self.simulation.get_line_boundary_eqs(*input)
+        for args, expected in combinations:
+            result = self.simulation.get_line_boundary_eqs(*args)
             self.assertEqual(result, expected)
 
 
 class FixedCoreDistanceSimulationTest(unittest.TestCase):
-
     def test_fixed_core_distance(self):
         r = random.uniform(1e-15, 4000, size=300)
         x, y = groundparticles.FixedCoreDistanceSimulation.generate_core_position(r)
-        testing.assert_allclose(sqrt(x ** 2 + y ** 2), r, 1e-11)
+        testing.assert_allclose(sqrt(x**2 + y**2), r, 1e-11)
 
 
 class MultipleGroundParticlesSimulationTest(unittest.TestCase):
-
     def setUp(self):
         self.simulation = groundparticles.MultipleGroundParticlesSimulation.__new__(
-            groundparticles.MultipleGroundParticlesSimulation)
+            groundparticles.MultipleGroundParticlesSimulation,
+        )
 
         self.simulation.cq = Mock()
         self.simulation.max_core_distance = sentinel.max_core_distance
         self.simulation.min_energy = sentinel.min_energy
         self.simulation.max_energy = sentinel.max_energy
         self.simulation.progress = False
 
@@ -197,28 +193,22 @@
 
     def test_generate_shower_parameters(self):
         self.simulation.n = 5
         self.simulation.select_simulation = Mock()
         self.simulation.select_simulation.return_value = None
         shower_parameters = self.simulation.generate_shower_parameters()
         self.assertRaises(StopIteration, shower_parameters.__next__)
-        self.assertEqual(self.simulation.select_simulation.call_count,
-                         self.simulation.n)
+        self.assertEqual(self.simulation.select_simulation.call_count, self.simulation.n)
 
     def test_select_simulation(self):
         self.simulation.generate_zenith = lambda: 0.27  # 15.5 deg
-        self.simulation.generate_energy = lambda e_min, e_max: 10 ** 16.4
+        self.simulation.generate_energy = lambda e_min, e_max: 10**16.4
         self.simulation.available_energies = set(arange(12, 18, 0.5))
-        self.simulation.available_zeniths = {e: set(arange(0, 60, 7.5))
-                                             for e in self.simulation.available_energies}
+        self.simulation.available_zeniths = {e: set(arange(0, 60, 7.5)) for e in self.simulation.available_energies}
         self.simulation.cq.simulations.return_value = [sentinel.sim]
         result = self.simulation.select_simulation()
-        self.simulation.cq.simulations.assert_called_once_with(energy=16.5, zenith=15.)
+        self.simulation.cq.simulations.assert_called_once_with(energy=16.5, zenith=15.0)
         self.assertEqual(result, sentinel.sim)
 
         self.simulation.cq.simulations.return_value = []
         result = self.simulation.select_simulation()
         self.assertIsNone(result)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_ldf.py` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_ldf.py`

 * *Files 22% similar despite different names*

```diff
@@ -3,56 +3,49 @@
 
 import numpy as np
 
 from sapphire.simulations import ldf
 
 
 class BaseLdfSimulationTest(unittest.TestCase):
-
     def setUp(self):
         self.simulation = ldf.BaseLdfSimulation
         random.seed(1)
         np.random.seed(1)
 
     def test_simulate_particles_for_density(self):
         self.assertEqual(self.simulation.simulate_particles_for_density(100), 98)
         self.assertEqual(self.simulation.simulate_particles_for_density(4), 0)
         self.assertEqual(self.simulation.simulate_particles_for_density(4), 2)
         self.assertEqual(self.simulation.simulate_particles_for_density(0), 0)
 
 
 class BaseLdfSimulationWithoutErrorsTest(BaseLdfSimulationTest):
-
     def setUp(self):
         super().setUp()
         self.simulation = ldf.BaseLdfSimulationWithoutErrors
 
     def test_simulate_particles_for_density(self):
         self.assertEqual(self.simulation.simulate_particles_for_density(100), 100)
         self.assertEqual(self.simulation.simulate_particles_for_density(4), 4)
         self.assertEqual(self.simulation.simulate_particles_for_density(4), 4)
         self.assertEqual(self.simulation.simulate_particles_for_density(0), 0)
 
 
 class BaseLdfTest(unittest.TestCase):
-
     def setUp(self):
         self.ldf = ldf.BaseLdf()
 
     def test_calculate_ldf_value(self):
         """Base LDF has no LDF, so no particles"""
 
         self.assertEqual(self.ldf.calculate_ldf_value(r=0), 0)
         self.assertEqual(self.ldf.calculate_ldf_value(r=10), 0)
         self.assertEqual(self.ldf.calculate_ldf_value(r=0, n_electrons=1e10), 0)
         self.assertEqual(self.ldf.calculate_ldf_value(r=0, n_electrons=1e10, s=3), 0)
 
     def test_calculate_core_distance(self):
         # TODO: Add core distances for inclined showers
-        self.assertEqual(self.ldf.calculate_core_distance(0., 0., 0., 0., 0., 0.), 0)
-        self.assertEqual(self.ldf.calculate_core_distance(10., 0., 0., 0., 0., 0.), 10.)
-        self.assertEqual(self.ldf.calculate_core_distance(10., 0., 10., 0., 0., 0.), 0.)
-        self.assertEqual(self.ldf.calculate_core_distance(10., 3., 10., 3., 0., 0.), 0.)
-
-
-if __name__ == '__main__':
-    unittest.main()
+        self.assertEqual(self.ldf.calculate_core_distance(0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 0)
+        self.assertEqual(self.ldf.calculate_core_distance(10.0, 0.0, 0.0, 0.0, 0.0, 0.0), 10.0)
+        self.assertEqual(self.ldf.calculate_core_distance(10.0, 0.0, 10.0, 0.0, 0.0, 0.0), 0.0)
+        self.assertEqual(self.ldf.calculate_core_distance(10.0, 3.0, 10.0, 3.0, 0.0, 0.0), 0.0)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/simulations/test_simulation_acceptance.py` & `hisparc_sapphire-3.0.0/sapphire/tests/simulations/test_simulation_acceptance.py`

 * *Files 23% similar despite different names*

```diff
@@ -13,52 +13,44 @@
     test_data_gamma,
     test_data_nkg,
     test_data_path,
 )
 
 
 class GroundparticlesSimulationAcceptanceTest(unittest.TestCase):
-
     def test_simulation_output(self):
         """Perform a simulation and verify the output"""
 
         output_path = create_tempfile_path()
+        self.addCleanup(os.remove, output_path)
         perform_groundparticlessimulation(output_path)
         validate_results(self, test_data_path, output_path)
-        os.remove(output_path)
 
 
 class GroundparticlesGammaSimulationAcceptanceTest(unittest.TestCase):
-
     def test_simulation_output(self):
         """Perform a simulation and verify the output"""
 
         output_path = create_tempfile_path()
+        self.addCleanup(os.remove, output_path)
         perform_groundparticlesgammasimulation(output_path)
         validate_results(self, test_data_gamma, output_path)
-        os.remove(output_path)
 
 
 class FlatFrontSimulationAcceptanceTest(unittest.TestCase):
-
     def test_simulation_output(self):
         """Perform a simulation and verify the output"""
 
         output_path = create_tempfile_path()
+        self.addCleanup(os.remove, output_path)
         perform_flatfrontsimulation(output_path)
         validate_results(self, test_data_flat, output_path)
-        os.remove(output_path)
 
 
 class NkgLdfSimulationAcceptanceTest(unittest.TestCase):
-
     def test_simulation_output(self):
         """Perform a simulation and verify the output"""
 
         output_path = create_tempfile_path()
+        self.addCleanup(os.remove, output_path)
         perform_nkgldfsimulation(output_path)
         validate_results(self, test_data_nkg, output_path)
-        os.remove(output_path)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_api.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_api.py`

 * *Files 2% similar despite different names*

```diff
@@ -50,74 +50,77 @@
         mock_urlopen.return_value.read.side_effect = URLError('no interwebs!')
         self.assertRaises(Exception, self.api._retrieve_url, '')
 
     @patch.object(api, 'urlopen')
     def test__get_tsv(self, mock_urlopen):
         mock_urlopen.return_value.read.return_value = b'1297956608\t52.3414237\t4.8807081\t43.32'
         self.api.force_fresh = True
-        self.assertEqual(self.api._get_tsv('gps/2/').tolist(),
-                         [(1297956608, 52.3414237, 4.8807081, 43.32)])
+        self.assertEqual(self.api._get_tsv('gps/2/').tolist(), [(1297956608, 52.3414237, 4.8807081, 43.32)])
 
         mock_urlopen.return_value.read.side_effect = URLError('no interwebs!')
         self.assertRaises(Exception, self.api._get_tsv, 'gps/2/')
         self.api.force_fresh = False
         self.assertRaises(Exception, self.api._get_tsv, 'gps/0/')
         with warnings.catch_warnings(record=True) as warned:
-            self.assertEqual(self.api._get_tsv('gps/2/').tolist()[0],
-                             (1297953008, 52.3414237, 4.8807081, 43.32))
+            self.assertEqual(self.api._get_tsv('gps/2/').tolist()[0], (1297953008, 52.3414237, 4.8807081, 43.32))
         self.assertEqual(len(warned), 1)
 
 
-@unittest.skipUnless(api.API.check_connection(), "Internet connection required")
+@unittest.skipUnless(api.API.check_connection(), 'Internet connection required')
 class APITestsLive(unittest.TestCase):
     def setUp(self):
         self.api = api.API()
 
     def test__retrieve_url(self):
         result = self.api._retrieve_url('', api.get_api_base())
         self.assertIsInstance(result, (str,))
 
     def test__get_json(self):
         json = self.api._get_json('')
         self.assertIsInstance(json, dict)
 
 
-@unittest.skipUnless(api.API.check_connection(), "Internet connection required")
+@unittest.skipUnless(api.API.check_connection(), 'Internet connection required')
 class NetworkTests(unittest.TestCase):
     def setUp(self):
         self.network = api.Network(force_fresh=True, force_stale=False)
         self.keys = ['name', 'number']
 
     @patch.object(api.Network, 'countries')
     @patch.object(api.Network, 'clusters')
     @patch.object(api.Network, 'subclusters')
     @patch.object(api.Network, 'stations')
-    def test_nested_network(self, mock_stations, mock_subcluster,
-                            mock_clusters, mock_countries):
-        mock_countries.return_value = [{'name': sentinel.country_name,
-                                        'number': sentinel.country_number}]
-        mock_clusters.return_value = [{'name': sentinel.cluster_name,
-                                       'number': sentinel.cluster_number}]
-        mock_subcluster.return_value = [{'name': sentinel.subcluster_name,
-                                         'number': sentinel.subcluster_number}]
-        mock_stations.return_value = [{'name': sentinel.station_name,
-                                       'number': sentinel.station_number}]
+    def test_nested_network(self, mock_stations, mock_subcluster, mock_clusters, mock_countries):
+        mock_countries.return_value = [{'name': sentinel.country_name, 'number': sentinel.country_number}]
+        mock_clusters.return_value = [{'name': sentinel.cluster_name, 'number': sentinel.cluster_number}]
+        mock_subcluster.return_value = [{'name': sentinel.subcluster_name, 'number': sentinel.subcluster_number}]
+        mock_stations.return_value = [{'name': sentinel.station_name, 'number': sentinel.station_number}]
         nested_network = self.network.nested_network()
-        self.assertEqual(nested_network,
-                         [{'clusters': [
-                           {'subclusters': [
-                            {'stations': [
-                             {'name': sentinel.station_name,
-                              'number': sentinel.station_number}],
-                             'name': sentinel.subcluster_name,
-                             'number': sentinel.subcluster_number}],
+        self.assertEqual(
+            nested_network,
+            [
+                {
+                    'clusters': [
+                        {
+                            'subclusters': [
+                                {
+                                    'stations': [{'name': sentinel.station_name, 'number': sentinel.station_number}],
+                                    'name': sentinel.subcluster_name,
+                                    'number': sentinel.subcluster_number,
+                                },
+                            ],
                             'name': sentinel.cluster_name,
-                            'number': sentinel.cluster_number}],
-                           'name': sentinel.country_name,
-                           'number': sentinel.country_number}])
+                            'number': sentinel.cluster_number,
+                        },
+                    ],
+                    'name': sentinel.country_name,
+                    'number': sentinel.country_number,
+                },
+            ],
+        )
 
     def test_lazy_countries(self):
         self.laziness_of_method('countries')
 
     def test_countries(self):
         self.network.countries()
         self.assertEqual(self.network._all_countries, self.network.countries())
@@ -148,51 +151,45 @@
 
     def test_bad_subcluster(self):
         bad_number = 1
         self.assertRaises(Exception, self.network.subclusters, country=bad_number)
         self.assertRaises(Exception, self.network.subclusters, cluster=bad_number)
 
     def test_country_numbers(self):
-        self.network._all_countries = [{'number': sentinel.number1},
-                                       {'number': sentinel.number2}]
-        self.assertEqual(self.network.country_numbers(),
-                         [sentinel.number1, sentinel.number2])
+        self.network._all_countries = [{'number': sentinel.number1}, {'number': sentinel.number2}]
+        self.assertEqual(self.network.country_numbers(), [sentinel.number1, sentinel.number2])
 
     @patch.object(api.Network, 'clusters')
     @patch.object(api.Network, 'validate_numbers')
     def test_cluster_numbers(self, mock_validate, mock_clusters):
-        mock_clusters.return_value = [{'number': sentinel.number1},
-                                      {'number': sentinel.number2}]
-        self.assertEqual(self.network.cluster_numbers(sentinel.country),
-                         [sentinel.number1, sentinel.number2])
+        mock_clusters.return_value = [{'number': sentinel.number1}, {'number': sentinel.number2}]
+        self.assertEqual(self.network.cluster_numbers(sentinel.country), [sentinel.number1, sentinel.number2])
         mock_clusters.assert_called_once_with(country=sentinel.country)
 
     @patch.object(api.Network, 'subclusters')
     @patch.object(api.Network, 'validate_numbers')
     def test_subcluster_numbers(self, mock_validate, mock_subclusters):
-        mock_subclusters.return_value = [{'number': sentinel.number1},
-                                         {'number': sentinel.number2}]
-        self.assertEqual(self.network.subcluster_numbers(sentinel.country,
-                                                         sentinel.cluster),
-                         [sentinel.number1, sentinel.number2])
-        mock_subclusters.assert_called_once_with(country=sentinel.country,
-                                                 cluster=sentinel.cluster)
+        mock_subclusters.return_value = [{'number': sentinel.number1}, {'number': sentinel.number2}]
+        self.assertEqual(
+            self.network.subcluster_numbers(sentinel.country, sentinel.cluster),
+            [sentinel.number1, sentinel.number2],
+        )
+        mock_subclusters.assert_called_once_with(country=sentinel.country, cluster=sentinel.cluster)
 
     @patch.object(api.Network, 'stations')
     @patch.object(api.Network, 'validate_numbers')
     def test_station_numbers(self, mock_validate, mock_stations):
-        mock_stations.return_value = [{'number': sentinel.number1},
-                                      {'number': sentinel.number2}]
-        station_numbers = self.network.station_numbers(sentinel.country,
-                                                       sentinel.cluster,
-                                                       sentinel.subcluster)
+        mock_stations.return_value = [{'number': sentinel.number1}, {'number': sentinel.number2}]
+        station_numbers = self.network.station_numbers(sentinel.country, sentinel.cluster, sentinel.subcluster)
         self.assertEqual(station_numbers, [sentinel.number1, sentinel.number2])
-        mock_stations.assert_called_once_with(country=sentinel.country,
-                                              cluster=sentinel.cluster,
-                                              subcluster=sentinel.subcluster)
+        mock_stations.assert_called_once_with(
+            country=sentinel.country,
+            cluster=sentinel.cluster,
+            subcluster=sentinel.subcluster,
+        )
 
     @patch.object(api.Network, '_retrieve_url')
     def test_station_numbers_disconnected(self, mock_retrieve_url):
         mock_retrieve_url.side_effect = Exception('no interwebs!')
         self.assertRaises(Exception, self.network.station_numbers)
         self.assertRaises(Exception, self.network.station_numbers, country=20000)
         self.assertRaises(Exception, self.network.station_numbers, cluster=1000)
@@ -255,59 +252,48 @@
         self.assertTrue((data['n'] == list(range(2, 100))).all())
         self.assertEqual(data['counts'][0], 9479)
 
     @patch.object(api, 'urlopen')
     def test_uptime(self, mock_urlopen):
         # datetime(2014,1,1) 2 days on, 2 days off, 1 day on
         sn = b'[{"name": "foo", "number": 501}, {"name": "bar", "number": 502}]'
-        event_time_1 = str.encode('1388534400\t2000.\n'
-                                  '1388538000\t2000.\n'
-                                  '1388541600\t12.\n'
-                                  '1388545200\t125.\n'
-                                  '1388548800\t3000.\n')
+        event_time_1 = str.encode(
+            '1388534400\t2000.\n1388538000\t2000.\n1388541600\t12.\n1388545200\t125.\n1388548800\t3000.\n',
+        )
         # datetime(2014,1,1) 2 days off, 3 days on
-        event_time_2 = str.encode('1388534400\t50.\n'
-                                  '1388538000\t20.\n'
-                                  '1388541600\t2000.\n'
-                                  '1388545200\t2000.\n'
-                                  '1388548800\t3000.\n')
+        event_time_2 = str.encode(
+            '1388534400\t50.\n1388538000\t20.\n1388541600\t2000.\n1388545200\t2000.\n1388548800\t3000.\n',
+        )
         # station 1
         mock_urlopen.return_value.read.side_effect = [sn, event_time_1] * 4
         self.assertEqual(self.network.uptime([501]), 3)
-        self.assertEqual(self.network.uptime([501], start=datetime(2014, 1, 1),
-                         end=datetime(2014, 1, 1, 2)), 2)
-        self.assertEqual(self.network.uptime([501], start=datetime(2014, 1, 1),
-                         end=datetime(2014, 1, 2)), 3)
-        self.assertEqual(self.network.uptime([501], start=datetime(2013, 1, 1),
-                         end=datetime(2013, 1, 2)), 0)
+        self.assertEqual(self.network.uptime([501], start=datetime(2014, 1, 1), end=datetime(2014, 1, 1, 2)), 2)
+        self.assertEqual(self.network.uptime([501], start=datetime(2014, 1, 1), end=datetime(2014, 1, 2)), 3)
+        self.assertEqual(self.network.uptime([501], start=datetime(2013, 1, 1), end=datetime(2013, 1, 2)), 0)
         # station 2
         mock_urlopen.return_value.read.side_effect = [sn, event_time_2] * 3
         self.assertEqual(self.network.uptime([501]), 3)
-        self.assertEqual(self.network.uptime([501], start=datetime(2014, 1, 1),
-                         end=datetime(2014, 1, 1, 2)), 0)
-        self.assertEqual(self.network.uptime([501], start=datetime(2014, 1, 1),
-                         end=datetime(2014, 1, 2)), 3)
+        self.assertEqual(self.network.uptime([501], start=datetime(2014, 1, 1), end=datetime(2014, 1, 1, 2)), 0)
+        self.assertEqual(self.network.uptime([501], start=datetime(2014, 1, 1), end=datetime(2014, 1, 2)), 3)
         # two stations together
-        mock_urlopen.return_value.read.side_effect = [sn, event_time_1,
-                                                      sn, event_time_2]
+        mock_urlopen.return_value.read.side_effect = [sn, event_time_1, sn, event_time_2]
         self.assertEqual(self.network.uptime([501, 502]), 1)
 
     def laziness_of_method(self, method):
         with patch.object(api.API, '_get_json') as mock_get_json:
             self.assertFalse(mock_get_json.called)
             data = self.network.__getattribute__(method)()
             self.assertTrue(mock_get_json.called)
             self.assertEqual(mock_get_json.call_count, 1)
             data2 = self.network.__getattribute__(method)()
             self.assertEqual(mock_get_json.call_count, 1)
             self.assertEqual(data, data2)
 
 
 class StaleNetworkTests(NetworkTests):
-
     """Tests using local data
 
     Overwrite tests using data not available locally.
 
     """
 
     def setUp(self):
@@ -327,55 +313,57 @@
 
     def test_coincidence_time(self):
         self.assertRaises(Exception, self.network.coincidence_time, 2013, 1, 1)
 
     def test_coincidence_number(self):
         self.assertRaises(Exception, self.network.coincidence_number, 2013, 1, 1)
 
-    @unittest.skipIf(has_extended_local_data('eventtime/%d/' % STATION),
-                     "Local data is extended")
+    @unittest.skipIf(has_extended_local_data('eventtime/%d/' % STATION), 'Local data is extended')
     def test_uptime(self):
         self.assertRaises(Exception, self.network.uptime, [501])
-        self.assertRaises(Exception, self.network.uptime, [501],
-                          start=datetime(2014, 1, 1),
-                          end=datetime(2014, 1, 1, 2))
+        self.assertRaises(
+            Exception,
+            self.network.uptime,
+            [501],
+            start=datetime(2014, 1, 1),
+            end=datetime(2014, 1, 1, 2),
+        )
 
 
-@unittest.skipUnless(api.API.check_connection(), "Internet connection required")
+@unittest.skipUnless(api.API.check_connection(), 'Internet connection required')
 class StationTests(unittest.TestCase):
     def setUp(self):
         self.station = api.Station(STATION, force_fresh=True, force_stale=False)
         self.alt_station = api.Station(ALT_STATION, force_fresh=True, force_stale=False)
 
     @patch.object(api.API, '_retrieve_url')
     def test_no_stale_station(self, mock_retrieve_url):
         mock_retrieve_url.side_effect = Exception('no interwebs!')
         self.assertRaises(Exception, api.Station, 501, force_fresh=True)
 
     @patch.object(api.Network, 'station_numbers')
     def test_bad_station_number(self, mock_station_numbers):
         mock_station_numbers.return_value = [501, 502, 503]
         with warnings.catch_warnings(record=True) as warned:
-            warnings.simplefilter("always")
+            warnings.simplefilter('always')
             api.Station(1)
         self.assertEqual(len(warned), 1)
 
     def test_id_numbers(self):
         self.assertEqual(self.station.station, STATION)
 
     def test_properties(self):
         self.assertEqual(self.station.country(), 'Netherlands')
         self.assertEqual(self.station.cluster(), 'Amsterdam')
         self.assertEqual(self.station.subcluster(), 'Science Park')
         self.assertIn(self.station.n_detectors(), [2, 4])
 
     def test_config(self):
         self.assertEqual(self.station.config()['detnum'], 501)
-        self.assertAlmostEqual(self.station.config(
-            date(2011, 1, 1))['mas_ch1_current'], 7.54901960784279)
+        self.assertAlmostEqual(self.station.config(date(2011, 1, 1))['mas_ch1_current'], 7.54901960784279)
 
     def test_num_events(self):
         self.assertIsInstance(self.station.n_events(2004), int)
         self.assertEqual(self.station.n_events(2004, 1, 1), 0)
         self.assertEqual(self.station.n_events(2013, 8, 1), 63735)
 
     def test_num_events_bad_args(self):
@@ -417,18 +405,19 @@
         self.assertRaises(Exception, self.station.has_weather, month=1)
         self.assertRaises(Exception, self.station.has_weather, month=1, day=1)
         self.assertRaises(Exception, self.station.has_weather, year=2011, day=1)
 
     @patch.object(api, 'urlopen')
     def test_event_trace(self, mock_urlopen):
         def make_trace(start, end):
-            """ return a trace (type bytes) to mock urlopen """
+            """return a trace (type bytes) to mock urlopen"""
             trace = '[%s]' % ', '.join(str(v) for v in range(start, end))
             return_value = '[%s]' % ', '.join(4 * [trace])
             return return_value.encode()
+
         mock_urlopen.return_value.read.return_value = make_trace(0, 11)
         self.assertEqual(self.station.event_trace(1378771205, 571920029)[3][9], 9)
         mock_urlopen.return_value.read.return_value = make_trace(200, 211)
         self.assertEqual(self.station.event_trace(1378771205, 571920029, raw=True)[3][9], 209)
 
     def test_event_time(self):
         names = ('timestamp', 'counts')
@@ -468,22 +457,20 @@
 
     def test_voltage(self):
         data = self.station.voltage(1378771200)  # 2013-9-10
         self.assertEqual(data, [954, 860, 714, 752])
 
         data2 = self.station.voltages[0]
         data = self.station.voltage(0)  # 1970-1-1
-        self.assertEqual(data, [data2['voltage1'], data2['voltage2'],
-                                data2['voltage3'], data2['voltage4']])
+        self.assertEqual(data, [data2['voltage1'], data2['voltage2'], data2['voltage3'], data2['voltage4']])
 
         data2 = self.station.voltages[-1]
         data1 = self.station.voltage(FUTURE)
         data = self.station.voltage()
-        self.assertEqual(data1, [data2['voltage1'], data2['voltage2'],
-                                 data2['voltage3'], data2['voltage4']])
+        self.assertEqual(data1, [data2['voltage1'], data2['voltage2'], data2['voltage3'], data2['voltage4']])
         self.assertEqual(data, data1)
 
     def test_laziness_currents(self):
         self.laziness_of_attribute('currents')
 
     def test_currents(self):
         names = ('timestamp', 'current1', 'current2', 'current3', 'current4')
@@ -514,16 +501,29 @@
         data2 = self.station.gps_location()
         self.assertEqual(data, data2)
 
     def test_laziness_station_layouts(self):
         self.laziness_of_attribute('station_layouts')
 
     def test_triggers(self):
-        names = ('timestamp', 'low1', 'low2', 'low3', 'low4', 'high1', 'high2',
-                 'high3', 'high4', 'n_low', 'n_high', 'and_or', 'external')
+        names = (
+            'timestamp',
+            'low1',
+            'low2',
+            'low3',
+            'low4',
+            'high1',
+            'high2',
+            'high3',
+            'high4',
+            'n_low',
+            'n_high',
+            'and_or',
+            'external',
+        )
         data = self.station.triggers
         self.assertEqual(data.dtype.names, names)
 
     def test_trigger(self):
         thresholds, trigger = self.station.trigger(1378771200)  # 2013-9-10
         self.assertCountEqual(thresholds, [[253, 323]] * 4)
         self.assertCountEqual(trigger, [2, 3, 1, 0])
@@ -531,19 +531,33 @@
         data2 = self.station.trigger()
         self.assertEqual(data, data2)
 
     def test_laziness_triggers(self):
         self.laziness_of_attribute('triggers')
 
     def test_station_layouts(self):
-        names = ('timestamp',
-                 'radius1', 'alpha1', 'height1', 'beta1',
-                 'radius2', 'alpha2', 'height2', 'beta2',
-                 'radius3', 'alpha3', 'height3', 'beta3',
-                 'radius4', 'alpha4', 'height4', 'beta4')
+        names = (
+            'timestamp',
+            'radius1',
+            'alpha1',
+            'height1',
+            'beta1',
+            'radius2',
+            'alpha2',
+            'height2',
+            'beta2',
+            'radius3',
+            'alpha3',
+            'height3',
+            'beta3',
+            'radius4',
+            'alpha4',
+            'height4',
+            'beta4',
+        )
         data = self.station.station_layouts
         self.assertEqual(data.dtype.names, names)
 
     def test_station_layout(self):
         data = self.station.station_layout(0)
         self.assertEqual(len(data), 4)
         self.assertEqual(len(data[0]), 4)
@@ -598,15 +612,15 @@
         # Test omitting timestamp results in lastest offset
         data = self.station.station_timing_offset(ALT_STATION, FUTURE)
         data2 = self.station.station_timing_offset(ALT_STATION)
         assert_equal(data, data2)
 
         # Zero offset to self
         data = self.station.station_timing_offset(STATION)
-        self.assertEqual(data, (0., 0.))
+        self.assertEqual(data, (0.0, 0.0))
 
     def laziness_of_attribute(self, attribute):
         with patch.object(api.API, '_get_tsv') as mock_get_tsv:
             self.assertFalse(mock_get_tsv.called)
             data = self.station.__getattribute__(attribute)
             self.assertTrue(mock_get_tsv.called)
             self.assertEqual(mock_get_tsv.call_count, 1)
@@ -622,15 +636,14 @@
             self.assertEqual(mock_get_tsv.call_count, 1)
             data2 = self.station.__getattribute__(method)(args)
             self.assertEqual(mock_get_tsv.call_count, 1)
             self.assertEqual(data, data2)
 
 
 class StaleStationTests(StationTests):
-
     """Tests using local data
 
     Overwrite tests using data not available locally.
 
     """
 
     def setUp(self):
@@ -654,15 +667,15 @@
     def test_has_weather(self):
         self.assertRaises(Exception, self.station.has_weather)
         self.assertRaises(Exception, self.station.has_weather, 2014)
         self.assertRaises(Exception, self.station.has_weather, 2014, 1, 1)
 
     @patch.object(api, 'urlopen')
     def test_event_trace(self, mock_urlopen):
-        trace = '[%s]' % ', '.join(str(v) for v in range(0, 11))
+        trace = '[%s]' % ', '.join(str(v) for v in range(11))
         mock_urlopen.return_value.read.return_value = '[%s]' % ', '.join(4 * [trace])
         self.assertRaises(Exception, self.station.event_trace, 1378771205, 571920029)
         self.assertRaises(Exception, self.station.event_trace, 1378771205, 571920029, raw=True)
 
     def test_event_time(self):
         self.assertRaises(Exception, self.station.event_time, 2013, 1, 1)
 
@@ -673,11 +686,7 @@
         self.assertRaises(Exception, self.station.pulse_integral, 2013, 1, 1)
 
     def test_barometer(self):
         self.assertRaises(Exception, self.station.barometer, 2013, 1, 1)
 
     def test_temperature(self):
         self.assertRaises(Exception, self.station.temperature, 2013, 1, 1)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_clusters.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_clusters.py`

 * *Files 5% similar despite different names*

```diff
@@ -11,41 +11,44 @@
 
 
 class DetectorTests(unittest.TestCase):
     def setUp(self):
         self.mock_station = Mock()
         self.detector_1 = clusters.Detector(self.mock_station, (1, 0, 0), 'LR')
         self.detector_2 = clusters.Detector(self.mock_station, (-1, 2, 1), 'UD')
-        self.detector_s = clusters.Detector(self.mock_station,
-                                            (sentinel.x, sentinel.y, sentinel.z),
-                                            sentinel.orientation)
-        self.detector_4d = clusters.Detector(station=self.mock_station,
-                                             position=([0, 5], [0, 5], [0, 5]),
-                                             detector_timestamps=[0, 5])
+        self.detector_s = clusters.Detector(
+            self.mock_station,
+            (sentinel.x, sentinel.y, sentinel.z),
+            sentinel.orientation,
+        )
+        self.detector_4d = clusters.Detector(
+            station=self.mock_station,
+            position=([0, 5], [0, 5], [0, 5]),
+            detector_timestamps=[0, 5],
+        )
 
     def test_bad_arguments(self):
-        self.assertRaises(Exception, clusters.Detector, self.mock_station,
-                          (1, 0, 0), 'LR', [0, 1])
+        self.assertRaises(Exception, clusters.Detector, self.mock_station, (1, 0, 0), 'LR', [0, 1])
 
     def test__update_timestamp(self):
         self.assertEqual(self.detector_4d.index, -1)
         for ts, index in [(-1, 0), (0, 0), (3, 0), (7, 1), (8, 1)]:
             self.detector_4d._update_timestamp(ts)
             self.assertEqual(self.detector_4d.index, index)
 
     def test_4d_positions(self):
         self.mock_station.get_coordinates.return_value = (0, 0, 0, 0)
         self.assertEqual(self.detector_4d.get_coordinates(), (5, 5, 5))
         self.detector_4d._update_timestamp(3)
         self.assertEqual(self.detector_4d.get_coordinates(), (0, 0, 0))
 
     def test_detector_size(self):
-        self.assertEqual(self.detector_1.detector_size, (.5, 1.))
-        self.assertEqual(self.detector_2.detector_size, (.5, 1.))
-        self.assertEqual(self.detector_s.detector_size, (.5, 1.))
+        self.assertEqual(self.detector_1.detector_size, (0.5, 1.0))
+        self.assertEqual(self.detector_2.detector_size, (0.5, 1.0))
+        self.assertEqual(self.detector_s.detector_size, (0.5, 1.0))
 
     def test_get_area(self):
         self.assertEqual(self.detector_1.get_area(), 0.5)
 
     def test_attributes(self):
         self.assertIs(self.detector_1.station, self.mock_station)
         self.assertEqual(self.detector_s.x, [sentinel.x])
@@ -79,17 +82,17 @@
         self.mock_station.get_coordinates.return_value = (0, 0, 0, 0)
         coordinates = self.detector_1.get_cylindrical_coordinates()
         self.assertEqual(coordinates, (1, 0, 0))
         coordinates = self.detector_2.get_cylindrical_coordinates()
         self.assertEqual(coordinates, (sqrt(5), atan2(2, -1), 1))
 
     def test_left_right_get_corners(self):
-        self.mock_station.get_coordinates.return_value = (.25, 3, 0, 0)
+        self.mock_station.get_coordinates.return_value = (0.25, 3, 0, 0)
         corners = self.detector_1.get_corners()
-        self.assertEqual(corners, [(.75, 3.25), (.75, 2.75), (1.75, 2.75), (1.75, 3.25)])
+        self.assertEqual(corners, [(0.75, 3.25), (0.75, 2.75), (1.75, 2.75), (1.75, 3.25)])
 
     def test_left_right_get_corners_rotated(self):
         self.mock_station.get_coordinates.return_value = (0, 0, 0, pi / 2)
         corners = self.detector_1.get_corners()
         expected_corners = [(-0.25, 0.5), (0.25, 0.5), (0.25, 1.5), (-0.25, 1.5)]
         for (x, y), (expected_x, expected_y) in zip(corners, expected_corners):
             self.assertAlmostEqual(x, expected_x)
@@ -106,30 +109,42 @@
         self.assertRaises(Exception, self.detector_2.get_corners)
 
 
 class StationTests(unittest.TestCase):
     def setUp(self):
         with patch('sapphire.clusters.Detector') as mock_detector:
             self.cluster = Mock()
-            self.station_1 = clusters.Station(self.cluster, 1, (0, 1, 2), pi / 4,
-                                              [((3, 4), 'LR')])
-            self.station_s = clusters.Station(self.cluster, sentinel.id,
-                                              (sentinel.x, sentinel.y, sentinel.z),
-                                              sentinel.angle, [],
-                                              number=sentinel.number)
-            self.station_4d = clusters.Station(self.cluster, 4,
-                                               ([0, 5], [0, 5], [0, 5]), (0, pi),
-                                               station_timestamps=[0, 5])
+            self.station_1 = clusters.Station(self.cluster, 1, (0, 1, 2), pi / 4, [((3, 4), 'LR')])
+            self.station_s = clusters.Station(
+                self.cluster,
+                sentinel.id,
+                (sentinel.x, sentinel.y, sentinel.z),
+                sentinel.angle,
+                [],
+                number=sentinel.number,
+            )
+            self.station_4d = clusters.Station(
+                self.cluster,
+                4,
+                ([0, 5], [0, 5], [0, 5]),
+                (0, pi),
+                station_timestamps=[0, 5],
+            )
             self.mock_detector_instance = mock_detector.return_value
 
     def test_bad_arguments(self):
         with patch('sapphire.clusters.Detector'):
-            self.assertRaises(Exception, clusters.Station,
-                              cluster=self.cluster, station_id=1,
-                              position=(0, 1, 2), station_timestamps=[1, 2])
+            self.assertRaises(
+                Exception,
+                clusters.Station,
+                cluster=self.cluster,
+                station_id=1,
+                position=(0, 1, 2),
+                station_timestamps=[1, 2],
+            )
 
     def test__update_timestamp(self):
         self.assertEqual(self.station_4d.index, -1)
         for ts, index in [(-1, 0), (0, 0), (3, 0), (7, 1), (8, 1)]:
             self.station_4d._update_timestamp(ts)
             self.assertEqual(self.station_4d.index, index)
 
@@ -180,16 +195,15 @@
     def test_get_coordinates(self):
         with patch('sapphire.clusters.Detector') as mock_detector:
             self.assertFalse(mock_detector.called)
             cluster = Mock()
 
             # Trivial
             cluster.get_coordinates.return_value = (0, 0, 0, 0)
-            station = clusters.Station(cluster, 1, position=(0, 0), angle=0,
-                                       detectors=[((0, 0), 'LR')])
+            station = clusters.Station(cluster, 1, position=(0, 0), angle=0, detectors=[((0, 0), 'LR')])
             coordinates = station.get_coordinates()
             self.assertEqual(coordinates, (0, 0, 0, 0))
             coordinates = station.get_xyalpha_coordinates()
             self.assertEqual(coordinates, (0, 0, 0))
 
             # Cluster not in origin and rotated
             cluster.get_coordinates.return_value = (sqrt(2) / 2, sqrt(2) / 2, 0, pi / 8)
@@ -239,16 +253,15 @@
             self.assertAlmostEqual(beta, pi / 4)
 
     def test_get_polar_alpha_coordinates(self):
         cluster = Mock()
 
         # Trivial
         cluster.get_coordinates.return_value = (0, 0, 0, 0)
-        station = clusters.Station(cluster, 1, position=(0, 0), angle=0,
-                                   detectors=[((0, 0), 'LR')])
+        station = clusters.Station(cluster, 1, position=(0, 0), angle=0, detectors=[((0, 0), 'LR')])
         coordinates = station.get_polar_alpha_coordinates()
         self.assertEqual(coordinates, (0, 0, 0))
 
         # Cluster not in origin and rotated
         cluster.get_coordinates.return_value = (sqrt(2) / 2, sqrt(2) / 2, 0, pi / 8)
         station = clusters.Station(cluster, 1, (0, 0), 0, [((0, 0), 'LR')])
         coordinates = station.get_polar_alpha_coordinates()
@@ -265,37 +278,46 @@
         station = clusters.Station(cluster, 1, (0, 5), pi / 4, [((0, 0), 'LR')])
         coordinates = station.get_polar_alpha_coordinates()
         self.assert_tuple_almost_equal(coordinates, (sqrt(125), 2.0344439357957027, 3 * pi / 4))
 
     def test_calc_r_and_phi_for_detectors(self):
         cluster = Mock()
         cluster.get_coordinates.return_value = (0, 0, 0, 0)
-        station = clusters.Station(cluster, 1, position=(0, 0), angle=0,
-                                   detectors=[((0, 0), 'LR'), ((10., 10.), 'LR')])
+        station = clusters.Station(
+            cluster,
+            1,
+            position=(0, 0),
+            angle=0,
+            detectors=[((0, 0), 'LR'), ((10.0, 10.0), 'LR')],
+        )
 
         r, phi = station.calc_r_and_phi_for_detectors(0, 1)
-        self.assertAlmostEqual(r ** 2, 10 ** 2 + 10 ** 2)
+        self.assertAlmostEqual(r**2, 10**2 + 10**2)
         self.assertAlmostEqual(phi, pi / 4)
 
     def test_calc_center_of_mass_coordinates(self):
         cluster = Mock()
         cluster.get_coordinates.return_value = (0, 0, 0, 0)
-        station = clusters.Station(cluster, 1, position=(0, 0), angle=0,
-                                   detectors=[((0, 0, 0), 'LR'), ((10, 9, 1), 'LR'),
-                                              ((nan, nan, nan), 'LR'), ((nan, nan, nan), 'LR')])
+        station = clusters.Station(
+            cluster,
+            1,
+            position=(0, 0),
+            angle=0,
+            detectors=[((0, 0, 0), 'LR'), ((10, 9, 1), 'LR'), ((nan, nan, nan), 'LR'), ((nan, nan, nan), 'LR')],
+        )
         center = station.calc_xy_center_of_mass_coordinates()
         self.assert_tuple_almost_equal(center, (5, 4.5))
         center = station.calc_center_of_mass_coordinates()
         self.assert_tuple_almost_equal(center, (5, 4.5, 0.5))
 
     def assert_tuple_almost_equal(self, actual, expected):
         self.assertIsInstance(actual, tuple)
         self.assertIsInstance(expected, tuple)
 
-        msg = f"Tuples differ: {str(actual)} != {str(expected)}"
+        msg = f'Tuples differ: {actual!s} != {expected!s}'
         for actual_value, expected_value in zip(actual, expected):
             self.assertAlmostEqual(actual_value, expected_value, msg=msg)
 
 
 class BaseClusterTests(unittest.TestCase):
     def test_add_station(self):
         with patch('sapphire.clusters.Station') as mock_station:
@@ -305,16 +327,15 @@
             x = Mock(name='x')
             y = Mock(name='y')
             z = Mock(name='z')
             angle = Mock(name='angle')
             detector_list = Mock(name='detector_list')
             number = Mock(name='number')
             cluster._add_station((x, y, z), angle, detector_list, number=number)
-            mock_station.assert_called_with(cluster, 0, (x, y, z), angle,
-                                            detector_list, None, None, number)
+            mock_station.assert_called_with(cluster, 0, (x, y, z), angle, detector_list, None, None, number)
 
     def test_set_timestamp(self):
         with patch('sapphire.clusters.Station'):
             cluster = clusters.BaseCluster()
             cluster._add_station(sentinel.position)
             self.assertEqual(cluster._timestamp, 2147483647)
             cluster.set_timestamp(sentinel.timestamp)
@@ -349,109 +370,111 @@
 
     def test_get_station_by_number(self):
         cluster = clusters.BaseCluster((0, 0, 0), 0)
         cluster._add_station((0, 0, 0), 0, number=501)
         self.assertEqual(cluster.get_station(501), cluster.stations[0])
 
     def test_init_sets_position(self):
-        cluster = clusters.BaseCluster((10., 20.), pi / 2)
-        self.assertEqual(cluster.x, 10.)
-        self.assertEqual(cluster.y, 20.)
-        self.assertEqual(cluster.z, 0.)
+        cluster = clusters.BaseCluster((10.0, 20.0), pi / 2)
+        self.assertEqual(cluster.x, 10.0)
+        self.assertEqual(cluster.y, 20.0)
+        self.assertEqual(cluster.z, 0.0)
         self.assertEqual(cluster.alpha, pi / 2)
 
     def test_get_coordinates(self):
-        cluster = clusters.BaseCluster((10., 20., 0), pi / 2)
+        cluster = clusters.BaseCluster((10.0, 20.0, 0), pi / 2)
         coordinates = cluster.get_coordinates()
-        self.assertEqual(coordinates, (10., 20., 0, pi / 2))
+        self.assertEqual(coordinates, (10.0, 20.0, 0, pi / 2))
         coordinates = cluster.get_xyalpha_coordinates()
-        self.assertEqual(coordinates, (10., 20., pi / 2))
+        self.assertEqual(coordinates, (10.0, 20.0, pi / 2))
         coordinates = cluster.get_xy_coordinates()
-        self.assertEqual(coordinates, (10., 20.))
+        self.assertEqual(coordinates, (10.0, 20.0))
 
     def test_get_polar_alpha_coordinates(self):
         cluster = clusters.BaseCluster((-sqrt(2) / 2, sqrt(2) / 2), pi / 2)
         r, phi, alpha = cluster.get_polar_alpha_coordinates()
-        self.assertAlmostEqual(r, 1.)
+        self.assertAlmostEqual(r, 1.0)
         self.assertAlmostEqual(phi, 3 * pi / 4)
         self.assertEqual(alpha, pi / 2)
 
     def test_set_coordinates(self):
         cluster = clusters.BaseCluster()
         cluster.set_coordinates(sentinel.x, sentinel.y, sentinel.z, sentinel.alpha)
-        self.assertEqual((cluster.x, cluster.y, cluster.z, cluster.alpha),
-                         (sentinel.x, sentinel.y, sentinel.z, sentinel.alpha))
+        self.assertEqual(
+            (cluster.x, cluster.y, cluster.z, cluster.alpha),
+            (sentinel.x, sentinel.y, sentinel.z, sentinel.alpha),
+        )
 
     def test_set_rphialpha_coordinates(self):
         cluster = clusters.BaseCluster()
-        cluster.set_cylindrical_coordinates(10., pi / 2, sentinel.z, sentinel.alpha)
-        self.assertAlmostEqual(cluster.x, 0.)
-        self.assertAlmostEqual(cluster.y, 10.)
+        cluster.set_cylindrical_coordinates(10.0, pi / 2, sentinel.z, sentinel.alpha)
+        self.assertAlmostEqual(cluster.x, 0.0)
+        self.assertAlmostEqual(cluster.y, 10.0)
         self.assertAlmostEqual(cluster.z, sentinel.z)
         self.assertAlmostEqual(cluster.alpha, sentinel.alpha)
 
     def test_calc_r_and_phi_for_stations(self):
         cluster = clusters.BaseCluster()
         cluster._add_station((0, 0), 0)
         cluster._add_station((1, sqrt(3)), 0)
         r, phi, z = cluster.calc_rphiz_for_stations(0, 1)
         self.assertAlmostEqual(r, 2)
-        self.assertAlmostEqual(phi, pi / 3.)
+        self.assertAlmostEqual(phi, pi / 3.0)
         self.assertAlmostEqual(z, 0)
 
     def test_calc_xy_center_of_mass_coordinates(self):
         cluster = clusters.BaseCluster()
-        cluster._add_station((0, 0), 0, [((0, 5 * sqrt(3)), 'UD'),
-                                         ((0, 5 * sqrt(3) / 3), 'UD'),
-                                         ((-10, 0), 'LR'),
-                                         ((10, 0), 'LR')])
+        cluster._add_station(
+            (0, 0),
+            0,
+            [((0, 5 * sqrt(3)), 'UD'), ((0, 5 * sqrt(3) / 3), 'UD'), ((-10, 0), 'LR'), ((10, 0), 'LR')],
+        )
         x, y = cluster.calc_xy_center_of_mass_coordinates()
         self.assertAlmostEqual(x, 0)
         self.assertAlmostEqual(y, 5 * sqrt(3) / 3)
 
     def test_calc_xy_center_of_mass_coordinates_nan_detectors(self):
         # detector locations can be nan, esp two detector stations
         cluster = clusters.BaseCluster()
-        cluster._add_station((0, 0), 0, [((-10, 0), 'LR'),
-                                         ((10, 0), 'LR'),
-                                         ((nan, nan), 'LR'),
-                                         ((nan, nan), 'LR')])
+        cluster._add_station((0, 0), 0, [((-10, 0), 'LR'), ((10, 0), 'LR'), ((nan, nan), 'LR'), ((nan, nan), 'LR')])
         x, y = cluster.calc_xy_center_of_mass_coordinates()
         self.assertAlmostEqual(x, 0)
         self.assertAlmostEqual(y, 0)
 
     def test_set_center_off_mass_at_origin(self):
         cluster = clusters.BaseCluster()
-        cluster._add_station((0, 0), 0, [((0, 5 * sqrt(3)), 'UD'),
-                                         ((0, 5 * sqrt(3) / 3), 'UD'),
-                                         ((-10, 0), 'LR'),
-                                         ((10, 0), 'LR')])
+        cluster._add_station(
+            (0, 0),
+            0,
+            [((0, 5 * sqrt(3)), 'UD'), ((0, 5 * sqrt(3) / 3), 'UD'), ((-10, 0), 'LR'), ((10, 0), 'LR')],
+        )
         cluster.set_center_off_mass_at_origin()
         center = cluster.calc_center_of_mass_coordinates()
-        assert_array_almost_equal(center, [0., 0., 0.])
+        assert_array_almost_equal(center, [0.0, 0.0, 0.0])
 
     def test_set_center_off_mass_at_origin_rotated_cluster(self):
         cluster = clusters.BaseCluster()
-        cluster._add_station((0, 0), 0, [((0, 5 * sqrt(3)), 'UD'),
-                                         ((0, 5 * sqrt(3) / 3), 'UD'),
-                                         ((-10, 0), 'LR'),
-                                         ((10, 0), 'LR')])
-        cluster.set_coordinates(10., -10., 1., 1.)
+        cluster._add_station(
+            (0, 0),
+            0,
+            [((0, 5 * sqrt(3)), 'UD'), ((0, 5 * sqrt(3) / 3), 'UD'), ((-10, 0), 'LR'), ((10, 0), 'LR')],
+        )
+        cluster.set_coordinates(10.0, -10.0, 1.0, 1.0)
         cluster.set_center_off_mass_at_origin()
         center = cluster.calc_center_of_mass_coordinates()
-        assert_array_almost_equal(center, [0., 0., 0.])
-        self.assertAlmostEqual(cluster.alpha, 1.)
+        assert_array_almost_equal(center, [0.0, 0.0, 0.0])
+        self.assertAlmostEqual(cluster.alpha, 1.0)
 
     def test__distance(self):
-        x = array([-5., 4., 3.])
-        y = array([2., -1., 0.])
+        x = array([-5.0, 4.0, 3.0])
+        y = array([2.0, -1.0, 0.0])
         dist = clusters.BaseCluster()._distance(x, y)
         self.assertAlmostEqual(dist, sqrt(49 + 25 + 9))
-        x = array([-5., 4.])
-        y = array([2., -1.])
+        x = array([-5.0, 4.0])
+        y = array([2.0, -1.0])
         dist = clusters.BaseCluster()._distance(x, y)
         self.assertAlmostEqual(dist, sqrt(49 + 25))
 
     def test_calc_distance_between_stations(self):
         cluster = clusters.BaseCluster()
         cluster._add_station((0, 0, 0), 0, number=1)
         cluster._add_station((3, 4, 5), 0, number=2)
@@ -481,176 +504,163 @@
         self.assertEqual(detectors[0].x, [-5.0])
         self.assert_tuple_almost_equal(detectors[0].get_coordinates(), (-5.0, 0, 0))
 
     def assert_tuple_almost_equal(self, actual, expected):
         self.assertIsInstance(actual, tuple)
         self.assertIsInstance(expected, tuple)
 
-        msg = f"Tuples differ: {str(actual)} != {str(expected)}"
+        msg = f'Tuples differ: {actual!s} != {expected!s}'
         for actual_value, expected_value in zip(actual, expected):
             self.assertAlmostEqual(actual_value, expected_value, msg=msg)
 
 
 class SimpleClusterTests(unittest.TestCase):
     def test_init_calls_super_init(self):
-        with patch.object(clusters.BaseCluster, '__init__',
-                          mocksignature=True) as mock_base_init:
+        with patch.object(clusters.BaseCluster, '__init__', mocksignature=True) as mock_base_init:
             clusters.SimpleCluster()
             self.assertTrue(mock_base_init.called)
 
     def test_get_coordinates_after_init(self):
         cluster = clusters.SimpleCluster()
         coordinates = cluster.get_xyalpha_coordinates()
-        self.assertEqual(coordinates, (0., 0., 0.))
+        self.assertEqual(coordinates, (0.0, 0.0, 0.0))
 
     def test_cluster_stations(self):
         cluster = clusters.SimpleCluster()
         stations = cluster.stations
         self.assertEqual(len(stations), 4)
 
 
 class SingleStationTests(unittest.TestCase):
     def test_init_calls_super_init(self):
-        with patch.object(clusters.BaseCluster, '__init__',
-                          mocksignature=True) as mock_base_init:
+        with patch.object(clusters.BaseCluster, '__init__', mocksignature=True) as mock_base_init:
             clusters.SingleStation()
             self.assertTrue(mock_base_init.called)
 
     def test_get_coordinates_after_init(self):
         cluster = clusters.SingleStation()
         coordinates = cluster.get_xyalpha_coordinates()
-        self.assertEqual(coordinates, (0., 0., 0.))
+        self.assertEqual(coordinates, (0.0, 0.0, 0.0))
 
     def test_single_station(self):
         cluster = clusters.SingleStation()
         stations = cluster.stations
         self.assertEqual(len(stations), 1)
 
 
 class SingleDetectorStationTests(unittest.TestCase):
     def setUp(self):
         self.cluster = clusters.SingleDetectorStation()
 
     def test_init_calls_super_init(self):
-        with patch.object(clusters.BaseCluster, '__init__',
-                          mocksignature=True) as mock_base_init:
+        with patch.object(clusters.BaseCluster, '__init__', mocksignature=True) as mock_base_init:
             clusters.SingleDetectorStation()
             self.assertTrue(mock_base_init.called)
 
     def test_get_coordinates_after_init(self):
         coordinates = self.cluster.get_xyalpha_coordinates()
-        self.assertEqual(coordinates, (0., 0., 0.))
+        self.assertEqual(coordinates, (0.0, 0.0, 0.0))
 
     def test_single_station_single_detector(self):
         self.assertEqual(len(self.cluster.stations), 1)
         self.assertEqual(len(self.cluster.stations[0].detectors), 1)
 
 
 class SingleTwoDetectorStationTests(unittest.TestCase):
     def test_init_calls_super_init(self):
-        with patch.object(clusters.BaseCluster, '__init__',
-                          mocksignature=True) as mock_base_init:
+        with patch.object(clusters.BaseCluster, '__init__', mocksignature=True) as mock_base_init:
             clusters.SingleTwoDetectorStation()
             self.assertTrue(mock_base_init.called)
 
     def test_get_coordinates_after_init(self):
         cluster = clusters.SingleTwoDetectorStation()
         coordinates = cluster.get_xyalpha_coordinates()
-        self.assertEqual(coordinates, (0., 0., 0.))
+        self.assertEqual(coordinates, (0.0, 0.0, 0.0))
 
     def test_single_station(self):
         cluster = clusters.SingleTwoDetectorStation()
         stations = cluster.stations
         self.assertEqual(len(stations), 1)
         detectors = stations[0].detectors
         self.assertEqual(len(detectors), 2)
 
 
 class SingleDiamondStationTests(unittest.TestCase):
     def test_init_calls_super_init(self):
-        with patch.object(clusters.BaseCluster, '__init__',
-                          mocksignature=True) as mock_base_init:
+        with patch.object(clusters.BaseCluster, '__init__', mocksignature=True) as mock_base_init:
             clusters.SingleDiamondStation()
             self.assertTrue(mock_base_init.called)
 
     def test_get_coordinates_after_init(self):
         cluster = clusters.SingleDiamondStation()
         coordinates = cluster.get_xyalpha_coordinates()
-        self.assertEqual(coordinates, (0., 0., 0.))
+        self.assertEqual(coordinates, (0.0, 0.0, 0.0))
 
     def test_single_station(self):
         cluster = clusters.SingleDiamondStation()
         stations = cluster.stations
         self.assertEqual(len(stations), 1)
         detectors = stations[0].detectors
         self.assertEqual(len(detectors), 4)
 
 
 class HiSPARCStationTests(unittest.TestCase):
     def setUp(self):
-        self.cluster = clusters.HiSPARCStations([501, 508, 510],
-                                                force_stale=True)
+        self.cluster = clusters.HiSPARCStations([501, 508, 510], force_stale=True)
 
     def test_first_station_was_reference(self):
         """First station was origin before shift to center mass"""
-        self.assertNotEqual(self.cluster.get_station(501).get_coordinates(), (0., 0., 0., 0.))
-        self.assertNotEqual(self.cluster.get_station(508).get_coordinates(), (0., 0., 0., 0.))
+        self.assertNotEqual(self.cluster.get_station(501).get_coordinates(), (0.0, 0.0, 0.0, 0.0))
+        self.assertNotEqual(self.cluster.get_station(508).get_coordinates(), (0.0, 0.0, 0.0, 0.0))
         # Undo cluster center at center mass
         self.cluster.set_coordinates(0, 0, 0, 0)
-        self.assertEqual(self.cluster.get_station(501).get_coordinates(), (0., 0., 0., 0.))
-        self.assertNotEqual(self.cluster.get_station(508).get_coordinates(), (0., 0., 0., 0.))
+        self.assertEqual(self.cluster.get_station(501).get_coordinates(), (0.0, 0.0, 0.0, 0.0))
+        self.assertNotEqual(self.cluster.get_station(508).get_coordinates(), (0.0, 0.0, 0.0, 0.0))
 
     def test_allow_missing_gps(self):
         """Allow making cluster with station without GPS coords
 
         First station with valid location is used as reference.
 
         """
         with warnings.catch_warnings(record=True) as warned:
-            cluster = clusters.HiSPARCStations(
-                [0, 508, 510], skip_missing=True, force_stale=True)
+            cluster = clusters.HiSPARCStations([0, 508, 510], skip_missing=True, force_stale=True)
         self.assertEqual(len(warned), 2)
         # Undo cluster center at center mass
         cluster.set_coordinates(0, 0, 0, 0)
-        self.assertEqual(cluster.get_station(508).get_coordinates(), (0., 0., 0., 0.))
+        self.assertEqual(cluster.get_station(508).get_coordinates(), (0.0, 0.0, 0.0, 0.0))
 
     def test_missing_gps_not_allowed(self):
         """Making cluster with station without GPS coords raises exception"""
         with self.assertRaises(KeyError):
-            clusters.HiSPARCStations(
-                [0, 508, 510], skip_missing=False, force_stale=True)
+            clusters.HiSPARCStations([0, 508, 510], skip_missing=False, force_stale=True)
 
     def test_zero_center_off_mass(self):
         center = self.cluster.calc_center_of_mass_coordinates()
-        assert_array_almost_equal(center, [0., 0., 0.])
+        assert_array_almost_equal(center, [0.0, 0.0, 0.0])
 
 
 class FlattenClusterTests(unittest.TestCase):
-
     def test_flatten_cluster_mock(self):
         cluster = Mock()
         station = Mock()
-        station.z = [1.]
+        station.z = [1.0]
         detector = Mock()
-        detector.z = [1.]
+        detector.z = [1.0]
         station.detectors = [detector]
         cluster.stations = [station]
-        self.assertEqual(cluster.stations[0].z[0], 1.)
-        self.assertEqual(cluster.stations[0].detectors[0].z[0], 1.)
+        self.assertEqual(cluster.stations[0].z[0], 1.0)
+        self.assertEqual(cluster.stations[0].detectors[0].z[0], 1.0)
         clusters.flatten_cluster(cluster)
-        self.assertEqual(cluster.stations[0].z[0], 0.)
-        self.assertEqual(cluster.stations[0].detectors[0].z[0], 0.)
+        self.assertEqual(cluster.stations[0].z[0], 0.0)
+        self.assertEqual(cluster.stations[0].detectors[0].z[0], 0.0)
 
     def test_flatten_cluster(self):
         cluster = clusters.CompassStations()
         cluster._add_station((0, 20, 40), [(7, 0, 1, 90), (7, 90, -10, 0)], number=104)
         station = cluster.get_station(104)
         detector = station.detectors[0]
         self.assertEqual(station.get_coordinates()[-2], 40)
         self.assertEqual(detector.get_coordinates()[-1], 41)
         clusters.flatten_cluster(cluster)
         self.assertEqual(station.get_coordinates()[-2], 0)
         self.assertEqual(detector.get_coordinates()[-1], 0)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_clusters_acceptance.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_clusters_acceptance.py`

 * *Files 10% similar despite different names*

```diff
@@ -6,32 +6,26 @@
 
 
 class SimpleClusterTest(unittest.TestCase):
     def setUp(self):
         self.cluster = clusters.SimpleCluster(size=100)
 
     def test_station_positions_and_angles(self):
-        a = sqrt(100 ** 2 - 50 ** 2)
-        expected = [(0, 2 * a / 3, 0, 0), (0, 0, 0, 0),
-                    (-50, -a / 3, 0, 2 * pi / 3), (50, -a / 3, 0, -2 * pi / 3)]
-        actual = [(station.x[0], station.y[0], station.z[0], station.angle[0])
-                  for station in self.cluster.stations]
+        a = sqrt(100**2 - 50**2)
+        expected = [(0, 2 * a / 3, 0, 0), (0, 0, 0, 0), (-50, -a / 3, 0, 2 * pi / 3), (50, -a / 3, 0, -2 * pi / 3)]
+        actual = [(station.x[0], station.y[0], station.z[0], station.angle[0]) for station in self.cluster.stations]
 
         for actual_value, expected_value in zip(actual, expected):
             self.assert_tuple_almost_equal(actual_value, expected_value)
 
     def test_get_detector_coordinates(self):
         for station in self.cluster.stations:
             for detector in station.detectors:
                 detector.get_xy_coordinates()
 
     def assert_tuple_almost_equal(self, actual, expected):
         self.assertIsInstance(actual, tuple)
         self.assertIsInstance(expected, tuple)
 
-        msg = f"Tuples differ: {str(actual)} != {str(expected)}"
+        msg = f'Tuples differ: {actual!s} != {expected!s}'
         for actual_value, expected_value in zip(actual, expected):
             self.assertAlmostEqual(actual_value, expected_value, msg=msg)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/coincidences-20160310.tsv` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/coincidences-20160310.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/esd_coincidence_data.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/esd_coincidence_data.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/esd_load_data.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/esd_load_data.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/events-s501-20120101.tsv` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/events-s501-20120101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/kascade.dat` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/kascade.dat`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/kascade.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/kascade.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/lightning-knmi-20150717.tsv` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/lightning-knmi-20150717.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/publicdb.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/publicdb.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/publicdb_src.h5` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/publicdb_src.h5`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/singles-s501-20170101.tsv` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/singles-s501-20170101.tsv`

 * *Files 1% similar despite different names*

```diff
@@ -8,22 +8,22 @@
 #
 #
 # This data contains the following columns:
 #
 # date:                 time of event [GPS calendar date]
 # time:                 time of event [GPS time of day]
 # timestamp:            time of event [UNIX timestamp]
-# mas_ch1_low           singles rate master channel 1 above low threshold
-# mas_ch1_high          singles rate master channel 1 above high threshold
-# mas_ch2_low           singles rate master channel 2 above low threshold
-# mas_ch2_high          singles rate master channel 2  above high threshold
-# slv_ch1_low           singles rate slave channel 1 above low threshold
-# slv_ch1_high          singles rate slave channel 1 above high threshold
-# slv_ch2_low           singles rate slave channel 2 above low threshold
-# slv_ch2_high          singles rate slave channel 2 above high threshold
+# mas_ch1_low           singles rate primary channel 1 above low threshold
+# mas_ch1_high          singles rate primary channel 1 above high threshold
+# mas_ch2_low           singles rate primary channel 2 above low threshold
+# mas_ch2_high          singles rate primary channel 2  above high threshold
+# slv_ch1_low           singles rate secondary channel 1 above low threshold
+# slv_ch1_high          singles rate secondary channel 1 above high threshold
+# slv_ch2_low           singles rate secondary channel 2 above low threshold
+# slv_ch2_high          singles rate secondary channel 2 above high threshold
 # Values of -1 or -999 indicate a problem in that measurement or
 # the absence of that sensor.
 #
 #
 2017-01-01	00:00:00	1483228800	423	109	383	96	516	110	446	116
 2017-01-01	00:00:01	1483228801	402	112	417	120	498	125	454	104
 2017-01-01	00:00:02	1483228802	413	103	410	100	503	133	488	125
@@ -620,8 +620,8 @@
 2017-01-01	00:09:53	1483229393	433	114	411	95	519	113	509	124
 2017-01-01	00:09:54	1483229394	433	114	355	95	512	115	493	123
 2017-01-01	00:09:55	1483229395	418	123	434	112	552	114	456	98
 2017-01-01	00:09:56	1483229396	420	102	387	94	565	122	462	123
 2017-01-01	00:09:57	1483229397	428	116	374	106	532	124	458	119
 2017-01-01	00:09:58	1483229398	379	93	392	105	526	126	461	110
 2017-01-01	00:09:59	1483229399	400	95	374	84	562	135	458	113
-# Finished downloading.
+# Finished downloading.
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_data/weather-s501-20120101.tsv` & `hisparc_sapphire-3.0.0/sapphire/tests/test_data/weather-s501-20120101.tsv`

 * *Files identical despite different names*

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_esd.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_esd.py`

 * *Files 9% similar despite different names*

```diff
@@ -16,84 +16,84 @@
     test_data_path,
 )
 from sapphire.tests.validate_results import validate_results
 
 
 class StaleNetwork(api.Network):
     """api.Network with `force_stale=True` always true"""
+
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.force_stale = True
 
 
 class ESDTest(unittest.TestCase):
-
     def test_create_table(self):
-        description = {'event_id': tables.UInt32Col(pos=0),
-                       'timestamp': tables.Time32Col(pos=1),
-                       'nanoseconds': tables.UInt32Col(pos=2),
-                       'ext_timestamp': tables.UInt64Col(pos=3),
-                       'pulseheights': tables.Int16Col(pos=4, shape=4),
-                       'integrals': tables.Int32Col(pos=5, shape=4),
-                       'n1': tables.Float32Col(pos=6),
-                       'n2': tables.Float32Col(pos=7),
-                       'n3': tables.Float32Col(pos=8),
-                       'n4': tables.Float32Col(pos=9),
-                       't1': tables.Float32Col(pos=10),
-                       't2': tables.Float32Col(pos=11),
-                       't3': tables.Float32Col(pos=12),
-                       't4': tables.Float32Col(pos=13),
-                       't_trigger': tables.Float32Col(pos=14)}
+        description = {
+            'event_id': tables.UInt32Col(pos=0),
+            'timestamp': tables.Time32Col(pos=1),
+            'nanoseconds': tables.UInt32Col(pos=2),
+            'ext_timestamp': tables.UInt64Col(pos=3),
+            'pulseheights': tables.Int16Col(pos=4, shape=4),
+            'integrals': tables.Int32Col(pos=5, shape=4),
+            'n1': tables.Float32Col(pos=6),
+            'n2': tables.Float32Col(pos=7),
+            'n3': tables.Float32Col(pos=8),
+            'n4': tables.Float32Col(pos=9),
+            't1': tables.Float32Col(pos=10),
+            't2': tables.Float32Col(pos=11),
+            't3': tables.Float32Col(pos=12),
+            't4': tables.Float32Col(pos=13),
+            't_trigger': tables.Float32Col(pos=14),
+        }
         file = MagicMock()
         result = esd._create_events_table(file, sentinel.group)
-        file.create_table.assert_called_once_with(sentinel.group, 'events',
-                                                  description,
-                                                  createparents=True)
+        file.create_table.assert_called_once_with(sentinel.group, 'events', description, createparents=True)
         self.assertEqual(result, file.create_table.return_value)
 
     def test_create_weather_table(self):
-        description = {'event_id': tables.UInt32Col(pos=0),
-                       'timestamp': tables.Time32Col(pos=1),
-                       'temp_inside': tables.Float32Col(pos=2),
-                       'temp_outside': tables.Float32Col(pos=3),
-                       'humidity_inside': tables.Int16Col(pos=4),
-                       'humidity_outside': tables.Int16Col(pos=5),
-                       'barometer': tables.Float32Col(pos=6),
-                       'wind_dir': tables.Int16Col(pos=7),
-                       'wind_speed': tables.Int16Col(pos=8),
-                       'solar_rad': tables.Int16Col(pos=9),
-                       'uv': tables.Int16Col(pos=10),
-                       'evapotranspiration': tables.Float32Col(pos=11),
-                       'rain_rate': tables.Float32Col(pos=12),
-                       'heat_index': tables.Int16Col(pos=13),
-                       'dew_point': tables.Float32Col(pos=14),
-                       'wind_chill': tables.Float32Col(pos=15)}
+        description = {
+            'event_id': tables.UInt32Col(pos=0),
+            'timestamp': tables.Time32Col(pos=1),
+            'temp_inside': tables.Float32Col(pos=2),
+            'temp_outside': tables.Float32Col(pos=3),
+            'humidity_inside': tables.Int16Col(pos=4),
+            'humidity_outside': tables.Int16Col(pos=5),
+            'barometer': tables.Float32Col(pos=6),
+            'wind_dir': tables.Int16Col(pos=7),
+            'wind_speed': tables.Int16Col(pos=8),
+            'solar_rad': tables.Int16Col(pos=9),
+            'uv': tables.Int16Col(pos=10),
+            'evapotranspiration': tables.Float32Col(pos=11),
+            'rain_rate': tables.Float32Col(pos=12),
+            'heat_index': tables.Int16Col(pos=13),
+            'dew_point': tables.Float32Col(pos=14),
+            'wind_chill': tables.Float32Col(pos=15),
+        }
         file = MagicMock()
         result = esd._create_weather_table(file, sentinel.group)
-        file.create_table.assert_called_once_with(sentinel.group, 'weather',
-                                                  description,
-                                                  createparents=True)
+        file.create_table.assert_called_once_with(sentinel.group, 'weather', description, createparents=True)
         self.assertEqual(result, file.create_table.return_value)
 
     def test_create_singles_table(self):
-        description = {'event_id': tables.UInt32Col(pos=0),
-                       'timestamp': tables.Time32Col(pos=1),
-                       'mas_ch1_low': tables.Int32Col(pos=2),
-                       'mas_ch1_high': tables.Int32Col(pos=3),
-                       'mas_ch2_low': tables.Int32Col(pos=4),
-                       'mas_ch2_high': tables.Int32Col(pos=5),
-                       'slv_ch1_low': tables.Int32Col(pos=6),
-                       'slv_ch1_high': tables.Int32Col(pos=7),
-                       'slv_ch2_low': tables.Int32Col(pos=8),
-                       'slv_ch2_high': tables.Int32Col(pos=9)}
+        description = {
+            'event_id': tables.UInt32Col(pos=0),
+            'timestamp': tables.Time32Col(pos=1),
+            'mas_ch1_low': tables.Int32Col(pos=2),
+            'mas_ch1_high': tables.Int32Col(pos=3),
+            'mas_ch2_low': tables.Int32Col(pos=4),
+            'mas_ch2_high': tables.Int32Col(pos=5),
+            'slv_ch1_low': tables.Int32Col(pos=6),
+            'slv_ch1_high': tables.Int32Col(pos=7),
+            'slv_ch2_low': tables.Int32Col(pos=8),
+            'slv_ch2_high': tables.Int32Col(pos=9),
+        }
         file = MagicMock()
         result = esd._create_singles_table(file, sentinel.group)
-        file.create_table.assert_called_once_with(sentinel.group, 'singles',
-                                                  description,
-                                                  createparents=True)
+        file.create_table.assert_called_once_with(sentinel.group, 'singles', description, createparents=True)
         self.assertEqual(result, file.create_table.return_value)
 
     def test__first_available_numbered_path(self):
         """Check if correct path is given if there is no existing h5."""
 
         self.assertEqual(esd._first_available_numbered_path(), 'data1.h5')
         # make data1.h5 and check if it returns data2.h5 then clean up..
@@ -103,24 +103,21 @@
         self.assertEqual(esd._first_available_numbered_path(), 'data2.h5')
         os.remove('data1.h5')
 
     def test_unsupported_type(self):
         """Check for Exception for unsupported data types"""
 
         self.assertRaises(ValueError, esd.load_data, None, None, None, 'bad')
-        self.assertRaises(ValueError, esd.download_data, None, None, 501,
-                          type='bad')
+        self.assertRaises(ValueError, esd.download_data, None, None, 501, type='bad')
 
     def test_start_end_values(self):
         """Check for RuntimeError for impossible end=value with start=None"""
 
-        self.assertRaises(RuntimeError, esd.download_data, None, None, 501,
-                          start=None, end='a_value')
-        self.assertRaises(RuntimeError, esd.download_coincidences, None,
-                          start=None, end="a_value")
+        self.assertRaises(RuntimeError, esd.download_data, None, None, 501, start=None, end='a_value')
+        self.assertRaises(RuntimeError, esd.download_coincidences, None, start=None, end='a_value')
 
     def test_load_data_output(self):
         """Load data tsv into hdf5 and verify the output"""
 
         output_path = create_tempfile_path()
         perform_load_data(output_path)
         validate_results(self, test_data_path, output_path)
@@ -140,31 +137,25 @@
     def test_quick_download(self, mock_open_file, mock_download_data):
         """Test esd.quick_download()"""
 
         esd.quick_download(501)
         mock_open_file.assert_called_once_with('data1.h5', 'w')
         mock_download_data.assert_called_once_with(ANY, None, 501, None)
 
-    @unittest.skipUnless(api.API.check_connection(),
-                         "Internet connection required")
+    @unittest.skipUnless(api.API.check_connection(), 'Internet connection required')
     def test_download_data(self):
         """Download data and validate results"""
 
         output_path = create_tempfile_path()
         perform_esd_download_data(output_path)
         validate_results(self, test_data_path, output_path)
         os.remove(output_path)
 
-    @unittest.skipUnless(api.API.check_connection(),
-                         "Internet connection required")
+    @unittest.skipUnless(api.API.check_connection(), 'Internet connection required')
     @patch.object(esd.api, 'Network', side_effect=StaleNetwork)
     def test_download_coincidences(self, mock_esd_api_network):
         """Download coincidence data from esd and validate results"""
 
         output_path = create_tempfile_path()
         perform_download_coincidences(output_path)
         validate_results(self, test_data_coincidences_path, output_path)
         os.remove(output_path)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_kascade.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_kascade.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,31 +9,22 @@
 
 self_path = os.path.dirname(__file__)
 TEST_DATA_FILE = os.path.join(self_path, 'test_data/kascade.dat')
 TEST_DATA_REF = os.path.join(self_path, 'test_data/kascade.h5')
 
 
 class StoreKascadeDataTests(unittest.TestCase):
-
     def setUp(self):
         self.destination_path = self.create_tempfile_path()
+        self.addCleanup(os.remove, self.destination_path)
 
     def test_read_and_store_data(self):
         path = self.destination_path
         with tables.open_file(path, 'a') as self.destination_data:
-            self.kascade = kascade.StoreKascadeData(self.destination_data,
-                                                    TEST_DATA_FILE, '/kascade',
-                                                    progress=False)
+            self.kascade = kascade.StoreKascadeData(self.destination_data, TEST_DATA_FILE, '/kascade', progress=False)
             self.kascade.read_and_store_data()
         validate_results(self, TEST_DATA_REF, self.destination_path)
 
-    def tearDown(self):
-        os.remove(self.destination_path)
-
     def create_tempfile_path(self):
         fd, path = tempfile.mkstemp('.h5')
         os.close(fd)
         return path
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_publicdb.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_publicdb.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,44 +14,45 @@
 
 self_path = os.path.dirname(__file__)
 test_data_src_path = os.path.join(self_path, 'test_data/publicdb_src.h5')
 test_data_path = os.path.join(self_path, 'test_data/publicdb.h5')
 
 
 class DownloadDataTest(unittest.TestCase):
-
     def setUp(self):
         logging.disable(logging.CRITICAL)
-
-    def tearDown(self):
-        logging.disable(logging.NOTSET)
+        self.addCleanup(logging.disable, logging.NOTSET)
 
     @patch.object(publicdb, '_store_data')
     @patch.object(publicdb, 'urlretrieve')
     @patch.object(publicdb, 'ServerProxy')
     def test_download_data(self, mock_server, mock_retrieve, mock_store):
         start = datetime(2010, 1, 1, 11)
         end = datetime(2010, 1, 1, 13)
         file = Mock()
         mock_get_data_url = mock_server.return_value.hisparc.get_data_url
         mock_get_data_url.return_value = sentinel.url
         mock_retrieve.return_value = (sentinel.tmpdata, sentinel.headers)
-        publicdb.download_data(file, sentinel.group, sentinel.station_id,
-                               start, end, get_blobs=sentinel.blobs)
-        mock_get_data_url.assert_called_once_with(sentinel.station_id, start,
-                                                  sentinel.blobs)
-
-        mock_get_data_url.side_effect = Exception("No data")
-        publicdb.download_data(file, sentinel.group, sentinel.station_id,
-                               start, end, get_blobs=sentinel.blobs)
-
-        mock_get_data_url.side_effect = Exception("Unknown error")
-        self.assertRaises(Exception, publicdb.download_data, file,
-                          sentinel.group, sentinel.station_id, start,
-                          end, get_blobs=sentinel.blobs)
+        publicdb.download_data(file, sentinel.group, sentinel.station_id, start, end, get_blobs=sentinel.blobs)
+        mock_get_data_url.assert_called_once_with(sentinel.station_id, start, sentinel.blobs)
+
+        mock_get_data_url.side_effect = Exception('No data')
+        publicdb.download_data(file, sentinel.group, sentinel.station_id, start, end, get_blobs=sentinel.blobs)
+
+        mock_get_data_url.side_effect = Exception('Unknown error')
+        self.assertRaises(
+            Exception,
+            publicdb.download_data,
+            file,
+            sentinel.group,
+            sentinel.station_id,
+            start,
+            end,
+            get_blobs=sentinel.blobs,
+        )
 
     def test__store_data(self):
         # store data removes the source data when completed, so use a temp
         tmp_src_path = create_tempfile_path()
         shutil.copy(test_data_src_path, tmp_src_path)
 
         output_path = create_tempfile_path()
@@ -68,81 +69,75 @@
         tmp_src_path = create_tempfile_path()
         shutil.copy(test_data_src_path, tmp_src_path)
 
         output_path = create_tempfile_path()
         start = datetime(2016, 4, 21)
         filters = tables.Filters(complevel=1)
         with tables.open_file(output_path, 'w', filters=filters) as datafile:
-            publicdb._store_data(datafile, '/station_501', tmp_src_path, start,
-                                 None)
+            publicdb._store_data(datafile, '/station_501', tmp_src_path, start, None)
         validate_results(self, test_data_src_path, output_path)
         os.remove(output_path)
 
     def test_datetimerange(self):
         combinations = [
-            (datetime(2010, 1, 1, 11),
-             datetime(2010, 1, 1, 13),
-             [(datetime(2010, 1, 1, 11), datetime(2010, 1, 1, 13))]),
-            (datetime(2010, 1, 1, 11),
-             datetime(2010, 1, 2),
-             [(datetime(2010, 1, 1, 11), None)]),
-            (datetime(2010, 1, 1, 11),
-             datetime(2010, 1, 2, 13),
-             [(datetime(2010, 1, 1, 11), None),
-              (datetime(2010, 1, 2), datetime(2010, 1, 2, 13))]),
-            (datetime(2010, 1, 1, 11),
-             datetime(2010, 1, 5, 13),
-             [(datetime(2010, 1, 1, 11), None),
-              (datetime(2010, 1, 2), None),
-              (datetime(2010, 1, 3), None),
-              (datetime(2010, 1, 4), None),
-              (datetime(2010, 1, 5), datetime(2010, 1, 5, 13))])]
+            (
+                datetime(2010, 1, 1, 11),
+                datetime(2010, 1, 1, 13),
+                [(datetime(2010, 1, 1, 11), datetime(2010, 1, 1, 13))],
+            ),
+            (datetime(2010, 1, 1, 11), datetime(2010, 1, 2), [(datetime(2010, 1, 1, 11), None)]),
+            (
+                datetime(2010, 1, 1, 11),
+                datetime(2010, 1, 2, 13),
+                [(datetime(2010, 1, 1, 11), None), (datetime(2010, 1, 2), datetime(2010, 1, 2, 13))],
+            ),
+            (
+                datetime(2010, 1, 1, 11),
+                datetime(2010, 1, 5, 13),
+                [
+                    (datetime(2010, 1, 1, 11), None),
+                    (datetime(2010, 1, 2), None),
+                    (datetime(2010, 1, 3), None),
+                    (datetime(2010, 1, 4), None),
+                    (datetime(2010, 1, 5), datetime(2010, 1, 5, 13)),
+                ],
+            ),
+        ]
         for start, stop, result in combinations:
             self.assertEqual(list(publicdb.datetimerange(start, stop)), result)
-            self.assertRaises(Exception, next,
-                              publicdb.datetimerange(stop, start))
+            self.assertRaises(Exception, next, publicdb.datetimerange(stop, start))
 
     def test__get_or_create_group(self):
         file = Mock()
         file.get_node.return_value = sentinel.file_group
         group = publicdb._get_or_create_group(file, sentinel.group)
         self.assertEqual(group, sentinel.file_group)
 
         file = Mock()
         file.get_node.side_effect = tables.NoSuchNodeError('no such node!')
         in_group = '/hisparc/station_501'
         out_group = publicdb._get_or_create_group(file, in_group)
-        file.create_group.assert_called_once_with('/hisparc', 'station_501',
-                                                  'Data group',
-                                                  createparents=True)
+        file.create_group.assert_called_once_with('/hisparc', 'station_501', 'Data group', createparents=True)
         self.assertEqual(file.create_group.return_value, out_group)
 
     def test__get_or_create_node(self):
         file = Mock()
         src_node = Mock()
         file.get_node.return_value = sentinel.node
 
         node = publicdb._get_or_create_node(file, sentinel.group, src_node)
         file.get_node.assert_called_once_with(sentinel.group, src_node.name)
         self.assertEqual(node, sentinel.node)
 
         file.get_node.side_effect = tables.NoSuchNodeError('no such node!')
         # Raise exception because type of Mock src_node is not Table or VLArray
-        self.assertRaises(Exception, publicdb._get_or_create_node, file,
-                          sentinel.group, src_node)
+        self.assertRaises(Exception, publicdb._get_or_create_node, file, sentinel.group, src_node)
 
         src_node = Mock(spec=tables.Table)
         src_node.description = sentinel.description
         node = publicdb._get_or_create_node(file, sentinel.group, src_node)
-        file.create_table.assert_called_once_with(
-            sentinel.group, src_node.name, src_node.description,
-            src_node.title)
+        file.create_table.assert_called_once_with(sentinel.group, src_node.name, src_node.description, src_node.title)
 
         src_node = Mock(spec=tables.VLArray)
         src_node.atom = sentinel.atom
         node = publicdb._get_or_create_node(file, sentinel.group, src_node)
-        file.create_vlarray.assert_called_once_with(
-            sentinel.group, src_node.name, src_node.atom, src_node.title)
-
-
-if __name__ == '__main__':
-    unittest.main()
+        file.create_vlarray.assert_called_once_with(sentinel.group, src_node.name, src_node.atom, src_node.title)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_qsub.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_qsub.py`

 * *Files 10% similar despite different names*

```diff
@@ -5,100 +5,87 @@
 from unittest.mock import mock_open, patch, sentinel
 
 from sapphire import qsub
 
 
 @patch.object(qsub.utils, 'which')
 class CheckQueueTest(unittest.TestCase):
-
     @patch.object(qsub.subprocess, 'check_output')
     def test_queues(self, mock_check_output, mock_which):
         for queue in ['express', 'short', 'generic', 'long']:
             qsub.check_queue(queue)
             last_two_calls = mock_check_output.call_args_list[-2:]
             for call in last_two_calls:
                 self.assertTrue(queue in call[0][0])
 
     @patch.object(qsub.subprocess, 'check_output')
     def test_bad_queue(self, mock_check_output, mock_which):
         self.assertRaises(KeyError, qsub.check_queue, 'bla')
 
     @patch.object(qsub.subprocess, 'check_output')
     def test_check_queue(self, mock_check_output, mock_which):
-        combinations = ([['   0\n'], 2, 'express'],
-                        [['   2\n'], 0, 'express'],
-                        [[' 100\n'], 900, 'short'],
-                        [['1100\n'], -100, 'short'],
-                        [['2000\n', '1000\n'], 1000, 'generic'],
-                        [['3600\n', '1000\n'], 400, 'generic'],
-                        [[' 200\n', ' 100\n'], 400, 'long'],
-                        [[' 620\n', ' 100\n'], 380, 'long'])
+        combinations = (
+            [['   0\n'], 2, 'express'],
+            [['   2\n'], 0, 'express'],
+            [[' 100\n'], 900, 'short'],
+            [['1100\n'], -100, 'short'],
+            [['2000\n', '1000\n'], 1000, 'generic'],
+            [['3600\n', '1000\n'], 400, 'generic'],
+            [[' 200\n', ' 100\n'], 400, 'long'],
+            [[' 620\n', ' 100\n'], 380, 'long'],
+        )
         for taken, available, queue in combinations:
             mock_check_output.side_effect = cycle(taken)
             self.assertEqual(qsub.check_queue(queue), available)
 
 
 @patch.object(qsub.utils, 'which')
 class SubmitJobTest(unittest.TestCase):
-
     @patch.object(qsub, 'create_script')
     @patch.object(qsub.subprocess, 'check_output')
     @patch.object(qsub, 'delete_script')
-    def test_submit_job(self, mock_delete, mock_check_output, mock_create,
-                        mock_which):
+    def test_submit_job(self, mock_delete, mock_check_output, mock_create, mock_which):
         mock_create.return_value = (sentinel.script_path, sentinel.script_name)
         mock_check_output.return_value = b''
         qsub.submit_job(sentinel.script, sentinel.name, sentinel.queue, sentinel.extra)
 
         mock_create.assert_called_once_with(sentinel.script, sentinel.name)
-        command = ('qsub -q {queue} -V -z -j oe -N {name} {extra} {script}'
-                   .format(queue=sentinel.queue, name=sentinel.script_name,
-                           script=sentinel.script_path, extra=sentinel.extra))
-        mock_check_output.assert_called_once_with(command,
-                                                  stderr=qsub.subprocess.STDOUT,
-                                                  shell=True)
+        command = (
+            f'qsub -q {sentinel.queue} -V -z -j oe -N {sentinel.script_name} {sentinel.extra} {sentinel.script_path}'
+        )
+        mock_check_output.assert_called_once_with(command, stderr=qsub.subprocess.STDOUT, shell=True)
         mock_delete.assert_called_once_with(sentinel.script_path)
 
     @patch.object(qsub, 'create_script')
     @patch.object(qsub.subprocess, 'check_output')
     @patch.object(qsub, 'delete_script')
-    def test_failed_submit_job(self, mock_delete, mock_check_output,
-                               mock_create, mock_which):
+    def test_failed_submit_job(self, mock_delete, mock_check_output, mock_create, mock_which):
         mock_create.return_value = (sentinel.script_path, sentinel.script_name)
         mock_check_output.return_value = 'Failed!'
-        self.assertRaises(Exception, qsub.submit_job, sentinel.script,
-                          sentinel.name, sentinel.queue, sentinel.extra)
+        self.assertRaises(Exception, qsub.submit_job, sentinel.script, sentinel.name, sentinel.queue, sentinel.extra)
 
         mock_create.assert_called_once_with(sentinel.script, sentinel.name)
-        command = ('qsub -q {queue} -V -z -j oe -N {name} {extra} {script}'
-                   .format(queue=sentinel.queue, name=sentinel.script_name,
-                           script=sentinel.script_path, extra=sentinel.extra))
-        mock_check_output.assert_called_once_with(command,
-                                                  stderr=qsub.subprocess.STDOUT,
-                                                  shell=True)
+        command = (
+            f'qsub -q {sentinel.queue} -V -z -j oe -N {sentinel.script_name} {sentinel.extra} {sentinel.script_path}'
+        )
+        mock_check_output.assert_called_once_with(command, stderr=qsub.subprocess.STDOUT, shell=True)
         self.assertFalse(mock_delete.called)
 
 
 class CreateScriptTest(unittest.TestCase):
-
     @patch.object(qsub.os, 'chmod')
     def test_create_script(self, mock_chmod):
         with patch.object(builtins, 'open', mock_open()) as mock_file:
             res_path, res_name = qsub.create_script(sentinel.script, 'hoi')
-        self.assertEqual(res_path, '/tmp/his_hoi.sh')
+        self.assertTrue(res_path.endswith('/his_hoi.sh'))
         self.assertEqual(res_name, 'his_hoi.sh')
         mock_file.assert_called_once_with(res_path, 'w')
-        mock_file().write.called_once_with(sentinel.script)
+        mock_file().write.assert_called_once_with(sentinel.script)
         mock_chmod.assert_called_once_with(res_path, 0o774)
 
 
 class DeleteScriptTest(unittest.TestCase):
-
     @patch.object(qsub.os, 'remove')
     def test_delete_script(self, mock_remove):
         self.assertFalse(mock_remove.called)
         qsub.delete_script(sentinel.path)
         mock_remove.assert_called_once_with(sentinel.path)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_time_util.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_time_util.py`

 * *Files 2% similar despite different names*

```diff
@@ -19,17 +19,13 @@
 
     def test_incorrect_arguments(self):
         self.assertRaises(TypeError, time_util.GPSTime)
         self.assertRaises(TypeError, time_util.GPSTime, 2012, 12)
 
     @patch.object(time_util.GPSTime, 'description')
     def test_str_returns_description(self, mock_description):
-        expected = "Foobar"
+        expected = 'Foobar'
         mock_description.return_value = expected
         t = time_util.GPSTime(2014, 10, 27)
         actual = str(t)
         mock_description.assert_called_once_with()
         self.assertIs(actual, expected)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/test_utils.py` & `hisparc_sapphire-3.0.0/sapphire/tests/test_utils.py`

 * *Files 6% similar despite different names*

```diff
@@ -7,29 +7,28 @@
 
 from numpy import exp, pi, random, sqrt
 
 from sapphire import utils
 
 
 class PbarTests(unittest.TestCase):
-
     def setUp(self):
         self.iterable = list(range(10))
         self.output = StringIO()
 
     def test_pbar_iterable(self):
         pb = utils.pbar(self.iterable, fd=self.output)
         self.assertIsInstance(pb, progressbar.ProgressBar)
         self.assertEqual(list(pb), self.iterable)
 
     def test_pbar_generator(self):
         """Return original generator, not a progressbar"""
 
         generator = (x for x in self.iterable)
-        pb = utils.pbar(generator)
+        pb = utils.pbar(generator, fd=self.output)
         self.assertIsInstance(pb, types.GeneratorType)
         self.assertEqual(list(pb), self.iterable)
 
     def test_pbar_generator_known_length(self):
         """Return progressbar for generator with known length"""
 
         generator = (y for y in self.iterable)
@@ -46,15 +45,14 @@
 
         pb = utils.pbar(self.iterable, show=True, fd=self.output)
         self.assertEqual(list(pb), self.iterable)
         self.assertNotEqual(self.output.getvalue(), '')
 
 
 class InBaseTests(unittest.TestCase):
-
     def test_ceil(self):
         self.assertEqual(utils.ceil_in_base(2.4, 2.5), 2.5)
         self.assertEqual(utils.ceil_in_base(0.1, 2.5), 2.5)
 
     def test_floor(self):
         self.assertEqual(utils.floor_in_base(2.4, 2.5), 0)
         self.assertEqual(utils.floor_in_base(0.1, 2.5), 0)
@@ -71,63 +69,59 @@
     def test_integers(self):
         self.assertEqual(utils.ceil_in_base(3, 4), 4)
         self.assertEqual(utils.floor_in_base(3, 4), 0)
         self.assertEqual(utils.round_in_base(3, 4), 4)
 
 
 class ActiveIndexTests(unittest.TestCase):
-
     def test_get_active_index(self):
         """Test if the bisection returns the correct index
 
         - If timestamp is before the first timestamp return index for
           first item
         - If timestamp is after last timestamp return index for last item
         - If timestamp is in the range return index of rightmost value
           equal or less than the timestamp
 
         """
-        timestamps = [1., 2., 3., 4.]
+        timestamps = [1.0, 2.0, 3.0, 4.0]
 
-        for idx, ts in [(0, 0.), (0, 1.), (0, 1.5), (1, 2.), (1, 2.1), (3, 4.),
-                        (3, 5.)]:
+        for idx, ts in [(0, 0.0), (0, 1.0), (0, 1.5), (1, 2.0), (1, 2.1), (3, 4.0), (3, 5.0)]:
             self.assertEqual(utils.get_active_index(timestamps, ts), idx)
 
 
 class GaussTests(unittest.TestCase):
-
     """Test against explicit Gaussian"""
 
     def gaussian(self, x, n, mu, sigma):
-        return n * exp(-(x - mu) ** 2. / (2. * sigma ** 2)) / (sigma * sqrt(2 * pi))
+        return n * exp(-((x - mu) ** 2.0) / (2.0 * sigma**2)) / (sigma * sqrt(2 * pi))
 
     def test_gauss(self):
-        x, n, mu, sigma = (1., 1., 0., 1.)
+        x, n, mu, sigma = (1.0, 1.0, 0.0, 1.0)
         self.assertEqual(utils.gauss(x, n, mu, sigma), self.gaussian(x, n, mu, sigma))
-        n = 2.
+        n = 2.0
         self.assertEqual(utils.gauss(x, n, mu, sigma), self.gaussian(x, n, mu, sigma))
-        sigma = 2.
+        sigma = 2.0
         self.assertEqual(utils.gauss(x, n, mu, sigma), self.gaussian(x, n, mu, sigma))
         x = 1e5
-        self.assertEqual(utils.gauss(x, n, mu, sigma), 0.)
+        self.assertEqual(utils.gauss(x, n, mu, sigma), 0.0)
 
     def test_gauss_array(self):
         """Test for arrays of random values"""
 
         size = 10000
         x, n, mu = random.uniform(-100, 100, size=(3, size))
         # sigma can not be 0
         sigma = random.uniform(1e-15, 100, size=size)
         value1 = utils.gauss(x, n, mu, sigma)
         value2 = self.gaussian(x, n, mu, sigma)
         self.assertTrue(all(abs(value1 - value2) < 1e-10))
 
 
 class AngleBetweenTests(unittest.TestCase):
-
     """Check opening angle between two directions"""
 
     def test_zeniths(self):
         """One of the directions is the Zenith"""
 
         n = 10000
         zenith = random.uniform(0, pi / 2, n)
@@ -162,42 +156,37 @@
         zenith = random.uniform(0, pi / 2)
         azimuth = random.uniform(-pi, pi)
         angle = utils.angle_between(zenith, azimuth, zenith, azimuth)
         self.assertTrue(angle == 0)
 
 
 class DistanceBetweenTests(unittest.TestCase):
-
     """Check distance between two (x, y) cartesian coordinates"""
 
     def test_distances(self):
         """Check if distances are correctly calculated"""
 
-        combinations = [((0, 0, 1.6, 0), 1.6),
-                        ((-1, 0, 1, 0), 2),
-                        ((-1, 0, -1, 0), 0),
-                        ((random.uniform(1e-15, 100),) * 4, 0),
-                        ((-10, -10, 5, 5), sqrt(450))]
+        combinations = [
+            ((0, 0, 1.6, 0), 1.6),
+            ((-1, 0, 1, 0), 2),
+            ((-1, 0, -1, 0), 0),
+            ((random.uniform(1e-15, 100),) * 4, 0),
+            ((-10, -10, 5, 5), sqrt(450)),
+        ]
         for coordinates, distance in combinations:
             self.assertEqual(utils.distance_between(*coordinates), distance)
             # same result if the coordinates and x, y are swapped
             self.assertEqual(utils.distance_between(*coordinates[::-1]), distance)
 
 
 class WhichTests(unittest.TestCase):
-
     """Check if which works"""
 
     def test_which(self):
         """Check existence of common command"""
 
         utils.which('ls')
 
     def test_non_existent_program(self):
         """Check for error for non-existent program"""
 
-        self.assertRaises(Exception, utils.which,
-                          'a_very_unlikely_program_name_to_exist_cosmic_ray')
-
-
-if __name__ == '__main__':
-    unittest.main()
+        self.assertRaises(Exception, utils.which, 'a_very_unlikely_program_name_to_exist_cosmic_ray')
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_axes.py` & `hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_axes.py`

 * *Files 12% similar despite different names*

```diff
@@ -2,31 +2,36 @@
 
 from numpy import arccos, array, pi, sqrt, testing
 
 from sapphire.transformations import axes
 
 
 class CoordinateSystemTests(unittest.TestCase):
-
     def setUp(self):
         """Test combinations of coordinates
 
         Cartesian, spherical, cylindrical, polar, and compass coordinates
 
         """
         self.combinations = (
             ((0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0)),
             ((1, 0, 0), (1, pi / 2, 0), (1, 0, 0), (1, 90, 0)),
             ((-1, 0, 0), (1, pi / 2, pi), (1, pi, 0), (1, -90, 0)),
-            ((0, 1, 0), (1, pi / 2, pi / 2.), (1, pi / 2., 0), (1, 0, 0)),
+            ((0, 1, 0), (1, pi / 2, pi / 2.0), (1, pi / 2.0, 0), (1, 0, 0)),
             ((0, -1, 0), (1, pi / 2, -pi / 2), (1, -pi / 2, 0), (1, 180, 0)),
             ((0, 0, 1), (1, 0, 0), (0, 0, 1), (0, 0, 1)),
             ((0, 0, -1), (1, pi, 0), (0, 0, -1), (0, 0, -1)),
             ((1, 1, 1), (sqrt(3), arccos(1 / sqrt(3)), pi / 4), (sqrt(2), pi / 4, 1), (sqrt(2), 45, 1)),
-            ((-1, -1, -1), (sqrt(3), arccos(-1 / sqrt(3)), -pi * 3 / 4), (sqrt(2), -pi * 3 / 4, -1), (sqrt(2), -135, -1)))
+            (
+                (-1, -1, -1),
+                (sqrt(3), arccos(-1 / sqrt(3)), -pi * 3 / 4),
+                (sqrt(2), -pi * 3 / 4, -1),
+                (sqrt(2), -135, -1),
+            ),
+        )
 
     def test_cartesian_to_spherical(self):
         for cartesian, spherical, _, _ in self.combinations:
             self.assertEqual(axes.cartesian_to_spherical(*cartesian), spherical)
 
     def test_cartesian_to_cylindrical(self):
         for cartesian, _, cylindrical, _ in self.combinations:
@@ -54,43 +59,34 @@
 
     def test_compass_to_cartesian(self):
         for cartesian, _, _, compass in self.combinations:
             testing.assert_almost_equal(axes.compass_to_cartesian(*compass), cartesian)
 
 
 class RotateCartesianTests(unittest.TestCase):
-
     def test_rotate_cartesian(self):
-        input = (3., 4., 5.)
-        x, y, z = input
-        self.assertEqual(input, axes.rotate_cartesian(x, y, z, 0, 'x'))
-        self.assertEqual(input, axes.rotate_cartesian(x, y, z, 0, 'y'))
-        self.assertEqual(input, axes.rotate_cartesian(x, y, z, 0, 'z'))
-
-        testing.assert_almost_equal((3., -5., 4.), axes.rotate_cartesian(x, y, z, pi / 2, 'x'))
-        testing.assert_almost_equal((5., 4., -3.), axes.rotate_cartesian(x, y, z, pi / 2, 'y'))
-        testing.assert_almost_equal((-4., 3., 5.), axes.rotate_cartesian(x, y, z, pi / 2, 'z'))
+        initial = (3.0, 4.0, 5.0)
+        x, y, z = initial
+        self.assertEqual(initial, axes.rotate_cartesian(x, y, z, 0, 'x'))
+        self.assertEqual(initial, axes.rotate_cartesian(x, y, z, 0, 'y'))
+        self.assertEqual(initial, axes.rotate_cartesian(x, y, z, 0, 'z'))
+
+        testing.assert_almost_equal((3.0, -5.0, 4.0), axes.rotate_cartesian(x, y, z, pi / 2, 'x'))
+        testing.assert_almost_equal((5.0, 4.0, -3.0), axes.rotate_cartesian(x, y, z, pi / 2, 'y'))
+        testing.assert_almost_equal((-4.0, 3.0, 5.0), axes.rotate_cartesian(x, y, z, pi / 2, 'z'))
 
 
 class RotationMatrixTests(unittest.TestCase):
-
     def test_no_rotation_matrix(self):
         """Check if no rotation is correctly returned"""
 
         no_rotation = array(((1, 0, 0), (0, 1, 0), (0, 0, 1)))
         testing.assert_equal(axes.rotation_matrix(0, 'x'), no_rotation)
         testing.assert_equal(axes.rotation_matrix(0, 'y'), no_rotation)
         testing.assert_equal(axes.rotation_matrix(0, 'z'), no_rotation)
 
     def test_rotation_matrix(self):
         """Rotate by 90 degrees to swap the other two axes"""
 
-        testing.assert_almost_equal(axes.rotation_matrix(pi / 2., 'x'),
-                                    array(((1, 0, 0), (0, 0, 1), (0, -1, 0))))
-        testing.assert_almost_equal(axes.rotation_matrix(pi / 2., 'y'),
-                                    array(((0, 0, -1), (0, 1, 0), (1, 0, 0))))
-        testing.assert_almost_equal(axes.rotation_matrix(pi / 2, 'z'),
-                                    array(((0, 1, 0), (-1, 0, 0), (0, 0, 1))))
-
-
-if __name__ == '__main__':
-    unittest.main()
+        testing.assert_almost_equal(axes.rotation_matrix(pi / 2.0, 'x'), array(((1, 0, 0), (0, 0, 1), (0, -1, 0))))
+        testing.assert_almost_equal(axes.rotation_matrix(pi / 2.0, 'y'), array(((0, 0, -1), (0, 1, 0), (1, 0, 0))))
+        testing.assert_almost_equal(axes.rotation_matrix(pi / 2, 'z'), array(((0, 1, 0), (-1, 0, 0), (0, 0, 1))))
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_base.py` & `hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_base.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,30 +1,27 @@
 import unittest
 
 from sapphire.transformations import base
 
 
 class DecimalSexagesimalTests(unittest.TestCase):
-
     def setUp(self):
         # (decimal, sexagesimal)
-        self.combinations = ((0, (0, 0, 0)),
-                             (1, (1, 0, 0)),
-                             (30, (30, 0, 0)),
-                             (1 / 60., (0, 1, 0)),
-                             (-1 + (30 / 60.), (0, -30, 0)),
-                             (-1 - (30 / 60.) - (30 / 3600.), (-1, -30, -30)),
-                             (.5, (0, 30, 0)),
-                             (1 / 3600., (0, 0, 1)),
-                             (30 / 3600., (0, 0, 30)))
+        self.combinations = (
+            (0, (0, 0, 0)),
+            (1, (1, 0, 0)),
+            (30, (30, 0, 0)),
+            (1 / 60.0, (0, 1, 0)),
+            (-1 + (30 / 60.0), (0, -30, 0)),
+            (-1 - (30 / 60.0) - (30 / 3600.0), (-1, -30, -30)),
+            (0.5, (0, 30, 0)),
+            (1 / 3600.0, (0, 0, 1)),
+            (30 / 3600.0, (0, 0, 30)),
+        )
 
     def test_decimal_to_sexagesimal(self):
         for dec, sexa in self.combinations:
             self.assertEqual(base.decimal_to_sexagesimal(dec), sexa)
 
     def test_sexagesimal_to_decimal(self):
         for dec, sexa in self.combinations:
             self.assertEqual(base.sexagesimal_to_decimal(*sexa), dec)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_celestial.py` & `hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_celestial.py`

 * *Files 5% similar despite different names*

```diff
@@ -4,48 +4,42 @@
 
 from math import pi
 
 import numpy as np
 
 from sapphire.transformations import base, celestial, clock
 
-# This is to switch off tests in case astropy is not present
-# Noqa used to silence flake8
 try:
-    import astropy  # noqa : F401
-    has_astropy = True
+    import astropy  # noqa: F401
+
 except ImportError:
-    has_astropy = False
+    astropy_available = False
+else:
+    astropy_available = True
 
 
 class ZenithAzimuthHorizontalTests(unittest.TestCase):
-
     def setUp(self):
-        self.zenith = (0., pi / 4., pi / 2.)
-        self.altitude = (pi / 2., pi / 4., 0.)
+        self.zenith = (0.0, pi / 4.0, pi / 2.0)
+        self.altitude = (pi / 2.0, pi / 4.0, 0.0)
 
-        self.azimuth = (-pi / 2., 0., pi / 2.)  # -pi
-        self.Azimuth = (-pi, pi / 2., 0.)  # -pi / 2.
+        self.azimuth = (-pi / 2.0, 0.0, pi / 2.0)  # -pi
+        self.Azimuth = (-pi, pi / 2.0, 0.0)  # -pi / 2.
 
     def test_zenithazimuth_to_horizontal(self):
         for zenith, altitude in zip(self.zenith, self.altitude):
-            self.assertEqual(celestial.zenithazimuth_to_horizontal(
-                zenith, 0)[0], altitude)
-            self.assertEqual(celestial.horizontal_to_zenithazimuth(
-                altitude, 0)[0], zenith)
+            self.assertEqual(celestial.zenithazimuth_to_horizontal(zenith, 0)[0], altitude)
+            self.assertEqual(celestial.horizontal_to_zenithazimuth(altitude, 0)[0], zenith)
 
         for azimuth, Azimuth in zip(self.azimuth, self.Azimuth):
-            self.assertEqual(celestial.zenithazimuth_to_horizontal(
-                0, azimuth)[1], Azimuth)
-            self.assertEqual(celestial.horizontal_to_zenithazimuth(
-                0, Azimuth)[1], azimuth)
+            self.assertEqual(celestial.zenithazimuth_to_horizontal(0, azimuth)[1], Azimuth)
+            self.assertEqual(celestial.horizontal_to_zenithazimuth(0, Azimuth)[1], azimuth)
 
 
 class EquatorialTests(unittest.TestCase):
-
     """Accuracy tests for Celestial coordinate transformations.
 
     Use references as tests also used by astropy.
 
     Source:
     https://github.com/astropy/astropy/blob/master/
     astropy/coordinates/tests/accuracy/test_altaz_icrs.py
@@ -88,21 +82,20 @@
         # Matches  LAST = +03 53 53.6  in the hor2eq.pro
 
         # SAPPHiRE
         utc = calendar.timegm(clock.juliandate_to_utc(jd).utctimetuple())
         gps = clock.utc_to_gps(utc)
         zenith, azimuth = celestial.horizontal_to_zenithazimuth(
             np.radians(base.sexagesimal_to_decimal(*altitude)),
-            np.radians(base.sexagesimal_to_decimal(*azi)))
-        ra, dec = celestial.zenithazimuth_to_equatorial(latitude, longitude,
-                                                        gps, zenith, azimuth)
+            np.radians(base.sexagesimal_to_decimal(*azi)),
+        )
+        ra, dec = celestial.zenithazimuth_to_equatorial(latitude, longitude, gps, zenith, azimuth)
 
         # Test eq_to_zenaz merely against IDL
-        zencalc, azcalc = celestial.equatorial_to_zenithazimuth(
-            latitude, longitude, gps, ra_expected, dec_expected)
+        zencalc, azcalc = celestial.equatorial_to_zenithazimuth(latitude, longitude, gps, ra_expected, dec_expected)
 
         self.assertAlmostEqual(ra, ra_expected, 1)
         self.assertAlmostEqual(ra, ra_astropy, 1)
         self.assertAlmostEqual(dec, dec_expected, 2)
         self.assertAlmostEqual(dec, dec_astropy, 2)
 
         self.assertAlmostEqual(zencalc, zenith, 1)
@@ -132,19 +125,17 @@
         utc = datetime.datetime(2011, 9, 18, 8, 50)
         altitude = np.radians(-60.7665)
         azi = np.radians(6.8927)
 
         # SAPPHiRE
         gps = clock.utc_to_gps(calendar.timegm(utc.utctimetuple()))
         zenith, azimuth = celestial.horizontal_to_zenithazimuth(altitude, azi)
-        ra, dec = celestial.zenithazimuth_to_equatorial(
-            latitude, longitude, gps, zenith, azimuth)
+        ra, dec = celestial.zenithazimuth_to_equatorial(latitude, longitude, gps, zenith, azimuth)
 
-        zencalc, azcalc = celestial.equatorial_to_zenithazimuth(
-            latitude, longitude, gps, ra_expected, dec_expected)
+        zencalc, azcalc = celestial.equatorial_to_zenithazimuth(latitude, longitude, gps, ra_expected, dec_expected)
 
         self.assertAlmostEqual(ra, ra_expected, 2)
         self.assertAlmostEqual(ra, ra_astropy, 2)
         self.assertAlmostEqual(dec, dec_expected, 2)
         self.assertAlmostEqual(dec, dec_astropy, 2)
 
         self.assertAlmostEqual(zencalc, zenith, 2)
@@ -173,158 +164,151 @@
         utc = datetime.datetime(1998, 7, 28, 3, 0)
         altitude = np.radians(2.6223)
         azi = np.radians(143.2970)
 
         # SAPPHiRE
         gps = clock.utc_to_gps(calendar.timegm(utc.utctimetuple()))
         zenith, azimuth = celestial.horizontal_to_zenithazimuth(altitude, azi)
-        ra, dec = celestial.zenithazimuth_to_equatorial(latitude, longitude,
-                                                        gps, zenith, azimuth)
+        ra, dec = celestial.zenithazimuth_to_equatorial(latitude, longitude, gps, zenith, azimuth)
 
-        zencalc, azcalc = celestial.equatorial_to_zenithazimuth(latitude,
-                                                                longitude, gps,
-                                                                ra_expected,
-                                                                dec_expected)
+        zencalc, azcalc = celestial.equatorial_to_zenithazimuth(latitude, longitude, gps, ra_expected, dec_expected)
 
         self.assertAlmostEqual(ra, ra_expected, 3)
         self.assertAlmostEqual(ra, ra_astropy, 3)
         self.assertAlmostEqual(dec, dec_expected, 2)
         self.assertAlmostEqual(dec, dec_astropy, 2)
 
         self.assertAlmostEqual(zencalc, zenith, 2)
         self.assertAlmostEqual(azcalc, azimuth, 2)
 
 
-@unittest.skipUnless(has_astropy, "astropy required.")
+@unittest.skipUnless(astropy_available, 'astropy required.')
 class AstropyEquatorialTests(unittest.TestCase):
     """
     This tests the 4 new astropy functions. They should be very close to
     Pyephem results and in this test they are compared to 10 different
     coordinates from astropy.
 
     """
 
     def setUp(self):
         """
         This is necessary to prevent iers downloads during testing
         and mute output
         """
         from astropy.utils import iers
+
         iers.conf.auto_download = False
 
     def test_pyephem_htoea(self):
-        """ Check celestial.horizontal_to_equatorial_astropy """
+        """Check celestial.horizontal_to_equatorial_astropy"""
 
         # This is the transform inputs
-        eq = [(-39.34633914878846, -112.2277168069694, 1295503840,
-               3.8662384455822716, -0.31222454326513827),
-              (53.13143508448587, -49.24074935964933, 985619982,
-               3.901575896592809, -0.3926720112815971),
-              (48.02031016860923, -157.4023812557098, 1126251396,
-               3.366278312183976, -1.3610394240813288)]
+        eq = [
+            (-39.34633914878846, -112.2277168069694, 1295503840, 3.8662384455822716, -0.31222454326513827),
+            (53.13143508448587, -49.24074935964933, 985619982, 3.901575896592809, -0.3926720112815971),
+            (48.02031016860923, -157.4023812557098, 1126251396, 3.366278312183976, -1.3610394240813288),
+        ]
 
         # result of pyephem hor->eq/zenaz-> eq
-        efemeq = [(5.620508199785029, -0.3651173667585858),
-                  (5.244630787139936, -0.7866376569183651),
-                  (2.276751381056623, -1.0406498066785745)]
+        efemeq = [
+            (5.620508199785029, -0.3651173667585858),
+            (5.244630787139936, -0.7866376569183651),
+            (2.276751381056623, -1.0406498066785745),
+        ]
 
         htoea_test = []
 
         # Produce horizontal_to_equatorial_astropy results
         for latitude, longitude, gps, az, alt in eq:
-            result = celestial.horizontal_to_equatorial_astropy(
-                latitude, longitude, gps, [(az, alt)])
+            result = celestial.horizontal_to_equatorial_astropy(latitude, longitude, gps, [(az, alt)])
             htoea_test.extend(result)
 
         # Check if all inputs are correct
         # Test horizontal_to_equatorial_astropy
         np.testing.assert_almost_equal(efemeq, htoea_test, 4)
 
     def test_pyephem_etoha(self):
         """Check celestial.equatorial_to_horizontal_astropy"""
 
         # This is the transform inputs
-        eq = [(-39.34633914878846, -112.2277168069694, 1295503840,
-               3.8662384455822716, -0.31222454326513827),
-              (53.13143508448587, -49.24074935964933, 985619982,
-               3.901575896592809, -0.3926720112815971),
-              (48.02031016860923, -157.4023812557098, 1126251396,
-               3.366278312183976, -1.3610394240813288)]
+        eq = [
+            (-39.34633914878846, -112.2277168069694, 1295503840, 3.8662384455822716, -0.31222454326513827),
+            (53.13143508448587, -49.24074935964933, 985619982, 3.901575896592809, -0.3926720112815971),
+            (48.02031016860923, -157.4023812557098, 1126251396, 3.366278312183976, -1.3610394240813288),
+        ]
         # result of pyephem eq->hor
-        altaz = [(2.175107479095459, -0.19537943601608276),
-                 (5.25273323059082, -0.8308737874031067),
-                 (3.4536221027374268, -0.894329845905304)]
+        altaz = [
+            (2.175107479095459, -0.19537943601608276),
+            (5.25273323059082, -0.8308737874031067),
+            (3.4536221027374268, -0.894329845905304),
+        ]
 
         etoha_test = []
 
         # Produce equatorial_to_horizontal_astropy results
         for latitude, longitude, gps, ra, dec in eq:
-            result = celestial.equatorial_to_horizontal_astropy(
-                latitude, longitude, gps, [(ra, dec)])
+            result = celestial.equatorial_to_horizontal_astropy(latitude, longitude, gps, [(ra, dec)])
 
             etoha_test.extend(result)
 
         # Check if all inputs are correct
         np.testing.assert_almost_equal(altaz, etoha_test, 4)
 
     def test_pyephem_eqtozenaz(self):
         """
         celestial.equatorial_to_zenithazimuth_astropy
         """
 
         # This is the transform inputs
-        eq = [(-39.34633914878846, -112.2277168069694, 1295503840,
-               3.8662384455822716, -0.31222454326513827),
-              (53.13143508448587, -49.24074935964933, 985619982,
-               3.901575896592809, -0.3926720112815971),
-              (48.02031016860923, -157.4023812557098, 1126251396,
-               3.366278312183976, -1.3610394240813288)]
+        eq = [
+            (-39.34633914878846, -112.2277168069694, 1295503840, 3.8662384455822716, -0.31222454326513827),
+            (53.13143508448587, -49.24074935964933, 985619982, 3.901575896592809, -0.3926720112815971),
+            (48.02031016860923, -157.4023812557098, 1126251396, 3.366278312183976, -1.3610394240813288),
+        ]
         # result converted for eq->zenaz
-        zenaz = [(1.7661757628109793, -0.6043111523005624),
-                 (2.4016701141980032, 2.6012484033836625),
-                 (2.4651261727002005, -1.8828257759425302)]
+        zenaz = [
+            (1.7661757628109793, -0.6043111523005624),
+            (2.4016701141980032, 2.6012484033836625),
+            (2.4651261727002005, -1.8828257759425302),
+        ]
 
         eqtozenaz_test = []
 
         # Produce equatorial_to_zenithazimuth_astropy results
         for latitude, longitude, gps, ra, dec in eq:
-            result = celestial.equatorial_to_zenithazimuth_astropy(
-                latitude, longitude, gps, [(ra, dec)])
+            result = celestial.equatorial_to_zenithazimuth_astropy(latitude, longitude, gps, [(ra, dec)])
             eqtozenaz_test.extend(result)
 
         # Check if all inputs are correct, cast to numpy array for certainty
         # Test equatorial_to_zenithazimuth_astropy
         np.testing.assert_almost_equal(zenaz, eqtozenaz_test, 4)
 
     def test_pyephem_zenaztoeq(self):
         """Check celestial.zenithazimuth_to_equatorial_astropy"""
 
         # equatorial inputs from test_pyephem_eqtozenaz transformed into
         # the shape of zenithazimuth coordinates so that they may be used for
         # reverse benchmarking purposes.
-        zeneq = [(-39.34633914878846, -112.2277168069694,
-                  1295503840, 1.8830208700600348, -2.295442118787375),
-                 (53.13143508448587, -49.24074935964933, 985619982,
-                  1.9634683380764937, -2.3307795697979126),
-                 (48.02031016860923, -157.4023812557098, 1126251396,
-                  2.9318357508762256, -1.7954819853890793)]
+        zeneq = [
+            (-39.34633914878846, -112.2277168069694, 1295503840, 1.8830208700600348, -2.295442118787375),
+            (53.13143508448587, -49.24074935964933, 985619982, 1.9634683380764937, -2.3307795697979126),
+            (48.02031016860923, -157.4023812557098, 1126251396, 2.9318357508762256, -1.7954819853890793),
+        ]
 
         # result of pyephem hor->eq/zenaz-> eq
-        efemeq = [(5.620508199785029, -0.3651173667585858),
-                  (5.244630787139936, -0.7866376569183651),
-                  (2.276751381056623, -1.0406498066785745)]
+        efemeq = [
+            (5.620508199785029, -0.3651173667585858),
+            (5.244630787139936, -0.7866376569183651),
+            (2.276751381056623, -1.0406498066785745),
+        ]
 
         zenaztoeq_test = []
 
         # Produce zenithazimuth_to_equatorial_astropy results
         for latitude, longitude, gps, zen, az in zeneq:
-            result = celestial.zenithazimuth_to_equatorial_astropy(
-                latitude, longitude, gps, [(zen, az)])
+            result = celestial.zenithazimuth_to_equatorial_astropy(latitude, longitude, gps, [(zen, az)])
             zenaztoeq_test.extend(result)
 
         # Check if all inputs are correct, cast to numpy array for certainty
         # Test zenithazimuth_to_equatorial_astropy
         np.testing.assert_almost_equal(efemeq, zenaztoeq_test, 4)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_clock.py` & `hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_clock.py`

 * *Files 7% similar despite different names*

```diff
@@ -2,15 +2,14 @@
 import random
 import unittest
 
 from sapphire.transformations import clock
 
 
 class DecimalTimeTests(unittest.TestCase):
-
     def test_time_to_decimal(self):
         """Check time to decimal hours conversion
 
         May be off by some microseconds due to precision
 
         """
         decimal = 11.51003771
@@ -19,144 +18,143 @@
         self.assertEqual(clock.time_to_decimal(time_obj), decimal)
         self.assertEqual(clock.decimal_to_time(decimal), time_obj)
         self.assertEqual(clock.time_to_decimal(clock.decimal_to_time(decimal)), decimal)
         self.assertEqual(clock.decimal_to_time(clock.time_to_decimal(time_obj)), time_obj)
 
 
 class DateTests(unittest.TestCase):
-
     def test_date_to_juliandate(self):
         self.assertEqual(clock.date_to_juliandate(2010, 12, 25), 2455555.5)
 
     def test_datetime_to_juliandate(self):
-        self.assertEqual(clock.datetime_to_juliandate(datetime.datetime(2010, 12, 25, 12)),
-                         2455556.0)
+        self.assertEqual(clock.datetime_to_juliandate(datetime.datetime(2010, 12, 25, 12)), 2455556.0)
 
 
 class ModifiedJulianDateTests(unittest.TestCase):
-
     def test_datetime_to_modifiedjd(self):
         mjd = clock.datetime_to_modifiedjd(datetime.datetime(2010, 12, 25, 12))
         self.assertEqual(mjd, 55555.5)
 
     def test_juliandate_to_modifiedjd(self):
         """Difference between Julian Date and Modified JD is 2400000.5"""
 
-        self.assertEqual(clock.juliandate_to_modifiedjd(2400000.5), 0.)
-        self.assertEqual(clock.modifiedjd_to_juliandate(0.), 2400000.5)
+        self.assertEqual(clock.juliandate_to_modifiedjd(2400000.5), 0.0)
+        self.assertEqual(clock.modifiedjd_to_juliandate(0.0), 2400000.5)
 
         for _ in range(5):
-            modifiedjd = random.uniform(0, 5000000)
+            modifiedjd = random.uniform(0, 5_000_000)
             self.assertAlmostEqual(
-                clock.juliandate_to_modifiedjd(
-                    clock.modifiedjd_to_juliandate(modifiedjd)),
-                modifiedjd)
-            juliandate = random.uniform(0, 5000000)
+                clock.juliandate_to_modifiedjd(clock.modifiedjd_to_juliandate(modifiedjd)),
+                modifiedjd,
+            )
+            juliandate = random.uniform(0, 5_000_000)
             self.assertAlmostEqual(
-                clock.modifiedjd_to_juliandate(
-                    clock.juliandate_to_modifiedjd(juliandate)),
-                juliandate)
+                clock.modifiedjd_to_juliandate(clock.juliandate_to_modifiedjd(juliandate)),
+                juliandate,
+            )
 
 
 class JulianDateToDateTimeTests(unittest.TestCase):
-
     def test_juliandate_to_utc(self):
-        self.assertEqual(clock.juliandate_to_utc(2400000.5),
-                         datetime.datetime(1858, 11, 17))
-        self.assertEqual(clock.juliandate_to_utc(2455581.40429),
-                         datetime.datetime(2011, 1, 19, 21, 42, 10, 655997))
+        self.assertEqual(clock.juliandate_to_utc(2400000.5), datetime.datetime(1858, 11, 17))
+        self.assertEqual(clock.juliandate_to_utc(2455581.40429), datetime.datetime(2011, 1, 19, 21, 42, 10, 655997))
 
     def test_juliandate_to_utc_gap(self):
-        self.assertEqual(clock.juliandate_to_utc(2299159.5),
-                         datetime.datetime(1582, 10, 4))
-        self.assertEqual(clock.juliandate_to_utc(2299160.5),
-                         datetime.datetime(1582, 10, 15))
+        self.assertEqual(clock.juliandate_to_utc(2299159.5), datetime.datetime(1582, 10, 4))
+        self.assertEqual(clock.juliandate_to_utc(2299160.5), datetime.datetime(1582, 10, 15))
 
     def test_modifiedjd_to_utc(self):
-        self.assertEqual(clock.modifiedjd_to_utc(55580.90429),
-                         datetime.datetime(2011, 1, 19, 21, 42, 10, 655997))
+        self.assertEqual(clock.modifiedjd_to_utc(55580.90429), datetime.datetime(2011, 1, 19, 21, 42, 10, 655997))
 
 
 class GMSTTests(unittest.TestCase):
-
     def test_utc_to_gmst(self):
         # Perhaps not perfect test, a few seconds of uncertainty exist..
-        self.assertAlmostEqual(clock.utc_to_gmst(datetime.datetime(2010, 12, 25)),
-                               clock.time_to_decimal(datetime.time(6, 13, 35, 852535)))
+        self.assertAlmostEqual(
+            clock.utc_to_gmst(datetime.datetime(2010, 12, 25)),
+            clock.time_to_decimal(datetime.time(6, 13, 35, 852535)),
+        )
 
 
 class LSTTests(unittest.TestCase):
-
     def test_gmst_to_lst(self):
         for _ in range(5):
             hours = random.uniform(0, 23.934)
             longitude = random.uniform(-180, 180)
-            self.assertAlmostEqual(clock.lst_to_gmst(clock.gmst_to_lst(hours, longitude),
-                                                     longitude), hours)
+            self.assertAlmostEqual(clock.lst_to_gmst(clock.gmst_to_lst(hours, longitude), longitude), hours)
 
     def test_utc_to_lst_gmst(self):
-        self.assertEqual(clock.utc_to_lst(datetime.datetime(2010, 12, 25), 0),
-                         clock.utc_to_gmst(datetime.datetime(2010, 12, 25)))
+        self.assertEqual(
+            clock.utc_to_lst(datetime.datetime(2010, 12, 25), 0),
+            clock.utc_to_gmst(datetime.datetime(2010, 12, 25)),
+        )
         # Perhaps not perfect test, a few seconds of uncertainty exist..
-        self.assertAlmostEqual(clock.utc_to_lst(datetime.datetime(2010, 12, 25), 0),
-                               clock.time_to_decimal(datetime.time(6, 13, 35, 852535)))
+        self.assertAlmostEqual(
+            clock.utc_to_lst(datetime.datetime(2010, 12, 25), 0),
+            clock.time_to_decimal(datetime.time(6, 13, 35, 852535)),
+        )
 
     def test_utc_to_lst_at_longitudes(self):
-        self.assertAlmostEqual(clock.utc_to_lst(datetime.datetime(2010, 12, 25), 90),
-                               clock.time_to_decimal(datetime.time(12, 13, 35, 852535)))
-        self.assertAlmostEqual(clock.utc_to_lst(datetime.datetime(2010, 12, 25), 180),
-                               clock.time_to_decimal(datetime.time(18, 13, 35, 852535)))
-        self.assertAlmostEqual(clock.utc_to_lst(datetime.datetime(2010, 12, 25), 5),
-                               clock.time_to_decimal(datetime.time(6, 33, 35, 852535)))
+        self.assertAlmostEqual(
+            clock.utc_to_lst(datetime.datetime(2010, 12, 25), 90),
+            clock.time_to_decimal(datetime.time(12, 13, 35, 852535)),
+        )
+        self.assertAlmostEqual(
+            clock.utc_to_lst(datetime.datetime(2010, 12, 25), 180),
+            clock.time_to_decimal(datetime.time(18, 13, 35, 852535)),
+        )
+        self.assertAlmostEqual(
+            clock.utc_to_lst(datetime.datetime(2010, 12, 25), 5),
+            clock.time_to_decimal(datetime.time(6, 33, 35, 852535)),
+        )
 
 
 class GPSTimeTests(unittest.TestCase):
-
     def setUp(self):
         """Setup combinations of calendar dates, timestamps and leap seconds
 
         The UTC timestamps follow from:
 
             import time
             import calendar
             t = calendar.timegm(time.strptime(date, '%B %d, %Y'))
 
         """
-        self.combinations = (('July 1, 2015', 1435708800, 17),
-                             ('January 1, 2014', 1388534400, 16),
-                             ('July 1, 2012', 1341100800, 16),
-                             ('June 30, 2012', 1341014400, 15),
-                             ('January 1, 2009', 1230768000, 15),
-                             ('December 31, 2008', 1230681600, 14),
-                             ('January 1, 2006', 1136073600, 14),
-                             ('December 31, 2005', 1135987200, 13),
-                             ('January 1, 2004', 1072915200, 13),
-                             ('January 1, 1999', 915148800, 13),
-                             ('July 1, 1997', 867715200, 12),
-                             ('January 1, 1996', 820454400, 11),
-                             ('July 1, 1994', 773020800, 10),
-                             ('July 1, 1993', 741484800, 9),
-                             ('July 1, 1992', 709948800, 8),
-                             ('January 1, 1991', 662688000, 7),
-                             ('January 1, 1990', 631152000, 6),
-                             ('January 1, 1988', 567993600, 5),
-                             ('July 1, 1985', 489024000, 4),
-                             ('July 1, 1983', 425865600, 3),
-                             ('July 1, 1982', 394329600, 2),
-                             ('July 1, 1981', 362793600, 1))
+        self.combinations = (
+            ('July 1, 2015', 1435708800, 17),
+            ('January 1, 2014', 1388534400, 16),
+            ('July 1, 2012', 1341100800, 16),
+            ('June 30, 2012', 1341014400, 15),
+            ('January 1, 2009', 1230768000, 15),
+            ('December 31, 2008', 1230681600, 14),
+            ('January 1, 2006', 1136073600, 14),
+            ('December 31, 2005', 1135987200, 13),
+            ('January 1, 2004', 1072915200, 13),
+            ('January 1, 1999', 915148800, 13),
+            ('July 1, 1997', 867715200, 12),
+            ('January 1, 1996', 820454400, 11),
+            ('July 1, 1994', 773020800, 10),
+            ('July 1, 1993', 741484800, 9),
+            ('July 1, 1992', 709948800, 8),
+            ('January 1, 1991', 662688000, 7),
+            ('January 1, 1990', 631152000, 6),
+            ('January 1, 1988', 567993600, 5),
+            ('July 1, 1985', 489024000, 4),
+            ('July 1, 1983', 425865600, 3),
+            ('July 1, 1982', 394329600, 2),
+            ('July 1, 1981', 362793600, 1),
+        )
 
     def test_gps_to_utc(self):
         for date, _, _ in self.combinations:
-            self.assertEqual(clock.gps_to_utc(clock.gps_from_string(date)),
-                             clock.utc_from_string(date))
+            self.assertEqual(clock.gps_to_utc(clock.gps_from_string(date)), clock.utc_from_string(date))
 
     def test_utc_to_gps(self):
         for date, _, _ in self.combinations:
-            self.assertEqual(clock.utc_to_gps(clock.utc_from_string(date)),
-                             clock.gps_from_string(date))
+            self.assertEqual(clock.utc_to_gps(clock.utc_from_string(date)), clock.gps_from_string(date))
 
     def test_utc_from_string(self):
         for date, timestamp, _ in self.combinations:
             self.assertEqual(clock.utc_from_string(date), timestamp)
 
     def test_gps_from_string(self):
         for date, timestamp, leapseconds in self.combinations:
@@ -176,11 +174,7 @@
         for date, timestamp, _ in self.combinations:
             dt = datetime.datetime.strptime(date, '%B %d, %Y')
             self.assertEqual(clock.process_time(dt), timestamp)
             self.assertEqual(clock.process_time(timestamp), timestamp)
         self.assertEqual(clock.process_time('1435708800'), 1435708800)
         with self.assertRaises(RuntimeError):
             clock.process_time('July 1, 1995')
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/transformations/test_geographic.py` & `hisparc_sapphire-3.0.0/sapphire/tests/transformations/test_geographic.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 import unittest
 
 from sapphire.transformations import geographic
 
 
 class GeographicTransformationTests(unittest.TestCase):
-
     def setUp(self):
-        self.ref_enu = (0., 0., 0.)
+        self.ref_enu = (0.0, 0.0, 0.0)
         self.ref_lla = (52.35592417, 4.95114402, 56.10234594)
         self.transform = geographic.FromWGS84ToENUTransformation(self.ref_lla)
 
     def test_attributes(self):
         self.assertEqual(self.ref_lla, self.transform.ref_lla)
 
         ref_ecef = (3889144.77, 336914.68, 5027133.30)
@@ -34,14 +33,10 @@
     def test_enu_to_ecef_at_reference(self):
         self.assert_tuple_almost_equal(self.transform.ref_ecef, self.transform.enu_to_ecef(self.ref_enu))
 
     def assert_tuple_almost_equal(self, actual, expected, places=7):
         self.assertIsInstance(actual, tuple)
         self.assertIsInstance(expected, tuple)
 
-        msg = f"Tuples differ: {actual} != {expected}"
+        msg = f'Tuples differ: {actual} != {expected}'
         for actual_value, expected_value in zip(actual, expected):
             self.assertAlmostEqual(actual_value, expected_value, places=places, msg=msg)
-
-
-if __name__ == '__main__':
-    unittest.main()
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/tests/validate_results.py` & `hisparc_sapphire-3.0.0/sapphire/tests/validate_results.py`

 * *Files 5% similar despite different names*

```diff
@@ -10,16 +10,15 @@
     """Validate results by comparing in and output HDF5 files
 
     :param test: instance of the TestCase.
     :param expected_path: path to the reference data.
     :param actual_path: path to the output from the test.
 
     """
-    with tables.open_file(expected_path, 'r') as expected_file, \
-            tables.open_file(actual_path, 'r') as actual_file:
+    with tables.open_file(expected_path, 'r') as expected_file, tables.open_file(actual_path, 'r') as actual_file:
         for expected_node in expected_file.walk_nodes('/', 'Leaf'):
             try:
                 actual_node = actual_file.get_node(expected_node._v_pathname)
             except tables.NoSuchNodeError:
                 test.fail(f"Node '{expected_node._v_pathname}' does not exist in datafile")
 
             if type(expected_node) is tables.table.Table:
@@ -30,27 +29,25 @@
                 validate_arrays(test, expected_node, actual_node)
             else:
                 raise NotImplementedError
             validate_attributes(test, expected_node, actual_node)
         validate_attributes(test, expected_file.root, actual_file.root)
 
 
-def validate_results_node(test, expected_path, actual_path, expected_node,
-                          actual_node):
+def validate_results_node(test, expected_path, actual_path, expected_node, actual_node):
     """Validate results by comparing two specific nodes
 
     :param test: instance of the TestCase.
     :param expected_path: path to the reference data.
     :param actual_path: path to the output from the test.
     :param expected_node: path to the reference node.
     :param actual_node: path to the output node from the test.
 
     """
-    with tables.open_file(expected_path, 'r') as expected_file, \
-            tables.open_file(actual_path, 'r') as actual_file:
+    with tables.open_file(expected_path, 'r') as expected_file, tables.open_file(actual_path, 'r') as actual_file:
         expected = expected_file.get_node(expected_node)
         try:
             actual = actual_file.get_node(actual_node)
         except tables.NoSuchNodeError:
             test.fail(f"Node '{actual_node}' does not exist in datafile")
 
         if type(expected) is tables.table.Table:
@@ -62,45 +59,57 @@
         else:
             raise NotImplementedError
 
 
 def validate_tables(test, expected_node, actual_node):
     """Verify that two Tables are identical"""
 
-    test.assertEqual(expected_node.nrows, actual_node.nrows,
-                     f"Tables '{expected_node._v_pathname}' do not have the same length.")
+    test.assertEqual(
+        expected_node.nrows,
+        actual_node.nrows,
+        f"Tables '{expected_node._v_pathname}' do not have the same length.",
+    )
     for colname in expected_node.colnames:
-        test.assertIn(colname, actual_node.colnames,
-                      f"Tables '{expected_node._v_pathname}' do not have the same columns.")
+        test.assertIn(
+            colname,
+            actual_node.colnames,
+            f"Tables '{expected_node._v_pathname}' do not have the same columns.",
+        )
         expected_col = expected_node.col(colname)
         actual_col = actual_node.col(colname)
         assert_array_almost_equal(
             expected_col,
             actual_col,
-            err_msg=f"Tables '{expected_node._v_pathname}' column '{colname}' do not match."
+            err_msg=f"Tables '{expected_node._v_pathname}' column '{colname}' do not match.",
         )
 
 
 def validate_vlarrays(test, expected_node, actual_node):
     """Verify that two VLArrays are identical"""
 
-    test.assertEqual(expected_node.shape, actual_node.shape,
-                     f"VLArrays '{expected_node._v_pathname}' do not have the same shape.")
+    test.assertEqual(
+        expected_node.shape,
+        actual_node.shape,
+        f"VLArrays '{expected_node._v_pathname}' do not have the same shape.",
+    )
     for expected_array, actual_array in zip(expected_node, actual_node):
-        test.assertTrue(all(expected_array == actual_array),
-                        f"VLArrays '{expected_node._v_pathname}' do not match.")
+        test.assertTrue(all(expected_array == actual_array), f"VLArrays '{expected_node._v_pathname}' do not match.")
 
 
 def validate_arrays(test, expected_node, actual_node):
     """Verify that two Arrays are identical"""
 
-    test.assertEqual(expected_node.shape, actual_node.shape,
-                     f"Arrays '{expected_node._v_pathname}' do not have the same shape.")
-    test.assertTrue(all(array(expected_node.read()) == array(actual_node.read())),
-                    f"Arrays '{expected_node._v_pathname}' do not match.")
+    test.assertEqual(
+        expected_node.shape,
+        actual_node.shape,
+        f"Arrays '{expected_node._v_pathname}' do not have the same shape.",
+    )
+    test.assertTrue(
+        all(array(expected_node.read()) == array(actual_node.read())),
+        f"Arrays '{expected_node._v_pathname}' do not match.",
+    )
 
 
 def validate_attributes(test, expected_node, actual_node):
     """Verify that two nodes have the same user attributes"""
 
-    test.assertEqual(expected_node._v_attrs._v_attrnamesuser,
-                     actual_node._v_attrs._v_attrnamesuser)
+    test.assertEqual(expected_node._v_attrs._v_attrnamesuser, actual_node._v_attrs._v_attrnamesuser)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/time_util.py` & `hisparc_sapphire-3.0.0/sapphire/time_util.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 
 The class in this module is intended to save you from typing trainwrecks
 just to convert GPS timestamps to GPS date/time and vice versa.
 Trainwrecks invite typos and thus many are easily confused about
 UTC/GPS/local time.  No more!
 
 """
+
 import calendar
 import datetime
 import time
 
 
 class GPSTime:
     """Date/time utility class."""
@@ -34,15 +35,15 @@
         if len(args) == 1:
             self._gpstimestamp = args[0]
         elif len(args) >= 3:
             datetime_ = datetime.datetime(*args)
             timetuple = datetime_.utctimetuple()
             self._gpstimestamp = calendar.timegm(timetuple)
         else:
-            raise TypeError("Incorrect arguments")
+            raise TypeError('Incorrect arguments')
 
     def gpstimestamp(self):
         """Return the GPS date/time as a timestamp.
 
         Example::
 
             >>> gpstime = GPSTime(2012, 12, 1)
@@ -79,8 +80,8 @@
 
     def __str__(self):
         """Return sensible description of object."""
 
         return self.description()
 
     def __repr__(self):
-        return "%s(%d)" % (self.__class__.__name__, self._gpstimestamp)
+        return '%s(%d)' % (self.__class__.__name__, self._gpstimestamp)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/transformations/__init__.py` & `hisparc_sapphire-3.0.0/sapphire/transformations/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -19,15 +19,11 @@
     conversion between different time keeping systems
 
 :mod:`~sapphire.transformations.geographic`
     geographic coordinate transformations (e.g. WGS84 to ENU)
 
 
 """
+
 from . import angles, axes, base, celestial, clock, geographic
 
-__all__ = ['angles',
-           'axes',
-           'base',
-           'celestial',
-           'clock',
-           'geographic']
+__all__ = ['angles', 'axes', 'base', 'celestial', 'clock', 'geographic']
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/transformations/angles.py` & `hisparc_sapphire-3.0.0/sapphire/transformations/angles.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,24 +1,25 @@
-""" Perform various angle related transformations
+"""Perform various angle related transformations
 
-    Transform between different notations for angles:
-    Degrees, radians and hours.
+Transform between different notations for angles:
+Degrees, radians and hours.
 
 """
+
 from numpy import degrees, radians
 
 
 def hours_to_degrees(angle):
     """Converts decimal hours to degrees
 
     :param hours: angle in decimal hours
     :return: angle in degrees
 
     """
-    return angle * 15.
+    return angle * 15.0
 
 
 def hours_to_radians(angle):
     """Converts decimal hours to radians
 
     :param hours: angle in decimal hours
     :return: angle in radians
@@ -30,15 +31,15 @@
 def degrees_to_hours(angle):
     """Converts degrees to decimal hours
 
     :param angle: angle in degrees
     :return: angle in decimal hours
 
     """
-    return angle / 15.
+    return angle / 15.0
 
 
 def radians_to_hours(angle):
     """Converts degrees to decimal hours
 
     :param angle: angle in degrees
     :return: angle in decimal hours
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/transformations/axes.py` & `hisparc_sapphire-3.0.0/sapphire/transformations/axes.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-""" Perform various axes related transformations
+"""Perform various axes related transformations
 
 - Transformation between Cartesian, polar, cylindrical, spherical and compass
   coordinate systems.
 - Create a rotation matrix for rotations around a certain axis.
 
 Cartesian coordinates: x, y, z axes.
 
@@ -18,14 +18,15 @@
 
 Compass coordinates:
 - r: length of vector in x,y-plane.
 - alpha: angle of vector to the y-axis in x,y-plane, rotating clockwise.
 - z: height above x,y-plane.
 
 """
+
 from numpy import arccos, arctan2, array, cos, degrees, radians, sin, sqrt
 
 
 def cartesian_to_spherical(x, y, z):
     """Converts Cartesian coordinates into spherical coordinates
 
     :param x,y,z: Cartesian coordinates.
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/transformations/base.py` & `hisparc_sapphire-3.0.0/sapphire/transformations/base.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,28 @@
 """Perform base conversions
 
 Currently supports conversion between base 10 (decimal) and
 base 60 (sexagesimal).
 
 """
+
 from numpy import modf
 
 
 def decimal_to_sexagesimal(decimal):
     """Convert decimal hours or degrees to sexagesimal.
 
     :param decimal: decimal number to be converted to sexagismal.
     :return: tuple of either (hours, minutes, seconds) or
              (degrees, arcminutes, arcseconds).
 
     """
     fractional, integral = modf(decimal)
     min_fractional, minutes = modf(fractional * 60)
-    seconds = min_fractional * 60.
+    seconds = min_fractional * 60.0
     return integral.astype(int), minutes.astype(int), seconds
 
 
 def sexagesimal_to_decimal(hd, minutes, seconds):
     """Convert sexagesimal hours or degrees to decimal.
 
     Warning! Ensure each part has the correct sign.
@@ -29,8 +30,8 @@
 
     :param hd: hours or degrees.
     :param minutes: minutes or arcminutes.
     :param seconds: seconds or arcseconds.
     :return: decimal hours or degrees.
 
     """
-    return hd + minutes / 60. + seconds / 3600.
+    return hd + minutes / 60.0 + seconds / 3600.0
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/transformations/celestial.py` & `hisparc_sapphire-3.0.0/sapphire/transformations/celestial.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,35 +1,35 @@
-""" Perform various Celestial coordinate transformations
+"""Perform various Celestial coordinate transformations
 
-    This module performs transformations between different
-    Celestial coordinate systems.
+This module performs transformations between different
+Celestial coordinate systems.
 
-    Legacy transformations (all those not marked astropy):
-    Formulae from: Duffett-Smith1990
-    'Astronomy with your personal computer'
-    ISBN 0-521-38995-X
-
-    New transformations have been added with _astropy added to function name
-    They are very exact, in the order of arcsec.
-    Ethan van Woerkom is the author of the new transformations; contact him
-    for further information.
+Legacy transformations (all those not marked astropy):
+Formulae from: Duffett-Smith1990
+'Astronomy with your personal computer'
+ISBN 0-521-38995-X
+
+New transformations have been added with _astropy added to function name
+They are very exact, in the order of arcsec.
+Ethan van Woerkom is the author of the new transformations; contact him
+for further information.
 """
+
 import datetime
 import warnings
 
 import numpy as np
 
 from numpy import arccos, arcsin, around, cos, pi, radians, sin
 
 from ..utils import norm_angle
 from . import angles, clock
 
 
-def zenithazimuth_to_equatorial(latitude, longitude, timestamp, zenith,
-                                azimuth):
+def zenithazimuth_to_equatorial(latitude, longitude, timestamp, zenith, azimuth):
     """Convert Zenith Azimuth to Equatorial coordinates (J2000.0)
 
     :param latitude,longitude: Position of the observer on Earth in degrees.
                                North and east positive.
     :param timestamp: GPS timestamp of the observation in seconds.
     :param zenith: zenith is the angle relative to the Zenith in radians.
     :param azimuth: azimuth angle of the observation in radians.
@@ -58,16 +58,16 @@
     in the horizontal plane, from East to North (ENWS).
 
     Horizontal is the coordinate system as described in
     Duffett-Smith1990 p38. Altitude is the angle above the horizon and
     Azimuth the angle in the horizontal plane, from North to East (NESW).
 
     """
-    altitude = norm_angle(pi / 2. - zenith)
-    alt_azimuth = norm_angle(pi / 2. - azimuth)
+    altitude = norm_angle(pi / 2.0 - zenith)
+    alt_azimuth = norm_angle(pi / 2.0 - azimuth)
 
     return altitude, alt_azimuth
 
 
 def horizontal_to_zenithazimuth(altitude, alt_azimuth):
     """Inverse of zenithazimuth_to_horizontal is the same transformation"""
 
@@ -138,22 +138,21 @@
     :param ha: Hour angle in radians.
     :param lst: Local Siderial Time observer at the time of observation
                 in decimal hours.
 
     :return: Right ascension (ra) in radians.
 
     """
-    ra = (angles.hours_to_radians(lst) - ha)
+    ra = angles.hours_to_radians(lst) - ha
     ra %= 2 * pi
 
     return ra
 
 
-def equatorial_to_zenithazimuth(latitude, longitude, timestamp,
-                                right_ascension, declination):
+def equatorial_to_zenithazimuth(latitude, longitude, timestamp, right_ascension, declination):
     """Convert Equatorial (J2000.0) to Zenith Azimuth coordinates
 
     :param latitude,longitude: Position of the observer on Earth in degrees.
                                North and east positive.
     :param timestamp: GPS timestamp of the observation in seconds.
     :param right_ascension: right_ascension of the observation in radians.
     :param declination: declination of the observation in radians.
@@ -163,27 +162,26 @@
     This function was renamed from equatorial_to_horizontal to
     equatorial_to_zenithazimuth in order to make it operate as the name does.
 
     From Duffett-Smith1990, 1500 EQHOR and 1600 HRANG
 
     """
     lst = clock.gps_to_lst(timestamp, longitude)
-    ha = (angles.hours_to_radians(lst) - right_ascension)
+    ha = angles.hours_to_radians(lst) - right_ascension
     ha %= 2 * pi
 
     slat = sin(radians(latitude))
     clat = cos(radians(latitude))
     sha = sin(ha)
     cha = cos(ha)
     sdec = sin(declination)
     cdec = cos(declination)
 
     altitude = arcsin((sdec * slat) + (cdec * clat * cha))
-    alt_azimuth = arccos((sdec - (slat * sin(altitude))) /
-                         (clat * cos(altitude)))
+    alt_azimuth = arccos((sdec - (slat * sin(altitude))) / (clat * cos(altitude)))
 
     if sha > 0:
         alt_azimuth = 2 * pi - alt_azimuth
 
     zenith, azimuth = horizontal_to_zenithazimuth(altitude, alt_azimuth)
 
     return zenith, azimuth
@@ -193,17 +191,16 @@
     # This try-except structure has been implemented,
     # to accommodate those without astropy.
     import astropy.units as u
 
     from astropy.coordinates import EarthLocation, SkyCoord
     from astropy.time import Time
 
-    def zenithazimuth_to_equatorial_astropy(latitude, longitude, utc_timestamp,
-                                            zenaz_coordinates):
-        """ Converts iterables of tuples of zenithazimuth
+    def zenithazimuth_to_equatorial_astropy(latitude, longitude, utc_timestamp, zenaz_coordinates):
+        """Converts iterables of tuples of zenithazimuth
             to equatorial coordinates
 
         :param latitude: Latitude in decimal degrees
         :param longitude: Longitude in decimal degrees
         :param utc_timestamp: Unix UTC timestamp integer
         :param zenaz_coordinates: np.array of tuples (zen, az) in radians
         :return: np.array of tuples (ra, dec) in radians
@@ -215,51 +212,49 @@
         zenaz_coordinates = np.array(zenaz_coordinates)
         zenaz_coordinates = 0.5 * np.pi - zenaz_coordinates
         horizontal_coordinates = np.unwrap(zenaz_coordinates[:, [1, 0]])
 
         # Normalise angle
         horizontal_coordinates = norm_angle(horizontal_coordinates)
 
-        return horizontal_to_equatorial_astropy(latitude, longitude,
-                                                utc_timestamp,
-                                                horizontal_coordinates)
-
-    def equatorial_to_zenithazimuth_astropy(latitude, longitude,
-                                            utc_timestamp,
-                                            equatorial_coordinates):
-        """ Converts iterables of tuples of equatorial
+        return horizontal_to_equatorial_astropy(latitude, longitude, utc_timestamp, horizontal_coordinates)
+
+    def equatorial_to_zenithazimuth_astropy(latitude, longitude, utc_timestamp, equatorial_coordinates):
+        """Converts iterables of tuples of equatorial
             to zenithazimuth coordinates
 
         :param latitude: Latitude in decimal degrees
         :param longitude: Longitude in decimal degrees
         :param utc_timestamp: Unix UTC timestamp integer
         :param equatorial_coordinates: np.array of tuples (ra, dec) in radians
         :return: np.array of tuples (zen, az) in radians
 
         For increased speed using array input is recommended.
         """
 
         equatorial_coordinates = np.array(equatorial_coordinates)
         horizontal_coordinates = equatorial_to_horizontal_astropy(
-            latitude, longitude, utc_timestamp, equatorial_coordinates)
+            latitude,
+            longitude,
+            utc_timestamp,
+            equatorial_coordinates,
+        )
 
         # Convert and flip order of zenaz coordinates, done in numpy for speed
         horizontal_coordinates = np.array(horizontal_coordinates)
         horizontal_coordinates = 0.5 * np.pi - horizontal_coordinates
         zenaz_coordinates = horizontal_coordinates[:, [1, 0]]
 
         # Normalise angle
         zenaz_coordinates = norm_angle(zenaz_coordinates)
 
         return zenaz_coordinates
 
-    def equatorial_to_horizontal_astropy(latitude, longitude,
-                                         utc_timestamp,
-                                         equatorial_coordinates):
-        """ Converts iterables of tuples of equatorial coordinates
+    def equatorial_to_horizontal_astropy(latitude, longitude, utc_timestamp, equatorial_coordinates):
+        """Converts iterables of tuples of equatorial coordinates
             to horizontal coordinates
 
         :param latitude: Latitude in decimal degrees
         :param longitude: Longitude in decimal degrees
         :param utc_timestamp: Unix UTC timestamp integer
         :param equatorial_coordinates: np.array of tuples (ra, dec) in radians
         :return: np.array of tuples (az, alt) in radians
@@ -267,39 +262,35 @@
         For increased speed using array input is recommended.
         """
         # For speed in numpy
         equatorial_coordinates = np.array(equatorial_coordinates)
 
         location = EarthLocation(longitude, latitude)
         t = Time(datetime.datetime.utcfromtimestamp(utc_timestamp))
-        equatorial_frame = SkyCoord(equatorial_coordinates, location=location,
-                                    obstime=t, unit=u.rad, frame='icrs')
+        equatorial_frame = SkyCoord(equatorial_coordinates, location=location, obstime=t, unit=u.rad, frame='icrs')
         horizontal_frame = equatorial_frame.transform_to('altaz')
 
         return np.array((horizontal_frame.az.rad, horizontal_frame.alt.rad)).T
 
-    def horizontal_to_equatorial_astropy(latitude, longitude,
-                                         utc_timestamp,
-                                         horizontal_coordinates):
-        """ Converts iterables of tuples of
+    def horizontal_to_equatorial_astropy(latitude, longitude, utc_timestamp, horizontal_coordinates):
+        """Converts iterables of tuples of
             horizontal coordinates to equatorial coordinates
 
         :param latitude: Latitude in decimal degrees
         :param longitude: Longitude in decimal degrees
         :param utc_timestamp: Unix UTC timestamp integer
         :param horizontal_coordinates: np.array of tuples (az, alt) in radians
         :return: np.array of tuples (ra, dec) in radians
         """
         # For speed in numpy
         horizontal_coordinates = np.array(horizontal_coordinates)
 
         location = EarthLocation(longitude, latitude)
         t = Time(datetime.datetime.utcfromtimestamp(utc_timestamp))
-        horizontal_frame = SkyCoord(horizontal_coordinates, location=location,
-                                    obstime=t, unit=u.rad, frame='altaz')
+        horizontal_frame = SkyCoord(horizontal_coordinates, location=location, obstime=t, unit=u.rad, frame='altaz')
         equatorial_frame = horizontal_frame.transform_to('icrs')
 
         return np.array((equatorial_frame.ra.rad, equatorial_frame.dec.rad)).T
 
 
 except ImportError as e:
-    warnings.warn(str(e) + "\nImport of astropy failed", ImportWarning)
+    warnings.warn(str(e) + '\nImport of astropy failed', ImportWarning)
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/transformations/clock.py` & `hisparc_sapphire-3.0.0/sapphire/transformations/clock.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-""" Time transformations
+"""Time transformations
 
 This handles all the wibbly wobbly timey wimey stuff.
 Such as easy conversions between different time systems.
 Supported systems: GPS, UTC, GMST, LST, JD and MJD.
 
 Formulae from:
 
@@ -19,52 +19,62 @@
 http://aa.usno.navy.mil/faq/docs/GAST.php
 
 Adrian Price-Whelan
 apwlib.convert
 https://github.com/adrn/apwlib
 
 """
+
 import calendar
 import datetime
 import math
 
 from time import strptime
 
 from . import angles, base
 
 #: Dates of leap second introductions.
-LEAP_SECONDS = (('January 1, 2017', 18),
-                ('July 1, 2015', 17),
-                ('July 1, 2012', 16),
-                ('January 1, 2009', 15),
-                ('January 1, 2006', 14),
-                ('January 1, 1999', 13),
-                ('July 1, 1997', 12),
-                ('January 1, 1996', 11),
-                ('July 1, 1994', 10),
-                ('July 1, 1993', 9),
-                ('July 1, 1992', 8),
-                ('January 1, 1991', 7),
-                ('January 1, 1990', 6),
-                ('January 1, 1988', 5),
-                ('July 1, 1985', 4),
-                ('July 1, 1983', 3),
-                ('July 1, 1982', 2),
-                ('July 1, 1981', 1))
+LEAP_SECONDS = (
+    ('January 1, 2017', 18),
+    ('July 1, 2015', 17),
+    ('July 1, 2012', 16),
+    ('January 1, 2009', 15),
+    ('January 1, 2006', 14),
+    ('January 1, 1999', 13),
+    ('July 1, 1997', 12),
+    ('January 1, 1996', 11),
+    ('July 1, 1994', 10),
+    ('July 1, 1993', 9),
+    ('July 1, 1992', 8),
+    ('January 1, 1991', 7),
+    ('January 1, 1990', 6),
+    ('January 1, 1988', 5),
+    ('July 1, 1985', 4),
+    ('July 1, 1983', 3),
+    ('July 1, 1982', 2),
+    ('July 1, 1981', 1),
+)
 
 
 def time_to_decimal(time):
     """Converts a time or datetime object into decimal time
 
     :param time: datetime.time or datetime.datetime object.
     :return: decimal number representing the input time.
 
     """
-    return (time.hour + time.minute / 60. + time.second / 3600. +
-            time.microsecond / 3600000000.)
+    minutes_per_hour = 60
+    seconds_per_hour = 3600
+    microseconds_per_hour = 3600_000_000
+    return (
+        time.hour
+        + time.minute / minutes_per_hour
+        + time.second / seconds_per_hour
+        + time.microsecond / microseconds_per_hour
+    )
 
 
 def decimal_to_time(hours):
     """Converts decimal time to a time object
 
     :param hours: datetime.time or datetime.datetime object.
     :return: decimal number representing the input time.
@@ -95,15 +105,21 @@
 
     if year1 < 0:
         year1 += 1
     if month in [1, 2]:
         year1 -= 1
         month1 = month + 12
 
-    if year1 > 1582 or (year1 == 1582 and month >= 10 and day >= 15):
+    # Correction for leap years
+    gregorian_year = 1582
+    gregorian_month = 10
+    gregorian_day = 15
+    if year1 > gregorian_year or (
+        year1 == gregorian_year and (month > gregorian_month or (month == gregorian_month and day >= gregorian_day))
+    ):
         a = int(year1 / 100)
         b = 2 - a + int(a / 4)
     else:
         b = 0
 
     if year1 < 0:
         c = int((365.25 * year1) - 0.75)
@@ -119,15 +135,15 @@
     """Convert a datetime object in UTC to a Julian Date
 
     :param dt: datetime object.
     :return: The Julian Date for the given datetime object.
 
     """
     juliandate = date_to_juliandate(dt.year, dt.month, dt.day)
-    decimal_time = time_to_decimal(dt.time()) / 24.
+    decimal_time = time_to_decimal(dt.time()) / 24.0
     return juliandate + decimal_time
 
 
 def juliandate_to_modifiedjd(juliandate):
     """Convert a Julian Date to a Modified Julian Date
 
     :param juliandate: a Julian Date.
@@ -162,24 +178,23 @@
     """Convert a Julian Date to Greenwich Mean Sidereal Time
 
     :param juliandate: Julian Date.
     :return: decimal hours in GMST.
 
     """
     jd0 = int(juliandate - 0.5) + 0.5  # Julian Date of previous midnight
-    h = (juliandate - jd0) * 24.  # Hours since mightnight
+    h = (juliandate - jd0) * 24.0  # Hours since mightnight
     # Days since J2000 (Julian Date 2451545.)
-    d0 = jd0 - 2451545.
-    d = juliandate - 2451545.
-    t = d / 36525.  # Centuries since J2000
+    d0 = jd0 - 2451545.0
+    d = juliandate - 2451545.0
+    t = d / 36525.0  # Centuries since J2000
 
-    gmst = (6.697374558 + 0.06570982441908 * d0 + 1.00273790935 * h +
-            0.000026 * t * t)
+    gmst = 6.697374558 + 0.06570982441908 * d0 + 1.00273790935 * h + 0.000026 * t * t
 
-    return gmst % 24.
+    return gmst % 24.0
 
 
 def utc_to_gmst(dt):
     """Convert a datetime object in UTC time to Greenwich Mean Sidereal Time
 
     :param dt: datetime object in UTC time.
     :return: decimal hours in GMST.
@@ -197,39 +212,40 @@
 
     :param dt: datetime object in GMST time.
     :return: datetime object in UTC.
 
     """
     jd = date_to_juliandate(dt.year, dt.month, dt.day)
 
-    d = jd - 2451545.
-    t = d / 36525.
+    d = jd - 2451545.0
+    t = d / 36525.0
     t0 = 6.697374558 + (2400.051336 * t) + (0.000025862 * t * t)
     t0 %= 24
 
     gst = (time_to_decimal(dt.time()) - t0) % 24
     ut = gst * 0.9972695663
 
     time = decimal_to_time(ut)
 
-    return dt.replace(hour=time.hour, minute=time.minute, second=time.seconds,
-                      microsecond=time.microsecond)
+    return dt.replace(hour=time.hour, minute=time.minute, second=time.seconds, microsecond=time.microsecond)
 
 
 def juliandate_to_utc(juliandate):
     """Convert Julian Date to datetime object in UTC
 
     :param juliandate: a Julian Date.
     :return: datetime object in UTC time.
 
     """
     juliandate += 0.5
     jd_frac, jd_int = math.modf(juliandate)
 
-    if jd_int > 2299160:
+    julian_gregorian_transition_date = 2299160
+
+    if jd_int > julian_gregorian_transition_date:
         a = int((jd_int - 1867216.25) / 36524.25)
         b = jd_int + 1 + a - int(a / 4)
     else:
         b = jd_int
 
     c = b + 1524
     d = int((c - 122.1) / 365.25)
@@ -318,28 +334,26 @@
 def gps_to_utc(timestamp):
     """Convert GPS time to UTC
 
     :param timestamp: GPS timestamp in seconds.
     :return: UTC timestamp in seconds.
 
     """
-    offset = next((seconds for date, seconds in LEAP_SECONDS
-                   if timestamp >= utc_from_string(date)), 0)
+    offset = next((seconds for date, seconds in LEAP_SECONDS if timestamp >= utc_from_string(date)), 0)
     return timestamp - offset
 
 
 def utc_to_gps(timestamp):
     """Convert UTC to GPS time
 
     :param timestamp: UTC timestamp in seconds.
     :return: GPS timestamp in seconds.
 
     """
-    offset = next((seconds for date, seconds in LEAP_SECONDS
-                   if timestamp >= utc_from_string(date)), 0)
+    offset = next((seconds for date, seconds in LEAP_SECONDS if timestamp >= utc_from_string(date)), 0)
     return timestamp + offset
 
 
 def utc_from_string(date):
     """Convert a date string to UTC
 
     :param date: date string.
@@ -405,8 +419,8 @@
     """
     try:
         return int(time)
     except (TypeError, ValueError):
         try:
             return datetime_to_gps(time)
         except Exception:
-            raise RuntimeError('Unable to parse time: ', time)
+            raise RuntimeError('Unable to parse time: {time}')
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/transformations/geographic.py` & `hisparc_sapphire-3.0.0/sapphire/transformations/geographic.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,38 +1,39 @@
-""" Perform various coordinate transformations
+"""Perform various coordinate transformations
 
-    This module performs various coordinate transformations, based on some
-    well-known formulas.
+This module performs various coordinate transformations, based on some
+well-known formulas.
 
 """
+
 from math import atan2, cos, degrees, radians, sin, sqrt
 
 from numpy import array
 
 
 class WGS84Datum:
     """Definition of the WGS84 datum
 
     These definitions are taken from
     https://en.wikipedia.org/wiki/Geodetic_system, believing that enough
     editors have gone over them to make sure they are correct.
 
     """
+
     # Defining constants
-    a = 6378137.
+    a = 6378137.0
     f = 1 / 298.257223563
 
     # Derived constants
     b = a * (1 - f)
-    e = sqrt(2 * f - f ** 2)
+    e = sqrt(2 * f - f**2)
     eprime = sqrt(f * (2 - f) / (1 - f) ** 2)
 
 
 class FromWGS84ToENUTransformation:
-
     """Convert between various geographic coordinate systems
 
     This class converts coordinates between LLA, ENU, and ECEF.
 
     """
 
     geode = WGS84Datum()
@@ -85,19 +86,19 @@
         latitude = radians(latitude)
         longitude = radians(longitude)
 
         a = self.geode.a
         b = self.geode.b
         e = self.geode.e
 
-        n = a / sqrt(1 - e ** 2 * sin(latitude) ** 2)
+        n = a / sqrt(1 - e**2 * sin(latitude) ** 2)
 
         x = (n + altitude) * cos(latitude) * cos(longitude)
         y = (n + altitude) * cos(latitude) * sin(longitude)
-        z = (b ** 2 / a ** 2 * n + altitude) * sin(latitude)
+        z = (b**2 / a**2 * n + altitude) * sin(latitude)
 
         return x, y, z
 
     def ecef_to_lla(self, coordinates):
         """Convert from ECEF coordinates to LLA coordinates
 
         ECEF: Earth-Centered, Earth-Fixed
@@ -113,21 +114,20 @@
         x, y, z = coordinates
 
         a = self.geode.a
         b = self.geode.b
         e = self.geode.e
         eprime = self.geode.eprime
 
-        p = sqrt(x ** 2 + y ** 2)
+        p = sqrt(x**2 + y**2)
         th = atan2(a * z, b * p)
 
         longitude = atan2(y, x)
-        latitude = atan2((z + eprime ** 2 * b * sin(th) ** 3),
-                         (p - e ** 2 * a * cos(th) ** 3))
-        n = a / sqrt(1 - e ** 2 * sin(latitude) ** 2)
+        latitude = atan2((z + eprime**2 * b * sin(th) ** 3), (p - e**2 * a * cos(th) ** 3))
+        n = a / sqrt(1 - e**2 * sin(latitude) ** 2)
         altitude = p / cos(latitude) - n
 
         return degrees(latitude), degrees(longitude), altitude
 
     def ecef_to_enu(self, coordinates):
         """Convert from ECEF coordinates to ENU coordinates
 
@@ -145,18 +145,21 @@
         latitude, longitude, altitude = self.ref_lla
         xr, yr, zr = self.ref_ecef
         x, y, z = coordinates
 
         lat = radians(latitude)
         lon = radians(longitude)
 
-        transformation = array([
-            [           -sin(lon),             cos(lon),       0.],  # noqa
-            [-sin(lat) * cos(lon), -sin(lat) * sin(lon), cos(lat)],
-            [ cos(lat) * cos(lon),  cos(lat) * sin(lon), sin(lat)]])  # noqa
+        transformation = array(
+            [
+                [-sin(lon), cos(lon), 0.0],
+                [-sin(lat) * cos(lon), -sin(lat) * sin(lon), cos(lat)],
+                [cos(lat) * cos(lon), cos(lat) * sin(lon), sin(lat)],
+            ],
+        )
 
         coordinates = array([x - xr, y - yr, z - zr])
 
         return tuple(transformation.dot(coordinates))
 
     def enu_to_ecef(self, coordinates):
         """Convert from ENU coordinates to ECEF coordinates
@@ -170,18 +173,21 @@
         """
         latitude, longitude, altitude = self.ref_lla
         xr, yr, zr = self.ref_ecef
 
         lat = radians(latitude)
         lon = radians(longitude)
 
-        transformation = array([
-            [-sin(lon), -sin(lat) * cos(lon), cos(lat) * cos(lon)],
-            [ cos(lon), -sin(lat) * sin(lon), cos(lat) * sin(lon)],  # noqa
-            [       0.,             cos(lat),            sin(lat)]])  # noqa
+        transformation = array(
+            [
+                [-sin(lon), -sin(lat) * cos(lon), cos(lat) * cos(lon)],
+                [cos(lon), -sin(lat) * sin(lon), cos(lat) * sin(lon)],
+                [0.0, cos(lat), sin(lat)],
+            ],
+        )
 
         x, y, z = transformation.dot(array(coordinates))
 
         return x + xr, y + yr, z + zr
 
     def __repr__(self):
-        return f"{self.__class__.__name__}({self.ref_lla!r})"
+        return f'{self.__class__.__name__}({self.ref_lla!r})'
```

### Comparing `hisparc-sapphire-2.0.0/sapphire/utils.py` & `hisparc_sapphire-3.0.0/sapphire/utils.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 """Utilities
 
 The module contains some commonly functions and classes.
 
 """
 
 from bisect import bisect_right
+from contextlib import suppress
 from distutils.spawn import find_executable
 from functools import wraps
 from os import environ
 
 from numpy import arcsin, ceil, floor, pi, round, sin, sqrt
 from progressbar import ETA, Bar, Percentage, ProgressBar
 from scipy.stats import norm
@@ -43,22 +44,19 @@
              the input, but shows a progressbar if possible.
 
     """
     if not show:
         return iterable
 
     if length is None:
-        try:
+        with suppress(TypeError):
             length = len(iterable)
-        except TypeError:
-            pass
 
     if length:
-        pb = ProgressBar(max_value=length,
-                         widgets=[Percentage(), Bar(), ETA()], **kwargs)
+        pb = ProgressBar(max_value=length, widgets=[Percentage(), Bar(), ETA()], **kwargs)
         return pb(iterable)
     else:
         return iterable
 
 
 def ceil_in_base(value, base):
     """Get nearest multiple of base above the value"""
@@ -126,28 +124,28 @@
     :param zenith#: Zenith parts of the coordinates, in radians (0, pi/2).
     :param azimuth#: Azimuth parts of the coordinates, in radians (-pi, pi).
     :return: Angle between the two coordinates.
 
     """
     dlat = zenith1 - zenith2
     dlon = azimuth2 - azimuth1
-    a = (sin(dlat / 2) ** 2 + sin(zenith1) * sin(zenith2) * sin(dlon / 2) ** 2)
+    a = sin(dlat / 2) ** 2 + sin(zenith1) * sin(zenith2) * sin(dlon / 2) ** 2
     angle = 2 * arcsin(sqrt(a))
 
     return angle
 
 
 def vector_length(x, y, z=0):
     """Length of a vector given by (x, y, z) coordinates
 
     :param x,y,z: vector components.
     :return: length of vector.
 
     """
-    return sqrt(x ** 2 + y ** 2 + z ** 2)
+    return sqrt(x**2 + y**2 + z**2)
 
 
 def distance_between(x1, y1, x2, y2):
     """Calculate the distance between two (x, y) coordinates
 
     :param x#: x parts of the coordinates.
     :param y#: y parts of the coordinates.
@@ -169,28 +167,28 @@
     An Exception is raised if the program is not available.
 
     :param program: name or program to check for, e.g. 'wget'.
 
     """
     path = find_executable(program)
     if not path:
-        raise Exception('The program %s is not available.' % program)
+        raise RuntimeError(f'The program {program} is not available.')
 
 
 def memoize(method):
     """Memoisation cache decorator
 
     Source: https://stackoverflow.com/a/29954160/1033535
 
     """
+
     @wraps(method)
     def memoizer(self, *args, **kwargs):
-
         # Prepare and get reference to cache
-        attr = f"_memo_{method.__name__}"
+        attr = f'_memo_{method.__name__}'
         if not hasattr(self, attr):
             setattr(self, attr, {})
         cache = getattr(self, attr)
 
         # Actual caching
         key = f'{args}{sorted(kwargs.items())}'
         try:
```


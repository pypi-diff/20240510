# Comparing `tmp/asyncdb-2.6.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip` & `tmp/asyncdb-2.7.0-pp39-pypy39_pp73-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,82 +1,71 @@
-Zip file size: 771894 bytes, number of entries: 80
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb-2.6.9.dist-info/
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb.libs/
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb/
--rw-r--r--  2.0 unx      148 b- defN 24-Jan-16 23:52 asyncdb-2.6.9.dist-info/WHEEL
--rw-r--r--  2.0 unx     1509 b- defN 24-Jan-16 23:52 asyncdb-2.6.9.dist-info/LICENSE
--rw-rw-r--  2.0 unx     5949 b- defN 24-Jan-16 23:52 asyncdb-2.6.9.dist-info/RECORD
--rw-r--r--  2.0 unx        8 b- defN 24-Jan-16 23:52 asyncdb-2.6.9.dist-info/top_level.txt
--rw-r--r--  2.0 unx    12512 b- defN 24-Jan-16 23:52 asyncdb-2.6.9.dist-info/METADATA
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb/drivers/
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb/meta/
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb/models/
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb/exceptions/
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb/utils/
--rw-r--r--  2.0 unx    27360 b- defN 24-Jan-16 23:52 asyncdb/interfaces.py
--rw-r--r--  2.0 unx     1254 b- defN 24-Jan-16 23:52 asyncdb/connections.py
--rw-r--r--  2.0 unx      390 b- defN 24-Jan-16 23:52 asyncdb/__init__.py
--rw-r--r--  2.0 unx      271 b- defN 24-Jan-16 23:52 asyncdb/version.py
--rw-r--r--  2.0 unx        0 b- defN 24-Jan-16 23:52 asyncdb/py.typed
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb/drivers/outputs/
--rw-r--r--  2.0 unx    12024 b- defN 24-Jan-16 23:52 asyncdb/drivers/bigquery.py
--rw-r--r--  2.0 unx    29046 b- defN 24-Jan-16 23:52 asyncdb/drivers/jdbc.py
--rw-r--r--  2.0 unx    16372 b- defN 24-Jan-16 23:52 asyncdb/drivers/sa.py
--rw-r--r--  2.0 unx    20436 b- defN 24-Jan-16 23:52 asyncdb/drivers/influx.py
--rw-r--r--  2.0 unx     9032 b- defN 24-Jan-16 23:52 asyncdb/drivers/memcache.py
--rw-r--r--  2.0 unx    29146 b- defN 24-Jan-16 23:52 asyncdb/drivers/scylladb.py
--rw-r--r--  2.0 unx    19323 b- defN 24-Jan-16 23:52 asyncdb/drivers/redis.py
--rw-r--r--  2.0 unx     9903 b- defN 24-Jan-16 23:52 asyncdb/drivers/delta.py
--rw-r--r--  2.0 unx     9920 b- defN 24-Jan-16 23:52 asyncdb/drivers/duckdb.py
--rw-r--r--  2.0 unx    17007 b- defN 24-Jan-16 23:52 asyncdb/drivers/cassandra.py
--rw-r--r--  2.0 unx    59985 b- defN 24-Jan-16 23:52 asyncdb/drivers/pg.py
--rw-r--r--  2.0 unx     6412 b- defN 24-Jan-16 23:52 asyncdb/drivers/mcache.py
--rw-r--r--  2.0 unx    22002 b- defN 24-Jan-16 23:52 asyncdb/drivers/postgres.py
--rw-r--r--  2.0 unx     2049 b- defN 24-Jan-16 23:52 asyncdb/drivers/dummy.py
--rw-r--r--  2.0 unx    25324 b- defN 24-Jan-16 23:52 asyncdb/drivers/sqlite.py
--rw-r--r--  2.0 unx       25 b- defN 24-Jan-16 23:52 asyncdb/drivers/__init__.py
--rw-r--r--  2.0 unx    14033 b- defN 24-Jan-16 23:52 asyncdb/drivers/sqlserver.py
--rw-r--r--  2.0 unx    19035 b- defN 24-Jan-16 23:52 asyncdb/drivers/mredis.py
--rw-r--r--  2.0 unx     3276 b- defN 24-Jan-16 23:52 asyncdb/drivers/mongo.py
--rw-r--r--  2.0 unx     2010 b- defN 24-Jan-16 23:52 asyncdb/drivers/sql.py
--rw-r--r--  2.0 unx     4106 b- defN 24-Jan-16 23:52 asyncdb/drivers/oracle.py
--rw-r--r--  2.0 unx    18098 b- defN 24-Jan-16 23:52 asyncdb/drivers/mysqlclient.py
--rw-r--r--  2.0 unx    12730 b- defN 24-Jan-16 23:52 asyncdb/drivers/hazel.py
--rw-r--r--  2.0 unx     4361 b- defN 24-Jan-16 23:52 asyncdb/drivers/abstract.py
--rw-r--r--  2.0 unx     7831 b- defN 24-Jan-16 23:52 asyncdb/drivers/odbc.py
--rw-r--r--  2.0 unx    15515 b- defN 24-Jan-16 23:52 asyncdb/drivers/mssql.py
--rw-r--r--  2.0 unx    15649 b- defN 24-Jan-16 23:52 asyncdb/drivers/mysql.py
--rw-r--r--  2.0 unx    34256 b- defN 24-Jan-16 23:52 asyncdb/drivers/rethink.py
--rw-r--r--  2.0 unx     7376 b- defN 24-Jan-16 23:52 asyncdb/drivers/_sa.py
--rw-r--r--  2.0 unx     1010 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/record.py
--rw-r--r--  2.0 unx      407 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/json.py
--rw-r--r--  2.0 unx      969 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/csv.py
--rw-r--r--  2.0 unx      667 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/dataclass.py
--rw-r--r--  2.0 unx      413 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/base.py
--rw-r--r--  2.0 unx      390 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/generator.py
--rw-r--r--  2.0 unx      749 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/recordset.py
--rw-r--r--  2.0 unx      801 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/dt.py
--rw-r--r--  2.0 unx      824 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/arrow.py
--rw-r--r--  2.0 unx      521 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/iter.py
--rw-r--r--  2.0 unx      499 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/__init__.py
--rw-r--r--  2.0 unx      838 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/polars.py
--rw-r--r--  2.0 unx      992 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/pandas.py
--rw-r--r--  2.0 unx      958 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/output.py
--rw-r--r--  2.0 unx     1199 b- defN 24-Jan-16 23:52 asyncdb/drivers/outputs/pyspark.py
--rw-r--r--  2.0 unx     2947 b- defN 24-Jan-16 23:52 asyncdb/meta/record.py
--rw-r--r--  2.0 unx     2144 b- defN 24-Jan-16 23:52 asyncdb/meta/recordset.py
--rw-r--r--  2.0 unx      166 b- defN 24-Jan-16 23:52 asyncdb/meta/__init__.py
--rw-r--r--  2.0 unx    17311 b- defN 24-Jan-16 23:52 asyncdb/models/model.py
--rw-r--r--  2.0 unx      527 b- defN 24-Jan-16 23:52 asyncdb/models/__init__.py
--rwxr-xr-x  2.0 unx  1440552 b- defN 24-Jan-16 23:52 asyncdb/exceptions/exceptions.cpython-39-x86_64-linux-gnu.so
--rw-r--r--  2.0 unx     2801 b- defN 24-Jan-16 23:52 asyncdb/exceptions/handlers.py
--rw-r--r--  2.0 unx      827 b- defN 24-Jan-16 23:52 asyncdb/exceptions/__init__.py
-drwxr-xr-x  2.0 unx        0 b- stor 24-Jan-16 23:52 asyncdb/utils/encoders/
--rw-r--r--  2.0 unx      636 b- defN 24-Jan-16 23:52 asyncdb/utils/modules.py
--rw-r--r--  2.0 unx      128 b- defN 24-Jan-16 23:52 asyncdb/utils/__init__.py
--rw-r--r--  2.0 unx      259 b- defN 24-Jan-16 23:52 asyncdb/utils/uv.py
--rw-r--r--  2.0 unx     2389 b- defN 24-Jan-16 23:52 asyncdb/utils/functions.py
--rwxr-xr-x  2.0 unx  1021448 b- defN 24-Jan-16 23:52 asyncdb/utils/types.cpython-39-x86_64-linux-gnu.so
--rw-r--r--  2.0 unx     1154 b- defN 24-Jan-16 23:52 asyncdb/utils/encoders/pg.py
--rw-r--r--  2.0 unx      225 b- defN 24-Jan-16 23:52 asyncdb/utils/encoders/__init__.py
--rw-r--r--  2.0 unx      467 b- defN 24-Jan-16 23:52 asyncdb/utils/encoders/numpy.py
-80 files, 3000901 bytes uncompressed, 761556 bytes compressed:  74.6%
+Zip file size: 215432 bytes, number of entries: 69
+-rw-rw-rw-  2.0 fat      411 b- defN 24-May-10 01:18 asyncdb/__init__.py
+-rw-rw-rw-  2.0 fat     1297 b- defN 24-May-10 01:18 asyncdb/connections.py
+-rw-rw-rw-  2.0 fat    25523 b- defN 24-May-10 01:18 asyncdb/interfaces.py
+-rw-rw-rw-  2.0 fat        0 b- defN 24-May-10 01:18 asyncdb/py.typed
+-rw-rw-rw-  2.0 fat      280 b- defN 24-May-10 01:18 asyncdb/version.py
+-rw-rw-rw-  2.0 fat       28 b- defN 24-May-10 01:18 asyncdb/drivers/__init__.py
+-rw-rw-rw-  2.0 fat     4529 b- defN 24-May-10 01:18 asyncdb/drivers/abstract.py
+-rw-rw-rw-  2.0 fat    12373 b- defN 24-May-10 01:18 asyncdb/drivers/bigquery.py
+-rw-rw-rw-  2.0 fat    17209 b- defN 24-May-10 01:18 asyncdb/drivers/cassandra.py
+-rw-rw-rw-  2.0 fat    10172 b- defN 24-May-10 01:18 asyncdb/drivers/delta.py
+-rw-rw-rw-  2.0 fat    10193 b- defN 24-May-10 01:18 asyncdb/drivers/duckdb.py
+-rw-rw-rw-  2.0 fat     2110 b- defN 24-May-10 01:18 asyncdb/drivers/dummy.py
+-rw-rw-rw-  2.0 fat    13068 b- defN 24-May-10 01:18 asyncdb/drivers/hazel.py
+-rw-rw-rw-  2.0 fat    20827 b- defN 24-May-10 01:18 asyncdb/drivers/influx.py
+-rw-rw-rw-  2.0 fat    29764 b- defN 24-May-10 01:18 asyncdb/drivers/jdbc.py
+-rw-rw-rw-  2.0 fat     6638 b- defN 24-May-10 01:18 asyncdb/drivers/mcache.py
+-rw-rw-rw-  2.0 fat     9336 b- defN 24-May-10 01:18 asyncdb/drivers/memcache.py
+-rw-rw-rw-  2.0 fat     3316 b- defN 24-May-10 01:18 asyncdb/drivers/mongo.py
+-rw-rw-rw-  2.0 fat    19474 b- defN 24-May-10 01:18 asyncdb/drivers/mredis.py
+-rw-rw-rw-  2.0 fat    15824 b- defN 24-May-10 01:18 asyncdb/drivers/mssql.py
+-rw-rw-rw-  2.0 fat    16072 b- defN 24-May-10 01:18 asyncdb/drivers/mysql.py
+-rw-rw-rw-  2.0 fat    18635 b- defN 24-May-10 01:18 asyncdb/drivers/mysqlclient.py
+-rw-rw-rw-  2.0 fat     8036 b- defN 24-May-10 01:18 asyncdb/drivers/odbc.py
+-rw-rw-rw-  2.0 fat     4206 b- defN 24-May-10 01:18 asyncdb/drivers/oracle.py
+-rw-rw-rw-  2.0 fat    61614 b- defN 24-May-10 01:18 asyncdb/drivers/pg.py
+-rw-rw-rw-  2.0 fat    22590 b- defN 24-May-10 01:18 asyncdb/drivers/postgres.py
+-rw-rw-rw-  2.0 fat    19814 b- defN 24-May-10 01:18 asyncdb/drivers/redis.py
+-rw-rw-rw-  2.0 fat    35185 b- defN 24-May-10 01:18 asyncdb/drivers/rethink.py
+-rw-rw-rw-  2.0 fat    16815 b- defN 24-May-10 01:18 asyncdb/drivers/sa.py
+-rw-rw-rw-  2.0 fat    56434 b- defN 24-May-10 01:18 asyncdb/drivers/scylladb.py
+-rw-rw-rw-  2.0 fat     2071 b- defN 24-May-10 01:18 asyncdb/drivers/sql.py
+-rw-rw-rw-  2.0 fat    25972 b- defN 24-May-10 01:18 asyncdb/drivers/sqlite.py
+-rw-rw-rw-  2.0 fat    14374 b- defN 24-May-10 01:18 asyncdb/drivers/sqlserver.py
+-rw-rw-rw-  2.0 fat      513 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/__init__.py
+-rw-rw-rw-  2.0 fat      848 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/arrow.py
+-rw-rw-rw-  2.0 fat      429 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/base.py
+-rw-rw-rw-  2.0 fat      997 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/csv.py
+-rw-rw-rw-  2.0 fat      693 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/dataclass.py
+-rw-rw-rw-  2.0 fat      827 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/dt.py
+-rw-rw-rw-  2.0 fat      408 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/generator.py
+-rw-rw-rw-  2.0 fat      543 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/iter.py
+-rw-rw-rw-  2.0 fat      418 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/json.py
+-rw-rw-rw-  2.0 fat      986 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/output.py
+-rw-rw-rw-  2.0 fat     1021 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/pandas.py
+-rw-rw-rw-  2.0 fat      864 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/polars.py
+-rw-rw-rw-  2.0 fat     1236 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/pyspark.py
+-rw-rw-rw-  2.0 fat     1038 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/record.py
+-rw-rw-rw-  2.0 fat      770 b- defN 24-May-10 01:18 asyncdb/drivers/outputs/recordset.py
+-rw-rw-rw-  2.0 fat      867 b- defN 24-May-10 01:18 asyncdb/exceptions/__init__.py
+-rw-rw-rw-  2.0 fat   158720 b- defN 24-May-10 01:25 asyncdb/exceptions/exceptions.pypy39-pp73-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     2539 b- defN 24-May-10 01:18 asyncdb/exceptions/handlers.py
+-rw-rw-rw-  2.0 fat      176 b- defN 24-May-10 01:18 asyncdb/meta/__init__.py
+-rw-rw-rw-  2.0 fat     3057 b- defN 24-May-10 01:18 asyncdb/meta/record.py
+-rw-rw-rw-  2.0 fat     2221 b- defN 24-May-10 01:18 asyncdb/meta/recordset.py
+-rw-rw-rw-  2.0 fat      542 b- defN 24-May-10 01:18 asyncdb/models/__init__.py
+-rw-rw-rw-  2.0 fat    17784 b- defN 24-May-10 01:18 asyncdb/models/model.py
+-rw-rw-rw-  2.0 fat      136 b- defN 24-May-10 01:18 asyncdb/utils/__init__.py
+-rw-rw-rw-  2.0 fat     2484 b- defN 24-May-10 01:18 asyncdb/utils/functions.py
+-rw-rw-rw-  2.0 fat      655 b- defN 24-May-10 01:18 asyncdb/utils/modules.py
+-rw-rw-rw-  2.0 fat   111616 b- defN 24-May-10 01:25 asyncdb/utils/types.pypy39-pp73-win_amd64.pyd
+-rw-rw-rw-  2.0 fat      319 b- defN 24-May-10 01:18 asyncdb/utils/uv.py
+-rw-rw-rw-  2.0 fat      234 b- defN 24-May-10 01:18 asyncdb/utils/encoders/__init__.py
+-rw-rw-rw-  2.0 fat      487 b- defN 24-May-10 01:18 asyncdb/utils/encoders/numpy.py
+-rw-rw-rw-  2.0 fat     1195 b- defN 24-May-10 01:18 asyncdb/utils/encoders/pg.py
+-rw-rw-rw-  2.0 fat     1538 b- defN 24-May-10 01:25 asyncdb-2.7.0.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    12674 b- defN 24-May-10 01:25 asyncdb-2.7.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      107 b- defN 24-May-10 01:25 asyncdb-2.7.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 24-May-10 01:25 asyncdb-2.7.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     5791 b- defN 24-May-10 01:25 asyncdb-2.7.0.dist-info/RECORD
+69 files, 838931 bytes uncompressed, 206332 bytes compressed:  75.4%
```

## zipnote {}

```diff
@@ -1,241 +1,208 @@
-Filename: asyncdb-2.6.9.dist-info/
-Comment: 
-
-Filename: asyncdb.libs/
-Comment: 
-
-Filename: asyncdb/
-Comment: 
-
-Filename: asyncdb-2.6.9.dist-info/WHEEL
-Comment: 
-
-Filename: asyncdb-2.6.9.dist-info/LICENSE
-Comment: 
-
-Filename: asyncdb-2.6.9.dist-info/RECORD
-Comment: 
-
-Filename: asyncdb-2.6.9.dist-info/top_level.txt
+Filename: asyncdb/__init__.py
 Comment: 
 
-Filename: asyncdb-2.6.9.dist-info/METADATA
+Filename: asyncdb/connections.py
 Comment: 
 
-Filename: asyncdb/drivers/
+Filename: asyncdb/interfaces.py
 Comment: 
 
-Filename: asyncdb/meta/
+Filename: asyncdb/py.typed
 Comment: 
 
-Filename: asyncdb/models/
+Filename: asyncdb/version.py
 Comment: 
 
-Filename: asyncdb/exceptions/
+Filename: asyncdb/drivers/__init__.py
 Comment: 
 
-Filename: asyncdb/utils/
+Filename: asyncdb/drivers/abstract.py
 Comment: 
 
-Filename: asyncdb/interfaces.py
+Filename: asyncdb/drivers/bigquery.py
 Comment: 
 
-Filename: asyncdb/connections.py
+Filename: asyncdb/drivers/cassandra.py
 Comment: 
 
-Filename: asyncdb/__init__.py
+Filename: asyncdb/drivers/delta.py
 Comment: 
 
-Filename: asyncdb/version.py
+Filename: asyncdb/drivers/duckdb.py
 Comment: 
 
-Filename: asyncdb/py.typed
+Filename: asyncdb/drivers/dummy.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/
+Filename: asyncdb/drivers/hazel.py
 Comment: 
 
-Filename: asyncdb/drivers/bigquery.py
+Filename: asyncdb/drivers/influx.py
 Comment: 
 
 Filename: asyncdb/drivers/jdbc.py
 Comment: 
 
-Filename: asyncdb/drivers/sa.py
-Comment: 
-
-Filename: asyncdb/drivers/influx.py
+Filename: asyncdb/drivers/mcache.py
 Comment: 
 
 Filename: asyncdb/drivers/memcache.py
 Comment: 
 
-Filename: asyncdb/drivers/scylladb.py
-Comment: 
-
-Filename: asyncdb/drivers/redis.py
+Filename: asyncdb/drivers/mongo.py
 Comment: 
 
-Filename: asyncdb/drivers/delta.py
+Filename: asyncdb/drivers/mredis.py
 Comment: 
 
-Filename: asyncdb/drivers/duckdb.py
+Filename: asyncdb/drivers/mssql.py
 Comment: 
 
-Filename: asyncdb/drivers/cassandra.py
+Filename: asyncdb/drivers/mysql.py
 Comment: 
 
-Filename: asyncdb/drivers/pg.py
+Filename: asyncdb/drivers/mysqlclient.py
 Comment: 
 
-Filename: asyncdb/drivers/mcache.py
+Filename: asyncdb/drivers/odbc.py
 Comment: 
 
-Filename: asyncdb/drivers/postgres.py
+Filename: asyncdb/drivers/oracle.py
 Comment: 
 
-Filename: asyncdb/drivers/dummy.py
+Filename: asyncdb/drivers/pg.py
 Comment: 
 
-Filename: asyncdb/drivers/sqlite.py
+Filename: asyncdb/drivers/postgres.py
 Comment: 
 
-Filename: asyncdb/drivers/__init__.py
+Filename: asyncdb/drivers/redis.py
 Comment: 
 
-Filename: asyncdb/drivers/sqlserver.py
+Filename: asyncdb/drivers/rethink.py
 Comment: 
 
-Filename: asyncdb/drivers/mredis.py
+Filename: asyncdb/drivers/sa.py
 Comment: 
 
-Filename: asyncdb/drivers/mongo.py
+Filename: asyncdb/drivers/scylladb.py
 Comment: 
 
 Filename: asyncdb/drivers/sql.py
 Comment: 
 
-Filename: asyncdb/drivers/oracle.py
+Filename: asyncdb/drivers/sqlite.py
 Comment: 
 
-Filename: asyncdb/drivers/mysqlclient.py
+Filename: asyncdb/drivers/sqlserver.py
 Comment: 
 
-Filename: asyncdb/drivers/hazel.py
+Filename: asyncdb/drivers/outputs/__init__.py
 Comment: 
 
-Filename: asyncdb/drivers/abstract.py
+Filename: asyncdb/drivers/outputs/arrow.py
 Comment: 
 
-Filename: asyncdb/drivers/odbc.py
+Filename: asyncdb/drivers/outputs/base.py
 Comment: 
 
-Filename: asyncdb/drivers/mssql.py
+Filename: asyncdb/drivers/outputs/csv.py
 Comment: 
 
-Filename: asyncdb/drivers/mysql.py
+Filename: asyncdb/drivers/outputs/dataclass.py
 Comment: 
 
-Filename: asyncdb/drivers/rethink.py
+Filename: asyncdb/drivers/outputs/dt.py
 Comment: 
 
-Filename: asyncdb/drivers/_sa.py
+Filename: asyncdb/drivers/outputs/generator.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/record.py
+Filename: asyncdb/drivers/outputs/iter.py
 Comment: 
 
 Filename: asyncdb/drivers/outputs/json.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/csv.py
-Comment: 
-
-Filename: asyncdb/drivers/outputs/dataclass.py
-Comment: 
-
-Filename: asyncdb/drivers/outputs/base.py
-Comment: 
-
-Filename: asyncdb/drivers/outputs/generator.py
+Filename: asyncdb/drivers/outputs/output.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/recordset.py
+Filename: asyncdb/drivers/outputs/pandas.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/dt.py
+Filename: asyncdb/drivers/outputs/polars.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/arrow.py
+Filename: asyncdb/drivers/outputs/pyspark.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/iter.py
+Filename: asyncdb/drivers/outputs/record.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/__init__.py
+Filename: asyncdb/drivers/outputs/recordset.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/polars.py
+Filename: asyncdb/exceptions/__init__.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/pandas.py
+Filename: asyncdb/exceptions/exceptions.pypy39-pp73-win_amd64.pyd
 Comment: 
 
-Filename: asyncdb/drivers/outputs/output.py
+Filename: asyncdb/exceptions/handlers.py
 Comment: 
 
-Filename: asyncdb/drivers/outputs/pyspark.py
+Filename: asyncdb/meta/__init__.py
 Comment: 
 
 Filename: asyncdb/meta/record.py
 Comment: 
 
 Filename: asyncdb/meta/recordset.py
 Comment: 
 
-Filename: asyncdb/meta/__init__.py
+Filename: asyncdb/models/__init__.py
 Comment: 
 
 Filename: asyncdb/models/model.py
 Comment: 
 
-Filename: asyncdb/models/__init__.py
+Filename: asyncdb/utils/__init__.py
 Comment: 
 
-Filename: asyncdb/exceptions/exceptions.cpython-39-x86_64-linux-gnu.so
+Filename: asyncdb/utils/functions.py
 Comment: 
 
-Filename: asyncdb/exceptions/handlers.py
+Filename: asyncdb/utils/modules.py
 Comment: 
 
-Filename: asyncdb/exceptions/__init__.py
+Filename: asyncdb/utils/types.pypy39-pp73-win_amd64.pyd
 Comment: 
 
-Filename: asyncdb/utils/encoders/
+Filename: asyncdb/utils/uv.py
 Comment: 
 
-Filename: asyncdb/utils/modules.py
+Filename: asyncdb/utils/encoders/__init__.py
 Comment: 
 
-Filename: asyncdb/utils/__init__.py
+Filename: asyncdb/utils/encoders/numpy.py
 Comment: 
 
-Filename: asyncdb/utils/uv.py
+Filename: asyncdb/utils/encoders/pg.py
 Comment: 
 
-Filename: asyncdb/utils/functions.py
+Filename: asyncdb-2.7.0.dist-info/LICENSE
 Comment: 
 
-Filename: asyncdb/utils/types.cpython-39-x86_64-linux-gnu.so
+Filename: asyncdb-2.7.0.dist-info/METADATA
 Comment: 
 
-Filename: asyncdb/utils/encoders/pg.py
+Filename: asyncdb-2.7.0.dist-info/WHEEL
 Comment: 
 
-Filename: asyncdb/utils/encoders/__init__.py
+Filename: asyncdb-2.7.0.dist-info/top_level.txt
 Comment: 
 
-Filename: asyncdb/utils/encoders/numpy.py
+Filename: asyncdb-2.7.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## filetype from file(1)

```diff
@@ -1 +1 @@
-Zip archive data, at least v2.0 to extract, compression method=store
+Zip archive data, at least v2.0 to extract, compression method=deflate
```

## asyncdb/interfaces.py

```diff
@@ -1,885 +1,828 @@
-"""
-Basic Interfaces for every kind of Database Connector.
-"""
-import asyncio
-import logging
-import uuid
-import inspect
-import types
-from importlib import import_module
-from collections.abc import Sequence, Iterable, Callable
-from datetime import datetime
-from abc import (
-    ABC,
-    abstractmethod,
-)
-from typing import (
-    Any,
-    List,
-    Optional,
-    Union
-)
-from functools import partial
-from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
-from datamodel.exceptions import ValidationError
-from .meta import Record, Recordset
-from .exceptions import default_exception_handler, DriverError, EmptyStatement
-from .models import Model, Field, is_missing, is_dataclass
-from .utils.types import Entity, SafeDict
-
-null_values = {"null", "NULL"}
-not_null_values = {"!null", "!NULL"}
-
-
-class PoolBackend(ABC):
-    """
-    Basic Interface for Pool-based Connectors.
-    """
-
-    _provider: str = "base"
-    _syntax: str = ""  # Used by QueryParser for parsing queries
-    _init_func: Optional[Callable] = None
-
-    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict[Any] = None, **kwargs) -> None:
-        self._pool = None
-        try:
-            self._encoding = kwargs["encoding"]
-        except KeyError:
-            self._encoding = "utf-8"
-        if "max_queries" in kwargs:
-            self._max_queries = kwargs["max_queries"]
-        else:
-            self._max_queries = 300
-        self._connection = None
-        self._connected = False
-        if loop:
-            self._loop = loop
-            asyncio.set_event_loop(self._loop)
-        else:
-            self._loop = asyncio.get_event_loop()
-            asyncio.set_event_loop(self._loop)
-        if self._loop.is_closed():
-            self._loop = asyncio.get_running_loop()
-            asyncio.set_event_loop(self._loop)
-        # exception handler
-        self._loop.set_exception_handler(default_exception_handler)
-        try:
-            self._debug = bool(params.get("DEBUG", False))
-        except (TypeError, KeyError, AttributeError):
-            try:
-                self._debug = kwargs["debug"]
-            except KeyError:
-                self._debug = False
-        try:
-            self._timeout = kwargs["timeout"]
-        except KeyError:
-            self._timeout = 600
-        # set the logger:
-        try:
-            self._logger = logging.getLogger(name=__name__)
-        except Exception as err:
-            self._logger = None
-            logging.exception(err)
-            raise
-
-    @abstractmethod
-    async def connect(self) -> "PoolBackend":
-        raise NotImplementedError()  # pragma: no cover
-
-    @abstractmethod
-    async def disconnect(self, timeout: int = 5) -> None:
-        raise NotImplementedError()  # pragma: no cover
-
-    close = disconnect
-
-    @abstractmethod
-    async def acquire(self) -> "ConnectionBackend":
-        raise NotImplementedError()  # pragma: no cover
-
-    @abstractmethod
-    async def release(self, connection: "ConnectionBackend" = None, timeout: int = 10) -> None:
-        raise NotImplementedError()  # pragma: no cover
-
-    ### Magic Methods
-    async def __aenter__(self) -> "PoolBackend":
-        if not self._pool:
-            await self.connect()
-        await self.acquire()
-        return self
-
-    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
-        # clean up anything you need to clean up
-        return await self.release(connection=self._connection, timeout=5)
-
-    @property
-    def log(self):
-        return self._logger
-
-    def pool(self):
-        return self._pool
-
-    def get_loop(self):
-        return self._loop
-
-    event_loop = get_loop
-
-    def is_connected(self):
-        return self._connected
-
-    def get_connection(self):
-        return self._pool
-
-    engine = get_connection
-
-    def is_closed(self):
-        if not self._connected:
-            logging.debug(f"Connection closed on: {self._pool}")
-            return True
-        return False
-
-    @classmethod
-    def driver(cls):
-        return cls.__name__
-
-    @classmethod
-    def dialect(cls):
-        return cls._syntax
-
-
-class ConnectionBackend(ABC):
-    """
-    Basic Interface with basic methods for connect and disconnect.
-    """
-
-    _provider: str = "base"
-    _syntax: str = ""  # Used by QueryParser for parsing queries
-    _init_func: Optional[Callable] = None  # a function called when connection is made
-
-    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict[Any] = Any, **kwargs) -> None:
-        self._connection: Callable = None
-        self._connected: bool = False
-        self._cursor = None
-        self._generated: datetime = None
-        self._starttime: datetime = None
-        self._pool = None
-        self._executor = None
-        try:
-            self._encoding = kwargs["encoding"]
-        except KeyError:
-            self._encoding = "utf-8"
-        if "max_queries" in kwargs:
-            self._max_queries = kwargs["max_queries"]
-        else:
-            self._max_queries = 300
-        try:
-            self.params = params.copy()
-        except (TypeError, AttributeError, ValueError):
-            self.params = {}
-        if loop:
-            self._loop = loop
-        else:
-            self._loop = asyncio.get_event_loop()
-        # if self._loop.is_closed():
-        #     self._loop = asyncio.get_running_loop()
-        asyncio.set_event_loop(self._loop)
-        # exception handler
-        self._loop.set_exception_handler(default_exception_handler)
-        try:
-            self._debug = bool(params["DEBUG"])
-        except KeyError:
-            try:
-                self._debug = kwargs["debug"]
-            except KeyError:
-                self._debug = False
-        try:
-            self._timeout = kwargs["timeout"]
-        except KeyError:
-            self._timeout = 600
-        self._logger = logging.getLogger(f"DB.{self.__class__.__name__}")
-
-    @abstractmethod
-    async def connection(self) -> Any:
-        raise NotImplementedError()  # pragma: no cover
-
-    def set_connection(self, connection):
-        self._connection = connection
-
-    @abstractmethod
-    async def close(self, timeout: int = 10) -> None:
-        raise NotImplementedError()  # pragma: no cover
-
-    def is_closed(self):
-        if not self._connected:
-            logging.debug(f"Connection closed on: {self._pool}")
-            return True
-        return False
-
-    # Properties
-    @classmethod
-    def type(cls):
-        return cls._provider
-
-    @property
-    def log(self):
-        return self._logger
-
-    def pool(self):
-        return self._pool
-
-    def get_loop(self):
-        return self._loop
-
-    event_loop = get_loop
-
-    def is_connected(self):
-        return bool(self._connected)
-
-    def get_connection(self):
-        return self._connection
-
-    engine = get_connection
-
-    @property
-    def raw_connection(self) -> Any:
-        return self._connection
-
-    def start_timing(self):
-        self._starttime = datetime.now()
-        return self._starttime
-
-    def generated_at(self, started: datetime = None):
-        if not started:
-            started = datetime.now()
-        try:
-            self._generated = started - self._starttime
-        except TypeError:
-            return None
-        return self._generated
-
-    def last_duration(self):
-        return self._generated
-
-    @classmethod
-    def driver(cls):
-        return cls.__name__
-
-    @classmethod
-    def dialect(cls):
-        return cls._syntax
-
-    ### Async Context magic Methods
-    async def __aenter__(self) -> "ConnectionBackend":
-        if not self._connection:
-            await self.connection()
-        return self
-
-    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
-        # clean up anything you need to clean up
-        try:
-            await asyncio.wait_for(self.close(), timeout=20)
-        except asyncio.TimeoutError as e:
-            self._logger.warning(f"Close timed out: {e}")
-        except RuntimeError as e:
-            self._logger.error(str(e))
-        except Exception as err:
-            self._logger.exception(f"Closing Error: {err}")
-            raise
-
-    def get_executor(self, executor="thread", max_workers: int = 2) -> Any:
-        if executor == "thread":
-            return ThreadPoolExecutor(max_workers=max_workers)
-        elif executor == "process":
-            return ProcessPoolExecutor(max_workers=max_workers)
-        else:
-            return None
-
-    async def _thread_func(self, fn, *args, executor: Any = None, **kwargs):
-        """_execute.
-
-        Returns a future to be executed into a Thread Pool.
-        """
-        loop = asyncio.get_event_loop()
-        func = partial(fn, *args, **kwargs)
-        if not executor:
-            executor = self._executor
-        try:
-            fut = loop.run_in_executor(executor, func)
-            return await fut
-        except Exception as e:
-            self._logger.exception(e, stack_info=True)
-            raise
-
-
-class ConnectionDSNBackend(ABC):
-    """
-    Interface for Databases with DSN Support.
-    """
-
-    _logger: Any = None
-
-    def __init__(self, dsn: str = None, params: Optional[dict] = None) -> None:
-        if dsn:
-            self._dsn = dsn
-        else:
-            self._dsn = self.create_dsn(params)
-        try:
-            self._params = params.copy()
-        except (TypeError, AttributeError, ValueError):
-            self._params = {}
-        # Executor:
-        self._executor = None
-
-    def create_dsn(self, params: dict):
-        try:
-            if params:
-                return self._dsn.format_map(SafeDict(**params))
-            else:
-                return None
-        except TypeError as err:
-            self._logger.exception(err)
-            raise DriverError(f"Error creating DSN connection: {err}") from err
-
-    def get_dsn(self):
-        return self._dsn
-
-    def get_executor(self, executor="thread", max_workers: int = 2) -> Any:
-        if executor == "thread":
-            return ThreadPoolExecutor(max_workers=max_workers)
-        elif executor == "process":
-            return ProcessPoolExecutor(max_workers=max_workers)
-        else:
-            return None
-
-    async def _thread_func(self, fn, *args, executor: Any = None, **kwargs):
-        """_execute.
-
-        Returns a future to be executed into a Thread Pool.
-        """
-        loop = asyncio.get_event_loop()
-        func = partial(fn, *args, **kwargs)
-        if not executor:
-            executor = self._executor
-        try:
-            fut = loop.run_in_executor(executor, func)
-            return await fut
-        except Exception as e:
-            self._logger.exception(e, stack_info=True)
-            raise
-
-
-class TransactionBackend(ABC):
-    """
-    Interface for Drivers with Transaction Support.
-    """
-
-    def __init__(self):
-        self._connection = None
-        self._transaction = None
-
-    @abstractmethod
-    async def transaction(self, options: dict[Any]) -> Any:
-        """
-        Getting a Transaction Object.
-        """
-        raise NotImplementedError()  # pragma: no cover
-
-    async def transaction_start(self, options: dict) -> None:
-        """
-        Starts a Transaction.
-        """
-        self._transaction = self.transaction(options)
-
-    @abstractmethod
-    async def commit(self) -> None:
-        pass
-
-    @abstractmethod
-    async def rollback(self) -> None:
-        pass
-
-
-class DatabaseBackend(ABC):
-    """
-    Interface for Basic Methods on Databases (query, fetch, execute).
-    """
-
-    _test_query: Optional[Any] = None
-
-    def __init__(self) -> None:
-        self._columns: list = []
-        self._attributes = None
-        self._result: list = []
-        self._prepared: Any = None
-
-    @property
-    def columns(self):
-        return self._columns
-
-    def get_columns(self):
-        return self._columns
-
-    @property
-    def result(self):
-        return self._result
-
-    def get_result(self):
-        return self._result
-
-    async def test_connection(self, **kwargs):
-        """Test Connnection.
-        Making a connection Test using the basic Query Method.
-        """
-        if self._test_query is None:
-            raise NotImplementedError()
-        try:
-            return await self.query(self._test_query, **kwargs)
-        except Exception as err:
-            raise DriverError(message=str(err)) from err
-
-    @abstractmethod
-    async def use(self, database: str) -> None:
-        """
-        Change the current Database.
-        """
-        raise NotImplementedError()  # pragma: no cover
-
-    @abstractmethod
-    async def execute(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
-        """
-        Execute a sentence
-        """
-        raise NotImplementedError()  # pragma: no cover
-
-    @abstractmethod
-    async def execute_many(self, sentence: list, *args) -> Optional[Any]:
-        """
-        Execute many sentences at once.
-        """
-
-    @abstractmethod
-    async def query(self, sentence: Union[str, list], **kwargs) -> Optional[Recordset]:
-        """queryrow.
-
-        Making a Query and returns a resultset.
-        Args:
-            sentence (Union[str, list]): sentence(s) to be executed.
-            kwargs: Optional attributes to query.
-
-        Returns:
-            Optional[Record]: Returns a Resultset
-        """
-
-    @abstractmethod
-    async def queryrow(self, sentence: Union[str, list]) -> Optional[Record]:
-        """queryrow.
-
-        Returns a single row of a query sentence.
-        Args:
-            sentence (Union[str, list]): sentence to be executed.
-
-        Returns:
-            Optional[Record]: Return one single row of a query.
-        """
-
-    @abstractmethod
-    async def prepare(self, sentence: Union[str, list]) -> Any:
-        """
-        Making Prepared statement.
-        """
-
-    def prepared_statement(self):
-        return self._prepared
-
-    def prepared_attributes(self):
-        return self._attributes
-
-    @abstractmethod
-    async def fetch_all(self, sentence: str, **kwargs) -> list[Sequence]:
-        pass
-
-    @abstractmethod
-    async def fetch_one(self, sentence: str, **kwargs) -> Optional[dict]:
-        """
-        Fetch only one record, optional getting an offset using "number".
-        """
-
-    async def fetch_val(self, sentence: str, column: Any = None, number: int = None) -> Any:
-        """
-        Fetch the value of a Column in a record.
-        """
-        row = await self.fetch_many(sentence, number)
-        return None if row is None else row[column]
-
-
-class CursorBackend(ABC):
-    """
-    Interface for Database Cursors.
-    """
-
-    def __init__(
-        self, provider: Any, sentence: str, result: Optional[Any] = None, parameters: Iterable[Any] = None, **kwargs
-    ):
-        self._cursor = None
-        self._provider = provider
-        self._result = result
-        self._sentence = sentence
-        self._params = parameters
-        self._connection = self._provider.engine()
-        self._kwargs = kwargs
-
-    ### Magic Context Methods for Cursors.
-    async def __aenter__(self) -> "CursorBackend":
-        self._cursor = await self._connection.cursor()
-        await self._cursor.execute(self._sentence, self._params)
-        return self
-
-    def __enter__(self) -> "CursorBackend":
-        self._cursor = self._connection.cursor()
-        self._cursor.execute(self._sentence, self._params)
-        return self
-
-    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
-        try:
-            return await self._provider.close()
-        except RuntimeError as e:
-            logging.error(str(e))
-        except DriverError as err:
-            logging.exception(err)
-            raise
-
-    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
-        try:
-            return self._provider.close()
-        except DriverError as err:
-            logging.exception(err)
-            raise
-
-    def __aiter__(self) -> "CursorBackend":
-        """The cursor is also an async iterator."""
-        return self
-
-    def __iter__(self) -> "CursorBackend":
-        """The cursor iterator."""
-        return self
-
-    async def __anext__(self):
-        """Use `cursor.fetchrow()` to provide an async iterable.
-
-        raise: StopAsyncIteration when done.
-        """
-        if row := await self._cursor.fetchone() is not None:
-            return row
-        else:
-            raise StopAsyncIteration
-
-    def __next__(self):
-        """Use `cursor.fetchrow()` to provide an iterable.
-
-        raise: StopAsyncIteration when done.
-        """
-        if row := self._cursor.fetchone() is not None:
-            return row
-        else:
-            raise StopAsyncIteration
-
-    ### Cursor Methods.
-    async def fetch_one(self) -> Optional[Sequence]:
-        return await self._cursor.fetchone()
-
-    async def fetch_many(self, size: int = None) -> Iterable[Sequence]:
-        return await self._cursor.fetch(size)
-
-    async def fetch_all(self) -> Iterable[Sequence]:
-        return await self._cursor.fetchall()
-
-
-class DBCursorBackend(ABC):
-    """
-    Interface for Backends with Cursor Support.
-    """
-
-    _provider: str = "base"
-
-    def __init__(self) -> None:
-        self._columns: list = []
-        self._attributes = None
-        self._result: Iterable[Any] = None
-        self._prepared: Any = None
-        self._cursor: Optional[Any] = None
-        try:
-            # dynamic loading of Cursor Class
-            cls = f"asyncdb.drivers.{self._provider}"
-            cursor = f"{self._provider}Cursor"
-            module = import_module(cls, package="drivers")
-            self.__cursor__ = getattr(module, cursor)
-        except ModuleNotFoundError as e:
-            logging.exception(f"Error Loading Cursor Class: {e}")
-            self.__cursor__ = None
-        except ImportError as err:
-            logging.exception(f"Error Loading Cursor Class: {err}")
-            self.__cursor__ = None
-
-    def cursor(self, sentence: Union[str, any], params: Iterable[Any] = None, **kwargs) -> Optional["DBCursorBackend"]:
-        """Returns an iterable Cursor Object"""
-        if not sentence:
-            raise EmptyStatement(f"{__name__!s} Error: Cannot use an empty Sentence.")
-        if params is None:
-            params = []
-        try:
-            return self.__cursor__(provider=self, sentence=sentence, parameters=params, **kwargs)
-        except (TypeError, AttributeError, ValueError) as e:
-            raise TypeError(f"{__name__}: No support for Cursors.") from e
-        except Exception as err:
-            logging.exception(err)
-            raise
-
-    ### Cursor Iterator Context
-    def __aiter__(self):
-        return self
-
-    async def __anext__(self) -> Optional[Record]:
-        """_summary_
-
-        Raises:
-            StopAsyncIteration: raised when end is reached.
-
-        Returns:
-            _type_: Single record for iteration.
-        """
-        if data := await self._cursor.fetchrow() is not None:
-            return data
-        else:
-            raise StopAsyncIteration
-
-
-class ModelBackend(ABC):
-    """
-    Interface for Backends with Dataclass-based Models Support.
-    """
-
-    # ## Class-based Methods.
-    async def _create_(self, _model: Model, rows: list):
-        """
-        Create all records based on a dataset and return result.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        results = []
-        for row in rows:
-            try:
-                record = _model(**row)
-            except (ValueError, ValidationError) as e:
-                raise ValueError(f"Invalid Row for Model {_model}: {e}") from e
-            if record:
-                try:
-                    result = await record.insert()
-                    results.append(result)
-                except Exception as e:
-                    raise DriverError(f"Error on Creation {table}: {e}") from e
-        return results
-
-    @abstractmethod
-    async def _remove_(self, _model: Model, **kwargs):
-        """
-        Deleting some records using Model.
-        """
-
-    @abstractmethod
-    async def _updating_(self, _model: Model, *args, _filter: dict = None, **kwargs):
-        """
-        Updating records using Model.
-        """
-
-    @abstractmethod
-    async def _fetch_(self, _model: Model, *args, **kwargs):
-        """
-        Returns one row from Model.
-        """
-
-    @abstractmethod
-    async def _filter_(self, _model: Model, *args, **kwargs):
-        """
-        Filter a Model using Fields.
-        """
-
-    @abstractmethod
-    async def _select_(self, _model: Model, *args, **kwargs):
-        """
-        Get a query from Model.
-        """
-
-    @abstractmethod
-    async def _all_(self, _model: Model, *args):
-        """
-        Get queries with model.
-        """
-
-    @abstractmethod
-    async def _get_(self, _model: Model, *args, **kwargs):
-        """
-        Get one row from model.
-        """
-
-    @abstractmethod
-    async def _delete_(self, _model: Model, **kwargs):
-        """
-        delete a row from model.
-        """
-
-    @abstractmethod
-    async def _update_(self, _model: Model, **kwargs):
-        """
-        Updating a row in a Model.
-        """
-
-    @abstractmethod
-    async def _save_(self, _model: Model, **kwargs):
-        """
-        Save a row in a Model, using Insert-or-Update methodology.
-        """
-
-    @abstractmethod
-    async def _insert_(self, _model: Model, **kwargs):
-        """
-        insert a row from model.
-        """
-
-    ## Aux Methods:
-    def _get_value(self, field: Field, value: Any) -> Any:
-        datatype = field.type
-        new_val = None
-        if is_dataclass(datatype) and value is not None:
-            if is_missing(value):
-                new_val = None
-            else:
-                new_val = value
-        if inspect.isclass(datatype) and value is None:
-            if isinstance(datatype, (types.BuiltinFunctionType, types.FunctionType)):
-                try:
-                    new_val = datatype()
-                except (TypeError, ValueError, AttributeError):
-                    self._logger.error(f"Error Calling {datatype} in Field {field}")
-                    new_val = None
-        elif callable(datatype) and value is None:
-            new_val = None
-        else:
-            new_val = value
-        return new_val
-
-    def _get_attribute(self, field: Field, value: Any, attr: str = "primary_key") -> Any:
-        if hasattr(field, attr):
-            datatype = field.type
-            if field.primary_key is True:
-                value = Entity.toSQL(value, datatype)
-                return value
-        return None
-
-    def _where(self, fields: dict[Field], **where):
-        if not fields or not where or not isinstance(where, dict):
-            return ""
-        _cond = []
-        for key, value in where.items():
-            f = fields[key]
-            datatype = f.type
-            condition = self._get_condition(key, f, value, datatype)
-            _cond.append(condition)
-        _and = " AND ".join(_cond)
-        result = f"\nWHERE {_and}"
-        return result
-
-    def _get_condition(self, key: str, field: Field, value: Any, datatype: Any) -> str:
-        condition = ""
-        if value is None or value in null_values:
-            condition = f"{key} is NULL"
-        elif value in not_null_values:
-            condition = f"{key} is NOT NULL"
-        elif isinstance(value, bool):
-            val = str(value)
-            condition = f"{key} is {val}"
-        elif isinstance(value, list):
-            null_vals = " OR {key} is NULL" if None in value else ""
-            values = ",".join(self._format_value(v) for v in value)
-            condition = f"({key} = ANY(ARRAY[{values}]){null_vals})"
-        elif isinstance(datatype, (list, List)):
-            val = ", ".join([str(Entity.escapeLiteral(v, type(v))) for v in value])
-            condition = f"ARRAY[{val}]<@ {key}::character varying[]"
-        elif Entity.is_array(datatype):
-            val = ", ".join([str(Entity.escapeLiteral(v, type(v))) for v in value])
-            condition = f"{key} IN ({val})"
-        else:
-            # is an scalar value
-            val = Entity.escapeLiteral(value, datatype)
-            condition = f"{key}={val}"
-        return condition
-
-    def _format_value(self, value):
-        if isinstance(value, str) and value is not None:
-            return f"'{value}'"
-        elif isinstance(value, uuid.UUID) and value is not None:
-            return f"uuid('{value}')"
-        elif value is not None:
-            return str(value)
-        return "NULL"
-
-    # def _where(self, fields: dict[Field], **where):
-    #     """
-    #     TODO: add conditions for BETWEEN, NOT NULL, NULL, etc
-    #        Re-think functionality for parsing where conditions.
-    #     """
-    #     result = ""
-    #     if not fields:
-    #         fields = {}
-    #     if not where:
-    #         return result
-    #     elif isinstance(where, dict):
-    #         _cond = []
-    #         for key, value in where.items():
-    #             f = fields[key]
-    #             datatype = f.type
-    #             if value is None or value in null_values:
-    #                 _cond.append(f"{key} is NULL")
-    #             elif value in not_null_values:
-    #                 _cond.append(f"{key} is NOT NULL")
-    #             elif isinstance(value, bool):
-    #                 val = str(value)
-    #                 _cond.append(f"{key} is {value}")
-    #             elif isinstance(value, list):
-    #                 if None in value:
-    #                     null_vals = f" OR {key} is NULL"
-    #                 else:
-    #                     null_vals = ""
-    #                 values = ",".join(
-    #                     [
-    #                         f"'{v}'"
-    #                         if isinstance(v, str) and v is not None
-    #                         else f"uuid('{v}')"
-    #                         if isinstance(v, uuid.UUID) and v is not None
-    #                         else str(v)
-    #                         if v is not None
-    #                         else "NULL"
-    #                         for v in value
-    #                     ]
-    #                 )
-    #                 _cond.append(f"({key} = ANY(ARRAY[{values}]){null_vals})")
-    #             elif isinstance(datatype, (list, List)):
-    #                 # val = ", ".join(map(str, [Entity.escapeLiteral(v, type(v)) for v in value]))
-    #                 # _cond.append(f"ARRAY[{val}]<@ {key}::character varying[]")
-    #                 val = ", ".join([str(Entity.escapeLiteral(v, type(v))) for v in value])
-    #                 _cond.append(f"ARRAY[{val}]<@ {key}::character varying[]")
-
-    #             elif Entity.is_array(datatype):
-    #                 # val = ", ".join(map(str, [Entity.escapeLiteral(v, type(v)) for v in value]))
-    #                 # _cond.append(f"{key} IN ({val})")
-    #                 val = ", ".join([str(Entity.escapeLiteral(v, type(v))) for v in value])
-    #                 _cond.append(f"{key} IN ({val})")
-    #             else:
-    #                 # is an scalar value
-    #                 val = Entity.escapeLiteral(value, datatype)
-    #                 _cond.append(f"{key}={val}")
-    #         _and = " AND ".join(_cond)
-    #         result = f"\nWHERE {_and}"
-    #         return result
-    #     else:
-    #         return result
+"""
+Basic Interfaces for every kind of Database Connector.
+"""
+import asyncio
+import logging
+import uuid
+import inspect
+import types
+from importlib import import_module
+from collections.abc import Sequence, Iterable, Callable
+from datetime import datetime
+from abc import (
+    ABC,
+    abstractmethod,
+)
+from typing import (
+    Any,
+    List,
+    Optional,
+    Union
+)
+from functools import partial
+from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
+from datamodel.exceptions import ValidationError
+from .meta import Record, Recordset
+from .exceptions import default_exception_handler, DriverError, EmptyStatement
+from .models import Model, Field, is_missing, is_dataclass
+from .utils.types import Entity, SafeDict
+
+null_values = {"null", "NULL"}
+not_null_values = {"!null", "!NULL"}
+
+
+class PoolBackend(ABC):
+    """
+    Basic Interface for Pool-based Connectors.
+    """
+
+    _provider: str = "base"
+    _syntax: str = ""  # Used by QueryParser for parsing queries
+    _init_func: Optional[Callable] = None
+
+    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict[Any] = None, **kwargs) -> None:
+        self._pool = None
+        try:
+            self._encoding = kwargs["encoding"]
+        except KeyError:
+            self._encoding = "utf-8"
+        if "max_queries" in kwargs:
+            self._max_queries = kwargs["max_queries"]
+        else:
+            self._max_queries = 300
+        self._connection = None
+        self._connected = False
+        if loop:
+            self._loop = loop
+            asyncio.set_event_loop(self._loop)
+        else:
+            self._loop = asyncio.get_event_loop()
+            asyncio.set_event_loop(self._loop)
+        if self._loop.is_closed():
+            self._loop = asyncio.get_running_loop()
+            asyncio.set_event_loop(self._loop)
+        # exception handler
+        self._loop.set_exception_handler(default_exception_handler)
+        try:
+            self._debug = bool(params.get("DEBUG", False))
+        except (TypeError, KeyError, AttributeError):
+            try:
+                self._debug = kwargs["debug"]
+            except KeyError:
+                self._debug = False
+        try:
+            self._timeout = kwargs["timeout"]
+        except KeyError:
+            self._timeout = 600
+        # set the logger:
+        try:
+            self._logger = logging.getLogger(name=__name__)
+        except Exception as err:
+            self._logger = None
+            logging.exception(err)
+            raise
+
+    @abstractmethod
+    async def connect(self) -> "PoolBackend":
+        raise NotImplementedError()  # pragma: no cover
+
+    @abstractmethod
+    async def disconnect(self, timeout: int = 5) -> None:
+        raise NotImplementedError()  # pragma: no cover
+
+    close = disconnect
+
+    @abstractmethod
+    async def acquire(self) -> "ConnectionBackend":
+        raise NotImplementedError()  # pragma: no cover
+
+    @abstractmethod
+    async def release(self, connection: "ConnectionBackend" = None, timeout: int = 10) -> None:
+        raise NotImplementedError()  # pragma: no cover
+
+    ### Magic Methods
+    async def __aenter__(self) -> "PoolBackend":
+        if not self._pool:
+            await self.connect()
+        await self.acquire()
+        return self
+
+    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
+        # clean up anything you need to clean up
+        return await self.release(connection=self._connection, timeout=5)
+
+    @property
+    def log(self):
+        return self._logger
+
+    def pool(self):
+        return self._pool
+
+    def get_loop(self):
+        return self._loop
+
+    event_loop = get_loop
+
+    def is_connected(self):
+        return self._connected
+
+    def get_connection(self):
+        return self._pool
+
+    engine = get_connection
+
+    def is_closed(self):
+        if not self._connected:
+            logging.debug(f"Connection closed on: {self._pool}")
+            return True
+        return False
+
+    @classmethod
+    def driver(cls):
+        return cls.__name__
+
+    @classmethod
+    def dialect(cls):
+        return cls._syntax
+
+
+class ConnectionBackend(ABC):
+    """
+    Basic Interface with basic methods for connect and disconnect.
+    """
+
+    _provider: str = "base"
+    _syntax: str = ""  # Used by QueryParser for parsing queries
+    _init_func: Optional[Callable] = None  # a function called when connection is made
+
+    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict[Any] = Any, **kwargs) -> None:
+        self._connection: Callable = None
+        self._connected: bool = False
+        self._cursor = None
+        self._generated: datetime = None
+        self._starttime: datetime = None
+        self._pool = None
+        self._executor = None
+        try:
+            self._encoding = kwargs["encoding"]
+        except KeyError:
+            self._encoding = "utf-8"
+        if "max_queries" in kwargs:
+            self._max_queries = kwargs["max_queries"]
+        else:
+            self._max_queries = 300
+        try:
+            self.params = params.copy()
+        except (TypeError, AttributeError, ValueError):
+            self.params = {}
+        if loop:
+            self._loop = loop
+        else:
+            self._loop = asyncio.get_event_loop()
+        # if self._loop.is_closed():
+        #     self._loop = asyncio.get_running_loop()
+        asyncio.set_event_loop(self._loop)
+        # exception handler
+        self._loop.set_exception_handler(default_exception_handler)
+        try:
+            self._debug = bool(params["DEBUG"])
+        except KeyError:
+            try:
+                self._debug = kwargs["debug"]
+            except KeyError:
+                self._debug = False
+        try:
+            self._timeout = kwargs["timeout"]
+        except KeyError:
+            self._timeout = 600
+        self._logger = logging.getLogger(f"DB.{self.__class__.__name__}")
+
+    @abstractmethod
+    async def connection(self) -> Any:
+        raise NotImplementedError()  # pragma: no cover
+
+    def set_connection(self, connection):
+        self._connection = connection
+
+    @abstractmethod
+    async def close(self, timeout: int = 10) -> None:
+        raise NotImplementedError()  # pragma: no cover
+
+    def is_closed(self):
+        if not self._connected:
+            logging.debug(f"Connection closed on: {self._pool}")
+            return True
+        return False
+
+    # Properties
+    @classmethod
+    def type(cls):
+        return cls._provider
+
+    @property
+    def log(self):
+        return self._logger
+
+    def pool(self):
+        return self._pool
+
+    def get_loop(self):
+        return self._loop
+
+    event_loop = get_loop
+
+    def is_connected(self):
+        return bool(self._connected)
+
+    def get_connection(self):
+        return self._connection
+
+    engine = get_connection
+
+    @property
+    def raw_connection(self) -> Any:
+        return self._connection
+
+    def start_timing(self):
+        self._starttime = datetime.now()
+        return self._starttime
+
+    def generated_at(self, started: datetime = None):
+        if not started:
+            started = datetime.now()
+        try:
+            self._generated = started - self._starttime
+        except TypeError:
+            return None
+        return self._generated
+
+    def last_duration(self):
+        return self._generated
+
+    @classmethod
+    def driver(cls):
+        return cls.__name__
+
+    @classmethod
+    def dialect(cls):
+        return cls._syntax
+
+    ### Async Context magic Methods
+    async def __aenter__(self) -> "ConnectionBackend":
+        if not self._connection:
+            await self.connection()
+        return self
+
+    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
+        # clean up anything you need to clean up
+        try:
+            await asyncio.wait_for(self.close(), timeout=20)
+        except asyncio.TimeoutError as e:
+            self._logger.warning(f"Close timed out: {e}")
+        except RuntimeError as e:
+            self._logger.error(str(e))
+        except Exception as err:
+            self._logger.exception(f"Closing Error: {err}")
+            raise
+
+    def get_executor(self, executor="thread", max_workers: int = 2) -> Any:
+        if executor == "thread":
+            return ThreadPoolExecutor(max_workers=max_workers)
+        elif executor == "process":
+            return ProcessPoolExecutor(max_workers=max_workers)
+        else:
+            return None
+
+    async def _thread_func(self, fn, *args, executor: Any = None, **kwargs):
+        """_execute.
+
+        Returns a future to be executed into a Thread Pool.
+        """
+        loop = asyncio.get_event_loop()
+        func = partial(fn, *args, **kwargs)
+        if not executor:
+            executor = self._executor
+        try:
+            fut = loop.run_in_executor(executor, func)
+            return await fut
+        except Exception as e:
+            self._logger.exception(e, stack_info=True)
+            raise
+
+
+class ConnectionDSNBackend(ABC):
+    """
+    Interface for Databases with DSN Support.
+    """
+
+    _logger: Any = None
+
+    def __init__(self, dsn: str = None, params: Optional[dict] = None) -> None:
+        if dsn:
+            self._dsn = dsn
+        else:
+            self._dsn = self.create_dsn(params)
+        try:
+            self._params = params.copy()
+        except (TypeError, AttributeError, ValueError):
+            self._params = {}
+        # Executor:
+        self._executor = None
+
+    def create_dsn(self, params: dict):
+        try:
+            if params:
+                return self._dsn.format_map(SafeDict(**params))
+            else:
+                return None
+        except TypeError as err:
+            self._logger.exception(err)
+            raise DriverError(f"Error creating DSN connection: {err}") from err
+
+    def get_dsn(self):
+        return self._dsn
+
+    def get_executor(self, executor="thread", max_workers: int = 2) -> Any:
+        if executor == "thread":
+            return ThreadPoolExecutor(max_workers=max_workers)
+        elif executor == "process":
+            return ProcessPoolExecutor(max_workers=max_workers)
+        else:
+            return None
+
+    async def _thread_func(self, fn, *args, executor: Any = None, **kwargs):
+        """_execute.
+
+        Returns a future to be executed into a Thread Pool.
+        """
+        loop = asyncio.get_event_loop()
+        func = partial(fn, *args, **kwargs)
+        if not executor:
+            executor = self._executor
+        try:
+            fut = loop.run_in_executor(executor, func)
+            return await fut
+        except Exception as e:
+            self._logger.exception(e, stack_info=True)
+            raise
+
+
+class TransactionBackend(ABC):
+    """
+    Interface for Drivers with Transaction Support.
+    """
+
+    def __init__(self):
+        self._connection = None
+        self._transaction = None
+
+    @abstractmethod
+    async def transaction(self, options: dict[Any]) -> Any:
+        """
+        Getting a Transaction Object.
+        """
+        raise NotImplementedError()  # pragma: no cover
+
+    async def transaction_start(self, options: dict) -> None:
+        """
+        Starts a Transaction.
+        """
+        self._transaction = self.transaction(options)
+
+    @abstractmethod
+    async def commit(self) -> None:
+        pass
+
+    @abstractmethod
+    async def rollback(self) -> None:
+        pass
+
+
+class DatabaseBackend(ABC):
+    """
+    Interface for Basic Methods on Databases (query, fetch, execute).
+    """
+
+    _test_query: Optional[Any] = None
+
+    def __init__(self) -> None:
+        self._columns: list = []
+        self._attributes = None
+        self._result: list = []
+        self._prepared: Any = None
+
+    @property
+    def columns(self):
+        return self._columns
+
+    def get_columns(self):
+        return self._columns
+
+    @property
+    def result(self):
+        return self._result
+
+    def get_result(self):
+        return self._result
+
+    async def test_connection(self, **kwargs):
+        """Test Connnection.
+        Making a connection Test using the basic Query Method.
+        """
+        if self._test_query is None:
+            raise NotImplementedError()
+        try:
+            return await self.query(self._test_query, **kwargs)
+        except Exception as err:
+            raise DriverError(message=str(err)) from err
+
+    @abstractmethod
+    async def use(self, database: str) -> None:
+        """
+        Change the current Database.
+        """
+        raise NotImplementedError()  # pragma: no cover
+
+    @abstractmethod
+    async def execute(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
+        """
+        Execute a sentence
+        """
+        raise NotImplementedError()  # pragma: no cover
+
+    @abstractmethod
+    async def execute_many(self, sentence: list, *args) -> Optional[Any]:
+        """
+        Execute many sentences at once.
+        """
+
+    @abstractmethod
+    async def query(self, sentence: Union[str, list], **kwargs) -> Optional[Recordset]:
+        """queryrow.
+
+        Making a Query and returns a resultset.
+        Args:
+            sentence (Union[str, list]): sentence(s) to be executed.
+            kwargs: Optional attributes to query.
+
+        Returns:
+            Optional[Record]: Returns a Resultset
+        """
+
+    @abstractmethod
+    async def queryrow(self, sentence: Union[str, list]) -> Optional[Record]:
+        """queryrow.
+
+        Returns a single row of a query sentence.
+        Args:
+            sentence (Union[str, list]): sentence to be executed.
+
+        Returns:
+            Optional[Record]: Return one single row of a query.
+        """
+
+    @abstractmethod
+    async def prepare(self, sentence: Union[str, list]) -> Any:
+        """
+        Making Prepared statement.
+        """
+
+    def prepared_statement(self):
+        return self._prepared
+
+    def prepared_attributes(self):
+        return self._attributes
+
+    @abstractmethod
+    async def fetch_all(self, sentence: str, **kwargs) -> list[Sequence]:
+        pass
+
+    @abstractmethod
+    async def fetch_one(self, sentence: str, **kwargs) -> Optional[dict]:
+        """
+        Fetch only one record, optional getting an offset using "number".
+        """
+
+    async def fetch_val(self, sentence: str, column: Any = None, number: int = None) -> Any:
+        """
+        Fetch the value of a Column in a record.
+        """
+        row = await self.fetch_many(sentence, number)
+        return None if row is None else row[column]
+
+
+class CursorBackend(ABC):
+    """
+    Interface for Database Cursors.
+    """
+
+    def __init__(
+        self, provider: Any, sentence: str, result: Optional[Any] = None, parameters: Iterable[Any] = None, **kwargs
+    ):
+        self._cursor = None
+        self._provider = provider
+        self._result = result
+        self._sentence = sentence
+        self._params = parameters
+        self._connection = self._provider.engine()
+        self._kwargs = kwargs
+
+    ### Magic Context Methods for Cursors.
+    async def __aenter__(self) -> "CursorBackend":
+        self._cursor = await self._connection.cursor()
+        await self._cursor.execute(self._sentence, self._params)
+        return self
+
+    def __enter__(self) -> "CursorBackend":
+        self._cursor = self._connection.cursor()
+        self._cursor.execute(self._sentence, self._params)
+        return self
+
+    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
+        try:
+            return await self._provider.close()
+        except RuntimeError as e:
+            logging.error(str(e))
+        except DriverError as err:
+            logging.exception(err)
+            raise
+
+    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
+        try:
+            return self._provider.close()
+        except DriverError as err:
+            logging.exception(err)
+            raise
+
+    def __aiter__(self) -> "CursorBackend":
+        """The cursor is also an async iterator."""
+        return self
+
+    def __iter__(self) -> "CursorBackend":
+        """The cursor iterator."""
+        return self
+
+    async def __anext__(self):
+        """Use `cursor.fetchrow()` to provide an async iterable.
+
+        raise: StopAsyncIteration when done.
+        """
+        if row := await self._cursor.fetchone() is not None:
+            return row
+        else:
+            raise StopAsyncIteration
+
+    def __next__(self):
+        """Use `cursor.fetchrow()` to provide an iterable.
+
+        raise: StopAsyncIteration when done.
+        """
+        if row := self._cursor.fetchone() is not None:
+            return row
+        else:
+            raise StopAsyncIteration
+
+    ### Cursor Methods.
+    async def fetch_one(self) -> Optional[Sequence]:
+        return await self._cursor.fetchone()
+
+    async def fetch_many(self, size: int = None) -> Iterable[Sequence]:
+        return await self._cursor.fetch(size)
+
+    async def fetch_all(self) -> Iterable[Sequence]:
+        return await self._cursor.fetchall()
+
+
+class DBCursorBackend(ABC):
+    """
+    Interface for Backends with Cursor Support.
+    """
+
+    _provider: str = "base"
+
+    def __init__(self) -> None:
+        self._columns: list = []
+        self._attributes = None
+        self._result: Iterable[Any] = None
+        self._prepared: Any = None
+        self._cursor: Optional[Any] = None
+        try:
+            # dynamic loading of Cursor Class
+            cls = f"asyncdb.drivers.{self._provider}"
+            cursor = f"{self._provider}Cursor"
+            module = import_module(cls, package="drivers")
+            self.__cursor__ = getattr(module, cursor)
+        except ModuleNotFoundError as e:
+            logging.exception(f"Error Loading Cursor Class: {e}")
+            self.__cursor__ = None
+        except ImportError as err:
+            logging.exception(f"Error Loading Cursor Class: {err}")
+            self.__cursor__ = None
+
+    def cursor(self, sentence: Union[str, any], params: Iterable[Any] = None, **kwargs) -> Optional["DBCursorBackend"]:
+        """Returns an iterable Cursor Object"""
+        if not sentence:
+            raise EmptyStatement(f"{__name__!s} Error: Cannot use an empty Sentence.")
+        if params is None:
+            params = []
+        try:
+            return self.__cursor__(provider=self, sentence=sentence, parameters=params, **kwargs)
+        except (TypeError, AttributeError, ValueError) as e:
+            raise TypeError(f"{__name__}: No support for Cursors.") from e
+        except Exception as err:
+            logging.exception(err)
+            raise
+
+    ### Cursor Iterator Context
+    def __aiter__(self):
+        return self
+
+    async def __anext__(self) -> Optional[Record]:
+        """_summary_
+
+        Raises:
+            StopAsyncIteration: raised when end is reached.
+
+        Returns:
+            _type_: Single record for iteration.
+        """
+        if data := await self._cursor.fetchrow() is not None:
+            return data
+        else:
+            raise StopAsyncIteration
+
+
+class ModelBackend(ABC):
+    """
+    Interface for Backends with Dataclass-based Models Support.
+    """
+
+    # ## Class-based Methods.
+    async def _create_(self, _model: Model, rows: list):
+        """
+        Create all records based on a dataset and return result.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        results = []
+        for row in rows:
+            try:
+                record = _model(**row)
+            except (ValueError, ValidationError) as e:
+                raise ValueError(f"Invalid Row for Model {_model}: {e}") from e
+            if record:
+                try:
+                    result = await record.insert()
+                    results.append(result)
+                except Exception as e:
+                    raise DriverError(f"Error on Creation {table}: {e}") from e
+        return results
+
+    @abstractmethod
+    async def _remove_(self, _model: Model, **kwargs):
+        """
+        Deleting some records using Model.
+        """
+
+    @abstractmethod
+    async def _updating_(self, _model: Model, *args, _filter: dict = None, **kwargs):
+        """
+        Updating records using Model.
+        """
+
+    @abstractmethod
+    async def _fetch_(self, _model: Model, *args, **kwargs):
+        """
+        Returns one row from Model.
+        """
+
+    @abstractmethod
+    async def _filter_(self, _model: Model, *args, **kwargs):
+        """
+        Filter a Model using Fields.
+        """
+
+    @abstractmethod
+    async def _select_(self, _model: Model, *args, **kwargs):
+        """
+        Get a query from Model.
+        """
+
+    @abstractmethod
+    async def _all_(self, _model: Model, *args):
+        """
+        Get queries with model.
+        """
+
+    @abstractmethod
+    async def _get_(self, _model: Model, *args, **kwargs):
+        """
+        Get one row from model.
+        """
+
+    @abstractmethod
+    async def _delete_(self, _model: Model, **kwargs):
+        """
+        delete a row from model.
+        """
+
+    @abstractmethod
+    async def _update_(self, _model: Model, **kwargs):
+        """
+        Updating a row in a Model.
+        """
+
+    @abstractmethod
+    async def _save_(self, _model: Model, **kwargs):
+        """
+        Save a row in a Model, using Insert-or-Update methodology.
+        """
+
+    @abstractmethod
+    async def _insert_(self, _model: Model, **kwargs):
+        """
+        insert a row from model.
+        """
+
+    ## Aux Methods:
+    def _get_value(self, field: Field, value: Any) -> Any:
+        datatype = field.type
+        new_val = None
+        if is_dataclass(datatype) and value is not None:
+            if is_missing(value):
+                new_val = None
+            else:
+                new_val = value
+        if inspect.isclass(datatype) and value is None:
+            if isinstance(datatype, (types.BuiltinFunctionType, types.FunctionType)):
+                try:
+                    new_val = datatype()
+                except (TypeError, ValueError, AttributeError):
+                    self._logger.error(f"Error Calling {datatype} in Field {field}")
+                    new_val = None
+        elif callable(datatype) and value is None:
+            new_val = None
+        else:
+            new_val = value
+        return new_val
+
+    def _get_attribute(self, field: Field, value: Any, attr: str = "primary_key") -> Any:
+        if hasattr(field, attr):
+            datatype = field.type
+            if field.primary_key is True:
+                value = Entity.toSQL(value, datatype)
+                return value
+        return None
+
+    def _where(self, fields: dict[Field], **where):
+        """
+        TODO: add conditions for BETWEEN, NOT NULL, NULL, etc
+           Re-think functionality for parsing where conditions.
+        """
+        if not fields or not where or not isinstance(where, dict):
+            return ""
+        _cond = []
+        for k, v in where.items():
+            f = fields[k]
+            datatype = f.type
+            condition = self._get_condition(k, f, v, datatype)
+            _cond.append(condition)
+        _and = " AND ".join(_cond)
+        result = f"\nWHERE {_and}"
+        return result
+
+    def _get_condition(self, key: str, field: Field, value: Any, datatype: Any) -> str:
+        condition = ""
+        if isinstance(value, list):
+            null_vals = f" OR {key} is NULL" if None in value else ""
+            values = ",".join(self._format_value(v) for v in value)
+            condition = f"({key} = ANY(ARRAY[{values}]){null_vals})"
+        elif value is None or value in null_values:
+            condition = f"{key} is NULL"
+        elif value in not_null_values:
+            condition = f"{key} is NOT NULL"
+        elif isinstance(value, bool):
+            val = str(value)
+            condition = f"{key} is {val}"
+        elif isinstance(datatype, (list, List)):  # pylint: disable=W6001
+            val = ", ".join([str(Entity.escapeLiteral(v, type(v))) for v in value])
+            condition = f"ARRAY[{val}]<@ {key}::character varying[]"
+        elif Entity.is_array(datatype):
+            val = ", ".join([str(Entity.escapeLiteral(v, type(v))) for v in value])
+            condition = f"{key} IN ({val})"
+        else:
+            # is an scalar value
+            val = Entity.escapeLiteral(value, datatype)
+            condition = f"{key}={val}"
+        return condition
+
+    def _format_value(self, value):
+        if isinstance(value, str) and value is not None:
+            return f"'{value}'"
+        elif isinstance(value, uuid.UUID) and value is not None:
+            return f"uuid('{value}')"
+        elif value is not None:
+            return str(value)
+        return "NULL"
```

## asyncdb/connections.py

```diff
@@ -1,45 +1,44 @@
-import logging
-
-from .exceptions import DriverError
-from .interfaces import ConnectionBackend, PoolBackend
-from .utils.modules import module_exists
-from .utils import install_uvloop
-
-
-install_uvloop()
-
-
-class AsyncPool:
-    """
-    AsyncPool.
-       Base class for Asyncio-based DB Pools.
-       Factory interface for Pool-based connectors.
-    """
-
-    def __new__(cls, driver: str = "dummy", **kwargs) -> PoolBackend:
-        classpath = f"asyncdb.drivers.{driver}"
-        pool = f"{driver}Pool"
-        try:
-            mdl = module_exists(pool, classpath)
-            obj = mdl(**kwargs)
-            return obj
-        except Exception as err:
-            logging.exception(err)
-            raise DriverError(message=f"Cannot Load Backend Pool: {pool}") from err
-
-
-class AsyncDB:
-    """AsyncDB.
-
-    Factory Proxy Interface for Database Providers.
-    """
-
-    def __new__(cls, driver: str = "dummy", **kwargs) -> ConnectionBackend:
-        classpath = f"asyncdb.drivers.{driver}"
-        try:
-            mdl = module_exists(driver, classpath)
-            obj = mdl(**kwargs)
-            return obj
-        except Exception as err:
-            logging.exception(err)
-            raise DriverError(message=f"Cannot Load Backend {driver}") from err
+import logging
+from .exceptions import DriverError
+from .interfaces import ConnectionBackend, PoolBackend
+from .utils.modules import module_exists
+from .utils import install_uvloop
+
+
+install_uvloop()
+
+
+class AsyncPool:
+    """
+    AsyncPool.
+       Base class for Asyncio-based DB Pools.
+       Factory interface for Pool-based connectors.
+    """
+
+    def __new__(cls, driver: str = "dummy", **kwargs) -> PoolBackend:
+        classpath = f"asyncdb.drivers.{driver}"
+        pool = f"{driver}Pool"
+        try:
+            mdl = module_exists(pool, classpath)
+            obj = mdl(**kwargs)
+            return obj
+        except Exception as err:
+            logging.exception(err)
+            raise DriverError(message=f"Cannot Load Backend Pool: {pool}") from err
+
+
+class AsyncDB:
+    """AsyncDB.
+
+    Factory Proxy Interface for Database Providers.
+    """
+
+    def __new__(cls, driver: str = "dummy", **kwargs) -> ConnectionBackend:
+        classpath = f"asyncdb.drivers.{driver}"
+        try:
+            mdl = module_exists(driver, classpath)
+            obj = mdl(**kwargs)
+            return obj
+        except Exception as err:
+            logging.exception(err)
+            raise DriverError(message=f"Cannot Load Backend {driver}") from err
```

## asyncdb/__init__.py

 * *Ordering differences only*

```diff
@@ -1,21 +1,21 @@
-# -*- coding: utf-8 -*-
-"""AsyncDB.
-
-Asyncio-based database connectors.
-"""
-from pathlib import Path
-
-from .connections import AsyncDB, AsyncPool
-from .version import __author__, __author_email__, __description__, __title__, __version__
-
-
-def get_project_root() -> Path:
-    return Path(__file__).parent.parent
-
-
-ABS_PATH = get_project_root()
-
-__all__ = (
-    "AsyncDB",
-    "AsyncPool",
-)
+# -*- coding: utf-8 -*-
+"""AsyncDB.
+
+Asyncio-based database connectors.
+"""
+from pathlib import Path
+
+from .connections import AsyncDB, AsyncPool
+from .version import __author__, __author_email__, __description__, __title__, __version__
+
+
+def get_project_root() -> Path:
+    return Path(__file__).parent.parent
+
+
+ABS_PATH = get_project_root()
+
+__all__ = (
+    "AsyncDB",
+    "AsyncPool",
+)
```

## asyncdb/version.py

```diff
@@ -1,9 +1,9 @@
-"""AsyncDB Meta information."""
-
-__title__ = "asyncdb"
-__description__ = "Library for Asynchronous data source connections \
-    Collection of asyncio drivers."
-__version__ = "2.6.9"
-__author__ = "Jesus Lara"
-__author_email__ = "jesuslarag@gmail.com"
-__license__ = "BSD"
+"""AsyncDB Meta information."""
+
+__title__ = "asyncdb"
+__description__ = "Library for Asynchronous data source connections \
+    Collection of asyncio drivers."
+__version__ = "2.7.0"
+__author__ = "Jesus Lara"
+__author_email__ = "jesuslarag@gmail.com"
+__license__ = "BSD"
```

## asyncdb/drivers/bigquery.py

```diff
@@ -1,311 +1,312 @@
-import os
-from typing import Any
-from collections.abc import Iterable
-from pathlib import Path
-import asyncio
-import pandas_gbq
-import pandas as pd
-from google.cloud import bigquery as bq
-from google.cloud.exceptions import Conflict
-from google.oauth2 import service_account
-
-from asyncdb.exceptions import DriverError
-from .sql import SQLDriver
-
-
-class bigquery(SQLDriver):
-    _provider = "bigquery"
-    _syntax = "sql"
-    _test_query = "SELECT 1"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._credentials = params.get("credentials", None)
-        if self._credentials:
-            self._credentials = Path(self._credentials).expanduser().resolve()
-        self._account = None
-        self._dsn = ""
-        self._project_id = params.get("project_id", None)
-        super().__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-        if not self._credentials:
-            self._account = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS", None)
-        if self._account is None and self._credentials is None:
-            raise DriverError("BigQuery: Missing account Credentials")
-        self._connection = None  # BigQuery does not use traditional connections
-
-    async def connection(self):
-        """Initialize BigQuery client.
-        # Assuming that authentication is handled outside (via environment variables or similar)
-        """
-        try:
-            if self._credentials:  # usage of explicit credentials
-                self.credentials = service_account.Credentials.from_service_account_file(self._credentials)
-                if not self._project_id:
-                    self._project_id = self.credentials.project_id
-                self._connection = bq.Client(credentials=self.credentials, project=self._project_id)
-                self._connected = True
-            else:
-                self.credentials = self._account
-                self._connection = bq.Client(project=self._project_id)
-        except Exception as e:
-            raise DriverError(f"BigQuery: Error initializing client: {e}")
-        return self
-
-    async def close(self):
-        # BigQuery client does not maintain persistent connections, so nothing to close here.
-        self._connected = False
-
-    disconnect = close
-
-    async def execute(self, query, **kwargs):
-        """
-        Execute a BigQuery query
-        """
-        if not self._connection:
-            await self.connection()
-        try:
-            job = self._connection.query(query, **kwargs)
-            result = job.result()  # Waits for the query to finish
-            return result
-        except Exception as e:
-            raise DriverError(f"BigQuery: Error executing query: {e}")
-
-    async def execute_many(self, query, **kwargs):
-        """
-        Execute a BigQuery query
-        """
-        if not self._connection:
-            await self.connection()
-        try:
-            job = self._connection.query(query, **kwargs)
-            result = job.result()  # Waits for the query to finish
-            return result
-        except Exception as e:
-            raise DriverError(f"BigQuery: Error executing query: {e}")
-
-    async def prepare(self, sentence: str, **kwargs):
-        pass
-
-    def get_query_config(self, **kwargs):
-        return bq.QueryJobConfig(**kwargs)
-
-    def get_load_config(self, **kwargs):
-        args = {}
-        _type = kwargs.pop("type", "json")
-        if _type == "json":
-            args = {"source_format": bq.SourceFormat.NEWLINE_DELIMITED_JSON, "autodetect": True}
-        args = {**kwargs, **args}
-        return bq.LoadJobConfig(**args)
-
-    async def create_dataset(self, dataset_id: str):
-        try:
-            dataset_ref = bq.DatasetReference(self._connection.project, dataset_id)
-            dataset_obj = bq.Dataset(dataset_ref)
-            dataset_obj = self._connection.create_dataset(dataset_obj)
-            return dataset_obj
-        except Conflict:
-            self._logger.warning(f"Dataset {self._connection.project}.{dataset_obj.dataset_id} already exists")
-            return dataset_obj
-        except Exception as exc:
-            self._logger.error(f"Error creating Dataset: {exc}")
-            raise DriverError(f"Error creating Dataset: {exc}")
-
-    async def create_table(self, dataset_id, table_id, schema):
-        """
-        Create a new table in the specified BigQuery dataset.
-        :param dataset_id: The ID of the dataset
-        :param table_id: The ID of the table to create
-        :param schema: A list of google.cloud.bigquery.SchemaField objects
-        """
-        if not self._connection:
-            await self.connection()
-
-        dataset_ref = bq.DatasetReference(self._connection.project, dataset_id)
-        table_ref = dataset_ref.table(table_id)
-        table = bq.Table(table_ref, schema=schema)
-        try:
-            table = self._connection.create_table(table)  # API request
-            self._logger.info(f"Created table {table.project}.{table.dataset_id}.{table.table_id}")
-            return table
-        except Conflict:
-            self._logger.warning(f"Table {table.project}.{table.dataset_id}.{table.table_id} already exists")
-            return table
-        except Exception as e:
-            raise DriverError(f"BigQuery: Error creating table: {e}")
-
-    async def truncate_table(self, table_id: str, dataset_id: str):
-        """
-        Truncate a BigQuery table by overwriting with an empty table.
-        """
-        if not self._connection:
-            await self.connection()
-
-        # Construct a reference to the dataset
-        dataset_ref = bq.DatasetReference(self._connection.project, dataset_id)
-        table_ref = dataset_ref.table(table_id)
-        table = self._connection.get_table(table_ref)  # API request to fetch the table schema
-
-        # Create an empty table with the same schema
-        job_config = bq.QueryJobConfig(destination=table_ref)
-        job_config.write_disposition = bq.WriteDisposition.WRITE_TRUNCATE
-
-        try:
-            job = self._connection.query(f"SELECT * FROM `{table_ref}` WHERE FALSE", job_config=job_config)
-            job.result()  # Wait for the job to finish
-            self._logger.info(f"Truncated table {dataset_id}.{table_id}")
-        except Exception as e:
-            raise DriverError(f"BigQuery: Error truncating table: {e}")
-
-    async def query(self, sentence: str, **kwargs):
-        if not self._connection:
-            await self.connection()
-        await self.valid_operation(sentence)
-        self.start_timing()
-        error = None
-        try:
-            job = self._connection.query(sentence, **kwargs)
-            result = job.result()  # Waits for the query to finish
-        except Exception as e:
-            error = f"BigQuery: Error executing query: {e}"
-        finally:
-            self.generated_at()
-            if error:
-                return [None, error]
-            return await self._serializer(result, error)  # pylint: disable=W0150
-
-    async def queryrow(self, sentence: str):
-        pass
-
-    async def fetch(self, sentence: str, use_pandas: bool = False, **kwargs):
-        """fetch.
-
-        Get a Query directly into a Pandas Dataframe.
-        Args:
-            sentence (str): Query to be executed.
-        """
-        if not self._connection:
-            await self.connection()
-        await self.valid_operation(sentence)
-        self.start_timing()
-        error = None
-        try:
-            if use_pandas is True:
-                result = pandas_gbq.read_gbq(
-                    sentence,
-                    project_id=self._project_id,
-                    credentials=self.credentials,
-                    dialect="standard",
-                    use_bqstorage_api=True,
-                    **kwargs,
-                )
-            else:
-                result = self._connection.query(sentence, **kwargs).to_dataframe()
-        except Exception as e:
-            error = f"BigQuery: Error executing Fetch: {e}"
-        finally:
-            self.generated_at()
-            if error:
-                return [None, error]
-            return (result, error)  # pylint: disable=W0150
-
-    async def fetch_all(self, query, *args):
-        """
-        Fetch all results from a BigQuery query
-        """
-        results = await self.execute(query, *args)
-        return results
-
-    async def fetch_one(self, query, *args):
-        """
-        Fetch all results from a BigQuery query
-        """
-        results = await self.execute(query, *args)
-        return [dict(row) for row in results]
-
-    async def write(
-        self,
-        table_id: str,
-        data,
-        dataset_id: str = None,
-        use_streams: bool = False,
-        use_pandas: bool = False,
-        if_exists: str = "append",
-        **kwargs,
-    ):
-        """
-        Write data to a BigQuery table
-        """
-        if not self._connection:
-            await self.connection()
-        try:
-            if isinstance(data, pd.DataFrame):
-                if use_pandas is True:
-                    job = await self._thread_func(
-                        self._connection.load_table_from_dataframe, data, table_id, if_exists=if_exists, **kwargs
-                    )
-                else:
-                    job = await self._thread_func(
-                        data.to_gbq, table_id, project_id=self._project_id, if_exists=if_exists
-                    )
-            elif isinstance(data, list):
-                dataset_ref = self._connection.dataset(dataset_id)
-                table_ref = dataset_ref.table(table_id)
-                table = bq.Table(table_ref)
-                if use_streams is True:
-                    errors = await self._thread_func(self._connection.insert_rows_json, table, data, **kwargs)
-                    if errors:
-                        raise RuntimeError(f"Errors occurred while inserting rows: {errors}")
-                else:
-                    job = await self._thread_func(self._connection.load_table_from_json, table, data, **kwargs)
-                    loop = asyncio.get_event_loop()
-                    await loop.run_in_executor(None, job.result)
-                    if job.errors and len(job.errors) > 0:
-                        raise RuntimeError(f"Job failed with errors: {job.errors}")
-                    else:
-                        self._logger.info(f"Loaded {len(data)} rows into {table_id}")
-
-            self._logger.info(f"Inserted rows into {table_id}")
-        except Exception as e:
-            raise DriverError(f"BigQuery: Error writing to table: {e}")
-
-    async def load_table_from_uri(
-        self,
-        source_uri: str,
-        table: Any = None,
-        job_config=None,
-        dataset_id: str = None,
-        table_id: str = None,
-    ):
-        """
-        Load a BigQuery table from a Google Cloud Storage URI
-        """
-        if not self._connection:
-            await self.connection()
-        if not table:
-            dataset_ref = self._connection.dataset(dataset_id)
-            table_ref = dataset_ref.table(table_id)
-            table = bq.Table(table_ref)
-        try:
-            job = await self._thread_func(
-                self._connection.load_table_from_uri, source_uri, table, job_config=job_config
-            )
-            job.result()  # Waits for table load to complete.
-            self._logger.info(f"Loaded {job.output_rows} rows into {table.project}.{table.dataset_id}.{table.table_id}")
-            return job
-        except Exception as e:
-            raise DriverError(f"BigQuery: Error loading table from URI: {e}")
-
-    @property
-    def connected(self):
-        return self._connection is not None
-
-    def is_connected(self):
-        return self._connected
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    async def use(self, database: str):
-        raise NotImplementedError  # pragma: no cover
+import os
+from typing import Any
+from collections.abc import Iterable
+from pathlib import Path
+import asyncio
+import pandas_gbq
+import pandas as pd
+from google.cloud import bigquery as bq
+from google.cloud.exceptions import Conflict
+from google.oauth2 import service_account
+from ..exceptions import DriverError
+from .sql import SQLDriver
+
+
+class bigquery(SQLDriver):
+    _provider = "bigquery"
+    _syntax = "sql"
+    _test_query = "SELECT 1"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._credentials = params.get("credentials", None)
+        if self._credentials:
+            self._credentials = Path(self._credentials).expanduser().resolve()
+        self._account = None
+        self._dsn = ""
+        self._project_id = params.get("project_id", None)
+        super().__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+        if not self._credentials:
+            self._account = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS", None)
+        if self._account is None and self._credentials is None:
+            raise DriverError("BigQuery: Missing account Credentials")
+        self._connection = None  # BigQuery does not use traditional connections
+
+    async def connection(self):
+        """Initialize BigQuery client.
+        # Assuming that authentication is handled outside (via environment variables or similar)
+        """
+        try:
+            if self._credentials:  # usage of explicit credentials
+                self.credentials = service_account.Credentials.from_service_account_file(self._credentials)
+                if not self._project_id:
+                    self._project_id = self.credentials.project_id
+                self._connection = bq.Client(credentials=self.credentials, project=self._project_id)
+                self._connected = True
+            else:
+                self.credentials = self._account
+                self._connection = bq.Client(project=self._project_id)
+        except Exception as e:
+            raise DriverError(f"BigQuery: Error initializing client: {e}")
+        return self
+
+    async def close(self):
+        # BigQuery client does not maintain persistent connections, so nothing to close here.
+        self._connected = False
+
+    disconnect = close
+
+    async def execute(self, query, **kwargs):
+        """
+        Execute a BigQuery query
+        """
+        if not self._connection:
+            await self.connection()
+        try:
+            job = self._connection.query(query, **kwargs)
+            result = job.result()  # Waits for the query to finish
+            return result
+        except Exception as e:
+            raise DriverError(f"BigQuery: Error executing query: {e}")
+
+    async def execute_many(self, query, **kwargs):
+        """
+        Execute a BigQuery query
+        """
+        if not self._connection:
+            await self.connection()
+        try:
+            job = self._connection.query(query, **kwargs)
+            result = job.result()  # Waits for the query to finish
+            return result
+        except Exception as e:
+            raise DriverError(f"BigQuery: Error executing query: {e}")
+
+    async def prepare(self, sentence: str, **kwargs):
+        pass
+
+    def get_query_config(self, **kwargs):
+        return bq.QueryJobConfig(**kwargs)
+
+    def get_load_config(self, **kwargs):
+        args = {}
+        _type = kwargs.pop("type", "json")
+        if _type == "json":
+            args = {"source_format": bq.SourceFormat.NEWLINE_DELIMITED_JSON, "autodetect": True}
+        args = {**kwargs, **args}
+        return bq.LoadJobConfig(**args)
+
+    async def create_dataset(self, dataset_id: str):
+        try:
+            dataset_ref = bq.DatasetReference(self._connection.project, dataset_id)
+            dataset_obj = bq.Dataset(dataset_ref)
+            dataset_obj = self._connection.create_dataset(dataset_obj)
+            return dataset_obj
+        except Conflict:
+            self._logger.warning(f"Dataset {self._connection.project}.{dataset_obj.dataset_id} already exists")
+            return dataset_obj
+        except Exception as exc:
+            self._logger.error(f"Error creating Dataset: {exc}")
+            raise DriverError(f"Error creating Dataset: {exc}")
+
+    async def create_table(self, dataset_id, table_id, schema):
+        """
+        Create a new table in the specified BigQuery dataset.
+        :param dataset_id: The ID of the dataset
+        :param table_id: The ID of the table to create
+        :param schema: A list of google.cloud.bigquery.SchemaField objects
+        """
+        if not self._connection:
+            await self.connection()
+
+        dataset_ref = bq.DatasetReference(self._connection.project, dataset_id)
+        table_ref = dataset_ref.table(table_id)
+        table = bq.Table(table_ref, schema=schema)
+        try:
+            table = self._connection.create_table(table)  # API request
+            self._logger.info(f"Created table {table.project}.{table.dataset_id}.{table.table_id}")
+            return table
+        except Conflict:
+            self._logger.warning(f"Table {table.project}.{table.dataset_id}.{table.table_id} already exists")
+            return table
+        except Exception as e:
+            raise DriverError(f"BigQuery: Error creating table: {e}")
+
+    async def truncate_table(self, table_id: str, dataset_id: str):
+        """
+        Truncate a BigQuery table by overwriting with an empty table.
+        """
+        if not self._connection:
+            await self.connection()
+
+        # Construct a reference to the dataset
+        dataset_ref = bq.DatasetReference(self._connection.project, dataset_id)
+        table_ref = dataset_ref.table(table_id)
+        table = self._connection.get_table(table_ref)  # API request to fetch the table schema
+
+        # Create an empty table with the same schema
+        job_config = bq.QueryJobConfig(destination=table_ref)
+        job_config.write_disposition = bq.WriteDisposition.WRITE_TRUNCATE
+
+        try:
+            job = self._connection.query(f"SELECT * FROM `{table_ref}` WHERE FALSE", job_config=job_config)
+            job.result()  # Wait for the job to finish
+            self._logger.info(f"Truncated table {dataset_id}.{table_id}")
+        except Exception as e:
+            raise DriverError(f"BigQuery: Error truncating table: {e}")
+
+    async def query(self, sentence: str, **kwargs):
+        if not self._connection:
+            await self.connection()
+        await self.valid_operation(sentence)
+        self.start_timing()
+        error = None
+        result = None
+        try:
+            job = self._connection.query(sentence, **kwargs)
+            result = job.result()  # Waits for the query to finish
+        except Exception as e:
+            error = f"BigQuery: Error executing query: {e}"
+        finally:
+            self.generated_at()
+            if error:
+                return [None, error]
+            return await self._serializer(result, error)  # pylint: disable=W0150
+
+    async def queryrow(self, sentence: str):
+        pass
+
+    async def fetch(self, sentence: str, use_pandas: bool = False, **kwargs):
+        """fetch.
+
+        Get a Query directly into a Pandas Dataframe.
+        Args:
+            sentence (str): Query to be executed.
+        """
+        if not self._connection:
+            await self.connection()
+        await self.valid_operation(sentence)
+        self.start_timing()
+        error = None
+        result = None
+        try:
+            if use_pandas is True:
+                result = pandas_gbq.read_gbq(
+                    sentence,
+                    project_id=self._project_id,
+                    credentials=self.credentials,
+                    dialect="standard",
+                    use_bqstorage_api=True,
+                    **kwargs,
+                )
+            else:
+                result = self._connection.query(sentence, **kwargs).to_dataframe()
+        except Exception as e:
+            error = f"BigQuery: Error executing Fetch: {e}"
+        finally:
+            self.generated_at()
+            if error:
+                return [None, error]
+            return (result, error)  # pylint: disable=W0150
+
+    async def fetch_all(self, query, *args):
+        """
+        Fetch all results from a BigQuery query
+        """
+        results = await self.execute(query, *args)
+        return results
+
+    async def fetch_one(self, query, *args):
+        """
+        Fetch all results from a BigQuery query
+        """
+        results = await self.execute(query, *args)
+        return [dict(row) for row in results]
+
+    async def write(
+        self,
+        table_id: str,
+        data,
+        dataset_id: str = None,
+        use_streams: bool = False,
+        use_pandas: bool = False,
+        if_exists: str = "append",
+        **kwargs,
+    ):
+        """
+        Write data to a BigQuery table
+        """
+        if not self._connection:
+            await self.connection()
+        try:
+            if isinstance(data, pd.DataFrame):
+                if use_pandas is True:
+                    job = await self._thread_func(
+                        self._connection.load_table_from_dataframe, data, table_id, if_exists=if_exists, **kwargs
+                    )
+                else:
+                    job = await self._thread_func(
+                        data.to_gbq, table_id, project_id=self._project_id, if_exists=if_exists
+                    )
+            elif isinstance(data, list):
+                dataset_ref = self._connection.dataset(dataset_id)
+                table_ref = dataset_ref.table(table_id)
+                table = bq.Table(table_ref)
+                if use_streams is True:
+                    errors = await self._thread_func(self._connection.insert_rows_json, table, data, **kwargs)
+                    if errors:
+                        raise RuntimeError(f"Errors occurred while inserting rows: {errors}")
+                else:
+                    job = await self._thread_func(self._connection.load_table_from_json, table, data, **kwargs)
+                    loop = asyncio.get_event_loop()
+                    await loop.run_in_executor(None, job.result)
+                    if job.errors and len(job.errors) > 0:
+                        raise RuntimeError(f"Job failed with errors: {job.errors}")
+                    else:
+                        self._logger.info(f"Loaded {len(data)} rows into {table_id}")
+
+            self._logger.info(f"Inserted rows into {table_id}")
+        except Exception as e:
+            raise DriverError(f"BigQuery: Error writing to table: {e}")
+
+    async def load_table_from_uri(
+        self,
+        source_uri: str,
+        table: Any = None,
+        job_config=None,
+        dataset_id: str = None,
+        table_id: str = None,
+    ):
+        """
+        Load a BigQuery table from a Google Cloud Storage URI
+        """
+        if not self._connection:
+            await self.connection()
+        if not table:
+            dataset_ref = self._connection.dataset(dataset_id)
+            table_ref = dataset_ref.table(table_id)
+            table = bq.Table(table_ref)
+        try:
+            job = await self._thread_func(
+                self._connection.load_table_from_uri, source_uri, table, job_config=job_config
+            )
+            job.result()  # Waits for table load to complete.
+            self._logger.info(f"Loaded {job.output_rows} rows into {table.project}.{table.dataset_id}.{table.table_id}")
+            return job
+        except Exception as e:
+            raise DriverError(f"BigQuery: Error loading table from URI: {e}")
+
+    @property
+    def connected(self):
+        return self._connection is not None
+
+    def is_connected(self):
+        return self._connected
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    async def use(self, database: str):
+        raise NotImplementedError  # pragma: no cover
```

## asyncdb/drivers/jdbc.py

```diff
@@ -1,742 +1,742 @@
-"""Dummy Driver.
-"""
-import asyncio
-from typing import Union, Any
-import time
-from collections.abc import Iterable, Sequence
-from pathlib import Path, PurePath
-from functools import partial
-import jaydebeapi
-import jpype
-from asyncdb.exceptions import DriverError, NoDataFound
-from asyncdb import ABS_PATH
-from asyncdb.models import Model
-from asyncdb.utils.types import Entity
-from asyncdb.interfaces import DatabaseBackend, ModelBackend
-from .sql import SQLDriver
-
-
-class jdbc(SQLDriver, DatabaseBackend, ModelBackend):
-    _provider = "JDBC"
-    _syntax = "sql"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._test_query = "SELECT 1"
-        try:
-            if isinstance(params["classpath"], str):
-                params["classpath"] = Path(params["classpath"])
-        except KeyError:
-            pass
-        self._file_jar, self._classname = self.get_classdriver(params)
-        SQLDriver.__init__(self, dsn, loop, params, **kwargs)
-        DatabaseBackend.__init__(self)
-
-    def get_classdriver(self, params):
-        driver = params["driver"]
-        if driver == "sqlserver":
-            classdriver = "com.microsoft.sqlserver.jdbc.SQLServerDriver"
-            self._dsn = "jdbc:{driver}://{host}:{port};DatabaseName={database}"
-        elif driver == "postgresql":
-            classdriver = "org.postgresql.Driver"
-            self._dsn = "jdbc:{driver}://{host}:{port}/{database}"
-        elif driver == "sybase":
-            classdriver = "com.sybase.jdbc4.jdbc.SybDriver"
-            self._dsn = "jdbc:{driver}://{host}:{port}/{database}"
-        elif driver == "mysql":
-            classdriver = "com.mysql.cj.jdbc.Driver"
-            self._dsn = "jdbc:{driver}://{host}:{port}/{database}"
-        elif driver == "oracle":
-            classdriver = "oracle.jdbc.driver.OracleDriver"
-            self._dsn = "jdbc:oracle:thin:{user}/{password}@//{host}:{port}/{database}"
-        elif driver == "azure":
-            classdriver = "com.microsoft.sqlserver.jdbc.SQLServerDriver"
-            self._dsn = "jdbc:sqlserver://{host}:{port};database={database};encrypt=true;trustServerCertificate=true;hostNameInCertificate=*.database.windows.net;loginTimeout=30;Authentication=ActiveDirectoryIntegrated"
-            msal = ABS_PATH.joinpath("bin", "jar", "msal4j-1.11.1.jar")
-            params["jar"].append(msal)
-        elif driver == "cassandra":
-            classdriver = "com.simba.cassandra.jdbc4.Driver"
-            self._dsn = "jdbc:cassandra://{host}:{port}/{database}"
-        else:
-            self._dsn = "jdbc:{driver}://{host}:{port}/{database}"
-            try:
-                classdriver = params["class"]
-            except KeyError as e:
-                raise DriverError(f"JDBC Error: a class Driver need to be declared for {self._dsn}") from e
-        # checking for JAR file
-        file = params["jar"]
-        files = []
-        if isinstance(file, (str, PurePath)):
-            file = [file]
-        elif not isinstance(file, list):
-            raise ValueError(f"Invalid type of Jar Filenames: {file}")
-        for f in file:
-            if isinstance(f, str):
-                d = params["classpath"].joinpath(f)
-            else:
-                d = f
-            if not d.exists():
-                raise DriverError(f"JDBC: Invalid or missing binary JDBC driver: {d}")
-            files.append(str(f))
-        return (files, classdriver)
-
-    async def prepare(self, sentence: Union[str, list]) -> Any:
-        "Ignoring prepared sentences on JDBC"
-        raise NotImplementedError()  # pragma: no cover
-
-    def start_jvm(self, jarpath):
-        if jpype.isJVMStarted():
-            return
-        _jvmArgs = ["-ea"]  # enable assertions
-        if "classpath" in self._params:
-            classpath = f"{self._params['classpath']}/*"
-        else:
-            classpath = None
-            path = ";".join(jarpath)
-            _jvmArgs.append("-Djava.class.path=" + path)
-        _jvmArgs.append("-Xmx12000m")
-        _jvmArgs.append("-Dfile.encoding=UTF8")
-        jpype.startJVM(
-            jvmpath=jpype.getDefaultJVMPath(), classpath=[classpath], *_jvmArgs, interrupt=True, convertStrings=True
-        )
-
-    async def connection(self):
-        """connection.
-
-        Get a JDBC connection.
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            print("JVM started: ", jpype.isJVMStarted())
-            self.start_jvm(self._file_jar)
-            if jpype.isJVMStarted() and not jpype.isThreadAttachedToJVM():
-                jpype.attachThreadToJVM()
-                jpype.java.lang.Thread.currentThread().setContextClassLoader(
-                    jpype.java.lang.ClassLoader.getSystemClassLoader()
-                )
-            if "options" in self._params:
-                options = ";".join({f"{k}={v}" for k, v in self._params["options"].items()})
-                self._dsn = f"{self._dsn};{options}"
-            user = self._params["user"]
-            password = self._params["password"]
-            self._executor = self.get_executor(executor=None, max_workers=10)
-            self._connection = await self._thread_func(
-                jaydebeapi.connect,
-                self._classname,
-                self._dsn,
-                driver_args=[user, password],
-                jars=self._file_jar,
-                executor=self._executor,
-            )
-            if self._connection:
-                print(f'{self._provider}: Connected at {self._params["driver"]}:{self._params["host"]}')
-                self._connected = True
-                self._initialized_on = time.time()
-                if self._init_func is not None and callable(self._init_func):
-                    await self._init_func(self._connection)  # pylint: disable=E1102
-        except jpype.JException as ex:
-            print(ex.stacktrace())
-            self._logger.error(f"Driver {self._classname} Error: {ex}")
-        except TypeError as e:
-            raise DriverError(f"Driver {self._classname} was not found: {e}") from e
-        except Exception as e:
-            self._logger.exception(e, stack_info=True)
-            raise DriverError(f"JDBC Unknown Error: {e!s}") from e
-        return self
-
-    connect = connection
-
-    async def close(self, timeout: int = 10) -> None:
-        try:
-            if self._connection:
-                close = self._thread_func(self._connection.close)
-                await asyncio.wait_for(close, timeout)
-                print(f'{self._provider}: Closed connection to {self._params["driver"]}:{self._params["host"]}')
-            self._connected = False
-            self._connection = None
-        except Exception as e:
-            print(e)
-            self._logger.exception(e, stack_info=True)
-            raise DriverError(f"JDBC Closing Error: {e!s}") from e
-
-    disconnect = close
-
-    def __del__(self) -> None:
-        try:
-            if jpype.isThreadAttachedToJVM():
-                jpype.detachThreadFromJVM()
-            jpype.shutdownJVM()
-        except Exception as e:
-            self._logger.exception(e, stack_info=True)
-
-    def get_columns(self):
-        return self._columns
-
-    async def _query(self, sentence, cursor: Any, fetch: Any, *args, **kwargs) -> Iterable:
-        loop = asyncio.get_event_loop()
-
-        def _execute(sentence, cursor, fetch, *args, **kwargs):
-            cursor.execute(sentence, *args, **kwargs)
-            self._columns = tuple([d[0] for d in cursor.description])
-            return fetch()
-
-        func = partial(_execute, sentence, cursor, fetch, *args, **kwargs)
-        try:
-            fut = loop.run_in_executor(self._executor, func)
-            return await fut
-        except Exception as e:
-            self._logger.exception(e, stack_info=True)
-            raise
-
-    async def _execute(self, sentence, cursor: Any, *args, **kwargs) -> Iterable:
-        loop = asyncio.get_event_loop()
-
-        def _execute(sentence, cursor, *args, **kwargs):
-            cursor.execute(sentence, *args, **kwargs)
-            self._connection.commit()
-            return self.rowcount
-
-        func = partial(_execute, sentence, cursor, *args, **kwargs)
-        try:
-            fut = loop.run_in_executor(self._executor, func)
-            return await fut
-        except Exception as e:
-            self._logger.exception(e, stack_info=True)
-            raise
-
-    async def query(self, sentence: str, **kwargs):
-        error = None
-        cursor = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._thread_func(self._connection.cursor)
-            rows = await self._query(sentence, cursor, cursor.fetchall, **kwargs)
-            self._result = [dict(zip(self._columns, row)) for row in rows]
-            if not self._result:
-                return (None, NoDataFound())
-            return await self._serializer(self._result, error)
-        except Exception as err:
-            error = f"JDBC Error on Query: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            try:
-                cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-
-    async def fetch_all(self, sentence: str, **kwargs) -> Iterable:
-        cursor = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._thread_func(self._connection.cursor)
-            result = await self._query(sentence, cursor, cursor.fetchall, **kwargs)
-            if not result:
-                return NoDataFound()
-            return [dict(zip(self._columns, row)) for row in result]
-        except Exception as err:
-            raise DriverError(message=f"JDBC Error on Query: {err}") from err
-        finally:
-            try:
-                cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-
-    async def queryrow(self, sentence: str, **kwargs):
-        error = None
-        cursor = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._thread_func(self._connection.cursor)
-            row = await self._query(sentence, cursor, cursor.fetchone, **kwargs)
-            self._result = dict(zip(self._columns, row))
-            if not self._result:
-                return (None, NoDataFound())
-            return await self._serializer(self._result, error)
-        except Exception as err:
-            error = f"JDBC Error on Query: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            try:
-                cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                print(err)
-                self._logger.exception(err)
-
-    async def fetch_one(self, sentence: str, **kwargs) -> Iterable[Any]:
-        error = None
-        cursor = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._thread_func(self._connection.cursor)
-            row = await self._query(sentence, cursor, cursor.fetchone, **kwargs)
-            result = dict(zip(self._columns, row))
-            if not result:
-                return NoDataFound()
-            return result
-        except Exception as err:
-            error = f"JDBC Error on Query: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            try:
-                cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-
-    async def fetch_many(self, sentence: str, size: int = None, **kwargs) -> Iterable[Any]:
-        error = None
-        cursor = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._thread_func(self._connection.cursor)
-            rows = await self._query(sentence, cursor, cursor.fetchmany, size=size, **kwargs)
-            result = [dict(zip(self._columns, row)) for row in rows]
-            if not result:
-                return NoDataFound()
-            return result
-        except Exception as err:
-            error = f"JDBC Error on Query: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            try:
-                cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-
-    async def execute(self, sentence: str, *args, **kwargs) -> Union[None, Sequence]:
-        cursor = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._thread_func(self._connection.cursor)
-            result = await self._execute(sentence, cursor, *args, **kwargs)
-            return result
-        except Exception as err:
-            raise DriverError(message=f"JDBC Error on Execute: {err}") from err
-        finally:
-            try:
-                cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-
-    async def execute_many(self, sentence: Union[str, list], *args, **kwargs) -> Union[None, Sequence]:
-        cursor = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._thread_func(self._connection.cursor)
-            if isinstance(sentence, list):
-                results = []
-                for st in sentence:
-                    result = await self._execute(st, cursor, *args, **kwargs)
-                    results.append(st)
-                return results
-            else:
-                result = await self._execute(sentence, cursor, *args, **kwargs)
-                return result
-        except Exception as err:
-            raise DriverError(message=f"JDBC Error on Execute: {err}") from err
-        finally:
-            try:
-                cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-
-    executemany = execute_many
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError()  # pragma: no cover
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError()  # pragma: no cover
-
-    async def use(self, database: str):
-        raise NotImplementedError("SQLite Error: There is no Database in SQLite")
-
-    ## ModelBackend Methods
-    async def _insert_(self, _model: Model, **kwargs):
-        """
-        insert a row from model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        cols = []
-        source = []
-        _filter = {}
-        n = 1
-        fields = _model.columns()
-        for name, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            column = field.name
-            # validating required field
-            try:
-                required = field.required()
-            except AttributeError:
-                required = False
-            if required is False and value is None or value == "None":
-                default = field.default
-                if callable(default):
-                    value = default()
-                else:
-                    continue
-            elif required is True and value is None or value == "None":
-                if "db_default" in field.metadata:
-                    # field get a default value from database
-                    continue
-                else:
-                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
-            source.append(value)
-            cols.append(column)
-            n += 1
-            if pk := self._get_attribute(field, value, attr="primary_key"):
-                _filter[column] = pk
-        try:
-            columns = ",".join(cols)
-            values = ",".join(["?" for a in range(1, n)])
-            insert = f"INSERT INTO {table}({columns}) VALUES({values})"
-            self._logger.debug(f"INSERT: {insert}")
-            cursor = await self._connection.execute(insert, parameters=source)
-            await self._connection.commit()
-            condition = self._where(fields, **_filter)
-            get = f"SELECT * FROM {table} {condition}"
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-            cursor = await self._connection.execute(get)
-            result = await cursor.fetchone()
-            if result:
-                for f, val in result.items():
-                    setattr(_model, f, val)
-                return _model
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _delete_(self, _model: Model, **kwargs):
-        """
-        delete a row from model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        source = []
-        _filter = {}
-        n = 1
-        fields = _model.columns()
-        for _, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            column = field.name
-            source.append(value)
-            n += 1
-            if pk := self._get_attribute(field, value, attr="primary_key"):
-                _filter[column] = pk
-        try:
-            condition = self._where(fields, **_filter)
-            _delete = f"DELETE FROM {table} {condition};"
-            self._logger.debug(f"DELETE: {_delete}")
-            cursor = await self._connection.execute(_delete)
-            await self._connection.commit()
-            return f"DELETE {cursor.rowcount}: {_filter!s}"
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _update_(self, _model: Model, **kwargs):
-        """
-        Updating a row in a Model.
-        TODO: How to update when if primary key changed.
-        Alternatives: Saving *dirty* status and previous value on dict
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        cols = []
-        source = []
-        _filter = {}
-        n = 1
-        fields = _model.columns()
-        for name, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            column = field.name
-            # validating required field
-            try:
-                required = field.required()
-            except AttributeError:
-                required = False
-            if required is False and value is None or value == "None":
-                default = field.default
-                if callable(default):
-                    value = default()
-                else:
-                    continue
-            elif required is True and value is None or value == "None":
-                if "db_default" in field.metadata:
-                    # field get a default value from database
-                    continue
-                else:
-                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
-            source.append(value)
-            cols.append(f"{column} = ?")
-            n += 1
-            if pk := self._get_attribute(field, value, attr="primary_key"):
-                _filter[column] = pk
-        try:
-            set_fields = ", ".join(cols)
-            condition = self._where(fields, **_filter)
-            _update = f"UPDATE {table} SET {set_fields} {condition}"
-            self._logger.debug(f"UPDATE: {_update}")
-            cursor = await self._connection.execute(_update, parameters=source)
-            await self._connection.commit()
-            get = f"SELECT * FROM {table} {condition}"
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-            cursor = await self._connection.execute(get)
-            result = await cursor.fetchone()
-            if result:
-                for f, val in result.items():
-                    setattr(_model, f, val)
-                return _model
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _save_(self, model: Model, *args, **kwargs):
-        """
-        Save a row in a Model, using Insert-or-Update methodology.
-        """
-
-    async def _fetch_(self, _model: Model, **kwargs):
-        """
-        Returns one Row using Model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns()
-        _filter = {}
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT * FROM {table} {condition}"
-        try:
-            cursor = await self._connection.execute(_get)
-            result = await cursor.fetchone()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model Fetch over {table}: {e}") from e
-
-    async def _filter_(self, _model: Model, *args, **kwargs):
-        """
-        Filter a Model using Fields.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        if args:
-            columns = ",".join(args)
-        else:
-            columns = "*"
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            cursor = await self._connection.execute(_get)
-            result = await cursor.fetchall()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model GET over {table}: {e}") from e
-
-    async def _select_(self, *args, **kwargs):
-        """
-        Get a query from Model.
-        """
-        try:
-            model = kwargs["_model"]
-        except KeyError as e:
-            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
-        try:
-            table = f"{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        if args:
-            condition = "{}".join(args)
-        else:
-            condition = None
-        if "fields" in kwargs:
-            columns = ",".join(kwargs["fields"])
-        else:
-            columns = "*"
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            cursor = await self._connection.execute(_get)
-            result = await cursor.fetchall()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model SELECT over {table}: {e}") from e
-
-    async def _get_(self, _model: Model, *args, **kwargs):
-        """
-        Get one row from model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        if args:
-            columns = ",".join(args)
-        else:
-            columns = "*"
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            cursor = await self._connection.execute(_get)
-            result = await cursor.fetchone()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model GET over {table}: {e}") from e
-
-    async def _all_(self, _model: Model, *args, **kwargs):
-        """
-        Get all rows on a Model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        if "fields" in kwargs:
-            columns = ",".join(kwargs["fields"])
-        else:
-            columns = "*"
-        _all = f"SELECT {columns} FROM {table}"
-        try:
-            cursor = await self._connection.execute(_all)
-            result = await cursor.fetchall()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model All over {table}: {e}") from e
-
-    async def _remove_(self, _model: Model, **kwargs):
-        """
-        Deleting some records using Model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        for name, field in fields.items():
-            datatype = field.type
-            if name in kwargs:
-                val = kwargs[name]
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _delete = f"DELETE FROM {table} {condition}"
-        try:
-            self._logger.debug(f"DELETE: {_delete}")
-            cursor = await self._connection.execute(_delete)
-            await self._connection.commit()
-            return f"DELETE {cursor.rowcount}: {_filter!s}"
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _updating_(self, *args, _filter: dict = None, **kwargs):
-        """
-        Updating records using Model.
-        """
-        try:
-            model = kwargs["_model"]
-        except KeyError as e:
-            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
-        try:
-            table = f"{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        try:
-            table = f"{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        fields = model.columns(model)
-        if _filter is None:
-            if args:
-                _filter = args[0]
-        cols = []
-        source = []
-        new_cond = {}
-        for name, field in fields.items():
-            try:
-                val = kwargs[name]
-            except (KeyError, AttributeError):
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            source.append(value)
-            if name in _filter:
-                new_cond[name] = value
-            cols.append(f"{name} = ?")
-        try:
-            set_fields = ", ".join(cols)
-            condition = self._where(fields, **_filter)
-            _update = f"UPDATE {table} SET {set_fields} {condition}"
-            self._logger.debug(f"UPDATE: {_update}")
-            cursor = await self._connection.execute(_update, parameters=source)
-            await self._connection.commit()
-            print(f"UPDATE {cursor.rowcount}: {_filter!s}")
-            new_conditions = {**_filter, **new_cond}
-            condition = self._where(fields, **new_conditions)
-            get = f"SELECT * FROM {table} {condition}"
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-            cursor = await self._connection.execute(get)
-            result = await cursor.fetchall()
-            return [model(**dict(r)) for r in result]
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {model.Meta.name}: {err!s}") from err
+"""Dummy Driver.
+"""
+import asyncio
+from typing import Union, Any
+import time
+from collections.abc import Iterable, Sequence
+from pathlib import Path, PurePath
+from functools import partial
+import jaydebeapi
+import jpype
+from ..exceptions import DriverError, NoDataFound
+from asyncdb import ABS_PATH
+from ..models import Model
+from ..utils.types import Entity
+from ..interfaces import DatabaseBackend, ModelBackend
+from .sql import SQLDriver
+
+
+class jdbc(SQLDriver, DatabaseBackend, ModelBackend):
+    _provider = "JDBC"
+    _syntax = "sql"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._test_query = "SELECT 1"
+        try:
+            if isinstance(params["classpath"], str):
+                params["classpath"] = Path(params["classpath"])
+        except KeyError:
+            pass
+        self._file_jar, self._classname = self.get_classdriver(params)
+        SQLDriver.__init__(self, dsn, loop, params, **kwargs)
+        DatabaseBackend.__init__(self)
+
+    def get_classdriver(self, params):
+        driver = params["driver"]
+        if driver == "sqlserver":
+            classdriver = "com.microsoft.sqlserver.jdbc.SQLServerDriver"
+            self._dsn = "jdbc:{driver}://{host}:{port};DatabaseName={database}"
+        elif driver == "postgresql":
+            classdriver = "org.postgresql.Driver"
+            self._dsn = "jdbc:{driver}://{host}:{port}/{database}"
+        elif driver == "sybase":
+            classdriver = "com.sybase.jdbc4.jdbc.SybDriver"
+            self._dsn = "jdbc:{driver}://{host}:{port}/{database}"
+        elif driver == "mysql":
+            classdriver = "com.mysql.cj.jdbc.Driver"
+            self._dsn = "jdbc:{driver}://{host}:{port}/{database}"
+        elif driver == "oracle":
+            classdriver = "oracle.jdbc.driver.OracleDriver"
+            self._dsn = "jdbc:oracle:thin:{user}/{password}@//{host}:{port}/{database}"
+        elif driver == "azure":
+            classdriver = "com.microsoft.sqlserver.jdbc.SQLServerDriver"
+            self._dsn = "jdbc:sqlserver://{host}:{port};database={database};encrypt=true;trustServerCertificate=true;hostNameInCertificate=*.database.windows.net;loginTimeout=30;Authentication=ActiveDirectoryIntegrated"
+            msal = ABS_PATH.joinpath("bin", "jar", "msal4j-1.11.1.jar")
+            params["jar"].append(msal)
+        elif driver == "cassandra":
+            classdriver = "com.simba.cassandra.jdbc4.Driver"
+            self._dsn = "jdbc:cassandra://{host}:{port}/{database}"
+        else:
+            self._dsn = "jdbc:{driver}://{host}:{port}/{database}"
+            try:
+                classdriver = params["class"]
+            except KeyError as e:
+                raise DriverError(f"JDBC Error: a class Driver need to be declared for {self._dsn}") from e
+        # checking for JAR file
+        file = params["jar"]
+        files = []
+        if isinstance(file, (str, PurePath)):
+            file = [file]
+        elif not isinstance(file, list):
+            raise ValueError(f"Invalid type of Jar Filenames: {file}")
+        for f in file:
+            if isinstance(f, str):
+                d = params["classpath"].joinpath(f)
+            else:
+                d = f
+            if not d.exists():
+                raise DriverError(f"JDBC: Invalid or missing binary JDBC driver: {d}")
+            files.append(str(f))
+        return (files, classdriver)
+
+    async def prepare(self, sentence: Union[str, list]) -> Any:
+        "Ignoring prepared sentences on JDBC"
+        raise NotImplementedError()  # pragma: no cover
+
+    def start_jvm(self, jarpath):
+        if jpype.isJVMStarted():
+            return
+        _jvmArgs = ["-ea"]  # enable assertions
+        if "classpath" in self._params:
+            classpath = f"{self._params['classpath']}/*"
+        else:
+            classpath = None
+            path = ";".join(jarpath)
+            _jvmArgs.append("-Djava.class.path=" + path)
+        _jvmArgs.append("-Xmx12000m")
+        _jvmArgs.append("-Dfile.encoding=UTF8")
+        jpype.startJVM(
+            jvmpath=jpype.getDefaultJVMPath(), classpath=[classpath], *_jvmArgs, interrupt=True, convertStrings=True
+        )
+
+    async def connection(self):
+        """connection.
+
+        Get a JDBC connection.
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            print("JVM started: ", jpype.isJVMStarted())
+            self.start_jvm(self._file_jar)
+            if jpype.isJVMStarted() and not jpype.isThreadAttachedToJVM():
+                jpype.attachThreadToJVM()
+                jpype.java.lang.Thread.currentThread().setContextClassLoader(
+                    jpype.java.lang.ClassLoader.getSystemClassLoader()
+                )
+            if "options" in self._params:
+                options = ";".join({f"{k}={v}" for k, v in self._params["options"].items()})
+                self._dsn = f"{self._dsn};{options}"
+            user = self._params["user"]
+            password = self._params["password"]
+            self._executor = self.get_executor(executor=None, max_workers=10)
+            self._connection = await self._thread_func(
+                jaydebeapi.connect,
+                self._classname,
+                self._dsn,
+                driver_args=[user, password],
+                jars=self._file_jar,
+                executor=self._executor,
+            )
+            if self._connection:
+                print(f'{self._provider}: Connected at {self._params["driver"]}:{self._params["host"]}')
+                self._connected = True
+                self._initialized_on = time.time()
+                if self._init_func is not None and callable(self._init_func):
+                    await self._init_func(self._connection)  # pylint: disable=E1102
+        except jpype.JException as ex:
+            print(ex.stacktrace())
+            self._logger.error(f"Driver {self._classname} Error: {ex}")
+        except TypeError as e:
+            raise DriverError(f"Driver {self._classname} was not found: {e}") from e
+        except Exception as e:
+            self._logger.exception(e, stack_info=True)
+            raise DriverError(f"JDBC Unknown Error: {e!s}") from e
+        return self
+
+    connect = connection
+
+    async def close(self, timeout: int = 10) -> None:
+        try:
+            if self._connection:
+                close = self._thread_func(self._connection.close)
+                await asyncio.wait_for(close, timeout)
+                print(f'{self._provider}: Closed connection to {self._params["driver"]}:{self._params["host"]}')
+            self._connected = False
+            self._connection = None
+        except Exception as e:
+            print(e)
+            self._logger.exception(e, stack_info=True)
+            raise DriverError(f"JDBC Closing Error: {e!s}") from e
+
+    disconnect = close
+
+    def __del__(self) -> None:
+        try:
+            if jpype.isThreadAttachedToJVM():
+                jpype.detachThreadFromJVM()
+            jpype.shutdownJVM()
+        except Exception as e:
+            self._logger.exception(e, stack_info=True)
+
+    def get_columns(self):
+        return self._columns
+
+    async def _query(self, sentence, cursor: Any, fetch: Any, *args, **kwargs) -> Iterable:
+        loop = asyncio.get_event_loop()
+
+        def _execute(sentence, cursor, fetch, *args, **kwargs):
+            cursor.execute(sentence, *args, **kwargs)
+            self._columns = tuple([d[0] for d in cursor.description])
+            return fetch()
+
+        func = partial(_execute, sentence, cursor, fetch, *args, **kwargs)
+        try:
+            fut = loop.run_in_executor(self._executor, func)
+            return await fut
+        except Exception as e:
+            self._logger.exception(e, stack_info=True)
+            raise
+
+    async def _execute(self, sentence, cursor: Any, *args, **kwargs) -> Iterable:
+        loop = asyncio.get_event_loop()
+
+        def _execute(sentence, cursor, *args, **kwargs):
+            cursor.execute(sentence, *args, **kwargs)
+            self._connection.commit()
+            return self.rowcount
+
+        func = partial(_execute, sentence, cursor, *args, **kwargs)
+        try:
+            fut = loop.run_in_executor(self._executor, func)
+            return await fut
+        except Exception as e:
+            self._logger.exception(e, stack_info=True)
+            raise
+
+    async def query(self, sentence: str, **kwargs):
+        error = None
+        cursor = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._thread_func(self._connection.cursor)
+            rows = await self._query(sentence, cursor, cursor.fetchall, **kwargs)
+            self._result = [dict(zip(self._columns, row)) for row in rows]
+            if not self._result:
+                return (None, NoDataFound())
+            return await self._serializer(self._result, error)
+        except Exception as err:
+            error = f"JDBC Error on Query: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            try:
+                cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+
+    async def fetch_all(self, sentence: str, **kwargs) -> Iterable:
+        cursor = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._thread_func(self._connection.cursor)
+            result = await self._query(sentence, cursor, cursor.fetchall, **kwargs)
+            if not result:
+                return NoDataFound()
+            return [dict(zip(self._columns, row)) for row in result]
+        except Exception as err:
+            raise DriverError(message=f"JDBC Error on Query: {err}") from err
+        finally:
+            try:
+                cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+
+    async def queryrow(self, sentence: str, **kwargs):
+        error = None
+        cursor = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._thread_func(self._connection.cursor)
+            row = await self._query(sentence, cursor, cursor.fetchone, **kwargs)
+            self._result = dict(zip(self._columns, row))
+            if not self._result:
+                return (None, NoDataFound())
+            return await self._serializer(self._result, error)
+        except Exception as err:
+            error = f"JDBC Error on Query: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            try:
+                cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                print(err)
+                self._logger.exception(err)
+
+    async def fetch_one(self, sentence: str, **kwargs) -> Iterable[Any]:
+        error = None
+        cursor = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._thread_func(self._connection.cursor)
+            row = await self._query(sentence, cursor, cursor.fetchone, **kwargs)
+            result = dict(zip(self._columns, row))
+            if not result:
+                return NoDataFound()
+            return result
+        except Exception as err:
+            error = f"JDBC Error on Query: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            try:
+                cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+
+    async def fetch_many(self, sentence: str, size: int = None, **kwargs) -> Iterable[Any]:
+        error = None
+        cursor = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._thread_func(self._connection.cursor)
+            rows = await self._query(sentence, cursor, cursor.fetchmany, size=size, **kwargs)
+            result = [dict(zip(self._columns, row)) for row in rows]
+            if not result:
+                return NoDataFound()
+            return result
+        except Exception as err:
+            error = f"JDBC Error on Query: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            try:
+                cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+
+    async def execute(self, sentence: str, *args, **kwargs) -> Union[None, Sequence]:
+        cursor = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._thread_func(self._connection.cursor)
+            result = await self._execute(sentence, cursor, *args, **kwargs)
+            return result
+        except Exception as err:
+            raise DriverError(message=f"JDBC Error on Execute: {err}") from err
+        finally:
+            try:
+                cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+
+    async def execute_many(self, sentence: Union[str, list], *args, **kwargs) -> Union[None, Sequence]:
+        cursor = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._thread_func(self._connection.cursor)
+            if isinstance(sentence, list):
+                results = []
+                for st in sentence:
+                    result = await self._execute(st, cursor, *args, **kwargs)
+                    results.append(st)
+                return results
+            else:
+                result = await self._execute(sentence, cursor, *args, **kwargs)
+                return result
+        except Exception as err:
+            raise DriverError(message=f"JDBC Error on Execute: {err}") from err
+        finally:
+            try:
+                cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+
+    executemany = execute_many
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError()  # pragma: no cover
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError()  # pragma: no cover
+
+    async def use(self, database: str):
+        raise NotImplementedError("SQLite Error: There is no Database in SQLite")
+
+    ## ModelBackend Methods
+    async def _insert_(self, _model: Model, **kwargs):
+        """
+        insert a row from model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        cols = []
+        source = []
+        _filter = {}
+        n = 1
+        fields = _model.columns()
+        for name, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            # validating required field
+            try:
+                required = field.required()
+            except AttributeError:
+                required = False
+            if required is False and value is None or value == "None":
+                default = field.default
+                if callable(default):
+                    value = default()
+                else:
+                    continue
+            elif required is True and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    # field get a default value from database
+                    continue
+                else:
+                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
+            source.append(value)
+            cols.append(column)
+            n += 1
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _filter[column] = pk
+        try:
+            columns = ",".join(cols)
+            values = ",".join(["?" for a in range(1, n)])
+            insert = f"INSERT INTO {table}({columns}) VALUES({values})"
+            self._logger.debug(f"INSERT: {insert}")
+            cursor = await self._connection.execute(insert, parameters=source)
+            await self._connection.commit()
+            condition = self._where(fields, **_filter)
+            get = f"SELECT * FROM {table} {condition}"
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+            cursor = await self._connection.execute(get)
+            result = await cursor.fetchone()
+            if result:
+                for f, val in result.items():
+                    setattr(_model, f, val)
+                return _model
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _delete_(self, _model: Model, **kwargs):
+        """
+        delete a row from model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        source = []
+        _filter = {}
+        n = 1
+        fields = _model.columns()
+        for _, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            source.append(value)
+            n += 1
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _filter[column] = pk
+        try:
+            condition = self._where(fields, **_filter)
+            _delete = f"DELETE FROM {table} {condition};"
+            self._logger.debug(f"DELETE: {_delete}")
+            cursor = await self._connection.execute(_delete)
+            await self._connection.commit()
+            return f"DELETE {cursor.rowcount}: {_filter!s}"
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _update_(self, _model: Model, **kwargs):
+        """
+        Updating a row in a Model.
+        TODO: How to update when if primary key changed.
+        Alternatives: Saving *dirty* status and previous value on dict
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        cols = []
+        source = []
+        _filter = {}
+        n = 1
+        fields = _model.columns()
+        for name, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            # validating required field
+            try:
+                required = field.required()
+            except AttributeError:
+                required = False
+            if required is False and value is None or value == "None":
+                default = field.default
+                if callable(default):
+                    value = default()
+                else:
+                    continue
+            elif required is True and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    # field get a default value from database
+                    continue
+                else:
+                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
+            source.append(value)
+            cols.append(f"{column} = ?")
+            n += 1
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _filter[column] = pk
+        try:
+            set_fields = ", ".join(cols)
+            condition = self._where(fields, **_filter)
+            _update = f"UPDATE {table} SET {set_fields} {condition}"
+            self._logger.debug(f"UPDATE: {_update}")
+            cursor = await self._connection.execute(_update, parameters=source)
+            await self._connection.commit()
+            get = f"SELECT * FROM {table} {condition}"
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+            cursor = await self._connection.execute(get)
+            result = await cursor.fetchone()
+            if result:
+                for f, val in result.items():
+                    setattr(_model, f, val)
+                return _model
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _save_(self, model: Model, *args, **kwargs):
+        """
+        Save a row in a Model, using Insert-or-Update methodology.
+        """
+
+    async def _fetch_(self, _model: Model, **kwargs):
+        """
+        Returns one Row using Model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns()
+        _filter = {}
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT * FROM {table} {condition}"
+        try:
+            cursor = await self._connection.execute(_get)
+            result = await cursor.fetchone()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model Fetch over {table}: {e}") from e
+
+    async def _filter_(self, _model: Model, *args, **kwargs):
+        """
+        Filter a Model using Fields.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        if args:
+            columns = ",".join(args)
+        else:
+            columns = "*"
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            cursor = await self._connection.execute(_get)
+            result = await cursor.fetchall()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model GET over {table}: {e}") from e
+
+    async def _select_(self, *args, **kwargs):
+        """
+        Get a query from Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            table = f"{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        if args:
+            condition = "{}".join(args)
+        else:
+            condition = None
+        if "fields" in kwargs:
+            columns = ",".join(kwargs["fields"])
+        else:
+            columns = "*"
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            cursor = await self._connection.execute(_get)
+            result = await cursor.fetchall()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model SELECT over {table}: {e}") from e
+
+    async def _get_(self, _model: Model, *args, **kwargs):
+        """
+        Get one row from model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        if args:
+            columns = ",".join(args)
+        else:
+            columns = "*"
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            cursor = await self._connection.execute(_get)
+            result = await cursor.fetchone()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model GET over {table}: {e}") from e
+
+    async def _all_(self, _model: Model, *args, **kwargs):
+        """
+        Get all rows on a Model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        if "fields" in kwargs:
+            columns = ",".join(kwargs["fields"])
+        else:
+            columns = "*"
+        _all = f"SELECT {columns} FROM {table}"
+        try:
+            cursor = await self._connection.execute(_all)
+            result = await cursor.fetchall()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model All over {table}: {e}") from e
+
+    async def _remove_(self, _model: Model, **kwargs):
+        """
+        Deleting some records using Model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        for name, field in fields.items():
+            datatype = field.type
+            if name in kwargs:
+                val = kwargs[name]
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _delete = f"DELETE FROM {table} {condition}"
+        try:
+            self._logger.debug(f"DELETE: {_delete}")
+            cursor = await self._connection.execute(_delete)
+            await self._connection.commit()
+            return f"DELETE {cursor.rowcount}: {_filter!s}"
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _updating_(self, *args, _filter: dict = None, **kwargs):
+        """
+        Updating records using Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            table = f"{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        try:
+            table = f"{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        fields = model.columns(model)
+        if _filter is None:
+            if args:
+                _filter = args[0]
+        cols = []
+        source = []
+        new_cond = {}
+        for name, field in fields.items():
+            try:
+                val = kwargs[name]
+            except (KeyError, AttributeError):
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            source.append(value)
+            if name in _filter:
+                new_cond[name] = value
+            cols.append(f"{name} = ?")
+        try:
+            set_fields = ", ".join(cols)
+            condition = self._where(fields, **_filter)
+            _update = f"UPDATE {table} SET {set_fields} {condition}"
+            self._logger.debug(f"UPDATE: {_update}")
+            cursor = await self._connection.execute(_update, parameters=source)
+            await self._connection.commit()
+            print(f"UPDATE {cursor.rowcount}: {_filter!s}")
+            new_conditions = {**_filter, **new_cond}
+            condition = self._where(fields, **new_conditions)
+            get = f"SELECT * FROM {table} {condition}"
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+            cursor = await self._connection.execute(get)
+            result = await cursor.fetchall()
+            return [model(**dict(r)) for r in result]
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {model.Meta.name}: {err!s}") from err
```

## asyncdb/drivers/sa.py

```diff
@@ -1,465 +1,465 @@
-""" sqlalchemy.
-
-non-async SQL Alchemy Provider.
-Notes on sqlalchemy Provider
---------------------
-This provider implements a basic set of funcionalities from SQLAlchemy core
-"""
-
-import asyncio
-from typing import Any, Dict, List, Optional
-from collections.abc import Callable, Iterable
-from sqlalchemy.exc import DatabaseError, OperationalError, SQLAlchemyError, ProgrammingError, InvalidRequestError
-from sqlalchemy import text
-from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
-from asyncdb.meta import Record
-from asyncdb.exceptions import (
-    EmptyStatement,
-    NoDataFound,
-    DriverError,
-    StatementError,
-    TooManyConnections,
-)
-from asyncdb.interfaces import DBCursorBackend
-from asyncdb.utils.encoders import json_encoder, json_decoder
-from .sql import SQLDriver, SQLCursor
-
-
-class saCursor(SQLCursor):
-    _connection: Any = None
-
-    async def __aenter__(self) -> "SQLCursor":
-        try:
-            self._cursor = await self._connection.execute(self._sentence, self._params)
-        except Exception as e:
-            raise DriverError(f"SQLAlchemy Error: {e}") from e
-        return self
-
-
-class sa(SQLDriver, DBCursorBackend):
-    _provider = "sa"
-    _syntax = "sql"
-    _test_query = "SELECT 1 as one"
-    _engine_options: Dict = {
-        "connect_args": {"timeout": 360},
-        "execution_options": {"isolation_level": "AUTOCOMMIT"},
-        "echo": False,
-        "future": True,
-        "json_deserializer": json_decoder,
-        "json_serializer": json_encoder,
-    }
-    setup_func: Optional[Callable] = None
-    init_func: Optional[Callable] = None
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
-        """sql_alchemy.
-
-        Args:
-            dsn (str, optional): Connection DSN. Defaults to "".
-            loop (asyncio.AbstractEventLoop, optional): optional Event Loop. Defaults to None.
-            params (dict, optional): Connection Parameters. Defaults to None.
-        """
-        self._session = None
-        self._dsn = "{driver}://{user}:{password}@{host}:{port}/{database}"
-        self._transaction = None
-        self._driver = "postgresql"
-        self.__cursor__ = None
-        self._row_format = "dict"
-        if params:
-            try:
-                if not params["driver"]:
-                    params["driver"] = "postgresql+asyncpg"
-                else:
-                    self._driver = params["driver"]
-            except KeyError:
-                params["driver"] = "postgresql+asyncpg"
-        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
-        DBCursorBackend.__init__(self)
-        self._options = self._engine_options
-        if kwargs:
-            self._options = {**self._options, **kwargs}
-
-    def engine(self):
-        return self._connection
-
-    def __del__(self):
-        del self._connection
-        del self._session
-
-    async def close(self):
-        await self.release()
-
-    async def release(self):
-        if self._connection:
-            try:
-                await self._connection.dispose()
-            except Exception as err:
-                self._connection = None
-                raise DriverError(f"Engine Error, Terminated: {err!s}")
-            finally:
-                self._connection = None
-                self._connected = False
-
-    async def connection(self):
-        """
-        Get a connection
-        """
-        self._logger.info(f"SQLAlchemy: Connecting to {self._dsn}")
-        self._connection = None
-        self._connected = False
-        try:
-            self._connection = create_async_engine(self._dsn, **self._options)
-            self._session = AsyncSession(bind=self._connection)
-            self._connected = True
-        except (SQLAlchemyError, OperationalError) as err:
-            print(err)
-            self._connection = None
-            raise DriverError(f"Connection Error: {err!s}")
-        except Exception as err:
-            print(err)
-            self._connection = None
-            raise DriverError(f"Engine Error, Terminated: {err!s}")
-        finally:
-            return self
-
-    def prepare(self, sentence=""):
-        """
-        Preparing a sentence.
-        """
-        raise NotImplementedError()
-
-    async def get_result(self, resultset):
-        result = None
-        if self._row_format == "native":
-            result = resultset.fetchone()
-        if self._row_format == "dict":
-            result = dict(resultset.mappings().one())
-        elif self._row_format == "iterable":
-            result = resultset.mappings().one()
-        elif self._row_format == "record":
-            row = resultset.mappings().one()
-            result = Record(row, row.keys())
-        else:
-            result = resultset.fetchone()
-        return result
-
-    async def get_resultset(self, resultset):
-        result = None
-        if self._row_format == "list":
-            result = resultset.mappings().all()
-        elif self._row_format == "iterable":
-            result = resultset.mappings().all()
-        elif self._row_format == "record":
-            rows = resultset.mappings().all()
-            result = [Record(row, row.keys()) for row in rows]
-        else:
-            result = resultset.fetchall()
-        return result
-
-    async def test_connection(self):
-        """
-        Test Connnection
-        """
-        error = None
-        row = {}
-        if self._test_query is None:
-            raise NotImplementedError()
-        if not self._connection:
-            await self.connection()
-        try:
-            async with self._connection.begin() as conn:
-                result = await conn.execute(text(self._test_query))
-                row = await self.get_result(result)
-            if error:
-                self._logger.info(f"Test Error: {err!s}")
-        except Exception as err:
-            error = str(err)
-            raise DriverError(message=str(err), code=0)
-        finally:
-            return [row, error]
-
-    def valid_operation(self, sentence: Any):
-        """
-        Returns if is a valid operation.
-        TODO: add some validations.
-        """
-        if not sentence:
-            raise EmptyStatement(f"{__name__!s} Error: cannot use an empty SQL sentence")
-        if not self._connection:
-            self.connection()
-
-    def query(self, sentence: Any, params: List = None):
-        """
-        Running Query.
-        """
-        self._result = None
-        error = None
-        self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            self._logger.debug("Running Query {}".format(sentence))
-            result = self._connection.execute(sentence, params)
-            if result:
-                rows = result.fetchall()
-                if self._row_format == "dict" or self._row_format == "iterable":
-                    self._result = [dict(zip(row.keys(), row)) for row in rows]
-                elif self._row_format == "record":
-                    self._result = [Record(row, row.keys()) for row in rows]
-                else:
-                    self._result = rows
-        except (DatabaseError, OperationalError) as err:
-            error = "Query Error: {}".format(str(err))
-            raise DriverError(message=error)
-        except Exception as err:
-            error = "Query Error, Terminated: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            self.generated_at()
-            return [self._result, error]
-
-    def queryrow(self, sentence: Any):
-        """
-        Running Query and return only one row.
-        """
-        self._result = None
-        error = None
-        self.valid_operation(sentence)
-        try:
-            self._logger.debug("Running Query {}".format(sentence))
-            result = self._connection.execute(sentence)
-            if result:
-                row = result.fetchone()
-                if self._row_format == "dict":
-                    self._result = dict(row)
-                elif self._row_format == "iterable":
-                    self._result = dict(zip(row.keys(), row))
-                elif self._row_format == "record":
-                    self._result = Record(row, row.keys())
-                else:
-                    self._result = row
-        except (DatabaseError, OperationalError) as err:
-            error = "Query Row Error: {}".format(str(err))
-            raise DriverError(message=error)
-        except Exception as err:
-            error = "Query Row Error, Terminated: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            return [self._result, error]
-
-    def fetch_all(self, sentence: Any, params: List = None):
-        """
-        Running Query.
-        """
-        result = None
-        self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            self._logger.debug("Running Query {}".format(sentence))
-            result = self._connection.execute(sentence, params)
-            if result:
-                rows = result.fetchall()
-                if self._row_format == "dict" or self._row_format == "iterable":
-                    result = [dict(zip(row.keys(), row)) for row in rows]
-                elif self._row_format == "record":
-                    result = [Record(row, row.keys()) for row in rows]
-                else:
-                    result = rows
-        except (DatabaseError, OperationalError) as err:
-            error = "Query Error: {}".format(str(err))
-            raise DriverError(message=error)
-        except Exception as err:
-            error = "Query Error, Terminated: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            self.generated_at()
-            return result
-
-    def fetch_one(self, sentence: Any):
-        """
-        Running Query and return only one row.
-        """
-        result = None
-        self.valid_operation(sentence)
-        try:
-            self._logger.debug("Running Query {}".format(sentence))
-            result = self._connection.execute(sentence)
-            if result:
-                row = result.fetchone()
-                if self._row_format == "dict":
-                    result = dict(row)
-                elif self._row_format == "iterable":
-                    result = dict(zip(row.keys(), row))
-                elif self._row_format == "record":
-                    result = Record(row, row.keys())
-                else:
-                    result = row
-        except (DatabaseError, OperationalError) as err:
-            error = "Query Row Error: {}".format(str(err))
-            raise DriverError(message=error)
-        except Exception as err:
-            error = "Query Row Error, Terminated: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            return result
-
-    fetchone = fetch_one
-
-    def execute(self, sentence, params: List = None):
-        """Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        self._result = None
-        error = None
-        self.valid_operation(sentence)
-        try:
-            self._logger.debug("Execute Sentence {}".format(sentence))
-            result = self._connection.execute(sentence, params)
-            self._result = result
-        except (DatabaseError, OperationalError) as err:
-            error = "Execute Error: {}".format(str(err))
-            raise DriverError(message=error)
-        except Exception as err:
-            error = "Exception Error on Execute: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            return [self._result, error]
-
-    def execute_many(self, sentence, params: List):
-        """Execute multiples transactions."""
-        self._result = None
-        error = None
-        self.valid_operation(sentence)
-        try:
-            self._logger.debug("Execute Sentence {}".format(sentence))
-            result = self._connection.execute(sentence, params)
-            self._result = result
-        except (DatabaseError, OperationalError) as err:
-            error = "Execute Error: {}".format(str(err))
-            raise DriverError(message=error)
-        except Exception as err:
-            error = "Exception Error on Execute: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            return [self._result, error]
-
-    executemany = execute_many
-
-    """
-    Transaction Context
-    """
-
-    def transaction(self):
-        if not self._connection:
-            self.connection()
-        self._transaction = self._connection.begin()
-        return self
-
-    def commit(self):
-        if self._transaction:
-            self._transaction.commit()
-
-    def rollback(self):
-        if self._transaction:
-            self._transaction.rollback()
-
-    def close_transaction(self):
-        if self._transaction:
-            try:
-                self._transaction.commit()
-                self._transaction.close()
-            except InvalidRequestError:
-                # transaction inactive
-                pass
-            except (SQLAlchemyError, DatabaseError, OperationalError) as err:
-                error = "Exception Error on Transaction: {}".format(str(err))
-                raise DriverError(message=error)
-            finally:
-                self._transaction = None
-
-    """
-    Context magic Methods
-    """
-
-    def __enter__(self):
-        return self
-
-    def __exit__(self, exc_type, exc, tb):
-        if self._transaction:
-            self.close_transaction()
-        self.release()
-
-    """
-    DDL Information.
-    """
-
-    def create(self, obj: str = "table", name: str = "", fields: Optional[List] = None) -> bool:
-        """
-        Create is a generic method for Database Objects Creation.
-        """
-        if obj == "table":
-            sql = "CREATE TABLE IF NOT EXISTS {name}({columns});"
-            columns = ", ".join(["{name} {type}".format(**e) for e in fields])
-            sql = sql.format(name=name, columns=columns)
-            try:
-                result = self._connection.execute(sql)
-                if result:
-                    return True
-                else:
-                    return False
-            except ProgrammingError as err:
-                raise DriverError(f"SQLAlchemy: Relation already exists: {err!s}")
-            except Exception as err:
-                raise DriverError(f"SQLAlchemy: Error in Object Creation: {err!s}")
-        else:
-            raise RuntimeError(f"SQLAlchemy: invalid Object type {object!s}")
-
-    """
-    Model Logic:
-    """
-
-    def column_info(self, tablename: str, schema: str = None):
-        """Column Info.
-
-        Get Meta information about a table (column name, data type and PK).
-        Useful to build a DataModel from Querying database.
-        Parameters:
-        @tablename: str The name of the table (including schema).
-        """
-        if schema:
-            table = f"{schema}.{tablename}"
-        else:
-            table = tablename
-        if self._driver == "postgresql":
-            sql = f"SELECT a.attname AS name, a.atttypid::regtype AS type, \
-            format_type(a.atttypid, a.atttypmod) as format_type, a.attnotnull::boolean as notnull, \
-            coalesce((SELECT true FROM pg_index i WHERE i.indrelid = a.attrelid \
-            AND i.indrelid = a.attrelid AND a.attnum = any(i.indkey) \
-            AND i.indisprimary), false) as is_primary \
-            FROM pg_attribute a WHERE a.attrelid = '{table!s}'::regclass \
-            AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum"
-        else:
-            raise NotImplementedError
-        if not self._connection:
-            self.connection()
-        try:
-            f = self._row_format
-            self._row_format = "dict"
-            colinfo = self.fetch_all(sql)
-            self._row_format == f
-            return colinfo
-        except Exception as err:
-            self._logger.exception(f"Wrong Table information {tablename!s}: {err}")
-
-    """
-    Metadata information.
-    """
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def use(self, tablename: str):
-        raise NotImplementedError("SQLAlchemy Error: There is no Database.")
+""" sqlalchemy.
+
+non-async SQL Alchemy Provider.
+Notes on sqlalchemy Provider
+--------------------
+This provider implements a basic set of funcionalities from SQLAlchemy core
+"""
+
+import asyncio
+from typing import Any, Dict, List, Optional
+from collections.abc import Callable, Iterable
+from sqlalchemy.exc import DatabaseError, OperationalError, SQLAlchemyError, ProgrammingError, InvalidRequestError
+from sqlalchemy import text
+from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
+from ..meta import Record
+from ..exceptions import (
+    EmptyStatement,
+    NoDataFound,
+    DriverError,
+    StatementError,
+    TooManyConnections,
+)
+from ..interfaces import DBCursorBackend
+from ..utils.encoders import json_encoder, json_decoder
+from .sql import SQLDriver, SQLCursor
+
+
+class saCursor(SQLCursor):
+    _connection: Any = None
+
+    async def __aenter__(self) -> "SQLCursor":
+        try:
+            self._cursor = await self._connection.execute(self._sentence, self._params)
+        except Exception as e:
+            raise DriverError(f"SQLAlchemy Error: {e}") from e
+        return self
+
+
+class sa(SQLDriver, DBCursorBackend):
+    _provider = "sa"
+    _syntax = "sql"
+    _test_query = "SELECT 1 as one"
+    _engine_options: Dict = {
+        "connect_args": {"timeout": 360},
+        "execution_options": {"isolation_level": "AUTOCOMMIT"},
+        "echo": False,
+        "future": True,
+        "json_deserializer": json_decoder,
+        "json_serializer": json_encoder,
+    }
+    setup_func: Optional[Callable] = None
+    init_func: Optional[Callable] = None
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
+        """sql_alchemy.
+
+        Args:
+            dsn (str, optional): Connection DSN. Defaults to "".
+            loop (asyncio.AbstractEventLoop, optional): optional Event Loop. Defaults to None.
+            params (dict, optional): Connection Parameters. Defaults to None.
+        """
+        self._session = None
+        self._dsn = "{driver}://{user}:{password}@{host}:{port}/{database}"
+        self._transaction = None
+        self._driver = "postgresql"
+        self.__cursor__ = None
+        self._row_format = "dict"
+        if params:
+            try:
+                if not params["driver"]:
+                    params["driver"] = "postgresql+asyncpg"
+                else:
+                    self._driver = params["driver"]
+            except KeyError:
+                params["driver"] = "postgresql+asyncpg"
+        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
+        DBCursorBackend.__init__(self)
+        self._options = self._engine_options
+        if kwargs:
+            self._options = {**self._options, **kwargs}
+
+    def engine(self):
+        return self._connection
+
+    def __del__(self):
+        del self._connection
+        del self._session
+
+    async def close(self):
+        await self.release()
+
+    async def release(self):
+        if self._connection:
+            try:
+                await self._connection.dispose()
+            except Exception as err:
+                self._connection = None
+                raise DriverError(f"Engine Error, Terminated: {err!s}")
+            finally:
+                self._connection = None
+                self._connected = False
+
+    async def connection(self):
+        """
+        Get a connection
+        """
+        self._logger.info(f"SQLAlchemy: Connecting to {self._dsn}")
+        self._connection = None
+        self._connected = False
+        try:
+            self._connection = create_async_engine(self._dsn, **self._options)
+            self._session = AsyncSession(bind=self._connection)
+            self._connected = True
+        except (SQLAlchemyError, OperationalError) as err:
+            print(err)
+            self._connection = None
+            raise DriverError(f"Connection Error: {err!s}")
+        except Exception as err:
+            print(err)
+            self._connection = None
+            raise DriverError(f"Engine Error, Terminated: {err!s}")
+        finally:
+            return self
+
+    def prepare(self, sentence=""):
+        """
+        Preparing a sentence.
+        """
+        raise NotImplementedError()
+
+    async def get_result(self, resultset):
+        result = None
+        if self._row_format == "native":
+            result = resultset.fetchone()
+        if self._row_format == "dict":
+            result = dict(resultset.mappings().one())
+        elif self._row_format == "iterable":
+            result = resultset.mappings().one()
+        elif self._row_format == "record":
+            row = resultset.mappings().one()
+            result = Record(row, row.keys())
+        else:
+            result = resultset.fetchone()
+        return result
+
+    async def get_resultset(self, resultset):
+        result = None
+        if self._row_format == "list":
+            result = resultset.mappings().all()
+        elif self._row_format == "iterable":
+            result = resultset.mappings().all()
+        elif self._row_format == "record":
+            rows = resultset.mappings().all()
+            result = [Record(row, row.keys()) for row in rows]
+        else:
+            result = resultset.fetchall()
+        return result
+
+    async def test_connection(self):
+        """
+        Test Connnection
+        """
+        error = None
+        row = {}
+        if self._test_query is None:
+            raise NotImplementedError()
+        if not self._connection:
+            await self.connection()
+        try:
+            async with self._connection.begin() as conn:
+                result = await conn.execute(text(self._test_query))
+                row = await self.get_result(result)
+            if error:
+                self._logger.info(f"Test Error: {error!s}")
+        except Exception as err:
+            error = str(err)
+            raise DriverError(message=str(err), code=0)
+        finally:
+            return [row, error]
+
+    def valid_operation(self, sentence: Any):
+        """
+        Returns if is a valid operation.
+        TODO: add some validations.
+        """
+        if not sentence:
+            raise EmptyStatement(f"{__name__!s} Error: cannot use an empty SQL sentence")
+        if not self._connection:
+            self.connection()
+
+    def query(self, sentence: Any, params: List = None):
+        """
+        Running Query.
+        """
+        self._result = None
+        error = None
+        self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            self._logger.debug("Running Query {}".format(sentence))
+            result = self._connection.execute(sentence, params)
+            if result:
+                rows = result.fetchall()
+                if self._row_format == "dict" or self._row_format == "iterable":
+                    self._result = [dict(zip(row.keys(), row)) for row in rows]
+                elif self._row_format == "record":
+                    self._result = [Record(row, row.keys()) for row in rows]
+                else:
+                    self._result = rows
+        except (DatabaseError, OperationalError) as err:
+            error = "Query Error: {}".format(str(err))
+            raise DriverError(message=error)
+        except Exception as err:
+            error = "Query Error, Terminated: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            self.generated_at()
+            return [self._result, error]
+
+    def queryrow(self, sentence: Any):
+        """
+        Running Query and return only one row.
+        """
+        self._result = None
+        error = None
+        self.valid_operation(sentence)
+        try:
+            self._logger.debug("Running Query {}".format(sentence))
+            result = self._connection.execute(sentence)
+            if result:
+                row = result.fetchone()
+                if self._row_format == "dict":
+                    self._result = dict(row)
+                elif self._row_format == "iterable":
+                    self._result = dict(zip(row.keys(), row))
+                elif self._row_format == "record":
+                    self._result = Record(row, row.keys())
+                else:
+                    self._result = row
+        except (DatabaseError, OperationalError) as err:
+            error = "Query Row Error: {}".format(str(err))
+            raise DriverError(message=error)
+        except Exception as err:
+            error = "Query Row Error, Terminated: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            return [self._result, error]
+
+    def fetch_all(self, sentence: Any, params: List = None):
+        """
+        Running Query.
+        """
+        result = None
+        self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            self._logger.debug("Running Query {}".format(sentence))
+            result = self._connection.execute(sentence, params)
+            if result:
+                rows = result.fetchall()
+                if self._row_format == "dict" or self._row_format == "iterable":
+                    result = [dict(zip(row.keys(), row)) for row in rows]
+                elif self._row_format == "record":
+                    result = [Record(row, row.keys()) for row in rows]
+                else:
+                    result = rows
+        except (DatabaseError, OperationalError) as err:
+            error = "Query Error: {}".format(str(err))
+            raise DriverError(message=error)
+        except Exception as err:
+            error = "Query Error, Terminated: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            self.generated_at()
+            return result
+
+    def fetch_one(self, sentence: Any):
+        """
+        Running Query and return only one row.
+        """
+        result = None
+        self.valid_operation(sentence)
+        try:
+            self._logger.debug("Running Query {}".format(sentence))
+            result = self._connection.execute(sentence)
+            if result:
+                row = result.fetchone()
+                if self._row_format == "dict":
+                    result = dict(row)
+                elif self._row_format == "iterable":
+                    result = dict(zip(row.keys(), row))
+                elif self._row_format == "record":
+                    result = Record(row, row.keys())
+                else:
+                    result = row
+        except (DatabaseError, OperationalError) as err:
+            error = "Query Row Error: {}".format(str(err))
+            raise DriverError(message=error)
+        except Exception as err:
+            error = "Query Row Error, Terminated: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            return result
+
+    fetchone = fetch_one
+
+    def execute(self, sentence, params: List = None):
+        """Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        self._result = None
+        error = None
+        self.valid_operation(sentence)
+        try:
+            self._logger.debug("Execute Sentence {}".format(sentence))
+            result = self._connection.execute(sentence, params)
+            self._result = result
+        except (DatabaseError, OperationalError) as err:
+            error = "Execute Error: {}".format(str(err))
+            raise DriverError(message=error)
+        except Exception as err:
+            error = "Exception Error on Execute: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            return [self._result, error]
+
+    def execute_many(self, sentence, params: List):
+        """Execute multiples transactions."""
+        self._result = None
+        error = None
+        self.valid_operation(sentence)
+        try:
+            self._logger.debug("Execute Sentence {}".format(sentence))
+            result = self._connection.execute(sentence, params)
+            self._result = result
+        except (DatabaseError, OperationalError) as err:
+            error = "Execute Error: {}".format(str(err))
+            raise DriverError(message=error)
+        except Exception as err:
+            error = "Exception Error on Execute: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            return [self._result, error]
+
+    executemany = execute_many
+
+    """
+    Transaction Context
+    """
+
+    def transaction(self):
+        if not self._connection:
+            self.connection()
+        self._transaction = self._connection.begin()
+        return self
+
+    def commit(self):
+        if self._transaction:
+            self._transaction.commit()
+
+    def rollback(self):
+        if self._transaction:
+            self._transaction.rollback()
+
+    def close_transaction(self):
+        if self._transaction:
+            try:
+                self._transaction.commit()
+                self._transaction.close()
+            except InvalidRequestError:
+                # transaction inactive
+                pass
+            except (SQLAlchemyError, DatabaseError, OperationalError) as err:
+                error = "Exception Error on Transaction: {}".format(str(err))
+                raise DriverError(message=error)
+            finally:
+                self._transaction = None
+
+    """
+    Context magic Methods
+    """
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, exc_type, exc, tb):
+        if self._transaction:
+            self.close_transaction()
+        self.release()
+
+    """
+    DDL Information.
+    """
+
+    def create(self, obj: str = "table", name: str = "", fields: Optional[List] = None) -> bool:
+        """
+        Create is a generic method for Database Objects Creation.
+        """
+        if obj == "table":
+            sql = "CREATE TABLE IF NOT EXISTS {name}({columns});"
+            columns = ", ".join(["{name} {type}".format(**e) for e in fields])
+            sql = sql.format(name=name, columns=columns)
+            try:
+                result = self._connection.execute(sql)
+                if result:
+                    return True
+                else:
+                    return False
+            except ProgrammingError as err:
+                raise DriverError(f"SQLAlchemy: Relation already exists: {err!s}")
+            except Exception as err:
+                raise DriverError(f"SQLAlchemy: Error in Object Creation: {err!s}")
+        else:
+            raise RuntimeError(f"SQLAlchemy: invalid Object type {object!s}")
+
+    """
+    Model Logic:
+    """
+
+    def column_info(self, tablename: str, schema: str = None):
+        """Column Info.
+
+        Get Meta information about a table (column name, data type and PK).
+        Useful to build a DataModel from Querying database.
+        Parameters:
+        @tablename: str The name of the table (including schema).
+        """
+        if schema:
+            table = f"{schema}.{tablename}"
+        else:
+            table = tablename
+        if self._driver == "postgresql":
+            sql = f"SELECT a.attname AS name, a.atttypid::regtype AS type, \
+            format_type(a.atttypid, a.atttypmod) as format_type, a.attnotnull::boolean as notnull, \
+            coalesce((SELECT true FROM pg_index i WHERE i.indrelid = a.attrelid \
+            AND i.indrelid = a.attrelid AND a.attnum = any(i.indkey) \
+            AND i.indisprimary), false) as is_primary \
+            FROM pg_attribute a WHERE a.attrelid = '{table!s}'::regclass \
+            AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum"
+        else:
+            raise NotImplementedError
+        if not self._connection:
+            self.connection()
+        try:
+            f = self._row_format
+            self._row_format = "dict"
+            colinfo = self.fetch_all(sql)
+            self._row_format == f
+            return colinfo
+        except Exception as err:
+            self._logger.exception(f"Wrong Table information {tablename!s}: {err}")
+
+    """
+    Metadata information.
+    """
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def use(self, tablename: str):
+        raise NotImplementedError("SQLAlchemy Error: There is no Database.")
```

## asyncdb/drivers/influx.py

```diff
@@ -1,519 +1,514 @@
-#!/usr/bin/env python3
-from typing import Any, Union
-import asyncio
-import json
-import time
-import logging
-from dataclasses import is_dataclass, asdict
-from functools import partial
-from urllib3 import Retry
-from datetime import datetime, timezone
-from datamodel.parsers.json import json_decoder
-from influxdb_client import InfluxDBClient, Dialect, BucketRetentionRules
-from influxdb_client.client.write_api import ASYNCHRONOUS, PointSettings
-
-from influxdb_client import Point
-from influxdb_client.client.influxdb_client_async import InfluxDBClientAsync
-
-
-from influxdb_client.client.exceptions import InfluxDBError
-from influxdb_client.client.flux_table import FluxStructureEncoder
-from influxdb_client.rest import _BaseRESTClient
-import pandas
-from asyncdb.exceptions import NoDataFound, DriverError
-from asyncdb.interfaces import ConnectionDSNBackend
-from .abstract import InitDriver
-
-
-class WriteCallback:
-    def success(self, conf: tuple[str, str, str], data: str):
-        """Successfully written batch."""
-        logging.debug(f"Written batch: {conf}, data: {data}")
-
-    def error(self, conf: tuple[str, str, str], data: str, exception: InfluxDBError):
-        """Unsuccessfully writen batch."""
-        logging.error(f"Cannot write batch: {conf}, data: {data} due: {exception}")
-
-    def retry(self, conf: tuple[str, str, str], data: str, exception: InfluxDBError):
-        """Retryable error."""
-        logging.error(f"Retryable error occurs for batch: {conf}, data: {data} retry: {exception}")
-
-
-class influx(InitDriver, ConnectionDSNBackend):
-    _provider = "influxdb"
-    _syntax = "sql"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._test_query = "SELECT 1"
-        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
-        self._version: str = None
-        self._dsn = "{protocol}://{host}:{port}"
-        self._client = InfluxDBClientAsync
-        self._enable_gzip = kwargs.get("enable_gzip", True)
-        self._retries = Retry(connect=5, read=2, redirect=5)
-        try:
-            self._debug = kwargs["debug"]
-        except KeyError:
-            self._debug = False
-        if not params:
-            params: dict = {"host": "localhost", "port": 8086}
-        try:
-            params["protocol"] = kwargs["protocol"]
-        except KeyError:
-            params["protocol"] = "http"
-        InitDriver.__init__(self, loop=loop, params=params, **kwargs)
-        ConnectionDSNBackend.__init__(self, dsn=dsn, params=params)
-        try:
-            self._config_file: str = kwargs["config_file"]
-        except KeyError:
-            self._config_file = None
-        if self._config_file is None:
-            # authentication:
-            try:
-                self._token = self.params["token"]
-            except KeyError:
-                try:
-                    self._token = self.params["password"]
-                except KeyError as e:
-                    raise DriverError("InfluxDB: Missing Token Authentication.") from e
-                self._token = None
-            try:
-                self._org = self.params["org"] if self.params["org"] else self.params["organization"]
-            except KeyError:
-                try:
-                    self._org = kwargs["user"]
-                except KeyError as e:
-                    raise DriverError("InfluxDB: Missing Organization on Connection Info.") from e
-        # callback
-        self._callback = WriteCallback
-        # dialect for export to csv
-        self._dialect = Dialect(
-            header=True, delimiter=",", comment_prefix="#", annotations=[], date_time_format="RFC3339"
-        )
-
-    async def connection(self):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            if self._config_file:
-                self._client = partial(InfluxDBClientAsync.from_config_file, self._config_file)
-                self._connection = InfluxDBClient.from_config_file(self._config_file, enable_gzip=self._enable_gzip)
-            else:
-                params = {
-                    "timeout": self._timeout * 1000,
-                    "connection_pool_maxsize": 5,
-                    "enable_gzip": True,
-                    "debug": self._debug,
-                    "org": self._org,
-                    "enable_gzip": self._enable_gzip,
-                }
-                if self._dsn:
-                    params["url"] = self._dsn
-                else:
-                    # fallback to host
-                    params["url"] = self.params["host"]
-                if self._token:
-                    params["token"] = self._token
-                self._client = partial(InfluxDBClientAsync, **params)
-                self._connection = InfluxDBClient(**params)
-            # checking if works:
-            try:
-                self._version = self._connection.version()
-            except Exception as err:
-                logging.exception(f"Error creating REST client: {err}")
-                raise DriverError(f"Error creating REST client: {err}") from err
-            settings = {"app_name": "${env.APP_NAME}", "customer": self._org}
-            self._settings = PointSettings(**settings)
-            if self._version:
-                self._connected = True
-                self._initialized_on = time.time()
-            return self
-        except Exception as err:
-            self._connection = None
-            self._cursor = None
-            logging.exception(err)
-            raise DriverError(message=f"InfluxDB connection Error: {err!s}") from err
-
-    async def close(self):  # pylint: disable=W0221
-        """
-        Closing a Connection
-        """
-        try:
-            if self._connection:
-                self._logger.debug("InfluxDB: Closing Connection")
-                try:
-                    self._connection.close()
-                except Exception as err:
-                    self._connection = None
-                    self._logger.warning(f"InfluxDB: Connection Error, Terminated: {err!s}")
-        except Exception as err:
-            raise DriverError(message=f"InfluxDB: Close Error: {err!s}") from err
-        finally:
-            self._connection = None
-            self._connected = False
-            self._client = None
-
-    async def test_connection(self):  # pylint: disable=W0221
-        error = None
-        result = None
-        if self._connection:
-            try:
-                result = self._connection.health()
-            except Exception as err:  # pylint: disable=W0703
-                error = err
-            finally:
-                return [result, error]  # pylint: disable=W0150
-
-    def api_client(self, client):
-        return client.api_client
-
-    def to_isoformat(self, dt: datetime) -> datetime:
-        dt.replace(tzinfo=timezone.utc)
-        return dt.isoformat(timespec="seconds") + "Z"
-
-    def point(self, measurement: str, tag: list, field: list, time: Union[str, int] = None) -> Point:
-        point = Point(measurement).tag(*tag).field(*field)
-        if time is not None:
-            point.time(time)
-        return point
-
-    async def ping(self):
-        """ping.
-
-            Check if the influx instance is active.
-        Returns:
-            bool: a boolean with the response of the instance.
-        """
-        async with self._client() as client:
-            return await client.ping()
-
-    async def health(self):
-        """health.
-
-        Returns:
-            HealthCheck: a class with Health information of the instance
-        """
-        return self._connection.health()
-
-    @property
-    def organization(self):
-        """Organization Name."""
-        return self._org
-
-    @organization.setter
-    def organization(self, org):
-        self._org = org
-
-    def settings(self, config: dict):
-        """settings.
-            Set Default Tags for every measurement.
-        Args:
-            config (Dict): list of variable values to be used as settings.
-        """
-        self._settings = PointSettings(**config)
-
-    def set_callback(self, callback: WriteCallback):
-        """SetCallback.
-
-        Set the current Callback for Writes.
-
-        Args:
-            callback (function): an extension class from WriteCallback.
-        """
-        self._callback = callback
-
-    def version(self):
-        """version.
-        Get Version information about InfluxDB instance.
-        Returns:
-            dict: version information.
-        """
-        return self._version
-
-    async def list_buckets(self):
-        buckets_api = self._connection.buckets_api()
-        return buckets_api.find_buckets().buckets
-
-    async def drop_bucket(self, bucket: str):
-        try:
-            buckets_api = self._connection.buckets_api()
-            bname = buckets_api.find_bucket_by_name(bucket)
-            if bname:
-                deleted = buckets_api.delete_bucket(bname)
-                return deleted
-            else:
-                self._logger.error(f"Bucket {bucket} does not exist.")
-                return False
-        except Exception as err:
-            raise DriverError(message=f"Error Deleting Bucket {bucket}: {err}") from err
-
-    drop_database = drop_bucket
-
-    async def create_bucket(self, bucket: str, btype: str = "expire", expiration: int = 0, **kwgars):
-        try:
-            buckets_api = self._connection.buckets_api()
-            rules = BucketRetentionRules(type=btype, every_seconds=expiration, **kwgars)
-            print("ORG ", self._org)
-            created = buckets_api.create_bucket(bucket_name=bucket, retention_rules=rules, org=self._org)
-            print(created)
-        except Exception as err:
-            raise DriverError(message=f"Error creating Bucket {err}") from err
-
-    create_database = create_bucket
-
-    async def use(self, database: str):
-        pass
-
-    async def write_data(self, data: list, bucket: str, **kwargs):
-        """
-        Write data into InfluxDB.
-        """
-        try:
-            result = None
-            with self._connection.write_api(
-                write_options=ASYNCHRONOUS,
-                success_callback=self._callback.success,
-                error_callback=self._callback.error,
-                retry_callback=self._callback.retry,
-                point_settings=self._settings,
-            ) as writer:
-                if isinstance(data, pandas.core.frame.DataFrame):
-                    # need the index and the name of the measurement
-                    rst = writer.write(
-                        bucket=bucket,
-                        org=self._org,
-                        data_frame_measurement_name=kwargs["name"],
-                        data_frame_tag_columns=kwargs["index"],
-                        record=data,
-                    )
-                elif is_dataclass(data):
-                    name = kwargs["name"]
-                    tag_keys = list(asdict(data).keys())
-                    field_keys = kwargs["fields"]
-                    try:
-                        time_keys = kwargs["time"]
-                    except KeyError:
-                        time_keys = {}
-                    rst = writer.write(
-                        bucket=bucket,
-                        org=self._org,
-                        record_measurement_name=name,
-                        record_tag_keys=tag_keys,
-                        record_field_keys=field_keys,
-                        **time_keys,
-                    )
-                else:
-                    rst = writer.write(bucket=bucket, org=self._org, record=data)
-                result = rst.get()
-            return result
-        except RuntimeError as err:
-            raise DriverError(f"InfluxDB: Runtime Error: {err!s}") from err
-        except Exception as err:
-            raise Exception(f"InfluxDB: Error on Write: {err!s}") from err
-
-    async def write(self, data: Union[list, dict], bucket: str, **kwargs):
-        """
-        Write data into InfluxDB (async version).
-        """
-        try:
-            result = None
-            async with self._client() as client:
-                writer = client.write_api(point_settings=self._settings)
-                if isinstance(data, pandas.core.frame.DataFrame):
-                    # need the index and the name of the measurement
-                    _name = kwargs.get("name", None)
-                    idx = kwargs.get("index", None)
-                    result = await writer.write(
-                        bucket=bucket,
-                        org=self._org,
-                        data_frame_measurement_name=_name,
-                        data_frame_tag_columns=idx,
-                        record=data,
-                        **kwargs,
-                    )
-                elif is_dataclass(data):
-                    name = kwargs["name"]
-                    tag_keys = list(asdict(data).keys())
-                    field_keys = kwargs["fields"]
-                    try:
-                        time_keys = kwargs["time"]
-                    except KeyError:
-                        time_keys = {}
-                    result = await writer.write(
-                        bucket=bucket,
-                        org=self._org,
-                        record_measurement_name=name,
-                        record_tag_keys=tag_keys,
-                        record_field_keys=field_keys,
-                        **time_keys,
-                    )
-                else:
-                    result = await writer.write(bucket=bucket, org=self._org, record=data)
-                return result
-        except RuntimeError as err:
-            raise DriverError(f"InfluxDB: Runtime Error: {err!s}") from err
-        except Exception as err:
-            raise Exception(f"InfluxDB: Error on Write: {err!s}") from err
-
-    save = write
-    copy = write
-
-    async def query(self, sentence: str, frmt: str = "native", params: dict = None, **kwargs):
-        self._result = None
-        try:
-            json_output = kwargs["json_output"]
-            del kwargs["json_output"]
-        except KeyError:
-            json_output = None
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            async with self._client() as client:
-                query_api = client.query_api()
-                if frmt == "flux":
-                    reader = partial(query_api.query_stream, query=sentence, params=params, **kwargs)
-                elif frmt == "pandas":
-                    reader = partial(query_api.query_data_frame, query=sentence, params=params, **kwargs)
-                elif frmt == "csv":
-                    reader = partial(
-                        query_api.query_csv, query=sentence, params=params, dialect=self._dialect, **kwargs
-                    )
-                else:
-                    reader = partial(query_api.query, query=sentence, params=params, **kwargs)
-                result = await reader()
-                if result is None:
-                    raise NoDataFound("InfluxDB: No Data was Found")
-                if frmt == "json":
-                    self._result = json.dumps(result, cls=FluxStructureEncoder)
-                elif frmt == "recordset":
-                    results = []
-                    for table in result:
-                        for record in table.records:
-                            try:
-                                row = {
-                                    "measurement": record.get_measurement(),
-                                    "time": record.get_time(),
-                                    **record.values,
-                                }
-                            except KeyError:
-                                row = {**record.values}
-                                if json_output:
-                                    for k, v in row.items():
-                                        if k in json_output:
-                                            try:
-                                                row[k] = json_decoder(v)
-                                            except (ValueError, TypeError):
-                                                pass
-                            results.append(row)
-                    self._result = results
-                else:
-                    # returning a FluxTable
-                    self._result = [r for r in result]
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    queryrow = query
-
-    async def fetch_all(self, sentence: str, params: dict = None, frmt: str = "native", **kwargs):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            result = None
-            async with self._client() as client:
-                query_api = client.query_api()
-                if frmt == "flux":
-                    reader = partial(query_api.query_stream, query=sentence, params=params, **kwargs)
-                elif frmt == "pandas":
-                    reader = partial(query_api.query_data_frame, query=sentence, params=params, **kwargs)
-                elif frmt == "csv":
-                    reader = partial(
-                        query_api.query_csv, query=sentence, params=params, dialect=self._dialect, **kwargs
-                    )
-                else:
-                    reader = partial(query_api.query, query=sentence, params=params, **kwargs)
-                result = await reader()
-            if not result:
-                raise NoDataFound("InfluxDB: No Data was Found")
-            if frmt == "json":
-                result = json.dumps(result, cls=FluxStructureEncoder)
-            self.generated_at()
-            return result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Error on Query: {err}") from err
-
-    fetch_one = fetch_all
-
-    async def delete(self, bucket: str, predicate: str = None, **kwargs):
-        """delete.
-
-            Delete Records from Bucket.
-        Args:
-            bucket (str): bucket name
-            *args: any optional arguments to Delete API.
-            predicate (str, optional): any optional predicate. Defaults to None.
-        """
-        try:
-            async with self._client() as client:
-                successfully = await client.delete_api().delete(bucket=bucket, predicate=predicate, **kwargs)
-                return f"Deleted?: {successfully}"
-        except RuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Error on Query: {err}") from err
-
-    async def execute(self, sentence: str, method: str = "GET", **kwargs):  # pylint: disable=W0221
-        """Execute a transaction.
-
-        returns: results of the execution
-        """
-        error = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            rst = self._client.call_api(sentence, method, **kwargs)
-            print(rst, type(rst), str(rst))
-            rst = self._client.request(url=self._dsn + sentence, method=method, **kwargs)
-            print(rst, type(rst), str(rst))
-            if isinstance(rst, _BaseRESTClient):
-                try:
-                    result = json.loads(rst.data)
-                except ValueError:
-                    result = rst.data
-            else:
-                result = rst
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Execute: {err}"
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    async def execute_many(self, sentence: Union[str, Any], method: str = "GET", **kwargs):
-        """Execute many transactions at once.
-
-        returns: results of the execution
-        """
-        raise NotImplementedError
-
-    def column_info(self, table):
-        """
-        column_info
-          get column information about a table
-        """
-        raise NotImplementedError
-
-    def prepare(self, sentence: str, *args, **kwargs):
-        raise NotImplementedError
+#!/usr/bin/env python3
+from typing import Any, Union
+import asyncio
+import json
+import time
+import logging
+from dataclasses import is_dataclass, asdict
+from functools import partial
+from urllib3 import Retry
+from datetime import datetime, timezone
+from datamodel.parsers.json import json_decoder
+from influxdb_client import InfluxDBClient, Dialect, BucketRetentionRules
+from influxdb_client.client.write_api import ASYNCHRONOUS, PointSettings
+from influxdb_client import Point
+from influxdb_client.client.influxdb_client_async import InfluxDBClientAsync
+from influxdb_client.client.exceptions import InfluxDBError
+from influxdb_client.client.flux_table import FluxStructureEncoder
+from influxdb_client.rest import _BaseRESTClient
+import pandas
+from ..exceptions import NoDataFound, DriverError
+from ..interfaces import ConnectionDSNBackend
+from .abstract import InitDriver
+
+
+class WriteCallback:
+    def success(self, conf: tuple[str, str, str], data: str):
+        """Successfully written batch."""
+        logging.debug(f"Written batch: {conf}, data: {data}")
+
+    def error(self, conf: tuple[str, str, str], data: str, exception: InfluxDBError):
+        """Unsuccessfully writen batch."""
+        logging.error(f"Cannot write batch: {conf}, data: {data} due: {exception}")
+
+    def retry(self, conf: tuple[str, str, str], data: str, exception: InfluxDBError):
+        """Retryable error."""
+        logging.error(f"Retryable error occurs for batch: {conf}, data: {data} retry: {exception}")
+
+
+class influx(InitDriver, ConnectionDSNBackend):
+    _provider = "influxdb"
+    _syntax = "sql"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._test_query = "SELECT 1"
+        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
+        self._version: str = None
+        self._dsn = "{protocol}://{host}:{port}"
+        self._client = InfluxDBClientAsync
+        self._enable_gzip = kwargs.get("enable_gzip", True)
+        self._retries = Retry(connect=5, read=2, redirect=5)
+        try:
+            self._debug = kwargs["debug"]
+        except KeyError:
+            self._debug = False
+        if not params:
+            params: dict = {"host": "localhost", "port": 8086}
+        try:
+            params["protocol"] = kwargs["protocol"]
+        except KeyError:
+            params["protocol"] = "http"
+        InitDriver.__init__(self, loop=loop, params=params, **kwargs)
+        ConnectionDSNBackend.__init__(self, dsn=dsn, params=params)
+        try:
+            self._config_file: str = kwargs["config_file"]
+        except KeyError:
+            self._config_file = None
+        if self._config_file is None:
+            # authentication:
+            try:
+                self._token = self.params["token"]
+            except KeyError:
+                try:
+                    self._token = self.params["password"]
+                except KeyError as e:
+                    raise DriverError("InfluxDB: Missing Token Authentication.") from e
+                self._token = None
+            try:
+                self._org = self.params["org"] if self.params["org"] else self.params["organization"]
+            except KeyError:
+                try:
+                    self._org = kwargs["user"]
+                except KeyError as e:
+                    raise DriverError("InfluxDB: Missing Organization on Connection Info.") from e
+        # callback
+        self._callback = WriteCallback
+        # dialect for export to csv
+        self._dialect = Dialect(
+            header=True, delimiter=",", comment_prefix="#", annotations=[], date_time_format="RFC3339"
+        )
+
+    async def connection(self):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            if self._config_file:
+                self._client = partial(InfluxDBClientAsync.from_config_file, self._config_file)
+                self._connection = InfluxDBClient.from_config_file(self._config_file, enable_gzip=self._enable_gzip)
+            else:
+                params = {
+                    "timeout": self._timeout * 1000,
+                    "connection_pool_maxsize": 5,
+                    "debug": self._debug,
+                    "org": self._org,
+                    "enable_gzip": self._enable_gzip,
+                }
+                if self._dsn:
+                    params["url"] = self._dsn
+                else:
+                    # fallback to host
+                    params["url"] = self.params["host"]
+                if self._token:
+                    params["token"] = self._token
+                self._client = partial(InfluxDBClientAsync, **params)
+                self._connection = InfluxDBClient(**params)
+            # checking if works:
+            try:
+                self._version = self._connection.version()
+            except Exception as err:
+                logging.exception(f"Error creating REST client: {err}")
+                raise DriverError(f"Error creating REST client: {err}") from err
+            settings = {"app_name": "${env.APP_NAME}", "customer": self._org}
+            self._settings = PointSettings(**settings)
+            if self._version:
+                self._connected = True
+                self._initialized_on = time.time()
+            return self
+        except Exception as err:
+            self._connection = None
+            self._cursor = None
+            logging.exception(err)
+            raise DriverError(message=f"InfluxDB connection Error: {err!s}") from err
+
+    async def close(self):  # pylint: disable=W0221
+        """
+        Closing a Connection
+        """
+        try:
+            if self._connection:
+                try:
+                    self._connection.close()
+                except Exception as err:
+                    self._connection = None
+                    self._logger.warning(f"InfluxDB: Connection Error, Terminated: {err!s}")
+        except Exception as err:
+            raise DriverError(message=f"InfluxDB: Close Error: {err!s}") from err
+        finally:
+            self._connection = None
+            self._connected = False
+            self._client = None
+
+    async def test_connection(self):  # pylint: disable=W0221
+        error = None
+        result = None
+        if self._connection:
+            try:
+                result = self._connection.health()
+            except Exception as err:  # pylint: disable=W0703
+                error = err
+            finally:
+                return [result, error]  # pylint: disable=W0150
+
+    def api_client(self, client):
+        return client.api_client
+
+    def to_isoformat(self, dt: datetime) -> datetime:
+        dt.replace(tzinfo=timezone.utc)
+        return dt.isoformat(timespec="seconds") + "Z"
+
+    def point(self, measurement: str, tag: list, field: list, time: Union[str, int] = None) -> Point:
+        point = Point(measurement).tag(*tag).field(*field)
+        if time is not None:
+            point.time(time)
+        return point
+
+    async def ping(self):
+        """ping.
+
+            Check if the influx instance is active.
+        Returns:
+            bool: a boolean with the response of the instance.
+        """
+        async with self._client() as client:
+            return await client.ping()
+
+    async def health(self):
+        """health.
+
+        Returns:
+            HealthCheck: a class with Health information of the instance
+        """
+        return self._connection.health()
+
+    @property
+    def organization(self):
+        """Organization Name."""
+        return self._org
+
+    @organization.setter
+    def organization(self, org):
+        self._org = org
+
+    def settings(self, config: dict):
+        """settings.
+            Set Default Tags for every measurement.
+        Args:
+            config (Dict): list of variable values to be used as settings.
+        """
+        self._settings = PointSettings(**config)
+
+    def set_callback(self, callback: WriteCallback):
+        """SetCallback.
+
+        Set the current Callback for Writes.
+
+        Args:
+            callback (function): an extension class from WriteCallback.
+        """
+        self._callback = callback
+
+    def version(self):
+        """version.
+        Get Version information about InfluxDB instance.
+        Returns:
+            dict: version information.
+        """
+        return self._version
+
+    async def list_buckets(self):
+        buckets_api = self._connection.buckets_api()
+        return buckets_api.find_buckets().buckets
+
+    async def drop_bucket(self, bucket: str):
+        try:
+            buckets_api = self._connection.buckets_api()
+            bname = buckets_api.find_bucket_by_name(bucket)
+            if bname:
+                deleted = buckets_api.delete_bucket(bname)
+                return deleted
+            else:
+                self._logger.error(f"Bucket {bucket} does not exist.")
+                return False
+        except Exception as err:
+            raise DriverError(message=f"Error Deleting Bucket {bucket}: {err}") from err
+
+    drop_database = drop_bucket
+
+    async def create_bucket(self, bucket: str, btype: str = "expire", expiration: int = 0, **kwgars):
+        try:
+            buckets_api = self._connection.buckets_api()
+            rules = BucketRetentionRules(type=btype, every_seconds=expiration, **kwgars)
+            print("ORG ", self._org)
+            created = buckets_api.create_bucket(bucket_name=bucket, retention_rules=rules, org=self._org)
+            print(created)
+        except Exception as err:
+            raise DriverError(message=f"Error creating Bucket {err}") from err
+
+    create_database = create_bucket
+
+    async def use(self, database: str):
+        pass
+
+    async def write_data(self, data: list, bucket: str, **kwargs):
+        """
+        Write data into InfluxDB.
+        """
+        try:
+            result = None
+            with self._connection.write_api(
+                write_options=ASYNCHRONOUS,
+                success_callback=self._callback.success,
+                error_callback=self._callback.error,
+                retry_callback=self._callback.retry,
+                point_settings=self._settings,
+            ) as writer:
+                if isinstance(data, pandas.core.frame.DataFrame):
+                    # need the index and the name of the measurement
+                    rst = writer.write(
+                        bucket=bucket,
+                        org=self._org,
+                        data_frame_measurement_name=kwargs["name"],
+                        data_frame_tag_columns=kwargs["index"],
+                        record=data,
+                    )
+                elif is_dataclass(data):
+                    name = kwargs["name"]
+                    tag_keys = list(asdict(data).keys())
+                    field_keys = kwargs["fields"]
+                    try:
+                        time_keys = kwargs["time"]
+                    except KeyError:
+                        time_keys = {}
+                    rst = writer.write(
+                        bucket=bucket,
+                        org=self._org,
+                        record_measurement_name=name,
+                        record_tag_keys=tag_keys,
+                        record_field_keys=field_keys,
+                        **time_keys,
+                    )
+                else:
+                    rst = writer.write(bucket=bucket, org=self._org, record=data)
+                result = rst.get()
+            return result
+        except RuntimeError as err:
+            raise DriverError(f"InfluxDB: Runtime Error: {err!s}") from err
+        except Exception as err:
+            raise Exception(f"InfluxDB: Error on Write: {err!s}") from err
+
+    async def write(self, data: Union[list, dict], bucket: str, **kwargs):
+        """
+        Write data into InfluxDB (async version).
+        """
+        try:
+            result = None
+            async with self._client() as client:
+                writer = client.write_api(point_settings=self._settings)
+                if isinstance(data, pandas.core.frame.DataFrame):
+                    # need the index and the name of the measurement
+                    _name = kwargs.get("name", None)
+                    idx = kwargs.get("index", None)
+                    result = await writer.write(
+                        bucket=bucket,
+                        org=self._org,
+                        data_frame_measurement_name=_name,
+                        data_frame_tag_columns=idx,
+                        record=data,
+                        **kwargs,
+                    )
+                elif is_dataclass(data):
+                    name = kwargs["name"]
+                    tag_keys = list(asdict(data).keys())
+                    field_keys = kwargs["fields"]
+                    try:
+                        time_keys = kwargs["time"]
+                    except KeyError:
+                        time_keys = {}
+                    result = await writer.write(
+                        bucket=bucket,
+                        org=self._org,
+                        record_measurement_name=name,
+                        record_tag_keys=tag_keys,
+                        record_field_keys=field_keys,
+                        **time_keys,
+                    )
+                else:
+                    result = await writer.write(bucket=bucket, org=self._org, record=data)
+                return result
+        except RuntimeError as err:
+            raise DriverError(f"InfluxDB: Runtime Error: {err!s}") from err
+        except Exception as err:
+            raise Exception(f"InfluxDB: Error on Write: {err!s}") from err
+
+    save = write
+    copy = write
+
+    async def query(self, sentence: str, frmt: str = "native", params: dict = None, **kwargs):
+        self._result = None
+        try:
+            json_output = kwargs["json_output"]
+            del kwargs["json_output"]
+        except KeyError:
+            json_output = None
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            async with self._client() as client:
+                query_api = client.query_api()
+                if frmt == "flux":
+                    reader = partial(query_api.query_stream, query=sentence, params=params, **kwargs)
+                elif frmt == "pandas":
+                    reader = partial(query_api.query_data_frame, query=sentence, params=params, **kwargs)
+                elif frmt == "csv":
+                    reader = partial(
+                        query_api.query_csv, query=sentence, params=params, dialect=self._dialect, **kwargs
+                    )
+                else:
+                    reader = partial(query_api.query, query=sentence, params=params, **kwargs)
+                result = await reader()
+                if result is None:
+                    raise NoDataFound("InfluxDB: No Data was Found")
+                if frmt == "json":
+                    self._result = json.dumps(result, cls=FluxStructureEncoder)
+                elif frmt == "recordset":
+                    results = []
+                    for table in result:
+                        for record in table.records:
+                            try:
+                                row = {
+                                    "measurement": record.get_measurement(),
+                                    "time": record.get_time(),
+                                    **record.values,
+                                }
+                            except KeyError:
+                                row = {**record.values}
+                                if json_output:
+                                    for k, v in row.items():
+                                        if k in json_output:
+                                            try:
+                                                row[k] = json_decoder(v)
+                                            except (ValueError, TypeError):
+                                                pass
+                            results.append(row)
+                    self._result = results
+                else:
+                    # returning a FluxTable
+                    self._result = [r for r in result]
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    queryrow = query
+
+    async def fetch_all(self, sentence: str, params: dict = None, frmt: str = "native", **kwargs):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            result = None
+            async with self._client() as client:
+                query_api = client.query_api()
+                if frmt == "flux":
+                    reader = partial(query_api.query_stream, query=sentence, params=params, **kwargs)
+                elif frmt == "pandas":
+                    reader = partial(query_api.query_data_frame, query=sentence, params=params, **kwargs)
+                elif frmt == "csv":
+                    reader = partial(
+                        query_api.query_csv, query=sentence, params=params, dialect=self._dialect, **kwargs
+                    )
+                else:
+                    reader = partial(query_api.query, query=sentence, params=params, **kwargs)
+                result = await reader()
+            if not result:
+                raise NoDataFound("InfluxDB: No Data was Found")
+            if frmt == "json":
+                result = json.dumps(result, cls=FluxStructureEncoder)
+            self.generated_at()
+            return result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Error on Query: {err}") from err
+
+    fetch_one = fetch_all
+
+    async def delete(self, bucket: str, predicate: str = None, **kwargs):
+        """delete.
+
+            Delete Records from Bucket.
+        Args:
+            bucket (str): bucket name
+            *args: any optional arguments to Delete API.
+            predicate (str, optional): any optional predicate. Defaults to None.
+        """
+        try:
+            async with self._client() as client:
+                successfully = await client.delete_api().delete(bucket=bucket, predicate=predicate, **kwargs)
+                return f"Deleted?: {successfully}"
+        except RuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Error on Query: {err}") from err
+
+    async def execute(self, sentence: str, method: str = "GET", **kwargs):  # pylint: disable=W0221
+        """Execute a transaction.
+
+        returns: results of the execution
+        """
+        error = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            rst = self._client.call_api(sentence, method, **kwargs)
+            print(rst, type(rst), str(rst))
+            rst = self._client.request(url=self._dsn + sentence, method=method, **kwargs)
+            print(rst, type(rst), str(rst))
+            if isinstance(rst, _BaseRESTClient):
+                try:
+                    result = json.loads(rst.data)
+                except ValueError:
+                    result = rst.data
+            else:
+                result = rst
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Execute: {err}"
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    async def execute_many(self, sentence: Union[str, Any], method: str = "GET", **kwargs):
+        """Execute many transactions at once.
+
+        returns: results of the execution
+        """
+        raise NotImplementedError
+
+    def column_info(self, table):
+        """
+        column_info
+          get column information about a table
+        """
+        raise NotImplementedError
+
+    def prepare(self, sentence: str, *args, **kwargs):
+        raise NotImplementedError
```

## asyncdb/drivers/memcache.py

```diff
@@ -1,258 +1,264 @@
-#!/usr/bin/env python3
-""" memcache Provider.
-Notes on memcache Provider
---------------------
-This provider implements a simple subset of funcionalities from aiomcache.
-"""
-import asyncio
-import time
-import aiomcache
-from aiomcache.exceptions import ClientException
-from asyncdb.exceptions import DriverError
-from .abstract import (
-    BasePool,
-    BaseDriver,
-)
-
-
-class memcachePool(BasePool):
-    """
-    Pool-based version of Memcached connector.
-    """
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._dsn = None
-        self._connection = None
-        self._max_queries = 10
-        super(memcachePool, self).__init__(dsn, loop, params, **kwargs)
-
-    def create_dsn(self, params: dict):
-        return params
-
-    async def connect(self):
-        self._logger.debug(f"Memcache: Connecting to {self._params}")
-        try:
-            self._pool = aiomcache.Client(pool_size=self._max_queries, **self._params)
-
-        except ClientException as err:
-            raise DriverError(f"Unable to connect to Memcache: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Error: {err}") from err
-        # is connected
-        if self._pool:
-            self._connected = True
-            self._initialized_on = time.time()
-        return self
-
-    async def acquire(self):
-        """
-        Take a connection from the pool.
-        TODO: create a Pool infraestructure.
-        """
-        db = None
-        self._connection = None
-        try:
-            self._connection = self._pool
-        except ClientException as err:
-            raise DriverError(f"Unable to connect to Memcache: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Error: {err}") from err
-        if self._connection:
-            db = memcache(pool=self, loop=self._loop, connection=self._connection)
-        return db
-
-    async def release(self, connection=None):  # pylint: disable=W0221
-        """
-        Release a connection from the pool
-        """
-        if not connection:
-            conn = self._connection
-        else:
-            conn = connection
-        try:
-            if conn:
-                self._pool.release(conn)
-        except Exception as err:
-            raise DriverError(f"Memcache Release Error: {err}") from err
-
-    async def close(self):  # pylint: disable=W0221
-        """
-        Close Pool
-        """
-        try:
-            if self._pool:
-                await self._pool.close()
-        except ClientException as err:
-            raise DriverError(f"Connection Close Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Closing Error: {err}") from err
-
-    disconnect = close
-
-
-class memcache(BaseDriver):
-    _provider = "memcache"
-    _syntax = "nosql"
-
-    def __init__(self, dsn: str = None, loop=None, params: dict = None, **kwargs) -> None:
-        super(memcache, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-        if "pool" in kwargs:
-            self._pool = kwargs["pool"]
-            self._connection = kwargs["connection"]
-            self._connected = True
-            self._initialized_on = time.time()
-
-    def create_dsn(self, params: dict):
-        return params
-
-    # Create a memcache Connection
-    async def connection(self):
-        """
-        __init async Memcache initialization
-        """
-        self._logger.debug(f"Memcache: Connecting to {self._params}")
-        try:
-            self._connection = aiomcache.Client(**self._params)
-        except aiomcache.exceptions.ValidationException as err:
-            raise DriverError(f"Invalid Connection Parameters: {err}") from err
-        except ClientException as err:
-            raise DriverError(f"Unable to connect to Memcache: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Error: {err}") from err
-        # is connected
-        if self._connection:
-            self._connected = True
-            self._initialized_on = time.time()
-        return self
-
-    async def close(self):  # pylint: disable=W0221
-        """
-        Closing memcache Connection
-        """
-        if self._pool:
-            await self._pool.release(connection=self._connection)
-        else:
-            try:
-                await self._connection.close()
-            except ClientException as err:
-                raise DriverError(f"Unable to connect to Memcache: {err}") from err
-            except Exception as err:
-                raise DriverError(f"Unknown Error: {err}") from err
-
-    disconnect = close
-
-    async def flush(self):
-        """
-        Flush all elements inmediately
-        """
-        try:
-            if self._connection:
-                self._connection.flush_all()
-        except ClientException as err:
-            raise DriverError(f"Unable to connect to Memcache: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Error: {err}") from err
-
-    async def prepare(self, sentence=""):
-        raise NotImplementedError
-
-    async def execute(self, sentence=""):  # pylint: disable=W0221
-        raise NotImplementedError
-
-    async def execute_many(self, sentence: str = ""):  # pylint: disable=W0221
-        raise NotImplementedError
-
-    async def use(self, database: str) -> None:  # pylint: disable=W0221
-        raise NotImplementedError
-
-    async def get(self, key):
-        try:
-            result = await self._connection.get(bytes(key, "utf-8"))
-            if result:
-                return result.decode("utf-8")
-            else:
-                return None
-        except aiomcache.exceptions.ClientException as err:
-            raise DriverError(f"Get Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Memcache Unknown Error: {err}") from err
-
-    async def query(self, sentence, **kwargs):
-        return await self.get(sentence)
-
-    async def queryrow(self, sentence, **kwargs):  # pylint: disable=W0613
-        result = await self.get(sentence)
-        if isinstance(result, list):
-            result = result[0]
-        return result
-
-    fetch_one = queryrow
-
-    async def fetch_all(self, sentence, *args):  # pylint: disable=W0221
-        return await self.multiget(*args)
-
-    async def get_multi(self, *kwargs):
-        return await self.multiget(kwargs)
-
-    async def multiget(self, *args):
-        try:
-            ky = [bytes(key, "utf-8") for key in args]
-            print(ky)
-            result = await self._connection.multi_get(*ky)
-            print(result)
-            return [k.decode("utf-8") for k in result]
-        except ClientException as err:
-            raise DriverError(f"Get Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Memcache Unknown Error: {err}") from err
-
-    async def set(self, key, value, timeout: int = None):
-        try:
-            args = {}
-            if timeout:
-                args = {"exptime": timeout}
-            return await self._connection.set(bytes(key, "utf-8"), bytes(value, "utf-8"), **args)
-        except ClientException as err:
-            raise DriverError(f"Set Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Memcache Unknown Error: {err}") from err
-
-    async def set_multi(self, mapping: dict, timeout=0):
-        """Migrate to pylibmc with Threads."""
-        try:
-            for k, v in mapping.items():
-                await self._connection.set(bytes(k, "utf-8"), bytes(v, "utf-8"), timeout)
-        except ClientException as err:
-            raise DriverError(f"Set Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Memcache Unknown Error: {err}") from err
-
-    async def delete(self, key):
-        try:
-            return await self._connection.delete(bytes(key, "utf-8"))
-        except ClientException as err:
-            raise DriverError(f"Delete Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Memcache Unknown Error: {err}") from err
-
-    async def delete_multi(self, *kwargs):
-        try:
-            for key in kwargs:
-                result = await self._connection.delete(bytes(key, "utf-8"))
-            return result
-        except ClientException as err:
-            raise DriverError(f"DELETE Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"DELETE Unknown Error: {err}") from err
-
-    async def test_connection(self, key: str = "test_123", optional: str = "1"):  # pylint: disable=W0221
-        result = None
-        error = None
-        try:
-            await self.set(key, optional)
-            result = await self.get(key)
-        except Exception as err:  # pylint: disable=W0703
-            error = err
-        finally:
-            await self.delete(key)
-            return [result, error]  # pylint: disable=W0150
+#!/usr/bin/env python3
+""" memcache Provider.
+Notes on memcache Provider
+--------------------
+This provider implements a simple subset of funcionalities from aiomcache.
+"""
+import asyncio
+import time
+import aiomcache
+from aiomcache.exceptions import ClientException
+from ..exceptions import DriverError
+from .abstract import (
+    BasePool,
+    BaseDriver,
+)
+
+
+class memcachePool(BasePool):
+    """
+    Pool-based version of Memcached connector.
+    """
+
+    def __init__(
+        self,
+        dsn: str = "",
+        loop: asyncio.AbstractEventLoop = None,
+        params: dict = None,
+        **kwargs
+    ) -> None:
+        self._dsn = None
+        self._connection = None
+        self._max_queries = 10
+        super(memcachePool, self).__init__(dsn, loop, params, **kwargs)
+
+    def create_dsn(self, params: dict):
+        return params
+
+    async def connect(self):
+        self._logger.debug(f"Memcache: Connecting to {self._params}")
+        try:
+            self._pool = aiomcache.Client(pool_size=self._max_queries, **self._params)
+
+        except ClientException as err:
+            raise DriverError(f"Unable to connect to Memcache: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Error: {err}") from err
+        # is connected
+        if self._pool:
+            self._connected = True
+            self._initialized_on = time.time()
+        return self
+
+    async def acquire(self):
+        """
+        Take a connection from the pool.
+        TODO: create a Pool infraestructure.
+        """
+        db = None
+        self._connection = None
+        try:
+            self._connection = self._pool
+        except ClientException as err:
+            raise DriverError(f"Unable to connect to Memcache: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Error: {err}") from err
+        if self._connection:
+            db = memcache(pool=self, loop=self._loop, connection=self._connection)
+        return db
+
+    async def release(self, connection=None):  # pylint: disable=W0221
+        """
+        Release a connection from the pool
+        """
+        if not connection:
+            conn = self._connection
+        else:
+            conn = connection
+        try:
+            if conn:
+                self._pool.release(conn)
+        except Exception as err:
+            raise DriverError(f"Memcache Release Error: {err}") from err
+
+    async def close(self):  # pylint: disable=W0221
+        """
+        Close Pool
+        """
+        try:
+            if self._pool:
+                await self._pool.close()
+        except ClientException as err:
+            raise DriverError(f"Connection Close Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Closing Error: {err}") from err
+
+    disconnect = close
+
+
+class memcache(BaseDriver):
+    _provider = "memcache"
+    _syntax = "nosql"
+
+    def __init__(self, dsn: str = None, loop=None, params: dict = None, **kwargs) -> None:
+        super(memcache, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+        if "pool" in kwargs:
+            self._pool = kwargs["pool"]
+            self._connection = kwargs["connection"]
+            self._connected = True
+            self._initialized_on = time.time()
+
+    def create_dsn(self, params: dict):
+        return params
+
+    # Create a memcache Connection
+    async def connection(self):
+        """
+        __init async Memcache initialization
+        """
+        self._logger.debug(f"Memcache: Connecting to {self._params}")
+        try:
+            self._connection = aiomcache.Client(**self._params)
+        except aiomcache.exceptions.ValidationException as err:
+            raise DriverError(f"Invalid Connection Parameters: {err}") from err
+        except ClientException as err:
+            raise DriverError(f"Unable to connect to Memcache: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Error: {err}") from err
+        # is connected
+        if self._connection:
+            self._connected = True
+            self._initialized_on = time.time()
+        return self
+
+    async def close(self):  # pylint: disable=W0221
+        """
+        Closing memcache Connection
+        """
+        if self._pool:
+            await self._pool.release(connection=self._connection)
+        else:
+            try:
+                await self._connection.close()
+            except ClientException as err:
+                raise DriverError(f"Unable to connect to Memcache: {err}") from err
+            except Exception as err:
+                raise DriverError(f"Unknown Error: {err}") from err
+
+    disconnect = close
+
+    async def flush(self):
+        """
+        Flush all elements inmediately
+        """
+        try:
+            if self._connection:
+                self._connection.flush_all()
+        except ClientException as err:
+            raise DriverError(f"Unable to connect to Memcache: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Error: {err}") from err
+
+    async def prepare(self, sentence=""):
+        raise NotImplementedError
+
+    async def execute(self, sentence=""):  # pylint: disable=W0221
+        raise NotImplementedError
+
+    async def execute_many(self, sentence: str = ""):  # pylint: disable=W0221
+        raise NotImplementedError
+
+    async def use(self, database: str) -> None:  # pylint: disable=W0221
+        raise NotImplementedError
+
+    async def get(self, key):
+        try:
+            result = await self._connection.get(bytes(key, "utf-8"))
+            if result:
+                return result.decode("utf-8")
+            else:
+                return None
+        except aiomcache.exceptions.ClientException as err:
+            raise DriverError(f"Get Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Memcache Unknown Error: {err}") from err
+
+    async def query(self, sentence, **kwargs):
+        return await self.get(sentence)
+
+    async def queryrow(self, sentence, **kwargs):  # pylint: disable=W0613
+        result = await self.get(sentence)
+        if isinstance(result, list):
+            result = result[0]
+        return result
+
+    fetch_one = queryrow
+
+    async def fetch_all(self, sentence, *args):  # pylint: disable=W0221
+        return await self.multiget(*args)
+
+    async def get_multi(self, *kwargs):
+        return await self.multiget(kwargs)
+
+    async def multiget(self, *args):
+        try:
+            ky = [bytes(key, "utf-8") for key in args]
+            print(ky)
+            result = await self._connection.multi_get(*ky)
+            print(result)
+            return [k.decode("utf-8") for k in result]
+        except ClientException as err:
+            raise DriverError(f"Get Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Memcache Unknown Error: {err}") from err
+
+    async def set(self, key, value, timeout: int = None):
+        try:
+            args = {}
+            if timeout:
+                args = {"exptime": timeout}
+            return await self._connection.set(bytes(key, "utf-8"), bytes(value, "utf-8"), **args)
+        except ClientException as err:
+            raise DriverError(f"Set Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Memcache Unknown Error: {err}") from err
+
+    async def set_multi(self, mapping: dict, timeout=0):
+        """Migrate to pylibmc with Threads."""
+        try:
+            for k, v in mapping.items():
+                await self._connection.set(bytes(k, "utf-8"), bytes(v, "utf-8"), timeout)
+        except ClientException as err:
+            raise DriverError(f"Set Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Memcache Unknown Error: {err}") from err
+
+    async def delete(self, key):
+        try:
+            return await self._connection.delete(bytes(key, "utf-8"))
+        except ClientException as err:
+            raise DriverError(f"Delete Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Memcache Unknown Error: {err}") from err
+
+    async def delete_multi(self, *kwargs):
+        try:
+            for key in kwargs:
+                result = await self._connection.delete(bytes(key, "utf-8"))
+            return result
+        except ClientException as err:
+            raise DriverError(f"DELETE Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"DELETE Unknown Error: {err}") from err
+
+    async def test_connection(self, key: str = "test_123", optional: str = "1"):  # pylint: disable=W0221
+        result = None
+        error = None
+        try:
+            await self.set(key, optional)
+            result = await self.get(key)
+        except Exception as err:  # pylint: disable=W0703
+            error = err
+        finally:
+            await self.delete(key)
+            return [result, error]  # pylint: disable=W0150
```

## asyncdb/drivers/scylladb.py

```diff
@@ -1,743 +1,1467 @@
-from typing import Union, Any
-import asyncio
-import time
-from dataclasses import is_dataclass, astuple, fields
-from ssl import PROTOCOL_TLSv1
-import logging
-from pathlib import PurePath
-import aiofiles
-import pandas as pd
-
-# async driver:
-import acsylla as c
-
-# Cassandra:
-from cassandra import ReadTimeout
-from cassandra.concurrent import execute_concurrent
-from cassandra.policies import DCAwareRoundRobinPolicy, WhiteListRoundRobinPolicy, DowngradingConsistencyRetryPolicy
-from cassandra.cluster import Cluster, EXEC_PROFILE_DEFAULT, ExecutionProfile, NoHostAvailable, ResultSet
-from cassandra.query import (
-    dict_factory,
-    ordered_dict_factory,
-    named_tuple_factory,
-    ConsistencyLevel,
-    PreparedStatement,
-    BatchStatement,
-    SimpleStatement,
-    BatchType,
-)
-from cassandra.io.libevreactor import LibevConnection
-from cassandra.auth import PlainTextAuthProvider
-from cassandra.query import SimpleStatement
-from cassandra import ConsistencyLevel
-from asyncdb.meta import Recordset
-from asyncdb.exceptions import NoDataFound, DriverError
-from .abstract import InitDriver
-
-
-logging.getLogger("cassandra").setLevel(logging.INFO)
-BATCH_SIZE = 1000
-
-
-def pandas_factory(colnames, rows):
-    df = pd.DataFrame(rows, columns=colnames)
-    return df
-
-
-def record_factory(colnames, rows):
-    return Recordset(result=[dict(zip(colnames, values)) for values in rows], columns=colnames)
-
-
-class scylladb(InitDriver):
-    _provider = "scylladb"
-    _syntax = "cql"
-
-    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
-        self.hosts: list = []
-        self._test_query = "SELECT release_version FROM system.local"
-        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
-        self._cluster = None
-        self._timeout: int = 120
-        self._protocol: int = kwargs.pop("protocol", 4)
-        self._driver: str = kwargs.pop("driver", "cassandra")
-        self.heartbeat_interval: int = kwargs.pop("heartbeat_interval", 0)
-        super(scylladb, self).__init__(loop=loop, params=params, **kwargs)
-        try:
-            if "host" in self.params:
-                self._hosts = self.params["host"].split(",")
-        except KeyError:
-            self._hosts = ["127.0.0.1"]
-        try:
-            self.whitelist = kwargs["whitelist"]
-        except KeyError:
-            self.whitelist = None
-        try:
-            self._auth = {
-                "username": self.params["username"],
-                "password": self.params["password"],
-            }
-        except KeyError:
-            self._auth = None
-
-    def sync_close(self):
-        # gracefully closing underlying connection
-        if self._connection:
-            self._logger.debug("Closing Connection")
-            try:
-                self._connection.shutdown()
-            except Exception as err:
-                self._connection = None
-                raise DriverError(message=f"Connection Error, Terminated: {err}") from err
-        if self._cluster:
-            self._logger.debug("Closing Cluster")
-            try:
-                self._cluster.shutdown()
-            except Exception as err:
-                raise DriverError(f"Cluster Shutdown Error: {err}") from err
-
-    async def async_close(self):
-        if self._connection:
-            self._logger.debug("Closing Connection")
-            try:
-                await self._connection.close()
-            except Exception as err:
-                self._connection = None
-                raise DriverError(message=f"Connection Error, Terminated: {err}") from err
-        if self._cluster:
-            self._logger.debug("Closing Cluster")
-            try:
-                await self._cluster.close()
-            except Exception as err:
-                raise DriverError(f"Cluster Shutdown Error: {err}") from err
-
-    async def close(self):
-        """close.
-        Closing a Connection
-        """
-        try:
-            if self._driver == "async":
-                await self.async_close()
-            else:
-                self.sync_close()
-        finally:
-            self._cluster = None
-            self._connection = None
-            self._connected = False
-
-    async def async_connect(self, keyspace: str = None):
-        """
-        Getting a Connection using async driver:
-        """
-        self._connection = None
-        self._connected = False
-        self._cluster = None
-        ssl_opts = {}
-        try:
-            if self.params["ssl"] is not None:
-                ssl_opts = {
-                    "ssl_enable": True,
-                    "ssl_trusted_cert": self.params["ssl"]["certfile"],
-                    "ssl_version": PROTOCOL_TLSv1,
-                    "ssl_private_key": self.params["ssl"]["userkey"],
-                    "ssl_cert": self.params["ssl"]["usercert"],
-                }
-        except KeyError:
-            pass
-        if not self._auth:
-            self._auth = {}
-        params = {
-            "port": self.params["port"],
-            "compression": True,
-            "application_name": "Navigator",
-            "protocol_version": self._protocol,
-            "connect_timeout": self._timeout,
-            "heartbeat_interval_sec": self.heartbeat_interval,
-            "num_threads_io": 4,
-            **ssl_opts,
-            **self._auth,
-        }
-        try:
-            self._cluster = c.create_cluster(self._hosts, **params)
-            self._connection = await self._cluster.connect(keyspace=keyspace)
-            self._driver = "async"
-            if self._connection:
-                self._connected = True
-                self._initialized_on = time.time()
-            if "database" in self.params:
-                await self.use(self.params["database"])
-            else:
-                self._keyspace = keyspace
-        except DriverError:
-            raise
-        except Exception as err:
-            self._logger.exception(f"Scylla Connection Error: {err}")
-            self._connection = None
-            self._cursor = None
-            raise DriverError(message=f"Scylla Connection Error: {err}") from err
-
-    async def connect(self, keyspace=None):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        self._cluster = None
-        try:
-            try:
-                if self.params["ssl"] is not None:
-                    ssl_opts = {
-                        "ca_certs": self.params["ssl"]["certfile"],
-                        "ssl_version": PROTOCOL_TLSv1,
-                        "keyfile": self.params["ssl"]["userkey"],
-                        "certfile": self.params["ssl"]["usercert"],
-                    }
-            except KeyError:
-                ssl_opts = {}
-            if self.whitelist:
-                policy = WhiteListRoundRobinPolicy(self.whitelist)
-            else:
-                policy = DCAwareRoundRobinPolicy()
-            defaultprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=dict_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            pandasprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=pandas_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            tupleprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=named_tuple_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            orderedprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=ordered_dict_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            recordprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=record_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            profiles = {
-                EXEC_PROFILE_DEFAULT: defaultprofile,
-                "pandas": pandasprofile,
-                "ordered": orderedprofile,
-                "default": tupleprofile,
-                "recordset": recordprofile,
-            }
-            params = {
-                "port": self.params["port"],
-                "compression": True,
-                "connection_class": LibevConnection,
-                "protocol_version": self._protocol,
-                "connect_timeout": self._timeout,
-                "idle_heartbeat_interval": self.heartbeat_interval,
-                "ssl_options": ssl_opts,
-                "executor_threads": 4,
-            }
-            auth_provider = None
-            if self._auth:
-                auth_provider = PlainTextAuthProvider(**self._auth)
-            self._cluster = Cluster(
-                self._hosts,
-                auth_provider=auth_provider,
-                execution_profiles=profiles,
-                **params,
-            )
-            try:
-                self._connection = self._cluster.connect(keyspace=keyspace)
-            except NoHostAvailable as ex:
-                raise DriverError(message=f"Not able to connect to any of the Scylla contact points: {ex}") from ex
-            if self._connection:
-                self._connected = True
-                self._initialized_on = time.time()
-            if "database" in self.params:
-                await self.use(self.params["database"])
-            else:
-                self._keyspace = keyspace
-        except DriverError:
-            raise
-        except Exception as err:
-            self._logger.exception(f"Scylla Connection Error: {err}")
-            self._connection = None
-            self._cursor = None
-            raise DriverError(message=f"Scylla Connection Error: {err}") from err
-
-    async def connection(self, keyspace: str = None):
-        if self._driver == "async":
-            await self.async_connect(keyspace)
-        else:
-            await self.connect(keyspace)
-        return self
-
-    async def table_exists(self, table: str, keyspace: str = None, schema: str = None) -> bool:
-        """
-        Ensure the table exists. Optional If not, create it.
-
-        Args:
-            table_name (str): Name of the table.
-            schema (str): CQL statement to create the table.
-        """
-        if not keyspace:
-            keyspace = self._keyspace
-        # Check if table exists
-        tables, error = await self.execute(
-            f"SELECT table_name FROM system_schema.tables WHERE keyspace_name = '{keyspace}'"
-        )
-        if table not in [row["table_name"] for row in tables]:
-            # If table doesn't exist, create it
-            if schema is not None:
-                result, error = await self.execute(schema)
-                if error:
-                    self._logger.error(error)
-                    return False
-                self._logger.debug(f"Table was created: {table}")
-            else:
-                return False
-        return True
-
-    async def drop_table(self, table):
-        result, error = await self.execute(f"DROP TABLE IF EXISTS {table}")
-        if error:
-            self._logger.error(error)
-        self._logger.debug(f"Table Dropped: {table}, result: {result}")
-        return result
-
-    async def execute(  # pylint: disable=W0221
-        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None, **kwargs
-    ) -> Any:
-        """Execute a transaction
-        get a CQL sentence and execute
-        returns: results of the execution
-        """
-        error = None
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            if isinstance(sentence, PreparedStatement):
-                smt = sentence
-            elif isinstance(sentence, SimpleStatement):
-                smt = sentence
-            else:
-                smt = self._connection.prepare(sentence)
-            if self._driver == "async":
-                statement = self._connection.create_statement(smt)
-                self._result = await self._connection.execute(statement)
-            else:
-                fut = self._connection.execute_async(smt, params)
-                self._result = fut.result()
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Execute: {err}"
-        finally:
-            return [self._result, error]  # pylint: disable=W0150
-
-    async def execute_many(  # pylint: disable=W0221
-        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None
-    ) -> Any:
-        """execute_many.
-
-        Execute a transaction many times using Batch prepared statements.
-
-        Args:
-            sentence (str): a parametrized CQL sentence.
-            params (List, optional): List of dicts with parameters.
-
-        Returns:
-            Any: Resultset of execution.
-        """
-        result = None
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            if self._driver == "async":
-                batch = self._connection.create_batch_unlogged()
-            else:
-                batch = BatchStatement(batch_type=BatchType.UNLOGGED)
-            for p in params:
-                args = ()
-                if isinstance(p, dict):
-                    args = tuple(p.values())
-                elif isinstance(p, tuple):
-                    args = p
-                else:
-                    args = tuple(p)
-                if isinstance(sentence, PreparedStatement):
-                    bound_statement = sentence.bind(args)
-                    batch.add(bound_statement)
-                else:
-                    smt = SimpleStatement(sentence)
-                    batch.add(smt, args)
-                if len(batch) >= BATCH_SIZE:
-                    if self._driver == "async":
-                        await self._connection.execute(batch)
-                        batch = self._connection.create_batch_unlogged()
-                    else:
-                        fut = self._connection.execute_async(batch)
-                        result = fut.result()
-                        batch = BatchStatement(batch_type=BatchType.UNLOGGED)
-            if len(batch) > 0:
-                if self._driver == "async":
-                    result = await self._connection.execute(batch)
-                else:
-                    fut = self._connection.execute_async(batch)
-                    result = fut.result()
-        except ReadTimeout:
-            error = "Timeout executing sentences"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Execute: {err}"
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    async def test_connection(self):  # pylint: disable=W0221
-        result = None
-        error = None
-        try:
-            result, error = await self.execute(self._test_query)
-            result = [row for row in result]
-        except Exception as err:  # pylint: disable=W0703
-            error = err
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    async def use(self, database: str):
-        try:
-            self._connection.set_keyspace(database)
-            self._keyspace = database
-            self._logger.debug(f"Using Keyspace: {database}")
-        except Exception as err:
-            self._logger.error(err)
-            raise
-        return self
-
-    async def create_keyspace(self, keyspace: str, use: bool = True):
-        db = "CREATE KEYSPACE IF NOT EXISTS {keyspace} WITH replication = {{'class': 'SimpleStrategy', 'replication_factor': 1}};"
-        db = db.format(keyspace=keyspace)
-        try:
-            if self._driver == "async":
-                result = await self._connection.execute(db)
-            else:
-                result = self._connection.execute(db)
-            self._logger.debug(f"CREATE {db}: {result!r}")
-        except Exception as err:
-            raise DriverError(f"Error: {err}") from err
-        if use is True:
-            await self.use(keyspace)
-
-    create_database = create_keyspace
-
-    async def create_table(self, table: str, schema: str = None, data: Any = None, pk: str = None):
-        if schema:
-            await self.use(schema)
-
-        # Generate CREATE TABLE statement
-        create_stmt = f"CREATE TABLE IF NOT EXISTS {table} ("
-
-        # If data is a DataFrame, generate column definitions
-        if isinstance(data, pd.DataFrame):
-            dtype_mapping = {
-                "int64": "int",
-                "float64": "float",
-                "object": "text",  # assuming object type is string
-                "datetime64[ns]": "timestamp"
-                # Add more type mappings as needed
-            }
-
-            columns = []
-            for col, dtype in data.dtypes.items():
-                scylla_type = dtype_mapping.get(str(dtype), "text")
-                columns.append(f"{col} {scylla_type}")
-
-            # Assuming the first column is the primary key for simplicity
-            # Adjust as needed
-            if pk is None:
-                columns.append(f"PRIMARY KEY ({data.columns[0]})")
-            else:
-                columns.append(f"PRIMARY KEY ({pk})")
-
-            create_stmt += ", ".join(columns) + ");"
-
-        # Execute the CREATE TABLE statement
-        self._logger.debug(f"CREATE TABLE: {create_stmt}")
-        if self._driver == "async":
-            await self._connection.execute(create_stmt)
-        else:
-            self._connection.execute(create_stmt)
-
-    async def prepare(self, sentence: str, consistency: str = "quorum"):
-        await self.valid_operation(sentence)
-        try:
-            self._prepared = self._connection.prepare(sentence)
-            if consistency == "quorum":
-                self._prepared.consistency_level = ConsistencyLevel.QUORUM
-            else:
-                self._prepared.consistency_level = ConsistencyLevel.ALL
-            return self._prepared
-        except RuntimeError as ex:
-            raise DriverError(message=f"Runtime Error: {ex}") from ex
-        except Exception as ex:
-            raise DriverError(f"Error on Query: {ex}") from ex
-
-    def create_query(self, sentence: str, consistency: str = "quorum"):
-        if consistency == "quorum":
-            cl = ConsistencyLevel.QUORUM
-        else:
-            cl = ConsistencyLevel.ALL
-        return SimpleStatement(sentence, consistency_level=cl)
-
-    async def get_sentence(
-        self, sentence: Union[str, SimpleStatement, PreparedStatement], prepared: bool = False, params: list = None
-    ):
-        if isinstance(sentence, PreparedStatement):
-            if params:
-                smt = sentence.bind(*params)
-            else:
-                smt = sentence
-        elif isinstance(sentence, SimpleStatement):
-            smt = sentence
-        elif prepared is True:
-            if self._driver == "async":
-                st = await self._connection.prepare(sentence)
-                smt = st.bind(*params)
-            else:
-                prepared = self._connection.prepare(sentence)
-                smt = prepared.bind(*params)
-        else:
-            if self._driver == "async":
-                smt = c.Statement(sentence, params)
-            else:
-                smt = SimpleStatement(sentence)
-        return smt
-
-    async def query(
-        self,
-        sentence: Union[str, SimpleStatement, PreparedStatement],
-        prepared: bool = False,
-        params: list = None,
-        factory: str = EXEC_PROFILE_DEFAULT,
-        **kwargs,
-    ) -> Union[ResultSet, None]:
-        error = None
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            self.start_timing()
-            smt = await self.get_sentence(sentence, prepared=prepared, params=params)
-            if self._driver == "async":
-                self._result = await self._connection.execute(smt)
-            else:
-                self._connection.fetch_size = None
-                fut = self._connection.execute_async(smt, execution_profile=factory)
-                self._result = fut.result()
-            try:
-                if factory in ("pandas", "record", "recordset"):
-                    self._result.result = self._result._current_rows
-            except ReadTimeout:
-                error = f"Timeout reading Data from {sentence}"
-            if not self._result:
-                raise NoDataFound("Scylla: No Data was Found")
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def fetch_all(
-        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None, **kwargs
-    ) -> ResultSet:
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            self.start_timing()
-            self._result = self._connection.execute(sentence, params)
-            if not self._result:
-                raise NoDataFound("Cassandra: No Data was Found")
-            self.generated_at()
-            return self._result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(message=f"Runtime Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Query: {err}") from err
-
-    async def fetch(self, sentence, params: list = None):
-        if not params:
-            params = []
-        return self.fetch_all(sentence, params)
-
-    async def queryrow(self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None):
-        error = None
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            if self._driver == "async":
-                smt = c.Statement(sentence, params)
-                self._result = await self._connection.execute(smt)
-            else:
-                smt = SimpleStatement(sentence)
-                self._result = self._connection.execute(sentence, params).one()
-            if not self._result:
-                raise NoDataFound("Cassandra: No Data was Found")
-        except RuntimeError as err:
-            error = f"Runtime on Query Row Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query Row: {err}"
-        return [self._result, error]  # pylint: disable=W0150
-
-    async def fetch_one(  # pylint: disable=W0221
-        self,
-        sentence: Union[str, SimpleStatement, PreparedStatement],
-        params: list = None,
-    ) -> ResultSet:
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            self._result = self._connection.execute(sentence, params).one()
-            if not self._result:
-                raise NoDataFound("Scylla: No Data was Found")
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(message=f"Runtime on Query Row Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Query Row: {err}") from err
-        return self._result
-
-    async def fetchrow(self, sentence, params: list = None):
-        if not params:
-            params = []
-        return self.fetch_one(sentence=sentence, params=params)
-
-    ### Model Logic:
-    async def column_info(self, table: str, schema: str = None):
-        """Column Info.
-
-        Get Meta information about a table (column name, data type and PK).
-        Useful to build a DataModel from Querying database.
-        Parameters:
-        @tablename: str The name of the table (including schema).
-        """
-        if not schema:
-            schema = self._keyspace
-        cql = f"select column_name as name, type, type as format_type, \
-            kind from system_schema.columns where \
-                keyspace_name = '{schema}' and table_name = '{table}';"
-        if not self._connection:
-            await self.connection()
-        try:
-            colinfo, error = await self.execute(cql)
-            if error:
-                return []
-            return [d for d in colinfo]
-        except Exception as err:
-            self._logger.exception(f"Wrong Table information {table!s}: {err}")
-            raise DriverError(f"Wrong Table information {table!s}: {err}") from err
-
-    async def run_cqlsh_copy(self, keyspace, table, columns, data_file, sep: str = ","):
-        # Construct the COPY command
-        columns_str = ", ".join(columns)
-        command_str = (
-            f"COPY {keyspace}.{table} ({columns_str}) FROM '{data_file}' WITH DELIMITER='{sep}' AND HEADER=true"
-        )
-        self._logger.debug(f"COMMAND > {command_str}")
-        # Create subprocess
-        process = await asyncio.create_subprocess_exec(
-            "cqlsh", "-e", command_str, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
-        )
-
-        # Wait for the subprocess to finish
-        stdout, stderr = await process.communicate()
-
-        # Return stdout, stderr, and the return code
-        return stdout, stderr, process.returncode
-
-    async def write(
-        self, data: Union[list, dict], sentence: str = None, table: str = None, keyspace: str = None, **kwargs
-    ):
-        """
-        Write data into ScyllaDB.
-        """
-        _data = None
-        columns = None
-        if not keyspace:
-            keyspace = self._keyspace
-        if isinstance(data, PurePath):
-            # is a CSV file:
-            if not data.exists():
-                raise ValueError(f"CSV File {data} does not exist")
-            self._logger.debug(f":: Loading CSV File {data.name} into {table}")
-            sep = kwargs.get("separator", ",")
-            columns = kwargs.get("columns", [])
-            if not columns:
-                async with aiofiles.open(data, mode="r") as file:
-                    header = await file.readline()
-                columns = header.strip().split(sep)
-            _data = str(data)
-            stdout, stderr, _ = await self.run_cqlsh_copy(keyspace, table, columns, _data, sep=sep)
-            self._logger.debug(f"COPY: {stdout.decode()}")
-            if stderr:
-                print("Error: ", stderr.decode())
-            return True
-        elif isinstance(data, pd.core.frame.DataFrame):
-            # Convert DataFrame to a list of tuples
-            _data = data.itertuples(index=False, name=None)
-            columns = data.columns.tolist()
-        elif is_dataclass(data):
-            _data = [astuple(data)]  # Wrap the tuple in a list
-            columns = [f.name for f in fields(data)]
-        elif isinstance(data, dict):
-            _data = [tuple(data.values())]
-            columns = list(data.keys())
-        elif isinstance(data, list) and all(isinstance(item, dict) for item in data):
-            _data = [tuple(item.values()) for item in data]
-            columns = list(data[0].keys())
-        else:
-            _data = [data]
-            columns = None
-        if _data is None:
-            raise ValueError("Write Error: Unsupported data type")
-        # Construct the INSERT statement if not provided
-        if sentence is None and table:
-            col_names = ", ".join(columns)
-            placeholders = ", ".join(["%s"] * len(columns))
-            sentence = f"INSERT INTO {table} ({col_names}) VALUES ({placeholders})"
-
-        if self._driver == "async":
-            stmt = await self._connection.prepare(sentence)
-            # List to hold all the tasks
-            tasks = []
-            # Create tasks for each insert
-            for row in _data:
-                bound_stmt = stmt.bind(*row)
-                task = self._connection.execute(bound_stmt)
-                tasks.append(task)
-            await asyncio.gather(*tasks)
-        else:
-            concurrency = kwargs.get("concurrency", 50)
-            stmt = SimpleStatement(sentence)
-            execute_concurrent(self._connection, ((stmt, row) for row in _data), concurrency=concurrency)
-
-    copy = write
+import os
+from typing import Union, Any
+import asyncio
+import time
+from dataclasses import is_dataclass, astuple, fields
+from ssl import PROTOCOL_TLSv1
+import logging
+from pathlib import PurePath
+import aiofiles
+import pandas as pd
+# async driver:
+import acsylla as c
+# Cassandra:
+from cassandra import ReadTimeout
+from cassandra.io.asyncorereactor import AsyncoreConnection
+# from cassandra.io.asyncioreactor import AsyncioConnection
+try:
+    from cassandra.io.libevreactor import LibevConnection
+    LIBEV = True
+except ImportError:
+    LIBEV = False
+from cassandra.concurrent import execute_concurrent
+from cassandra.policies import (
+    DCAwareRoundRobinPolicy,
+    WhiteListRoundRobinPolicy,
+    DowngradingConsistencyRetryPolicy,
+    TokenAwarePolicy,
+    RoundRobinPolicy
+)
+from cassandra.cluster import (
+    Cluster,
+    EXEC_PROFILE_DEFAULT,
+    ExecutionProfile,
+    NoHostAvailable,
+    ResultSet
+)
+from cassandra.query import (
+    tuple_factory,
+    dict_factory,
+    ordered_dict_factory,
+    named_tuple_factory,
+    ConsistencyLevel,
+    PreparedStatement,
+    BatchStatement,
+    SimpleStatement,
+    BatchType,
+)
+from cassandra.auth import PlainTextAuthProvider
+from cassandra.query import SimpleStatement
+from cassandra import ConsistencyLevel
+from asyncdb.meta import Recordset
+from asyncdb.exceptions import NoDataFound, DriverError
+from .abstract import InitDriver
+from ..interfaces import ModelBackend
+from ..models import Model, Field
+from ..utils.types import Entity
+
+
+logging.getLogger("cassandra").setLevel(logging.INFO)
+BATCH_SIZE = 1000
+
+
+def pandas_factory(colnames, rows):
+    df = pd.DataFrame(rows, columns=colnames)
+    return df
+
+
+def record_factory(colnames, rows):
+    return Recordset(result=[dict(zip(colnames, values)) for values in rows], columns=colnames)
+
+
+class scylladb(InitDriver, ModelBackend):
+    _provider = "scylladb"
+    _syntax = "cql"
+
+    def __init__(
+        self,
+        loop: asyncio.AbstractEventLoop = None,
+        params: dict = None,
+        **kwargs
+    ):
+        self.hosts: list = []
+        self.application_name = os.getenv("APP_NAME", "NAV")
+        self._enable_shard_awareness = kwargs.pop("shard_awareness", True)
+        self._test_query = "SELECT release_version FROM system.local"
+        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
+        self._cluster = None
+        self._timeout: int = 120
+        self._protocol: int = kwargs.pop("protocol", 4)
+        self._driver: str = kwargs.pop("driver", "cassandra")
+        self.heartbeat_interval: int = kwargs.pop("heartbeat_interval", 0)
+        self._row_factory = kwargs.pop("row_factory", 'dict_factory')
+        super(scylladb, self).__init__(loop=loop, params=params, **kwargs)
+        try:
+            if "host" in self.params:
+                self._hosts = self.params["host"].split(",")
+        except KeyError:
+            self._hosts = ["127.0.0.1"]
+        try:
+            self.whitelist = kwargs["whitelist"]
+        except KeyError:
+            self.whitelist = None
+        try:
+            self._auth = {
+                "username": self.params["username"],
+                "password": self.params["password"],
+            }
+        except KeyError:
+            self._auth = None
+
+    def sync_close(self):
+        # gracefully closing underlying connection
+        if self._connection:
+            try:
+                self._connection.shutdown()
+            except Exception as err:
+                self._connection = None
+                raise DriverError(message=f"Connection Error, Terminated: {err}") from err
+        if self._cluster:
+            self._logger.debug("Closing Cluster")
+            try:
+                self._cluster.shutdown()
+            except Exception as err:
+                raise DriverError(f"Cluster Shutdown Error: {err}") from err
+
+    async def async_close(self):
+        if self._connection:
+            try:
+                await self._connection.close()
+            except Exception as err:
+                self._connection = None
+                raise DriverError(message=f"Connection Error, Terminated: {err}") from err
+        if self._cluster:
+            self._logger.debug("Closing Cluster")
+            try:
+                await self._cluster.close()
+            except Exception as err:
+                raise DriverError(f"Cluster Shutdown Error: {err}") from err
+
+    async def close(self):
+        """close.
+        Closing a Connection
+        """
+        try:
+            if self._driver == "async":
+                await self.async_close()
+            else:
+                self.sync_close()
+        finally:
+            self._cluster = None
+            self._connection = None
+            self._connected = False
+
+    async def async_connect(self, keyspace: str = None):
+        """
+        Getting a Connection using async driver:
+        """
+        self._connection = None
+        self._connected = False
+        self._cluster = None
+        ssl_opts = {}
+        try:
+            if self.params["ssl"] is not None:
+                ssl_opts = {
+                    "ssl_enable": True,
+                    "ssl_trusted_cert": self.params["ssl"]["certfile"],
+                    "ssl_version": PROTOCOL_TLSv1,
+                    "ssl_private_key": self.params["ssl"]["userkey"],
+                    "ssl_cert": self.params["ssl"]["usercert"],
+                }
+        except KeyError:
+            pass
+        if not self._auth:
+            self._auth = {}
+        params = {
+            "port": self.params["port"],
+            "compression": True,
+            "application_name": "Navigator",
+            "protocol_version": self._protocol,
+            "connect_timeout": self._timeout,
+            "heartbeat_interval_sec": self.heartbeat_interval,
+            "num_threads_io": 4,
+            **ssl_opts,
+            **self._auth,
+        }
+        try:
+            self._cluster = c.create_cluster(self._hosts, **params)
+            self._connection = await self._cluster.connect(
+                keyspace=keyspace
+            )
+            self._driver = "async"
+            if self._connection:
+                self._connected = True
+                self._initialized_on = time.time()
+            if "database" in self.params:
+                await self.use(self.params["database"])
+            else:
+                self._keyspace = keyspace
+        except DriverError:
+            raise
+        except Exception as err:
+            self._logger.exception(f"Scylla Connection Error: {err}")
+            self._connection = None
+            self._cursor = None
+            raise DriverError(
+                message=f"Scylla Connection Error: {err}"
+            ) from err
+
+    async def connect(self, keyspace=None):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        self._cluster = None
+        try:
+            try:
+                if self.params["ssl"] is not None:
+                    ssl_opts = {
+                        "ca_certs": self.params["ssl"]["certfile"],
+                        "ssl_version": PROTOCOL_TLSv1,
+                        "keyfile": self.params["ssl"]["userkey"],
+                        "certfile": self.params["ssl"]["usercert"],
+                    }
+            except KeyError:
+                ssl_opts = {}
+            if self._enable_shard_awareness:
+                policy = TokenAwarePolicy(RoundRobinPolicy())
+            if self.whitelist:
+                policy = WhiteListRoundRobinPolicy(self.whitelist)
+            else:
+                policy = DCAwareRoundRobinPolicy()
+            # defining row factory:
+            if self._row_factory == "dict_factory":
+                row_factory = dict_factory
+            elif self._row_factory == "pandas_factory":
+                row_factory = pandas_factory
+            elif self._row_factory == "tuple_factory":
+                row_factory = tuple_factory
+            elif self._row_factory == "named_tuple_factory":
+                row_factory = named_tuple_factory
+            elif self._row_factory == "ordered_dict_factory":
+                row_factory = ordered_dict_factory
+            elif self._row_factory == "record_factory":
+                row_factory = record_factory
+            else:
+                # Set Dict Factory by default
+                row_factory = named_tuple_factory
+            defaultprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+                request_timeout=self._timeout,
+                row_factory=row_factory,
+            )
+            # Long-term execution profile:
+            longprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+                request_timeout=180,
+                row_factory=row_factory,
+            )
+            # Pandas Profile
+            pandasprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=pandas_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            tupleprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=named_tuple_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            orderedprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=ordered_dict_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            recordprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=record_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            profiles = {
+                EXEC_PROFILE_DEFAULT: defaultprofile,
+                "pandas": pandasprofile,
+                "ordered": orderedprofile,
+                "default": tupleprofile,
+                "recordset": recordprofile,
+                "long": longprofile,
+            }
+            # TODO: migrate to asyncio when available.
+            if LIBEV is True:
+                conn_class = LibevConnection
+            else:
+                conn_class = AsyncoreConnection
+            params = {
+                "application_name": self.application_name,
+                "port": self.params["port"],
+                "compression": True,
+                "connection_class": conn_class,
+                "protocol_version": self._protocol,
+                "connect_timeout": self._timeout,
+                "idle_heartbeat_interval": self.heartbeat_interval,
+                "ssl_options": ssl_opts,
+                "executor_threads": 4,
+            }
+            auth_provider = None
+            if self._auth:
+                auth_provider = PlainTextAuthProvider(**self._auth)
+            self._cluster = Cluster(
+                self._hosts,
+                auth_provider=auth_provider,
+                execution_profiles=profiles,
+                **params,
+            )
+            try:
+                self._connection = self._cluster.connect(keyspace=keyspace)
+            except NoHostAvailable as ex:
+                raise DriverError(
+                    message=f"Not able to connect to any of the Scylla contact points: {ex}"
+                ) from ex
+            if self._connection:
+                self._connected = True
+                self._initialized_on = time.time()
+            if "database" in self.params:
+                await self.use(self.params["database"])
+            else:
+                self._keyspace = keyspace
+        except DriverError:
+            raise
+        except Exception as err:
+            self._logger.exception(
+                f"Scylla Connection Error: {err}"
+            )
+            self._connection = None
+            self._cursor = None
+            raise DriverError(
+                message=f"Scylla Connection Error: {err}"
+            ) from err
+
+    async def connection(self, keyspace: str = None):
+        if self._driver == "async":
+            await self.async_connect(keyspace)
+        else:
+            await self.connect(keyspace)
+        return self
+
+    async def table_exists(
+        self,
+        table: str,
+        keyspace: str = None,
+        schema: str = None
+    ) -> bool:
+        """
+        Ensure the table exists. Optional If not, create it.
+
+        Args:
+            table_name (str): Name of the table.
+            schema (str): CQL statement to create the table.
+        """
+        if not keyspace:
+            keyspace = self._keyspace
+        # Check if table exists
+        tables, error = await self.execute(
+            f"SELECT table_name FROM system_schema.tables WHERE keyspace_name = '{keyspace}'"
+        )
+        if table not in [row["table_name"] for row in tables]:
+            # If table doesn't exist, create it
+            if schema is not None:
+                result, error = await self.execute(schema)
+                if error:
+                    self._logger.error(error)
+                    return False
+                self._logger.debug(f"Table was created: {table}")
+            else:
+                return False
+        return True
+
+    async def drop_table(self, table):
+        result, error = await self.execute(f"DROP TABLE IF EXISTS {table}")
+        if error:
+            self._logger.error(error)
+        self._logger.debug(f"Table Dropped: {table}, result: {result}")
+        return result
+
+    async def execute(  # pylint: disable=W0221
+        self,
+        sentence: Union[str, SimpleStatement, PreparedStatement],
+        params: list = None,
+        **kwargs
+    ) -> Any:
+        """Execute a transaction
+        get a CQL sentence and execute
+        returns: results of the execution
+        """
+        error = None
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            if isinstance(sentence, PreparedStatement):
+                smt = sentence
+            elif isinstance(sentence, SimpleStatement):
+                smt = sentence
+            else:
+                smt = self._connection.prepare(sentence)
+            if self._driver == "async":
+                statement = self._connection.create_statement(smt)
+                self._result = await self._connection.execute(statement)
+            else:
+                fut = self._connection.execute_async(smt, params)
+                self._result = fut.result()
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Execute: {err}"
+        finally:
+            return [self._result, error]  # pylint: disable=W0150
+
+    async def execute_batch(
+        self,
+        sentences: list,
+        params: list = None,
+    ) -> Any:
+        """execute_batch.
+
+        Execute a transaction using Batch prepared statements.
+
+        Args:
+            sentences (List): List of parametrized CQL sentences.
+            params (List, optional): List of dicts with parameters.
+
+        Returns:
+            Any: Resultset of execution.
+        """
+        result = None
+        error = None
+        await self.valid_operation(sentences)
+        try:
+            if self._driver == "async":
+                batch = self._connection.create_batch_unlogged()
+            else:
+                batch = BatchStatement(batch_type=BatchType.UNLOGGED)
+            for idx, sentence in enumerate(sentences):
+                args = ()
+                if params:
+                    args = params[idx]
+                if isinstance(sentence, PreparedStatement):
+                    bound_statement = sentence.bind(args)
+                    batch.add(bound_statement)
+                else:
+                    smt = SimpleStatement(sentence)
+                    batch.add(smt, args)
+            if self._driver == "async":
+                result = await self._connection.execute(batch)
+            else:
+                fut = self._connection.execute_async(batch)
+                result = fut.result()
+        except ReadTimeout:
+            error = "Timeout executing sentences"
+        except Exception as err:
+            error = f"Error on Execute: {err}"
+        finally:
+            return [result, error]
+
+    async def execute_many(  # pylint: disable=W0221
+        self,
+        sentence: Union[str, SimpleStatement, PreparedStatement],
+        params: list = None
+    ) -> Any:
+        """execute_many.
+
+        Execute a transaction many times using Batch prepared statements.
+
+        Args:
+            sentence (str): a parametrized CQL sentence.
+            params (List, optional): List of dicts with parameters.
+
+        Returns:
+            Any: Resultset of execution.
+        """
+        result = None
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            if self._driver == "async":
+                batch = self._connection.create_batch_unlogged()
+            else:
+                batch = BatchStatement(batch_type=BatchType.UNLOGGED)
+            for p in params:
+                args = ()
+                if isinstance(p, dict):
+                    args = tuple(p.values())
+                elif isinstance(p, tuple):
+                    args = p
+                else:
+                    args = tuple(p)
+                if isinstance(sentence, PreparedStatement):
+                    bound_statement = sentence.bind(args)
+                    batch.add(bound_statement)
+                else:
+                    smt = SimpleStatement(sentence)
+                    batch.add(smt, args)
+                if len(batch) >= BATCH_SIZE:
+                    if self._driver == "async":
+                        await self._connection.execute(batch)
+                        batch = self._connection.create_batch_unlogged()
+                    else:
+                        fut = self._connection.execute_async(batch)
+                        result = fut.result()
+                        batch = BatchStatement(batch_type=BatchType.UNLOGGED)
+            if len(batch) > 0:
+                if self._driver == "async":
+                    result = await self._connection.execute(batch)
+                else:
+                    fut = self._connection.execute_async(batch)
+                    result = fut.result()
+        except ReadTimeout:
+            error = "Timeout executing sentences"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Execute: {err}"
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    async def test_connection(self):  # pylint: disable=W0221
+        result = None
+        error = None
+        try:
+            result, error = await self.execute(self._test_query)
+            result = [row for row in result]
+        except Exception as err:  # pylint: disable=W0703
+            error = err
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    async def use(self, database: str):
+        try:
+            self._connection.set_keyspace(database)
+            self._keyspace = database
+            self._logger.debug(f"Using Keyspace: {database}")
+        except Exception as err:
+            self._logger.error(err)
+            raise
+        return self
+
+    async def drop_keyspace(self, keyspace: str):
+        db = f"DROP KEYSPACE IF EXISTS {keyspace};"
+        try:
+            if self._driver == "async":
+                result = await self._connection.execute(db)
+            else:
+                result = self._connection.execute(db)
+            self._logger.debug(f"DROP {db}: {result!r}")
+        except Exception as err:
+            raise DriverError(f"Error: {err}") from err
+
+    async def create_keyspace(self, keyspace: str, use: bool = True):
+        db = "CREATE KEYSPACE IF NOT EXISTS {keyspace} WITH replication = {{'class': 'SimpleStrategy', 'replication_factor': 1}};"
+        db = db.format(keyspace=keyspace)
+        try:
+            if self._driver == "async":
+                result = await self._connection.execute(db)
+            else:
+                result = self._connection.execute(db)
+            self._logger.debug(f"CREATE {db}: {result!r}")
+        except Exception as err:
+            raise DriverError(f"Error: {err}") from err
+        if use is True:
+            await self.use(keyspace)
+
+    create_database = create_keyspace
+
+    async def drop_table(self, table: str):
+        db = f"DROP TABLE IF EXISTS {table};"
+        try:
+            if self._driver == "async":
+                result = await self._connection.execute(db)
+            else:
+                result = self._connection.execute(db)
+            self._logger.debug(f"DROP {db}: {result!r}")
+        except Exception as err:
+            raise DriverError(f"Error: {err}") from err
+
+    async def create_table(
+        self,
+        table: str,
+        schema: str = None,
+        data: Any = None,
+        pk: str = None,
+        optionals: dict = None
+    ):
+        if schema:
+            await self.use(schema)
+
+        # Generate CREATE TABLE statement
+        create_stmt = f"CREATE TABLE IF NOT EXISTS {table} ("
+
+        # If data is a DataFrame, generate column definitions
+        if isinstance(data, pd.DataFrame):
+            dtype_mapping = {
+                "int64": "int",
+                "float64": "float",
+                "object": "text",  # assuming object type is string
+                "datetime64[ns]": "timestamp"
+                # Add more type mappings as needed
+            }
+            columns = []
+            for col, dtype in data.dtypes.items():
+                scylla_type = dtype_mapping.get(str(dtype), "text")
+                columns.append(f"{col} {scylla_type}")
+            # Assuming the first column is the primary key for simplicity
+            # Adjust as needed
+            if pk is None:
+                columns.append(f"PRIMARY KEY ({data.columns[0]})")
+            else:
+                columns.append(f"PRIMARY KEY ({pk})")
+
+            create_stmt += ", ".join(columns) + ")"
+        elif isinstance(data, dict):
+            columns = []
+            for col, dtype in data.items():
+                columns.append(f"{col} {dtype}")
+            if pk is None:
+                columns.append(f"PRIMARY KEY ({list(data.keys())[0]})")
+            else:
+                columns.append(f"PRIMARY KEY ({pk})")
+            create_stmt += ", ".join(columns) + ")"
+        if optionals:
+            if isinstance(optionals, dict):
+                for k, v in optionals.items():
+                    create_stmt += f" {k}={v}"
+            elif isinstance(optionals, list):
+                for item in optionals:
+                    create_stmt += f" {item}"
+            elif isinstance(optionals, str):
+                create_stmt += f" {optionals}"
+            else:
+                raise ValueError(
+                    "Optional WITH must be a list, dict or string"
+                )
+        create_stmt += ";"
+        # Execute the CREATE TABLE statement
+        self._logger.debug(f"CREATE TABLE: {create_stmt}")
+        if self._driver == "async":
+            await self._connection.execute(create_stmt)
+        else:
+            self._connection.execute(create_stmt)
+
+    async def prepare(self, sentence: str, consistency: str = "quorum"):
+        await self.valid_operation(sentence)
+        try:
+            self._prepared = self._connection.prepare(sentence)
+            if consistency == "quorum":
+                self._prepared.consistency_level = ConsistencyLevel.QUORUM
+            else:
+                self._prepared.consistency_level = ConsistencyLevel.ALL
+            return self._prepared
+        except RuntimeError as ex:
+            raise DriverError(message=f"Runtime Error: {ex}") from ex
+        except Exception as ex:
+            raise DriverError(f"Error on Query: {ex}") from ex
+
+    def create_query(self, sentence: str, consistency: str = "quorum"):
+        if consistency == "quorum":
+            cl = ConsistencyLevel.QUORUM
+        else:
+            cl = ConsistencyLevel.ALL
+        return SimpleStatement(sentence, consistency_level=cl)
+
+    async def get_sentence(
+        self,
+        sentence: Union[str, SimpleStatement, PreparedStatement],
+        prepared: bool = False,
+        params: list = None
+    ):
+        if isinstance(sentence, PreparedStatement):
+            if params:
+                smt = sentence.bind(*params)
+            else:
+                smt = sentence
+        elif isinstance(sentence, SimpleStatement):
+            smt = sentence
+        elif prepared is True:
+            if self._driver == "async":
+                st = await self._connection.prepare(sentence)
+                smt = st.bind(*params)
+            else:
+                prepared = self._connection.prepare(sentence)
+                smt = prepared.bind(*params)
+        else:
+            if self._driver == "async":
+                smt = c.Statement(sentence, params)  # pylint: disable=E0110
+            else:
+                smt = SimpleStatement(sentence)
+        return smt
+
+    async def query(
+        self,
+        sentence: Union[str, SimpleStatement, PreparedStatement],
+        prepared: bool = False,
+        params: list = None,
+        factory: str = EXEC_PROFILE_DEFAULT,
+        **kwargs,
+    ) -> Union[ResultSet, None]:
+        error = None
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            self.start_timing()
+            smt = await self.get_sentence(sentence, prepared=prepared, params=params)
+            if self._driver == "async":
+                self._result = await self._connection.execute(smt)
+            else:
+                self._connection.fetch_size = None
+                fut = self._connection.execute_async(smt, execution_profile=factory)
+                self._result = fut.result()
+            try:
+                if factory in ("pandas", "record", "recordset"):
+                    self._result.result = self._result._current_rows
+            except ReadTimeout:
+                error = f"Timeout reading Data from {sentence}"
+            if not self._result:
+                raise NoDataFound("Scylla: No Data was Found")
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def fetch_all(
+        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None, **kwargs
+    ) -> ResultSet:
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            self.start_timing()
+            self._result = self._connection.execute(sentence, params)
+            if not self._result:
+                raise NoDataFound(
+                    "Cassandra: No Data was Found"
+                )
+            self.generated_at()
+            return self._result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(message=f"Runtime Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Query: {err}") from err
+
+    async def fetch(self, sentence, params: list = None):
+        if not params:
+            params = []
+        return self.fetch_all(sentence, params)
+
+    async def queryrow(
+        self,
+        sentence: Union[str, SimpleStatement, PreparedStatement],
+        params: list = None
+    ):
+        error = None
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            if self._driver == "async":
+                smt = c.Statement(sentence, params)  # pylint: disable=E0110
+                self._result = await self._connection.execute(smt)
+            else:
+                smt = SimpleStatement(sentence)
+                self._result = self._connection.execute(sentence, params).one()
+            if not self._result:
+                raise NoDataFound("Cassandra: No Data was Found")
+        except RuntimeError as err:
+            error = f"Runtime on Query Row Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query Row: {err}"
+        return [self._result, error]  # pylint: disable=W0150
+
+    async def fetch_one(  # pylint: disable=W0221
+        self,
+        sentence: Union[str, SimpleStatement, PreparedStatement],
+        params: list = None,
+    ) -> ResultSet:
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            self._result = self._connection.execute(sentence, params).one()
+            if not self._result:
+                raise NoDataFound("Scylla: No Data was Found")
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(message=f"Runtime on Query Row Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Query Row: {err}") from err
+        return self._result
+
+    async def fetchrow(self, sentence, params: list = None):
+        if not params:
+            params = []
+        return self.fetch_one(sentence=sentence, params=params)
+
+    ### Model Logic:
+    async def column_info(self, table: str, schema: str = None):
+        """Column Info.
+
+        Get Meta information about a table (column name, data type and PK).
+        Useful to build a DataModel from Querying database.
+        Parameters:
+        @tablename: str The name of the table (including schema).
+        """
+        if not schema:
+            schema = self._keyspace
+        cql = f"select column_name as name, type, type as format_type, \
+            kind from system_schema.columns where \
+                keyspace_name = '{schema}' and table_name = '{table}';"
+        if not self._connection:
+            await self.connection()
+        try:
+            colinfo, error = await self.execute(cql)
+            if error:
+                return []
+            return [d for d in colinfo]
+        except Exception as err:
+            self._logger.exception(f"Wrong Table information {table!s}: {err}")
+            raise DriverError(f"Wrong Table information {table!s}: {err}") from err
+
+    async def run_cqlsh_copy(self, keyspace, table, columns, data_file, sep: str = ","):
+        # Construct the COPY command
+        columns_str = ", ".join(columns)
+        command_str = (
+            f"COPY {keyspace}.{table} ({columns_str}) FROM '{data_file}' WITH DELIMITER='{sep}' AND HEADER=true"
+        )
+        self._logger.debug(f"COMMAND > {command_str}")
+        # Create subprocess
+        process = await asyncio.create_subprocess_exec(
+            "cqlsh", "-e", command_str, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE
+        )
+
+        # Wait for the subprocess to finish
+        stdout, stderr = await process.communicate()
+
+        # Return stdout, stderr, and the return code
+        return stdout, stderr, process.returncode
+
+    async def write(
+        self,
+        data: Union[list, dict],
+        sentence: str = None,
+        table: str = None,
+        keyspace: str = None,
+        **kwargs
+    ):
+        """
+        Write data into ScyllaDB.
+        """
+        _data = None
+        columns = None
+        if not keyspace:
+            keyspace = self._keyspace
+        if isinstance(data, PurePath):
+            # is a CSV file:
+            if not data.exists():
+                raise ValueError(f"CSV File {data} does not exist")
+            self._logger.debug(f":: Loading CSV File {data.name} into {table}")
+            sep = kwargs.get("separator", ",")
+            columns = kwargs.get("columns", [])
+            if not columns:
+                async with aiofiles.open(data, mode="r") as file:
+                    header = await file.readline()
+                columns = header.strip().split(sep)
+            _data = str(data)
+            stdout, stderr, _ = await self.run_cqlsh_copy(keyspace, table, columns, _data, sep=sep)
+            self._logger.debug(f"COPY: {stdout.decode()}")
+            if stderr:
+                print("Error: ", stderr.decode())
+            return True
+        elif isinstance(data, pd.core.frame.DataFrame):
+            # Convert DataFrame to a list of tuples
+            _data = data.itertuples(index=False, name=None)
+            columns = data.columns.tolist()
+        elif is_dataclass(data):
+            _data = [astuple(data)]  # Wrap the tuple in a list
+            columns = [f.name for f in fields(data)]
+        elif isinstance(data, dict):
+            _data = [tuple(data.values())]
+            columns = list(data.keys())
+        elif isinstance(data, list) and all(isinstance(item, dict) for item in data):
+            _data = [tuple(item.values()) for item in data]
+            columns = list(data[0].keys())
+        else:
+            _data = [data]
+            columns = None
+        if _data is None:
+            raise ValueError("Write Error: Unsupported data type")
+        # Construct the INSERT statement if not provided
+        if sentence is None and table:
+            col_names = ", ".join(columns)
+            placeholders = ", ".join(["%s"] * len(columns))
+            sentence = f"INSERT INTO {table} ({col_names}) VALUES ({placeholders})"
+
+        if self._driver == "async":
+            stmt = await self._connection.prepare(sentence)
+            # List to hold all the tasks
+            tasks = []
+            # Create tasks for each insert
+            for row in _data:
+                bound_stmt = stmt.bind(*row)
+                task = self._connection.execute(bound_stmt)
+                tasks.append(task)
+            await asyncio.gather(*tasks)
+        else:
+            concurrency = kwargs.get("concurrency", 50)
+            stmt = SimpleStatement(sentence)
+            execute_concurrent(
+                self._connection, ((stmt, row) for row in _data),
+                concurrency=concurrency
+            )
+
+    copy = write
+
+    ## Model Logic:
+    async def _insert_(self, _model: Model, **kwargs):  # pylint: disable=W0613
+        """
+        insert a row from model.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        cols = []
+        columns = []
+        source = []
+        _filter = {}
+        n = 1
+        fields = _model.columns()
+        for name, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            columns.append(column)
+            # validating required field
+            try:
+                required = field.required()
+            except AttributeError:
+                required = False
+            pk = self._get_attribute(field, value, attr="primary_key")
+            if pk is True and value is None:
+                if "db_default" in field.metadata:
+                    continue
+            if required is False and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    continue
+                else:
+                    # get default value
+                    default = field.default
+                    if callable(default):
+                        value = default()
+                    else:
+                        continue
+            elif required is True and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    # field get a default value from database
+                    continue
+                else:
+                    raise ValueError(
+                        f"Field {name} is required and value is null over {_model.Meta.name}"
+                    )
+            elif is_dataclass(value):
+                if isinstance(value, Model):
+                    ### get value for primary key associated with.
+                    try:
+                        value = getattr(value, name)
+                    except AttributeError:
+                        value = None
+            source.append(value)
+            cols.append(column)
+            n += 1
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _filter[column] = pk
+        try:
+            cols = ",".join(cols)
+            values = ",".join(["?" for a in range(1, n)])  # pylint: disable=C0209
+            insert = f"INSERT INTO {table}({cols}) VALUES({values}) IF NOT EXISTS;"
+            self._logger.debug(f"INSERT: {insert}")
+            stmt = self._connection.prepare(insert)
+            result = self._connection.execute(stmt, source)
+            if result.was_applied:
+                # get the row inserted again:
+                condition = self._where(fields, **_filter)
+                stmt = SimpleStatement(f"SELECT * FROM {table} {condition}")
+                result = self._connection.execute(stmt).one()
+            if result:
+                _model.reset_values()
+                for f, val in result.items():
+                    setattr(_model, f, val)
+                return _model
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _delete_(self, _model: Model, _filter: dict = None, **kwargs):  # pylint: disable=W0613
+        """
+        delete a row from model.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        source = []
+        if not _filter:
+            _filter = {}
+        n = 1
+        fields = _model.columns()
+        for _, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            source.append(value)
+            n += 1
+            curval = _model.old_value(column)
+            if pk := self._get_attribute(field, curval, attr="primary_key"):
+                if column in _filter:
+                    # already this value on delete:
+                    continue
+                _filter[column] = pk
+        try:
+            condition = self._where(fields, **_filter)
+            if not condition:
+                raise DriverError(f"Avoid DELETE without WHERE conditions: {_filter}")
+            _delete = f"DELETE FROM {table} {condition};"
+            self._logger.debug(f"DELETE: {_delete}")
+            result = self._connection.execute(_delete)
+            return f"DELETE {result}: {_filter!s}"
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _update_(self, _model: Model, **kwargs):  # pylint: disable=W0613
+        """
+        Updating a row in a Model.
+        TODO: How to update when if primary key changed.
+        Alternatives: Saving *dirty* status and previous value on dict
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        cols = []
+        source = []
+        _filter = {}
+        _updated = {}
+        _primary = []
+        n = 1
+        fields = _model.columns()
+        for name, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+
+            column = field.name
+            # validating required field
+            try:
+                required = field.required()
+            except AttributeError:
+                required = False
+            if required is False and value is None or value == "None":
+                default = field.default
+                if callable(default):
+                    value = default()
+                else:
+                    continue
+            elif required is True and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    # field get a default value from database
+                    continue
+                raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
+            elif is_dataclass(value):
+                if isinstance(value, Model):
+                    ### get value for primary key associated with.
+                    try:
+                        value = getattr(value, name)
+                    except AttributeError:
+                        value = None
+            curval = _model.old_value(name)
+            if pk := self._get_attribute(field, curval, attr="primary_key"):
+                _filter[column] = pk
+                _primary.append(column)
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _updated[column] = pk
+                _primary.append(column)
+            if curval == value:
+                continue  # no changes
+            cols.append(name)  # pylint: disable=C0209
+            source.append(value)
+            n += 1
+        try:
+            if any(col in _primary for col in cols):
+                # in Cassandra we need to delete and insert again
+                condition = self._where(fields, **_filter)
+                _delete = f"DELETE FROM {table} {condition}"
+                result = self._connection.execute(
+                    SimpleStatement(_delete)
+                )
+                return await self._insert_(_model, **kwargs)
+            set_fields = ", ".join(cols)
+            condition = self._where(fields, **_filter)
+            _update = f"UPDATE {table} SET {set_fields} {condition}"
+            self._logger.debug(f"UPDATE: {_update}")
+            stmt = await self.get_sentence(_update, prepared=True)
+            self._connection.execute(stmt, source)
+            condition = self._where(fields, **_updated)
+            stmt = SimpleStatement(f"SELECT * FROM {table} {condition}")
+            result = self._connection.execute(stmt).one()
+            if result:
+                _model.reset_values()
+                for f, val in result.items():
+                    setattr(_model, f, val)
+                return _model
+        except Exception as err:
+            raise DriverError(
+                message=f"Error on Update over table {_model.Meta.name}: {err!s}"
+            ) from err
+
+    async def _save_(self, _model: Model, *args, **kwargs):
+        """
+        Save a row in a Model, using Insert-or-Update methodology.
+        """
+        raise NotImplementedError("Method not implemented")
+
+    async def _fetch_(self, _model: Model, *args, **kwargs):
+        """
+        Returns one single Row using Model.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns()
+        _filter = {}
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT * FROM {table} {condition}"
+        try:
+            smt = SimpleStatement(_get)
+            return self._connection.execute(smt).one()
+        except Exception as e:
+            raise DriverError(f"Error: Model Fetch over {table}: {e}") from e
+
+    async def _filter_(self, _model: Model, *args, **kwargs):
+        """
+        Filter a Model using Fields.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        if args:
+            columns = ",".join(args)
+        else:
+            columns = "*"
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            stmt = SimpleStatement(_get)
+            fut = self._connection.execute_async(stmt)
+            result = fut.result()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model GET over {table}: {e}") from e
+
+    async def _select_(self, *args, **kwargs):
+        """
+        Get a query from Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            schema = ""
+            sc = model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        if args:
+            condition = "{}".join(args)
+        else:
+            condition = None
+        if "fields" in kwargs:
+            columns = ",".join(kwargs["fields"])
+        else:
+            columns = "*"
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            smt = SimpleStatement(_get)
+            return self._connection.execute(smt)
+        except Exception as e:
+            raise DriverError(f"Error: Model SELECT over {table}: {e}") from e
+
+    async def _get_(self, _model: Model, *args, **kwargs):
+        """
+        Get one row from model.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        if args:
+            columns = ",".join(args)
+        else:
+            columns = ",".join(fields)  # getting only selected fields
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        print('SELECT ', _get)
+        try:
+            smt = SimpleStatement(_get)
+            return self._connection.execute(smt).one()
+        except Exception as e:
+            raise DriverError(
+                f"Error: Model GET over {table}: {e}"
+            ) from e
+
+    async def _all_(self, _model: Model, *args, **kwargs):  # pylint: disable=W0613
+        """
+        Get all rows on a Model.
+        """
+        try:
+            schema = ""
+            # sc = _model.Meta.schema
+            if sc := _model.Meta.schema:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        if "fields" in kwargs:
+            columns = ",".join(kwargs["fields"])
+        else:
+            columns = "*"
+        _all = f"SELECT {columns} FROM {table}"
+        try:
+            smt = SimpleStatement(_all)
+            return self._connection.execute(smt)
+        except Exception as e:
+            raise DriverError(f"Error: Model All over {table}: {e}") from e
+
+    async def _remove_(self, _model: Model, **kwargs):
+        """
+        Deleting some records using Model.
+        """
+        try:
+            schema = ""
+            if sc := _model.Meta.schema:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        for name, field in fields.items():
+            datatype = field.type
+            if name in kwargs:
+                val = kwargs[name]
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        if not condition:
+            raise ValueError(
+                "Avoid DELETE without WHERE conditions"
+            )
+        _delete = f"DELETE FROM {table} {condition}"
+        try:
+            self._logger.debug(f"DELETE: {_delete}")
+            smt = SimpleStatement(_delete)
+            result = self._connection.execute(smt)
+            return f"DELETE {result}: {_filter!s}"
+        except Exception as err:
+            raise DriverError(message=f"Error on DELETE {_model.Meta.name}: {err!s}") from err
+
+    async def _updating_(self, *args, _filter: dict = None, **kwargs):
+        """
+        Updating records using Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            schema = ""
+            sc = model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        fields = model.columns(model)
+        if _filter is None:
+            if args:
+                _filter = args[0]
+        cols = []
+        source = []
+        new_cond = {}
+        n = 1
+        for name, field in fields.items():
+            try:
+                val = kwargs[name]
+            except (KeyError, AttributeError):
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            source.append(value)
+            if name in _filter:
+                new_cond[name] = value
+            cols.append("{} = {}".format(name, "?".format(n)))  # pylint: disable=C0209
+            n += 1
+        try:
+            set_fields = ", ".join(cols)
+            condition = self._where(fields, **_filter)
+            _update = f"UPDATE {table} SET {set_fields} {condition}"
+            self._logger.debug(f"UPDATE: {_update}")
+            stmt = await self.get_sentence(_update, prepared=True)
+            result = self._connection.execute(stmt, source)
+            print(f"UPDATE {result}: {_filter!s}")
+
+            new_conditions = {**_filter, **new_cond}
+            condition = self._where(fields, **new_conditions)
+
+            _all = f"SELECT * FROM {table} {condition}"
+            stmt = await self.get_sentence(_all)
+            result = self._connection.execute(stmt)
+            return [model(**dict(r)) for r in result]
+        except Exception as err:
+            raise DriverError(
+                message=f"Error on UPDATE over table {model.Meta.name}: {err!s}"
+            ) from err
+
+    async def _deleting_(self, *args, _filter: dict = None, **kwargs):
+        """
+        Deleting records using Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            schema = ""
+            sc = model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        fields = model.columns(model)
+        if _filter is None:
+            if args:
+                _filter = args[0]
+        cols = []
+        source = []
+        new_cond = {}
+        n = 1
+        for name, field in fields.items():
+            try:
+                val = kwargs[name]
+            except (KeyError, AttributeError):
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            source.append(value)
+            if name in _filter:
+                new_cond[name] = value
+            cols.append("{} = {}".format(name, "?".format(n)))  # pylint: disable=C0209
+            n += 1
+        try:
+            condition = self._where(fields, **_filter)
+            _delete = f"DELETE FROM {table} {condition}"
+            self._logger.debug(f"DELETE: {_delete}")
+            stmt = await self.get_sentence(_delete)
+            result = self._connection.excute(stmt, source)
+            print(f"DELETE {result}: {_filter!s}")
+            return f'DELETED: {_filter}'
+        except Exception as err:
+            raise DriverError(message=f"Error on DELETE over table {model.Meta.name}: {err!s}") from err
```

## asyncdb/drivers/redis.py

```diff
@@ -1,515 +1,513 @@
-#!/usr/bin/env python3
-""" Redis async Provider.
-Notes on redis Provider
---------------------
-This provider implements a few subset of funcionalities from aioredis, is a WIP
-TODO:
- - use jsonpath to query json-objects
- - implements lists and hash datatypes
-"""
-import asyncio
-import time
-from typing import Any, Union
-from redis import asyncio as aioredis
-from aioredis.exceptions import AuthenticationError, RedisError
-
-from asyncdb.exceptions import ConnectionTimeout, DriverError
-
-from .abstract import BaseDriver, BasePool
-
-
-class redisPool(BasePool):
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._dsn = "redis://{host}:{port}/{db}"
-        super(redisPool, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-
-    # Create a redis connection pool
-    async def connect(self, **kwargs):
-        """
-        __init async db initialization
-        """
-        self._logger.debug(f"Redis Pool: Connecting to {self._dsn}")
-        try:
-            self._pool = aioredis.ConnectionPool.from_url(
-                self._dsn,
-                encoding=self._encoding,
-                decode_responses=True,
-                max_connections=self._max_queries,
-                health_check_interval=60.0,
-                **kwargs,
-            )
-            self._connection = aioredis.Redis(connection_pool=self._pool)
-        except ConnectionError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Error: {err}") from err
-        # is connected
-        if self._pool:
-            self._connected = True
-            self._initialized_on = time.time()
-        return self
-
-    async def acquire(self):
-        """
-        Take a connection from the pool.
-        """
-        # Take a connection from the pool.
-        try:
-            return redis(connection=self._connection, pool=self)
-        except ConnectionError as err:
-            raise ConnectionError(f"Redis Pool is already closed: {err}") from err
-        except RedisError as err:
-            raise ConnectionError(f"Redis Pool is closed o doesnt exists: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Unknown Error: {err}") from err
-
-    async def release(self, connection: "redis " = None):  # pylint: disable=W0221
-        """
-        Release a connection from the pool
-        """
-        if not connection:
-            return True
-        try:
-            print(type(connection.get_connection()))
-            await self._pool.release(connection.get_connection())
-        except Exception as err:
-            raise DriverError(f"Release Error: {err}") from err
-
-    async def close(self):  # pylint: disable=W0221
-        """
-        Close Pool
-        """
-        try:
-            if self._connection is not None:
-                await self._connection.close()
-            if self._pool:
-                await self._pool.disconnect(inuse_connections=True)
-            self._connected = False
-            return True
-        except ConnectionError as err:
-            raise DriverError(f"Connection close Error: {err}") from err
-        except Exception as err:
-            self._logger.exception(f"Pool Closing Error: {err}")
-            raise DriverError(f"Connection close Error: {err}") from err
-
-    disconnect = close
-
-    async def execute(self, sentence, *args, **kwargs):
-        """
-        Execute a connection into the Pool
-        """
-        if self._pool:
-            try:
-                result = await self._connection.execute_command(sentence, *args, **kwargs)
-                return result
-            except TypeError as err:
-                raise DriverError(f"Execute Error: {err}") from err
-            except aioredis.exceptions.ConnectionError as err:
-                raise DriverError(f"Connection cannot be decoded or is broken, Error: {err}") from err
-            except RedisError as err:
-                raise DriverError(f"Connection close Error: {err}") from err
-            except Exception as err:
-                raise DriverError(f"Redis Execute Error: {err}") from err
-
-
-class redis(BaseDriver):
-    _provider = "redis"
-    _syntax = "json"
-
-    def __init__(self, dsn: str = None, loop=None, params: dict = None, **kwargs):
-        self._dsn = "redis://{host}:{port}/{db}"
-        super(redis, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-        if "connection" in kwargs:
-            self._connection = kwargs["connection"]
-            self._connected = True
-        if "pool" in kwargs:
-            self._pool = kwargs["pool"]
-            self._connected = True
-        self._initialized_on = time.time()
-
-    ### Properties
-    @property
-    def redis(self):
-        return self._connection
-
-    # Create a redis pool
-    async def connection(self, **kwargs):
-        """
-        __init async redis initialization
-        """
-        try:
-            self._connection = await aioredis.from_url(
-                self._dsn,
-                encoding=self._encoding,
-                decode_responses=True,
-                **kwargs,
-            )
-        except AuthenticationError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except ConnectionError as err:
-            raise DriverError(f"Connection Error: {err}") from err
-        except (aioredis.RedisError, asyncio.TimeoutError) as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-        # is connected
-        if self._connection:
-            self._connected = True
-            self._initialized_on = time.time()
-        return self
-
-    def is_closed(self):
-        if not self._connection:
-            return True
-        else:
-            return not self._connected
-
-    async def ping(self, msg: str = None):
-        if msg is not None:
-            await self._connection.echo(msg)
-        await self._connection.ping()
-
-    async def close(self, timeout: int = 10):
-        try:
-            # gracefully closing underlying connection
-            await self._connection.close()
-            try:
-                # safely closing the inner connection pool
-                await self._connection.connection_pool.disconnect()
-                self._connected = False
-            except Exception as err:
-                raise DriverError(f"Unknown Redis Error: {err}") from err
-        except (RuntimeError, AttributeError):
-            pass
-        except Exception as err:
-            self._logger.exception(f"Redis Closing Error: {err}")
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    disconnect = close
-
-    async def execute(self, sentence, *args, **kwargs) -> Any:
-        """execute.
-        Raises:
-            DriverError: Error on execution.
-
-        Returns:
-            Any: _description_
-        """
-        if self._connection:
-            try:
-                result = await self._connection.execute_command(sentence, *args)
-                return result
-            except (RedisError,) as err:
-                raise DriverError(f"Connection Error: {err}") from err
-
-    execute_many = execute
-
-    async def prepare(self, sentence: Union[str, list]) -> Any:
-        raise NotImplementedError()  # pragma: no-cover
-
-    async def test_connection(self, key: str = "test_123", optional: int = 1):  # pylint: disable=W0221
-        result = None
-        error = None
-        try:
-            await self.set(key, optional)
-            result = await self.get(key)
-        except Exception as err:  # pylint: disable=W0703
-            error = err
-        finally:
-            await self.delete(key)
-            return [result, error]  # pylint: disable=W0150
-
-    async def get(self, key):
-        try:
-            return await self._connection.get(key)
-        except aioredis.RedisError as err:
-            raise DriverError(f"Redis Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Unknown Error: {err}") from err
-
-    async def query(self, sentence: str, **kwargs):
-        return await self.get(sentence)
-
-    async def queryrow(self, sentence: str):
-        result = await self.get(sentence)
-        if isinstance(result, list):
-            result = result[0]
-        return result
-
-    async def set(self, key, value, **kwargs):
-        try:
-            return await self._connection.set(key, value, **kwargs)
-        except aioredis.RedisError as err:
-            raise DriverError(f"Redis Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Unknown Error: {err}") from err
-
-    async def use(self, database: int):
-        try:
-            await self._connection.execute_command("SELECT", database)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Can't change to DB: {err!s}") from err
-
-    async def clear_redis(self, host: bool = True):
-        """
-        Clear a cache.
-        """
-        try:
-            if host is True:
-                return await self._connection.flushall()
-            else:
-                return await self._connection.flushdb()
-        except Exception as ex:
-            raise DriverError(f"Redis: Error cleaning DB: {ex!s}") from ex
-
-    async def exists(self, key, *keys):
-        if not self._connection:
-            await self.connection()
-        try:
-            return await self._connection.exists(key, *keys)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Exists: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Exists Unknown Error: {err}") from err
-
-    async def delete(self, key, *keys):
-        try:
-            return await self._connection.delete(key, *keys)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Delete: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Delete Unknown Error: {err}") from err
-
-    async def expire_at(self, key, timestamp):
-        try:
-            return await self._connection.expireat(key, timestamp)
-        except TypeError as ex:
-            raise DriverError(f"Redis: wrong Expiration timestamp: {timestamp}") from ex
-        except Exception as err:
-            raise DriverError(f"Redis Expiration Unknown Error: {err}") from err
-
-    async def setex(self, key, value, timeout):
-        """
-        setex.
-           Set the value and expiration of a Key.
-           params:
-            key: key Name
-            value: value of the key
-            timeout: expiration time in seconds
-        """
-        if not isinstance(timeout, int):
-            expiration = 900
-        else:
-            expiration = timeout
-        try:
-            await self._connection.setex(key, expiration, value)
-        except TypeError as ex:
-            raise DriverError(f"Redis: wrong Expiration timestamp: {expiration}") from ex
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on SetEX: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis SetEX Unknown Error: {err}") from err
-
-    def persist(self, key):
-        """
-        persist.
-            Remove the expiration of a key.
-        """
-        try:
-            return self._connection.persist(key)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Persist: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Persist Unknown Error: {err}") from err
-
-    async def set_key(self, key, value):
-        await self.set(key, value)
-
-    async def get_key(self, key):
-        return await self.get(key)
-
-    ### Hash functions
-    async def hmset(self, name: str, info: dict):
-        """
-        set the value of a key in field (redis dict).
-        """
-        try:
-            # await self._connection.hmset(name, mapping)
-            await self._connection.hmset(name, mapping=info)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on hmset: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis hmset Unknown Error: {err}") from err
-
-    async def hgetall(self, key):
-        """
-        Get all the fields and values in a hash (redis dict).
-        """
-        try:
-            return await self._connection.hgetall(key)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on hgetall: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis hgetall Unknown Error: {err}") from err
-
-    async def set_hash(self, key, kwargs):
-        await self.hmset(key, kwargs)
-
-    async def get_hash(self, key):
-        return await self.hgetall(key)
-
-    fetch_all = get_hash
-
-    async def hkeys(self, key):
-        """
-        Get the keys in a hash (redis dict).
-        """
-        try:
-            return await self._connection.hkeys(key)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on hkeys: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis hkeys Unknown Error: {err}") from err
-
-    async def hlen(self, key):
-        """
-        Return the number of elements in hash *key* (redis dict).
-        """
-        try:
-            return await self._connection.hlen(key)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on hlen: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis hlen Unknown Error: {err}") from err
-
-    async def hvals(self, key):
-        """
-        Return the list of values within hash (redis dict).
-        """
-        try:
-            return await self._connection.hvals(key)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on hvals: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis hvals Unknown Error: {err}") from err
-
-    async def keys(self, key):
-        return await self.hkeys(key)
-
-    async def values(self, key):
-        return await self.hvals(key)
-
-    async def hset(self, key, field, value, mapping: dict = None):
-        """
-        Set field to value within hash with name *key*.
-        """
-        try:
-            await self._connection.hset(key, key=field, value=value, mapping=mapping)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Hset: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Hset Unknown Error: {err}") from err
-
-    async def hget(self, key, field):
-        """
-        get the value of a hash field (redis dict)
-        """
-        try:
-            return await self._connection.hget(key, field)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Hget: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Hget Unknown Error: {err}") from err
-
-    fetch_one = hget
-
-    async def hexists(self, key, field):
-        """
-        Determine if hash field exists on redis dict *key*.
-        """
-        try:
-            await self._connection.hexists(key, field)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Hexists: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Hexists Unknown Error: {err}") from err
-
-    async def hdel(self, key, field, *fields):
-        """
-        Delete one or more hash fields from *key*.
-        """
-        try:
-            await self._connection.hdel(key, field, *fields)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on HDel: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis HDel Unknown Error: {err}") from err
-
-    async def mset(self, mapping):
-        """
-        Sets key/values based on a mapping.
-        """
-        try:
-            await self._connection.mset(mapping)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Mset: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Mset Unknown Error: {err}") from err
-
-    async def move(self, key, database):
-        """
-        Moves a key to another database.
-        """
-        try:
-            await self._connection.move(key, database)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Move: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Move Unknown Error: {err}") from err
-
-    async def lrange(self, key, start: int = 0, stop: int = 100):
-        """
-        Return a slice of the list key between position start and end.
-        """
-        try:
-            await self._connection.lrange(key, start, stop)
-        except ConnectionError as err:
-            raise DriverError(f"Error connecting to Redis {err}") from err
-        except RedisError as err:
-            raise DriverError(f"Redis: Error on Lrange: {err!s}") from err
-        except Exception as err:
-            raise DriverError(f"Redis Lrange Unknown Error: {err}") from err
+#!/usr/bin/env python3
+""" Redis async Provider.
+Notes on redis Provider
+--------------------
+This provider implements a few subset of funcionalities from aioredis, is a WIP
+TODO:
+ - use jsonpath to query json-objects
+ - implements lists and hash datatypes
+"""
+import asyncio
+import time
+from typing import Any, Union
+from redis import asyncio as aioredis
+from redis.exceptions import AuthenticationError, RedisError
+from ..exceptions import ConnectionTimeout, DriverError
+from .abstract import BaseDriver, BasePool
+
+
+class redisPool(BasePool):
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._dsn = "redis://{host}:{port}/{db}"
+        super(redisPool, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+
+    # Create a redis connection pool
+    async def connect(self, **kwargs):
+        """
+        __init async db initialization
+        """
+        self._logger.debug(f"Redis Pool: Connecting to {self._dsn}")
+        try:
+            self._pool = aioredis.ConnectionPool.from_url(
+                self._dsn,
+                encoding=self._encoding,
+                decode_responses=True,
+                max_connections=self._max_queries,
+                health_check_interval=60.0,
+                **kwargs,
+            )
+            self._connection = aioredis.Redis(connection_pool=self._pool)
+        except ConnectionError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Error: {err}") from err
+        # is connected
+        if self._pool:
+            self._connected = True
+            self._initialized_on = time.time()
+        return self
+
+    async def acquire(self):
+        """
+        Take a connection from the pool.
+        """
+        # Take a connection from the pool.
+        try:
+            return redis(connection=self._connection, pool=self)
+        except ConnectionError as err:
+            raise ConnectionError(f"Redis Pool is already closed: {err}") from err
+        except RedisError as err:
+            raise ConnectionError(f"Redis Pool is closed o doesnt exists: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Unknown Error: {err}") from err
+
+    async def release(self, connection: "redis " = None):  # pylint: disable=W0221
+        """
+        Release a connection from the pool
+        """
+        if not connection:
+            return True
+        try:
+            print(type(connection.get_connection()))
+            await self._pool.release(connection.get_connection())
+        except Exception as err:
+            raise DriverError(f"Release Error: {err}") from err
+
+    async def close(self):  # pylint: disable=W0221
+        """
+        Close Pool
+        """
+        try:
+            if self._connection is not None:
+                await self._connection.close()
+            if self._pool:
+                await self._pool.disconnect(inuse_connections=True)
+            self._connected = False
+            return True
+        except ConnectionError as err:
+            raise DriverError(f"Connection close Error: {err}") from err
+        except Exception as err:
+            self._logger.exception(f"Pool Closing Error: {err}")
+            raise DriverError(f"Connection close Error: {err}") from err
+
+    disconnect = close
+
+    async def execute(self, sentence, *args, **kwargs):
+        """
+        Execute a connection into the Pool
+        """
+        if self._pool:
+            try:
+                result = await self._connection.execute_command(sentence, *args, **kwargs)
+                return result
+            except TypeError as err:
+                raise DriverError(f"Execute Error: {err}") from err
+            except (ConnectionError, redis.exceptions.ConnectionError) as err:
+                raise DriverError(f"Connection cannot be decoded or is broken, Error: {err}") from err
+            except RedisError as err:
+                raise DriverError(f"Connection close Error: {err}") from err
+            except Exception as err:
+                raise DriverError(f"Redis Execute Error: {err}") from err
+
+
+class redis(BaseDriver):
+    _provider = "redis"
+    _syntax = "json"
+
+    def __init__(self, dsn: str = None, loop=None, params: dict = None, **kwargs):
+        self._dsn = "redis://{host}:{port}/{db}"
+        super(redis, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+        if "connection" in kwargs:
+            self._connection = kwargs["connection"]
+            self._connected = True
+        if "pool" in kwargs:
+            self._pool = kwargs["pool"]
+            self._connected = True
+        self._initialized_on = time.time()
+
+    ### Properties
+    @property
+    def redis(self):
+        return self._connection
+
+    # Create a redis pool
+    async def connection(self, **kwargs):
+        """
+        __init async redis initialization
+        """
+        try:
+            self._connection = await aioredis.from_url(
+                self._dsn,
+                encoding=self._encoding,
+                decode_responses=True,
+                **kwargs,
+            )
+        except AuthenticationError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except ConnectionError as err:
+            raise DriverError(f"Connection Error: {err}") from err
+        except (RedisError, asyncio.TimeoutError) as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+        # is connected
+        if self._connection:
+            self._connected = True
+            self._initialized_on = time.time()
+        return self
+
+    def is_closed(self):
+        if not self._connection:
+            return True
+        else:
+            return not self._connected
+
+    async def ping(self, msg: str = None):
+        if msg is not None:
+            await self._connection.echo(msg)
+        await self._connection.ping()
+
+    async def close(self, timeout: int = 10):
+        try:
+            # gracefully closing underlying connection
+            await self._connection.close()
+            try:
+                # safely closing the inner connection pool
+                await self._connection.connection_pool.disconnect()
+                self._connected = False
+            except Exception as err:
+                raise DriverError(f"Unknown Redis Error: {err}") from err
+        except (RuntimeError, AttributeError):
+            pass
+        except Exception as err:
+            self._logger.exception(f"Redis Closing Error: {err}")
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    disconnect = close
+
+    async def execute(self, sentence, *args, **kwargs) -> Any:
+        """execute.
+        Raises:
+            DriverError: Error on execution.
+
+        Returns:
+            Any: _description_
+        """
+        if self._connection:
+            try:
+                result = await self._connection.execute_command(sentence, *args)
+                return result
+            except (RedisError,) as err:
+                raise DriverError(f"Connection Error: {err}") from err
+
+    execute_many = execute
+
+    async def prepare(self, sentence: Union[str, list]) -> Any:
+        raise NotImplementedError()  # pragma: no-cover
+
+    async def test_connection(self, key: str = "test_123", optional: int = 1):  # pylint: disable=W0221
+        result = None
+        error = None
+        try:
+            await self.set(key, optional)
+            result = await self.get(key)
+        except Exception as err:  # pylint: disable=W0703
+            error = err
+        finally:
+            await self.delete(key)
+            return [result, error]  # pylint: disable=W0150
+
+    async def get(self, key):
+        try:
+            return await self._connection.get(key)
+        except RedisError as err:
+            raise DriverError(f"Redis Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Unknown Error: {err}") from err
+
+    async def query(self, sentence: str, **kwargs):
+        return await self.get(sentence)
+
+    async def queryrow(self, sentence: str):
+        result = await self.get(sentence)
+        if isinstance(result, list):
+            result = result[0]
+        return result
+
+    async def set(self, key, value, **kwargs):
+        try:
+            return await self._connection.set(key, value, **kwargs)
+        except RedisError as err:
+            raise DriverError(f"Redis Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Unknown Error: {err}") from err
+
+    async def use(self, database: int):
+        try:
+            await self._connection.execute_command("SELECT", database)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Can't change to DB: {err!s}") from err
+
+    async def clear_redis(self, host: bool = True):
+        """
+        Clear a cache.
+        """
+        try:
+            if host is True:
+                return await self._connection.flushall()
+            else:
+                return await self._connection.flushdb()
+        except Exception as ex:
+            raise DriverError(f"Redis: Error cleaning DB: {ex!s}") from ex
+
+    async def exists(self, key, *keys):
+        if not self._connection:
+            await self.connection()
+        try:
+            return await self._connection.exists(key, *keys)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Exists: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Exists Unknown Error: {err}") from err
+
+    async def delete(self, key, *keys):
+        try:
+            return await self._connection.delete(key, *keys)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Delete: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Delete Unknown Error: {err}") from err
+
+    async def expire_at(self, key, timestamp):
+        try:
+            return await self._connection.expireat(key, timestamp)
+        except TypeError as ex:
+            raise DriverError(f"Redis: wrong Expiration timestamp: {timestamp}") from ex
+        except Exception as err:
+            raise DriverError(f"Redis Expiration Unknown Error: {err}") from err
+
+    async def setex(self, key, value, timeout):
+        """
+        setex.
+           Set the value and expiration of a Key.
+           params:
+            key: key Name
+            value: value of the key
+            timeout: expiration time in seconds
+        """
+        if not isinstance(timeout, int):
+            expiration = 900
+        else:
+            expiration = timeout
+        try:
+            await self._connection.setex(key, expiration, value)
+        except TypeError as ex:
+            raise DriverError(f"Redis: wrong Expiration timestamp: {expiration}") from ex
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on SetEX: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis SetEX Unknown Error: {err}") from err
+
+    def persist(self, key):
+        """
+        persist.
+            Remove the expiration of a key.
+        """
+        try:
+            return self._connection.persist(key)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Persist: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Persist Unknown Error: {err}") from err
+
+    async def set_key(self, key, value):
+        await self.set(key, value)
+
+    async def get_key(self, key):
+        return await self.get(key)
+
+    ### Hash functions
+    async def hmset(self, name: str, info: dict):
+        """
+        set the value of a key in field (redis dict).
+        """
+        try:
+            # await self._connection.hmset(name, mapping)
+            await self._connection.hmset(name, mapping=info)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on hmset: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis hmset Unknown Error: {err}") from err
+
+    async def hgetall(self, key):
+        """
+        Get all the fields and values in a hash (redis dict).
+        """
+        try:
+            return await self._connection.hgetall(key)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on hgetall: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis hgetall Unknown Error: {err}") from err
+
+    async def set_hash(self, key, kwargs):
+        await self.hmset(key, kwargs)
+
+    async def get_hash(self, key):
+        return await self.hgetall(key)
+
+    fetch_all = get_hash
+
+    async def hkeys(self, key):
+        """
+        Get the keys in a hash (redis dict).
+        """
+        try:
+            return await self._connection.hkeys(key)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on hkeys: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis hkeys Unknown Error: {err}") from err
+
+    async def hlen(self, key):
+        """
+        Return the number of elements in hash *key* (redis dict).
+        """
+        try:
+            return await self._connection.hlen(key)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on hlen: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis hlen Unknown Error: {err}") from err
+
+    async def hvals(self, key):
+        """
+        Return the list of values within hash (redis dict).
+        """
+        try:
+            return await self._connection.hvals(key)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on hvals: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis hvals Unknown Error: {err}") from err
+
+    async def keys(self, key):
+        return await self.hkeys(key)
+
+    async def values(self, key):
+        return await self.hvals(key)
+
+    async def hset(self, key, field, value, mapping: dict = None):
+        """
+        Set field to value within hash with name *key*.
+        """
+        try:
+            await self._connection.hset(key, key=field, value=value, mapping=mapping)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Hset: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Hset Unknown Error: {err}") from err
+
+    async def hget(self, key, field):
+        """
+        get the value of a hash field (redis dict)
+        """
+        try:
+            return await self._connection.hget(key, field)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Hget: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Hget Unknown Error: {err}") from err
+
+    fetch_one = hget
+
+    async def hexists(self, key, field):
+        """
+        Determine if hash field exists on redis dict *key*.
+        """
+        try:
+            await self._connection.hexists(key, field)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Hexists: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Hexists Unknown Error: {err}") from err
+
+    async def hdel(self, key, field, *fields):
+        """
+        Delete one or more hash fields from *key*.
+        """
+        try:
+            await self._connection.hdel(key, field, *fields)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on HDel: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis HDel Unknown Error: {err}") from err
+
+    async def mset(self, mapping):
+        """
+        Sets key/values based on a mapping.
+        """
+        try:
+            await self._connection.mset(mapping)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Mset: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Mset Unknown Error: {err}") from err
+
+    async def move(self, key, database):
+        """
+        Moves a key to another database.
+        """
+        try:
+            await self._connection.move(key, database)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Move: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Move Unknown Error: {err}") from err
+
+    async def lrange(self, key, start: int = 0, stop: int = 100):
+        """
+        Return a slice of the list key between position start and end.
+        """
+        try:
+            await self._connection.lrange(key, start, stop)
+        except ConnectionError as err:
+            raise DriverError(f"Error connecting to Redis {err}") from err
+        except RedisError as err:
+            raise DriverError(f"Redis: Error on Lrange: {err!s}") from err
+        except Exception as err:
+            raise DriverError(f"Redis Lrange Unknown Error: {err}") from err
```

## asyncdb/drivers/delta.py

```diff
@@ -1,275 +1,275 @@
-#!/usr/bin/env python3
-""" DeltaLake no-async Provider.
-Notes on memcache Provider
---------------------
-This provider implements a simple subset of funcionalities
-over DeltaLake DeltaTable Protocol.
-TODO: add Thread Pool Support.
-"""
-import asyncio
-import time
-from typing import Any, Union, Optional
-from datetime import datetime
-from pathlib import Path
-import pyarrow.parquet as pq
-import pyarrow.csv as pcsv
-from pyarrow import fs
-import pandas as pd
-import datatable as dt
-from deltalake import DeltaTable
-from deltalake import PyDeltaTableError
-from deltalake.table import DeltaTableProtocolError
-from deltalake.writer import write_deltalake
-from asyncdb.exceptions import DriverError
-from .abstract import (
-    InitDriver,
-)
-
-
-class delta(InitDriver):
-    _provider = "delta"
-    _syntax = "nosql"
-
-    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        try:
-            self.storage_options = params["storage_options"]
-            del params["storage_options"]
-        except KeyError:
-            self.storage_options = {}
-        try:
-            self.filename = params["filename"]
-            del params["filename"]
-        except KeyError as ex:
-            raise DriverError("Delta: Missing Filename on Parameters") from ex
-        super().__init__(loop=loop, params=params, **kwargs)
-        self.kwargs = params
-
-    ### Context magic Methods
-    def __enter__(self):
-        return self
-
-    def __exit__(self, *args):
-        self.close()
-
-    # Create a memcache Connection
-    async def connection(self, version: int = None):  # pylint: disable=W0236
-        """
-        __init Memcache initialization.
-        """
-        self._logger.info(f"DeltaTable: Connecting to {self.filename}")
-        try:
-            if version is not None:
-                self.kwargs["version"] = version
-            if self.filename.startswith("s3:"):
-                raw_fs, normalized_path = fs.FileSystem.from_uri(self.filename)
-                filesystem = fs.SubTreeFileSystem(normalized_path, raw_fs)
-                self._connection = DeltaTable(self.filename)
-                self._storage = self._connection.to_pyarrow_dataset(filesystem=filesystem)
-            # filesystem = fs.SubTreeFileSystem(self.filename, fs.LocalFileSystem())
-            else:
-                self._connection = DeltaTable(self.filename, storage_options=self.storage_options, **self.kwargs)
-        except PyDeltaTableError as exc:
-            raise DriverError(message=f"{exc}") from exc
-        except Exception as err:
-            raise DriverError(message=f"Unknown DataTable Error: {err}") from err
-        # is connected
-        if self._connection:
-            self._connected = True
-            self._initialized_on = time.time()
-        return self
-
-    async def close(self):  # pylint: disable=W0221,W0236
-        """
-        Closing DeltaTable Connection
-        """
-        try:
-            pass  # TODO
-        except Exception as err:
-            raise DriverError(f"Unknown Closing Error: {err}") from err
-
-    disconnect = close
-
-    def load_version(self, version: Union[int, datetime]):
-        if isinstance(version, int):
-            self._connection.load_version(version)
-        elif isinstance(version, datetime):
-            self._connection.load_with_datetime(version)
-        return self
-
-    def metadata(self):
-        return self._connection.metadata()
-
-    def schema(self):
-        return self._connection.schema()
-
-    def test_connection(self, key: str = "test_123", optional: int = 1):  # pylint: disable=W0221,W0236
-        result = None
-        error = None
-        try:
-            self.set(key, optional)
-            result = self.get(key)
-        except Exception as err:  # pylint: disable=W0703
-            error = err
-        finally:
-            self.delete(key)
-            return [result, error]  # pylint: disable=W0150
-
-    async def create(
-        self, path: Union[str, Path], data: Any, name: Optional[str] = None, mode: str = "append", **kwargs
-    ):
-        if isinstance(path, str):
-            path = Path(str).resolve()
-        if isinstance(data, str):
-            data = Path(str).resolve()
-        if isinstance(data, Path):
-            # open this file with Pandas or Arrow
-            ext = data.suffix
-            if ext == ".csv":
-                read_options = pcsv.ReadOptions()
-                parse_options = pcsv.ParseOptions()
-                convert_options = pcsv.ConvertOptions()
-                data = pcsv.read_csv(
-                    data, read_options=read_options, parse_options=parse_options, convert_options=convert_options
-                )
-            elif ext in [".xls", ".xlsx"]:
-                if ext == ".xls":
-                    engine = "xlrd"
-                else:
-                    engine = "openpyxl"
-                data = pd.read_excel(data, engine=engine)
-            elif ext == ".parquet":
-                data = pq.read_table(data)
-        try:
-            write_deltalake(path, data, name=name, mode=mode, **kwargs)
-        except PyDeltaTableError as exc:
-            raise DriverError(f"Delta: can't create a table in path {path}, error: {exc}") from exc
-        except Exception as exc:
-            raise DriverError(f"Delta Error: {exc}") from exc
-
-    def execute(self, sentence: Any):  # pylint: disable=W0221,W0236
-        raise NotImplementedError
-
-    async def execute_many(self, sentence=""):  # pylint: disable=W0221,W0236
-        raise NotImplementedError
-
-    async def prepare(self, sentence=""):
-        raise NotImplementedError
-
-    async def use(self, database=""):
-        raise NotImplementedError
-
-    async def get(
-        self,
-        partitions: Optional[list] = None,
-        columns: Optional[list] = None,
-        factory: Optional[str] = "pandas",
-        **kwargs,
-    ):  # pylint: disable=W0221,W0236
-        """get.
-        Getting Data from Delta using columns and
-        partitions.
-        """
-        result = None
-        args = {}
-        if partitions:
-            args = {"partitions": partitions}
-        if columns:
-            args["columns"] = columns
-        try:
-            if factory == "pandas":
-                result = self._connection.to_pandas(**args)
-            elif factory == "arrow":
-                result = self._connection.to_pyarrow_table(**args)
-            elif factory == "arrow_dataset":
-                result = self._connection.to_pyarrow_dataset(**args, **kwargs)
-            return result
-        except (PyDeltaTableError, DeltaTableProtocolError) as exc:
-            raise DriverError(f"DeltaTable Error: {exc}") from exc
-        except Exception as exc:
-            raise DriverError(f"Query Error: {exc}") from exc
-
-    async def query(
-        self,
-        sentence: Optional[str] = None,
-        partitions: Optional[list] = None,
-        columns: Optional[list] = None,
-        factory: Optional[str] = "pandas",
-        **kwargs,
-    ):  # pylint: disable=W0221,W0236
-        """query.
-        Getting Data from Delta using a query (with DuckDB) or via columns and
-        partitions.
-        """
-        result = None
-        error = None
-        args = {}
-        if partitions:
-            args = {"partitions": partitions}
-        if columns:
-            args["columns"] = columns
-        try:
-            if factory == "pandas":
-                result = self._connection.to_pandas(**args)
-            elif factory == "arrow":
-                result = self._connection.to_pyarrow_table(**args)
-            elif factory == "arrow_dataset":
-                result = self._connection.to_pyarrow_dataset(**args, **kwargs)
-        except (PyDeltaTableError, DeltaTableProtocolError) as exc:
-            error = exc
-            raise DriverError(f"DeltaTable Error: {exc}") from exc
-        except Exception as exc:
-            error = exc
-            raise DriverError(f"Query Error: {exc}") from exc
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    fetch_all = query
-
-    def queryrow(self, key: str, *args):  # pylint: disable=W0221,W0236
-        return self.get(key, *args)
-
-    fetch_one = queryrow
-
-    async def file_to_parquet(self, filename: Union[str, Path], parquet: str, factory: str = "pandas", **kwargs):
-        """csv_to_parquet.
-
-        Creating a parquet file from a CSV object.
-        """
-        if isinstance(filename, str):
-            filename = Path(filename).resolve()
-        ext = filename.suffix
-        arguments = kwargs.get("pd_args", {})
-        df = None
-        if ext in (".csv", ".txt", ".TXT", ".CSV"):
-            if factory == "pandas":
-                df = pd.read_csv(
-                    filename,
-                    quotechar='"',
-                    decimal=",",
-                    engine="c",
-                    keep_default_na=False,
-                    na_values=["NULL", "TBD"],
-                    na_filter=True,
-                    skipinitialspace=True,
-                    **arguments,
-                )
-            elif factory == "datatable":
-                frame = dt.fread(filename, **arguments)
-                df = frame.to_pandas()
-            elif factory == "arrow":
-                atable = pcsv.read_csv(filename, **arguments)
-        elif ext in [".xls", ".xlsx"]:
-            if ext == ".xls":
-                engine = "xlrd"
-            else:
-                engine = "openpyxl"
-            df = pd.read_excel(
-                filename, na_values=["NULL", "TBD"], na_filter=True, engine=engine, keep_default_na=False, **arguments
-            )
-        try:
-            if df is not None:
-                df.to_parquet(parquet, engine="pyarrow", compression="snappy")
-            elif atable is not None:
-                pq.write_table(atable, parquet, compression="snappy")
-        except Exception as exc:
-            raise DriverError(f"Query Error: {exc}") from exc
+#!/usr/bin/env python3
+""" DeltaLake no-async Provider.
+Notes on memcache Provider
+--------------------
+This provider implements a simple subset of funcionalities
+over DeltaLake DeltaTable Protocol.
+TODO: add Thread Pool Support.
+"""
+import asyncio
+import time
+from typing import Any, Union, Optional
+from datetime import datetime
+from pathlib import Path
+import pyarrow.parquet as pq
+import pyarrow.csv as pcsv
+from pyarrow import fs
+import pandas as pd
+import datatable as dt
+from deltalake import DeltaTable
+from deltalake import PyDeltaTableError
+from deltalake.table import DeltaTableProtocolError
+from deltalake.writer import write_deltalake
+from ..exceptions import DriverError
+from .abstract import (
+    InitDriver,
+)
+
+
+class delta(InitDriver):
+    _provider = "delta"
+    _syntax = "nosql"
+
+    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        try:
+            self.storage_options = params["storage_options"]
+            del params["storage_options"]
+        except KeyError:
+            self.storage_options = {}
+        try:
+            self.filename = params["filename"]
+            del params["filename"]
+        except KeyError as ex:
+            raise DriverError("Delta: Missing Filename on Parameters") from ex
+        super().__init__(loop=loop, params=params, **kwargs)
+        self.kwargs = params
+
+    ### Context magic Methods
+    def __enter__(self):
+        return self
+
+    def __exit__(self, *args):
+        self.close()
+
+    # Create a memcache Connection
+    async def connection(self, version: int = None):  # pylint: disable=W0236
+        """
+        __init Memcache initialization.
+        """
+        self._logger.info(f"DeltaTable: Connecting to {self.filename}")
+        try:
+            if version is not None:
+                self.kwargs["version"] = version
+            if self.filename.startswith("s3:"):
+                raw_fs, normalized_path = fs.FileSystem.from_uri(self.filename)
+                filesystem = fs.SubTreeFileSystem(normalized_path, raw_fs)
+                self._connection = DeltaTable(self.filename)
+                self._storage = self._connection.to_pyarrow_dataset(filesystem=filesystem)
+            # filesystem = fs.SubTreeFileSystem(self.filename, fs.LocalFileSystem())
+            else:
+                self._connection = DeltaTable(self.filename, storage_options=self.storage_options, **self.kwargs)
+        except PyDeltaTableError as exc:
+            raise DriverError(message=f"{exc}") from exc
+        except Exception as err:
+            raise DriverError(message=f"Unknown DataTable Error: {err}") from err
+        # is connected
+        if self._connection:
+            self._connected = True
+            self._initialized_on = time.time()
+        return self
+
+    async def close(self):  # pylint: disable=W0221,W0236
+        """
+        Closing DeltaTable Connection
+        """
+        try:
+            pass  # TODO
+        except Exception as err:
+            raise DriverError(f"Unknown Closing Error: {err}") from err
+
+    disconnect = close
+
+    def load_version(self, version: Union[int, datetime]):
+        if isinstance(version, int):
+            self._connection.load_version(version)
+        elif isinstance(version, datetime):
+            self._connection.load_with_datetime(version)
+        return self
+
+    def metadata(self):
+        return self._connection.metadata()
+
+    def schema(self):
+        return self._connection.schema()
+
+    def test_connection(self, key: str = "test_123", optional: int = 1):  # pylint: disable=W0221,W0236
+        result = None
+        error = None
+        try:
+            self.set(key, optional)
+            result = self.get(key)
+        except Exception as err:  # pylint: disable=W0703
+            error = err
+        finally:
+            self.delete(key)
+            return [result, error]  # pylint: disable=W0150
+
+    async def create(
+        self, path: Union[str, Path], data: Any, name: Optional[str] = None, mode: str = "append", **kwargs
+    ):
+        if isinstance(path, str):
+            path = Path(str).resolve()
+        if isinstance(data, str):
+            data = Path(str).resolve()
+        if isinstance(data, Path):
+            # open this file with Pandas or Arrow
+            ext = data.suffix
+            if ext == ".csv":
+                read_options = pcsv.ReadOptions()
+                parse_options = pcsv.ParseOptions()
+                convert_options = pcsv.ConvertOptions()
+                data = pcsv.read_csv(
+                    data, read_options=read_options, parse_options=parse_options, convert_options=convert_options
+                )
+            elif ext in [".xls", ".xlsx"]:
+                if ext == ".xls":
+                    engine = "xlrd"
+                else:
+                    engine = "openpyxl"
+                data = pd.read_excel(data, engine=engine)
+            elif ext == ".parquet":
+                data = pq.read_table(data)
+        try:
+            write_deltalake(path, data, name=name, mode=mode, **kwargs)
+        except PyDeltaTableError as exc:
+            raise DriverError(f"Delta: can't create a table in path {path}, error: {exc}") from exc
+        except Exception as exc:
+            raise DriverError(f"Delta Error: {exc}") from exc
+
+    def execute(self, sentence: Any):  # pylint: disable=W0221,W0236
+        raise NotImplementedError
+
+    async def execute_many(self, sentence=""):  # pylint: disable=W0221,W0236
+        raise NotImplementedError
+
+    async def prepare(self, sentence=""):
+        raise NotImplementedError
+
+    async def use(self, database=""):
+        raise NotImplementedError
+
+    async def get(
+        self,
+        partitions: Optional[list] = None,
+        columns: Optional[list] = None,
+        factory: Optional[str] = "pandas",
+        **kwargs,
+    ):  # pylint: disable=W0221,W0236
+        """get.
+        Getting Data from Delta using columns and
+        partitions.
+        """
+        result = None
+        args = {}
+        if partitions:
+            args = {"partitions": partitions}
+        if columns:
+            args["columns"] = columns
+        try:
+            if factory == "pandas":
+                result = self._connection.to_pandas(**args)
+            elif factory == "arrow":
+                result = self._connection.to_pyarrow_table(**args)
+            elif factory == "arrow_dataset":
+                result = self._connection.to_pyarrow_dataset(**args, **kwargs)
+            return result
+        except (PyDeltaTableError, DeltaTableProtocolError) as exc:
+            raise DriverError(f"DeltaTable Error: {exc}") from exc
+        except Exception as exc:
+            raise DriverError(f"Query Error: {exc}") from exc
+
+    async def query(
+        self,
+        sentence: Optional[str] = None,
+        partitions: Optional[list] = None,
+        columns: Optional[list] = None,
+        factory: Optional[str] = "pandas",
+        **kwargs,
+    ):  # pylint: disable=W0221,W0236
+        """query.
+        Getting Data from Delta using a query (with DuckDB) or via columns and
+        partitions.
+        """
+        result = None
+        error = None
+        args = {}
+        if partitions:
+            args = {"partitions": partitions}
+        if columns:
+            args["columns"] = columns
+        try:
+            if factory == "pandas":
+                result = self._connection.to_pandas(**args)
+            elif factory == "arrow":
+                result = self._connection.to_pyarrow_table(**args)
+            elif factory == "arrow_dataset":
+                result = self._connection.to_pyarrow_dataset(**args, **kwargs)
+        except (PyDeltaTableError, DeltaTableProtocolError) as exc:
+            error = exc
+            raise DriverError(f"DeltaTable Error: {exc}") from exc
+        except Exception as exc:
+            error = exc
+            raise DriverError(f"Query Error: {exc}") from exc
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    fetch_all = query
+
+    def queryrow(self, key: str, *args):  # pylint: disable=W0221,W0236
+        return self.get(key, *args)
+
+    fetch_one = queryrow
+
+    async def file_to_parquet(self, filename: Union[str, Path], parquet: str, factory: str = "pandas", **kwargs):
+        """csv_to_parquet.
+
+        Creating a parquet file from a CSV object.
+        """
+        if isinstance(filename, str):
+            filename = Path(filename).resolve()
+        ext = filename.suffix
+        arguments = kwargs.get("pd_args", {})
+        df = None
+        if ext in (".csv", ".txt", ".TXT", ".CSV"):
+            if factory == "pandas":
+                df = pd.read_csv(
+                    filename,
+                    quotechar='"',
+                    decimal=",",
+                    engine="c",
+                    keep_default_na=False,
+                    na_values=["NULL", "TBD"],
+                    na_filter=True,
+                    skipinitialspace=True,
+                    **arguments,
+                )
+            elif factory == "datatable":
+                frame = dt.fread(filename, **arguments)
+                df = frame.to_pandas()
+            elif factory == "arrow":
+                atable = pcsv.read_csv(filename, **arguments)
+        elif ext in [".xls", ".xlsx"]:
+            if ext == ".xls":
+                engine = "xlrd"
+            else:
+                engine = "openpyxl"
+            df = pd.read_excel(
+                filename, na_values=["NULL", "TBD"], na_filter=True, engine=engine, keep_default_na=False, **arguments
+            )
+        try:
+            if df is not None:
+                df.to_parquet(parquet, engine="pyarrow", compression="snappy")
+            elif atable is not None:
+                pq.write_table(atable, parquet, compression="snappy")
+        except Exception as exc:
+            raise DriverError(f"Query Error: {exc}") from exc
```

## asyncdb/drivers/duckdb.py

```diff
@@ -1,285 +1,285 @@
-from typing import Any, Optional, Union
-from collections.abc import Iterable, Sequence
-import asyncio
-import time
-import duckdb as db
-from asyncdb.exceptions import NoDataFound, DriverError
-from asyncdb.interfaces import DBCursorBackend
-from .sql import SQLCursor, SQLDriver
-
-
-class duckdbCursor(SQLCursor):
-    """
-    Cursor Object for SQLite.
-    """
-
-    _provider: "duckdb"
-    _connection: db.DuckDBPyConnection = None
-
-    async def __aenter__(self) -> "duckdbCursor":
-        self._cursor = self._connection.execute(self._sentence, parameters=self._params)
-        return self
-
-    async def __anext__(self):
-        """Use `cursor.fetchrow()` to provide an async iterable.
-        raise: StopAsyncIteration when done.
-        """
-        row = self._cursor.fetchone()
-        if row is not None:
-            return row
-        else:
-            raise StopAsyncIteration
-
-    ### Cursor Methods.
-    async def fetch_one(self) -> Optional[Sequence]:
-        return self._cursor.fetchone()
-
-    async def fetch_many(self, size: int = None) -> Iterable[Sequence]:
-        return self._cursor.fetch(size)
-
-    async def fetch_all(self) -> Iterable[Sequence]:
-        return self._cursor.fetchall()
-
-
-class duckdb(SQLDriver, DBCursorBackend):
-    _provider: str = "duckdb"
-    _syntax: str = "sql"
-    _dsn: str = "{database}"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        SQLDriver.__init__(self, dsn, loop, params, **kwargs)
-        DBCursorBackend.__init__(self)
-
-    async def connection(self, **kwargs):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            self._connection = db.connect(database=self._dsn, **kwargs)
-            if self._connection:
-                if self._init_func is not None and callable(self._init_func):
-                    try:
-                        await self._init_func(self._connection)  # pylint: disable=E1102
-                    except RuntimeError as err:
-                        self._logger.exception(f"Error on Init Connection: {err!s}")
-                self._connected = True
-                self._initialized_on = time.time()
-            return self
-        except duckdb.ConnectionException as e:
-            raise DriverError(f"Unable to Open Database: {self._dsn}, {e}") from e
-        except Exception as e:
-            self._logger.exception(e, stack_info=True)
-            raise DriverError(f"SQLite Unknown Error: {e!s}") from e
-
-    connect = connection
-
-    async def prepare(self, sentence: Union[str, list]) -> Any:
-        "Ignoring prepared sentences on DuckDB for now"
-        raise NotImplementedError()  # pragma: no cover
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError()  # pragma: no cover
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError()  # pragma: no cover
-
-    async def use(self, database: str):
-        raise NotImplementedError("DuckDB Error: There is no Database in DuckDB")
-
-    async def close(self, timeout: int = 5) -> None:
-        """
-        Closing the Connection on DuckDB
-        """
-        try:
-            if self._connection:
-                self._connection.close()
-        except Exception as err:
-            raise DriverError(message=f"{__name__!s}: Closing Error: {err!s}") from err
-        finally:
-            self._connection = None
-            self._connected = False
-
-    async def query(self, sentence: Any, *args, **kwargs) -> Any:
-        """
-        Getting a Query from Database
-        """
-        error = None
-        cursor = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = self._connection.execute(sentence, *args, **kwargs)
-            self._result = cursor.fetchall()
-            if not self._result:
-                return (None, NoDataFound())
-        except Exception as err:
-            error = f"DuckDB Error on Query: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            return await self._serializer(self._result, error)
-
-    async def queryrow(self, sentence: Any = None) -> Iterable[Any]:
-        """
-        Getting a single Row from Database
-        """
-        error = None
-        cursor = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = self._connection.execute(sentence)
-            self._result = cursor.fetchone()
-            if not self._result:
-                return (None, NoDataFound())
-        except Exception as e:
-            error = f"Error on Query: {e}"
-            raise DriverError(message=error) from e
-        finally:
-            return await self._serializer(self._result, error)
-
-    async def fetch_all(self, sentence: str, *args, **kwargs) -> Sequence:
-        """
-        Alias for Query, but without error Support.
-        """
-        cursor = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = self._connection.execute(sentence, *args, **kwargs)
-            self._result = await cursor.fetchall()
-            if not self._result:
-                raise NoDataFound("DuckDB Fetch All: Data Not Found")
-            return self._result
-        except Exception as e:
-            error = f"Error on Fetch: {e}"
-            raise DriverError(message=error) from e
-
-    # alias to be compatible with aiosqlite methods.
-    fetchall = fetch_all
-
-    async def fetch_many(self, sentence: str, size: int = None):
-        """
-        Aliases for query, without error support
-        """
-        await self.valid_operation(sentence)
-        cursor = None
-        try:
-            cursor = self._connection.execute(sentence)
-            self._result = cursor.fetchmany(size)
-            if not self._result:
-                raise NoDataFound()
-            return self._result
-        except Exception as err:
-            error = f"Error on Query: {err}"
-            raise DriverError(message=error) from err
-
-    fetchmany = fetch_many
-
-    async def fetch_one(self, sentence: str, *args, **kwargs) -> Optional[dict]:
-        """
-        aliases for queryrow, but without error support
-        """
-        await self.valid_operation(sentence)
-        cursor = None
-        try:
-            cursor = self._connection.execute(sentence, *args, **kwargs)
-            self._result = cursor.fetchone()
-            return self._result
-            if not self._result:
-                raise NoDataFound()
-        except Exception as err:
-            error = f"Error on Query: {err}"
-            raise DriverError(message=error) from err
-
-    fetchone = fetch_one
-    fetchrow = fetch_one
-
-    async def execute(self, sentence: Any, **kwargs) -> Optional[Any]:
-        """Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        error = None
-        result = None
-        if kwargs:
-            params = kwargs
-        else:
-            params = None
-        await self.valid_operation(sentence)
-        try:
-            if result := self._connection.execute(sentence, parameters=params):
-                self._connection.commit()
-        except Exception as err:
-            error = f"Error on Execute: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            return (result, error)
-
-    async def execute_many(self, sentence: Union[str, list], *args) -> Optional[Any]:
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            result = self._connection.executemany(sentence, parameters=args)
-            if result:
-                self._connection.commit()
-        except Exception as err:
-            error = f"Error on Execute Many: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            return (result, error)
-
-    executemany = execute_many
-
-    async def __aenter__(self) -> Any:
-        try:
-            await self.connection()
-        except Exception as err:
-            error = f"Error on Cursor Fetch: {err}"
-            raise DriverError(message=error) from err
-        return self
-
-    async def fetch(self, sentence: str, parameters: Iterable[Any] = None) -> Iterable:
-        """Helper to create a cursor and execute the given query."""
-        await self.valid_operation(sentence)
-        if parameters is None:
-            parameters = []
-        try:
-            result = self._connection.execute(sentence, parameters=parameters)
-        except Exception as err:
-            error = f"Error on Cursor Fetch: {err}"
-            raise DriverError(message=error) from err
-        return result
-
-    async def __anext__(self) -> Optional[Any]:
-        """_summary_
-
-        Raises:
-            StopAsyncIteration: raised when end is reached.
-
-        Returns:
-            _type_: Single record for iteration.
-        """
-        data = self._cursor.fetchone()
-        if data is not None:
-            return data
-        else:
-            raise StopAsyncIteration
-
-    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
-        """
-        Create is a generic method for Database Objects Creation.
-        """
-        if obj == "table":
-            sql = "CREATE TABLE {name} ({columns});"
-            columns = ", ".join(["{name} {type}".format(**e) for e in fields])
-            sql = sql.format(name=name, columns=columns)
-            try:
-                result = self._connection.execute(sql)
-                if result:
-                    self._connection.commit()
-                    return True
-                else:
-                    return False
-            except Exception as err:
-                raise DriverError(f"Error in Object Creation: {err!s}") from err
-        else:
-            raise RuntimeError(f"DuckDB: invalid Object type {object!s}")
+from typing import Any, Optional, Union
+from collections.abc import Iterable, Sequence
+import asyncio
+import time
+import duckdb as db
+from ..exceptions import NoDataFound, DriverError
+from ..interfaces import DBCursorBackend
+from .sql import SQLCursor, SQLDriver
+
+
+class duckdbCursor(SQLCursor):
+    """
+    Cursor Object for SQLite.
+    """
+
+    _provider: "duckdb"
+    _connection: db.DuckDBPyConnection = None
+
+    async def __aenter__(self) -> "duckdbCursor":
+        self._cursor = self._connection.execute(self._sentence, parameters=self._params)
+        return self
+
+    async def __anext__(self):
+        """Use `cursor.fetchrow()` to provide an async iterable.
+        raise: StopAsyncIteration when done.
+        """
+        row = self._cursor.fetchone()
+        if row is not None:
+            return row
+        else:
+            raise StopAsyncIteration
+
+    ### Cursor Methods.
+    async def fetch_one(self) -> Optional[Sequence]:
+        return self._cursor.fetchone()
+
+    async def fetch_many(self, size: int = None) -> Iterable[Sequence]:
+        return self._cursor.fetch(size)
+
+    async def fetch_all(self) -> Iterable[Sequence]:
+        return self._cursor.fetchall()
+
+
+class duckdb(SQLDriver, DBCursorBackend):
+    _provider: str = "duckdb"
+    _syntax: str = "sql"
+    _dsn: str = "{database}"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        SQLDriver.__init__(self, dsn, loop, params, **kwargs)
+        DBCursorBackend.__init__(self)
+
+    async def connection(self, **kwargs):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            self._connection = db.connect(database=self._dsn, **kwargs)
+            if self._connection:
+                if self._init_func is not None and callable(self._init_func):
+                    try:
+                        await self._init_func(self._connection)  # pylint: disable=E1102
+                    except RuntimeError as err:
+                        self._logger.exception(f"Error on Init Connection: {err!s}")
+                self._connected = True
+                self._initialized_on = time.time()
+            return self
+        except duckdb.ConnectionException as e:
+            raise DriverError(f"Unable to Open Database: {self._dsn}, {e}") from e
+        except Exception as e:
+            self._logger.exception(e, stack_info=True)
+            raise DriverError(f"SQLite Unknown Error: {e!s}") from e
+
+    connect = connection
+
+    async def prepare(self, sentence: Union[str, list]) -> Any:
+        "Ignoring prepared sentences on DuckDB for now"
+        raise NotImplementedError()  # pragma: no cover
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError()  # pragma: no cover
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError()  # pragma: no cover
+
+    async def use(self, database: str):
+        raise NotImplementedError("DuckDB Error: There is no Database in DuckDB")
+
+    async def close(self, timeout: int = 5) -> None:
+        """
+        Closing the Connection on DuckDB
+        """
+        try:
+            if self._connection:
+                self._connection.close()
+        except Exception as err:
+            raise DriverError(message=f"{__name__!s}: Closing Error: {err!s}") from err
+        finally:
+            self._connection = None
+            self._connected = False
+
+    async def query(self, sentence: Any, *args, **kwargs) -> Any:
+        """
+        Getting a Query from Database
+        """
+        error = None
+        cursor = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = self._connection.execute(sentence, *args, **kwargs)
+            self._result = cursor.fetchall()
+            if not self._result:
+                return (None, NoDataFound())
+        except Exception as err:
+            error = f"DuckDB Error on Query: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            return await self._serializer(self._result, error)
+
+    async def queryrow(self, sentence: Any = None) -> Iterable[Any]:
+        """
+        Getting a single Row from Database
+        """
+        error = None
+        cursor = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = self._connection.execute(sentence)
+            self._result = cursor.fetchone()
+            if not self._result:
+                return (None, NoDataFound())
+        except Exception as e:
+            error = f"Error on Query: {e}"
+            raise DriverError(message=error) from e
+        finally:
+            return await self._serializer(self._result, error)
+
+    async def fetch_all(self, sentence: str, *args, **kwargs) -> Sequence:
+        """
+        Alias for Query, but without error Support.
+        """
+        cursor = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = self._connection.execute(sentence, *args, **kwargs)
+            self._result = await cursor.fetchall()
+            if not self._result:
+                raise NoDataFound("DuckDB Fetch All: Data Not Found")
+            return self._result
+        except Exception as e:
+            error = f"Error on Fetch: {e}"
+            raise DriverError(message=error) from e
+
+    # alias to be compatible with aiosqlite methods.
+    fetchall = fetch_all
+
+    async def fetch_many(self, sentence: str, size: int = None):
+        """
+        Aliases for query, without error support
+        """
+        await self.valid_operation(sentence)
+        cursor = None
+        try:
+            cursor = self._connection.execute(sentence)
+            self._result = cursor.fetchmany(size)
+            if not self._result:
+                raise NoDataFound()
+            return self._result
+        except Exception as err:
+            error = f"Error on Query: {err}"
+            raise DriverError(message=error) from err
+
+    fetchmany = fetch_many
+
+    async def fetch_one(self, sentence: str, *args, **kwargs) -> Optional[dict]:
+        """
+        aliases for queryrow, but without error support
+        """
+        await self.valid_operation(sentence)
+        cursor = None
+        try:
+            cursor = self._connection.execute(sentence, *args, **kwargs)
+            self._result = cursor.fetchone()
+            return self._result
+            if not self._result:
+                raise NoDataFound()
+        except Exception as err:
+            error = f"Error on Query: {err}"
+            raise DriverError(message=error) from err
+
+    fetchone = fetch_one
+    fetchrow = fetch_one
+
+    async def execute(self, sentence: Any, **kwargs) -> Optional[Any]:
+        """Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        error = None
+        result = None
+        if kwargs:
+            params = kwargs
+        else:
+            params = None
+        await self.valid_operation(sentence)
+        try:
+            if result := self._connection.execute(sentence, parameters=params):
+                self._connection.commit()
+        except Exception as err:
+            error = f"Error on Execute: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            return (result, error)
+
+    async def execute_many(self, sentence: Union[str, list], *args) -> Optional[Any]:
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            result = self._connection.executemany(sentence, parameters=args)
+            if result:
+                self._connection.commit()
+        except Exception as err:
+            error = f"Error on Execute Many: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            return (result, error)
+
+    executemany = execute_many
+
+    async def __aenter__(self) -> Any:
+        try:
+            await self.connection()
+        except Exception as err:
+            error = f"Error on Cursor Fetch: {err}"
+            raise DriverError(message=error) from err
+        return self
+
+    async def fetch(self, sentence: str, parameters: Iterable[Any] = None) -> Iterable:
+        """Helper to create a cursor and execute the given query."""
+        await self.valid_operation(sentence)
+        if parameters is None:
+            parameters = []
+        try:
+            result = self._connection.execute(sentence, parameters=parameters)
+        except Exception as err:
+            error = f"Error on Cursor Fetch: {err}"
+            raise DriverError(message=error) from err
+        return result
+
+    async def __anext__(self) -> Optional[Any]:
+        """_summary_
+
+        Raises:
+            StopAsyncIteration: raised when end is reached.
+
+        Returns:
+            _type_: Single record for iteration.
+        """
+        data = self._cursor.fetchone()
+        if data is not None:
+            return data
+        else:
+            raise StopAsyncIteration
+
+    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
+        """
+        Create is a generic method for Database Objects Creation.
+        """
+        if obj == "table":
+            sql = "CREATE TABLE {name} ({columns});"
+            columns = ", ".join(["{name} {type}".format(**e) for e in fields])
+            sql = sql.format(name=name, columns=columns)
+            try:
+                result = self._connection.execute(sql)
+                if result:
+                    self._connection.commit()
+                    return True
+                else:
+                    return False
+            except Exception as err:
+                raise DriverError(f"Error in Object Creation: {err!s}") from err
+        else:
+            raise RuntimeError(f"DuckDB: invalid Object type {object!s}")
```

## asyncdb/drivers/cassandra.py

```diff
@@ -1,450 +1,446 @@
-#!/usr/bin/env python3
-"""Cassandra.
-
-Cassandra Driver for asyncDB.
-
-TODO: migrate to Asyncio version (when available).
-"""
-import time
-import logging
-import asyncio
-from typing import Any, Union
-from ssl import PROTOCOL_TLSv1
-import pandas as pd
-from cassandra import ReadTimeout
-from cassandra.cluster import Cluster, EXEC_PROFILE_DEFAULT, ExecutionProfile, NoHostAvailable, ResultSet
-from cassandra.io.asyncorereactor import AsyncoreConnection
-from cassandra.io.asyncioreactor import AsyncioConnection
-
-try:
-    from cassandra.io.libevreactor import LibevConnection
-
-    LIBEV = True
-except ImportError:
-    LIBEV = False
-
-from cassandra.auth import PlainTextAuthProvider
-from cassandra.policies import (
-    DCAwareRoundRobinPolicy,
-    WhiteListRoundRobinPolicy,
-    DowngradingConsistencyRetryPolicy,
-    # RetryPolicy
-)
-from cassandra.query import (
-    dict_factory,
-    ordered_dict_factory,
-    named_tuple_factory,
-    ConsistencyLevel,
-    PreparedStatement,
-    BatchStatement,
-    SimpleStatement,
-    BatchType,
-)
-from asyncdb.meta import Recordset
-from asyncdb.exceptions import NoDataFound, DriverError
-from .abstract import InitDriver
-
-
-def pandas_factory(colnames, rows):
-    df = pd.DataFrame(rows, columns=colnames)
-    return df
-
-
-def record_factory(colnames, rows):
-    return Recordset(result=[dict(zip(colnames, values)) for values in rows], columns=colnames)
-
-
-class cassandra(InitDriver):
-    _provider = "cassandra"
-    _syntax = "cql"
-
-    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
-        self.hosts: list = []
-        self._test_query = "SELECT release_version FROM system.local"
-        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
-        self._cluster = None
-        self._timeout: int = 120
-        super(cassandra, self).__init__(loop=loop, params=params, **kwargs)
-        try:
-            if "host" in self.params:
-                self._hosts = self.params["host"].split(",")
-        except KeyError:
-            self._hosts = ["127.0.0.1"]
-        try:
-            self.whitelist = kwargs["whitelist"]
-        except KeyError:
-            self.whitelist = None
-        try:
-            self._auth = {
-                "username": self.params["username"],
-                "password": self.params["password"],
-            }
-        except KeyError:
-            self._auth = None
-
-    async def close(self, timeout: int = 10):
-        """close.
-        Closing a Connection
-        """
-        try:
-            # gracefully closing underlying connection
-            if self._connection:
-                self._logger.debug("Closing Connection")
-                try:
-                    self._connection.shutdown()
-                except Exception as err:
-                    self._cluster.shutdown()
-                    self._connection = None
-                    raise DriverError(message=f"Connection Error, Terminated: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Close Error: {err}") from err
-        finally:
-            self._connection = None
-            self._connected = False
-
-    async def connection(self, keyspace=None):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        self._cluster = None
-        try:
-            try:
-                if self.params["ssl"] is not None:
-                    ssl_opts = {
-                        "ca_certs": self.params["ssl"]["certfile"],
-                        "ssl_version": PROTOCOL_TLSv1,
-                        "keyfile": self.params["ssl"]["userkey"],
-                        "certfile": self.params["ssl"]["usercert"],
-                    }
-            except KeyError:
-                ssl_opts = {}
-            if self.whitelist:
-                policy = WhiteListRoundRobinPolicy(self.whitelist)
-            else:
-                policy = DCAwareRoundRobinPolicy()
-            defaultprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=dict_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            pandasprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=pandas_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            tupleprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=named_tuple_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            orderedprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=ordered_dict_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            recordprofile = ExecutionProfile(
-                load_balancing_policy=policy,
-                retry_policy=DowngradingConsistencyRetryPolicy(),
-                request_timeout=self._timeout,
-                row_factory=record_factory,
-                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
-                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
-            )
-            profiles = {
-                EXEC_PROFILE_DEFAULT: defaultprofile,
-                "pandas": pandasprofile,
-                "ordered": orderedprofile,
-                "default": tupleprofile,
-                "recordset": recordprofile,
-            }
-            params = {
-                "port": self.params["port"],
-                "compression": True,
-                "connection_class": AsyncoreConnection,
-                "protocol_version": 4,
-                "connect_timeout": 60,
-                "idle_heartbeat_interval": 0,
-                "ssl_options": ssl_opts,
-            }
-            if LIBEV is True:
-                params["connection_class"] = LibevConnection
-            auth_provider = None
-            if self._auth:
-                auth_provider = PlainTextAuthProvider(**self._auth)
-            self._cluster = Cluster(
-                self._hosts,
-                auth_provider=auth_provider,
-                execution_profiles=profiles,
-                **params,
-            )
-            print(self._cluster)
-            try:
-                self._connection = self._cluster.connect(keyspace=keyspace)
-            except NoHostAvailable as ex:
-                raise DriverError(message=f"Not able to connect to any of the Cassandra contact points: {ex}") from ex
-            if self._connection:
-                self._connected = True
-                self._initialized_on = time.time()
-            if "database" in self.params:
-                await self.use(self.params["database"])
-            else:
-                self._keyspace = keyspace
-            return self
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.exception(f"connection Error, Terminated: {err}")
-            self._connection = None
-            self._cursor = None
-            raise DriverError(message=f"connection Error, Terminated: {err}") from err
-
-    async def test_connection(self):  # pylint: disable=W0221
-        result = None
-        error = None
-        try:
-            response = self._connection.execute(self._test_query)
-            result = [row for row in response]
-        except Exception as err:  # pylint: disable=W0703
-            error = err
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    async def use(self, database: str):
-        try:
-            self._connection.set_keyspace(database)
-            self._keyspace = database
-        except Exception as err:
-            logging.exception(err)
-            raise
-        return self
-
-    ### Preparing a sentence
-    def prepared_statement(self):
-        return self._prepared
-
-    def prepared_smt(self):
-        return self._prepared
-
-    async def prepare(self, sentence: str, consistency: str = "quorum"):
-        await self.valid_operation(sentence)
-        try:
-            self._prepared = self._connection.prepare(sentence)
-            if consistency == "quorum":
-                self._prepared.consistency_level = ConsistencyLevel.QUORUM
-            else:
-                self._prepared.consistency_level = ConsistencyLevel.ALL
-            return self._prepared
-        except RuntimeError as ex:
-            raise DriverError(message=f"Runtime Error: {ex}") from ex
-        except Exception as ex:
-            raise DriverError(f"Error on Query: {ex}") from ex
-
-    def create_query(self, sentence: str, consistency: str = "quorum"):
-        if consistency == "quorum":
-            cl = ConsistencyLevel.QUORUM
-        else:
-            cl = ConsistencyLevel.ALL
-        return SimpleStatement(sentence, consistency_level=cl)
-
-    async def query(
-        self,
-        sentence: Union[str, SimpleStatement, PreparedStatement],
-        params: list = None,
-        factory: str = EXEC_PROFILE_DEFAULT,
-        **kwargs,
-    ) -> Union[ResultSet, None]:
-        error = None
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            self.start_timing()
-            if isinstance(sentence, PreparedStatement):
-                smt = sentence
-            elif isinstance(sentence, SimpleStatement):
-                smt = sentence
-            else:
-                smt = self._connection.prepare(sentence)
-            self._connection.fetch_size = None
-            fut = self._connection.execute_async(smt, params, execution_profile=factory)
-            try:
-                self._result = fut.result()
-                if factory in ("pandas", "record", "recordset"):
-                    self._result.result = self._result._current_rows
-            except ReadTimeout:
-                error = f"Timeout reading Data from {sentence}"
-            if not self._result:
-                raise NoDataFound("Cassandra: No Data was Found")
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def fetch_all(
-        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None, **kwargs
-    ) -> ResultSet:
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            self.start_timing()
-            self._result = self._connection.execute(sentence, params)
-            if not self._result:
-                raise NoDataFound("Cassandra: No Data was Found")
-            self.generated_at()
-            return self._result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(message=f"Runtime Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Query: {err}") from err
-
-    async def fetch(self, sentence, params: list = None):
-        if not params:
-            params = []
-        return self.fetch_all(sentence, params)
-
-    async def queryrow(self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None):
-        error = None
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            self._result = self._connection.execute(sentence, params).one()
-            if not self._result:
-                raise NoDataFound("Cassandra: No Data was Found")
-        except RuntimeError as err:
-            error = f"Runtime on Query Row Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query Row: {err}"
-        return [self._result, error]  # pylint: disable=W0150
-
-    async def fetch_one(  # pylint: disable=W0221
-        self,
-        sentence: Union[str, SimpleStatement, PreparedStatement],
-        params: list = None,
-    ) -> ResultSet:
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            self._result = self._connection.execute(sentence, params).one()
-            if not self._result:
-                raise NoDataFound("Cassandra: No Data was Found")
-        except RuntimeError as err:
-            raise DriverError(message=f"Runtime on Query Row Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Query Row: {err}") from err
-        return self._result
-
-    async def fetchrow(self, sentence, params: list = None):
-        if not params:
-            params = []
-        return self.fetch_one(sentence=sentence, params=params)
-
-    async def execute(  # pylint: disable=W0221
-        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None, **kwargs
-    ) -> Any:
-        """Execute a transaction
-        get a CQL sentence and execute
-        returns: results of the execution
-        """
-        error = None
-        self._result = None
-        try:
-            await self.valid_operation(sentence)
-            if isinstance(sentence, PreparedStatement):
-                smt = sentence
-            elif isinstance(sentence, SimpleStatement):
-                smt = sentence
-            else:
-                smt = self._connection.prepare(sentence)
-            fut = self._connection.execute_async(smt, params)
-            try:
-                self._result = fut.result()
-            except ReadTimeout:
-                error = "Timeout executing sentences"
-            if not self._result:
-                error = NoDataFound("Cassandra: No Data was Found")
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Execute: {err}"
-        finally:
-            return [self._result, error]  # pylint: disable=W0150
-
-    async def execute_many(  # pylint: disable=W0221
-        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None
-    ) -> Any:
-        """execute_many.
-
-        Execute a transaction many times using Batch prepared statements.
-
-        Args:
-            sentence (str): a parametrized CQL sentence.
-            params (List, optional): List of dicts with parameters.
-
-        Returns:
-            Any: Resultset of execution.
-        """
-        result = None
-        error = None
-        try:
-            await self.valid_operation(sentence)
-            batch = BatchStatement(batch_type=BatchType.UNLOGGED)
-            for p in params:
-                args = ()
-                if isinstance(p, dict):
-                    args = tuple(p.values())
-                else:
-                    args = tuple(p)
-                if isinstance(sentence, PreparedStatement):
-                    smt = sentence
-                else:
-                    smt = SimpleStatement(sentence)
-                batch.add(smt, p)
-            fut = self._connection.execute_async(batch)
-            result = fut.result()
-        except ReadTimeout:
-            error = "Timeout executing sentences"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Execute: {err}"
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    ### Model Logic:
-    async def column_info(self, table: str, schema: str = None):
-        """Column Info.
-
-        Get Meta information about a table (column name, data type and PK).
-        Useful to build a DataModel from Querying database.
-        Parameters:
-        @tablename: str The name of the table (including schema).
-        """
-        if not schema:
-            schema = self._keyspace
-        cql = f"select column_name as name, type, type as format_type, \
-            kind from system_schema.columns where \
-                keyspace_name = '{schema}' and table_name = '{table}';"
-        if not self._connection:
-            await self.connection()
-        try:
-            colinfo = self._connection.execute(cql)
-            return [d for d in colinfo]
-        except Exception as err:
-            self._logger.exception(f"Wrong Table information {table!s}: {err}")
-            raise DriverError(f"Wrong Table information {table!s}: {err}") from err
+#!/usr/bin/env python3
+"""Cassandra.
+
+Cassandra Driver for asyncDB.
+
+TODO: migrate to Asyncio version (when available).
+"""
+import time
+import logging
+import asyncio
+from typing import Any, Union
+from ssl import PROTOCOL_TLSv1
+import pandas as pd
+from cassandra import ReadTimeout
+from cassandra.cluster import (
+    Cluster,
+    EXEC_PROFILE_DEFAULT,
+    ExecutionProfile,
+    NoHostAvailable,
+    ResultSet
+)
+from cassandra.io.asyncorereactor import AsyncoreConnection
+from cassandra.io.asyncioreactor import AsyncioConnection
+
+from cassandra.auth import PlainTextAuthProvider
+from cassandra.policies import (
+    DCAwareRoundRobinPolicy,
+    WhiteListRoundRobinPolicy,
+    DowngradingConsistencyRetryPolicy,
+    # RetryPolicy
+)
+from cassandra.query import (
+    dict_factory,
+    ordered_dict_factory,
+    named_tuple_factory,
+    ConsistencyLevel,
+    PreparedStatement,
+    BatchStatement,
+    SimpleStatement,
+    BatchType,
+)
+from asyncdb.meta import Recordset
+from asyncdb.exceptions import NoDataFound, DriverError
+from .abstract import InitDriver
+
+
+def pandas_factory(colnames, rows):
+    df = pd.DataFrame(rows, columns=colnames)
+    return df
+
+
+def record_factory(colnames, rows):
+    return Recordset(result=[dict(zip(colnames, values)) for values in rows], columns=colnames)
+
+
+class cassandra(InitDriver):
+    _provider = "cassandra"
+    _syntax = "cql"
+
+    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
+        self.hosts: list = []
+        self._test_query = "SELECT release_version FROM system.local"
+        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
+        self._cluster = None
+        self._timeout: int = 120
+        super(cassandra, self).__init__(loop=loop, params=params, **kwargs)
+        try:
+            if "host" in self.params:
+                self._hosts = self.params["host"].split(",")
+        except KeyError:
+            self._hosts = ["127.0.0.1"]
+        try:
+            self.whitelist = kwargs["whitelist"]
+        except KeyError:
+            self.whitelist = None
+        try:
+            self._auth = {
+                "username": self.params["username"],
+                "password": self.params["password"],
+            }
+        except KeyError:
+            self._auth = None
+
+    async def close(self, timeout: int = 10):
+        """close.
+        Closing a Connection
+        """
+        try:
+            # gracefully closing underlying connection
+            if self._connection:
+                try:
+                    self._connection.shutdown()
+                except Exception as err:
+                    self._cluster.shutdown()
+                    self._connection = None
+                    raise DriverError(message=f"Connection Error, Terminated: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Close Error: {err}") from err
+        finally:
+            self._connection = None
+            self._connected = False
+
+    async def connection(self, keyspace=None):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        self._cluster = None
+        try:
+            try:
+                if self.params["ssl"] is not None:
+                    ssl_opts = {
+                        "ca_certs": self.params["ssl"]["certfile"],
+                        "ssl_version": PROTOCOL_TLSv1,
+                        "keyfile": self.params["ssl"]["userkey"],
+                        "certfile": self.params["ssl"]["usercert"],
+                    }
+            except KeyError:
+                ssl_opts = {}
+            if self.whitelist:
+                policy = WhiteListRoundRobinPolicy(self.whitelist)
+            else:
+                policy = DCAwareRoundRobinPolicy()
+            defaultprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=dict_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            pandasprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=pandas_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            tupleprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=named_tuple_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            orderedprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=ordered_dict_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            recordprofile = ExecutionProfile(
+                load_balancing_policy=policy,
+                retry_policy=DowngradingConsistencyRetryPolicy(),
+                request_timeout=self._timeout,
+                row_factory=record_factory,
+                consistency_level=ConsistencyLevel.LOCAL_QUORUM,
+                serial_consistency_level=ConsistencyLevel.LOCAL_SERIAL,
+            )
+            profiles = {
+                EXEC_PROFILE_DEFAULT: defaultprofile,
+                "pandas": pandasprofile,
+                "ordered": orderedprofile,
+                "default": tupleprofile,
+                "recordset": recordprofile,
+            }
+            params = {
+                "port": self.params["port"],
+                "compression": True,
+                "connection_class": AsyncoreConnection,
+                "protocol_version": 4,
+                "connect_timeout": 60,
+                "idle_heartbeat_interval": 0,
+                "ssl_options": ssl_opts,
+            }
+            auth_provider = None
+            if self._auth:
+                auth_provider = PlainTextAuthProvider(**self._auth)
+            self._cluster = Cluster(
+                self._hosts,
+                auth_provider=auth_provider,
+                execution_profiles=profiles,
+                **params,
+            )
+            print(self._cluster)
+            try:
+                self._connection = self._cluster.connect(keyspace=keyspace)
+            except NoHostAvailable as ex:
+                raise DriverError(message=f"Not able to connect to any of the Cassandra contact points: {ex}") from ex
+            if self._connection:
+                self._connected = True
+                self._initialized_on = time.time()
+            if "database" in self.params:
+                await self.use(self.params["database"])
+            else:
+                self._keyspace = keyspace
+            return self
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.exception(f"connection Error, Terminated: {err}")
+            self._connection = None
+            self._cursor = None
+            raise DriverError(message=f"connection Error, Terminated: {err}") from err
+
+    async def test_connection(self):  # pylint: disable=W0221
+        result = None
+        error = None
+        try:
+            response = self._connection.execute(self._test_query)
+            result = [row for row in response]
+        except Exception as err:  # pylint: disable=W0703
+            error = err
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    async def use(self, database: str):
+        try:
+            self._connection.set_keyspace(database)
+            self._keyspace = database
+        except Exception as err:
+            logging.exception(err)
+            raise
+        return self
+
+    ### Preparing a sentence
+    def prepared_statement(self):
+        return self._prepared
+
+    def prepared_smt(self):
+        return self._prepared
+
+    async def prepare(self, sentence: str, consistency: str = "quorum"):
+        await self.valid_operation(sentence)
+        try:
+            self._prepared = self._connection.prepare(sentence)
+            if consistency == "quorum":
+                self._prepared.consistency_level = ConsistencyLevel.QUORUM
+            else:
+                self._prepared.consistency_level = ConsistencyLevel.ALL
+            return self._prepared
+        except RuntimeError as ex:
+            raise DriverError(message=f"Runtime Error: {ex}") from ex
+        except Exception as ex:
+            raise DriverError(f"Error on Query: {ex}") from ex
+
+    def create_query(self, sentence: str, consistency: str = "quorum"):
+        if consistency == "quorum":
+            cl = ConsistencyLevel.QUORUM
+        else:
+            cl = ConsistencyLevel.ALL
+        return SimpleStatement(sentence, consistency_level=cl)
+
+    async def query(
+        self,
+        sentence: Union[str, SimpleStatement, PreparedStatement],
+        params: list = None,
+        factory: str = EXEC_PROFILE_DEFAULT,
+        **kwargs,
+    ) -> Union[ResultSet, None]:
+        error = None
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            self.start_timing()
+            if isinstance(sentence, PreparedStatement):
+                smt = sentence
+            elif isinstance(sentence, SimpleStatement):
+                smt = sentence
+            else:
+                smt = self._connection.prepare(sentence)
+            self._connection.fetch_size = None
+            fut = self._connection.execute_async(smt, params, execution_profile=factory)
+            try:
+                self._result = fut.result()
+                if factory in ("pandas", "record", "recordset"):
+                    self._result.result = self._result._current_rows
+            except ReadTimeout:
+                error = f"Timeout reading Data from {sentence}"
+            if not self._result:
+                raise NoDataFound("Cassandra: No Data was Found")
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def fetch_all(
+        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None, **kwargs
+    ) -> ResultSet:
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            self.start_timing()
+            self._result = self._connection.execute(sentence, params)
+            if not self._result:
+                raise NoDataFound("Cassandra: No Data was Found")
+            self.generated_at()
+            return self._result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(message=f"Runtime Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Query: {err}") from err
+
+    async def fetch(self, sentence, params: list = None):
+        if not params:
+            params = []
+        return self.fetch_all(sentence, params)
+
+    async def queryrow(self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None):
+        error = None
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            self._result = self._connection.execute(sentence, params).one()
+            if not self._result:
+                raise NoDataFound("Cassandra: No Data was Found")
+        except RuntimeError as err:
+            error = f"Runtime on Query Row Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query Row: {err}"
+        return [self._result, error]  # pylint: disable=W0150
+
+    async def fetch_one(  # pylint: disable=W0221
+        self,
+        sentence: Union[str, SimpleStatement, PreparedStatement],
+        params: list = None,
+    ) -> ResultSet:
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            self._result = self._connection.execute(sentence, params).one()
+            if not self._result:
+                raise NoDataFound("Cassandra: No Data was Found")
+        except RuntimeError as err:
+            raise DriverError(message=f"Runtime on Query Row Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Query Row: {err}") from err
+        return self._result
+
+    async def fetchrow(self, sentence, params: list = None):
+        if not params:
+            params = []
+        return self.fetch_one(sentence=sentence, params=params)
+
+    async def execute(  # pylint: disable=W0221
+        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None, **kwargs
+    ) -> Any:
+        """Execute a transaction
+        get a CQL sentence and execute
+        returns: results of the execution
+        """
+        error = None
+        self._result = None
+        try:
+            await self.valid_operation(sentence)
+            if isinstance(sentence, PreparedStatement):
+                smt = sentence
+            elif isinstance(sentence, SimpleStatement):
+                smt = sentence
+            else:
+                smt = self._connection.prepare(sentence)
+            fut = self._connection.execute_async(smt, params)
+            try:
+                self._result = fut.result()
+            except ReadTimeout:
+                error = "Timeout executing sentences"
+            if not self._result:
+                error = NoDataFound("Cassandra: No Data was Found")
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Execute: {err}"
+        finally:
+            return [self._result, error]  # pylint: disable=W0150
+
+    async def execute_many(  # pylint: disable=W0221
+        self, sentence: Union[str, SimpleStatement, PreparedStatement], params: list = None
+    ) -> Any:
+        """execute_many.
+
+        Execute a transaction many times using Batch prepared statements.
+
+        Args:
+            sentence (str): a parametrized CQL sentence.
+            params (List, optional): List of dicts with parameters.
+
+        Returns:
+            Any: Resultset of execution.
+        """
+        result = None
+        error = None
+        try:
+            await self.valid_operation(sentence)
+            batch = BatchStatement(batch_type=BatchType.UNLOGGED)
+            for p in params:
+                args = ()
+                if isinstance(p, dict):
+                    args = tuple(p.values())
+                else:
+                    args = tuple(p)
+                if isinstance(sentence, PreparedStatement):
+                    smt = sentence
+                else:
+                    smt = SimpleStatement(sentence)
+                batch.add(smt, p)
+            fut = self._connection.execute_async(batch)
+            result = fut.result()
+        except ReadTimeout:
+            error = "Timeout executing sentences"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Execute: {err}"
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    ### Model Logic:
+    async def column_info(self, table: str, schema: str = None):
+        """Column Info.
+
+        Get Meta information about a table (column name, data type and PK).
+        Useful to build a DataModel from Querying database.
+        Parameters:
+        @tablename: str The name of the table (including schema).
+        """
+        if not schema:
+            schema = self._keyspace
+        cql = f"select column_name as name, type, type as format_type, \
+            kind from system_schema.columns where \
+                keyspace_name = '{schema}' and table_name = '{table}';"
+        if not self._connection:
+            await self.connection()
+        try:
+            colinfo = self._connection.execute(cql)
+            return [d for d in colinfo]
+        except Exception as err:
+            self._logger.exception(f"Wrong Table information {table!s}: {err}")
+            raise DriverError(f"Wrong Table information {table!s}: {err}") from err
```

## asyncdb/drivers/pg.py

```diff
@@ -1,1511 +1,1515 @@
-""" pg PostgreSQL Provider.
-Notes on pg Provider
---------------------
-This provider implements basic funcionalities from asyncpg
-(cursors, transactions, copy from and to files, pools, native data types, etc).
-"""
-import asyncio
-import os
-import ssl
-import time
-import uuid
-from collections.abc import Callable, Iterable
-from typing import Any, Optional, Union
-from dataclasses import is_dataclass
-from datamodel import BaseModel
-import asyncpg
-from asyncpg.exceptions import (
-    ConnectionDoesNotExistError,
-    DuplicateTableError,
-    FatalPostgresError,
-    InterfaceError,
-    InterfaceWarning,
-    InternalClientError,
-    InvalidSQLStatementNameError,
-    PostgresError,
-    PostgresSyntaxError,
-    TooManyConnectionsError,
-    UndefinedColumnError,
-    UndefinedTableError,
-    UniqueViolationError,
-)
-from asyncpg.pgproto import pgproto
-
-from asyncdb.exceptions import (
-    ConnectionTimeout,
-    DriverError,
-    EmptyStatement,
-    ProviderError,
-    StatementError,
-    TooManyConnections,
-    UninitializedError,
-)
-from asyncdb.interfaces import DBCursorBackend, ModelBackend
-from asyncdb.models import Model
-from asyncdb.utils.encoders import DefaultEncoder
-from asyncdb.utils.types import Entity
-
-from .abstract import BasePool
-from .sql import SQLCursor, SQLDriver
-
-max_cached_statement_lifetime = 600
-max_cacheable_statement_size = 1024 * 15
-
-
-class NAVConnection(asyncpg.Connection):
-    def _get_reset_query(self):
-        return None
-
-
-class pgPool(BasePool):
-    _setup_func: Optional[Callable] = None
-    _init_func: Optional[Callable] = None
-
-    def __init__(
-        self, dsn: str = None, loop: asyncio.AbstractEventLoop = None, params: Optional[dict] = None, **kwargs
-    ):
-        self._test_query = "SELECT 1"
-        self.application_name = os.getenv("APP_NAME", "NAV")
-        self._max_clients = 300
-        self._min_size = 10
-        self._server_settings = {}
-        self._dsn = "postgres://{user}:{password}@{host}:{port}/{database}"
-        super(pgPool, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-        try:
-            self._max_inactive_timeout = kwargs["max_inactive_timeout"]
-        except KeyError:
-            self._max_inactive_timeout = 36000
-        if "server_settings" in kwargs:
-            self._server_settings = kwargs["server_settings"]
-        if "application_name" in self._server_settings:
-            self.application_name = self._server_settings["application_name"]
-        if "max_clients" in kwargs:
-            self._max_clients = kwargs["max_clients"]
-        if "min_size" in kwargs:
-            self._min_size = kwargs["min_size"]
-        if "numeric_as_float" in kwargs:
-            self._numeric_as_float = kwargs["numeric_as_float"]
-        # Connection Configuration:
-        try:
-            self._connection_config = params.pop("connection_config", {})
-        except AttributeError:
-            self._connection_config = {}
-        # set the JSON encoder:
-        self._encoder = DefaultEncoder()
-        ### SSL Support:
-        self.ssl: bool = False
-        if params and "ssl" in params:
-            ssloptions = params["ssl"]
-        elif "ssl" in kwargs:
-            ssloptions = kwargs["ssl"]
-        else:
-            ssloptions = None
-        if ssloptions:
-            self.ssl: bool = True
-            try:
-                check_hostname = ssloptions["check_hostname"]
-            except KeyError:
-                check_hostname = False
-            ### certificate Support:
-            try:
-                ca_file = ssloptions["cafile"]
-            except KeyError:
-                ca_file = None
-            args = {"cafile": ca_file}
-            self.sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, **args)
-            # Certificate Chain:
-            try:
-                certs = {"certfile": ssloptions["certfile"], "keyfile": ssloptions["keyfile"]}
-            except KeyError:
-                certs = {"certfile": None, "keyfile": None}
-            if certs["certfile"]:
-                self.sslctx.load_cert_chain(**certs)
-            self.sslctx.check_hostname = check_hostname
-
-    async def setup_connection(self, connection):
-        if self._setup_func:
-            try:
-                await self.setup_func(connection)
-            except (ValueError, RuntimeError) as err:
-                self._logger.error(f"Error on Setup Function: {err}")
-
-    async def test_connection(self, *args):
-        """Test Connnection.
-        Making a connection Test using the basic Query Method.
-        """
-        result = None
-        error = None
-        if self._test_query is None:
-            return [None, NotImplementedError()]
-        try:
-            result = await self.execute(self._test_query, *args)
-        except ProviderError as err:
-            error = err
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    async def init_connection(self, connection):
-        # Setup jsonb encoder/decoder
-        def _encoder(value):
-            # return json.dumps(value, cls=BaseEncoder)
-            return self._encoder.dumps(value)  # pylint: disable=E1120
-
-        def _decoder(value):
-            return self._encoder.loads(value)  # pylint: disable=E1120
-
-        await connection.set_type_codec("json", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
-        await connection.set_type_codec("jsonb", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
-        await connection.set_builtin_type_codec("hstore", codec_name="pg_contrib.hstore")
-
-        def _uuid_encoder(value):
-            if isinstance(value, uuid.UUID):
-                val = value.bytes
-            elif value is not None:
-                val = uuid.UUID(value).bytes
-            else:
-                val = b""
-            return val
-
-        await connection.set_type_codec(
-            "uuid",
-            encoder=_uuid_encoder,
-            decoder=lambda u: pgproto.UUID(u),  # pylint: disable=I1101,W0108
-            schema="pg_catalog",
-            format="binary",
-        )
-        if self._connection_config and isinstance(self._connection_config, dict):
-            for key, value in self._connection_config.items():
-                config = f"SELECT set_config('{key}', '{value}', false);"
-                try:
-                    r = await connection.execute(config)
-                    self._logger.debug(f"{r} - Config {key} = {value}")
-                except RuntimeError as err:
-                    self._logger.warning(f"Pg: Error on Connection Configuration: {err}")
-        if self._init_func is not None and callable(self._init_func):
-            try:
-                await self._init_func(connection)  # pylint: disable=E1102
-            except (ValueError, RuntimeError) as err:
-                self._logger.warning(f"Error on Init Connection: {err}")
-
-    # Create a database connection pool
-    async def connect(self):
-        """
-        Creates a Pool Connection.
-        """
-        self._logger.debug(f"AsyncPg (Pool): Connecting to {self._dsn}")
-        try:
-            # TODO: pass a setup class for set_builtin_type_codec and a setup for add listener
-            server_settings = {
-                "application_name": self.application_name,
-                "idle_in_transaction_session_timeout": "60min",
-                "idle_session_timeout": "60min",
-                "statement_timeout": "60min",
-                "tcp_keepalives_idle": "30min",
-            }
-            server_settings = {**server_settings, **self._server_settings}
-            if self.ssl:
-                _ssl = {"ssl": self.sslctx}
-            else:
-                _ssl = {}
-            self._pool = await asyncpg.create_pool(
-                dsn=self._dsn,
-                max_queries=self._max_queries,
-                min_size=self._min_size,
-                max_size=self._max_clients,
-                max_inactive_connection_lifetime=self._max_inactive_timeout,
-                statement_cache_size=36000,
-                timeout=self._timeout,
-                # command_timeout=self._timeout,
-                init=self.init_connection,
-                setup=self.setup_connection,
-                loop=self._loop,
-                server_settings=server_settings,
-                connection_class=NAVConnection,
-                **_ssl,
-            )
-            # is connected
-            if self._pool:
-                self._connected = True
-                self._initialized_on = time.time()
-            return self
-        except ConnectionRefusedError as err:
-            raise UninitializedError(f"Unable to connect to database, connection Refused: {err}") from err
-        except ConnectionError as ex:
-            self._logger.error(f"Connection Error: {ex}")
-            raise UninitializedError(f"Connection Error: {ex}") from ex
-        except TooManyConnectionsError as err:
-            self._logger.error(f"Too Many Connections Error: {err}")
-            raise UninitializedError(f"Too Many Connections Error: {err}") from err
-        except TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to database: {err}") from err
-        except ConnectionDoesNotExistError as err:
-            raise ProviderError(f"Connection Error: {err}") from err
-        except InternalClientError as err:
-            raise ProviderError(f"Internal Error: {err}") from err
-        except InterfaceError as err:
-            raise ProviderError(f"Interface Error: {err}") from err
-        except InterfaceWarning as err:
-            self._logger.warning(f"Interface Warning: {err}")
-            return False
-        except Exception as ex:
-            self._logger.exception(f"Asyncpg Unknown Error: {ex}", stack_info=True)
-            raise DriverError(f"Asyncpg Unknown Error: {ex}") from ex
-
-    async def acquire(self):
-        """
-        Takes a connection from the pool.
-        """
-        db = None
-        self._connection = None
-        # Take a connection from the pool.
-        try:
-            self._connection = await self._pool.acquire()
-        except TooManyConnectionsError as err:
-            self._logger.error(f"Too Many Connections Error: {err}")
-            raise TooManyConnections(f"Too Many Connections Error: {err}") from err
-        except TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to database: {err}") from err
-        except ConnectionRefusedError as err:
-            raise UninitializedError(f"Unable to connect to database, connection Refused: {err}") from err
-        except ConnectionDoesNotExistError as err:
-            raise ProviderError(f"Connection Error: {err}") from err
-        except InternalClientError as err:
-            raise ProviderError(f"Internal Error: {err}") from err
-        except InterfaceError as err:
-            raise ProviderError(f"Interface Error: {err}") from err
-        except InterfaceWarning as err:
-            self._logger.warning(f"Interface Warning: {err}")
-        except Exception as err:  # pylint: disable=W0703
-            self._logger.error(f"Unknown Error on Acquire: {err}")
-        if self._connection:
-            db = pg(pool=self)
-            db.set_connection(self._connection)
-        return db
-
-    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
-        # clean up anything you need to clean up
-        return await self.release(connection=self._connection, timeout=5)
-
-    async def release(self, connection=None, timeout=5):
-        """
-        Release a connection from the pool
-        """
-        if not connection:
-            conn = self._connection
-        else:
-            conn = connection
-        if isinstance(conn, pg):
-            conn = connection.engine()
-        if not conn:
-            return True
-        try:
-            await self._pool.release(conn, timeout=timeout)
-            return True
-        except InterfaceError as err:
-            raise ProviderError(message=f"Release Interface Error: {err}") from err
-        except InternalClientError as err:
-            self._logger.debug(
-                f"Connection already released, \
-                called on a free connection holder: {err}"
-            )
-            return False
-        except Exception as err:
-            raise ProviderError(message=f"Release Error: {err}") from err
-
-    async def wait_close(self, gracefully=True, timeout=5):
-        """
-        close
-            Close Pool Connection
-        """
-        if self._pool:
-            # try to closing main connection
-            try:
-                if self._connection:
-                    await self._pool.release(self._connection, timeout=timeout)
-                    self._connection = None
-            except (InternalClientError, InterfaceError) as err:
-                raise ProviderError(f"Release Interface Error: {err}") from err
-            except Exception as err:
-                raise ProviderError(f"Release Error: {err}") from err
-            try:
-                if gracefully:
-                    await asyncio.wait_for(self._pool.expire_connections(), timeout=timeout)
-                    await asyncio.wait_for(self._pool.close(), timeout=timeout)
-                # # until end, close the pool correctly:
-                self._pool.terminate()
-            except asyncio.TimeoutError as e:
-                self._logger.warning(f"Close timed out: {e}")
-            except Exception as err:
-                error = f"Pool Exception: {err.__class__.__name__}: {err}"
-                print(f"Pool Error: {error}")
-                raise ProviderError(f"Pool Error: {error}") from err
-            finally:
-                self._connected = False
-
-    async def close(self, **kwargs):
-        """
-        Close Pool
-        """
-        try:
-            if self._connection:
-                await self._pool.release(self._connection, timeout=1)
-                self._connection = None
-        except InterfaceError as err:
-            raise ProviderError(f"Release Interface Error: {err}") from err
-        except Exception as err:
-            raise ProviderError(f"Release Error: {err}") from err
-        try:
-            await self._pool.expire_connections()
-            await self._pool.close()
-        except Exception as err:
-            error = f"Pool Closing Error: {err.__class__.__name__}: {err}"
-            raise Exception(error) from err
-        finally:
-            self._pool.terminate()
-            self._connected = False
-
-    disconnect = close
-
-    async def execute(self, sentence, *args):
-        """
-        Execute a connection into the Pool
-        """
-        try:
-            return await self._pool.execute(sentence, *args)
-        except InterfaceError as err:
-            raise ProviderError(f"Execute Interface Error: {err}") from err
-        except Exception as err:
-            raise ProviderError(f"Execute Error: {err}") from err
-
-
-class pgCursor(SQLCursor):
-    _connection: asyncpg.Connection = None
-
-
-class pg(SQLDriver, DBCursorBackend, ModelBackend):
-    _provider = "pg"
-    _syntax = "sql"
-    _test_query = "SELECT 1"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._dsn = "postgres://{user}:{password}@{host}:{port}/{database}"
-        self.application_name = os.getenv("APP_NAME", "NAV")
-        self._prepared = None
-        self._cursor = None
-        self._transaction = None
-        self._server_settings = {}
-        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
-        DBCursorBackend.__init__(self)
-        if "pool" in kwargs:
-            self._pool = kwargs["pool"]
-            self._loop = self._pool.get_loop()
-        if "server_settings" in kwargs:
-            self._server_settings = kwargs["server_settings"]
-        if "application_name" in self._server_settings:
-            self.application_name = self._server_settings["application_name"]
-        if "numeric_as_float" in kwargs:
-            self._numeric_as_float = kwargs["numeric_as_float"]
-        else:
-            self._numeric_as_float = False
-        # set the JSON encoder:
-        self._encoder = DefaultEncoder()
-        # Connection Configuration:
-        try:
-            self._connection_config = params.pop("connection_config", {})
-        except AttributeError:
-            self._connection_config = {}
-        ### SSL Support:
-        self.ssl: bool = False
-        if params and "ssl" in params:
-            ssloptions = params["ssl"]
-        elif "ssl" in kwargs:
-            ssloptions = kwargs["ssl"]
-        else:
-            ssloptions = None
-        if ssloptions:
-            self.ssl: bool = True
-            try:
-                check_hostname = ssloptions["check_hostname"]
-            except KeyError:
-                check_hostname = False
-            ### certificate Support:
-            try:
-                ca_file = ssloptions["cafile"]
-            except KeyError:
-                ca_file = None
-            args = {"cafile": ca_file}
-            self.sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, **args)
-            # Certificate Chain:
-            try:
-                certs = {"certfile": ssloptions["certfile"], "keyfile": ssloptions["keyfile"]}
-            except KeyError:
-                certs = {"certfile": None, "keyfile": None}
-            if certs["certfile"]:
-                self.sslctx.load_cert_chain(**certs)
-            self.sslctx.check_hostname = check_hostname
-
-    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
-        # clean up anything you need to clean up
-        return await self.close()
-
-    async def close(self, timeout=5):
-        """
-        Closing a Connection.
-        """
-        if self._connection:
-            try:
-                if not self._connection.is_closed():
-                    self._logger.debug(f"Closing Connection, id: {self._connection.get_server_pid()}")
-                    if self._pool:
-                        await self._pool.release(self._connection)
-                    else:
-                        await self._connection.close(timeout=timeout)
-            except TypeError:
-                pass
-            except InterfaceError as err:
-                raise ProviderError(f"AsyncPg: Closing Error: {err}") from err
-            except Exception as err:
-                try:
-                    await self._connection.terminate()
-                    self._connection = None
-                    raise ProviderError(f"Connection Error, Terminated: {err}") from err
-                except TypeError:
-                    pass
-            finally:
-                self._connected = False
-                self._connection = None
-
-    disconnect = close
-
-    def terminate(self):
-        self._loop.run_until_complete(self.close())
-
-    async def is_in_transaction(self):
-        return self._connection.is_in_transaction()
-
-    def is_connected(self):
-        try:
-            if self._connection:
-                return not (self._connection.is_closed())
-        except (AttributeError, InterfaceError):
-            pass
-        return self._connected
-
-    async def connection(self):
-        """connection.
-
-        Get an asyncpg connection
-        """
-        if self._connection:
-            if not self._connection.is_closed():
-                self._connected = True
-                return self
-        self._connection = None
-        self._connected = False
-        # Setup jsonb encoder/decoder
-
-        def _encoder(value):
-            return self._encoder.dumps(value)  # pylint: disable=E1120
-
-        def _decoder(value):
-            return self._encoder.loads(value)  # pylint: disable=E1120
-
-        server_settings = {
-            "application_name": self.application_name,
-            "idle_session_timeout": "120min",
-            "tcp_keepalives_idle": "36000",
-            "max_parallel_workers": "512",
-        }
-        server_settings = {**server_settings, **self._server_settings}
-        if self.ssl:
-            _ssl = {"ssl": self.sslctx}
-        else:
-            _ssl = {}
-        try:
-            if self._pool and not self._connection:
-                self._connection = await self._pool.pool().acquire()
-            else:
-                self._connection = await asyncpg.connect(
-                    dsn=self._dsn,
-                    timeout=self._timeout,
-                    statement_cache_size=36000,
-                    server_settings=server_settings,
-                    connection_class=NAVConnection,
-                    loop=self._loop,
-                    **_ssl,
-                )
-                await self._connection.set_type_codec("json", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
-                await self._connection.set_type_codec("jsonb", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
-                await self._connection.set_builtin_type_codec("hstore", codec_name="pg_contrib.hstore")
-
-                def _uuid_encoder(value):
-                    if isinstance(value, uuid.UUID):
-                        val = value.bytes
-                    elif value is not None:
-                        val = uuid.UUID(bytes=value)
-                    else:
-                        val = b""
-                    return val
-
-                def _uuid_decoder(value):
-                    if value is None:
-                        return b""
-                    else:
-                        return uuid.UUID(bytes=value)
-
-                await self._connection.set_type_codec(
-                    "uuid",
-                    encoder=_uuid_encoder,
-                    decoder=_uuid_decoder,
-                    schema="pg_catalog",
-                    format="binary",
-                )
-            if self._connection:
-                self._connected = True
-                if self._connection_config and isinstance(self._connection_config, dict):
-                    for key, value in self._connection_config.items():
-                        config = f"SELECT set_config('{key}', '{value}', false);"
-                        try:
-                            r = await self._connection.execute(config)
-                        except RuntimeError as err:
-                            self._logger.warning(f"Pg: Error on Connection Configuration: {err}")
-                if self._init_func is not None and callable(self._init_func):
-                    try:
-                        await self._init_func(self._connection)  # pylint: disable=E1102
-                    except (ValueError, RuntimeError) as err:
-                        self._logger.warning(f"Error on Init Connection: {err}")
-                self._initialized_on = time.time()
-                self._logger.debug(f"Initialized on: {self._initialized_on}")
-            return self
-        except ConnectionRefusedError as err:
-            raise UninitializedError(f"Unable to connect to database, connection Refused: {err}") from err
-        except TooManyConnectionsError as err:
-            self._logger.error(f"Too Many Connections Error: {err}")
-            raise TooManyConnections(f"Too Many Connections Error: {err}") from err
-        except TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to database: {err}") from err
-        except ConnectionDoesNotExistError as err:
-            raise ProviderError(f"Connection Error: {err}") from err
-        except ConnectionError as ex:
-            self._logger.error(f"Connection Error: {ex}")
-            raise UninitializedError(f"Connection Error: {ex}") from ex
-        except InternalClientError as err:
-            raise ProviderError(f"Internal Error: {err}") from err
-        except InterfaceError as err:
-            raise ProviderError(f"Interface Error: {err}") from err
-        except InterfaceWarning as err:
-            self._logger.warning(f"Interface Warning: {err}")
-            return False
-        except Exception as ex:
-            self._logger.exception(f"Asyncpg Unknown Error: {ex}", stack_info=True)
-            raise DriverError(f"Asyncpg Unknown Error: {ex}") from ex
-
-    async def release(self):
-        try:
-            if not await self._connection.is_closed():
-                if self._pool:
-                    if isinstance(self._connection, pg):
-                        connection = self._connection.engine()
-                    else:
-                        connection = self._connection
-                    release = asyncio.create_task(self._pool.release(connection, timeout=10))
-                    asyncio.ensure_future(release, loop=self._loop)
-                    return await release
-                else:
-                    await self._connection.close(timeout=5)
-        except (InterfaceError, RuntimeError) as err:
-            raise ProviderError(f"Release Interface Error: {err}") from err
-        finally:
-            self._connected = False
-            self._connection = None
-
-    def prepared_statement(self):
-        return self._prepared
-
-    @property
-    def connected(self):
-        if self._pool:
-            return self._pool._connected
-        elif self._connection:
-            return not self._connection.is_closed()
-        else:
-            return False
-
-    async def prepare(self, sentence: str):
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            stmt = await asyncio.shield(self._connection.prepare(sentence))
-            try:
-                self._attributes = stmt.get_attributes()
-                self._columns = [a.name for a in self._attributes]
-                # self._columns = [a.name for a in stmt.get_attributes()]
-                self._prepared = stmt
-                self._parameters = stmt.get_parameters()
-            except TypeError:
-                self._columns = []
-        except FatalPostgresError as err:
-            error = f"Fatal Runtime Error: {err}"
-        except (InvalidSQLStatementNameError, PostgresSyntaxError) as err:
-            error = f"Sentence Syntax Error: {err}"
-        except PostgresError as err:
-            error = f"PostgreSQL Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Prepare Unknown Error: {err}"
-        finally:
-            return [self._prepared, error]  # pylint: disable=W0150
-
-    async def query(self, sentence: Union[str, Any], *args, **kwargs):
-        self._result = None
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            self._result = await self._connection.fetch(sentence, *args, **kwargs)
-            if not self._result:
-                return [None, "Data was not found"]
-        except RuntimeError as err:
-            error = f"Query Error: {err}"
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
-            error = f"Sentence Error: {err}"
-        except PostgresError as err:
-            error = f"Postgres Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            self.generated_at()
-            if error:
-                return [None, error]
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def queryrow(self, sentence: str, *args):
-        self._result = None
-        error = None
-        started = self.start_timing()
-        await self.valid_operation(sentence)
-        try:
-            stmt = await self._connection.prepare(sentence)
-            self._attributes = stmt.get_attributes()
-            self._columns = [a.name for a in self._attributes]
-            self._result = await stmt.fetchrow(*args)
-            if not self._result:
-                return [None, "Data was not found"]
-        except RuntimeError as err:
-            error = f"Query Error: {err}"
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
-            error = f"Sentence Error: {err}"
-        except PostgresError as err:
-            error = f"Postgres Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query Row: {err}"
-        finally:
-            self.generated_at(started)
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def execute(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
-        """Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        error = None
-        self.start_timing()
-        await self.valid_operation(sentence)
-        try:
-            self._result = await self._connection.execute(sentence, *args, **kwargs)
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
-            error = f"Sentence Error: {err}"
-        except DuplicateTableError as err:
-            error = f"Duplicated table: {err}"
-        except PostgresError as err:
-            error = f"Postgres Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Execute: {err}"
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def execute_many(self, sentence: str, *args):
-        error = None
-        self.start_timing()
-        await self.valid_operation(sentence)
-        try:
-            self._result = await self._connection.executemany(sentence, *args)
-        except InterfaceWarning as err:
-            error = f"Interface Warning: {err}"
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
-            error = f"Sentence Error: {err}"
-        except DuplicateTableError as err:
-            error = f"Duplicated table: {err}"
-        except PostgresError as err:
-            error = f"Postgres Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Execute: {err}"
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    executemany = execute_many
-
-    async def fetch_all(self, sentence: str, *args, **kwargs):
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            stmt = await self._connection.prepare(sentence)
-            self._attributes = stmt.get_attributes()
-            self._columns = [a.name for a in self._attributes]
-            result = await stmt.fetch(*args)
-            if not result:
-                return None
-            return result
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
-            raise StatementError(f"Statement Error: {err}") from err
-        except (RuntimeError, PostgresError) as err:
-            raise ProviderError(f"Postgres Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Fetch: {err}") from err
-        finally:
-            self.generated_at()
-
-    fetchall = fetch_all
-
-    async def fetch_one(self, sentence: str, *args, **kwargs):
-        result = None
-        self.start_timing()
-        await self.valid_operation(sentence)
-        try:
-            result = await self._connection.fetchrow(sentence, *args, **kwargs)
-            return result
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
-            raise StatementError(f"Statement Error: {err}") from err
-        except (RuntimeError, PostgresError) as err:
-            raise ProviderError(f"Postgres Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Fetch: {err}") from err
-        finally:
-            self.generated_at()
-
-    async def fetchval(self, sentence: str, *args, column: int = 0, **kwargs):
-        result = None
-        await self.valid_operation(sentence)
-        self.start_timing()
-        try:
-            result = await self._connection.fetchval(sentence, column=column, *args, **kwargs)
-            return result
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
-            raise StatementError(f"Statement Error: {err}") from err
-        except (RuntimeError, PostgresError) as err:
-            raise ProviderError(f"Postgres Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Fetch: {err}") from err
-        finally:
-            self.generated_at()
-
-    ## Transaction Context
-    async def transaction(self):
-        if not self._connection:
-            await self.connection()
-        self._transaction = self._connection.transaction()
-        await self._transaction.start()
-        return self
-
-    async def commit(self):
-        if self._transaction:
-            await self._transaction.commit()
-
-    async def rollback(self):
-        if self._transaction:
-            await self._transaction.rollback()
-
-    async def cursor(self, sentence: Union[str, any], params: Iterable[Any] = None, **kwargs):  # pylint: disable=W0236
-        if not sentence:
-            raise EmptyStatement("Sentence is an empty string")
-        if not self._connection:
-            await self.connection()
-        self._transaction = self._connection.transaction()
-        await self._transaction.start()
-        self._cursor = await self._connection.cursor(sentence)
-        return self
-
-    async def forward(self, number):
-        try:
-            return await self._cursor.forward(number)
-        except Exception as err:
-            error = f"Error forward Cursor: {err}"
-            raise DriverError(error) from err
-
-    async def fetch(self, number=1):
-        try:
-            return await self._cursor.fetch(number)
-        except Exception as err:
-            error = f"Error Fetch Cursor: {err}"
-            raise DriverError(error) from err
-
-    async def fetchrow(self):
-        try:
-            return await self._cursor.fetchrow()
-        except Exception as err:
-            error = f"Error Fetchrow Cursor: {err}"
-            raise DriverError(error) from err
-
-    ## Cursor Iterator Context
-    def __aiter__(self):
-        return self
-
-    async def __anext__(self):
-        data = await self._cursor.fetchrow()
-        if data is not None:
-            return data
-        else:
-            raise StopAsyncIteration
-
-    ## COPY Functions
-    ## type: [ text, csv, binary ]
-    async def copy_from_table(self, table="", schema="public", output=None, file_type="csv", columns=None):
-        """table_copy
-        get a copy of table data into a file, file-like object or a coroutine passed on "output"
-        returns: num of rows copied.
-        example: COPY 1470
-        """
-        if not self._connection:
-            await self.connection()
-        try:
-            result = await self._connection.copy_from_table(
-                table_name=table,
-                schema_name=schema,
-                columns=columns,
-                format=file_type,
-                output=output,
-            )
-            return result
-        except UndefinedTableError as ex:
-            raise StatementError(f"Error on Copy, Table {table }doesn't exists: {ex}") from ex
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError) as ex:
-            raise StatementError(f"Error on Copy, Invalid Statement Error: {ex}") from ex
-        except Exception as ex:
-            raise DriverError(f"Error on Table Copy: {ex}") from ex
-
-    async def copy_to_table(self, table="", schema="public", source=None, file_type="csv", columns=None):
-        """copy_to_table
-        get data from a file, file-like object or a coroutine passed on "source" and copy into table
-        returns: num of rows copied.
-        example: COPY 1470
-        """
-        if not self._connection:
-            await self.connection()
-        if self._transaction:
-            # a transaction exists:
-            await self._transaction.commit()
-        try:
-            result = await self._connection.copy_to_table(
-                table_name=table,
-                schema_name=schema,
-                columns=columns,
-                format=file_type,
-                source=source,
-            )
-            return result
-        except UndefinedTableError as ex:
-            raise StatementError(f"Error on Copy to Table {table }doesn't exists: {ex}") from ex
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError) as ex:
-            raise StatementError(f"Error on Copy, Invalid Statement Error: {ex}") from ex
-        except Exception as ex:
-            raise DriverError(f"Error on Copy to Table {ex}") from ex
-
-    async def copy_into_table(self, table="", schema="public", source=None, columns=None):
-        """copy_into_table
-        get data from records (any iterable object) and save into table
-        returns: num of rows copied.
-        example: COPY 1470
-        """
-        if not self._connection:
-            await self.connection()
-        if self._transaction:
-            # a transaction exists:
-            await self._transaction.commit()
-        try:
-            result = await self._connection.copy_records_to_table(
-                table_name=table, schema_name=schema, columns=columns, records=source
-            )
-            return result
-        except UndefinedTableError as ex:
-            raise StatementError(f"Error on Copy to Table {table }doesn't exists: {ex}") from ex
-        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError) as ex:
-            raise StatementError(f"Error on Copy, Invalid Statement Error: {ex}") from ex
-        except UniqueViolationError as ex:
-            raise StatementError(f"Error on Copy, Constraint Violated: {ex}") from ex
-        except InterfaceError as ex:
-            raise DriverError(f"Error on Copy into Table Function: {ex}") from ex
-        except (RuntimeError, PostgresError) as ex:
-            raise DriverError(f"Postgres Error on Copy into Table: {ex}") from ex
-        except Exception as ex:
-            raise DriverError(f"Error on Copy into Table: {ex}") from ex
-
-    ## Model Logic:
-    async def column_info(self, tablename: str, schema: str = None):
-        """Column Info.
-
-        Get Meta information about a table (column name, data type and PK).
-        Useful to build a DataModel from Querying database.
-        Parameters:
-        @tablename: str The name of the table (including schema).
-        """
-        if schema:
-            table = f"{schema}.{tablename}"
-        else:
-            table = tablename
-        sql = f"SELECT a.attname AS name, a.atttypid::regtype AS type, \
-        format_type(a.atttypid, a.atttypmod) as format_type, a.attnotnull::boolean as notnull, \
-        coalesce((SELECT true FROM pg_index i WHERE i.indrelid = a.attrelid \
-        AND i.indrelid = a.attrelid AND a.attnum = any(i.indkey) \
-        AND i.indisprimary), false) as is_primary \
-        FROM pg_attribute a WHERE a.attrelid = '{table!s}'::regclass \
-        AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum"
-        if not self._connection:
-            await self.connection()
-        try:
-            colinfo = await self._connection.fetch(sql)
-            return colinfo
-        except Exception as err:  # pylint: disable=W0703
-            self._logger.exception(f"Wrong Table information {tablename!s}: {err}")
-
-    ### DDL Information.
-    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
-        """
-        Create is a generic method for Database Objects Creation.
-        """
-        if obj == "table":
-            sql = "CREATE TABLE {name}({columns});"
-            columns = ", ".join(["{name} {type}".format(**e) for e in fields])  # pylint: disable=C0209
-            sql = sql.format(name=name, columns=columns)
-            try:
-                result = await self._connection.execute(sql)
-                if result:
-                    await self._connection.commit()
-                    return True
-                else:
-                    return False
-            except Exception as err:
-                raise DriverError(f"Error in Object Creation: {err!s}") from err
-        else:
-            raise RuntimeError(f"SQLite: invalid Object type {object!s}")
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    async def use(self, database: str):
-        raise NotImplementedError  # pragma: no cover
-
-    async def _insert_(self, _model: Model, **kwargs):  # pylint: disable=W0613
-        """
-        insert a row from model.
-        """
-        try:
-            schema = ""
-            sc = _model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        cols = []
-        columns = []
-        source = []
-        _filter = {}
-        n = 1
-        fields = _model.columns()
-        for name, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            column = field.name
-            columns.append(column)
-            # validating required field
-            try:
-                required = field.required()
-            except AttributeError:
-                required = False
-            pk = self._get_attribute(field, value, attr="primary_key")
-            if pk is True and value is None:
-                if "db_default" in field.metadata:
-                    continue
-            if required is False and value is None or value == "None":
-                if "db_default" in field.metadata:
-                    continue
-                else:
-                    # get default value
-                    default = field.default
-                    if callable(default):
-                        value = default()
-                    else:
-                        continue
-            elif required is True and value is None or value == "None":
-                if "db_default" in field.metadata:
-                    # field get a default value from database
-                    continue
-                else:
-                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
-            elif is_dataclass(value):
-                if isinstance(value, BaseModel):
-                    ### get value for primary key associated with.
-                    try:
-                        value = getattr(value, name)
-                    except AttributeError:
-                        value = None
-            source.append(value)
-            cols.append(column)
-            n += 1
-            if pk := self._get_attribute(field, value, attr="primary_key"):
-                _filter[column] = pk
-        try:
-            cols = ",".join(cols)
-            values = ",".join(["${}".format(a) for a in range(1, n)])  # pylint: disable=C0209
-            columns = ",".join(columns)
-            primary = f"RETURNING {columns}"
-            insert = f"INSERT INTO {table}({cols}) VALUES({values}) {primary}"
-            self._logger.debug(f"INSERT: {insert}")
-            stmt = await self._connection.prepare(insert)
-            result = await stmt.fetchrow(*source, timeout=2)
-            self._logger.debug(stmt.get_statusmsg())
-            if result:
-                _model.reset_values()
-                for f, val in result.items():
-                    setattr(_model, f, val)
-                return _model
-        except UniqueViolationError:
-            raise
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _delete_(self, _model: Model, _filter: dict = None, **kwargs):  # pylint: disable=W0613
-        """
-        delete a row from model.
-        """
-        try:
-            schema = ""
-            sc = _model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        source = []
-        if not _filter:
-            _filter = {}
-        n = 1
-        fields = _model.columns()
-        for _, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            column = field.name
-            source.append(value)
-            n += 1
-            curval = _model.old_value(column)
-            if pk := self._get_attribute(field, curval, attr="primary_key"):
-                if column in _filter:
-                    # already this value on delete:
-                    continue
-                _filter[column] = pk
-        try:
-            condition = self._where(fields, **_filter)
-            if not condition:
-                raise DriverError(f"Avoid DELETE without WHERE conditions: {_filter}")
-            _delete = f"DELETE FROM {table} {condition};"
-            self._logger.debug(f"DELETE: {_delete}")
-            result = await self._connection.execute(_delete)
-            return f"DELETE {result}: {_filter!s}"
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _update_(self, _model: Model, **kwargs):  # pylint: disable=W0613
-        """
-        Updating a row in a Model.
-        TODO: How to update when if primary key changed.
-        Alternatives: Saving *dirty* status and previous value on dict
-        """
-        try:
-            schema = ""
-            sc = _model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        cols = []
-        source = []
-        _filter = {}
-        _updated = {}
-        n = 1
-        fields = _model.columns()
-        for name, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-
-            column = field.name
-            # validating required field
-            try:
-                required = field.required()
-            except AttributeError:
-                required = False
-            if required is False and value is None or value == "None":
-                default = field.default
-                if callable(default):
-                    value = default()
-                else:
-                    continue
-            elif required is True and value is None or value == "None":
-                if "db_default" in field.metadata:
-                    # field get a default value from database
-                    continue
-                raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
-            elif is_dataclass(value):
-                if isinstance(value, BaseModel):
-                    ### get value for primary key associated with.
-                    try:
-                        value = getattr(value, name)
-                    except AttributeError:
-                        value = None
-            cols.append("{} = {}".format(name, "${}".format(n)))  # pylint: disable=C0209
-            source.append(value)
-            n += 1
-            curval = _model.old_value(name)
-            if pk := self._get_attribute(field, curval, attr="primary_key"):
-                _filter[column] = pk
-            if pk := self._get_attribute(field, value, attr="primary_key"):
-                _updated[column] = pk
-        try:
-            set_fields = ", ".join(cols)
-            condition = self._where(fields, **_filter)
-            _update = f"UPDATE {table} SET {set_fields} {condition}"
-            self._logger.debug(f"UPDATE: {_update}")
-            stmt = await self._connection.prepare(_update)
-            result = await stmt.fetchrow(*source, timeout=2)
-            self._logger.debug(f"STATUS {stmt.get_statusmsg()}")
-            condition = self._where(fields, **_updated)
-            get = f"SELECT * FROM {table} {condition}"
-            result = await self._connection.fetchrow(get)
-            if result:
-                _model.reset_values()
-                for f, val in result.items():
-                    setattr(_model, f, val)
-                return _model
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _save_(self, _model: Model, *args, **kwargs):
-        """
-        Save a row in a Model, using Insert-or-Update methodology.
-        """
-        try:
-            return await self._insert_(_model, *args, **kwargs)
-        except UniqueViolationError:
-            return await self._update_(_model, *args, **kwargs)
-
-    async def _fetch_(self, _model: Model, *args, **kwargs):
-        """
-        Returns one Row using Model.
-        """
-        try:
-            schema = ""
-            sc = _model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns()
-        _filter = {}
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT * FROM {table} {condition}"
-        try:
-            result = await self._connection.fetchrow(_get)
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model Fetch over {table}: {e}") from e
-
-    async def _filter_(self, _model: Model, *args, **kwargs):
-        """
-        Filter a Model using Fields.
-        """
-        try:
-            schema = ""
-            sc = _model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        if args:
-            columns = ",".join(args)
-        else:
-            columns = "*"
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            result = await self._connection.fetch(_get)
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model GET over {table}: {e}") from e
-
-    async def _select_(self, *args, **kwargs):
-        """
-        Get a query from Model.
-        """
-        try:
-            model = kwargs["_model"]
-        except KeyError as e:
-            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
-        try:
-            schema = ""
-            sc = model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        if args:
-            condition = "{}".join(args)
-        else:
-            condition = None
-        if "fields" in kwargs:
-            columns = ",".join(kwargs["fields"])
-        else:
-            columns = "*"
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            result = await self._connection.fetch(_get)
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model SELECT over {table}: {e}") from e
-
-    async def _get_(self, _model: Model, *args, **kwargs):
-        """
-        Get one row from model.
-        """
-        try:
-            schema = ""
-            sc = _model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        if args:
-            columns = ",".join(args)
-        else:
-            columns = ",".join(fields)  # getting only selected fields
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            result = await self._connection.fetchrow(_get)
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model GET over {table}: {e}") from e
-
-    async def _all_(self, _model: Model, *args, **kwargs):  # pylint: disable=W0613
-        """
-        Get all rows on a Model.
-        """
-        try:
-            schema = ""
-            # sc = _model.Meta.schema
-            if sc := _model.Meta.schema:
-                schema = f"{sc}."
-            table = f"{schema}{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        if "fields" in kwargs:
-            columns = ",".join(kwargs["fields"])
-        else:
-            columns = "*"
-        _all = f"SELECT {columns} FROM {table}"
-        try:
-            result = await self._connection.fetch(_all)
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model All over {table}: {e}") from e
-
-    async def _remove_(self, _model: Model, **kwargs):
-        """
-        Deleting some records using Model.
-        """
-        try:
-            schema = ""
-            if sc := _model.Meta.schema:
-                schema = f"{sc}."
-            table = f"{schema}{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        for name, field in fields.items():
-            datatype = field.type
-            if name in kwargs:
-                val = kwargs[name]
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _delete = f"DELETE FROM {table} {condition}"
-        try:
-            self._logger.debug(f"DELETE: {_delete}")
-            result = await self._connection.execute(_delete)
-            return f"DELETE {result}: {_filter!s}"
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _updating_(self, *args, _filter: dict = None, **kwargs):
-        """
-        Updating records using Model.
-        """
-        try:
-            model = kwargs["_model"]
-        except KeyError as e:
-            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
-        try:
-            schema = ""
-            sc = model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        fields = model.columns(model)
-        if _filter is None:
-            if args:
-                _filter = args[0]
-        cols = []
-        source = []
-        new_cond = {}
-        n = 1
-        for name, field in fields.items():
-            try:
-                val = kwargs[name]
-            except (KeyError, AttributeError):
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            source.append(value)
-            if name in _filter:
-                new_cond[name] = value
-            cols.append("{} = {}".format(name, "${}".format(n)))  # pylint: disable=C0209
-            n += 1
-        try:
-            set_fields = ", ".join(cols)
-            condition = self._where(fields, **_filter)
-            _update = f"UPDATE {table} SET {set_fields} {condition}"
-            self._logger.debug(f"UPDATE: {_update}")
-            stmt = await self._connection.prepare(_update)
-            result = await stmt.fetchrow(*source, timeout=2)
-            self._logger.debug(stmt.get_statusmsg())
-            print(f"UPDATE {result}: {_filter!s}")
-
-            new_conditions = {**_filter, **new_cond}
-            condition = self._where(fields, **new_conditions)
-
-            _all = f"SELECT * FROM {table} {condition}"
-            if result := await self._connection.fetch(_all):
-                return [model(**dict(r)) for r in result]
-        except Exception as err:
-            raise DriverError(message=f"Error on UPDATE over table {model.Meta.name}: {err!s}") from err
-
-    async def _deleting_(self, *args, _filter: dict = None, **kwargs):
-        """
-        Deleting records using Model.
-        """
-        try:
-            model = kwargs["_model"]
-        except KeyError as e:
-            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
-        try:
-            schema = ""
-            sc = model.Meta.schema
-            if sc:
-                schema = f"{sc}."
-            table = f"{schema}{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        fields = model.columns(model)
-        if _filter is None:
-            if args:
-                _filter = args[0]
-        cols = []
-        source = []
-        new_cond = {}
-        n = 1
-        for name, field in fields.items():
-            try:
-                val = kwargs[name]
-            except (KeyError, AttributeError):
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            source.append(value)
-            if name in _filter:
-                new_cond[name] = value
-            cols.append("{} = {}".format(name, "${}".format(n)))  # pylint: disable=C0209
-            n += 1
-        try:
-            condition = self._where(fields, **_filter)
-            _delete = f"DELETE FROM {table} {condition}"
-            self._logger.debug(f"DELETE: {_delete}")
-            stmt = await self._connection.prepare(_delete)
-            result = await stmt.fetchrow(*source, timeout=2)
-            self._logger.debug(stmt.get_statusmsg())
-            print(f"DELETE {result}: {_filter!s}")
-
-            new_conditions = {**_filter, **new_cond}
-            condition = self._where(fields, **new_conditions)
-
-            _all = f"SELECT * FROM {table} {condition}"
-            if result := await self._connection.fetch(_all):
-                return [model(**dict(r)) for r in result]
-        except Exception as err:
-            raise DriverError(message=f"Error on DELETE over table {model.Meta.name}: {err!s}") from err
+""" pg PostgreSQL Provider.
+Notes on pg Provider
+--------------------
+This provider implements basic funcionalities from asyncpg
+(cursors, transactions, copy from and to files, pools, native data types, etc).
+"""
+import asyncio
+import os
+import ssl
+import time
+import uuid
+from collections.abc import Callable, Iterable
+from typing import Any, Optional, Union
+from dataclasses import is_dataclass
+from datamodel import BaseModel
+import asyncpg
+from asyncpg.exceptions import (
+    ConnectionDoesNotExistError,
+    DuplicateTableError,
+    FatalPostgresError,
+    InterfaceError,
+    InterfaceWarning,
+    InternalClientError,
+    InvalidSQLStatementNameError,
+    PostgresError,
+    PostgresSyntaxError,
+    TooManyConnectionsError,
+    UndefinedColumnError,
+    UndefinedTableError,
+    UniqueViolationError,
+)
+from asyncpg.pgproto import pgproto
+
+from ..exceptions import (
+    ConnectionTimeout,
+    DriverError,
+    EmptyStatement,
+    ProviderError,
+    StatementError,
+    TooManyConnections,
+    UninitializedError,
+)
+from ..interfaces import DBCursorBackend, ModelBackend
+from ..models import Model
+from ..utils.encoders import DefaultEncoder
+from ..utils.types import Entity
+
+from .abstract import BasePool
+from .sql import SQLCursor, SQLDriver
+
+max_cached_statement_lifetime = 600
+max_cacheable_statement_size = 1024 * 15
+
+
+class NAVConnection(asyncpg.Connection):
+    def _get_reset_query(self):
+        return None
+
+
+class pgPool(BasePool):
+    _setup_func: Optional[Callable] = None
+    _init_func: Optional[Callable] = None
+
+    def __init__(
+        self, dsn: str = None, loop: asyncio.AbstractEventLoop = None, params: Optional[dict] = None, **kwargs
+    ):
+        self._test_query = "SELECT 1"
+        self.application_name = os.getenv("APP_NAME", "NAV")
+        self._max_clients = 300
+        self._min_size = 10
+        self._server_settings = {}
+        self._dsn = "postgres://{user}:{password}@{host}:{port}/{database}"
+        super(pgPool, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+        try:
+            self._max_inactive_timeout = kwargs["max_inactive_timeout"]
+        except KeyError:
+            self._max_inactive_timeout = 36000
+        if "server_settings" in kwargs:
+            self._server_settings = kwargs["server_settings"]
+        if "application_name" in self._server_settings:
+            self.application_name = self._server_settings["application_name"]
+        if "max_clients" in kwargs:
+            self._max_clients = kwargs["max_clients"]
+        if "min_size" in kwargs:
+            self._min_size = kwargs["min_size"]
+        if "numeric_as_float" in kwargs:
+            self._numeric_as_float = kwargs["numeric_as_float"]
+        # Connection Configuration:
+        try:
+            self._connection_config = params.pop("connection_config", {})
+        except AttributeError:
+            self._connection_config = {}
+        # set the JSON encoder:
+        self._encoder = DefaultEncoder()
+        ### SSL Support:
+        self.ssl: bool = False
+        if params and "ssl" in params:
+            ssloptions = params["ssl"]
+        elif "ssl" in kwargs:
+            ssloptions = kwargs["ssl"]
+        else:
+            ssloptions = None
+        if ssloptions:
+            self.ssl: bool = True
+            try:
+                check_hostname = ssloptions["check_hostname"]
+            except KeyError:
+                check_hostname = False
+            ### certificate Support:
+            try:
+                ca_file = ssloptions["cafile"]
+            except KeyError:
+                ca_file = None
+            args = {"cafile": ca_file}
+            self.sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, **args)
+            # Certificate Chain:
+            try:
+                certs = {"certfile": ssloptions["certfile"], "keyfile": ssloptions["keyfile"]}
+            except KeyError:
+                certs = {"certfile": None, "keyfile": None}
+            if certs["certfile"]:
+                self.sslctx.load_cert_chain(**certs)
+            self.sslctx.check_hostname = check_hostname
+
+    async def setup_connection(self, connection):
+        if self._setup_func:
+            try:
+                await self.setup_func(connection)
+            except (ValueError, RuntimeError) as err:
+                self._logger.error(f"Error on Setup Function: {err}")
+
+    async def test_connection(self, *args):
+        """Test Connnection.
+        Making a connection Test using the basic Query Method.
+        """
+        result = None
+        error = None
+        if self._test_query is None:
+            return [None, NotImplementedError()]
+        try:
+            result = await self.execute(self._test_query, *args)
+        except ProviderError as err:
+            error = err
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    async def init_connection(self, connection):
+        # Setup jsonb encoder/decoder
+        def _encoder(value):
+            # return json.dumps(value, cls=BaseEncoder)
+            return self._encoder.dumps(value)  # pylint: disable=E1120
+
+        def _decoder(value):
+            return self._encoder.loads(value)  # pylint: disable=E1120
+
+        await connection.set_type_codec("json", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
+        await connection.set_type_codec("jsonb", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
+        await connection.set_builtin_type_codec("hstore", codec_name="pg_contrib.hstore")
+
+        def _uuid_encoder(value):
+            if isinstance(value, uuid.UUID):
+                val = value.bytes
+            elif value is not None:
+                val = uuid.UUID(value).bytes
+            else:
+                val = b""
+            return val
+
+        await connection.set_type_codec(
+            "uuid",
+            encoder=_uuid_encoder,
+            decoder=lambda u: pgproto.UUID(u),  # pylint: disable=I1101,W0108
+            schema="pg_catalog",
+            format="binary",
+        )
+        if self._connection_config and isinstance(self._connection_config, dict):
+            for key, value in self._connection_config.items():
+                config = f"SELECT set_config('{key}', '{value}', false);"
+                try:
+                    r = await connection.execute(config)
+                    self._logger.debug(f"{r} - Config {key} = {value}")
+                except RuntimeError as err:
+                    self._logger.warning(f"Pg: Error on Connection Configuration: {err}")
+        if self._init_func is not None and callable(self._init_func):
+            try:
+                await self._init_func(connection)  # pylint: disable=E1102
+            except (ValueError, RuntimeError) as err:
+                self._logger.warning(f"Error on Init Connection: {err}")
+
+    # Create a database connection pool
+    async def connect(self):
+        """
+        Creates a Pool Connection.
+        """
+        self._logger.debug(f"AsyncPg (Pool): Connecting to {self._dsn}")
+        try:
+            # TODO: pass a setup class for set_builtin_type_codec and a setup for add listener
+            server_settings = {
+                "application_name": self.application_name,
+                "idle_in_transaction_session_timeout": "60min",
+                "idle_session_timeout": "60min",
+                "statement_timeout": "60min",
+                "tcp_keepalives_idle": "30min",
+            }
+            server_settings = {**server_settings, **self._server_settings}
+            if self.ssl:
+                _ssl = {"ssl": self.sslctx}
+            else:
+                _ssl = {}
+            self._pool = await asyncpg.create_pool(
+                dsn=self._dsn,
+                max_queries=self._max_queries,
+                min_size=self._min_size,
+                max_size=self._max_clients,
+                max_inactive_connection_lifetime=self._max_inactive_timeout,
+                statement_cache_size=36000,
+                timeout=self._timeout,
+                # command_timeout=self._timeout,
+                init=self.init_connection,
+                setup=self.setup_connection,
+                loop=self._loop,
+                server_settings=server_settings,
+                connection_class=NAVConnection,
+                **_ssl,
+            )
+            # is connected
+            if self._pool:
+                self._connected = True
+                self._initialized_on = time.time()
+            return self
+        except ConnectionRefusedError as err:
+            raise UninitializedError(f"Unable to connect to database, connection Refused: {err}") from err
+        except ConnectionError as ex:
+            self._logger.error(f"Connection Error: {ex}")
+            raise UninitializedError(f"Connection Error: {ex}") from ex
+        except TooManyConnectionsError as err:
+            self._logger.error(f"Too Many Connections Error: {err}")
+            raise UninitializedError(f"Too Many Connections Error: {err}") from err
+        except TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to database: {err}") from err
+        except ConnectionDoesNotExistError as err:
+            raise ProviderError(f"Connection Error: {err}") from err
+        except InternalClientError as err:
+            raise ProviderError(f"Internal Error: {err}") from err
+        except InterfaceError as err:
+            raise ProviderError(f"Interface Error: {err}") from err
+        except InterfaceWarning as err:
+            self._logger.warning(f"Interface Warning: {err}")
+            return False
+        except Exception as ex:
+            self._logger.exception(f"Asyncpg Unknown Error: {ex}", stack_info=True)
+            raise DriverError(f"Asyncpg Unknown Error: {ex}") from ex
+
+    async def acquire(self):
+        """
+        Takes a connection from the pool.
+        """
+        db = None
+        self._connection = None
+        # Take a connection from the pool.
+        try:
+            self._connection = await self._pool.acquire()
+        except TooManyConnectionsError as err:
+            self._logger.error(f"Too Many Connections Error: {err}")
+            raise TooManyConnections(f"Too Many Connections Error: {err}") from err
+        except TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to database: {err}") from err
+        except ConnectionRefusedError as err:
+            raise UninitializedError(f"Unable to connect to database, connection Refused: {err}") from err
+        except ConnectionDoesNotExistError as err:
+            raise ProviderError(f"Connection Error: {err}") from err
+        except InternalClientError as err:
+            raise ProviderError(f"Internal Error: {err}") from err
+        except InterfaceError as err:
+            raise ProviderError(f"Interface Error: {err}") from err
+        except InterfaceWarning as err:
+            self._logger.warning(f"Interface Warning: {err}")
+        except Exception as err:  # pylint: disable=W0703
+            self._logger.error(f"Unknown Error on Acquire: {err}")
+        if self._connection:
+            db = pg(pool=self)
+            db.set_connection(self._connection)
+        return db
+
+    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
+        # clean up anything you need to clean up
+        return await self.release(connection=self._connection, timeout=5)
+
+    async def release(self, connection=None, timeout=5):
+        """
+        Release a connection from the pool
+        """
+        if not connection:
+            conn = self._connection
+        else:
+            conn = connection
+        if isinstance(conn, pg):
+            conn = connection.engine()
+        if not conn:
+            return True
+        try:
+            await self._pool.release(conn, timeout=timeout)
+            return True
+        except asyncio.exceptions.CancelledError:
+            pass
+        except InterfaceError as err:
+            raise ProviderError(message=f"Release Interface Error: {err}") from err
+        except InternalClientError as err:
+            self._logger.debug(
+                f"Connection already released, \
+                called on a free connection holder: {err}"
+            )
+            return False
+        except Exception as err:
+            raise ProviderError(message=f"Release Error: {err}") from err
+
+    async def wait_close(self, gracefully=True, timeout=5):
+        """
+        close
+            Close Pool Connection
+        """
+        if self._pool:
+            # try to closing main connection
+            try:
+                if self._connection:
+                    await self._pool.release(self._connection, timeout=timeout)
+                    self._connection = None
+            except asyncio.exceptions.CancelledError:
+                pass
+            except (InternalClientError, InterfaceError) as err:
+                raise ProviderError(f"Release Interface Error: {err}") from err
+            except Exception as err:
+                raise ProviderError(f"Release Error: {err}") from err
+            try:
+                if gracefully:
+                    await asyncio.wait_for(self._pool.expire_connections(), timeout=timeout)
+                    await asyncio.wait_for(self._pool.close(), timeout=timeout)
+                # # until end, close the pool correctly:
+                self._pool.terminate()
+            except asyncio.TimeoutError as e:
+                self._logger.warning(f"Close timed out: {e}")
+            except Exception as err:
+                error = f"Pool Exception: {err.__class__.__name__}: {err}"
+                print(f"Pool Error: {error}")
+                raise ProviderError(f"Pool Error: {error}") from err
+            finally:
+                self._connected = False
+
+    async def close(self, **kwargs):
+        """
+        Close Pool
+        """
+        try:
+            if self._connection:
+                await self._pool.release(self._connection, timeout=1)
+                self._connection = None
+        except InterfaceError as err:
+            raise ProviderError(f"Release Interface Error: {err}") from err
+        except Exception as err:
+            raise ProviderError(f"Release Error: {err}") from err
+        try:
+            await self._pool.expire_connections()
+            await self._pool.close()
+        except Exception as err:
+            error = f"Pool Closing Error: {err.__class__.__name__}: {err}"
+            raise Exception(error) from err
+        finally:
+            self._pool.terminate()
+            self._connected = False
+
+    disconnect = close
+
+    async def execute(self, sentence, *args):
+        """
+        Execute a connection into the Pool
+        """
+        try:
+            return await self._pool.execute(sentence, *args)
+        except InterfaceError as err:
+            raise ProviderError(f"Execute Interface Error: {err}") from err
+        except Exception as err:
+            raise ProviderError(f"Execute Error: {err}") from err
+
+
+class pgCursor(SQLCursor):
+    _connection: asyncpg.Connection = None
+
+
+class pg(SQLDriver, DBCursorBackend, ModelBackend):
+    _provider = "pg"
+    _syntax = "sql"
+    _test_query = "SELECT 1"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._dsn = "postgres://{user}:{password}@{host}:{port}/{database}"
+        self.application_name = os.getenv("APP_NAME", "NAV")
+        self._prepared = None
+        self._cursor = None
+        self._transaction = None
+        self._server_settings = {}
+        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
+        DBCursorBackend.__init__(self)
+        if "pool" in kwargs:
+            self._pool = kwargs["pool"]
+            self._loop = self._pool.get_loop()
+        if "server_settings" in kwargs:
+            self._server_settings = kwargs["server_settings"]
+        if "application_name" in self._server_settings:
+            self.application_name = self._server_settings["application_name"]
+        if "numeric_as_float" in kwargs:
+            self._numeric_as_float = kwargs["numeric_as_float"]
+        else:
+            self._numeric_as_float = False
+        # set the JSON encoder:
+        self._encoder = DefaultEncoder()
+        # Connection Configuration:
+        try:
+            self._connection_config = params.pop("connection_config", {})
+        except AttributeError:
+            self._connection_config = {}
+        ### SSL Support:
+        self.ssl: bool = False
+        if params and "ssl" in params:
+            ssloptions = params["ssl"]
+        elif "ssl" in kwargs:
+            ssloptions = kwargs["ssl"]
+        else:
+            ssloptions = None
+        if ssloptions:
+            self.ssl: bool = True
+            try:
+                check_hostname = ssloptions["check_hostname"]
+            except KeyError:
+                check_hostname = False
+            ### certificate Support:
+            try:
+                ca_file = ssloptions["cafile"]
+            except KeyError:
+                ca_file = None
+            args = {"cafile": ca_file}
+            self.sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, **args)
+            # Certificate Chain:
+            try:
+                certs = {"certfile": ssloptions["certfile"], "keyfile": ssloptions["keyfile"]}
+            except KeyError:
+                certs = {"certfile": None, "keyfile": None}
+            if certs["certfile"]:
+                self.sslctx.load_cert_chain(**certs)
+            self.sslctx.check_hostname = check_hostname
+
+    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
+        # clean up anything you need to clean up
+        return await self.close()
+
+    async def close(self, timeout=5):
+        """
+        Closing a Connection.
+        """
+        if self._connection:
+            try:
+                if not self._connection.is_closed():
+                    # self._logger.debug(f"Closing Connection, id: {self._connection.get_server_pid()}")
+                    if self._pool:
+                        await self._pool.release(self._connection)
+                    else:
+                        await self._connection.close(timeout=timeout)
+            except TypeError:
+                pass
+            except InterfaceError as err:
+                raise ProviderError(f"AsyncPg: Closing Error: {err}") from err
+            except Exception as err:
+                try:
+                    await self._connection.terminate()
+                    self._connection = None
+                    raise ProviderError(f"Connection Error, Terminated: {err}") from err
+                except TypeError:
+                    pass
+            finally:
+                self._connected = False
+                self._connection = None
+
+    disconnect = close
+
+    def terminate(self):
+        self._loop.run_until_complete(self.close())
+
+    async def is_in_transaction(self):
+        return self._connection.is_in_transaction()
+
+    def is_connected(self):
+        try:
+            if self._connection:
+                return not (self._connection.is_closed())
+        except (AttributeError, InterfaceError):
+            pass
+        return self._connected
+
+    async def connection(self):
+        """connection.
+
+        Get an asyncpg connection
+        """
+        if self._connection:
+            if not self._connection.is_closed():
+                self._connected = True
+                return self
+        self._connection = None
+        self._connected = False
+        # Setup jsonb encoder/decoder
+
+        def _encoder(value):
+            return self._encoder.dumps(value)  # pylint: disable=E1120
+
+        def _decoder(value):
+            return self._encoder.loads(value)  # pylint: disable=E1120
+
+        server_settings = {
+            "application_name": self.application_name,
+            "idle_session_timeout": "120min",
+            "tcp_keepalives_idle": "36000",
+            "max_parallel_workers": "512",
+        }
+        server_settings = {**server_settings, **self._server_settings}
+        if self.ssl:
+            _ssl = {"ssl": self.sslctx}
+        else:
+            _ssl = {}
+        try:
+            if self._pool and not self._connection:
+                self._connection = await self._pool.pool().acquire()
+            else:
+                self._connection = await asyncpg.connect(
+                    dsn=self._dsn,
+                    timeout=self._timeout,
+                    statement_cache_size=36000,
+                    server_settings=server_settings,
+                    connection_class=NAVConnection,
+                    loop=self._loop,
+                    **_ssl,
+                )
+                await self._connection.set_type_codec("json", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
+                await self._connection.set_type_codec("jsonb", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
+                await self._connection.set_builtin_type_codec("hstore", codec_name="pg_contrib.hstore")
+
+                def _uuid_encoder(value):
+                    if isinstance(value, uuid.UUID):
+                        val = value.bytes
+                    elif value is not None:
+                        val = uuid.UUID(bytes=value)
+                    else:
+                        val = b""
+                    return val
+
+                def _uuid_decoder(value):
+                    if value is None:
+                        return b""
+                    else:
+                        return uuid.UUID(bytes=value)
+
+                await self._connection.set_type_codec(
+                    "uuid",
+                    encoder=_uuid_encoder,
+                    decoder=_uuid_decoder,
+                    schema="pg_catalog",
+                    format="binary",
+                )
+            if self._connection:
+                self._connected = True
+                if self._connection_config and isinstance(self._connection_config, dict):
+                    for key, value in self._connection_config.items():
+                        config = f"SELECT set_config('{key}', '{value}', false);"
+                        try:
+                            r = await self._connection.execute(config)
+                        except RuntimeError as err:
+                            self._logger.warning(f"Pg: Error on Connection Configuration: {err}")
+                if self._init_func is not None and callable(self._init_func):
+                    try:
+                        await self._init_func(self._connection)  # pylint: disable=E1102
+                    except (ValueError, RuntimeError) as err:
+                        self._logger.warning(f"Error on Init Connection: {err}")
+                self._initialized_on = time.time()
+                self._logger.debug(f"Initialized on: {self._initialized_on}")
+            return self
+        except ConnectionRefusedError as err:
+            raise UninitializedError(f"Unable to connect to database, connection Refused: {err}") from err
+        except TooManyConnectionsError as err:
+            self._logger.error(f"Too Many Connections Error: {err}")
+            raise TooManyConnections(f"Too Many Connections Error: {err}") from err
+        except TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to database: {err}") from err
+        except ConnectionDoesNotExistError as err:
+            raise ProviderError(f"Connection Error: {err}") from err
+        except ConnectionError as ex:
+            self._logger.error(f"Connection Error: {ex}")
+            raise UninitializedError(f"Connection Error: {ex}") from ex
+        except InternalClientError as err:
+            raise ProviderError(f"Internal Error: {err}") from err
+        except InterfaceError as err:
+            raise ProviderError(f"Interface Error: {err}") from err
+        except InterfaceWarning as err:
+            self._logger.warning(f"Interface Warning: {err}")
+            return False
+        except Exception as ex:
+            self._logger.exception(f"Asyncpg Unknown Error: {ex}", stack_info=True)
+            raise DriverError(f"Asyncpg Unknown Error: {ex}") from ex
+
+    async def release(self):
+        try:
+            if not await self._connection.is_closed():
+                if self._pool:
+                    if isinstance(self._connection, pg):
+                        connection = self._connection.engine()
+                    else:
+                        connection = self._connection
+                    release = asyncio.create_task(self._pool.release(connection, timeout=10))
+                    asyncio.ensure_future(release, loop=self._loop)
+                    return await release
+                else:
+                    await self._connection.close(timeout=5)
+        except (InterfaceError, RuntimeError) as err:
+            raise ProviderError(f"Release Interface Error: {err}") from err
+        finally:
+            self._connected = False
+            self._connection = None
+
+    def prepared_statement(self):
+        return self._prepared
+
+    @property
+    def connected(self):
+        if self._pool:
+            return self._pool._connected
+        elif self._connection:
+            return not self._connection.is_closed()
+        else:
+            return False
+
+    async def prepare(self, sentence: str):
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            stmt = await asyncio.shield(self._connection.prepare(sentence))
+            try:
+                self._attributes = stmt.get_attributes()
+                self._columns = [a.name for a in self._attributes]
+                # self._columns = [a.name for a in stmt.get_attributes()]
+                self._prepared = stmt
+                self._parameters = stmt.get_parameters()
+            except TypeError:
+                self._columns = []
+        except FatalPostgresError as err:
+            error = f"Fatal Runtime Error: {err}"
+        except (InvalidSQLStatementNameError, PostgresSyntaxError) as err:
+            error = f"Sentence Syntax Error: {err}"
+        except PostgresError as err:
+            error = f"PostgreSQL Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Prepare Unknown Error: {err}"
+        finally:
+            return [self._prepared, error]  # pylint: disable=W0150
+
+    async def query(self, sentence: Union[str, Any], *args, **kwargs):
+        self._result = None
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            self._result = await self._connection.fetch(sentence, *args, **kwargs)
+            if not self._result:
+                return [None, "Data was not found"]
+        except RuntimeError as err:
+            error = f"Query Error: {err}"
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
+            error = f"Sentence Error: {err}"
+        except PostgresError as err:
+            error = f"Postgres Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            self.generated_at()
+            if error:
+                return [None, error]
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def queryrow(self, sentence: str, *args):
+        self._result = None
+        error = None
+        started = self.start_timing()
+        await self.valid_operation(sentence)
+        try:
+            stmt = await self._connection.prepare(sentence)
+            self._attributes = stmt.get_attributes()
+            self._columns = [a.name for a in self._attributes]
+            self._result = await stmt.fetchrow(*args)
+            if not self._result:
+                return [None, "Data was not found"]
+        except RuntimeError as err:
+            error = f"Query Error: {err}"
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
+            error = f"Sentence Error: {err}"
+        except PostgresError as err:
+            error = f"Postgres Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query Row: {err}"
+        finally:
+            self.generated_at(started)
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def execute(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
+        """Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        error = None
+        self.start_timing()
+        await self.valid_operation(sentence)
+        try:
+            self._result = await self._connection.execute(sentence, *args, **kwargs)
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
+            error = f"Sentence Error: {err}"
+        except DuplicateTableError as err:
+            error = f"Duplicated table: {err}"
+        except PostgresError as err:
+            error = f"Postgres Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Execute: {err}"
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def execute_many(self, sentence: str, *args):
+        error = None
+        self.start_timing()
+        await self.valid_operation(sentence)
+        try:
+            self._result = await self._connection.executemany(sentence, *args)
+        except InterfaceWarning as err:
+            error = f"Interface Warning: {err}"
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
+            error = f"Sentence Error: {err}"
+        except DuplicateTableError as err:
+            error = f"Duplicated table: {err}"
+        except PostgresError as err:
+            error = f"Postgres Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Execute: {err}"
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    executemany = execute_many
+
+    async def fetch_all(self, sentence: str, *args, **kwargs):
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            stmt = await self._connection.prepare(sentence)
+            self._attributes = stmt.get_attributes()
+            self._columns = [a.name for a in self._attributes]
+            result = await stmt.fetch(*args)
+            if not result:
+                return None
+            return result
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
+            raise StatementError(f"Statement Error: {err}") from err
+        except (RuntimeError, PostgresError) as err:
+            raise ProviderError(f"Postgres Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Fetch: {err}") from err
+        finally:
+            self.generated_at()
+
+    fetchall = fetch_all
+
+    async def fetch_one(self, sentence: str, *args, **kwargs):
+        result = None
+        self.start_timing()
+        await self.valid_operation(sentence)
+        try:
+            result = await self._connection.fetchrow(sentence, *args, **kwargs)
+            return result
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
+            raise StatementError(f"Statement Error: {err}") from err
+        except (RuntimeError, PostgresError) as err:
+            raise ProviderError(f"Postgres Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Fetch: {err}") from err
+        finally:
+            self.generated_at()
+
+    async def fetchval(self, sentence: str, *args, column: int = 0, **kwargs):
+        result = None
+        await self.valid_operation(sentence)
+        self.start_timing()
+        try:
+            result = await self._connection.fetchval(sentence, column=column, *args, **kwargs)
+            return result
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError, UndefinedTableError) as err:
+            raise StatementError(f"Statement Error: {err}") from err
+        except (RuntimeError, PostgresError) as err:
+            raise ProviderError(f"Postgres Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Fetch: {err}") from err
+        finally:
+            self.generated_at()
+
+    ## Transaction Context
+    async def transaction(self):
+        if not self._connection:
+            await self.connection()
+        self._transaction = self._connection.transaction()
+        await self._transaction.start()
+        return self
+
+    async def commit(self):
+        if self._transaction:
+            await self._transaction.commit()
+
+    async def rollback(self):
+        if self._transaction:
+            await self._transaction.rollback()
+
+    async def cursor(self, sentence: Union[str, any], params: Iterable[Any] = None, **kwargs):  # pylint: disable=W0236
+        if not sentence:
+            raise EmptyStatement("Sentence is an empty string")
+        if not self._connection:
+            await self.connection()
+        self._transaction = self._connection.transaction()
+        await self._transaction.start()
+        self._cursor = await self._connection.cursor(sentence)
+        return self
+
+    async def forward(self, number):
+        try:
+            return await self._cursor.forward(number)
+        except Exception as err:
+            error = f"Error forward Cursor: {err}"
+            raise DriverError(error) from err
+
+    async def fetch(self, number=1):
+        try:
+            return await self._cursor.fetch(number)
+        except Exception as err:
+            error = f"Error Fetch Cursor: {err}"
+            raise DriverError(error) from err
+
+    async def fetchrow(self):
+        try:
+            return await self._cursor.fetchrow()
+        except Exception as err:
+            error = f"Error Fetchrow Cursor: {err}"
+            raise DriverError(error) from err
+
+    ## Cursor Iterator Context
+    def __aiter__(self):
+        return self
+
+    async def __anext__(self):
+        data = await self._cursor.fetchrow()
+        if data is not None:
+            return data
+        else:
+            raise StopAsyncIteration
+
+    ## COPY Functions
+    ## type: [ text, csv, binary ]
+    async def copy_from_table(self, table="", schema="public", output=None, file_type="csv", columns=None):
+        """table_copy
+        get a copy of table data into a file, file-like object or a coroutine passed on "output"
+        returns: num of rows copied.
+        example: COPY 1470
+        """
+        if not self._connection:
+            await self.connection()
+        try:
+            result = await self._connection.copy_from_table(
+                table_name=table,
+                schema_name=schema,
+                columns=columns,
+                format=file_type,
+                output=output,
+            )
+            return result
+        except UndefinedTableError as ex:
+            raise StatementError(f"Error on Copy, Table {table }doesn't exists: {ex}") from ex
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError) as ex:
+            raise StatementError(f"Error on Copy, Invalid Statement Error: {ex}") from ex
+        except Exception as ex:
+            raise DriverError(f"Error on Table Copy: {ex}") from ex
+
+    async def copy_to_table(self, table="", schema="public", source=None, file_type="csv", columns=None):
+        """copy_to_table
+        get data from a file, file-like object or a coroutine passed on "source" and copy into table
+        returns: num of rows copied.
+        example: COPY 1470
+        """
+        if not self._connection:
+            await self.connection()
+        if self._transaction:
+            # a transaction exists:
+            await self._transaction.commit()
+        try:
+            result = await self._connection.copy_to_table(
+                table_name=table,
+                schema_name=schema,
+                columns=columns,
+                format=file_type,
+                source=source,
+            )
+            return result
+        except UndefinedTableError as ex:
+            raise StatementError(f"Error on Copy to Table {table }doesn't exists: {ex}") from ex
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError) as ex:
+            raise StatementError(f"Error on Copy, Invalid Statement Error: {ex}") from ex
+        except Exception as ex:
+            raise DriverError(f"Error on Copy to Table {ex}") from ex
+
+    async def copy_into_table(self, table="", schema="public", source=None, columns=None):
+        """copy_into_table
+        get data from records (any iterable object) and save into table
+        returns: num of rows copied.
+        example: COPY 1470
+        """
+        if not self._connection:
+            await self.connection()
+        if self._transaction:
+            # a transaction exists:
+            await self._transaction.commit()
+        try:
+            result = await self._connection.copy_records_to_table(
+                table_name=table, schema_name=schema, columns=columns, records=source
+            )
+            return result
+        except UndefinedTableError as ex:
+            raise StatementError(f"Error on Copy to Table {table }doesn't exists: {ex}") from ex
+        except (InvalidSQLStatementNameError, PostgresSyntaxError, UndefinedColumnError) as ex:
+            raise StatementError(f"Error on Copy, Invalid Statement Error: {ex}") from ex
+        except UniqueViolationError as ex:
+            raise StatementError(f"Error on Copy, Constraint Violated: {ex}") from ex
+        except InterfaceError as ex:
+            raise DriverError(f"Error on Copy into Table Function: {ex}") from ex
+        except (RuntimeError, PostgresError) as ex:
+            raise DriverError(f"Postgres Error on Copy into Table: {ex}") from ex
+        except Exception as ex:
+            raise DriverError(f"Error on Copy into Table: {ex}") from ex
+
+    ## Model Logic:
+    async def column_info(self, tablename: str, schema: str = None):
+        """Column Info.
+
+        Get Meta information about a table (column name, data type and PK).
+        Useful to build a DataModel from Querying database.
+        Parameters:
+        @tablename: str The name of the table (including schema).
+        """
+        if schema:
+            table = f"{schema}.{tablename}"
+        else:
+            table = tablename
+        sql = f"SELECT a.attname AS name, a.atttypid::regtype AS type, \
+        format_type(a.atttypid, a.atttypmod) as format_type, a.attnotnull::boolean as notnull, \
+        coalesce((SELECT true FROM pg_index i WHERE i.indrelid = a.attrelid \
+        AND i.indrelid = a.attrelid AND a.attnum = any(i.indkey) \
+        AND i.indisprimary), false) as is_primary \
+        FROM pg_attribute a WHERE a.attrelid = '{table!s}'::regclass \
+        AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum"
+        if not self._connection:
+            await self.connection()
+        try:
+            colinfo = await self._connection.fetch(sql)
+            return colinfo
+        except Exception as err:  # pylint: disable=W0703
+            self._logger.exception(f"Wrong Table information {tablename!s}: {err}")
+
+    ### DDL Information.
+    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
+        """
+        Create is a generic method for Database Objects Creation.
+        """
+        if obj == "table":
+            sql = "CREATE TABLE {name}({columns});"
+            columns = ", ".join(["{name} {type}".format(**e) for e in fields])  # pylint: disable=C0209
+            sql = sql.format(name=name, columns=columns)
+            try:
+                result = await self._connection.execute(sql)
+                if result:
+                    await self._connection.commit()
+                    return True
+                else:
+                    return False
+            except Exception as err:
+                raise DriverError(f"Error in Object Creation: {err!s}") from err
+        else:
+            raise RuntimeError(f"SQLite: invalid Object type {object!s}")
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    async def use(self, database: str):
+        raise NotImplementedError  # pragma: no cover
+
+    async def _insert_(self, _model: Model, **kwargs):  # pylint: disable=W0613
+        """
+        insert a row from model.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        cols = []
+        columns = []
+        source = []
+        _filter = {}
+        n = 1
+        fields = _model.columns()
+        for name, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            columns.append(column)
+            # validating required field
+            try:
+                required = field.required()
+            except AttributeError:
+                required = False
+            pk = self._get_attribute(field, value, attr="primary_key")
+            if pk is True and value is None:
+                if "db_default" in field.metadata:
+                    continue
+            if required is False and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    continue
+                else:
+                    # get default value
+                    default = field.default
+                    if callable(default):
+                        value = default()
+                    else:
+                        continue
+            elif required is True and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    # field get a default value from database
+                    continue
+                else:
+                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
+            elif is_dataclass(value):
+                if isinstance(value, BaseModel):
+                    ### get value for primary key associated with.
+                    try:
+                        value = getattr(value, name)
+                    except AttributeError:
+                        value = None
+            source.append(value)
+            cols.append(column)
+            n += 1
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _filter[column] = pk
+        try:
+            cols = ",".join(cols)
+            values = ",".join(["${}".format(a) for a in range(1, n)])  # pylint: disable=C0209
+            columns = ",".join(columns)
+            primary = f"RETURNING {columns}"
+            insert = f"INSERT INTO {table}({cols}) VALUES({values}) {primary}"
+            self._logger.debug(f"INSERT: {insert}")
+            stmt = await self._connection.prepare(insert)
+            result = await stmt.fetchrow(*source, timeout=2)
+            self._logger.debug(stmt.get_statusmsg())
+            if result:
+                _model.reset_values()
+                for f, val in result.items():
+                    setattr(_model, f, val)
+                return _model
+        except UniqueViolationError:
+            raise
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _delete_(self, _model: Model, _filter: dict = None, **kwargs):  # pylint: disable=W0613
+        """
+        delete a row from model.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        source = []
+        if not _filter:
+            _filter = {}
+        n = 1
+        fields = _model.columns()
+        for _, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            source.append(value)
+            n += 1
+            curval = _model.old_value(column)
+            if pk := self._get_attribute(field, curval, attr="primary_key"):
+                if column in _filter:
+                    # already this value on delete:
+                    continue
+                _filter[column] = pk
+        try:
+            condition = self._where(fields, **_filter)
+            if not condition:
+                raise DriverError(f"Avoid DELETE without WHERE conditions: {_filter}")
+            _delete = f"DELETE FROM {table} {condition};"
+            self._logger.debug(f"DELETE: {_delete}")
+            result = await self._connection.execute(_delete)
+            return f"DELETE {result}: {_filter!s}"
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _update_(self, _model: Model, **kwargs):  # pylint: disable=W0613
+        """
+        Updating a row in a Model.
+        TODO: How to update when if primary key changed.
+        Alternatives: Saving *dirty* status and previous value on dict
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        cols = []
+        source = []
+        _filter = {}
+        _updated = {}
+        n = 1
+        fields = _model.columns()
+        for name, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+
+            column = field.name
+            # validating required field
+            try:
+                required = field.required()
+            except AttributeError:
+                required = False
+            if required is False and value is None or value == "None":
+                default = field.default
+                if callable(default):
+                    value = default()
+                else:
+                    continue
+            elif required is True and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    # field get a default value from database
+                    continue
+                raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
+            elif is_dataclass(value):
+                if isinstance(value, BaseModel):
+                    ### get value for primary key associated with.
+                    try:
+                        value = getattr(value, name)
+                    except AttributeError:
+                        value = None
+            cols.append("{} = {}".format(name, "${}".format(n)))  # pylint: disable=C0209
+            source.append(value)
+            n += 1
+            curval = _model.old_value(name)
+            if pk := self._get_attribute(field, curval, attr="primary_key"):
+                _filter[column] = pk
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _updated[column] = pk
+        try:
+            set_fields = ", ".join(cols)
+            condition = self._where(fields, **_filter)
+            _update = f"UPDATE {table} SET {set_fields} {condition}"
+            self._logger.debug(f"UPDATE: {_update}")
+            stmt = await self._connection.prepare(_update)
+            result = await stmt.fetchrow(*source, timeout=2)
+            self._logger.debug(f"STATUS {stmt.get_statusmsg()}")
+            condition = self._where(fields, **_updated)
+            get = f"SELECT * FROM {table} {condition}"
+            result = await self._connection.fetchrow(get)
+            if result:
+                _model.reset_values()
+                for f, val in result.items():
+                    setattr(_model, f, val)
+                return _model
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _save_(self, _model: Model, *args, **kwargs):
+        """
+        Save a row in a Model, using Insert-or-Update methodology.
+        """
+        try:
+            return await self._insert_(_model, *args, **kwargs)
+        except UniqueViolationError:
+            return await self._update_(_model, *args, **kwargs)
+
+    async def _fetch_(self, _model: Model, *args, **kwargs):
+        """
+        Returns one Row using Model.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns()
+        _filter = {}
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT * FROM {table} {condition}"
+        try:
+            result = await self._connection.fetchrow(_get)
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model Fetch over {table}: {e}") from e
+
+    async def _filter_(self, _model: Model, *args, **kwargs):
+        """
+        Filter a Model using Fields.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        if args:
+            columns = ",".join(args)
+        else:
+            columns = "*"
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            result = await self._connection.fetch(_get)
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model GET over {table}: {e}") from e
+
+    async def _select_(self, *args, **kwargs):
+        """
+        Get a query from Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            schema = ""
+            sc = model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        if args:
+            condition = "{}".join(args)
+        else:
+            condition = None
+        if "fields" in kwargs:
+            columns = ",".join(kwargs["fields"])
+        else:
+            columns = "*"
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            result = await self._connection.fetch(_get)
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model SELECT over {table}: {e}") from e
+
+    async def _get_(self, _model: Model, *args, **kwargs):
+        """
+        Get one row from model.
+        """
+        try:
+            schema = ""
+            sc = _model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        if args:
+            columns = ",".join(args)
+        else:
+            columns = ",".join(fields)  # getting only selected fields
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            result = await self._connection.fetchrow(_get)
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model GET over {table}: {e}") from e
+
+    async def _all_(self, _model: Model, *args, **kwargs):  # pylint: disable=W0613
+        """
+        Get all rows on a Model.
+        """
+        try:
+            schema = ""
+            # sc = _model.Meta.schema
+            if sc := _model.Meta.schema:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        if "fields" in kwargs:
+            columns = ",".join(kwargs["fields"])
+        else:
+            columns = "*"
+        _all = f"SELECT {columns} FROM {table}"
+        try:
+            result = await self._connection.fetch(_all)
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model All over {table}: {e}") from e
+
+    async def _remove_(self, _model: Model, **kwargs):
+        """
+        Deleting some records using Model.
+        """
+        try:
+            schema = ""
+            if sc := _model.Meta.schema:
+                schema = f"{sc}."
+            table = f"{schema}{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        for name, field in fields.items():
+            datatype = field.type
+            if name in kwargs:
+                val = kwargs[name]
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _delete = f"DELETE FROM {table} {condition}"
+        try:
+            self._logger.debug(f"DELETE: {_delete}")
+            result = await self._connection.execute(_delete)
+            return f"DELETE {result}: {_filter!s}"
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _updating_(self, *args, _filter: dict = None, **kwargs):
+        """
+        Updating records using Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            schema = ""
+            sc = model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        fields = model.columns(model)
+        if _filter is None:
+            if args:
+                _filter = args[0]
+        cols = []
+        source = []
+        new_cond = {}
+        n = 1
+        for name, field in fields.items():
+            try:
+                val = kwargs[name]
+            except (KeyError, AttributeError):
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            source.append(value)
+            if name in _filter:
+                new_cond[name] = value
+            cols.append("{} = {}".format(name, "${}".format(n)))  # pylint: disable=C0209
+            n += 1
+        try:
+            set_fields = ", ".join(cols)
+            condition = self._where(fields, **_filter)
+            _update = f"UPDATE {table} SET {set_fields} {condition}"
+            self._logger.debug(f"UPDATE: {_update}")
+            stmt = await self._connection.prepare(_update)
+            result = await stmt.fetchrow(*source, timeout=2)
+            self._logger.debug(stmt.get_statusmsg())
+            print(f"UPDATE {result}: {_filter!s}")
+
+            new_conditions = {**_filter, **new_cond}
+            condition = self._where(fields, **new_conditions)
+
+            _all = f"SELECT * FROM {table} {condition}"
+            if result := await self._connection.fetch(_all):
+                return [model(**dict(r)) for r in result]
+        except Exception as err:
+            raise DriverError(message=f"Error on UPDATE over table {model.Meta.name}: {err!s}") from err
+
+    async def _deleting_(self, *args, _filter: dict = None, **kwargs):
+        """
+        Deleting records using Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            schema = ""
+            sc = model.Meta.schema
+            if sc:
+                schema = f"{sc}."
+            table = f"{schema}{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        fields = model.columns(model)
+        if _filter is None:
+            if args:
+                _filter = args[0]
+        cols = []
+        source = []
+        new_cond = {}
+        n = 1
+        for name, field in fields.items():
+            try:
+                val = kwargs[name]
+            except (KeyError, AttributeError):
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            source.append(value)
+            if name in _filter:
+                new_cond[name] = value
+            cols.append("{} = {}".format(name, "${}".format(n)))  # pylint: disable=C0209
+            n += 1
+        try:
+            condition = self._where(fields, **_filter)
+            _delete = f"DELETE FROM {table} {condition}"
+            self._logger.debug(f"DELETE: {_delete}")
+            stmt = await self._connection.prepare(_delete)
+            result = await stmt.fetchrow(*source, timeout=2)
+            self._logger.debug(stmt.get_statusmsg())
+            print(f"DELETE {result}: {_filter!s}")
+
+            new_conditions = {**_filter, **new_cond}
+            condition = self._where(fields, **new_conditions)
+
+            _all = f"SELECT * FROM {table} {condition}"
+            if result := await self._connection.fetch(_all):
+                return [model(**dict(r)) for r in result]
+        except Exception as err:
+            raise DriverError(message=f"Error on DELETE over table {model.Meta.name}: {err!s}") from err
```

## asyncdb/drivers/mcache.py

```diff
@@ -1,189 +1,194 @@
-#!/usr/bin/env python3
-""" memcache no-async Provider.
-Notes on memcache Provider
---------------------
-This provider implements a simple subset of funcionalities from aiomcache, this is a WIP
-TODO: add Thread Pool Support.
-"""
-import asyncio
-import time
-from typing import Any
-import pylibmc
-from asyncdb.exceptions import DriverError
-from .abstract import (
-    InitDriver,
-)
-
-
-class mcache(InitDriver):
-    _provider = "memcache"
-    _syntax = "nosql"
-    _behaviors = {"tcp_nodelay": True, "ketama": True}
-
-    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        super(mcache, self).__init__(loop=loop, params=params, **kwargs)
-        try:
-            host = params["host"]
-        except KeyError as ex:
-            raise DriverError("Memcache: Unable to find *host* in parameters.") from ex
-        try:
-            port = params["port"]
-        except KeyError:
-            port = 11211
-        self._server = [f"{host}:{port}"]
-        try:
-            if kwargs["behaviors"]:
-                self._behaviors = {**self._behaviors, **kwargs["behaviors"]}
-        except KeyError:
-            pass
-
-    ### Context magic Methods
-    def __enter__(self):
-        return self
-
-    def __exit__(self, *args):
-        self.release()
-
-    # Create a memcache Connection
-    def connection(self):  # pylint: disable=W0236
-        """
-        __init Memcache initialization.
-        """
-        self._logger.info(f"Memcache: Connecting to {self._server}")
-        try:
-            self._connection = pylibmc.Client(self._server, binary=True, behaviors=self._behaviors)
-        except pylibmc.Error as err:
-            raise DriverError(message=f"Connection Error: {err}") from err
-        except Exception as err:
-            raise DriverError(message=f"Unknown Memcache Error: {err}") from err
-        # is connected
-        if self._connection:
-            self._connected = True
-            self._initialized_on = time.time()
-        return self
-
-    def release(self):
-        """
-        Release all connections
-        """
-        self._connection.disconnect_all()
-
-    def close(self):  # pylint: disable=W0221,W0236
-        """
-        Closing memcache Connection
-        """
-        try:
-            self._connection.disconnect_all()
-        except pylibmc.Error as err:
-            raise DriverError(f"Close Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Memcache Closing Error: {err}") from err
-
-    disconnect = close
-
-    def flush(self):
-        """
-        Flush all elements inmediately
-        """
-        try:
-            if self._connection:
-                self._connection.flush_all()
-        except pylibmc.Error as err:
-            raise DriverError(f"Close Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Memcache Error: {err}") from err
-
-    def test_connection(self, key: str = "test_123", optional: int = 1):  # pylint: disable=W0221,W0236
-        result = None
-        error = None
-        try:
-            self.set(key, optional)
-            result = self.get(key)
-        except Exception as err:  # pylint: disable=W0703
-            error = err
-        finally:
-            self.delete(key)
-            return [result, error]  # pylint: disable=W0150
-
-    def execute(self, sentence: Any):  # pylint: disable=W0221,W0236
-        raise NotImplementedError
-
-    async def execute_many(self, sentence=""):  # pylint: disable=W0221,W0236
-        raise NotImplementedError
-
-    async def prepare(self, sentence=""):
-        raise NotImplementedError
-
-    async def use(self, database=""):
-        raise NotImplementedError
-
-    def query(self, key: str, *val):  # pylint: disable=W0221,W0236
-        return self.get_multi(key, val)
-
-    fetch_all = query
-
-    def queryrow(self, key: str, *args):  # pylint: disable=W0221,W0236
-        return self.get(key, *args)
-
-    fetch_one = queryrow
-
-    def set(self, key, value, timeout=None):
-        try:
-            if timeout:
-                return self._connection.set(bytes(key, "utf-8"), bytes(value, "utf-8"), time=timeout)
-            else:
-                return self._connection.set(bytes(key, "utf-8"), bytes(value, "utf-8"))
-        except pylibmc.Error as err:
-            raise DriverError(f"Set Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Memcache Unknown Error: {err}") from err
-
-    def set_multi(self, mapping, timeout=0):
-        try:
-            self._connection.set_multi(mapping, timeout)
-        except pylibmc.Error as err:
-            raise DriverError(f"Set Memcache Error: {err}") from err
-
-    def get(self, key, default=None):
-        try:
-            result = self._connection.get(bytes(key, "utf-8"), default)
-            if result:
-                return result.decode("utf-8")
-            else:
-                return None
-        except pylibmc.Error as err:
-            raise DriverError(f"Get Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Memcache Unknown Error: {err}") from err
-
-    def get_multi(self, *kwargs):
-        return self.multiget(kwargs)
-
-    def delete(self, key):
-        try:
-            return self._connection.delete(bytes(key, "utf-8"))
-        except pylibmc.Error as err:
-            raise DriverError(f"DELETE Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"DELETE Unknown Error: {err}") from err
-
-    def delete_multi(self, *kwargs):
-        try:
-            ky = [bytes(key, "utf-8") for key in kwargs]
-            result = self._connection.delete_multi(ky)
-            return result
-        except pylibmc.Error as err:
-            raise DriverError(f"DELETE Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"DELETE Unknown Error: {err}") from err
-
-    def multiget(self, *kwargs):
-        try:
-            ky = [bytes(key, "utf-8") for key in kwargs]
-            result = self._connection.get_multi(ky)
-            if result:
-                return {key.decode("utf-8"): value for key, value in result.items()}
-        except pylibmc.Error as err:
-            raise DriverError(f"MULTI Memcache Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"MULTI Unknown Error: {err}") from err
+#!/usr/bin/env python3
+""" memcache no-async Provider.
+Notes on memcache Provider
+--------------------
+This provider implements a simple subset of funcionalities from aiomcache, this is a WIP
+TODO: add Thread Pool Support.
+"""
+import asyncio
+import time
+from typing import Any
+import pylibmc
+from ..exceptions import DriverError
+from .abstract import (
+    InitDriver,
+)
+
+
+class mcache(InitDriver):
+    _provider = "memcache"
+    _syntax = "nosql"
+    _behaviors = {"tcp_nodelay": True, "ketama": True}
+
+    def __init__(
+        self,
+        loop: asyncio.AbstractEventLoop = None,
+        params: dict = None,
+        **kwargs
+    ) -> None:
+        super(mcache, self).__init__(loop=loop, params=params, **kwargs)
+        try:
+            host = params["host"]
+        except KeyError as ex:
+            raise DriverError("Memcache: Unable to find *host* in parameters.") from ex
+        try:
+            port = params["port"]
+        except KeyError:
+            port = 11211
+        self._server = [f"{host}:{port}"]
+        try:
+            if kwargs["behaviors"]:
+                self._behaviors = {**self._behaviors, **kwargs["behaviors"]}
+        except KeyError:
+            pass
+
+    ### Context magic Methods
+    def __enter__(self):
+        return self
+
+    def __exit__(self, *args):
+        self.release()
+
+    # Create a memcache Connection
+    def connection(self):  # pylint: disable=W0236
+        """
+        __init Memcache initialization.
+        """
+        self._logger.info(f"Memcache: Connecting to {self._server}")
+        try:
+            self._connection = pylibmc.Client(self._server, binary=True, behaviors=self._behaviors)
+        except pylibmc.Error as err:
+            raise DriverError(message=f"Connection Error: {err}") from err
+        except Exception as err:
+            raise DriverError(message=f"Unknown Memcache Error: {err}") from err
+        # is connected
+        if self._connection:
+            self._connected = True
+            self._initialized_on = time.time()
+        return self
+
+    def release(self):
+        """
+        Release all connections
+        """
+        self._connection.disconnect_all()
+
+    def close(self):  # pylint: disable=W0221,W0236
+        """
+        Closing memcache Connection
+        """
+        try:
+            self._connection.disconnect_all()
+        except pylibmc.Error as err:
+            raise DriverError(f"Close Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Memcache Closing Error: {err}") from err
+
+    disconnect = close
+
+    def flush(self):
+        """
+        Flush all elements inmediately
+        """
+        try:
+            if self._connection:
+                self._connection.flush_all()
+        except pylibmc.Error as err:
+            raise DriverError(f"Close Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Memcache Error: {err}") from err
+
+    def test_connection(self, key: str = "test_123", optional: int = 1):  # pylint: disable=W0221,W0236
+        result = None
+        error = None
+        try:
+            self.set(key, optional)
+            result = self.get(key)
+        except Exception as err:  # pylint: disable=W0703
+            error = err
+        finally:
+            self.delete(key)
+            return [result, error]  # pylint: disable=W0150
+
+    def execute(self, sentence: Any):  # pylint: disable=W0221,W0236
+        raise NotImplementedError
+
+    async def execute_many(self, sentence=""):  # pylint: disable=W0221,W0236
+        raise NotImplementedError
+
+    async def prepare(self, sentence=""):
+        raise NotImplementedError
+
+    async def use(self, database=""):
+        raise NotImplementedError
+
+    def query(self, key: str, *val):  # pylint: disable=W0221,W0236
+        return self.get_multi(key, val)
+
+    fetch_all = query
+
+    def queryrow(self, key: str, *args):  # pylint: disable=W0221,W0236
+        return self.get(key, *args)
+
+    fetch_one = queryrow
+
+    def set(self, key, value, timeout=None):
+        try:
+            if timeout:
+                return self._connection.set(bytes(key, "utf-8"), bytes(value, "utf-8"), time=timeout)
+            else:
+                return self._connection.set(bytes(key, "utf-8"), bytes(value, "utf-8"))
+        except pylibmc.Error as err:
+            raise DriverError(f"Set Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Memcache Unknown Error: {err}") from err
+
+    def set_multi(self, mapping, timeout=0):
+        try:
+            self._connection.set_multi(mapping, timeout)
+        except pylibmc.Error as err:
+            raise DriverError(f"Set Memcache Error: {err}") from err
+
+    def get(self, key, default=None):
+        try:
+            result = self._connection.get(bytes(key, "utf-8"), default)
+            if result:
+                return result.decode("utf-8")
+            else:
+                return None
+        except pylibmc.Error as err:
+            raise DriverError(f"Get Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Memcache Unknown Error: {err}") from err
+
+    def get_multi(self, *kwargs):
+        return self.multiget(kwargs)
+
+    def delete(self, key):
+        try:
+            return self._connection.delete(bytes(key, "utf-8"))
+        except pylibmc.Error as err:
+            raise DriverError(f"DELETE Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"DELETE Unknown Error: {err}") from err
+
+    def delete_multi(self, *kwargs):
+        try:
+            ky = [bytes(key, "utf-8") for key in kwargs]
+            result = self._connection.delete_multi(ky)
+            return result
+        except pylibmc.Error as err:
+            raise DriverError(f"DELETE Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"DELETE Unknown Error: {err}") from err
+
+    def multiget(self, *kwargs):
+        try:
+            ky = [bytes(key, "utf-8") for key in kwargs]
+            result = self._connection.get_multi(ky)
+            if result:
+                return {key.decode("utf-8"): value for key, value in result.items()}
+        except pylibmc.Error as err:
+            raise DriverError(f"MULTI Memcache Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"MULTI Unknown Error: {err}") from err
```

## asyncdb/drivers/postgres.py

```diff
@@ -1,606 +1,606 @@
-""" postgres PostgreSQL Provider.
-Notes on pg Provider
---------------------
-This provider implements all funcionalities from asyncpg
-(cursors, transactions, copy from and to files, pools, native data types, etc)
-but using Threads.
-"""
-import os
-import asyncio
-import json
-import threading
-import time
-from threading import Thread
-from typing import Any, Optional
-from collections.abc import Iterable
-from dateutil.relativedelta import relativedelta
-import asyncpg
-import uvloop
-from asyncpg.exceptions import (
-    ConnectionDoesNotExistError,
-    InterfaceError,
-    InterfaceWarning,
-    InternalClientError,
-    PostgresError,
-    PostgresSyntaxError,
-    TooManyConnectionsError,
-    UndefinedColumnError,
-    InvalidSQLStatementNameError,
-    UndefinedTableError,
-)
-from asyncdb.exceptions import (
-    UninitializedError,
-    EmptyStatement,
-    ConnectionTimeout,
-    NoDataFound,
-    DriverError,
-    StatementError,
-    TooManyConnections,
-)
-
-from asyncdb.utils.encoders import (
-    BaseEncoder,
-)
-from asyncdb.meta import Recordset
-from .sql import SQLDriver
-
-# from .abstract import BaseCursor
-
-
-asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
-uvloop.install()
-
-
-class postgres(threading.Thread, SQLDriver):
-    _provider = "postgres"
-    _syntax = "sql"
-    _test_query = "SELECT 1"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._dsn = "postgres://{user}:{password}@{host}:{port}/{database}"
-        self.application_name = os.getenv("APP_NAME", "NAV")
-        self._is_started = False
-        self._error = None
-        self._params = params
-        self._result = None
-        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
-        if loop:
-            self._loop = loop
-        else:
-            self._loop = asyncio.new_event_loop()
-        asyncio.set_event_loop(self._loop)
-        # calling parent Thread
-        Thread.__init__(self, name=self._provider)
-        self.stop_event = threading.Event()
-
-    def get_connection(self):
-        self.join(timeout=self._timeout)
-        return self._connection
-
-    ## Thread Methodss
-    def start(self, target=None, args=()):
-        if target:
-            Thread.__init__(self, target=target, args=args)
-        else:
-            Thread.__init__(self, name="postgres")
-        super(postgres, self).start()
-
-    def join(self, timeout=5):
-        super(postgres, self).join(timeout=timeout)
-
-    def stop(self):
-        self.stop_event.set()
-
-    ## Async Context magic Methods
-    async def __aenter__(self):
-        if not self._connection:
-            await self.connection()
-        return self
-
-    async def __aexit__(self, exc_type, exc, tb):
-        # clean up anything you need to clean up
-        await self.close(timeout=5)
-
-    ### Context magic Methods
-    def __enter__(self):
-        return self
-
-    def __exit__(self, _type, value, traceback, *args):
-        self.start(target=self.release)
-        self.stop()
-        self.join(timeout=self._timeout)
-
-    async def init_connection(self, connection):
-        # Setup jsonb encoder/decoder
-        def _encoder(value):
-            return json.dumps(value, cls=BaseEncoder)
-
-        def _decoder(value):
-            return json.loads(value)
-
-        def interval_encoder(delta):
-            ndelta = delta.normalized()
-            return (
-                ndelta.years * 12 + ndelta.months,
-                ndelta.days,
-                ((ndelta.hours * 3600 + ndelta.minutes * 60 + ndelta.seconds) * 1000000 + ndelta.microseconds),
-            )
-
-        def interval_decoder(tup):
-            return relativedelta(months=tup[0], days=tup[1], microseconds=tup[2])
-
-        await connection.set_type_codec("json", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
-        await connection.set_type_codec("jsonb", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
-        await connection.set_builtin_type_codec("hstore", codec_name="pg_contrib.hstore")
-        await connection.set_type_codec(
-            "interval",
-            schema="pg_catalog",
-            encoder=interval_encoder,
-            decoder=interval_decoder,
-            format="tuple",
-        )
-        if self._init_func and callable(self._init_func):
-            try:
-                await self._init_func(connection)  # pylint: disable=E1102
-            except (RuntimeError, ValueError) as err:
-                self._logger.debug(f"Error on Init Connection: {err}")
-
-    def disconnect(self):
-        if self._loop.is_running():
-            self._loop.stop()
-        self._loop.close()
-        # finish the main thread
-        try:
-            self.join(timeout=5)
-        finally:
-            self._connection = None
-            self._connected = False
-
-    terminate = disconnect
-
-    def is_closed(self):
-        return not self._connection
-
-    def connect(self):
-        """
-        connect.
-
-        sync-version of connection, for use with sync-methods
-        """
-        self._connection = None
-        self._connected = False
-        if not self._is_started:
-            self.start(target=self._connect)  # start a thread
-            self._is_started = True
-            self.join(timeout=self._timeout)
-            self._connected = True
-        return self
-
-    open = connect
-
-    def _connect(self):
-        if not self._connection:
-            self._loop.run_until_complete(self.connection())
-
-    async def connection(self):
-        """
-        connection.
-
-        Get a connection from DB
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            self._connection = await asyncpg.connect(
-                dsn=self._dsn,
-                loop=self._loop,
-                command_timeout=self._timeout,
-                timeout=self._timeout,
-            )
-            if self._connection:
-                await self.init_connection(self._connection)
-                self._connected = True
-                self._initialized_on = time.time()
-            return self
-        except ConnectionRefusedError as err:
-            raise UninitializedError(f"Unable to connect to database, connection Refused: {err}") from err
-        except TooManyConnectionsError as err:
-            self._logger.error(f"Too Many Connections Error: {err}")
-            raise TooManyConnections(f"Too Many Connections Error: {err}") from err
-        except TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to database: {err}") from err
-        except ConnectionDoesNotExistError as err:
-            raise DriverError(f"Connection Error: {err}") from err
-        except ConnectionError as ex:
-            self._logger.error(f"Connection Error: {ex}")
-            raise UninitializedError(f"Connection Error: {ex}") from ex
-        except InternalClientError as err:
-            raise DriverError(f"Internal Error: {err}") from err
-        except InterfaceError as err:
-            raise DriverError(f"Interface Error: {err}") from err
-        except InterfaceWarning as err:
-            self._logger.warning(f"Interface Warning: {err}")
-            return False
-        except Exception as ex:
-            self._logger.exception(f"Asyncpg Unknown Error: {ex}", stack_info=True)
-            raise DriverError(f"Asyncpg Unknown Error: {ex}") from ex
-        finally:
-            if not self._is_started:
-                self.start()  # start a thread
-                self._is_started = True
-
-    async def close(self, timeout=5):
-        """
-        close.
-            Closing a Connection
-        """
-        try:
-            if self._connection:
-                if not self._connection.is_closed():
-                    await self._connection.close(timeout=timeout)
-                    self.join(timeout=timeout)
-        except InterfaceError as err:
-            raise DriverError(f"Close Error: {err}") from err
-        except Exception as err:
-            await self._connection.terminate()
-            self._connection = None
-            raise DriverError(f"Connection Error, Terminated: {err}") from err
-        finally:
-            self._connection = None
-            self._connected = False
-
-    def release(self, wait_close=10):
-        """
-        Release a Connection
-        """
-        if self._connection:
-            try:
-                if not self._connection.is_closed():
-                    self._loop.run_until_complete(self._connection.close(timeout=wait_close))
-            except (InterfaceError, RuntimeError) as err:
-                raise DriverError(message=f"Release Interface Error: {err!s}") from err
-            except Exception as err:
-                raise DriverError(f"Connection Error, Terminated: {err}") from err
-            finally:
-                self._connected = False
-                self._connection = None
-
-    @property
-    def connected(self):
-        if self._connection:
-            return not self._connection.is_closed()
-
-    async def prepare(self, sentence: Any, *args):
-        """
-        Preparing a sentence
-        """
-        stmt = None
-        error = None
-        self._columns = []
-        if not self._connection:
-            await self.connection()
-        try:
-            stmt = await self._connection.prepare(sentence, *args)
-            self._columns = [a.name for a in stmt.get_attributes()]
-            self._prepared = stmt
-        except RuntimeError as err:
-            raise DriverError(f"Runtime on Query Row Error: {err}") from err
-        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
-            raise StatementError(f"Sentence on Query Row Error: {err}") from err
-        except PostgresError as err:
-            raise DriverError(f"Postgres Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on prepare Row: {err}") from err
-        finally:
-            return [self._prepared, error]  # pylint: disable=W0150
-
-    async def columns(self, sentence, *args):  # pylint: disable=W0236,W0221
-        self._columns = []
-        if not self._connection:
-            await self.connection()
-        try:
-            stmt = await self._connection.prepare(sentence, *args)
-            self._columns = [a.name for a in stmt.get_attributes()]
-        except RuntimeError as err:
-            raise DriverError(f"Runtime on Query Row Error: {err}") from err
-        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
-            raise StatementError(f"Sentence Error: {err}") from err
-        except PostgresError as err:
-            raise DriverError(f"Postgres Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Column: {err}") from err
-
-    async def query(self, sentence: Any, **kwargs):
-        """
-        Query.
-
-            Make a query to DB
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            self._result = await self._connection.fetch(sentence)
-            if not self._result:
-                return [None, NoDataFound("No data was found")]
-        except RuntimeError as err:
-            raise DriverError(f"Runtime on Query Error: {err}") from err
-        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
-            raise StatementError(f"Sentence Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Query: {err}") from err
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def queryrow(self, sentence: Any):
-        """
-        queryrow.
-
-            Make a query to DB returning only one row
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            stmt = await self._connection.prepare(sentence)
-            self._columns = [a.name for a in stmt.get_attributes()]
-            self._result = await stmt.fetchrow()
-        except RuntimeError as err:
-            raise DriverError(f"Runtime on Query Row Error: {err}") from err
-        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
-            raise StatementError(f"Sentence Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Query Row: {err}") from err
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def execute(self, sentence: Any, *args, **kwargs):
-        """execute.
-
-        Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        self._error = None
-        self._result = None
-        if not sentence:
-            raise EmptyStatement("Sentence is an empty string")
-        if not self._connection:
-            await self.connection()
-        try:
-            self._result = await self._connection.execute(sentence, *args)
-            return [self._result, None]
-        except RuntimeError as err:
-            raise DriverError(f"Runtime on Execute Error: {err}") from err
-        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
-            raise StatementError(f"Execute Sentence Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Execute: {err}") from err
-        finally:
-            return [self._result, self._error]  # pylint: disable=W0150
-
-    async def execute_many(self, sentence: Any, *args, timeout=None):
-        """execute.
-
-        Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        self._error = None
-        self._result = None
-        if not sentence:
-            raise EmptyStatement("Sentence is an empty string")
-        if not self._connection:
-            await self.connection()
-        try:
-            async with self._connection.transaction():
-                await self._connection.executemany(sentence, timeout=timeout, *args)
-            return [True, None]
-        except RuntimeError as err:
-            raise DriverError(f"Runtime on Execute Error: {err}") from err
-        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
-            raise StatementError(f"Execute Sentence Error: {err}") from err
-        except Exception as err:
-            raise Exception(f"Error on Execute: {err}") from err
-        finally:
-            return [True, self._error]  # pylint: disable=W0150
-
-    executemany = execute_many
-
-    """
-    Transaction Context
-    """
-
-    async def transaction(self):
-        if not self._connection:
-            await self.connection()
-        self._transaction = self._connection.transaction()
-        await self._transaction.start()
-        return self
-
-    async def commit(self):
-        if self._transaction:
-            await self._transaction.commit()
-
-    async def rollback(self):
-        if self._transaction:
-            await self._transaction.rollback()
-
-    ### Cursor Context
-    async def cursor(self, sentence):
-        if not sentence:
-            raise EmptyStatement("Sentence is an empty string")
-        if not self._connection:
-            await self.connection()
-        self._transaction = self._connection.transaction()
-        await self._transaction.start()
-        self._cursor = await self._connection.cursor(sentence)
-        return self
-
-    async def forward(self, number):
-        try:
-            return await self._cursor.forward(number)
-        except Exception as err:
-            raise Exception(f"Error forward Cursor: {err}") from err
-
-    async def get(self, number=1):
-        try:
-            return await self._cursor.fetch(number)
-        except Exception as err:
-            raise Exception(f"Error Fetch Cursor: {err}") from err
-
-    async def getrow(self):
-        try:
-            return await self._cursor.fetchrow()
-        except Exception as err:
-            raise Exception(f"Error Fetchrow Cursor: {err}") from err
-
-    ### Cursor Iterator Context
-    def __aiter__(self):
-        return self
-
-    async def __anext__(self):
-        data = await self._cursor.fetchrow()
-        if data is not None:
-            return data
-        else:
-            raise StopAsyncIteration
-
-    ### Non-Async Methods
-    async def test_connection(self, **kwargs):
-        result = None
-        error = None
-        try:
-            result = await self.queryrow(self._test_query)
-        except Exception as err:  # pylint: disable=W0703
-            error = err
-        return [result, error]
-
-    def _test_connection(self):
-        self._error = None
-        self._result = None
-        self.start(target=self._fetchone, args=(self._test_query,))
-        self.join(timeout=self._timeout)
-        return [self._result, self._error]
-
-    def perform(self, sentence):
-        self.start(target=self._execute, args=(sentence,))
-        if self.is_alive():
-            self.join(timeout=self._timeout)
-            return [self._result, self._error]
-
-    def _execute(self, sentence):
-        self._error = None
-        self._result = None
-        return self._loop.run_until_complete(self.execute(sentence))
-
-    def fetchall(self, sentence):
-        self.start(target=self._fetchall, args=(sentence,))
-        if self.is_alive():
-            self.join(timeout=self._timeout)
-            return [self._result, self._error]
-
-    fetch_all = fetchall
-
-    def _fetchall(self, sentence):
-        self._error = None
-        self._result = None
-        try:
-            stmt, error = self._loop.run_until_complete(self.prepare(sentence))
-            self._error = error
-            if stmt:
-                result = self._loop.run_until_complete(stmt.fetch())
-                self._result = Recordset(result=result, columns=self._columns)
-        except RuntimeError as err:
-            self._error = f"Fetch Error: {err}"
-            raise DriverError(message=self._error) from err
-        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
-            raise StatementError(f"Execute Sentence Error: {err}") from err
-        except PostgresError as err:
-            raise DriverError(f"Error on Fetch: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Error on Execute: {err}") from err
-        finally:
-            return [self._result, self._error]  # pylint: disable=W0150
-
-    def fetchone(self, sentence):
-        self.start(target=self._fetchone, args=(sentence,))
-        self.join(timeout=self._timeout)
-        return [self._result, self._error]
-
-    fetch_one = fetchone
-
-    def _fetchone(self, sentence):
-        self._error = None
-        self._result = None
-        try:
-            row = self._loop.run_until_complete(self._connection.fetchrow(sentence))
-            if row:
-                self._result = row
-        except Exception as err:
-            self._error = f"Error on Query Row: {err}"
-            raise Exception(self._error) from err
-        finally:
-            return [self._result, self._error]  # pylint: disable=W0150
-
-    ### Model Logic:
-    async def column_info(self, tablename: str, schema: str = None):
-        """Column Info.
-
-        Get Meta information about a table (column name, data type and PK).
-        Useful to build a DataModel from Querying database.
-        Parameters:
-        @tablename: str The name of the table (including schema).
-        """
-        if schema:
-            table = f"{schema}.{tablename}"
-        else:
-            table = tablename
-        sql = f"SELECT a.attname AS name, a.atttypid::regtype AS type, \
-        format_type(a.atttypid, a.atttypmod) as format_type, a.attnotnull::boolean as notnull, \
-        coalesce((SELECT true FROM pg_index i WHERE i.indrelid = a.attrelid \
-        AND i.indrelid = a.attrelid AND a.attnum = any(i.indkey) \
-        AND i.indisprimary), false) as is_primary \
-        FROM pg_attribute a WHERE a.attrelid = '{table!s}'::regclass \
-        AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum"
-        if not self._connection:
-            await self.connection()
-        try:
-            colinfo = await self._connection.fetch(sql)
-            return colinfo
-        except Exception as err:  # pylint: disable=W0703
-            self._logger.exception(f"Wrong Table information {tablename!s}: {err}")
-
-    ### DDL Information.
-    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
-        """
-        Create is a generic method for Database Objects Creation.
-        """
-        if obj == "table":
-            sql = "CREATE TABLE {name}({columns});"
-            columns = ", ".join(["{name} {type}".format(**e) for e in fields])  # pylint: disable=C0209
-            sql = sql.format(name=name, columns=columns)
-            try:
-                result = await self._connection.execute(sql)
-                if result:
-                    await self._connection.commit()
-                    return True
-                else:
-                    return False
-            except Exception as err:
-                raise DriverError(f"Error in Object Creation: {err!s}") from err
-        else:
-            raise RuntimeError(f"Pg: invalid Object type {object!s}")
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    async def use(self, database: str):
-        raise NotImplementedError("AsyncPg Error: You cannot change database on realtime.")
+""" postgres PostgreSQL Provider.
+Notes on pg Provider
+--------------------
+This provider implements all funcionalities from asyncpg
+(cursors, transactions, copy from and to files, pools, native data types, etc)
+but using Threads.
+"""
+import os
+import asyncio
+import json
+import threading
+import time
+from threading import Thread
+from typing import Any, Optional
+from collections.abc import Iterable
+from dateutil.relativedelta import relativedelta
+import asyncpg
+import uvloop
+from asyncpg.exceptions import (
+    ConnectionDoesNotExistError,
+    InterfaceError,
+    InterfaceWarning,
+    InternalClientError,
+    PostgresError,
+    PostgresSyntaxError,
+    TooManyConnectionsError,
+    UndefinedColumnError,
+    InvalidSQLStatementNameError,
+    UndefinedTableError,
+)
+from ..exceptions import (
+    UninitializedError,
+    EmptyStatement,
+    ConnectionTimeout,
+    NoDataFound,
+    DriverError,
+    StatementError,
+    TooManyConnections,
+)
+
+from ..utils.encoders import (
+    BaseEncoder,
+)
+from ..meta import Recordset
+from .sql import SQLDriver
+
+# from .abstract import BaseCursor
+
+
+asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
+uvloop.install()
+
+
+class postgres(threading.Thread, SQLDriver):
+    _provider = "postgres"
+    _syntax = "sql"
+    _test_query = "SELECT 1"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._dsn = "postgres://{user}:{password}@{host}:{port}/{database}"
+        self.application_name = os.getenv("APP_NAME", "NAV")
+        self._is_started = False
+        self._error = None
+        self._params = params
+        self._result = None
+        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
+        if loop:
+            self._loop = loop
+        else:
+            self._loop = asyncio.new_event_loop()
+        asyncio.set_event_loop(self._loop)
+        # calling parent Thread
+        Thread.__init__(self, name=self._provider)
+        self.stop_event = threading.Event()
+
+    def get_connection(self):
+        self.join(timeout=self._timeout)
+        return self._connection
+
+    ## Thread Methodss
+    def start(self, target=None, args=()):
+        if target:
+            Thread.__init__(self, target=target, args=args)
+        else:
+            Thread.__init__(self, name="postgres")
+        super(postgres, self).start()
+
+    def join(self, timeout=5):
+        super(postgres, self).join(timeout=timeout)
+
+    def stop(self):
+        self.stop_event.set()
+
+    ## Async Context magic Methods
+    async def __aenter__(self):
+        if not self._connection:
+            await self.connection()
+        return self
+
+    async def __aexit__(self, exc_type, exc, tb):
+        # clean up anything you need to clean up
+        await self.close(timeout=5)
+
+    ### Context magic Methods
+    def __enter__(self):
+        return self
+
+    def __exit__(self, _type, value, traceback, *args):
+        self.start(target=self.release)
+        self.stop()
+        self.join(timeout=self._timeout)
+
+    async def init_connection(self, connection):
+        # Setup jsonb encoder/decoder
+        def _encoder(value):
+            return json.dumps(value, cls=BaseEncoder)
+
+        def _decoder(value):
+            return json.loads(value)
+
+        def interval_encoder(delta):
+            ndelta = delta.normalized()
+            return (
+                ndelta.years * 12 + ndelta.months,
+                ndelta.days,
+                ((ndelta.hours * 3600 + ndelta.minutes * 60 + ndelta.seconds) * 1000000 + ndelta.microseconds),
+            )
+
+        def interval_decoder(tup):
+            return relativedelta(months=tup[0], days=tup[1], microseconds=tup[2])
+
+        await connection.set_type_codec("json", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
+        await connection.set_type_codec("jsonb", encoder=_encoder, decoder=_decoder, schema="pg_catalog")
+        await connection.set_builtin_type_codec("hstore", codec_name="pg_contrib.hstore")
+        await connection.set_type_codec(
+            "interval",
+            schema="pg_catalog",
+            encoder=interval_encoder,
+            decoder=interval_decoder,
+            format="tuple",
+        )
+        if self._init_func and callable(self._init_func):
+            try:
+                await self._init_func(connection)  # pylint: disable=E1102
+            except (RuntimeError, ValueError) as err:
+                self._logger.debug(f"Error on Init Connection: {err}")
+
+    def disconnect(self):
+        if self._loop.is_running():
+            self._loop.stop()
+        self._loop.close()
+        # finish the main thread
+        try:
+            self.join(timeout=5)
+        finally:
+            self._connection = None
+            self._connected = False
+
+    terminate = disconnect
+
+    def is_closed(self):
+        return not self._connection
+
+    def connect(self):
+        """
+        connect.
+
+        sync-version of connection, for use with sync-methods
+        """
+        self._connection = None
+        self._connected = False
+        if not self._is_started:
+            self.start(target=self._connect)  # start a thread
+            self._is_started = True
+            self.join(timeout=self._timeout)
+            self._connected = True
+        return self
+
+    open = connect
+
+    def _connect(self):
+        if not self._connection:
+            self._loop.run_until_complete(self.connection())
+
+    async def connection(self):
+        """
+        connection.
+
+        Get a connection from DB
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            self._connection = await asyncpg.connect(
+                dsn=self._dsn,
+                loop=self._loop,
+                command_timeout=self._timeout,
+                timeout=self._timeout,
+            )
+            if self._connection:
+                await self.init_connection(self._connection)
+                self._connected = True
+                self._initialized_on = time.time()
+            return self
+        except ConnectionRefusedError as err:
+            raise UninitializedError(f"Unable to connect to database, connection Refused: {err}") from err
+        except TooManyConnectionsError as err:
+            self._logger.error(f"Too Many Connections Error: {err}")
+            raise TooManyConnections(f"Too Many Connections Error: {err}") from err
+        except TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to database: {err}") from err
+        except ConnectionDoesNotExistError as err:
+            raise DriverError(f"Connection Error: {err}") from err
+        except ConnectionError as ex:
+            self._logger.error(f"Connection Error: {ex}")
+            raise UninitializedError(f"Connection Error: {ex}") from ex
+        except InternalClientError as err:
+            raise DriverError(f"Internal Error: {err}") from err
+        except InterfaceError as err:
+            raise DriverError(f"Interface Error: {err}") from err
+        except InterfaceWarning as err:
+            self._logger.warning(f"Interface Warning: {err}")
+            return False
+        except Exception as ex:
+            self._logger.exception(f"Asyncpg Unknown Error: {ex}", stack_info=True)
+            raise DriverError(f"Asyncpg Unknown Error: {ex}") from ex
+        finally:
+            if not self._is_started:
+                self.start()  # start a thread
+                self._is_started = True
+
+    async def close(self, timeout=5):
+        """
+        close.
+            Closing a Connection
+        """
+        try:
+            if self._connection:
+                if not self._connection.is_closed():
+                    await self._connection.close(timeout=timeout)
+                    self.join(timeout=timeout)
+        except InterfaceError as err:
+            raise DriverError(f"Close Error: {err}") from err
+        except Exception as err:
+            await self._connection.terminate()
+            self._connection = None
+            raise DriverError(f"Connection Error, Terminated: {err}") from err
+        finally:
+            self._connection = None
+            self._connected = False
+
+    def release(self, wait_close=10):
+        """
+        Release a Connection
+        """
+        if self._connection:
+            try:
+                if not self._connection.is_closed():
+                    self._loop.run_until_complete(self._connection.close(timeout=wait_close))
+            except (InterfaceError, RuntimeError) as err:
+                raise DriverError(message=f"Release Interface Error: {err!s}") from err
+            except Exception as err:
+                raise DriverError(f"Connection Error, Terminated: {err}") from err
+            finally:
+                self._connected = False
+                self._connection = None
+
+    @property
+    def connected(self):
+        if self._connection:
+            return not self._connection.is_closed()
+
+    async def prepare(self, sentence: Any, *args):
+        """
+        Preparing a sentence
+        """
+        stmt = None
+        error = None
+        self._columns = []
+        if not self._connection:
+            await self.connection()
+        try:
+            stmt = await self._connection.prepare(sentence, *args)
+            self._columns = [a.name for a in stmt.get_attributes()]
+            self._prepared = stmt
+        except RuntimeError as err:
+            raise DriverError(f"Runtime on Query Row Error: {err}") from err
+        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
+            raise StatementError(f"Sentence on Query Row Error: {err}") from err
+        except PostgresError as err:
+            raise DriverError(f"Postgres Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on prepare Row: {err}") from err
+        finally:
+            return [self._prepared, error]  # pylint: disable=W0150
+
+    async def columns(self, sentence, *args):  # pylint: disable=W0236,W0221
+        self._columns = []
+        if not self._connection:
+            await self.connection()
+        try:
+            stmt = await self._connection.prepare(sentence, *args)
+            self._columns = [a.name for a in stmt.get_attributes()]
+        except RuntimeError as err:
+            raise DriverError(f"Runtime on Query Row Error: {err}") from err
+        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
+            raise StatementError(f"Sentence Error: {err}") from err
+        except PostgresError as err:
+            raise DriverError(f"Postgres Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Column: {err}") from err
+
+    async def query(self, sentence: Any, **kwargs):
+        """
+        Query.
+
+            Make a query to DB
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            self._result = await self._connection.fetch(sentence)
+            if not self._result:
+                return [None, NoDataFound("No data was found")]
+        except RuntimeError as err:
+            raise DriverError(f"Runtime on Query Error: {err}") from err
+        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
+            raise StatementError(f"Sentence Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Query: {err}") from err
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def queryrow(self, sentence: Any):
+        """
+        queryrow.
+
+            Make a query to DB returning only one row
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            stmt = await self._connection.prepare(sentence)
+            self._columns = [a.name for a in stmt.get_attributes()]
+            self._result = await stmt.fetchrow()
+        except RuntimeError as err:
+            raise DriverError(f"Runtime on Query Row Error: {err}") from err
+        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
+            raise StatementError(f"Sentence Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Query Row: {err}") from err
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def execute(self, sentence: Any, *args, **kwargs):
+        """execute.
+
+        Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        self._error = None
+        self._result = None
+        if not sentence:
+            raise EmptyStatement("Sentence is an empty string")
+        if not self._connection:
+            await self.connection()
+        try:
+            self._result = await self._connection.execute(sentence, *args)
+            return [self._result, None]
+        except RuntimeError as err:
+            raise DriverError(f"Runtime on Execute Error: {err}") from err
+        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
+            raise StatementError(f"Execute Sentence Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Execute: {err}") from err
+        finally:
+            return [self._result, self._error]  # pylint: disable=W0150
+
+    async def execute_many(self, sentence: Any, *args, timeout=None):
+        """execute.
+
+        Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        self._error = None
+        self._result = None
+        if not sentence:
+            raise EmptyStatement("Sentence is an empty string")
+        if not self._connection:
+            await self.connection()
+        try:
+            async with self._connection.transaction():
+                await self._connection.executemany(sentence, timeout=timeout, *args)
+            return [True, None]
+        except RuntimeError as err:
+            raise DriverError(f"Runtime on Execute Error: {err}") from err
+        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
+            raise StatementError(f"Execute Sentence Error: {err}") from err
+        except Exception as err:
+            raise Exception(f"Error on Execute: {err}") from err
+        finally:
+            return [True, self._error]  # pylint: disable=W0150
+
+    executemany = execute_many
+
+    """
+    Transaction Context
+    """
+
+    async def transaction(self):
+        if not self._connection:
+            await self.connection()
+        self._transaction = self._connection.transaction()
+        await self._transaction.start()
+        return self
+
+    async def commit(self):
+        if self._transaction:
+            await self._transaction.commit()
+
+    async def rollback(self):
+        if self._transaction:
+            await self._transaction.rollback()
+
+    ### Cursor Context
+    async def cursor(self, sentence):
+        if not sentence:
+            raise EmptyStatement("Sentence is an empty string")
+        if not self._connection:
+            await self.connection()
+        self._transaction = self._connection.transaction()
+        await self._transaction.start()
+        self._cursor = await self._connection.cursor(sentence)
+        return self
+
+    async def forward(self, number):
+        try:
+            return await self._cursor.forward(number)
+        except Exception as err:
+            raise Exception(f"Error forward Cursor: {err}") from err
+
+    async def get(self, number=1):
+        try:
+            return await self._cursor.fetch(number)
+        except Exception as err:
+            raise Exception(f"Error Fetch Cursor: {err}") from err
+
+    async def getrow(self):
+        try:
+            return await self._cursor.fetchrow()
+        except Exception as err:
+            raise Exception(f"Error Fetchrow Cursor: {err}") from err
+
+    ### Cursor Iterator Context
+    def __aiter__(self):
+        return self
+
+    async def __anext__(self):
+        data = await self._cursor.fetchrow()
+        if data is not None:
+            return data
+        else:
+            raise StopAsyncIteration
+
+    ### Non-Async Methods
+    async def test_connection(self, **kwargs):
+        result = None
+        error = None
+        try:
+            result = await self.queryrow(self._test_query)
+        except Exception as err:  # pylint: disable=W0703
+            error = err
+        return [result, error]
+
+    def _test_connection(self):
+        self._error = None
+        self._result = None
+        self.start(target=self._fetchone, args=(self._test_query,))
+        self.join(timeout=self._timeout)
+        return [self._result, self._error]
+
+    def perform(self, sentence):
+        self.start(target=self._execute, args=(sentence,))
+        if self.is_alive():
+            self.join(timeout=self._timeout)
+            return [self._result, self._error]
+
+    def _execute(self, sentence):
+        self._error = None
+        self._result = None
+        return self._loop.run_until_complete(self.execute(sentence))
+
+    def fetchall(self, sentence):
+        self.start(target=self._fetchall, args=(sentence,))
+        if self.is_alive():
+            self.join(timeout=self._timeout)
+            return [self._result, self._error]
+
+    fetch_all = fetchall
+
+    def _fetchall(self, sentence):
+        self._error = None
+        self._result = None
+        try:
+            stmt, error = self._loop.run_until_complete(self.prepare(sentence))
+            self._error = error
+            if stmt:
+                result = self._loop.run_until_complete(stmt.fetch())
+                self._result = Recordset(result=result, columns=self._columns)
+        except RuntimeError as err:
+            self._error = f"Fetch Error: {err}"
+            raise DriverError(message=self._error) from err
+        except (PostgresSyntaxError, UndefinedColumnError, InvalidSQLStatementNameError, UndefinedTableError) as err:
+            raise StatementError(f"Execute Sentence Error: {err}") from err
+        except PostgresError as err:
+            raise DriverError(f"Error on Fetch: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Error on Execute: {err}") from err
+        finally:
+            return [self._result, self._error]  # pylint: disable=W0150
+
+    def fetchone(self, sentence):
+        self.start(target=self._fetchone, args=(sentence,))
+        self.join(timeout=self._timeout)
+        return [self._result, self._error]
+
+    fetch_one = fetchone
+
+    def _fetchone(self, sentence):
+        self._error = None
+        self._result = None
+        try:
+            row = self._loop.run_until_complete(self._connection.fetchrow(sentence))
+            if row:
+                self._result = row
+        except Exception as err:
+            self._error = f"Error on Query Row: {err}"
+            raise Exception(self._error) from err
+        finally:
+            return [self._result, self._error]  # pylint: disable=W0150
+
+    ### Model Logic:
+    async def column_info(self, tablename: str, schema: str = None):
+        """Column Info.
+
+        Get Meta information about a table (column name, data type and PK).
+        Useful to build a DataModel from Querying database.
+        Parameters:
+        @tablename: str The name of the table (including schema).
+        """
+        if schema:
+            table = f"{schema}.{tablename}"
+        else:
+            table = tablename
+        sql = f"SELECT a.attname AS name, a.atttypid::regtype AS type, \
+        format_type(a.atttypid, a.atttypmod) as format_type, a.attnotnull::boolean as notnull, \
+        coalesce((SELECT true FROM pg_index i WHERE i.indrelid = a.attrelid \
+        AND i.indrelid = a.attrelid AND a.attnum = any(i.indkey) \
+        AND i.indisprimary), false) as is_primary \
+        FROM pg_attribute a WHERE a.attrelid = '{table!s}'::regclass \
+        AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum"
+        if not self._connection:
+            await self.connection()
+        try:
+            colinfo = await self._connection.fetch(sql)
+            return colinfo
+        except Exception as err:  # pylint: disable=W0703
+            self._logger.exception(f"Wrong Table information {tablename!s}: {err}")
+
+    ### DDL Information.
+    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
+        """
+        Create is a generic method for Database Objects Creation.
+        """
+        if obj == "table":
+            sql = "CREATE TABLE {name}({columns});"
+            columns = ", ".join(["{name} {type}".format(**e) for e in fields])  # pylint: disable=C0209
+            sql = sql.format(name=name, columns=columns)
+            try:
+                result = await self._connection.execute(sql)
+                if result:
+                    await self._connection.commit()
+                    return True
+                else:
+                    return False
+            except Exception as err:
+                raise DriverError(f"Error in Object Creation: {err!s}") from err
+        else:
+            raise RuntimeError(f"Pg: invalid Object type {object!s}")
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    async def use(self, database: str):
+        raise NotImplementedError("AsyncPg Error: You cannot change database on realtime.")
```

## asyncdb/drivers/dummy.py

```diff
@@ -1,67 +1,67 @@
-"""Dummy Driver.
-"""
-from datetime import datetime
-from asyncdb.exceptions import DriverError
-from .abstract import BaseDriver
-
-
-class dummy(BaseDriver):
-    _provider = "dummy"
-    _syntax = "sql"
-
-    def __init__(self, dsn="", loop=None, params: dict = None, **kwargs):
-        self._test_query = "SELECT 1"
-        _starttime = datetime.now()
-        self._dsn = "test:/{host}:{port}/{db}"
-        if not params:
-            params = {"host": "127.0.0.1", "port": "0", "db": 0}
-        try:
-            super(dummy, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-            self._logger.debug(f"Dummy Params are: {params}")
-            _generated = datetime.now() - _starttime
-            print(f"Started in: {_generated}")
-        except Exception as err:
-            raise DriverError(f"Dummy Error: {err}") from err
-
-    async def prepare(self):
-        pass
-
-    async def connection(self):
-        print(f'{self._provider}: Connected at {self._params["host"]}')
-        self._connected = True
-        return self
-
-    async def close(self):
-        print("Connection Closed")
-        self._connected = False
-
-    async def get_columns(self):
-        return {"id": "value"}
-
-    async def use(self, database):
-        print(f"Changing Database to {database}")
-
-    async def query(self, sentence="", **kwargs):
-        error = None
-        print(f"Running Query: {sentence}")
-        result = [{"col1": [1, 2], "col2": [3, 4], "col3": [5, 6]}]
-        return await self._serializer(result, error)
-
-    fetch_all = query
-
-    async def execute(self, sentence: str, *args, **kwargs):
-        print(f"Execute Query {sentence}")
-        data = []
-        error = None
-        result = [data, error]
-        return await self._serializer(result, error)
-
-    execute_many = execute
-
-    async def queryrow(self, sentence=""):
-        error = None
-        print(f"Running Row {sentence}")
-        result = {"col1": [1, 2], "col2": [3, 4], "col3": [5, 6]}
-        return await self._serializer(result, error)
-
-    fetch_one = queryrow
+"""Dummy Driver.
+"""
+from datetime import datetime
+from ..exceptions import DriverError
+from .abstract import BaseDriver
+
+
+class dummy(BaseDriver):
+    _provider = "dummy"
+    _syntax = "sql"
+
+    def __init__(self, dsn="", loop=None, params: dict = None, **kwargs):
+        self._test_query = "SELECT 1"
+        _starttime = datetime.now()
+        self._dsn = "test:/{host}:{port}/{db}"
+        if not params:
+            params = {"host": "127.0.0.1", "port": "0", "db": 0}
+        try:
+            super(dummy, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+            self._logger.debug(f"Dummy Params are: {params}")
+            _generated = datetime.now() - _starttime
+            print(f"Started in: {_generated}")
+        except Exception as err:
+            raise DriverError(f"Dummy Error: {err}") from err
+
+    async def prepare(self):
+        pass
+
+    async def connection(self):
+        print(f'{self._provider}: Connected at {self._params["host"]}')
+        self._connected = True
+        return self
+
+    async def close(self):
+        print("Connection Closed")
+        self._connected = False
+
+    async def get_columns(self):
+        return {"id": "value"}
+
+    async def use(self, database):
+        print(f"Changing Database to {database}")
+
+    async def query(self, sentence="", **kwargs):
+        error = None
+        print(f"Running Query: {sentence}")
+        result = [{"col1": [1, 2], "col2": [3, 4], "col3": [5, 6]}]
+        return await self._serializer(result, error)
+
+    fetch_all = query
+
+    async def execute(self, sentence: str, *args, **kwargs):
+        print(f"Execute Query {sentence}")
+        data = []
+        error = None
+        result = [data, error]
+        return await self._serializer(result, error)
+
+    execute_many = execute
+
+    async def queryrow(self, sentence=""):
+        error = None
+        print(f"Running Row {sentence}")
+        result = {"col1": [1, 2], "col2": [3, 4], "col3": [5, 6]}
+        return await self._serializer(result, error)
+
+    fetch_one = queryrow
```

## asyncdb/drivers/sqlite.py

```diff
@@ -1,672 +1,672 @@
-#!/usr/bin/env python3
-import time
-import asyncio
-from typing import Any, Optional, Union
-from collections.abc import Sequence, Iterable
-import aiosqlite
-from asyncdb.exceptions import NoDataFound, DriverError
-from asyncdb.interfaces import DBCursorBackend, ModelBackend
-from asyncdb.models import Model
-from asyncdb.utils.types import Entity
-from .sql import SQLDriver, SQLCursor
-
-
-class sqliteCursor(SQLCursor):
-    """
-    Cursor Object for SQLite.
-    """
-
-    _provider: "sqlite"
-    _connection: aiosqlite.Connection = None
-
-    async def __aenter__(self) -> "sqliteCursor":
-        self._cursor = await self._connection.execute(self._sentence, self._params)
-        return self
-
-
-class sqlite(SQLDriver, DBCursorBackend, ModelBackend):
-    _provider: str = "sqlite"
-    _syntax: str = "sql"
-    _dsn: str = "{database}"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        SQLDriver.__init__(self, dsn, loop, params, **kwargs)
-        DBCursorBackend.__init__(self)
-
-    async def prepare(self, sentence: Union[str, list]) -> Any:
-        "Ignoring prepared sentences on SQLite"
-        raise NotImplementedError()  # pragma: no cover
-
-    async def __aenter__(self) -> Any:
-        if not self._connection:
-            await self.connection()
-        return self
-
-    async def connection(self, **kwargs):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            self._connection = await aiosqlite.connect(database=self._dsn, **kwargs)
-            if self._connection:
-                if self._init_func is not None and callable(self._init_func):
-                    try:
-                        await self._init_func(self._connection)  # pylint: disable=E1102
-                    except RuntimeError as err:
-                        self._logger.exception(f"Error on Init Connection: {err!s}")
-                self._connected = True
-                self._initialized_on = time.time()
-            return self
-        except aiosqlite.OperationalError as e:
-            raise DriverError(f"Unable to Open Database: {self._dsn}, {e}") from e
-        except aiosqlite.DatabaseError as e:
-            raise DriverError(f"Database Connection Error: {e!s}") from e
-        except aiosqlite.Error as e:
-            raise DriverError(f"SQLite Internal Error: {e!s}") from e
-        except Exception as e:
-            self._logger.exception(e, stack_info=True)
-            raise DriverError(f"SQLite Unknown Error: {e!s}") from e
-
-    connect = connection
-
-    async def valid_operation(self, sentence: Any):
-        await super(sqlite, self).valid_operation(sentence)
-        if self._row_format == "iterable":
-            # converting to a dictionary
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-        else:
-            self._connection.row_factory = None
-
-    async def query(self, sentence: Any, **kwargs) -> Any:
-        """
-        Getting a Query from Database
-        """
-        error = None
-        cursor = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._connection.execute(sentence, parameters=kwargs)
-            self._result = await cursor.fetchall()
-            if not self._result:
-                return (None, NoDataFound())
-        except Exception as err:
-            error = f"SQLite Error on Query: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            try:
-                await cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-            return await self._serializer(self._result, error)
-
-    async def queryrow(self, sentence: Any = None) -> Iterable[Any]:
-        """
-        Getting a single Row from Database
-        """
-        error = None
-        cursor = None
-        await self.valid_operation(sentence)
-        try:
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-            cursor = await self._connection.execute(sentence)
-            self._result = await cursor.fetchone()
-            if not self._result:
-                return (None, NoDataFound())
-        except Exception as e:
-            error = f"Error on Query: {e}"
-            raise DriverError(message=error) from e
-        finally:
-            try:
-                await cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-            return await self._serializer(self._result, error)
-
-    async def fetch_all(self, sentence: str, **kwargs) -> Sequence:
-        """
-        Alias for Query, but without error Support.
-        """
-        cursor = None
-        await self.valid_operation(sentence)
-        try:
-            cursor = await self._connection.execute(sentence, parameters=kwargs)
-            self._result = await cursor.fetchall()
-            if not self._result:
-                raise NoDataFound("SQLite Fetch All: Data Not Found")
-        except Exception as e:
-            error = f"Error on Fetch: {e}"
-            raise DriverError(message=error) from e
-        finally:
-            try:
-                await cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-            return self._result
-
-    # alias to be compatible with aiosqlite methods.
-    fetchall = fetch_all
-
-    async def fetch_many(self, sentence: str, size: int = None):
-        """
-        Aliases for query, without error support
-        """
-        await self.valid_operation(sentence)
-        cursor = None
-        try:
-            cursor = await self._connection.execute(sentence)
-            self._result = await cursor.fetchmany(size)
-            if not self._result:
-                raise NoDataFound()
-        except Exception as err:
-            error = "Error on Query: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            try:
-                await cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-            return self._result
-
-    fetchmany = fetch_many
-
-    async def fetch_one(self, sentence: str, **kwargs) -> Optional[dict]:
-        """
-        aliases for queryrow, but without error support
-        """
-        await self.valid_operation(sentence)
-        cursor = None
-        try:
-            cursor = await self._connection.execute(sentence, **kwargs)
-            self._result = await cursor.fetchone()
-            if not self._result:
-                raise NoDataFound()
-        except Exception as err:
-            error = "Error on Query: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            try:
-                await cursor.close()
-            except (ValueError, TypeError, RuntimeError) as err:
-                self._logger.exception(err)
-            return self._result
-
-    fetchone = fetch_one
-    fetchrow = fetch_one
-
-    async def execute(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
-        """Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        error = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            result = await self._connection.execute(sentence, parameters=kwargs)
-            if result:
-                await self._connection.commit()
-        except Exception as err:
-            error = "Error on Execute: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            return (result, error)
-
-    async def execute_many(self, sentence: Union[str, list], *args) -> Optional[Any]:
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            result = await self._connection.executemany(sentence, *args)
-            if result:
-                await self._connection.commit()
-        except Exception as err:
-            error = "Error on Execute Many: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            return (result, error)
-
-    executemany = execute_many
-
-    async def fetch(self, sentence: str, parameters: Iterable[Any] = None) -> Iterable:
-        """Helper to create a cursor and execute the given query."""
-        await self.valid_operation(sentence)
-        if parameters is None:
-            parameters = []
-        result = await self._connection.execute(sentence, parameters)
-        return result
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError()  # pragma: no cover
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError()  # pragma: no cover
-
-    async def use(self, database: str):
-        raise NotImplementedError("SQLite Error: There is no Database in SQLite")
-
-    async def column_info(self, table: str, **kwargs) -> Iterable[Any]:
-        """
-        Getting Column info from an existing Table in Provider.
-        """
-        try:
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-            cursor = await self._connection.execute(f"PRAGMA table_info({table});", parameters=kwargs)
-            cols = await cursor.fetchall()
-            self._columns = []
-            for col in cols:
-                d = {"name": col["name"], "type": col["type"]}
-                self._columns.append(d)
-            if not self._columns:
-                raise NoDataFound()
-        except Exception as err:
-            error = "Error on Column Info: {err}"
-            raise DriverError(message=error) from err
-        finally:
-            return self._columns
-
-    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
-        """
-        Create is a generic method for Database Objects Creation.
-        """
-        if obj == "table":
-            sql = "CREATE TABLE {name} ({columns});"
-            columns = ", ".join(["{name} {type}".format(**e) for e in fields])
-            sql = sql.format(name=name, columns=columns)
-            try:
-                result = await self._connection.execute(sql)
-                if result:
-                    await self._connection.commit()
-                    return True
-                else:
-                    return False
-            except Exception as err:
-                raise DriverError(f"Error in Object Creation: {err!s}") from err
-        else:
-            raise RuntimeError(f"SQLite: invalid Object type {object!s}")
-
-    ## ModelBackend Methods
-    async def _insert_(self, _model: Model, **kwargs):
-        """
-        insert a row from model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        cols = []
-        source = []
-        _filter = {}
-        n = 1
-        fields = _model.columns()
-        for name, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            column = field.name
-            # validating required field
-            try:
-                required = field.required()
-            except AttributeError:
-                required = False
-            if required is False and value is None or value == "None":
-                default = field.default
-                if callable(default):
-                    value = default()
-                else:
-                    continue
-            elif required is True and value is None or value == "None":
-                if "db_default" in field.metadata:
-                    # field get a default value from database
-                    continue
-                else:
-                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
-            source.append(value)
-            cols.append(column)
-            n += 1
-            if pk := self._get_attribute(field, value, attr="primary_key"):
-                _filter[column] = pk
-        try:
-            columns = ",".join(cols)
-            values = ",".join(["?" for a in range(1, n)])
-            insert = f"INSERT INTO {table}({columns}) VALUES({values})"
-            self._logger.debug(f"INSERT: {insert}")
-            cursor = await self._connection.execute(insert, parameters=source)
-            await self._connection.commit()
-            condition = self._where(fields, **_filter)
-            get = f"SELECT * FROM {table} {condition}"
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-            cursor = await self._connection.execute(get)
-            result = await cursor.fetchone()
-            if result:
-                for f, val in result.items():
-                    setattr(_model, f, val)
-                return _model
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _delete_(self, _model: Model, **kwargs):
-        """
-        delete a row from model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        source = []
-        _filter = {}
-        n = 1
-        fields = _model.columns()
-        for _, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            column = field.name
-            source.append(value)
-            n += 1
-            if pk := self._get_attribute(field, value, attr="primary_key"):
-                _filter[column] = pk
-        try:
-            condition = self._where(fields, **_filter)
-            _delete = f"DELETE FROM {table} {condition};"
-            self._logger.debug(f"DELETE: {_delete}")
-            cursor = await self._connection.execute(_delete)
-            await self._connection.commit()
-            return f"DELETE {cursor.rowcount}: {_filter!s}"
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _update_(self, _model: Model, **kwargs):
-        """
-        Updating a row in a Model.
-        TODO: How to update when if primary key changed.
-        Alternatives: Saving *dirty* status and previous value on dict
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        cols = []
-        source = []
-        _filter = {}
-        n = 1
-        fields = _model.columns()
-        for name, field in fields.items():
-            try:
-                val = getattr(_model, field.name)
-            except AttributeError:
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            column = field.name
-            # validating required field
-            try:
-                required = field.required()
-            except AttributeError:
-                required = False
-            if required is False and value is None or value == "None":
-                default = field.default
-                if callable(default):
-                    value = default()
-                else:
-                    continue
-            elif required is True and value is None or value == "None":
-                if "db_default" in field.metadata:
-                    # field get a default value from database
-                    continue
-                else:
-                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
-            source.append(value)
-            cols.append(f"{column} = ?")
-            n += 1
-            if pk := self._get_attribute(field, value, attr="primary_key"):
-                _filter[column] = pk
-        try:
-            set_fields = ", ".join(cols)
-            condition = self._where(fields, **_filter)
-            _update = f"UPDATE {table} SET {set_fields} {condition}"
-            self._logger.debug(f"UPDATE: {_update}")
-            cursor = await self._connection.execute(_update, parameters=source)
-            await self._connection.commit()
-            get = f"SELECT * FROM {table} {condition}"
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-            cursor = await self._connection.execute(get)
-            result = await cursor.fetchone()
-            if result:
-                for f, val in result.items():
-                    setattr(_model, f, val)
-                return _model
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _save_(self, model: Model, *args, **kwargs):
-        """
-        Save a row in a Model, using Insert-or-Update methodology.
-        """
-
-    async def _fetch_(self, _model: Model, **kwargs):
-        """
-        Returns one Row using Model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns()
-        _filter = {}
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT * FROM {table} {condition}"
-        try:
-            cursor = await self._connection.execute(_get)
-            result = await cursor.fetchone()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model Fetch over {table}: {e}") from e
-
-    async def _filter_(self, _model: Model, *args, **kwargs):
-        """
-        Filter a Model using Fields.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        if args:
-            columns = ",".join(args)
-        else:
-            columns = "*"
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            cursor = await self._connection.execute(_get)
-            result = await cursor.fetchall()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model GET over {table}: {e}") from e
-
-    async def _select_(self, *args, **kwargs):
-        """
-        Get a query from Model.
-        """
-        try:
-            model = kwargs["_model"]
-        except KeyError as e:
-            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
-        try:
-            table = f"{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        if args:
-            condition = "{}".join(args)
-        else:
-            condition = None
-        if "fields" in kwargs:
-            columns = ",".join(kwargs["fields"])
-        else:
-            columns = "*"
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            cursor = await self._connection.execute(_get)
-            result = await cursor.fetchall()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model SELECT over {table}: {e}") from e
-
-    async def _get_(self, _model: Model, *args, **kwargs):
-        """
-        Get one row from model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        if args:
-            columns = ",".join(args)
-        else:
-            columns = "*"
-        for name, field in fields.items():
-            if name in kwargs:
-                try:
-                    val = kwargs[name]
-                except AttributeError:
-                    continue
-                ## getting the value of column:
-                datatype = field.type
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _get = f"SELECT {columns} FROM {table} {condition}"
-        try:
-            cursor = await self._connection.execute(_get)
-            result = await cursor.fetchone()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model GET over {table}: {e}") from e
-
-    async def _all_(self, _model: Model, *args, **kwargs):
-        """
-        Get all rows on a Model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        if "fields" in kwargs:
-            columns = ",".join(kwargs["fields"])
-        else:
-            columns = "*"
-        _all = f"SELECT {columns} FROM {table}"
-        try:
-            cursor = await self._connection.execute(_all)
-            result = await cursor.fetchall()
-            return result
-        except Exception as e:
-            raise DriverError(f"Error: Model All over {table}: {e}") from e
-
-    async def _remove_(self, _model: Model, **kwargs):
-        """
-        Deleting some records using Model.
-        """
-        try:
-            table = f"{_model.Meta.name}"
-        except AttributeError:
-            table = _model.__name__
-        fields = _model.columns(_model)
-        _filter = {}
-        for name, field in fields.items():
-            datatype = field.type
-            if name in kwargs:
-                val = kwargs[name]
-                value = Entity.toSQL(val, datatype)
-                _filter[name] = value
-        condition = self._where(fields, **_filter)
-        _delete = f"DELETE FROM {table} {condition}"
-        try:
-            self._logger.debug(f"DELETE: {_delete}")
-            cursor = await self._connection.execute(_delete)
-            await self._connection.commit()
-            return f"DELETE {cursor.rowcount}: {_filter!s}"
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
-
-    async def _updating_(self, *args, _filter: dict = None, **kwargs):
-        """
-        Updating records using Model.
-        """
-        try:
-            model = kwargs["_model"]
-        except KeyError as e:
-            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
-        try:
-            table = f"{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        try:
-            table = f"{model.Meta.name}"
-        except AttributeError:
-            table = model.__name__
-        fields = model.columns(model)
-        if _filter is None:
-            if args:
-                _filter = args[0]
-        cols = []
-        source = []
-        new_cond = {}
-        for name, field in fields.items():
-            try:
-                val = kwargs[name]
-            except (KeyError, AttributeError):
-                continue
-            ## getting the value of column:
-            value = self._get_value(field, val)
-            source.append(value)
-            if name in _filter:
-                new_cond[name] = value
-            cols.append(f"{name} = ?")
-        try:
-            set_fields = ", ".join(cols)
-            condition = self._where(fields, **_filter)
-            _update = f"UPDATE {table} SET {set_fields} {condition}"
-            self._logger.debug(f"UPDATE: {_update}")
-            cursor = await self._connection.execute(_update, parameters=source)
-            await self._connection.commit()
-            print(f"UPDATE {cursor.rowcount}: {_filter!s}")
-            new_conditions = {**_filter, **new_cond}
-            condition = self._where(fields, **new_conditions)
-            get = f"SELECT * FROM {table} {condition}"
-            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
-            cursor = await self._connection.execute(get)
-            result = await cursor.fetchall()
-            return [model(**dict(r)) for r in result]
-        except Exception as err:
-            raise DriverError(message=f"Error on Insert over table {model.Meta.name}: {err!s}") from err
+#!/usr/bin/env python3
+import time
+import asyncio
+from typing import Any, Optional, Union
+from collections.abc import Sequence, Iterable
+import aiosqlite
+from ..exceptions import NoDataFound, DriverError
+from ..interfaces import DBCursorBackend, ModelBackend
+from ..models import Model
+from ..utils.types import Entity
+from .sql import SQLDriver, SQLCursor
+
+
+class sqliteCursor(SQLCursor):
+    """
+    Cursor Object for SQLite.
+    """
+
+    _provider: "sqlite"
+    _connection: aiosqlite.Connection = None
+
+    async def __aenter__(self) -> "sqliteCursor":
+        self._cursor = await self._connection.execute(self._sentence, self._params)
+        return self
+
+
+class sqlite(SQLDriver, DBCursorBackend, ModelBackend):
+    _provider: str = "sqlite"
+    _syntax: str = "sql"
+    _dsn: str = "{database}"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        SQLDriver.__init__(self, dsn, loop, params, **kwargs)
+        DBCursorBackend.__init__(self)
+
+    async def prepare(self, sentence: Union[str, list]) -> Any:
+        "Ignoring prepared sentences on SQLite"
+        raise NotImplementedError()  # pragma: no cover
+
+    async def __aenter__(self) -> Any:
+        if not self._connection:
+            await self.connection()
+        return self
+
+    async def connection(self, **kwargs):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            self._connection = await aiosqlite.connect(database=self._dsn, **kwargs)
+            if self._connection:
+                if self._init_func is not None and callable(self._init_func):
+                    try:
+                        await self._init_func(self._connection)  # pylint: disable=E1102
+                    except RuntimeError as err:
+                        self._logger.exception(f"Error on Init Connection: {err!s}")
+                self._connected = True
+                self._initialized_on = time.time()
+            return self
+        except aiosqlite.OperationalError as e:
+            raise DriverError(f"Unable to Open Database: {self._dsn}, {e}") from e
+        except aiosqlite.DatabaseError as e:
+            raise DriverError(f"Database Connection Error: {e!s}") from e
+        except aiosqlite.Error as e:
+            raise DriverError(f"SQLite Internal Error: {e!s}") from e
+        except Exception as e:
+            self._logger.exception(e, stack_info=True)
+            raise DriverError(f"SQLite Unknown Error: {e!s}") from e
+
+    connect = connection
+
+    async def valid_operation(self, sentence: Any):
+        await super(sqlite, self).valid_operation(sentence)
+        if self._row_format == "iterable":
+            # converting to a dictionary
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+        else:
+            self._connection.row_factory = None
+
+    async def query(self, sentence: Any, **kwargs) -> Any:
+        """
+        Getting a Query from Database
+        """
+        error = None
+        cursor = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._connection.execute(sentence, parameters=kwargs)
+            self._result = await cursor.fetchall()
+            if not self._result:
+                return (None, NoDataFound())
+        except Exception as err:
+            error = f"SQLite Error on Query: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            try:
+                await cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+            return await self._serializer(self._result, error)
+
+    async def queryrow(self, sentence: Any = None) -> Iterable[Any]:
+        """
+        Getting a single Row from Database
+        """
+        error = None
+        cursor = None
+        await self.valid_operation(sentence)
+        try:
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+            cursor = await self._connection.execute(sentence)
+            self._result = await cursor.fetchone()
+            if not self._result:
+                return (None, NoDataFound())
+        except Exception as e:
+            error = f"Error on Query: {e}"
+            raise DriverError(message=error) from e
+        finally:
+            try:
+                await cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+            return await self._serializer(self._result, error)
+
+    async def fetch_all(self, sentence: str, **kwargs) -> Sequence:
+        """
+        Alias for Query, but without error Support.
+        """
+        cursor = None
+        await self.valid_operation(sentence)
+        try:
+            cursor = await self._connection.execute(sentence, parameters=kwargs)
+            self._result = await cursor.fetchall()
+            if not self._result:
+                raise NoDataFound("SQLite Fetch All: Data Not Found")
+        except Exception as e:
+            error = f"Error on Fetch: {e}"
+            raise DriverError(message=error) from e
+        finally:
+            try:
+                await cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+            return self._result
+
+    # alias to be compatible with aiosqlite methods.
+    fetchall = fetch_all
+
+    async def fetch_many(self, sentence: str, size: int = None):
+        """
+        Aliases for query, without error support
+        """
+        await self.valid_operation(sentence)
+        cursor = None
+        try:
+            cursor = await self._connection.execute(sentence)
+            self._result = await cursor.fetchmany(size)
+            if not self._result:
+                raise NoDataFound()
+        except Exception as err:
+            error = "Error on Query: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            try:
+                await cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+            return self._result
+
+    fetchmany = fetch_many
+
+    async def fetch_one(self, sentence: str, **kwargs) -> Optional[dict]:
+        """
+        aliases for queryrow, but without error support
+        """
+        await self.valid_operation(sentence)
+        cursor = None
+        try:
+            cursor = await self._connection.execute(sentence, **kwargs)
+            self._result = await cursor.fetchone()
+            if not self._result:
+                raise NoDataFound()
+        except Exception as err:
+            error = "Error on Query: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            try:
+                await cursor.close()
+            except (ValueError, TypeError, RuntimeError) as err:
+                self._logger.exception(err)
+            return self._result
+
+    fetchone = fetch_one
+    fetchrow = fetch_one
+
+    async def execute(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
+        """Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        error = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            result = await self._connection.execute(sentence, parameters=kwargs)
+            if result:
+                await self._connection.commit()
+        except Exception as err:
+            error = "Error on Execute: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            return (result, error)
+
+    async def execute_many(self, sentence: Union[str, list], *args) -> Optional[Any]:
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            result = await self._connection.executemany(sentence, *args)
+            if result:
+                await self._connection.commit()
+        except Exception as err:
+            error = "Error on Execute Many: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            return (result, error)
+
+    executemany = execute_many
+
+    async def fetch(self, sentence: str, parameters: Iterable[Any] = None) -> Iterable:
+        """Helper to create a cursor and execute the given query."""
+        await self.valid_operation(sentence)
+        if parameters is None:
+            parameters = []
+        result = await self._connection.execute(sentence, parameters)
+        return result
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError()  # pragma: no cover
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError()  # pragma: no cover
+
+    async def use(self, database: str):
+        raise NotImplementedError("SQLite Error: There is no Database in SQLite")
+
+    async def column_info(self, table: str, **kwargs) -> Iterable[Any]:
+        """
+        Getting Column info from an existing Table in Provider.
+        """
+        try:
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+            cursor = await self._connection.execute(f"PRAGMA table_info({table});", parameters=kwargs)
+            cols = await cursor.fetchall()
+            self._columns = []
+            for col in cols:
+                d = {"name": col["name"], "type": col["type"]}
+                self._columns.append(d)
+            if not self._columns:
+                raise NoDataFound()
+        except Exception as err:
+            error = "Error on Column Info: {err}"
+            raise DriverError(message=error) from err
+        finally:
+            return self._columns
+
+    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
+        """
+        Create is a generic method for Database Objects Creation.
+        """
+        if obj == "table":
+            sql = "CREATE TABLE {name} ({columns});"
+            columns = ", ".join(["{name} {type}".format(**e) for e in fields])
+            sql = sql.format(name=name, columns=columns)
+            try:
+                result = await self._connection.execute(sql)
+                if result:
+                    await self._connection.commit()
+                    return True
+                else:
+                    return False
+            except Exception as err:
+                raise DriverError(f"Error in Object Creation: {err!s}") from err
+        else:
+            raise RuntimeError(f"SQLite: invalid Object type {object!s}")
+
+    ## ModelBackend Methods
+    async def _insert_(self, _model: Model, **kwargs):
+        """
+        insert a row from model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        cols = []
+        source = []
+        _filter = {}
+        n = 1
+        fields = _model.columns()
+        for name, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            # validating required field
+            try:
+                required = field.required()
+            except AttributeError:
+                required = False
+            if required is False and value is None or value == "None":
+                default = field.default
+                if callable(default):
+                    value = default()
+                else:
+                    continue
+            elif required is True and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    # field get a default value from database
+                    continue
+                else:
+                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
+            source.append(value)
+            cols.append(column)
+            n += 1
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _filter[column] = pk
+        try:
+            columns = ",".join(cols)
+            values = ",".join(["?" for a in range(1, n)])
+            insert = f"INSERT INTO {table}({columns}) VALUES({values})"
+            self._logger.debug(f"INSERT: {insert}")
+            cursor = await self._connection.execute(insert, parameters=source)
+            await self._connection.commit()
+            condition = self._where(fields, **_filter)
+            get = f"SELECT * FROM {table} {condition}"
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+            cursor = await self._connection.execute(get)
+            result = await cursor.fetchone()
+            if result:
+                for f, val in result.items():
+                    setattr(_model, f, val)
+                return _model
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _delete_(self, _model: Model, **kwargs):
+        """
+        delete a row from model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        source = []
+        _filter = {}
+        n = 1
+        fields = _model.columns()
+        for _, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            source.append(value)
+            n += 1
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _filter[column] = pk
+        try:
+            condition = self._where(fields, **_filter)
+            _delete = f"DELETE FROM {table} {condition};"
+            self._logger.debug(f"DELETE: {_delete}")
+            cursor = await self._connection.execute(_delete)
+            await self._connection.commit()
+            return f"DELETE {cursor.rowcount}: {_filter!s}"
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _update_(self, _model: Model, **kwargs):
+        """
+        Updating a row in a Model.
+        TODO: How to update when if primary key changed.
+        Alternatives: Saving *dirty* status and previous value on dict
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        cols = []
+        source = []
+        _filter = {}
+        n = 1
+        fields = _model.columns()
+        for name, field in fields.items():
+            try:
+                val = getattr(_model, field.name)
+            except AttributeError:
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            column = field.name
+            # validating required field
+            try:
+                required = field.required()
+            except AttributeError:
+                required = False
+            if required is False and value is None or value == "None":
+                default = field.default
+                if callable(default):
+                    value = default()
+                else:
+                    continue
+            elif required is True and value is None or value == "None":
+                if "db_default" in field.metadata:
+                    # field get a default value from database
+                    continue
+                else:
+                    raise ValueError(f"Field {name} is required and value is null over {_model.Meta.name}")
+            source.append(value)
+            cols.append(f"{column} = ?")
+            n += 1
+            if pk := self._get_attribute(field, value, attr="primary_key"):
+                _filter[column] = pk
+        try:
+            set_fields = ", ".join(cols)
+            condition = self._where(fields, **_filter)
+            _update = f"UPDATE {table} SET {set_fields} {condition}"
+            self._logger.debug(f"UPDATE: {_update}")
+            cursor = await self._connection.execute(_update, parameters=source)
+            await self._connection.commit()
+            get = f"SELECT * FROM {table} {condition}"
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+            cursor = await self._connection.execute(get)
+            result = await cursor.fetchone()
+            if result:
+                for f, val in result.items():
+                    setattr(_model, f, val)
+                return _model
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _save_(self, model: Model, *args, **kwargs):
+        """
+        Save a row in a Model, using Insert-or-Update methodology.
+        """
+
+    async def _fetch_(self, _model: Model, **kwargs):
+        """
+        Returns one Row using Model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns()
+        _filter = {}
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT * FROM {table} {condition}"
+        try:
+            cursor = await self._connection.execute(_get)
+            result = await cursor.fetchone()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model Fetch over {table}: {e}") from e
+
+    async def _filter_(self, _model: Model, *args, **kwargs):
+        """
+        Filter a Model using Fields.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        if args:
+            columns = ",".join(args)
+        else:
+            columns = "*"
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            cursor = await self._connection.execute(_get)
+            result = await cursor.fetchall()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model GET over {table}: {e}") from e
+
+    async def _select_(self, *args, **kwargs):
+        """
+        Get a query from Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            table = f"{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        if args:
+            condition = "{}".join(args)
+        else:
+            condition = None
+        if "fields" in kwargs:
+            columns = ",".join(kwargs["fields"])
+        else:
+            columns = "*"
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            cursor = await self._connection.execute(_get)
+            result = await cursor.fetchall()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model SELECT over {table}: {e}") from e
+
+    async def _get_(self, _model: Model, *args, **kwargs):
+        """
+        Get one row from model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        if args:
+            columns = ",".join(args)
+        else:
+            columns = "*"
+        for name, field in fields.items():
+            if name in kwargs:
+                try:
+                    val = kwargs[name]
+                except AttributeError:
+                    continue
+                ## getting the value of column:
+                datatype = field.type
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _get = f"SELECT {columns} FROM {table} {condition}"
+        try:
+            cursor = await self._connection.execute(_get)
+            result = await cursor.fetchone()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model GET over {table}: {e}") from e
+
+    async def _all_(self, _model: Model, *args, **kwargs):
+        """
+        Get all rows on a Model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        if "fields" in kwargs:
+            columns = ",".join(kwargs["fields"])
+        else:
+            columns = "*"
+        _all = f"SELECT {columns} FROM {table}"
+        try:
+            cursor = await self._connection.execute(_all)
+            result = await cursor.fetchall()
+            return result
+        except Exception as e:
+            raise DriverError(f"Error: Model All over {table}: {e}") from e
+
+    async def _remove_(self, _model: Model, **kwargs):
+        """
+        Deleting some records using Model.
+        """
+        try:
+            table = f"{_model.Meta.name}"
+        except AttributeError:
+            table = _model.__name__
+        fields = _model.columns(_model)
+        _filter = {}
+        for name, field in fields.items():
+            datatype = field.type
+            if name in kwargs:
+                val = kwargs[name]
+                value = Entity.toSQL(val, datatype)
+                _filter[name] = value
+        condition = self._where(fields, **_filter)
+        _delete = f"DELETE FROM {table} {condition}"
+        try:
+            self._logger.debug(f"DELETE: {_delete}")
+            cursor = await self._connection.execute(_delete)
+            await self._connection.commit()
+            return f"DELETE {cursor.rowcount}: {_filter!s}"
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {_model.Meta.name}: {err!s}") from err
+
+    async def _updating_(self, *args, _filter: dict = None, **kwargs):
+        """
+        Updating records using Model.
+        """
+        try:
+            model = kwargs["_model"]
+        except KeyError as e:
+            raise DriverError(f"Missing Model for SELECT {kwargs!s}") from e
+        try:
+            table = f"{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        try:
+            table = f"{model.Meta.name}"
+        except AttributeError:
+            table = model.__name__
+        fields = model.columns(model)
+        if _filter is None:
+            if args:
+                _filter = args[0]
+        cols = []
+        source = []
+        new_cond = {}
+        for name, field in fields.items():
+            try:
+                val = kwargs[name]
+            except (KeyError, AttributeError):
+                continue
+            ## getting the value of column:
+            value = self._get_value(field, val)
+            source.append(value)
+            if name in _filter:
+                new_cond[name] = value
+            cols.append(f"{name} = ?")
+        try:
+            set_fields = ", ".join(cols)
+            condition = self._where(fields, **_filter)
+            _update = f"UPDATE {table} SET {set_fields} {condition}"
+            self._logger.debug(f"UPDATE: {_update}")
+            cursor = await self._connection.execute(_update, parameters=source)
+            await self._connection.commit()
+            print(f"UPDATE {cursor.rowcount}: {_filter!s}")
+            new_conditions = {**_filter, **new_cond}
+            condition = self._where(fields, **new_conditions)
+            get = f"SELECT * FROM {table} {condition}"
+            self._connection.row_factory = lambda c, r: dict(zip([col[0] for col in c.description], r))
+            cursor = await self._connection.execute(get)
+            result = await cursor.fetchall()
+            return [model(**dict(r)) for r in result]
+        except Exception as err:
+            raise DriverError(message=f"Error on Insert over table {model.Meta.name}: {err!s}") from err
```

## asyncdb/drivers/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-"""
-AsyncDB Drivers.
-"""
+"""
+AsyncDB Drivers.
+"""
```

## asyncdb/drivers/sqlserver.py

```diff
@@ -1,347 +1,347 @@
-#!/usr/bin/env python3
-import asyncio
-import time
-import logging
-from typing import Any, Optional
-from collections.abc import Iterable
-import pymssql
-from asyncdb.exceptions import DataError, EmptyStatement, NoDataFound, DriverError
-from .sql import SQLCursor
-from .mssql import mssql
-
-
-class sqlserverCursor(SQLCursor):
-    _connection = None
-
-    async def __aenter__(self) -> "sqlserverCursor":
-        if not self._connection:
-            await self.connection()
-        self._cursor = self._connection.cursor()
-        try:
-            self._cursor.execute(self._sentence, self._params)
-            return self
-        except (pymssql.StandardError, pymssql.Error) as err:
-            print(err)
-            error = f"SQL Server Error: {err}"
-            raise DriverError(message=error) from err
-        except Exception as err:
-            print(err)
-            raise
-
-    async def __anext__(self):
-        """Use `cursor.fetchone()` to provide an async iterable."""
-        row = await self.fetchone()
-        if row is not None:
-            return row
-        else:
-            raise StopAsyncIteration
-
-    async def fetchone(self) -> Optional[dict]:
-        return self._cursor.fetchone()
-
-    async def fetchmany(self, size: int = None) -> Iterable[list]:
-        return self._cursor.fetchmany(size)
-
-    async def fetchall(self) -> Iterable[list]:
-        return self._cursor.fetchall()
-
-
-class sqlserver(mssql):
-    """sqlserver.
-
-    Microsoft SQL Server using DB-API connection
-    """
-
-    _provider = "sqlserver"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        try:
-            self.tds_version = kwargs["tds_version"]
-            del kwargs["tds_version"]
-        except KeyError:
-            self.tds_version = "8.0"
-        super(sqlserver, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-
-    async def connection(self) -> Any:
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            self.params["appname"] = self.application_name
-            self.params["as_dict"] = True
-            self.params["timeout"] = self._timeout
-            self.params["charset"] = self._charset.upper()
-            self.params["tds_version"] = self.tds_version
-            self._connection = pymssql.connect(**self.params)
-            if self._connection:
-                self._connected = True
-                self._initialized_on = time.time()
-            if "database" in self.params:
-                await self.use(self.params["database"])
-            return self
-        except Exception as err:
-            print(err)
-            self._connection = None
-            self._cursor = None
-            raise DriverError(f"connection Error, Terminated: {err}") from err
-
-    async def use(self, database: str):
-        try:
-            self._cursor = self._connection.cursor()
-            self._cursor.execute(f"USE {database!s}")
-            return self
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-        except (pymssql.StandardError, pymssql.Error) as err:
-            raise DriverError(message=f"SQL Server Error: {err}") from err
-
-    async def execute(self, sentence, *args, **kwargs):
-        """
-        Execute a sentence
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        # getting a cursor
-        try:
-            self._cursor = self._connection.cursor(**kwargs)
-            self._result = self._cursor.execute(sentence, *args)
-            print(sentence, self._result)
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-            error = warn
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            logging.debug(error)
-            return [self._result, error]  # pylint: disable=W0150
-
-    async def execute_many(self, sentence, *args):
-        """
-        Execute multiple sentences
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        # getting a cursor
-        try:
-            self._cursor = self._connection.cursor()
-            self._result = self._cursor.executemany(sentence, *args)
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-            error = warn
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            logging.debug(error)
-            return [self._result, error]  # pylint: disable=W0150
-
-    executemany = execute_many
-
-    async def query(self, sentence, *args, **kwargs):
-        """
-        Making a Query and return result
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        if isinstance(sentence, str):
-            sentence = sentence.encode(self._charset)
-        try:
-            self._cursor = self._connection.cursor(**kwargs)
-            self._cursor.execute(sentence, *args)
-            self._result = self._cursor.fetchall()
-            if not self._result:
-                return [None, NoDataFound("SQL Server: No Data was Found")]
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Query Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def procedure(self, sentence, **kwargs):
-        """
-        Making a Query and return result based on a Procedure (callproc)
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self._cursor = self._connection.cursor()
-            params = tuple(kwargs.values())
-            self._cursor.callproc(sentence, params)
-            self._cursor.nextset()
-            self._result = self._cursor.fetchall()
-            self._cursor.close()
-            try:
-                self._connection.commit()
-            except pymssql.Error as err:
-                logging.error(err)
-                self._connection.rollback()
-            if not self._result:
-                return [None, NoDataFound("SQL Server: No Data was Found")]
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Query Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    callproc = procedure
-
-    async def queryrow(self, sentence, *args, **kwargs):
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        if isinstance(sentence, str):
-            sentence = sentence.encode(self._charset)
-        try:
-            self._cursor = self._connection.cursor(**kwargs)
-            self._cursor.execute(sentence, *args)
-            self._result = self._cursor.fetchone()
-            if not self._result:
-                return [None, NoDataFound("SQL Server: No Data was Found")]
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Query Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def fetch_one(self, sentence, *args, **kwargs):
-        self._result = None
-        await self.valid_operation(sentence)
-        if isinstance(sentence, str):
-            sentence = sentence.encode(self._charset)
-        try:
-            self._cursor = self._connection.cursor(**kwargs)
-            self._cursor.execute(sentence, args)
-            self._result = self._cursor.fetchone()
-            if not self._result:
-                raise NoDataFound("SQL Server: No Data was Found")
-            return self._result
-        except (pymssql.StandardError, pymssql.Error) as err:
-            raise DataError(f"SQL Server Query Error: {err}") from err
-        except RuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Error on Query: {err}") from err
-
-    fetchone = fetch_one
-
-    async def fetch_all(self, sentence, *args, **kwargs):
-        self._result = None
-        await self.valid_operation(sentence)
-        if isinstance(sentence, str):
-            sentence = sentence.encode(self._charset)
-        try:
-            self._cursor = self._connection.cursor(**kwargs)
-            self._cursor.execute(sentence, args)
-            self._result = self._cursor.fetchall()
-            if not self._result:
-                raise NoDataFound("SQL Server: No Data was Found")
-            return self._result
-        except (pymssql.StandardError, pymssql.Error) as err:
-            raise DataError(f"SQL Server Query Error: {err}") from err
-        except RuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Error on Query: {err}") from err
-
-    async def fetch(self, sentence, *args, size: int = 1, **kwargs):
-        self._result = None
-        if not sentence:
-            raise EmptyStatement("Error: Empty Sentence")
-        if not self._connection:
-            await self.connection()
-        try:
-            self._cursor = self._connection.cursor(**kwargs)
-            self._cursor.execute(sentence, args)
-            self._result = self._cursor.fetchmany(size)
-            if not self._result:
-                raise NoDataFound("SQL Server: No Data was Found")
-        except (pymssql.StandardError, pymssql.Error) as err:
-            raise DataError(f"SQL Server Query Error: {err}") from err
-        except RuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Error on Query: {err}") from err
-
-    async def exec(self, sentence, *args, paginated: bool = False, page: str = None, idx: str = None, **kwargs):
-        """exec.
-
-        Calling an Stored Function with parameters.
-        Args:
-            sentence (str): Called Procedure.
-            paginated (bool, optional): True if Stored Function is paginated. Defaults to False.
-            page (str, optional): Rowset parameter with the number of records. Defaults to None.
-            idx (str, optional): Parameter used to declare the Page Index. Defaults to None.
-            *args (optional): Any other parameter required by the function (passed on executed).
-            **kwargs (str, optional): any parameter required by the stored function.
-        Returns:
-            Tuple(Any, Exception): tuple with resultset and possible error.
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self._cursor = self._connection.cursor()
-            if idx is not None and idx not in kwargs:
-                kwargs[idx] = 1
-            if kwargs:
-                params = ", ".join([f"{k}={v}" for k, v in kwargs.items() if k is not None])
-            else:
-                params = ""
-            procedure = f"EXEC {sentence} {params}"
-            self._cursor.execute(procedure, *args)
-            # result = self._cursor.fetchall()
-            if not (result := self._cursor.fetchall()):
-                return [None, NoDataFound("SQL Server: No Data was Found")]
-            else:
-                # preparing for pagination and other stuff.
-                rowlen = len(result)
-                if paginated is True:
-                    results = []
-                    # this procedure is paginated:
-                    sample_row = result[0]
-                    num_rows = sample_row[page]
-                    if num_rows > rowlen:
-                        results.extend(result)
-                        # there are many more results:
-                        index = kwargs[idx]
-                        new_index = index + rowlen
-                        kwargs[idx] = new_index
-                        r, error = await self.exec(sentence, paginated=paginated, page=page, idx=idx, **kwargs)
-                        if r and not error:
-                            results.extend(r)
-                        return await self._serializer(results, error)
-                    else:
-                        return await self._serializer(result, error)
-                else:
-                    # is not paginated, return as usual:
-                    return await self._serializer(result, error)
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Query Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
+#!/usr/bin/env python3
+import asyncio
+import time
+import logging
+from typing import Any, Optional
+from collections.abc import Iterable
+import pymssql
+from ..exceptions import DataError, EmptyStatement, NoDataFound, DriverError
+from .sql import SQLCursor
+from .mssql import mssql
+
+
+class sqlserverCursor(SQLCursor):
+    _connection = None
+
+    async def __aenter__(self) -> "sqlserverCursor":
+        if not self._connection:
+            await self.connection()
+        self._cursor = self._connection.cursor()
+        try:
+            self._cursor.execute(self._sentence, self._params)
+            return self
+        except (pymssql.StandardError, pymssql.Error) as err:
+            print(err)
+            error = f"SQL Server Error: {err}"
+            raise DriverError(message=error) from err
+        except Exception as err:
+            print(err)
+            raise
+
+    async def __anext__(self):
+        """Use `cursor.fetchone()` to provide an async iterable."""
+        row = await self.fetchone()
+        if row is not None:
+            return row
+        else:
+            raise StopAsyncIteration
+
+    async def fetchone(self) -> Optional[dict]:
+        return self._cursor.fetchone()
+
+    async def fetchmany(self, size: int = None) -> Iterable[list]:
+        return self._cursor.fetchmany(size)
+
+    async def fetchall(self) -> Iterable[list]:
+        return self._cursor.fetchall()
+
+
+class sqlserver(mssql):
+    """sqlserver.
+
+    Microsoft SQL Server using DB-API connection
+    """
+
+    _provider = "sqlserver"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        try:
+            self.tds_version = kwargs["tds_version"]
+            del kwargs["tds_version"]
+        except KeyError:
+            self.tds_version = "8.0"
+        super(sqlserver, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+
+    async def connection(self) -> Any:
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            self.params["appname"] = self.application_name
+            self.params["as_dict"] = True
+            self.params["timeout"] = self._timeout
+            self.params["charset"] = self._charset.upper()
+            self.params["tds_version"] = self.tds_version
+            self._connection = pymssql.connect(**self.params)
+            if self._connection:
+                self._connected = True
+                self._initialized_on = time.time()
+            if "database" in self.params:
+                await self.use(self.params["database"])
+            return self
+        except Exception as err:
+            print(err)
+            self._connection = None
+            self._cursor = None
+            raise DriverError(f"connection Error, Terminated: {err}") from err
+
+    async def use(self, database: str):
+        try:
+            self._cursor = self._connection.cursor()
+            self._cursor.execute(f"USE {database!s}")
+            return self
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+        except (pymssql.StandardError, pymssql.Error) as err:
+            raise DriverError(message=f"SQL Server Error: {err}") from err
+
+    async def execute(self, sentence, *args, **kwargs):
+        """
+        Execute a sentence
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        # getting a cursor
+        try:
+            self._cursor = self._connection.cursor(**kwargs)
+            self._result = self._cursor.execute(sentence, *args)
+            print(sentence, self._result)
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+            error = warn
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            logging.debug(error)
+            return [self._result, error]  # pylint: disable=W0150
+
+    async def execute_many(self, sentence, *args):
+        """
+        Execute multiple sentences
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        # getting a cursor
+        try:
+            self._cursor = self._connection.cursor()
+            self._result = self._cursor.executemany(sentence, *args)
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+            error = warn
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            logging.debug(error)
+            return [self._result, error]  # pylint: disable=W0150
+
+    executemany = execute_many
+
+    async def query(self, sentence, *args, **kwargs):
+        """
+        Making a Query and return result
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        if isinstance(sentence, str):
+            sentence = sentence.encode(self._charset)
+        try:
+            self._cursor = self._connection.cursor(**kwargs)
+            self._cursor.execute(sentence, *args)
+            self._result = self._cursor.fetchall()
+            if not self._result:
+                return [None, NoDataFound("SQL Server: No Data was Found")]
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Query Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def procedure(self, sentence, **kwargs):
+        """
+        Making a Query and return result based on a Procedure (callproc)
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self._cursor = self._connection.cursor()
+            params = tuple(kwargs.values())
+            self._cursor.callproc(sentence, params)
+            self._cursor.nextset()
+            self._result = self._cursor.fetchall()
+            self._cursor.close()
+            try:
+                self._connection.commit()
+            except pymssql.Error as err:
+                logging.error(err)
+                self._connection.rollback()
+            if not self._result:
+                return [None, NoDataFound("SQL Server: No Data was Found")]
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Query Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    callproc = procedure
+
+    async def queryrow(self, sentence, *args, **kwargs):
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        if isinstance(sentence, str):
+            sentence = sentence.encode(self._charset)
+        try:
+            self._cursor = self._connection.cursor(**kwargs)
+            self._cursor.execute(sentence, *args)
+            self._result = self._cursor.fetchone()
+            if not self._result:
+                return [None, NoDataFound("SQL Server: No Data was Found")]
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Query Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def fetch_one(self, sentence, *args, **kwargs):
+        self._result = None
+        await self.valid_operation(sentence)
+        if isinstance(sentence, str):
+            sentence = sentence.encode(self._charset)
+        try:
+            self._cursor = self._connection.cursor(**kwargs)
+            self._cursor.execute(sentence, args)
+            self._result = self._cursor.fetchone()
+            if not self._result:
+                raise NoDataFound("SQL Server: No Data was Found")
+            return self._result
+        except (pymssql.StandardError, pymssql.Error) as err:
+            raise DataError(f"SQL Server Query Error: {err}") from err
+        except RuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Error on Query: {err}") from err
+
+    fetchone = fetch_one
+
+    async def fetch_all(self, sentence, *args, **kwargs):
+        self._result = None
+        await self.valid_operation(sentence)
+        if isinstance(sentence, str):
+            sentence = sentence.encode(self._charset)
+        try:
+            self._cursor = self._connection.cursor(**kwargs)
+            self._cursor.execute(sentence, args)
+            self._result = self._cursor.fetchall()
+            if not self._result:
+                raise NoDataFound("SQL Server: No Data was Found")
+            return self._result
+        except (pymssql.StandardError, pymssql.Error) as err:
+            raise DataError(f"SQL Server Query Error: {err}") from err
+        except RuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Error on Query: {err}") from err
+
+    async def fetch(self, sentence, *args, size: int = 1, **kwargs):
+        self._result = None
+        if not sentence:
+            raise EmptyStatement("Error: Empty Sentence")
+        if not self._connection:
+            await self.connection()
+        try:
+            self._cursor = self._connection.cursor(**kwargs)
+            self._cursor.execute(sentence, args)
+            self._result = self._cursor.fetchmany(size)
+            if not self._result:
+                raise NoDataFound("SQL Server: No Data was Found")
+        except (pymssql.StandardError, pymssql.Error) as err:
+            raise DataError(f"SQL Server Query Error: {err}") from err
+        except RuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Error on Query: {err}") from err
+
+    async def exec(self, sentence, *args, paginated: bool = False, page: str = None, idx: str = None, **kwargs):
+        """exec.
+
+        Calling an Stored Function with parameters.
+        Args:
+            sentence (str): Called Procedure.
+            paginated (bool, optional): True if Stored Function is paginated. Defaults to False.
+            page (str, optional): Rowset parameter with the number of records. Defaults to None.
+            idx (str, optional): Parameter used to declare the Page Index. Defaults to None.
+            *args (optional): Any other parameter required by the function (passed on executed).
+            **kwargs (str, optional): any parameter required by the stored function.
+        Returns:
+            Tuple(Any, Exception): tuple with resultset and possible error.
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self._cursor = self._connection.cursor()
+            if idx is not None and idx not in kwargs:
+                kwargs[idx] = 1
+            if kwargs:
+                params = ", ".join([f"{k}={v}" for k, v in kwargs.items() if k is not None])
+            else:
+                params = ""
+            procedure = f"EXEC {sentence} {params}"
+            self._cursor.execute(procedure, *args)
+            # result = self._cursor.fetchall()
+            if not (result := self._cursor.fetchall()):
+                return [None, NoDataFound("SQL Server: No Data was Found")]
+            else:
+                # preparing for pagination and other stuff.
+                rowlen = len(result)
+                if paginated is True:
+                    results = []
+                    # this procedure is paginated:
+                    sample_row = result[0]
+                    num_rows = sample_row[page]
+                    if num_rows > rowlen:
+                        results.extend(result)
+                        # there are many more results:
+                        index = kwargs[idx]
+                        new_index = index + rowlen
+                        kwargs[idx] = new_index
+                        r, error = await self.exec(sentence, paginated=paginated, page=page, idx=idx, **kwargs)
+                        if r and not error:
+                            results.extend(r)
+                        return await self._serializer(results, error)
+                    else:
+                        return await self._serializer(result, error)
+                else:
+                    # is not paginated, return as usual:
+                    return await self._serializer(result, error)
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Query Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
```

## asyncdb/drivers/mredis.py

```diff
@@ -1,451 +1,451 @@
-#!/usr/bin/env python3
-""" Redis async Provider.
-Notes on redis Provider
---------------------
-This provider implements a few subset of funcionalities from aioredis, is a WIP
-TODO:
- - use jsonpath to query json-objects
- - implements lists and hash datatypes
-"""
-import asyncio
-import time
-import redis
-from asyncdb.exceptions import DriverError, ConnectionTimeout
-from asyncdb.interfaces import ConnectionDSNBackend
-from .abstract import (
-    InitDriver,
-)
-
-
-class mredis(InitDriver, ConnectionDSNBackend):
-    _provider = "redis"
-    _syntax = "json"
-    _encoding = "utf-8"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._dsn = "redis://{host}:{port}/{db}"
-        InitDriver.__init__(self, loop=loop, params=params, **kwargs)
-        ConnectionDSNBackend.__init__(self, dsn=dsn, params=params)
-        try:
-            self._encoding = params["encoding"]
-            del params["encoding"]
-        except KeyError:
-            pass
-
-    ### Context magic Methods
-    def __enter__(self):
-        if not self._connection:
-            self.connection()
-        return self
-
-    def __exit__(self, *args):
-        self.release()
-
-    @property
-    def redis(self):
-        return self._connection
-
-    # Create a redis connection
-    def connection(self, **kwargs):  # pylint: disable=W0236
-        """
-        __init redis initialization.
-        """
-        try:
-            args = {
-                "socket_timeout": self._timeout,
-                "encoding": self._encoding,
-                "decode_responses": True,
-            }
-            if self._dsn:
-                self._pool = redis.ConnectionPool.from_url(url=self._dsn, **args)
-            else:
-                self._pool = redis.ConnectionPool(**self._params)
-            args = {**args, **kwargs}
-            self._logger.debug(f"Redis: Connecting to {self._params}")
-            self._connection = redis.Redis(connection_pool=self._pool, **args)
-            if self._connection:
-                self._connected = True
-                self._initialized_on = time.time()
-            return self
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def release(self, connection=None):
-        """
-        Release a connection and return into pool
-        """
-        if not connection:
-            connection = self._connection
-        try:
-            self._pool.release(connection=connection)
-        except Exception as err:  # pylint: disable=W0703
-            self._logger.exception(err)
-        self._connection = None
-
-    def close(self):  # pylint: disable=W0236,W0221
-        if self._connection:
-            try:
-                self._connection.close()
-            except Exception as err:  # pylint: disable=W0703
-                self._logger.exception(err)
-        if self._pool:
-            try:
-                self._pool.disconnect(inuse_connections=True)
-            except Exception as err:  # pylint: disable=W0703
-                self._logger.exception(err)
-        self._pool = None
-        self._connected = False
-
-    def is_closed(self):
-        return not self._connected
-
-    disconnect = close
-
-    def execute(self, sentence, *args):  # pylint: disable=W0236,W0221
-        try:
-            result = self._connection.send_command(*args)
-            return result
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    execute_many = execute
-
-    def use(self, database):  # pylint: disable=W0236,W0221
-        raise NotImplementedError
-
-    def prepare(self):  # pylint: disable=W0236,W0221
-        raise NotImplementedError
-
-    def get(self, key):
-        try:
-            return self._connection.get(key)
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def query(self, sentence):  # pylint: disable=W0236,W0221
-        return self.get(sentence)
-
-    fetch_all = query
-
-    def queryrow(self, sentence):  # pylint: disable=W0236,W0221
-        result = self.get(sentence)
-        if isinstance(result, list):
-            result = result[0]
-        return result
-
-    fetch_one = queryrow
-
-    def set(self, key, value):
-        try:
-            return self._connection.set(key, value)
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def clear_redis(self, host: bool = True):
-        """
-        Clear a cache.
-        """
-        try:
-            if host is True:
-                return self._connection.flushall()
-            else:
-                return self._connection.flushdb()
-        except Exception as ex:
-            raise DriverError(f"Redis: Error cleaning DB: {ex!s}") from ex
-
-    def exists(self, key, *keys):
-        try:
-            return bool(self._connection.exists(key, *keys))
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def delete(self, key, *keys):
-        try:
-            if keys:
-                return self._connection.delete(*keys)
-            else:
-                return self._connection.delete(key, *keys)
-        except redis.exceptions.ReadOnlyError as err:
-            raise DriverError(f"Redis is Read Only: {err}") from err
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def expire_at(self, key, timestamp):
-        try:
-            return self._connection.expireat(key, timestamp)
-        except TypeError as ex:
-            raise DriverError(f"Redis: wrong Expiration timestamp {timestamp}: {ex}") from ex
-        except redis.exceptions.ReadOnlyError as err:
-            raise DriverError(f"Redis is Read Only: {err}") from err
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def setex(self, key, value, timeout):
-        """
-        setex
-           Set the value and expiration of a Key
-           params:
-            key: key Name
-            value: value of the key
-            timeout: expiration time in seconds
-        """
-        if not isinstance(timeout, int):
-            expiration = 900
-        else:
-            expiration = timeout
-        try:
-            self._connection.setex(key, expiration, value)
-        except TypeError as ex:
-            raise DriverError(f"Redis: wrong Expiration timestamp {expiration}: {ex}") from ex
-        except redis.exceptions.ReadOnlyError as err:
-            raise DriverError(f"Redis is Read Only: {err}") from err
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def persist(self, key):
-        """
-        persist
-            Remove the expiration of a key
-        """
-        try:
-            return self._connection.persist(key)
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Redis Protocol Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def set_key(self, key, value):
-        self.set(key, value)
-
-    def get_key(self, key):
-        return self.get(key)
-
-    ### Hash functions
-    def hmset(self, key, value):
-        """
-        set the value of a key in field (redis dict)
-        """
-        try:
-            self._connection.hmset(key, value)
-        except redis.exceptions.ReadOnlyError as err:
-            raise DriverError(f"Redis is Read Only: {err}") from err
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def hgetall(self, key):
-        """
-        Get all the fields and values in a hash (redis dict)
-        """
-        try:
-            return self._connection.hgetall(key)
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def set_hash(self, key, *args, **kwargs):
-        self.hmset(key, *args, **kwargs)
-
-    def get_hash(self, key):
-        return self.hgetall(key)
-
-    def hkeys(self, key):
-        """
-        Get the keys in a hash (redis dict)
-        """
-        try:
-            return self._connection.hkeys(key)
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def hvals(self, key):
-        """
-        Get the keys in a hash (redis dict)
-        """
-        try:
-            return self._connection.hvals(key)
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def keys(self, key):
-        return self.hkeys(key)
-
-    def values(self, key):
-        return self.hvals(key)
-
-    def hset(self, key, field, value):
-        """
-        Set the string value of a hash field (redis dict)
-        """
-        try:
-            return self._connection.hset(key, field, value)
-        except redis.exceptions.ReadOnlyError as err:
-            raise DriverError(f"Redis is Read Only: {err}") from err
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def hget(self, key, field):
-        """
-        get the value of a hash field (redis dict)
-        """
-        try:
-            return self._connection.hget(key, field)
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def hexists(self, key, field):
-        """
-        Determine if hash field exists on redis dict
-        """
-        try:
-            return self._connection.hexists(key, field)
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def hdel(self, key, field, *fields):
-        """
-        Delete one or more hash fields
-        """
-        try:
-            if fields:
-                return self._connection.hdel(key, *fields)
-            else:
-                return self._connection.hdel(key, field)
-        except redis.exceptions.ReadOnlyError as err:
-            raise DriverError(f"Redis is Read Only: {err}") from err
-        except redis.exceptions.ResponseError as err:
-            raise DriverError(f"Redis Response Error: {err}") from err
-        except redis.exceptions.ConnectionError as err:
-            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
-        except redis.exceptions.TimeoutError as err:
-            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
-        except redis.exceptions.RedisError as err:
-            raise DriverError(f"Unable to connect to Redis: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Unknown Redis Error: {err}") from err
-
-    def test_connection(self, key: str = "test_123", optional: int = 1):  # pylint: disable=W0221,W0236
-        result = None
-        error = None
-        try:
-            self.set(key, optional)
-            result = self.get(key)
-        except Exception as err:  # pylint: disable=W0703
-            error = err
-        finally:
-            self.delete(key)
-            return [result, error]  # pylint: disable=W0150
+#!/usr/bin/env python3
+""" Redis async Provider.
+Notes on redis Provider
+--------------------
+This provider implements a few subset of funcionalities from aioredis, is a WIP
+TODO:
+ - use jsonpath to query json-objects
+ - implements lists and hash datatypes
+"""
+import asyncio
+import time
+import redis
+from ..exceptions import DriverError, ConnectionTimeout
+from ..interfaces import ConnectionDSNBackend
+from .abstract import (
+    InitDriver,
+)
+
+
+class mredis(InitDriver, ConnectionDSNBackend):
+    _provider = "redis"
+    _syntax = "json"
+    _encoding = "utf-8"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._dsn = "redis://{host}:{port}/{db}"
+        InitDriver.__init__(self, loop=loop, params=params, **kwargs)
+        ConnectionDSNBackend.__init__(self, dsn=dsn, params=params)
+        try:
+            self._encoding = params["encoding"]
+            del params["encoding"]
+        except KeyError:
+            pass
+
+    ### Context magic Methods
+    def __enter__(self):
+        if not self._connection:
+            self.connection()
+        return self
+
+    def __exit__(self, *args):
+        self.release()
+
+    @property
+    def redis(self):
+        return self._connection
+
+    # Create a redis connection
+    def connection(self, **kwargs):  # pylint: disable=W0236
+        """
+        __init redis initialization.
+        """
+        try:
+            args = {
+                "socket_timeout": self._timeout,
+                "encoding": self._encoding,
+                "decode_responses": True,
+            }
+            if self._dsn:
+                self._pool = redis.ConnectionPool.from_url(url=self._dsn, **args)
+            else:
+                self._pool = redis.ConnectionPool(**self._params)
+            args = {**args, **kwargs}
+            self._logger.debug(f"Redis: Connecting to {self._params}")
+            self._connection = redis.Redis(connection_pool=self._pool, **args)
+            if self._connection:
+                self._connected = True
+                self._initialized_on = time.time()
+            return self
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def release(self, connection=None):
+        """
+        Release a connection and return into pool
+        """
+        if not connection:
+            connection = self._connection
+        try:
+            self._pool.release(connection=connection)
+        except Exception as err:  # pylint: disable=W0703
+            self._logger.exception(err)
+        self._connection = None
+
+    def close(self):  # pylint: disable=W0236,W0221
+        if self._connection:
+            try:
+                self._connection.close()
+            except Exception as err:  # pylint: disable=W0703
+                self._logger.exception(err)
+        if self._pool:
+            try:
+                self._pool.disconnect(inuse_connections=True)
+            except Exception as err:  # pylint: disable=W0703
+                self._logger.exception(err)
+        self._pool = None
+        self._connected = False
+
+    def is_closed(self):
+        return not self._connected
+
+    disconnect = close
+
+    def execute(self, sentence, *args):  # pylint: disable=W0236,W0221
+        try:
+            result = self._connection.send_command(*args)
+            return result
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    execute_many = execute
+
+    def use(self, database):  # pylint: disable=W0236,W0221
+        raise NotImplementedError
+
+    def prepare(self):  # pylint: disable=W0236,W0221
+        raise NotImplementedError
+
+    def get(self, key):
+        try:
+            return self._connection.get(key)
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def query(self, sentence):  # pylint: disable=W0236,W0221
+        return self.get(sentence)
+
+    fetch_all = query
+
+    def queryrow(self, sentence):  # pylint: disable=W0236,W0221
+        result = self.get(sentence)
+        if isinstance(result, list):
+            result = result[0]
+        return result
+
+    fetch_one = queryrow
+
+    def set(self, key, value):
+        try:
+            return self._connection.set(key, value)
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def clear_redis(self, host: bool = True):
+        """
+        Clear a cache.
+        """
+        try:
+            if host is True:
+                return self._connection.flushall()
+            else:
+                return self._connection.flushdb()
+        except Exception as ex:
+            raise DriverError(f"Redis: Error cleaning DB: {ex!s}") from ex
+
+    def exists(self, key, *keys):
+        try:
+            return bool(self._connection.exists(key, *keys))
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def delete(self, key, *keys):
+        try:
+            if keys:
+                return self._connection.delete(*keys)
+            else:
+                return self._connection.delete(key, *keys)
+        except redis.exceptions.ReadOnlyError as err:
+            raise DriverError(f"Redis is Read Only: {err}") from err
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def expire_at(self, key, timestamp):
+        try:
+            return self._connection.expireat(key, timestamp)
+        except TypeError as ex:
+            raise DriverError(f"Redis: wrong Expiration timestamp {timestamp}: {ex}") from ex
+        except redis.exceptions.ReadOnlyError as err:
+            raise DriverError(f"Redis is Read Only: {err}") from err
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def setex(self, key, value, timeout):
+        """
+        setex
+           Set the value and expiration of a Key
+           params:
+            key: key Name
+            value: value of the key
+            timeout: expiration time in seconds
+        """
+        if not isinstance(timeout, int):
+            expiration = 900
+        else:
+            expiration = timeout
+        try:
+            self._connection.setex(key, expiration, value)
+        except TypeError as ex:
+            raise DriverError(f"Redis: wrong Expiration timestamp {expiration}: {ex}") from ex
+        except redis.exceptions.ReadOnlyError as err:
+            raise DriverError(f"Redis is Read Only: {err}") from err
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def persist(self, key):
+        """
+        persist
+            Remove the expiration of a key
+        """
+        try:
+            return self._connection.persist(key)
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Redis Protocol Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def set_key(self, key, value):
+        self.set(key, value)
+
+    def get_key(self, key):
+        return self.get(key)
+
+    ### Hash functions
+    def hmset(self, key, value):
+        """
+        set the value of a key in field (redis dict)
+        """
+        try:
+            self._connection.hmset(key, value)
+        except redis.exceptions.ReadOnlyError as err:
+            raise DriverError(f"Redis is Read Only: {err}") from err
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def hgetall(self, key):
+        """
+        Get all the fields and values in a hash (redis dict)
+        """
+        try:
+            return self._connection.hgetall(key)
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def set_hash(self, key, *args, **kwargs):
+        self.hmset(key, *args, **kwargs)
+
+    def get_hash(self, key):
+        return self.hgetall(key)
+
+    def hkeys(self, key):
+        """
+        Get the keys in a hash (redis dict)
+        """
+        try:
+            return self._connection.hkeys(key)
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def hvals(self, key):
+        """
+        Get the keys in a hash (redis dict)
+        """
+        try:
+            return self._connection.hvals(key)
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def keys(self, key):
+        return self.hkeys(key)
+
+    def values(self, key):
+        return self.hvals(key)
+
+    def hset(self, key, field, value):
+        """
+        Set the string value of a hash field (redis dict)
+        """
+        try:
+            return self._connection.hset(key, field, value)
+        except redis.exceptions.ReadOnlyError as err:
+            raise DriverError(f"Redis is Read Only: {err}") from err
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def hget(self, key, field):
+        """
+        get the value of a hash field (redis dict)
+        """
+        try:
+            return self._connection.hget(key, field)
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def hexists(self, key, field):
+        """
+        Determine if hash field exists on redis dict
+        """
+        try:
+            return self._connection.hexists(key, field)
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def hdel(self, key, field, *fields):
+        """
+        Delete one or more hash fields
+        """
+        try:
+            if fields:
+                return self._connection.hdel(key, *fields)
+            else:
+                return self._connection.hdel(key, field)
+        except redis.exceptions.ReadOnlyError as err:
+            raise DriverError(f"Redis is Read Only: {err}") from err
+        except redis.exceptions.ResponseError as err:
+            raise DriverError(f"Redis Response Error: {err}") from err
+        except redis.exceptions.ConnectionError as err:
+            raise DriverError(f"Unable to connect to Redis, connection Refused: {err}") from err
+        except redis.exceptions.TimeoutError as err:
+            raise ConnectionTimeout(f"Unable to connect to Redis: {err}") from err
+        except redis.exceptions.RedisError as err:
+            raise DriverError(f"Unable to connect to Redis: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Unknown Redis Error: {err}") from err
+
+    def test_connection(self, key: str = "test_123", optional: int = 1):  # pylint: disable=W0221,W0236
+        result = None
+        error = None
+        try:
+            self.set(key, optional)
+            result = self.get(key)
+        except Exception as err:  # pylint: disable=W0703
+            error = err
+        finally:
+            self.delete(key)
+            return [result, error]  # pylint: disable=W0150
```

## asyncdb/drivers/mongo.py

```diff
@@ -1,104 +1,103 @@
-#!/usr/bin/env python3
-
-import asyncio
-import time
-import motor.motor_asyncio
-from asyncdb.exceptions import (
-    ConnectionTimeout,
-    DataError,
-    EmptyStatement,
-    NoDataFound,
-    DriverError,
-    StatementError,
-    TooManyConnections,
-)
-from .abstract import BaseDriver
-
-
-class mongo(BaseDriver):
-    _provider = "mongodb"
-    _dsn = "'mongodb://{host}:{port}"
-    _syntax = "mongo"
-    _parameters = ()
-    _initialized_on = None
-    _timeout: int = 5
-    _databases: list = []
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        if "username" in params:
-            self._dsn = "mongodb://{username}:{password}@{host}:{port}"
-        if "database" in params:
-            self._dsn = self._dsn + "/{database}"
-        super(mongo, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-        asyncio.set_event_loop(self._loop)
-
-    async def connection(self):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            if self._dsn:
-                self._connection = motor.motor_asyncio.AsyncIOMotorClient(self._dsn)
-            else:
-                params = {"host": self._params["host"], "port": self._params["port"]}
-                if self._params["username"]:
-                    params["username"] = self._params["username"]
-                    params["password"] = self._params["password"]
-                self._connection = motor.motor_asyncio.AsyncIOMotorClient(**params)
-            try:
-                self._databases = await self._connection.list_database_names()
-            except Exception as err:
-                raise DriverError(f"Error Connecting to Mongo: {err}") from err
-            if len(self._databases) > 0:
-                self._connected = True
-                self._initialized_on = time.time()
-            return self
-        except Exception as err:
-            self._connection = None
-            self._cursor = None
-            print(err)
-            raise DriverError(f"connection Error, Terminated: {err}") from err
-
-    async def close(self):
-        """
-        Closing a Connection
-        """
-        try:
-            if self._connection:
-                self._logger.debug("Closing Connection")
-                try:
-                    self._connection.close()
-                except Exception as err:
-                    self._connection = None
-                    raise DriverError("Connection Error, Terminated: {}".format(str(err)))
-        except Exception as err:
-            raise DriverError("Close Error: {}".format(str(err)))
-        finally:
-            self._connection = None
-            self._connected = False
-
-    async def test_connection(self):
-        """
-        Getting information about Server.
-        """
-        error = None
-        result = None
-        if self._connection:
-            print("TEST")
-            try:
-                result = await self._connection.server_info()
-            except Exception as err:
-                error = err
-            finally:
-                return [result, error]
-
-    async def execute(self):
-        pass
-
-    async def query(self):
-        pass
-
-    async def queryrow(self):
-        pass
+#!/usr/bin/env python3
+
+import asyncio
+import time
+import motor.motor_asyncio
+from ..exceptions import (
+    ConnectionTimeout,
+    DataError,
+    EmptyStatement,
+    NoDataFound,
+    DriverError,
+    StatementError,
+    TooManyConnections,
+)
+from .abstract import BaseDriver
+
+
+class mongo(BaseDriver):
+    _provider = "mongodb"
+    _dsn = "'mongodb://{host}:{port}"
+    _syntax = "mongo"
+    _parameters = ()
+    _initialized_on = None
+    _timeout: int = 5
+    _databases: list = []
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        if "username" in params:
+            self._dsn = "mongodb://{username}:{password}@{host}:{port}"
+        if "database" in params:
+            self._dsn = self._dsn + "/{database}"
+        super(mongo, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+        asyncio.set_event_loop(self._loop)
+
+    async def connection(self):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            if self._dsn:
+                self._connection = motor.motor_asyncio.AsyncIOMotorClient(self._dsn)
+            else:
+                params = {"host": self._params["host"], "port": self._params["port"]}
+                if self._params["username"]:
+                    params["username"] = self._params["username"]
+                    params["password"] = self._params["password"]
+                self._connection = motor.motor_asyncio.AsyncIOMotorClient(**params)
+            try:
+                self._databases = await self._connection.list_database_names()
+            except Exception as err:
+                raise DriverError(f"Error Connecting to Mongo: {err}") from err
+            if len(self._databases) > 0:
+                self._connected = True
+                self._initialized_on = time.time()
+            return self
+        except Exception as err:
+            self._connection = None
+            self._cursor = None
+            print(err)
+            raise DriverError(f"connection Error, Terminated: {err}") from err
+
+    async def close(self):
+        """
+        Closing a Connection
+        """
+        try:
+            if self._connection:
+                try:
+                    self._connection.close()
+                except Exception as err:
+                    self._connection = None
+                    raise DriverError("Connection Error, Terminated: {}".format(str(err)))
+        except Exception as err:
+            raise DriverError("Close Error: {}".format(str(err)))
+        finally:
+            self._connection = None
+            self._connected = False
+
+    async def test_connection(self):
+        """
+        Getting information about Server.
+        """
+        error = None
+        result = None
+        if self._connection:
+            print("TEST")
+            try:
+                result = await self._connection.server_info()
+            except Exception as err:
+                error = err
+            finally:
+                return [result, error]
+
+    async def execute(self):
+        pass
+
+    async def query(self):
+        pass
+
+    async def queryrow(self):
+        pass
```

## asyncdb/drivers/sql.py

```diff
@@ -1,67 +1,67 @@
-"""
-SQLProvider.
-
-Abstract class covering all major functionalities for Relational SQL-based databases.
-"""
-import asyncio
-from typing import Any
-from collections.abc import Iterable
-from asyncdb.exceptions import DriverError
-from .abstract import BaseDBDriver, BaseCursor
-
-
-class SQLCursor(BaseCursor):
-    """SQLCursor.
-
-    Base class for all SQL-based Drivers.
-    """
-
-    _connection = None
-
-    async def __aenter__(self) -> "BaseCursor":
-        try:
-            self._cursor = await self._connection.cursor(self._sentence, self._params)
-        except Exception as e:
-            raise DriverError(f"SQLCursor Error: {e}") from e
-        return self
-
-
-class SQLDriver(BaseDBDriver):
-    """SQLDriver.
-
-    Driver for SQL-based providers.
-    """
-
-    _syntax = "sql"
-    _test_query = "SELECT 1"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
-        super(SQLDriver, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-
-    async def close(self, timeout: int = 5) -> None:
-        """
-        Closing Method for any SQL Connector.
-        """
-        try:
-            if self._connection:
-                if self._cursor:
-                    await self._cursor.close()
-                await asyncio.wait_for(self._connection.close(), timeout=timeout)
-        except asyncio.TimeoutError as e:
-            self._logger.warning(f"Close timed out: {e}")
-        except Exception as err:
-            raise DriverError(message=f"{__name__!s}: Closing Error: {err!s}") from err
-        finally:
-            self._connection = None
-            self._connected = False
-
-    # alias for connection
-    disconnect = close
-
-    async def column_info(self, tablename: str, schema: str = "") -> Iterable[Any]:
-        """
-        column_info
-          get column information about a table
-          TODO: rewrite column info using information schema.
-        """
+"""
+SQLProvider.
+
+Abstract class covering all major functionalities for Relational SQL-based databases.
+"""
+import asyncio
+from typing import Any
+from collections.abc import Iterable
+from ..exceptions import DriverError
+from .abstract import BaseDBDriver, BaseCursor
+
+
+class SQLCursor(BaseCursor):
+    """SQLCursor.
+
+    Base class for all SQL-based Drivers.
+    """
+
+    _connection = None
+
+    async def __aenter__(self) -> "BaseCursor":
+        try:
+            self._cursor = await self._connection.cursor(self._sentence, self._params)
+        except Exception as e:
+            raise DriverError(f"SQLCursor Error: {e}") from e
+        return self
+
+
+class SQLDriver(BaseDBDriver):
+    """SQLDriver.
+
+    Driver for SQL-based providers.
+    """
+
+    _syntax = "sql"
+    _test_query = "SELECT 1"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
+        super(SQLDriver, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+
+    async def close(self, timeout: int = 5) -> None:
+        """
+        Closing Method for any SQL Connector.
+        """
+        try:
+            if self._connection:
+                if self._cursor:
+                    await self._cursor.close()
+                await asyncio.wait_for(self._connection.close(), timeout=timeout)
+        except asyncio.TimeoutError as e:
+            self._logger.warning(f"Close timed out: {e}")
+        except Exception as err:
+            raise DriverError(message=f"{__name__!s}: Closing Error: {err!s}") from err
+        finally:
+            self._connection = None
+            self._connected = False
+
+    # alias for connection
+    disconnect = close
+
+    async def column_info(self, tablename: str, schema: str = "") -> Iterable[Any]:
+        """
+        column_info
+          get column information about a table
+          TODO: rewrite column info using information schema.
+        """
```

## asyncdb/drivers/oracle.py

```diff
@@ -1,112 +1,112 @@
-"""Oracle Driver.
-"""
-import os
-import asyncio
-from typing import Union, Any
-from collections.abc import Iterable
-import time
-from datetime import datetime
-import oracledb
-from asyncdb.utils.encoders import DefaultEncoder
-from asyncdb.exceptions import DriverError, NoDataFound
-from .sql import SQLDriver
-
-
-class oracle(SQLDriver):
-    _provider = "oracle"
-    _syntax = "sql"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._test_query = "SELECT 1"
-        _starttime = datetime.now()
-        self._dsn = "{host}:{port}/{database}"
-        self.application_name = os.getenv("APP_NAME", "ASYNCDB")
-        try:
-            self._lib_dir = params["oracle_client"]
-        except (KeyError, TypeError):
-            try:
-                self._lib_dir = kwargs["oracle_client"]
-            except KeyError:
-                self._lib_dir = None
-        try:
-            super(oracle, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-            _generated = datetime.now() - _starttime
-            print(f"Oracle Started in: {_generated}")
-        except Exception as err:
-            raise DriverError(f"Oracle Error: {err}") from err
-        # set the JSON encoder:
-        self._encoder = DefaultEncoder()
-
-    async def prepare(self, sentence: Union[str, list]) -> Any:
-        raise NotImplementedError
-
-    async def connection(self):
-        print(f"{self._provider}: Connected at {self._dsn}")
-        user = self._params["user"]
-        password = self._params["password"]
-        if self._lib_dir is not None:
-            oracledb.init_oracle_client(lib_dir=self._lib_dir, driver_name=f"{self.application_name} : 1.0")
-        self._executor = self.get_executor(executor="thread", max_workers=10)
-        try:
-            self._connection = await self._thread_func(
-                oracledb.connect, dsn=self._dsn, user=user, password=password, executor=self._executor
-            )
-            print("Connection: ", self._connection)
-            self._connected = True
-            self._initialized_on = time.time()
-            if self._init_func is not None and callable(self._init_func):
-                await self._init_func(self._connection)  # pylint: disable=E1102
-            return self
-        except Exception as ex:
-            self._logger.exception(ex, stack_info=True)
-            raise DriverError(f"Oracle Unknown Error: {ex!s}") from ex
-
-    async def close(self, timeout: int = 10) -> None:
-        try:
-            if self._connection:
-                close = self._thread_func(self._connection.close)
-                await asyncio.wait_for(close, timeout)
-                print(f"{self._provider}: Closed connection to {self._dsn}")
-            self._connected = False
-            self._connection = None
-        except Exception as e:
-            print(e)
-            self._logger.exception(e, stack_info=True)
-            raise DriverError(f"Oracle Closing Error: {e!s}") from e
-
-    async def get_columns(self):
-        return {"id": "value"}
-
-    async def use(self, database):
-        print(f"Changing Database to {database}")
-
-    async def query(self, sentence="", **kwargs):
-        error = None
-        print(f"Running Query: {sentence}")
-        result = [{"col1": [1, 2], "col2": [3, 4], "col3": [5, 6]}]
-        return await self._serializer(result, error)
-
-    fetch_all = query
-
-    async def execute(self, sentence: str, *args, **kwargs):
-        print(f"Execute Query {sentence}")
-        data = []
-        error = None
-        result = [data, error]
-        return await self._serializer(result, error)
-
-    execute_many = execute
-
-    async def queryrow(self, sentence=""):
-        error = None
-        print(f"Running Row {sentence}")
-        result = {"col1": [1, 2], "col2": [3, 4], "col3": [5, 6]}
-        return await self._serializer(result, error)
-
-    fetch_one = queryrow
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError
+"""Oracle Driver.
+"""
+import os
+import asyncio
+from typing import Union, Any
+from collections.abc import Iterable
+import time
+from datetime import datetime
+import oracledb
+from ..utils.encoders import DefaultEncoder
+from ..exceptions import DriverError, NoDataFound
+from .sql import SQLDriver
+
+
+class oracle(SQLDriver):
+    _provider = "oracle"
+    _syntax = "sql"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._test_query = "SELECT 1"
+        _starttime = datetime.now()
+        self._dsn = "{host}:{port}/{database}"
+        self.application_name = os.getenv("APP_NAME", "ASYNCDB")
+        try:
+            self._lib_dir = params["oracle_client"]
+        except (KeyError, TypeError):
+            try:
+                self._lib_dir = kwargs["oracle_client"]
+            except KeyError:
+                self._lib_dir = None
+        try:
+            super(oracle, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+            _generated = datetime.now() - _starttime
+            print(f"Oracle Started in: {_generated}")
+        except Exception as err:
+            raise DriverError(f"Oracle Error: {err}") from err
+        # set the JSON encoder:
+        self._encoder = DefaultEncoder()
+
+    async def prepare(self, sentence: Union[str, list]) -> Any:
+        raise NotImplementedError
+
+    async def connection(self):
+        print(f"{self._provider}: Connected at {self._dsn}")
+        user = self._params["user"]
+        password = self._params["password"]
+        if self._lib_dir is not None:
+            oracledb.init_oracle_client(lib_dir=self._lib_dir, driver_name=f"{self.application_name} : 1.0")
+        self._executor = self.get_executor(executor="thread", max_workers=10)
+        try:
+            self._connection = await self._thread_func(
+                oracledb.connect, dsn=self._dsn, user=user, password=password, executor=self._executor
+            )
+            print("Connection: ", self._connection)
+            self._connected = True
+            self._initialized_on = time.time()
+            if self._init_func is not None and callable(self._init_func):
+                await self._init_func(self._connection)  # pylint: disable=E1102
+            return self
+        except Exception as ex:
+            self._logger.exception(ex, stack_info=True)
+            raise DriverError(f"Oracle Unknown Error: {ex!s}") from ex
+
+    async def close(self, timeout: int = 10) -> None:
+        try:
+            if self._connection:
+                close = self._thread_func(self._connection.close)
+                await asyncio.wait_for(close, timeout)
+                print(f"{self._provider}: Closed connection to {self._dsn}")
+            self._connected = False
+            self._connection = None
+        except Exception as e:
+            print(e)
+            self._logger.exception(e, stack_info=True)
+            raise DriverError(f"Oracle Closing Error: {e!s}") from e
+
+    async def get_columns(self):
+        return {"id": "value"}
+
+    async def use(self, database):
+        print(f"Changing Database to {database}")
+
+    async def query(self, sentence="", **kwargs):
+        error = None
+        print(f"Running Query: {sentence}")
+        result = [{"col1": [1, 2], "col2": [3, 4], "col3": [5, 6]}]
+        return await self._serializer(result, error)
+
+    fetch_all = query
+
+    async def execute(self, sentence: str, *args, **kwargs):
+        print(f"Execute Query {sentence}")
+        data = []
+        error = None
+        result = [data, error]
+        return await self._serializer(result, error)
+
+    execute_many = execute
+
+    async def queryrow(self, sentence=""):
+        error = None
+        print(f"Running Row {sentence}")
+        result = {"col1": [1, 2], "col2": [3, 4], "col3": [5, 6]}
+        return await self._serializer(result, error)
+
+    fetch_one = queryrow
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError
```

## asyncdb/drivers/mysqlclient.py

```diff
@@ -1,520 +1,521 @@
-#!/usr/bin/env python3
-
-import asyncio
-import time
-from typing import Optional, Union, Any
-from collections.abc import Callable, Iterable
-import ssl
-from concurrent.futures import ThreadPoolExecutor
-import MySQLdb
-from MySQLdb.cursors import DictCursor
-from asyncdb.exceptions import (
-    ConnectionTimeout,
-    NoDataFound,
-    DriverError,
-)
-from asyncdb.interfaces import DBCursorBackend
-from .abstract import BasePool
-from .sql import SQLCursor, SQLDriver
-
-
-class mysqlCursor(SQLCursor):
-    _connection: Any = None
-
-
-class mysqlclientPool(BasePool):
-    _setup_func: Optional[Callable] = None
-    _init_func: Optional[Callable] = None
-
-    def __init__(
-        self, dsn: str = None, loop: asyncio.AbstractEventLoop = None, params: Optional[dict] = None, **kwargs
-    ):
-        self._test_query = "SELECT 1"
-        self._max_clients = 30
-        self._min_size = 10
-        self._dsn = "mysql://{user}:{password}@{host}:{port}/{database}"
-        self._init_command = kwargs.pop("init_command", None)
-        self._sql_modes = kwargs.pop("sql_modes", None)
-        self._executor = ThreadPoolExecutor(max_workers=self._min_size)
-        self._queue = asyncio.Queue(maxsize=self._max_clients)
-        self._current_size: int = 0
-        super(mysqlclientPool, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-
-    async def _connection_(self):
-        params = {}
-        if self._init_command:
-            params["init_command"] = self._init_command
-        if self._sql_modes:
-            params["sql_mode"] = self._sql_modes
-        connection = await self._thread_func(
-            MySQLdb.connect,
-            host=self._params["host"],
-            port=int(self._params["port"]),
-            user=self._params["user"],
-            password=self._params["password"],
-            database=self._params["database"],
-            connect_timeout=self._timeout,
-            **params,
-            executor=self._executor,
-        )
-        return connection
-
-    async def connect(self):
-        """
-        Create a database connection pool.
-        """
-        self._logger.debug("MySQL Client: Connecting to {}".format(self._params))
-        try:
-            # First connection of Pool
-            self._pool = await self._connection_()
-        except MySQLdb.OperationalError as err:
-            raise ConnectionTimeout(f"MySQL: Unable to connect to database: {err}")
-        except Exception as err:
-            raise DriverError(f"Unknown Error: {err}")
-        # is connected
-        if self._pool:
-            self._connected = True
-            self._initialized_on = time.time()
-        return self
-
-    async def acquire(self):
-        """
-        Acquire a connection from the pool, creating a new one if needed.
-        """
-        if self._queue.empty() and self._current_size < self._max_clients:
-            try:
-                self._connection = await self._connection_()
-                self._current_size += 1
-            except Exception as err:
-                raise DriverError(f"MySQL: Unable to acquire a connection from the pool: {err}")
-        if self._connection:
-            db = mysqlclient(pool=self)
-            db.set_connection(self._connection)
-        return db
-
-    async def release(self, connection=None):
-        """
-        Release a connection from the pool
-        """
-        if not connection:
-            conn = self._connection
-        elif isinstance(connection, mysqlclient):
-            conn = connection.get_connection()
-        else:
-            conn = connection
-        try:
-            if self._queue.full():
-                conn.close()
-                self._current_size -= 1
-            else:
-                await self._queue.put(conn)
-        except Exception as err:
-            raise DriverError(f"MySQL: Unable to release a connection from the pool: {err}")
-
-    async def wait_close(self, gracefully=True):
-        """
-        close
-            Close Pool Connection
-        """
-        raise NotImplementedError
-
-    async def close(self):
-        """
-        Close Pool.
-        """
-        while not self._queue.empty():
-            conn = await self._queue.get()
-            try:
-                conn.close()
-            except MySQLdb.OperationalError as err:
-                self._logger.warning(f"MySQL: Unable to close connection: {err}")
-            self._current_size -= 1
-        # Close connection from the pool:
-        await self._thread_func(self._pool.close)
-        self._connected = False
-        self._logger.debug(f"MySQL Connection Closed.")
-
-    disconnect = close
-
-    def terminate(self):
-        self._pool.terminate()
-
-    def _execute(self, conn, sentence: str, *args):
-        """
-        Execute a connection into the Pool
-        """
-        try:
-            with conn.cursor() as cursor:
-                result = cursor.execute(sentence, *args)
-            return result
-        except MySQLdb.Error as e:
-            raise DriverError(f"Error executing query: {e}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Unable to Execute: {err}")
-
-    async def execute(self, sentence, *args):
-        """
-        Execute a connection into the Pool
-        """
-        error = None
-        try:
-            loop = asyncio.get_running_loop()
-            conn = await self._connection_()
-            result = await loop.run_in_executor(self._executor, self._execute, conn, sentence, *args)
-        except Exception as err:
-            error = f"MySQL: Unable to Execute: {err}"
-        finally:
-            conn.close()
-            return [result, error]
-
-    async def test_connection(self, *args):
-        """Test Connnection.
-        Making a connection Test using the basic Query Method.
-        """
-        result = None
-        error = None
-        if self._test_query is None:
-            return [None, NotImplementedError()]
-        try:
-            result = await self.execute(self._test_query, *args)
-        except DriverError as err:
-            error = err
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-
-class mysqlclient(SQLDriver, DBCursorBackend):
-    _provider = "mysql"
-    _syntax = "sql"
-    _test_query = "SELECT 1"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._dsn = "mysql://{user}:{password}@{host}:{port}/{database}"
-        self._prepared = None
-        self._cursor = None
-        self._transaction = None
-        self._init_command = kwargs.pop("init_command", None)
-        self._sql_modes = kwargs.pop("sql_modes", None)
-        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
-        DBCursorBackend.__init__(self)
-        if "pool" in kwargs:
-            self._pool = kwargs["pool"]
-            self._loop = self._pool.get_loop()
-        ### SSL Support:
-        self.ssl: bool = False
-        if params and "ssl" in params:
-            ssloptions = params["ssl"]
-        elif "ssl" in kwargs:
-            ssloptions = kwargs["ssl"]
-        else:
-            ssloptions = None
-        if ssloptions:
-            self.ssl: bool = True
-            try:
-                check_hostname = ssloptions["check_hostname"]
-            except KeyError:
-                check_hostname = False
-            ### certificate Support:
-            try:
-                ca_file = ssloptions["cafile"]
-            except KeyError:
-                ca_file = None
-            args = {"cafile": ca_file}
-            self.sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, **args)
-            # Certificate Chain:
-            try:
-                certs = {"certfile": ssloptions["certfile"], "keyfile": ssloptions["keyfile"]}
-            except KeyError:
-                certs = {"certfile": None, "keyfile": None}
-            if certs["certfile"]:
-                self.sslctx.load_cert_chain(**certs)
-            self.sslctx.check_hostname = check_hostname
-
-    async def close(self, timeout: int = 10) -> None:
-        try:
-            if self._connection:
-                close = self._thread_func(self._connection.close)
-                await asyncio.wait_for(close, timeout)
-                print(f"{self._provider}: Closed connection to {self._dsn}")
-        except Exception as e:
-            print(e)
-            self._logger.exception(e, stack_info=True)
-            raise DriverError(f"MySQL Closing Error: {e!s}") from e
-        finally:
-            self._connected = False
-            self._connection = None
-
-    def terminate(self):
-        self.terminate()
-
-    async def _connection_(self):
-        params = {}
-        if self._init_command:
-            params["init_command"] = self._init_command
-        if self._sql_modes:
-            params["sql_mode"] = self._sql_modes
-        try:
-            connection = await self._thread_func(
-                MySQLdb.connect,
-                host=self._params["host"],
-                port=int(self._params["port"]),
-                user=self._params["user"],
-                password=self._params["password"],
-                database=self._params["database"],
-                connect_timeout=self._timeout,
-                **params,
-                executor=self._executor,
-            )
-        except Exception as exc:
-            raise DriverError(f"MySQL: Unable to connect to database: {exc}")
-        return connection
-
-    async def connection(self):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            if not self._pool:
-                self._connection = await self._connection_()
-            else:
-                self._connection = await self._pool.acquire()
-            if self._connection:
-                self._connected = True
-                self._initialized_on = time.time()
-        except DriverError:
-            raise
-        except Exception as err:
-            self._connection = None
-            raise DriverError(f"Connection Error: {err}")
-        finally:
-            return self
-
-    async def release(self):
-        """
-        Release a Connection
-        """
-        try:
-            if self._pool:
-                release = asyncio.create_task(self._pool.release(self._connection, timeout=10))
-                asyncio.ensure_future(release, loop=self._loop)
-                return await release
-            else:
-                self._connection.close()
-        except Exception as err:
-            raise DriverError(f"Release Error: {err}")
-        finally:
-            self._connected = False
-            self._connection = None
-
-    def prepared_statement(self):
-        return self._prepared
-
-    @property
-    def connected(self):
-        return self._connected
-
-    async def prepare(self, sentence: str):
-        """
-        Preparing a sentence
-        """
-        raise NotImplementedError
-
-    def _query_(self, conn, sentence: str, *args, returns: str = "all", size: int = None):
-        """
-        Execute a connection into the Pool
-        """
-        try:
-            with conn.cursor(DictCursor) as cursor:
-                cursor.execute(sentence, *args)
-                if returns == "all":
-                    result = cursor.fetchall()
-                elif returns == "one":
-                    result = cursor.fetchone()
-                elif returns == "many":
-                    result = cursor.fetchmany(size)
-                else:
-                    result = cursor.fetchall()
-            return result
-        except MySQLdb.Error as e:
-            raise DriverError(f"Error executing query: {e}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Unable to Execute: {err}")
-
-    async def query(self, sentence: str, *args, size: int = None):
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            if size is not None:
-                returns = "many"
-            else:
-                returns = "all"
-            self._result = await self._thread_func(
-                self._query_, self._connection, sentence, *args, returns=returns, size=size
-            )
-            if not self._result:
-                raise NoDataFound("MySQL: No Data was Found")
-        except NoDataFound:
-            error = "Mysql: No Data was Found"
-        except RuntimeError as err:
-            error = "Runtime Error: {}".format(str(err))
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-        finally:
-            self.generated_at()
-            if error:
-                return [None, error]
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def queryrow(self, sentence: str, *args):
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            self._result = await self._thread_func(self._query_, self._connection, sentence, *args, returns="one")
-            if not self._result:
-                raise NoDataFound("MySQL: No Data was Found")
-        except NoDataFound:
-            error = "Mysql: No Data was Found"
-        except RuntimeError as err:
-            error = "Runtime Error: {}".format(str(err))
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-        finally:
-            self.generated_at()
-            if error:
-                return [None, error]
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def fetch_one(self, sentence: str, *args):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            result = await self._thread_func(self._query_, self._connection, sentence, *args, returns="one")
-            if not result:
-                raise NoDataFound("MySQL: No Data was Found")
-            return result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(f"MySQL Runtime Error: {err}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Error on Query: {err}")
-        finally:
-            self.generated_at()
-
-    async def fetch_all(self, sentence: str, *args):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            result = await self._thread_func(self._query_, self._connection, sentence, *args, returns="all")
-            if not result:
-                raise NoDataFound("MySQL: No Data was Found")
-            return result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(f"MySQL Runtime Error: {err}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Error on Query: {err}")
-        finally:
-            self.generated_at()
-
-    async def fetch_many(self, sentence: str, *args, size: int = 1000):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            result = await self._thread_func(self._query_, self._connection, sentence, *args, returns="many", size=size)
-            if not result:
-                raise NoDataFound("MySQL: No Data was Found")
-            return result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(f"MySQL Runtime Error: {err}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Error on Query: {err}")
-        finally:
-            self.generated_at()
-
-    def _execute_(self, conn, sentence: str, *args):
-        """
-        Execute a connection into the Pool
-        """
-        try:
-            with conn.cursor(DictCursor) as cursor:
-                result = cursor.execute(sentence, *args)
-            return result
-        except MySQLdb.Error as e:
-            raise DriverError(f"Error executing query: {e}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Unable to Execute: {err}")
-
-    async def execute(self, sentence: str, *args):
-        """Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        error = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            result = await self._thread_func(self._execute_, self._connection, sentence, *args)
-            return [result, None]
-        except Exception as err:
-            error = "Error on Execute: {}".format(str(err))
-        finally:
-            self.generated_at()
-            return [result, error]
-
-    def _executemany_(self, conn, sentence: str, args):
-        """
-        Execute a connection into the Pool
-        """
-        try:
-            with conn.cursor(DictCursor) as cursor:
-                result = cursor.executemany(sentence, args)
-            return result
-        except MySQLdb.Error as e:
-            raise DriverError(f"Error executing query: {e}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Unable to Execute: {err}")
-
-    async def executemany(self, sentence: str, args: Union[tuple, list]):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            result = await self._thread_func(self._executemany_, self._connection, sentence, args)
-            return result
-        except Exception as err:
-            raise DriverError(f"MySQL: Error on Execute: {err}")
-        finally:
-            self.generated_at()
-
-    execute_many = executemany
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    async def use(self, database: str):
-        raise NotImplementedError  # pragma: no cover
-
-    """
-    Cursor Iterator Context
-    """
-
-    def __aiter__(self):
-        return self
-
-    async def __anext__(self):
-        data = await self._cursor.fetchrow()
-        if data is not None:
-            return data
-        else:
-            raise StopAsyncIteration
+#!/usr/bin/env python3
+
+import asyncio
+import time
+from typing import Optional, Union, Any
+from collections.abc import Callable, Iterable
+import ssl
+from concurrent.futures import ThreadPoolExecutor
+import MySQLdb
+from MySQLdb.cursors import DictCursor
+from asyncdb.exceptions import (
+    ConnectionTimeout,
+    NoDataFound,
+    DriverError,
+)
+from ..interfaces import DBCursorBackend
+from .abstract import BasePool
+from .sql import SQLCursor, SQLDriver
+
+
+class mysqlCursor(SQLCursor):
+    _connection: Any = None
+
+
+class mysqlclientPool(BasePool):
+    _setup_func: Optional[Callable] = None
+    _init_func: Optional[Callable] = None
+
+    def __init__(
+        self, dsn: str = None, loop: asyncio.AbstractEventLoop = None, params: Optional[dict] = None, **kwargs
+    ):
+        self._test_query = "SELECT 1"
+        self._max_clients = 30
+        self._min_size = 10
+        self._dsn = "mysql://{user}:{password}@{host}:{port}/{database}"
+        self._init_command = kwargs.pop("init_command", None)
+        self._sql_modes = kwargs.pop("sql_modes", None)
+        self._executor = ThreadPoolExecutor(max_workers=self._min_size)
+        self._queue = asyncio.Queue(maxsize=self._max_clients)
+        self._current_size: int = 0
+        super(mysqlclientPool, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+
+    async def _connection_(self):
+        params = {}
+        if self._init_command:
+            params["init_command"] = self._init_command
+        if self._sql_modes:
+            params["sql_mode"] = self._sql_modes
+        connection = await self._thread_func(
+            MySQLdb.connect,
+            host=self._params["host"],
+            port=int(self._params["port"]),
+            user=self._params["user"],
+            password=self._params["password"],
+            database=self._params["database"],
+            connect_timeout=self._timeout,
+            **params,
+            executor=self._executor,
+        )
+        return connection
+
+    async def connect(self):
+        """
+        Create a database connection pool.
+        """
+        self._logger.debug("MySQL Client: Connecting to {}".format(self._params))
+        try:
+            # First connection of Pool
+            self._pool = await self._connection_()
+        except MySQLdb.OperationalError as err:
+            raise ConnectionTimeout(f"MySQL: Unable to connect to database: {err}")
+        except Exception as err:
+            raise DriverError(f"Unknown Error: {err}")
+        # is connected
+        if self._pool:
+            self._connected = True
+            self._initialized_on = time.time()
+        return self
+
+    async def acquire(self):
+        """
+        Acquire a connection from the pool, creating a new one if needed.
+        """
+        if self._queue.empty() and self._current_size < self._max_clients:
+            try:
+                self._connection = await self._connection_()
+                self._current_size += 1
+            except Exception as err:
+                raise DriverError(f"MySQL: Unable to acquire a connection from the pool: {err}")
+        if self._connection:
+            db = mysqlclient(pool=self)
+            db.set_connection(self._connection)
+        return db
+
+    async def release(self, connection=None):
+        """
+        Release a connection from the pool
+        """
+        if not connection:
+            conn = self._connection
+        elif isinstance(connection, mysqlclient):
+            conn = connection.get_connection()
+        else:
+            conn = connection
+        try:
+            if self._queue.full():
+                conn.close()
+                self._current_size -= 1
+            else:
+                await self._queue.put(conn)
+        except Exception as err:
+            raise DriverError(f"MySQL: Unable to release a connection from the pool: {err}")
+
+    async def wait_close(self, gracefully=True):
+        """
+        close
+            Close Pool Connection
+        """
+        raise NotImplementedError
+
+    async def close(self):
+        """
+        Close Pool.
+        """
+        while not self._queue.empty():
+            conn = await self._queue.get()
+            try:
+                conn.close()
+            except MySQLdb.OperationalError as err:
+                self._logger.warning(f"MySQL: Unable to close connection: {err}")
+            self._current_size -= 1
+        # Close connection from the pool:
+        await self._thread_func(self._pool.close)
+        self._connected = False
+        self._logger.debug(f"MySQL Connection Closed.")
+
+    disconnect = close
+
+    def terminate(self):
+        self._pool.terminate()
+
+    def _execute(self, conn, sentence: str, *args):
+        """
+        Execute a connection into the Pool
+        """
+        try:
+            with conn.cursor() as cursor:
+                result = cursor.execute(sentence, *args)
+            return result
+        except MySQLdb.Error as e:
+            raise DriverError(f"Error executing query: {e}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Unable to Execute: {err}")
+
+    async def execute(self, sentence, *args):
+        """
+        Execute a connection into the Pool
+        """
+        error = None
+        result = None
+        try:
+            loop = asyncio.get_running_loop()
+            conn = await self._connection_()
+            result = await loop.run_in_executor(self._executor, self._execute, conn, sentence, *args)
+        except Exception as err:
+            error = f"MySQL: Unable to Execute: {err}"
+        finally:
+            conn.close()
+            return [result, error]
+
+    async def test_connection(self, *args):
+        """Test Connnection.
+        Making a connection Test using the basic Query Method.
+        """
+        result = None
+        error = None
+        if self._test_query is None:
+            return [None, NotImplementedError()]
+        try:
+            result = await self.execute(self._test_query, *args)
+        except DriverError as err:
+            error = err
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+
+class mysqlclient(SQLDriver, DBCursorBackend):
+    _provider = "mysql"
+    _syntax = "sql"
+    _test_query = "SELECT 1"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._dsn = "mysql://{user}:{password}@{host}:{port}/{database}"
+        self._prepared = None
+        self._cursor = None
+        self._transaction = None
+        self._init_command = kwargs.pop("init_command", None)
+        self._sql_modes = kwargs.pop("sql_modes", None)
+        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
+        DBCursorBackend.__init__(self)
+        if "pool" in kwargs:
+            self._pool = kwargs["pool"]
+            self._loop = self._pool.get_loop()
+        ### SSL Support:
+        self.ssl: bool = False
+        if params and "ssl" in params:
+            ssloptions = params["ssl"]
+        elif "ssl" in kwargs:
+            ssloptions = kwargs["ssl"]
+        else:
+            ssloptions = None
+        if ssloptions:
+            self.ssl: bool = True
+            try:
+                check_hostname = ssloptions["check_hostname"]
+            except KeyError:
+                check_hostname = False
+            ### certificate Support:
+            try:
+                ca_file = ssloptions["cafile"]
+            except KeyError:
+                ca_file = None
+            args = {"cafile": ca_file}
+            self.sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, **args)
+            # Certificate Chain:
+            try:
+                certs = {"certfile": ssloptions["certfile"], "keyfile": ssloptions["keyfile"]}
+            except KeyError:
+                certs = {"certfile": None, "keyfile": None}
+            if certs["certfile"]:
+                self.sslctx.load_cert_chain(**certs)
+            self.sslctx.check_hostname = check_hostname
+
+    async def close(self, timeout: int = 10) -> None:
+        try:
+            if self._connection:
+                close = self._thread_func(self._connection.close)
+                await asyncio.wait_for(close, timeout)
+                print(f"{self._provider}: Closed connection to {self._dsn}")
+        except Exception as e:
+            print(e)
+            self._logger.exception(e, stack_info=True)
+            raise DriverError(f"MySQL Closing Error: {e!s}") from e
+        finally:
+            self._connected = False
+            self._connection = None
+
+    def terminate(self):
+        self.terminate()
+
+    async def _connection_(self):
+        params = {}
+        if self._init_command:
+            params["init_command"] = self._init_command
+        if self._sql_modes:
+            params["sql_mode"] = self._sql_modes
+        try:
+            connection = await self._thread_func(
+                MySQLdb.connect,
+                host=self._params["host"],
+                port=int(self._params["port"]),
+                user=self._params["user"],
+                password=self._params["password"],
+                database=self._params["database"],
+                connect_timeout=self._timeout,
+                **params,
+                executor=self._executor,
+            )
+        except Exception as exc:
+            raise DriverError(f"MySQL: Unable to connect to database: {exc}")
+        return connection
+
+    async def connection(self):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            if not self._pool:
+                self._connection = await self._connection_()
+            else:
+                self._connection = await self._pool.acquire()
+            if self._connection:
+                self._connected = True
+                self._initialized_on = time.time()
+        except DriverError:
+            raise
+        except Exception as err:
+            self._connection = None
+            raise DriverError(f"Connection Error: {err}")
+        finally:
+            return self
+
+    async def release(self):
+        """
+        Release a Connection
+        """
+        try:
+            if self._pool:
+                release = asyncio.create_task(self._pool.release(self._connection, timeout=10))
+                asyncio.ensure_future(release, loop=self._loop)
+                return await release
+            else:
+                self._connection.close()
+        except Exception as err:
+            raise DriverError(f"Release Error: {err}")
+        finally:
+            self._connected = False
+            self._connection = None
+
+    def prepared_statement(self):
+        return self._prepared
+
+    @property
+    def connected(self):
+        return self._connected
+
+    async def prepare(self, sentence: str):
+        """
+        Preparing a sentence
+        """
+        raise NotImplementedError
+
+    def _query_(self, conn, sentence: str, *args, returns: str = "all", size: int = None):
+        """
+        Execute a connection into the Pool
+        """
+        try:
+            with conn.cursor(DictCursor) as cursor:
+                cursor.execute(sentence, *args)
+                if returns == "all":
+                    result = cursor.fetchall()
+                elif returns == "one":
+                    result = cursor.fetchone()
+                elif returns == "many":
+                    result = cursor.fetchmany(size)
+                else:
+                    result = cursor.fetchall()
+            return result
+        except MySQLdb.Error as e:
+            raise DriverError(f"Error executing query: {e}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Unable to Execute: {err}")
+
+    async def query(self, sentence: str, *args, size: int = None):
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            if size is not None:
+                returns = "many"
+            else:
+                returns = "all"
+            self._result = await self._thread_func(
+                self._query_, self._connection, sentence, *args, returns=returns, size=size
+            )
+            if not self._result:
+                raise NoDataFound("MySQL: No Data was Found")
+        except NoDataFound:
+            error = "Mysql: No Data was Found"
+        except RuntimeError as err:
+            error = "Runtime Error: {}".format(str(err))
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+        finally:
+            self.generated_at()
+            if error:
+                return [None, error]
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def queryrow(self, sentence: str, *args):
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            self._result = await self._thread_func(self._query_, self._connection, sentence, *args, returns="one")
+            if not self._result:
+                raise NoDataFound("MySQL: No Data was Found")
+        except NoDataFound:
+            error = "Mysql: No Data was Found"
+        except RuntimeError as err:
+            error = "Runtime Error: {}".format(str(err))
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+        finally:
+            self.generated_at()
+            if error:
+                return [None, error]
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def fetch_one(self, sentence: str, *args):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            result = await self._thread_func(self._query_, self._connection, sentence, *args, returns="one")
+            if not result:
+                raise NoDataFound("MySQL: No Data was Found")
+            return result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(f"MySQL Runtime Error: {err}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Error on Query: {err}")
+        finally:
+            self.generated_at()
+
+    async def fetch_all(self, sentence: str, *args):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            result = await self._thread_func(self._query_, self._connection, sentence, *args, returns="all")
+            if not result:
+                raise NoDataFound("MySQL: No Data was Found")
+            return result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(f"MySQL Runtime Error: {err}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Error on Query: {err}")
+        finally:
+            self.generated_at()
+
+    async def fetch_many(self, sentence: str, *args, size: int = 1000):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            result = await self._thread_func(self._query_, self._connection, sentence, *args, returns="many", size=size)
+            if not result:
+                raise NoDataFound("MySQL: No Data was Found")
+            return result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(f"MySQL Runtime Error: {err}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Error on Query: {err}")
+        finally:
+            self.generated_at()
+
+    def _execute_(self, conn, sentence: str, *args):
+        """
+        Execute a connection into the Pool
+        """
+        try:
+            with conn.cursor(DictCursor) as cursor:
+                result = cursor.execute(sentence, *args)
+            return result
+        except MySQLdb.Error as e:
+            raise DriverError(f"Error executing query: {e}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Unable to Execute: {err}")
+
+    async def execute(self, sentence: str, *args):
+        """Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        error = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            result = await self._thread_func(self._execute_, self._connection, sentence, *args)
+            return [result, None]
+        except Exception as err:
+            error = "Error on Execute: {}".format(str(err))
+        finally:
+            self.generated_at()
+            return [result, error]
+
+    def _executemany_(self, conn, sentence: str, args):
+        """
+        Execute a connection into the Pool
+        """
+        try:
+            with conn.cursor(DictCursor) as cursor:
+                result = cursor.executemany(sentence, args)
+            return result
+        except MySQLdb.Error as e:
+            raise DriverError(f"Error executing query: {e}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Unable to Execute: {err}")
+
+    async def executemany(self, sentence: str, args: Union[tuple, list]):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            result = await self._thread_func(self._executemany_, self._connection, sentence, args)
+            return result
+        except Exception as err:
+            raise DriverError(f"MySQL: Error on Execute: {err}")
+        finally:
+            self.generated_at()
+
+    execute_many = executemany
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    async def use(self, database: str):
+        raise NotImplementedError  # pragma: no cover
+
+    """
+    Cursor Iterator Context
+    """
+
+    def __aiter__(self):
+        return self
+
+    async def __anext__(self):
+        data = await self._cursor.fetchrow()
+        if data is not None:
+            return data
+        else:
+            raise StopAsyncIteration
```

## asyncdb/drivers/hazel.py

```diff
@@ -1,350 +1,350 @@
-"""Hazelcast AsyncDB Driver.
-
-"""
-import asyncio
-import logging
-from datetime import datetime
-from typing import Union, Any, ClassVar
-from collections.abc import Sequence
-from datamodel import BaseModel, Field
-
-import hazelcast
-from hazelcast.serialization.api import Portable
-from hazelcast.errors import HazelcastError, HazelcastClientNotActiveError
-from asyncdb.utils.types import Entity
-from asyncdb.exceptions import (
-    DriverError,
-    NoDataFound,
-)
-from .abstract import InitDriver
-
-
-class HazelPortable(BaseModel, Portable):
-    FACTORY_ID: ClassVar[int] = Field(default=1, repr=False)
-    CLASS_ID: ClassVar[int] = Field(default=1, repr=False)
-
-    def write_portable(self, writer):
-        for name, f in self.columns().items():
-            if name == "FACTORY_ID":
-                continue
-            _type = f.type
-            value = getattr(self, name)
-            if Entity.is_integer(_type):
-                writer.write_int(name, value)
-            elif _type == bool:
-                writer.write_boolean(name, value)
-            elif Entity.is_number(_type):
-                writer.write_long(name, value)
-            else:
-                writer.write_string(name, value)
-
-    def read_portable(self, reader):
-        for name, f in self.columns().items():
-            if name == "FACTORY_ID":
-                continue
-            _type = f.type
-            if Entity.is_integer(_type):
-                value = reader.read_int(name)
-            elif _type == bool:
-                val = reader.read_boolean(name)
-                value = bool(val)
-            elif Entity.is_number(_type):
-                value = reader.read_long(name)
-            else:
-                value = reader.read_string(name)
-            try:
-                setattr(self, name, value)
-            except (TypeError, ValueError) as e:
-                logging.warning(f"Hazelcast Error on Portable: {e}")
-
-    @classmethod
-    def set_factory(cls, fid: int = 1):
-        cls.FACTORY_ID = fid
-
-    def get_factory_id(self):
-        return self.__class__.FACTORY_ID
-
-    def get_class_id(self):
-        return self.__class__.FACTORY_ID
-
-
-class hazel(InitDriver):
-    _provider = "hazelcast"
-    _syntax = "sql"
-
-    def __init__(self, dsn: str = None, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
-        self._test_query = None
-        self._server = None
-        _starttime = datetime.now()
-        self._timeout: int = 10
-        try:
-            self._map_name = params["map_name"]
-            del params["map_name"]
-        except KeyError:
-            self._map_name = "asyncdb-map"
-        try:
-            self._cluster = params["cluster"]
-            del params["cluster"]
-        except KeyError:
-            self._cluster = None
-        try:
-            self._client = params["client"]
-            del params["client"]
-        except KeyError:
-            self._client = "asyncdb"
-        try:
-            host = params["host"]
-        except KeyError as ex:
-            raise DriverError("Hazelcast: Unable to find *host* in parameters.") from ex
-        try:
-            port = params["port"]
-        except KeyError:
-            port = 5701
-        self._server = f"{host}:{port}"
-        ### factories:
-        try:
-            self.factories = params["factories"]
-            del params["factories"]
-        except KeyError:
-            self.factories = []
-        try:
-            super(hazel, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-            _generated = datetime.now() - _starttime
-            print(f"HazelCast Started in: {_generated}")
-        except Exception as err:
-            raise DriverError(f"HazelCast Error: {err}") from err
-
-    async def prepare(self, sentence: Union[str, list]) -> Any:
-        self._prepared = sentence
-        return self._prepared
-
-    async def connection(self):
-        try:
-            print(f"{self._provider}: connecting at {self._server}")
-            # processing the factories:
-            n = 1
-            factories = {}
-            for factory in self.factories:
-                if not issubclass(factory, HazelPortable):
-                    raise TypeError(f"Wrong instance type for a Hazelcast Portable: {factory!r}")
-                factory.set_factory(n)
-                factories[factory.FACTORY_ID] = {factory.CLASS_ID: factory}
-                n += 1
-            self._connection = hazelcast.HazelcastClient(
-                cluster_members=[self._server],
-                client_name=self._client,
-                connection_timeout=self._timeout,
-                cluster_name=self._cluster,
-                retry_initial_backoff=1,
-                retry_max_backoff=15,
-                retry_multiplier=1.5,
-                retry_jitter=0.2,
-                cluster_connect_timeout=120,
-                portable_factories=factories,
-            )
-            self._connected = True
-            return self
-        except RuntimeError as ex:
-            raise DriverError(f"Error connecting to Hazelcast Cluster: {ex}") from ex
-        except Exception as err:
-            raise DriverError(message=f"Unknown Hazelcast Error: {err}") from err
-
-    def add_member(self, server):
-        try:
-            config = hazelcast.ClientConfig()
-            config.network_config.addresses.append(server)
-        except Exception as ex:
-            self._logger.exception(ex)
-            raise
-
-    async def close(self, timeout: int = 10) -> None:
-        try:
-            self._connection.shutdown()
-        except HazelcastClientNotActiveError as ex:
-            self._logger.warning(f"Hazelcast Client is not Active: {ex}")
-        except Exception as err:
-            raise DriverError(message=f"Close Hazelcast Error: {err}") from err
-        finally:
-            self._connected = False
-
-    async def get(self, key, map_name: str = None):
-        if not map_name:
-            map_name = self._map_name
-        try:
-            a_map = self._connection.get_map(map_name)
-            result = a_map.get(key)
-            if result:
-                return result.result()
-            else:
-                return None
-        except HazelcastError as err:
-            raise DriverError(f"Get Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    async def set(self, key, value: Any, map_name: str = None) -> None:
-        if not map_name:
-            map_name = self._map_name
-        try:
-            a_map = self._connection.get_map(map_name)
-            a_map.set(key, value)
-        except HazelcastError as err:
-            raise DriverError(f"Get Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    async def put(self, key, value: Any, map_name: str = None) -> None:
-        if not map_name:
-            map_name = self._map_name
-        try:
-            a_map = self._connection.get_map(map_name)
-            a_map.put(key, value)
-        except HazelcastError as err:
-            raise DriverError(f"Get Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    async def set_multi(self, key, *args, map_name: str = None):
-        if not map_name:
-            map_name = self._map_name
-        try:
-            mmap = self._connection.get_multi_map(map_name)
-            for el in args:
-                mmap.put(key, el)
-        except HazelcastError as err:
-            raise DriverError(f"Set-Multi Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    async def get_multi(self, key, map_name: str = None):
-        if not map_name:
-            map_name = self._map_name
-        try:
-            mmap = self._connection.get_multi_map(map_name)
-            result = mmap.get(key)
-            if not result:
-                raise NoDataFound(f"No Data was found: {key}")
-            return result.result()
-        except HazelcastError as err:
-            raise DriverError(f"Set-Multi Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    async def delete_multi(self, *keys, map_name: str = None):
-        if not map_name:
-            map_name = self._map_name
-        try:
-            mmap = self._connection.get_map(map_name)
-            for key in keys:
-                mmap.remove(key)
-            self._logger.debug(f"Map {mmap}, size: {mmap.entry_set().result()}")
-            print(f"Map {mmap}, size: {mmap.entry_set().result()}")
-        except HazelcastError as err:
-            raise DriverError(f"Set-Multi Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    def all(self, map_name: str = None):
-        """all.
-        Get all elements in a Distributed Map.
-        """
-        if not map_name:
-            map_name = self._map_name
-        try:
-            a_map = self._connection.get_map(map_name)
-            return a_map.entry_set().result()
-        except HazelcastError as err:
-            raise DriverError(f"Get Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    async def exists(self, key: str, map_name: str = None) -> bool:
-        if not map_name:
-            map_name = self._map_name
-        try:
-            a_map = self._connection.get_map(map_name)
-            return a_map.contains_key(key).result()
-        except HazelcastError as err:
-            raise DriverError(f"Get Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    contains = exists
-
-    async def delete(self, key: str, map_name: str = None):
-        if not map_name:
-            map_name = self._map_name
-        try:
-            a_map = self._connection.get_map(map_name)
-            a_map.remove(key)
-        except HazelcastError as err:
-            raise DriverError(f"Get Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    remove = delete
-
-    def get_columns(self):
-        raise NotImplementedError
-
-    async def use(self, database):
-        raise NotImplementedError
-
-    async def query(self, sentence: Any = None, map_name: str = None, **kwargs):
-        error = None
-        result = None
-        if not map_name:
-            map_name = self._map_name
-        try:
-            mmap = self._connection.get_map(map_name)
-            if not sentence:
-                result = mmap.entry_set().result()
-            else:
-                result = mmap.get(sentence).result()
-        except HazelcastError as err:
-            error = f"Get Hazelcast Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Hazelcast Unknown Error: {err}"
-        finally:
-            return await self._serializer(result, error)  # pylint: disable=W0150
-
-    queryrow = query
-
-    async def fetch_all(self, sentence, map_name: str = None, **kwargs):
-        result = None
-        if not map_name:
-            map_name = self._map_name
-        try:
-            mmap = self._connection.get_multi_map(map_name)
-            result = mmap.get(sentence).result()
-            if not result:
-                raise NoDataFound()
-            return result
-        except HazelcastError as err:
-            raise DriverError(f"Get Hazelcast Error: {err}") from err
-        except Exception as err:
-            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
-
-    fetch_one = fetch_all
-
-    async def execute(
-        self, sentence: Union[Any, str], *args, fut: bool = False, map_name: str = None, **kwargs
-    ) -> Union[Sequence, None]:
-        print(f"Execute Query {sentence}")
-        result = []
-        error = None
-        try:
-            if map_name:
-                self._connection.get_map(map_name).blocking()
-            if not fut:
-                result = self._connection.sql.execute(sentence, *args).result()
-            else:
-                result = self._connection.sql.execute(sentence, *args)
-        except HazelcastError as err:
-            error = f"Get Hazelcast Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Hazelcast Unknown Error: {err}"
-        finally:
-            return await self._serializer(result, error)  # pylint: disable=W0150
-
-    execute_many = execute
+"""Hazelcast AsyncDB Driver.
+
+"""
+import asyncio
+import logging
+from datetime import datetime
+from typing import Union, Any, ClassVar
+from collections.abc import Sequence
+from datamodel import BaseModel, Field
+
+import hazelcast
+from hazelcast.serialization.api import Portable
+from hazelcast.errors import HazelcastError, HazelcastClientNotActiveError
+from ..utils.types import Entity
+from ..exceptions import (
+    DriverError,
+    NoDataFound,
+)
+from .abstract import InitDriver
+
+
+class HazelPortable(BaseModel, Portable):
+    FACTORY_ID: ClassVar[int] = Field(default=1, repr=False)
+    CLASS_ID: ClassVar[int] = Field(default=1, repr=False)
+
+    def write_portable(self, writer):
+        for name, f in self.columns().items():
+            if name == "FACTORY_ID":
+                continue
+            _type = f.type
+            value = getattr(self, name)
+            if Entity.is_integer(_type):
+                writer.write_int(name, value)
+            elif _type == bool:
+                writer.write_boolean(name, value)
+            elif Entity.is_number(_type):
+                writer.write_long(name, value)
+            else:
+                writer.write_string(name, value)
+
+    def read_portable(self, reader):
+        for name, f in self.columns().items():
+            if name == "FACTORY_ID":
+                continue
+            _type = f.type
+            if Entity.is_integer(_type):
+                value = reader.read_int(name)
+            elif _type == bool:
+                val = reader.read_boolean(name)
+                value = bool(val)
+            elif Entity.is_number(_type):
+                value = reader.read_long(name)
+            else:
+                value = reader.read_string(name)
+            try:
+                setattr(self, name, value)
+            except (TypeError, ValueError) as e:
+                logging.warning(f"Hazelcast Error on Portable: {e}")
+
+    @classmethod
+    def set_factory(cls, fid: int = 1):
+        cls.FACTORY_ID = fid
+
+    def get_factory_id(self):
+        return self.__class__.FACTORY_ID
+
+    def get_class_id(self):
+        return self.__class__.FACTORY_ID
+
+
+class hazel(InitDriver):
+    _provider = "hazelcast"
+    _syntax = "sql"
+
+    def __init__(self, dsn: str = None, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
+        self._test_query = None
+        self._server = None
+        _starttime = datetime.now()
+        self._timeout: int = 10
+        try:
+            self._map_name = params["map_name"]
+            del params["map_name"]
+        except KeyError:
+            self._map_name = "asyncdb-map"
+        try:
+            self._cluster = params["cluster"]
+            del params["cluster"]
+        except KeyError:
+            self._cluster = None
+        try:
+            self._client = params["client"]
+            del params["client"]
+        except KeyError:
+            self._client = "asyncdb"
+        try:
+            host = params["host"]
+        except KeyError as ex:
+            raise DriverError("Hazelcast: Unable to find *host* in parameters.") from ex
+        try:
+            port = params["port"]
+        except KeyError:
+            port = 5701
+        self._server = f"{host}:{port}"
+        ### factories:
+        try:
+            self.factories = params["factories"]
+            del params["factories"]
+        except KeyError:
+            self.factories = []
+        try:
+            super(hazel, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+            _generated = datetime.now() - _starttime
+            print(f"HazelCast Started in: {_generated}")
+        except Exception as err:
+            raise DriverError(f"HazelCast Error: {err}") from err
+
+    async def prepare(self, sentence: Union[str, list]) -> Any:
+        self._prepared = sentence
+        return self._prepared
+
+    async def connection(self):
+        try:
+            print(f"{self._provider}: connecting at {self._server}")
+            # processing the factories:
+            n = 1
+            factories = {}
+            for factory in self.factories:
+                if not issubclass(factory, HazelPortable):
+                    raise TypeError(f"Wrong instance type for a Hazelcast Portable: {factory!r}")
+                factory.set_factory(n)
+                factories[factory.FACTORY_ID] = {factory.CLASS_ID: factory}
+                n += 1
+            self._connection = hazelcast.HazelcastClient(
+                cluster_members=[self._server],
+                client_name=self._client,
+                connection_timeout=self._timeout,
+                cluster_name=self._cluster,
+                retry_initial_backoff=1,
+                retry_max_backoff=15,
+                retry_multiplier=1.5,
+                retry_jitter=0.2,
+                cluster_connect_timeout=120,
+                portable_factories=factories,
+            )
+            self._connected = True
+            return self
+        except RuntimeError as ex:
+            raise DriverError(f"Error connecting to Hazelcast Cluster: {ex}") from ex
+        except Exception as err:
+            raise DriverError(message=f"Unknown Hazelcast Error: {err}") from err
+
+    def add_member(self, server):
+        try:
+            config = hazelcast.ClientConfig()
+            config.network_config.addresses.append(server)
+        except Exception as ex:
+            self._logger.exception(ex)
+            raise
+
+    async def close(self, timeout: int = 10) -> None:
+        try:
+            self._connection.shutdown()
+        except HazelcastClientNotActiveError as ex:
+            self._logger.warning(f"Hazelcast Client is not Active: {ex}")
+        except Exception as err:
+            raise DriverError(message=f"Close Hazelcast Error: {err}") from err
+        finally:
+            self._connected = False
+
+    async def get(self, key, map_name: str = None):
+        if not map_name:
+            map_name = self._map_name
+        try:
+            a_map = self._connection.get_map(map_name)
+            result = a_map.get(key)
+            if result:
+                return result.result()
+            else:
+                return None
+        except HazelcastError as err:
+            raise DriverError(f"Get Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    async def set(self, key, value: Any, map_name: str = None) -> None:
+        if not map_name:
+            map_name = self._map_name
+        try:
+            a_map = self._connection.get_map(map_name)
+            a_map.set(key, value)
+        except HazelcastError as err:
+            raise DriverError(f"Get Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    async def put(self, key, value: Any, map_name: str = None) -> None:
+        if not map_name:
+            map_name = self._map_name
+        try:
+            a_map = self._connection.get_map(map_name)
+            a_map.put(key, value)
+        except HazelcastError as err:
+            raise DriverError(f"Get Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    async def set_multi(self, key, *args, map_name: str = None):
+        if not map_name:
+            map_name = self._map_name
+        try:
+            mmap = self._connection.get_multi_map(map_name)
+            for el in args:
+                mmap.put(key, el)
+        except HazelcastError as err:
+            raise DriverError(f"Set-Multi Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    async def get_multi(self, key, map_name: str = None):
+        if not map_name:
+            map_name = self._map_name
+        try:
+            mmap = self._connection.get_multi_map(map_name)
+            result = mmap.get(key)
+            if not result:
+                raise NoDataFound(f"No Data was found: {key}")
+            return result.result()
+        except HazelcastError as err:
+            raise DriverError(f"Set-Multi Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    async def delete_multi(self, *keys, map_name: str = None):
+        if not map_name:
+            map_name = self._map_name
+        try:
+            mmap = self._connection.get_map(map_name)
+            for key in keys:
+                mmap.remove(key)
+            self._logger.debug(f"Map {mmap}, size: {mmap.entry_set().result()}")
+            print(f"Map {mmap}, size: {mmap.entry_set().result()}")
+        except HazelcastError as err:
+            raise DriverError(f"Set-Multi Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    def all(self, map_name: str = None):
+        """all.
+        Get all elements in a Distributed Map.
+        """
+        if not map_name:
+            map_name = self._map_name
+        try:
+            a_map = self._connection.get_map(map_name)
+            return a_map.entry_set().result()
+        except HazelcastError as err:
+            raise DriverError(f"Get Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    async def exists(self, key: str, map_name: str = None) -> bool:
+        if not map_name:
+            map_name = self._map_name
+        try:
+            a_map = self._connection.get_map(map_name)
+            return a_map.contains_key(key).result()
+        except HazelcastError as err:
+            raise DriverError(f"Get Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    contains = exists
+
+    async def delete(self, key: str, map_name: str = None):
+        if not map_name:
+            map_name = self._map_name
+        try:
+            a_map = self._connection.get_map(map_name)
+            a_map.remove(key)
+        except HazelcastError as err:
+            raise DriverError(f"Get Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    remove = delete
+
+    def get_columns(self):
+        raise NotImplementedError
+
+    async def use(self, database):
+        raise NotImplementedError
+
+    async def query(self, sentence: Any = None, map_name: str = None, **kwargs):
+        error = None
+        result = None
+        if not map_name:
+            map_name = self._map_name
+        try:
+            mmap = self._connection.get_map(map_name)
+            if not sentence:
+                result = mmap.entry_set().result()
+            else:
+                result = mmap.get(sentence).result()
+        except HazelcastError as err:
+            error = f"Get Hazelcast Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Hazelcast Unknown Error: {err}"
+        finally:
+            return await self._serializer(result, error)  # pylint: disable=W0150
+
+    queryrow = query
+
+    async def fetch_all(self, sentence, map_name: str = None, **kwargs):
+        result = None
+        if not map_name:
+            map_name = self._map_name
+        try:
+            mmap = self._connection.get_multi_map(map_name)
+            result = mmap.get(sentence).result()
+            if not result:
+                raise NoDataFound()
+            return result
+        except HazelcastError as err:
+            raise DriverError(f"Get Hazelcast Error: {err}") from err
+        except Exception as err:
+            raise DriverError(f"Hazelcast Unknown Error: {err}") from err
+
+    fetch_one = fetch_all
+
+    async def execute(
+        self, sentence: Union[Any, str], *args, fut: bool = False, map_name: str = None, **kwargs
+    ) -> Union[Sequence, None]:
+        print(f"Execute Query {sentence}")
+        result = []
+        error = None
+        try:
+            if map_name:
+                self._connection.get_map(map_name).blocking()
+            if not fut:
+                result = self._connection.sql.execute(sentence, *args).result()
+            else:
+                result = self._connection.sql.execute(sentence, *args)
+        except HazelcastError as err:
+            error = f"Get Hazelcast Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Hazelcast Unknown Error: {err}"
+        finally:
+            return await self._serializer(result, error)  # pylint: disable=W0150
+
+    execute_many = execute
```

## asyncdb/drivers/abstract.py

```diff
@@ -1,150 +1,156 @@
-# -*- coding: utf-8 -*-
-import sys
-import asyncio
-import traceback
-from abc import (
-    ABC,
-    abstractmethod,
-)
-from typing import Optional, Any
-from collections.abc import Iterable
-from asyncdb.exceptions import EmptyStatement
-from asyncdb.interfaces import PoolBackend, ConnectionDSNBackend, ConnectionBackend, DatabaseBackend, CursorBackend
-from .outputs import OutputFactory
-
-
-class BasePool(PoolBackend, ConnectionDSNBackend):
-    """BasePool.
-
-    Abstract Class to create Pool-based database connectors.
-    """
-
-    def __init__(self, dsn: str = "", loop=None, params: Optional[dict] = None, **kwargs):
-        ConnectionDSNBackend.__init__(self, dsn=dsn, params=params)
-        PoolBackend.__init__(self, loop=loop, params=params, **kwargs)
-
-    # Create a database connection pool
-    @abstractmethod
-    async def connect(self):
-        """connect.
-        __init async db initialization
-        """
-
-    @abstractmethod
-    async def acquire(self):
-        """acquire.
-        Take a connection from the pool.
-        """
-
-    @abstractmethod
-    async def close(self, **kwargs):
-        """close.
-        Closing a connection from the pool.
-        """
-
-
-class InitDriver(ConnectionBackend, DatabaseBackend, ABC):
-    """
-    InitDriver
-        Abstract Class for Simple Connections.
-    ----
-    """
-
-    _provider: str = "init"
-    _syntax: str = "init"  # can use QueryParser for parsing SQL queries
-
-    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
-        if params is None:
-            params = {}
-        self._pool = None
-        self._max_connections = 4
-        self._parameters = ()
-        # noinspection PyTypeChecker
-        self._serializer: OutputFactory = None
-        self._row_format = "native"
-        self._connected: bool = False
-        self._connection = None
-        ConnectionBackend.__init__(self, loop=loop, params=params, **kwargs)
-        DatabaseBackend.__init__(self)
-        self._initialized_on = None
-        # always starts output format to native:
-        self.output_format("native")
-        if self._loop.get_debug():
-            self._source_traceback = traceback.extract_stack(sys._getframe(1))
-
-    def row_format(self, frmt: str = "native"):
-        """
-        Formats:
-        - row_format: run before query
-        - output: runs in the return (serialization) of data
-        """
-        self._row_format = frmt
-
-    async def output(self, result, error):
-        # return result in default format
-        self._result = result
-        return [result, error]
-
-    def output_format(self, frmt: str = "native", *args, **kwargs):  # pylint: disable=W1113
-        self._serializer = OutputFactory(self, frmt=frmt, *args, **kwargs)
-
-    async def valid_operation(self, sentence: Any):
-        """
-        Returns if is a valid operation.
-        TODO: add some validations.
-        """
-        if not sentence:
-            raise EmptyStatement(f"{__name__!s} Error: cannot use an empty sentence")
-        if not self._connection:
-            await self.connection()
-
-
-class BaseDriver(InitDriver, ConnectionDSNBackend, ABC):
-    """
-    BaseDriver
-        Abstract Class for DB Connection
-    ----
-    """
-
-    _provider: str = "base"
-    _syntax: str = "base"  # can use QueryParser for parsing SQL queries
-
-    def __init__(self, dsn: str = None, loop=None, params: dict = None, **kwargs):
-        InitDriver.__init__(self, loop=loop, params=params, **kwargs)
-        ConnectionDSNBackend.__init__(self, dsn=dsn, params=params)
-        # always starts output format to native:
-        self.output_format("native")
-
-
-class BaseDBDriver(BaseDriver):
-    """
-    Interface for more DB-oriented connections.
-    """
-
-    @abstractmethod
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        """tables.
-        Getting a list of tables in schema.
-        """
-
-    @abstractmethod
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        """table.
-        Getting table structure in schema.
-        """
-
-    @abstractmethod
-    async def column_info(self, tablename: str, schema: str = "") -> Iterable[Any]:
-        """
-        Getting Column info from an existing Table in Driver.
-        """
-
-
-class BaseCursor(CursorBackend):
-    """
-    baseCursor.
-
-    Iterable Object for Cursor-Like functionality
-    """
-
-    _provider: BaseDriver
+# -*- coding: utf-8 -*-
+import sys
+import asyncio
+import traceback
+from abc import (
+    ABC,
+    abstractmethod,
+)
+from typing import Optional, Any
+from collections.abc import Iterable
+from ..exceptions import EmptyStatement
+from ..interfaces import (
+    PoolBackend,
+    ConnectionDSNBackend,
+    ConnectionBackend,
+    DatabaseBackend,
+    CursorBackend
+)
+from .outputs import OutputFactory
+
+
+class BasePool(PoolBackend, ConnectionDSNBackend):
+    """BasePool.
+
+    Abstract Class to create Pool-based database connectors.
+    """
+
+    def __init__(self, dsn: str = "", loop=None, params: Optional[dict] = None, **kwargs):
+        ConnectionDSNBackend.__init__(self, dsn=dsn, params=params)
+        PoolBackend.__init__(self, loop=loop, params=params, **kwargs)
+
+    # Create a database connection pool
+    @abstractmethod
+    async def connect(self):
+        """connect.
+        __init async db initialization
+        """
+
+    @abstractmethod
+    async def acquire(self):
+        """acquire.
+        Take a connection from the pool.
+        """
+
+    @abstractmethod
+    async def close(self, **kwargs):
+        """close.
+        Closing a connection from the pool.
+        """
+
+
+class InitDriver(ConnectionBackend, DatabaseBackend, ABC):
+    """
+    InitDriver
+        Abstract Class for Simple Connections.
+    ----
+    """
+
+    _provider: str = "init"
+    _syntax: str = "init"  # can use QueryParser for parsing SQL queries
+
+    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
+        if params is None:
+            params = {}
+        self._pool = None
+        self._max_connections = 4
+        self._parameters = ()
+        # noinspection PyTypeChecker
+        self._serializer: OutputFactory = None
+        self._row_format = "native"
+        self._connected: bool = False
+        self._connection = None
+        ConnectionBackend.__init__(self, loop=loop, params=params, **kwargs)
+        DatabaseBackend.__init__(self)
+        self._initialized_on = None
+        # always starts output format to native:
+        self.output_format("native")
+        if self._loop.get_debug():
+            self._source_traceback = traceback.extract_stack(sys._getframe(1))
+
+    def row_format(self, frmt: str = "native"):
+        """
+        Formats:
+        - row_format: run before query
+        - output: runs in the return (serialization) of data
+        """
+        self._row_format = frmt
+
+    async def output(self, result, error):
+        # return result in default format
+        self._result = result
+        return [result, error]
+
+    def output_format(self, frmt: str = "native", *args, **kwargs):  # pylint: disable=W1113
+        self._serializer = OutputFactory(self, frmt=frmt, *args, **kwargs)
+
+    async def valid_operation(self, sentence: Any):
+        """
+        Returns if is a valid operation.
+        TODO: add some validations.
+        """
+        if not sentence:
+            raise EmptyStatement(f"{__name__!s} Error: cannot use an empty sentence")
+        if not self._connection:
+            await self.connection()
+
+
+class BaseDriver(InitDriver, ConnectionDSNBackend, ABC):
+    """
+    BaseDriver
+        Abstract Class for DB Connection
+    ----
+    """
+
+    _provider: str = "base"
+    _syntax: str = "base"  # can use QueryParser for parsing SQL queries
+
+    def __init__(self, dsn: str = None, loop=None, params: dict = None, **kwargs):
+        InitDriver.__init__(self, loop=loop, params=params, **kwargs)
+        ConnectionDSNBackend.__init__(self, dsn=dsn, params=params)
+        # always starts output format to native:
+        self.output_format("native")
+
+
+class BaseDBDriver(BaseDriver):
+    """
+    Interface for more DB-oriented connections.
+    """
+
+    @abstractmethod
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        """tables.
+        Getting a list of tables in schema.
+        """
+
+    @abstractmethod
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        """table.
+        Getting table structure in schema.
+        """
+
+    @abstractmethod
+    async def column_info(self, tablename: str, schema: str = "") -> Iterable[Any]:
+        """
+        Getting Column info from an existing Table in Driver.
+        """
+
+
+class BaseCursor(CursorBackend):
+    """
+    baseCursor.
+
+    Iterable Object for Cursor-Like functionality
+    """
+
+    _provider: BaseDriver
```

## asyncdb/drivers/odbc.py

```diff
@@ -1,217 +1,217 @@
-#!/usr/bin/env python3
-import asyncio
-import time
-from typing import (
-    Any,
-    Optional,
-)
-from collections.abc import Iterable
-import aioodbc
-from aioodbc.cursor import Cursor
-import pyodbc
-from asyncdb.exceptions import (
-    ConnectionTimeout,
-    DataError,
-    EmptyStatement,
-    NoDataFound,
-    DriverError,
-    StatementError,
-    TooManyConnections,
-)
-from asyncdb.interfaces import DBCursorBackend
-from .sql import SQLDriver, SQLCursor
-
-
-class odbcCursor(SQLCursor):
-    async def __aenter__(self) -> "odbcCursor":
-        "Redefining __aenter__ based on requirements of ODBC Cursors"
-        self._cursor = await self._connection.cursor()
-        await self._cursor.execute(self._sentence, self._params)
-        return self
-
-
-class odbc(SQLDriver, DBCursorBackend):
-    _provider = "odbc"
-    _dsn = "Driver={driver};Database={database}"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        if "host" in params:
-            self._dsn = "DRIVER={driver};Database={database};server={host};uid={user};pwd={password}"
-        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
-        DBCursorBackend.__init__(self)
-
-    async def prepare(self):
-        raise NotImplementedError("Prepared Statements not supported yet.")
-
-    async def connection(self, **kwargs):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            self._connection = await aioodbc.connect(dsn=self._dsn)
-            if self._connection:
-                if callable(self.init_func):
-                    try:
-                        await self.init_func(self._connection)
-                    except Exception as err:
-                        print("ODBC: Error on Init Connection: {}".format(err))
-                self._connected = True
-                self._initialized_on = time.time()
-        except pyodbc.Error as err:
-            print("ERR ", err)
-            self._logger.exception(err)
-            raise DriverError("ODBC Internal Error: {}".format(str(err)))
-        except Exception as err:
-            print("ERR ", err)
-            self._logger.exception(err)
-            raise DriverError("ODBC Unknown Error: {}".format(str(err)))
-        finally:
-            return self
-
-    async def query(self, sentence: str = Any):
-        """
-        Getting a Query from Database
-        """
-        # TODO: getting aiosql structures or sql-like function structures or query functions
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            # getting cursor:
-            self._cursor = await self._connection.cursor()
-            await self._cursor.execute(sentence)
-            self._result = await self._cursor.fetchall()
-            if not self._result:
-                return [None, NoDataFound]
-        except pyodbc.Error as err:
-            error = "ODBC: Query Error: {}".format(err)
-            raise DriverError(message=error)
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            await self._cursor.close()
-            return [self._result, error]
-
-    async def fetchall(self, sentence: str):
-        """
-        aliases for query, without error support
-        """
-        await self.valid_operation(sentence)
-        try:
-            # getting cursor:
-            self._cursor = await self._connection.cursor()
-            await self._cursor.execute(sentence)
-            self._result = await self._cursor.fetchall()
-            if not self._result:
-                raise NoDataFound
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            await self._cursor.close()
-            return self._result
-
-    async def fetchmany(self, sentence: str, size: int = None):
-        """
-        aliases for query, without error support
-        """
-        await self.valid_operation(sentence)
-        try:
-            self._cursor = await self._connection.cursor()
-            await self._cursor.execute(sentence)
-            self._result = await self._cursor.fetchmany(size)
-            if not self._result:
-                raise NoDataFound
-        except pyodbc.ProgrammingError as err:
-            error = "ODBC Query Error: {}".format(str(err))
-            raise DriverError(message=error)
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            await self._cursor.close()
-            return self._result
-
-    async def queryrow(self, sentence: str = Any):
-        """
-        Getting a Query from Database
-        """
-        # TODO: getting aiosql structures or sql-like function structures or query functions
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            self._cursor = await self._connection.cursor()
-            await self._cursor.execute(sentence)
-            self._result = await self._cursor.fetchone()
-            if not self._result:
-                return [None, NoDataFound]
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            await self._cursor.close()
-            return [self._result, error]
-
-    async def fetchone(self, sentence: str):
-        """
-        aliases for queryrow, without error support
-        """
-        await self.valid_operation(sentence)
-        try:
-            self._cursor = await self._connection.cursor()
-            await self._cursor.execute(sentence)
-            self._result = await self._cursor.fetchone()
-            if not self._result:
-                raise NoDataFound
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            await self._cursor.close()
-            return self._result
-
-    async def execute(self, sentence: str = Any, *args):
-        """Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        error = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            self._cursor = await self._connection.cursor()
-            result = await self._cursor.execute(sentence, *args)
-            if result:
-                await self._connection.commit()
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            await self._cursor.close()
-            return [result, error]
-
-    async def executemany(self, sentence: str, *args):
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            self._cursor = await self._connection.cursor()
-            result = await self._cursor.executemany(sentence, *args)
-            if result:
-                await self._connection.commit()
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-            raise DriverError(message=error)
-        finally:
-            await self._cursor.close()
-            return [result, error]
-
-    async def fetch(self, sentence: str, parameters: Iterable[Any] = None) -> Iterable:
-        """Helper to create a cursor and execute the given query, returns a Native Cursor"""
-        if parameters is None:
-            parameters = []
-        await self.valid_operation(sentence)
-        self._cursor = await self._connection.cursor()
-        await self._cursor.execute(sentence, parameters)
-        return self._cursor
+#!/usr/bin/env python3
+import asyncio
+import time
+from typing import (
+    Any,
+    Optional,
+)
+from collections.abc import Iterable
+import aioodbc
+from aioodbc.cursor import Cursor
+import pyodbc
+from ..exceptions import (
+    ConnectionTimeout,
+    DataError,
+    EmptyStatement,
+    NoDataFound,
+    DriverError,
+    StatementError,
+    TooManyConnections,
+)
+from ..interfaces import DBCursorBackend
+from .sql import SQLDriver, SQLCursor
+
+
+class odbcCursor(SQLCursor):
+    async def __aenter__(self) -> "odbcCursor":
+        "Redefining __aenter__ based on requirements of ODBC Cursors"
+        self._cursor = await self._connection.cursor()
+        await self._cursor.execute(self._sentence, self._params)
+        return self
+
+
+class odbc(SQLDriver, DBCursorBackend):
+    _provider = "odbc"
+    _dsn = "Driver={driver};Database={database}"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        if "host" in params:
+            self._dsn = "DRIVER={driver};Database={database};server={host};uid={user};pwd={password}"
+        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
+        DBCursorBackend.__init__(self)
+
+    async def prepare(self):
+        raise NotImplementedError("Prepared Statements not supported yet.")
+
+    async def connection(self, **kwargs):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            self._connection = await aioodbc.connect(dsn=self._dsn)
+            if self._connection:
+                if callable(self.init_func):
+                    try:
+                        await self.init_func(self._connection)
+                    except Exception as err:
+                        print("ODBC: Error on Init Connection: {}".format(err))
+                self._connected = True
+                self._initialized_on = time.time()
+        except pyodbc.Error as err:
+            print("ERR ", err)
+            self._logger.exception(err)
+            raise DriverError("ODBC Internal Error: {}".format(str(err)))
+        except Exception as err:
+            print("ERR ", err)
+            self._logger.exception(err)
+            raise DriverError("ODBC Unknown Error: {}".format(str(err)))
+        finally:
+            return self
+
+    async def query(self, sentence: str = Any):
+        """
+        Getting a Query from Database
+        """
+        # TODO: getting aiosql structures or sql-like function structures or query functions
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            # getting cursor:
+            self._cursor = await self._connection.cursor()
+            await self._cursor.execute(sentence)
+            self._result = await self._cursor.fetchall()
+            if not self._result:
+                return [None, NoDataFound]
+        except pyodbc.Error as err:
+            error = "ODBC: Query Error: {}".format(err)
+            raise DriverError(message=error)
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            await self._cursor.close()
+            return [self._result, error]
+
+    async def fetchall(self, sentence: str):
+        """
+        aliases for query, without error support
+        """
+        await self.valid_operation(sentence)
+        try:
+            # getting cursor:
+            self._cursor = await self._connection.cursor()
+            await self._cursor.execute(sentence)
+            self._result = await self._cursor.fetchall()
+            if not self._result:
+                raise NoDataFound
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            await self._cursor.close()
+            return self._result
+
+    async def fetchmany(self, sentence: str, size: int = None):
+        """
+        aliases for query, without error support
+        """
+        await self.valid_operation(sentence)
+        try:
+            self._cursor = await self._connection.cursor()
+            await self._cursor.execute(sentence)
+            self._result = await self._cursor.fetchmany(size)
+            if not self._result:
+                raise NoDataFound
+        except pyodbc.ProgrammingError as err:
+            error = "ODBC Query Error: {}".format(str(err))
+            raise DriverError(message=error)
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            await self._cursor.close()
+            return self._result
+
+    async def queryrow(self, sentence: str = Any):
+        """
+        Getting a Query from Database
+        """
+        # TODO: getting aiosql structures or sql-like function structures or query functions
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            self._cursor = await self._connection.cursor()
+            await self._cursor.execute(sentence)
+            self._result = await self._cursor.fetchone()
+            if not self._result:
+                return [None, NoDataFound]
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            await self._cursor.close()
+            return [self._result, error]
+
+    async def fetchone(self, sentence: str):
+        """
+        aliases for queryrow, without error support
+        """
+        await self.valid_operation(sentence)
+        try:
+            self._cursor = await self._connection.cursor()
+            await self._cursor.execute(sentence)
+            self._result = await self._cursor.fetchone()
+            if not self._result:
+                raise NoDataFound
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            await self._cursor.close()
+            return self._result
+
+    async def execute(self, sentence: str = Any, *args):
+        """Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        error = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            self._cursor = await self._connection.cursor()
+            result = await self._cursor.execute(sentence, *args)
+            if result:
+                await self._connection.commit()
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            await self._cursor.close()
+            return [result, error]
+
+    async def executemany(self, sentence: str, *args):
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            self._cursor = await self._connection.cursor()
+            result = await self._cursor.executemany(sentence, *args)
+            if result:
+                await self._connection.commit()
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+            raise DriverError(message=error)
+        finally:
+            await self._cursor.close()
+            return [result, error]
+
+    async def fetch(self, sentence: str, parameters: Iterable[Any] = None) -> Iterable:
+        """Helper to create a cursor and execute the given query, returns a Native Cursor"""
+        if parameters is None:
+            parameters = []
+        await self.valid_operation(sentence)
+        self._cursor = await self._connection.cursor()
+        await self._cursor.execute(sentence, parameters)
+        return self._cursor
```

## asyncdb/drivers/mssql.py

```diff
@@ -1,391 +1,390 @@
-#!/usr/bin/env python3
-import os
-import asyncio
-import time
-import logging
-from typing import Union, Optional, Any
-from collections.abc import Iterable
-import pymssql
-from pymssql import _mssql
-from asyncdb.interfaces import DBCursorBackend
-from asyncdb.exceptions import DataError, EmptyStatement, NoDataFound, DriverError, StatementError
-from .sql import SQLDriver, SQLCursor
-
-types_map = {
-    1: "string",
-    2: "nvarchar",
-    # Type #3 supposed to be an integer, but in some cases decimals are returned
-    # with this type. To be on safe side, marking it as float.
-    3: "integer",
-    4: "datetime",
-    5: "float",
-}
-
-
-class mssqlCursor(SQLCursor):
-    """MS SQL Server Cursor."""
-
-
-class mssql(SQLDriver, DBCursorBackend):
-    """mssql.
-
-    Microsoft SQL Server using low-level _mssql Protocol.
-    """
-
-    _provider = "mssql"
-    _syntax = "sql"
-    _test_query = "SELECT 1 as one"
-    _charset: str = "UTF8"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._dsn = ""
-        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
-        self._version: str = None
-        self.application_name = os.getenv("APP_NAME", "NAV")
-        self._server_settings: dict = []
-        self._connected: bool = False
-        try:
-            self.tds_version = kwargs["tds_version"]
-            del kwargs["tds_version"]
-        except KeyError:
-            self.tds_version = "7.3"
-        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
-        DBCursorBackend.__init__(self)
-        try:
-            if "host" in self.params:
-                self.params["server"] = "{}:{}".format(self.params["host"], self.params["port"])
-                del self.params["host"]
-        except (TypeError, KeyError) as err:
-            raise DriverError(f"MS SQL: Invalid Settings: {err}") from err
-        if "server_settings" in kwargs:
-            self._server_settings = kwargs["server_settings"]
-        if "application_name" in self._server_settings:
-            self.application_name = self._server_settings["application_name"]
-            del self._server_settings["application_name"]
-
-    async def close(self):  # pylint: disable=W0221
-        """
-        Closing a Connection
-        """
-        try:
-            if self._connection:
-                self._logger.debug("SQL Server: Closing Connection")
-                try:
-                    self._connection.close()
-                except Exception as err:
-                    self._connection = None
-                    raise DriverError(message=f"Connection Error, Terminated: {err}") from err
-        except Exception as err:
-            raise DriverError(message=f"Close Error: {err}") from err
-        finally:
-            self._connection = None
-            self._connected = False
-
-    disconnect = close
-
-    async def prepare(self, sentence: Union[str, list]) -> Any:
-        raise NotImplementedError("Prepared Sentences are not supported yet.")
-
-    async def connection(self):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        try:
-            self.params["appname"] = self.application_name
-            self.params["charset"] = self._charset.upper()
-            self.params["tds_version"] = self.tds_version
-            if self._server_settings:
-                self.params["conn_properties"] = self._server_settings
-            self._connection = _mssql.connect(**self.params)  # pylint: disable=I1101
-            if self._connection.connected:
-                self._connected = True
-                self._initialized_on = time.time()
-            return self
-        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
-            num = ex.number
-            state = ex.state
-            msg = ex.message
-            raise DriverError(f"MSSQL Error {num}: {msg}, state={state}") from ex
-        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
-            raise DriverError(message=f"connection Error: {ex}") from ex
-        except Exception as err:
-            self._connection = None
-            self._cursor = None
-            raise DriverError(message=f"connection Error, Terminated: {err}") from err
-
-    async def use(self, database: str):  # pylint: disable=W0236
-        self._connection.select_db(database)
-
-    @property
-    async def identity(self):
-        return self._connection.identity
-
-    async def test_connection(self):  # pylint: disable=W0221
-        """
-        Test Connnection.
-        """
-        error = None
-        result = None
-        if self._test_query is None:
-            raise NotImplementedError()
-        try:
-            result = await self.fetchone(self._test_query)
-        except Exception as err:  # pylint: disable=W0703
-            error = str(err)
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    async def execute(self, sentence: str, *args, **kwargs):
-        """
-        Execute a sentence
-        """
-        error = None
-        if not sentence:
-            raise EmptyStatement("Error: Empty Sentence")
-        if not self._connection:
-            await self.connection()
-        try:
-            self._result = self._connection.execute_non_query(sentence, args)
-        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
-            num = ex.number
-            state = ex.state
-            msg = ex.message
-            error = f"MSSQL Database Error {num}: {msg}, state={state}"
-        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
-            error = f"connection Error: {ex}"
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-            error = warn
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            return [self._result, error]  # pylint: disable=W0150
-
-    async def execute_many(self, sentence, *args):
-        """
-        Execute multiple sentences
-        """
-        return await self.execute(sentence, *args)
-
-    executemany = execute_many
-
-    async def query(self, sentence, *args, **kwargs):
-        """
-        Making a Query and return result
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self._connection.execute_query(sentence, args)
-            self._result = self._connection
-        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
-            num = ex.number
-            state = ex.state
-            msg = ex.message
-            error = f"MSSQL Database Error {num}: {msg}, state={state}"
-        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
-            error = f"connection Error: {ex}"
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-            error = warn
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def queryrow(self, sentence, *args):
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self._result = self._connection.execute_row(sentence, args)
-            if not self._result:
-                # raise NoDataFound("SQL Server: No Data was Found")
-                return [None, NoDataFound("SQL Server: No Data was Found")]
-        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
-            num = ex.number
-            state = ex.state
-            msg = ex.message
-            error = f"MSSQL Database Error {num}: {msg}, state={state}"
-        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
-            error = f"connection Error: {ex}"
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-            error = warn
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Error: {err}"
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def fetch_one(self, sentence, *args, **kwargs):
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self._result = self._connection.execute_row(sentence, args)
-            if not self._result:
-                # raise NoDataFound("SQL Server: No Data was Found")
-                raise NoDataFound("SQL Server: No Data was Found")
-            else:
-                return self._result
-        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
-            num = ex.number
-            state = ex.state
-            msg = ex.message
-            error = f"MSSQL Database Error {num}: {msg}, state={state}"
-            raise StatementError(error) from ex
-        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
-            error = f"connection Error: {ex}"
-            raise DataError(error) from ex
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-            error = warn
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Error: {err}"
-            raise DataError(error) from err
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-            raise DriverError(error) from err
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-            raise DriverError(error) from err
-
-    fetchone = fetch_one
-
-    async def fetch_all(self, sentence, *args, **kwargs):
-        """
-        Making a Query and return result
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self._connection.execute_query(sentence, args)
-            if not self._result:
-                raise NoDataFound("SQL Server: No Data was Found")
-            return self._result
-        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
-            num = ex.number
-            state = ex.state
-            msg = ex.message
-            error = f"MSSQL Database Error {num}: {msg}, state={state}"
-            raise StatementError(error) from ex
-        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
-            error = f"connection Error: {ex}"
-            raise DataError(error) from ex
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-            error = warn
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Error: {err}"
-            raise DataError(error) from err
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-            raise DriverError(error) from err
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-            raise DriverError(error) from err
-
-    fetchall = fetch_all
-
-    async def fetch_scalar(self, sentence, *args):
-        error = None
-        self._result = None
-        await self.valid_operation(sentence)
-        try:
-            self._result = self._connection.execute_scalar(sentence, args)
-            if not self._result:
-                raise NoDataFound("SQL Server: No Data was Found")
-            return self._result
-        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
-            num = ex.number
-            state = ex.state
-            msg = ex.message
-            error = f"MSSQL Database Error {num}: {msg}, state={state}"
-            raise StatementError(error) from ex
-        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
-            error = f"connection Error: {ex}"
-            raise DataError(error) from ex
-        except pymssql.Warning as warn:
-            logging.warning(f"SQL Server Warning: {warn!s}")
-            error = warn
-        except (pymssql.StandardError, pymssql.Error) as err:
-            error = f"SQL Server Error: {err}"
-            raise DataError(error) from err
-        except RuntimeError as err:
-            error = f"Runtime Error: {err}"
-            raise DriverError(error) from err
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Error on Query: {err}"
-            raise DriverError(error) from err
-
-    fetchval = fetch_scalar
-
-    ### Model Logic:
-    async def column_info(self, tablename: str, schema: str = None):
-        """Column Info.
-
-        Get Meta information about a table (column name, data type and PK).
-        Useful to build a DataModel from Querying database.
-        Parameters:
-        @tablename: str The name of the table (including schema).
-        """
-        if schema:
-            table = f"{schema}.{tablename}"
-        else:
-            table = tablename
-        sql = f"SELECT a.attname AS name, a.atttypid::regtype AS type, \
-        format_type(a.atttypid, a.atttypmod) as format_type, a.attnotnull::boolean as notnull, \
-        coalesce((SELECT true FROM pg_index i WHERE i.indrelid = a.attrelid \
-        AND i.indrelid = a.attrelid AND a.attnum = any(i.indkey) \
-        AND i.indisprimary), false) as is_primary \
-        FROM pg_attribute a WHERE a.attrelid = '{tablename!s}'::regclass \
-        AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum"
-        if not self._connection:
-            await self.connection()
-        try:
-            colinfo = await self._connection.fetch(sql)
-            return colinfo
-        except Exception as err:
-            self._logger.exception(f"Wrong Table information {tablename!s}: {err}")
-
-    ### DDL Information.
-    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
-        """
-        Create is a generic method for Database Objects Creation.
-        """
-        if obj == "table":
-            sql = "CREATE TABLE {name}({columns});"
-            columns = ", ".join(["{name} {type}".format(**e) for e in fields])
-            sql = sql.format(name=name, columns=columns)
-            try:
-                result = await self._connection.execute(sql)
-                if result:
-                    await self._connection.commit()
-                    return True
-                else:
-                    return False
-            except Exception as err:
-                raise DriverError(message=f"Error in Object Creation: {err!s}") from err
-        else:
-            raise RuntimeError(f"SQLite: invalid Object type {object!s}")
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError
+#!/usr/bin/env python3
+import os
+import asyncio
+import time
+import logging
+from typing import Union, Optional, Any
+from collections.abc import Iterable
+import pymssql
+from pymssql import _mssql
+from ..interfaces import DBCursorBackend
+from ..exceptions import DataError, EmptyStatement, NoDataFound, DriverError, StatementError
+from .sql import SQLDriver, SQLCursor
+
+types_map = {
+    1: "string",
+    2: "nvarchar",
+    # Type #3 supposed to be an integer, but in some cases decimals are returned
+    # with this type. To be on safe side, marking it as float.
+    3: "integer",
+    4: "datetime",
+    5: "float",
+}
+
+
+class mssqlCursor(SQLCursor):
+    """MS SQL Server Cursor."""
+
+
+class mssql(SQLDriver, DBCursorBackend):
+    """mssql.
+
+    Microsoft SQL Server using low-level _mssql Protocol.
+    """
+
+    _provider = "mssql"
+    _syntax = "sql"
+    _test_query = "SELECT 1 as one"
+    _charset: str = "UTF8"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._dsn = ""
+        self._query_raw = "SELECT {fields} FROM {table} {where_cond}"
+        self._version: str = None
+        self.application_name = os.getenv("APP_NAME", "NAV")
+        self._server_settings: dict = []
+        self._connected: bool = False
+        try:
+            self.tds_version = kwargs["tds_version"]
+            del kwargs["tds_version"]
+        except KeyError:
+            self.tds_version = "7.3"
+        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
+        DBCursorBackend.__init__(self)
+        try:
+            if "host" in self.params:
+                self.params["server"] = "{}:{}".format(self.params["host"], self.params["port"])
+                del self.params["host"]
+        except (TypeError, KeyError) as err:
+            raise DriverError(f"MS SQL: Invalid Settings: {err}") from err
+        if "server_settings" in kwargs:
+            self._server_settings = kwargs["server_settings"]
+        if "application_name" in self._server_settings:
+            self.application_name = self._server_settings["application_name"]
+            del self._server_settings["application_name"]
+
+    async def close(self):  # pylint: disable=W0221
+        """
+        Closing a Connection
+        """
+        try:
+            if self._connection:
+                try:
+                    self._connection.close()
+                except Exception as err:
+                    self._connection = None
+                    raise DriverError(message=f"Connection Error, Terminated: {err}") from err
+        except Exception as err:
+            raise DriverError(message=f"Close Error: {err}") from err
+        finally:
+            self._connection = None
+            self._connected = False
+
+    disconnect = close
+
+    async def prepare(self, sentence: Union[str, list]) -> Any:
+        raise NotImplementedError("Prepared Sentences are not supported yet.")
+
+    async def connection(self):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        try:
+            self.params["appname"] = self.application_name
+            self.params["charset"] = self._charset.upper()
+            self.params["tds_version"] = self.tds_version
+            if self._server_settings:
+                self.params["conn_properties"] = self._server_settings
+            self._connection = _mssql.connect(**self.params)  # pylint: disable=I1101
+            if self._connection.connected:
+                self._connected = True
+                self._initialized_on = time.time()
+            return self
+        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
+            num = ex.number
+            state = ex.state
+            msg = ex.message
+            raise DriverError(f"MSSQL Error {num}: {msg}, state={state}") from ex
+        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
+            raise DriverError(message=f"connection Error: {ex}") from ex
+        except Exception as err:
+            self._connection = None
+            self._cursor = None
+            raise DriverError(message=f"connection Error, Terminated: {err}") from err
+
+    async def use(self, database: str):  # pylint: disable=W0236
+        self._connection.select_db(database)
+
+    @property
+    async def identity(self):
+        return self._connection.identity
+
+    async def test_connection(self):  # pylint: disable=W0221
+        """
+        Test Connnection.
+        """
+        error = None
+        result = None
+        if self._test_query is None:
+            raise NotImplementedError()
+        try:
+            result = await self.fetchone(self._test_query)
+        except Exception as err:  # pylint: disable=W0703
+            error = str(err)
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    async def execute(self, sentence: str, *args, **kwargs):
+        """
+        Execute a sentence
+        """
+        error = None
+        if not sentence:
+            raise EmptyStatement("Error: Empty Sentence")
+        if not self._connection:
+            await self.connection()
+        try:
+            self._result = self._connection.execute_non_query(sentence, args)
+        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
+            num = ex.number
+            state = ex.state
+            msg = ex.message
+            error = f"MSSQL Database Error {num}: {msg}, state={state}"
+        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
+            error = f"connection Error: {ex}"
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+            error = warn
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            return [self._result, error]  # pylint: disable=W0150
+
+    async def execute_many(self, sentence, *args):
+        """
+        Execute multiple sentences
+        """
+        return await self.execute(sentence, *args)
+
+    executemany = execute_many
+
+    async def query(self, sentence, *args, **kwargs):
+        """
+        Making a Query and return result
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self._connection.execute_query(sentence, args)
+            self._result = self._connection
+        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
+            num = ex.number
+            state = ex.state
+            msg = ex.message
+            error = f"MSSQL Database Error {num}: {msg}, state={state}"
+        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
+            error = f"connection Error: {ex}"
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+            error = warn
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def queryrow(self, sentence, *args):
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self._result = self._connection.execute_row(sentence, args)
+            if not self._result:
+                # raise NoDataFound("SQL Server: No Data was Found")
+                return [None, NoDataFound("SQL Server: No Data was Found")]
+        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
+            num = ex.number
+            state = ex.state
+            msg = ex.message
+            error = f"MSSQL Database Error {num}: {msg}, state={state}"
+        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
+            error = f"connection Error: {ex}"
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+            error = warn
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Error: {err}"
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def fetch_one(self, sentence, *args, **kwargs):
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self._result = self._connection.execute_row(sentence, args)
+            if not self._result:
+                # raise NoDataFound("SQL Server: No Data was Found")
+                raise NoDataFound("SQL Server: No Data was Found")
+            else:
+                return self._result
+        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
+            num = ex.number
+            state = ex.state
+            msg = ex.message
+            error = f"MSSQL Database Error {num}: {msg}, state={state}"
+            raise StatementError(error) from ex
+        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
+            error = f"connection Error: {ex}"
+            raise DataError(error) from ex
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+            error = warn
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Error: {err}"
+            raise DataError(error) from err
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+            raise DriverError(error) from err
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+            raise DriverError(error) from err
+
+    fetchone = fetch_one
+
+    async def fetch_all(self, sentence, *args, **kwargs):
+        """
+        Making a Query and return result
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self._connection.execute_query(sentence, args)
+            if not self._result:
+                raise NoDataFound("SQL Server: No Data was Found")
+            return self._result
+        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
+            num = ex.number
+            state = ex.state
+            msg = ex.message
+            error = f"MSSQL Database Error {num}: {msg}, state={state}"
+            raise StatementError(error) from ex
+        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
+            error = f"connection Error: {ex}"
+            raise DataError(error) from ex
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+            error = warn
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Error: {err}"
+            raise DataError(error) from err
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+            raise DriverError(error) from err
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+            raise DriverError(error) from err
+
+    fetchall = fetch_all
+
+    async def fetch_scalar(self, sentence, *args):
+        error = None
+        self._result = None
+        await self.valid_operation(sentence)
+        try:
+            self._result = self._connection.execute_scalar(sentence, args)
+            if not self._result:
+                raise NoDataFound("SQL Server: No Data was Found")
+            return self._result
+        except _mssql.MSSQLDatabaseException as ex:  # pylint: disable=I1101
+            num = ex.number
+            state = ex.state
+            msg = ex.message
+            error = f"MSSQL Database Error {num}: {msg}, state={state}"
+            raise StatementError(error) from ex
+        except _mssql.MSSQLDriverException as ex:  # pylint: disable=I1101
+            error = f"connection Error: {ex}"
+            raise DataError(error) from ex
+        except pymssql.Warning as warn:
+            logging.warning(f"SQL Server Warning: {warn!s}")
+            error = warn
+        except (pymssql.StandardError, pymssql.Error) as err:
+            error = f"SQL Server Error: {err}"
+            raise DataError(error) from err
+        except RuntimeError as err:
+            error = f"Runtime Error: {err}"
+            raise DriverError(error) from err
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Error on Query: {err}"
+            raise DriverError(error) from err
+
+    fetchval = fetch_scalar
+
+    ### Model Logic:
+    async def column_info(self, tablename: str, schema: str = None):
+        """Column Info.
+
+        Get Meta information about a table (column name, data type and PK).
+        Useful to build a DataModel from Querying database.
+        Parameters:
+        @tablename: str The name of the table (including schema).
+        """
+        if schema:
+            table = f"{schema}.{tablename}"
+        else:
+            table = tablename
+        sql = f"SELECT a.attname AS name, a.atttypid::regtype AS type, \
+        format_type(a.atttypid, a.atttypmod) as format_type, a.attnotnull::boolean as notnull, \
+        coalesce((SELECT true FROM pg_index i WHERE i.indrelid = a.attrelid \
+        AND i.indrelid = a.attrelid AND a.attnum = any(i.indkey) \
+        AND i.indisprimary), false) as is_primary \
+        FROM pg_attribute a WHERE a.attrelid = '{tablename!s}'::regclass \
+        AND a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum"
+        if not self._connection:
+            await self.connection()
+        try:
+            colinfo = await self._connection.fetch(sql)
+            return colinfo
+        except Exception as err:
+            self._logger.exception(f"Wrong Table information {tablename!s}: {err}")
+
+    ### DDL Information.
+    async def create(self, obj: str = "table", name: str = "", fields: Optional[list] = None) -> bool:
+        """
+        Create is a generic method for Database Objects Creation.
+        """
+        if obj == "table":
+            sql = "CREATE TABLE {name}({columns});"
+            columns = ", ".join(["{name} {type}".format(**e) for e in fields])
+            sql = sql.format(name=name, columns=columns)
+            try:
+                result = await self._connection.execute(sql)
+                if result:
+                    await self._connection.commit()
+                    return True
+                else:
+                    return False
+            except Exception as err:
+                raise DriverError(message=f"Error in Object Creation: {err!s}") from err
+        else:
+            raise RuntimeError(f"SQLite: invalid Object type {object!s}")
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError
```

## asyncdb/drivers/mysql.py

```diff
@@ -1,457 +1,460 @@
-#!/usr/bin/env python3
-
-import asyncio
-import time
-from typing import Optional, Union, Any
-from collections.abc import Callable, Iterable
-import ssl
-import asyncmy
-from asyncmy.cursors import DictCursor
-from asyncdb.exceptions import (
-    ConnectionTimeout,
-    NoDataFound,
-    DriverError,
-    StatementError,
-)
-from asyncdb.interfaces import DBCursorBackend
-from .abstract import BasePool
-from .sql import SQLCursor, SQLDriver
-
-
-class mysqlCursor(SQLCursor):
-    _connection: Any = None
-
-
-class mysqlPool(BasePool):
-    _setup_func: Optional[Callable] = None
-    _init_func: Optional[Callable] = None
-
-    def __init__(
-        self, dsn: str = None, loop: asyncio.AbstractEventLoop = None, params: Optional[dict] = None, **kwargs
-    ):
-        self._test_query = "SELECT 1"
-        self._max_clients = 300
-        self._min_size = 10
-        self._dsn = "mysql://{user}:{password}@{host}:{port}/{database}"
-        self._init_command = kwargs.pop("init_command", None)
-        self._sql_modes = kwargs.pop("sql_modes", None)
-        super(mysqlPool, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
-
-    async def connect(self):
-        """
-        Create a database connection pool.
-        """
-        self._logger.debug("MySQL: Connecting to {}".format(self._params))
-        try:
-            # TODO: pass a setup class for set_builtin_type_codec and a setup for add listener
-            params = {}
-            if self._init_command:
-                params["init_command"] = self._init_command
-            if self._sql_modes:
-                params["sql_mode"] = self._sql_modes
-            self._pool = await asyncmy.create_pool(
-                host=self._params["host"],
-                port=int(self._params["port"]),
-                user=self._params["user"],
-                password=self._params["password"],
-                database=self._params["database"],
-                connect_timeout=self._timeout,
-                **params,
-            )
-        except TimeoutError as err:
-            raise ConnectionTimeout(f"MySQL: Unable to connect to database: {err}")
-        except ConnectionRefusedError as err:
-            raise DriverError(f"MySQL: Unable to connect to database, connection Refused: {err}")
-        except Exception as err:
-            raise DriverError(f"Unknown Error: {err}")
-        # is connected
-        if self._pool:
-            self._connected = True
-            self._initialized_on = time.time()
-        return self
-
-    async def acquire(self):
-        """
-        Take a connection from the pool.
-        """
-        try:
-            self._connection = await self._pool.acquire()
-        except Exception as err:
-            raise DriverError(f"MySQL: Unable to acquire a connection from the pool: {err}")
-        if self._connection:
-            db = mysql(pool=self)
-            db.set_connection(self._connection)
-        return db
-
-    async def release(self, connection=None):
-        """
-        Release a connection from the pool
-        """
-        if not connection:
-            conn = self._connection
-        elif isinstance(connection, mysql):
-            conn = connection.get_connection()
-        else:
-            conn = connection
-        try:
-            await self._pool.release(conn)
-        except Exception as err:
-            raise DriverError(f"MySQL: Unable to release a connection from the pool: {err}")
-
-    async def wait_close(self, gracefully=True):
-        """
-        close
-            Close Pool Connection
-        """
-        if self._pool:
-            # try to closing main connection
-            try:
-                if self._connection:
-                    await self._pool.release(self._connection)
-            except Exception as err:
-                raise DriverError(f"MySQL: Unable to release a connection from the pool: {err}")
-            # at now, try to closing pool
-            try:
-                self._pool.close()
-            except Exception as err:
-                raise DriverError(f"Closing Error: {err}")
-            finally:
-                self._pool.terminate()
-                self._pool = None
-
-    async def close(self):
-        """
-        Close Pool.
-        """
-        try:
-            await self._pool.clear()
-            self._pool.close()
-        except Exception as err:
-            print(f"MySQL: Unable to close the pool: {err}")
-            self._pool.terminate()
-
-    disconnect = close
-
-    def terminate(self):
-        self._pool.terminate()
-
-    async def execute(self, sentence, *args):
-        """
-        Execute a connection into the Pool
-        """
-        try:
-            async with self._pool.acquire() as conn:
-                async with conn.cursor(DictCursor) as cursor:
-                    result = await cursor.execute(sentence, *args)
-            return result
-        except Exception as err:
-            raise DriverError(f"MySQL: Unable to Execute: {err}")
-
-    async def test_connection(self, *args):
-        """Test Connnection.
-        Making a connection Test using the basic Query Method.
-        """
-        result = None
-        error = None
-        if self._test_query is None:
-            return [None, NotImplementedError()]
-        try:
-            result = await self.execute(self._test_query, *args)
-        except DriverError as err:
-            error = err
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-
-class mysql(SQLDriver, DBCursorBackend):
-    _provider = "mysql"
-    _syntax = "sql"
-    _test_query = "SELECT 1"
-
-    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
-        self._dsn = "mysql://{user}:{password}@{host}:{port}/{database}"
-        self._prepared = None
-        self._cursor = None
-        self._transaction = None
-        self._server_settings = {}
-        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
-        DBCursorBackend.__init__(self)
-        if "pool" in kwargs:
-            self._pool = kwargs["pool"]
-            self._loop = self._pool.get_loop()
-        ### SSL Support:
-        self.ssl: bool = False
-        if params and "ssl" in params:
-            ssloptions = params["ssl"]
-        elif "ssl" in kwargs:
-            ssloptions = kwargs["ssl"]
-        else:
-            ssloptions = None
-        if ssloptions:
-            self.ssl: bool = True
-            try:
-                check_hostname = ssloptions["check_hostname"]
-            except KeyError:
-                check_hostname = False
-            ### certificate Support:
-            try:
-                ca_file = ssloptions["cafile"]
-            except KeyError:
-                ca_file = None
-            args = {"cafile": ca_file}
-            self.sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, **args)
-            # Certificate Chain:
-            try:
-                certs = {"certfile": ssloptions["certfile"], "keyfile": ssloptions["keyfile"]}
-            except KeyError:
-                certs = {"certfile": None, "keyfile": None}
-            if certs["certfile"]:
-                self.sslctx.load_cert_chain(**certs)
-            self.sslctx.check_hostname = check_hostname
-
-    async def close(self):
-        """
-        Closing a Connection
-        """
-        try:
-            if self._connection:
-                self._logger.debug("Closing Connection")
-                if self._pool:
-                    await self._pool.release(self._connection)
-                else:
-                    self._connection.close()
-        except Exception as err:
-            raise DriverError(f"Error on Close Connection: {err}")
-        finally:
-            self._connection = None
-            self._connected = False
-
-    def terminate(self):
-        self.terminate()
-
-    async def connection(self):
-        """
-        Get a connection
-        """
-        self._connection = None
-        self._connected = False
-        self._cursor = None
-        try:
-            if not self._pool:
-                params = {}
-                self._connection = await asyncmy.connect(
-                    host=self._params["host"],
-                    port=int(self._params["port"]),
-                    user=self._params["user"],
-                    password=self._params["password"],
-                    database=self._params["database"],
-                    connect_timeout=self._timeout,
-                    **params,
-                )
-            else:
-                self._connection = await self._pool.acquire()
-            if self._connection:
-                self._connected = True
-                self._initialized_on = time.time()
-        except Exception as err:
-            self._connection = None
-            self._cursor = None
-            raise DriverError(f"Connection Error: {err}")
-        finally:
-            return self
-
-    async def release(self):
-        """
-        Release a Connection
-        """
-        try:
-            if not await self._connection._closed:
-                if self._pool:
-                    release = asyncio.create_task(self._pool.release(self._connection, timeout=10))
-                    asyncio.ensure_future(release, loop=self._loop)
-                    return await release
-                else:
-                    self._connection.close()
-        except Exception as err:
-            raise DriverError(f"Release Error: {err}")
-        finally:
-            self._connected = False
-            self._connection = None
-
-    def prepared_statement(self):
-        return self._prepared
-
-    @property
-    def connected(self):
-        if self._pool:
-            return not self._pool._closed
-        elif self._connection:
-            return not self._connection._closed
-        else:
-            return False
-
-    async def prepare(self, sentence: str):
-        """
-        Preparing a sentence
-        """
-        raise NotImplementedError
-
-    async def query(self, sentence: str, size: int = None):
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            async with self._connection.cursor(cursor=DictCursor) as cursor:
-                await cursor.execute(sentence)
-                if not size:
-                    self._result = await cursor.fetchall()
-                else:
-                    self._result = await cursor.fetchmany(size)
-            if not self._result:
-                raise NoDataFound("MySQL: No Data was Found")
-        except NoDataFound:
-            error = "Mysql: No Data was Found"
-        except RuntimeError as err:
-            error = "Runtime Error: {}".format(str(err))
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-        finally:
-            self.generated_at()
-            if error:
-                return [None, error]
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def queryrow(self, sentence: str):
-        error = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            async with self._connection.cursor(cursor=DictCursor) as cursor:
-                await cursor.execute(sentence)
-                self._result = await cursor.fetchone()
-            if not self._result:
-                raise NoDataFound("MySQL: No Data was Found")
-        except NoDataFound:
-            error = "Mysql: No Data was Found"
-        except RuntimeError as err:
-            error = "Runtime Error: {}".format(str(err))
-        except Exception as err:
-            error = "Error on Query: {}".format(str(err))
-        finally:
-            self.generated_at()
-            if error:
-                return [None, error]
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def fetch_one(self, sentence: str):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            async with self._connection.cursor(cursor=DictCursor) as cursor:
-                await cursor.execute(sentence)
-                result = await cursor.fetchone()
-            if not result:
-                raise NoDataFound("MySQL: No Data was Found")
-            return result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(f"MySQL Runtime Error: {err}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Error on Query: {err}")
-        finally:
-            self.generated_at()
-
-    async def fetch_all(self, sentence: str):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            async with self._connection.cursor(cursor=DictCursor) as cursor:
-                await cursor.execute(sentence)
-                result = await cursor.fetchall()
-            if not result:
-                raise NoDataFound("MySQL: No Data was Found")
-            return result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(f"MySQL Runtime Error: {err}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Error on Query: {err}")
-        finally:
-            self.generated_at()
-
-    async def fetch_many(self, sentence: str, size: int = 1000):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            async with self._connection.cursor(cursor=DictCursor) as cursor:
-                await cursor.execute(sentence)
-                result = await cursor.fetchmany(size)
-            if not result:
-                raise NoDataFound("MySQL: No Data was Found")
-            return result
-        except NoDataFound:
-            raise
-        except RuntimeError as err:
-            raise DriverError(f"MySQL Runtime Error: {err}")
-        except Exception as err:
-            raise DriverError(f"MySQL: Error on Query: {err}")
-        finally:
-            self.generated_at()
-
-    async def execute(self, sentence: str):
-        """Execute a transaction
-        get a SQL sentence and execute
-        returns: results of the execution
-        """
-        error = None
-        result = None
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            async with self._connection.cursor() as cursor:
-                result = await cursor.execute(sentence)
-            return [result, None]
-        except Exception as err:
-            error = "Error on Execute: {}".format(str(err))
-        finally:
-            self.generated_at()
-            return [result, error]
-
-    async def executemany(self, sentence: str, args: Union[tuple, list]):
-        await self.valid_operation(sentence)
-        try:
-            self.start_timing()
-            async with self._connection.cursor(cursor=DictCursor) as cursor:
-                result = await cursor.executemany(sentence, args)
-            return result
-        except Exception as err:
-            raise DriverError(f"MySQL: Error on Execute: {err}")
-        finally:
-            self.generated_at()
-
-    execute_many = executemany
-
-    def tables(self, schema: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    def table(self, tablename: str = "") -> Iterable[Any]:
-        raise NotImplementedError
-
-    async def use(self, database: str):
-        raise NotImplementedError  # pragma: no cover
-
-    """
-    Cursor Iterator Context
-    """
-
-    def __aiter__(self):
-        return self
-
-    async def __anext__(self):
-        data = await self._cursor.fetchrow()
-        if data is not None:
-            return data
-        else:
-            raise StopAsyncIteration
+#!/usr/bin/env python3
+
+import asyncio
+import time
+from typing import Optional, Union, Any
+from collections.abc import Callable, Iterable
+import ssl
+import asyncmy
+from asyncmy.cursors import DictCursor
+from ..exceptions import (
+    ConnectionTimeout,
+    NoDataFound,
+    DriverError,
+    StatementError,
+)
+from ..interfaces import DBCursorBackend
+from .abstract import BasePool
+from .sql import SQLCursor, SQLDriver
+
+
+class mysqlCursor(SQLCursor):
+    _connection: Any = None
+
+
+class mysqlPool(BasePool):
+    _setup_func: Optional[Callable] = None
+    _init_func: Optional[Callable] = None
+
+    def __init__(
+        self,
+        dsn: str = None,
+        loop: asyncio.AbstractEventLoop = None,
+        params: Optional[dict] = None,
+        **kwargs
+    ):
+        self._test_query = "SELECT 1"
+        self._max_clients = 300
+        self._min_size = 10
+        self._dsn = "mysql://{user}:{password}@{host}:{port}/{database}"
+        self._init_command = kwargs.pop("init_command", None)
+        self._sql_modes = kwargs.pop("sql_modes", None)
+        super(mysqlPool, self).__init__(dsn=dsn, loop=loop, params=params, **kwargs)
+
+    async def connect(self):
+        """
+        Create a database connection pool.
+        """
+        self._logger.debug("MySQL: Connecting to {}".format(self._params))
+        try:
+            # TODO: pass a setup class for set_builtin_type_codec and a setup for add listener
+            params = {}
+            if self._init_command:
+                params["init_command"] = self._init_command
+            if self._sql_modes:
+                params["sql_mode"] = self._sql_modes
+            self._pool = await asyncmy.create_pool(
+                host=self._params["host"],
+                port=int(self._params["port"]),
+                user=self._params["user"],
+                password=self._params["password"],
+                database=self._params["database"],
+                connect_timeout=self._timeout,
+                **params,
+            )
+        except TimeoutError as err:
+            raise ConnectionTimeout(f"MySQL: Unable to connect to database: {err}")
+        except ConnectionRefusedError as err:
+            raise DriverError(f"MySQL: Unable to connect to database, connection Refused: {err}")
+        except Exception as err:
+            raise DriverError(f"Unknown Error: {err}")
+        # is connected
+        if self._pool:
+            self._connected = True
+            self._initialized_on = time.time()
+        return self
+
+    async def acquire(self):
+        """
+        Take a connection from the pool.
+        """
+        try:
+            self._connection = await self._pool.acquire()
+        except Exception as err:
+            raise DriverError(f"MySQL: Unable to acquire a connection from the pool: {err}")
+        if self._connection:
+            db = mysql(pool=self)
+            db.set_connection(self._connection)
+        return db
+
+    async def release(self, connection=None):
+        """
+        Release a connection from the pool
+        """
+        if not connection:
+            conn = self._connection
+        elif isinstance(connection, mysql):
+            conn = connection.get_connection()
+        else:
+            conn = connection
+        try:
+            await self._pool.release(conn)
+        except Exception as err:
+            raise DriverError(f"MySQL: Unable to release a connection from the pool: {err}")
+
+    async def wait_close(self, gracefully=True):
+        """
+        close
+            Close Pool Connection
+        """
+        if self._pool:
+            # try to closing main connection
+            try:
+                if self._connection:
+                    await self._pool.release(self._connection)
+            except Exception as err:
+                raise DriverError(f"MySQL: Unable to release a connection from the pool: {err}")
+            # at now, try to closing pool
+            try:
+                self._pool.close()
+            except Exception as err:
+                raise DriverError(f"Closing Error: {err}")
+            finally:
+                self._pool.terminate()
+                self._pool = None
+
+    async def close(self):
+        """
+        Close Pool.
+        """
+        try:
+            await self._pool.clear()
+            self._pool.close()
+        except Exception as err:
+            print(f"MySQL: Unable to close the pool: {err}")
+            self._pool.terminate()
+
+    disconnect = close
+
+    def terminate(self):
+        self._pool.terminate()
+
+    async def execute(self, sentence, *args):
+        """
+        Execute a connection into the Pool
+        """
+        try:
+            async with self._pool.acquire() as conn:
+                async with conn.cursor(DictCursor) as cursor:
+                    result = await cursor.execute(sentence, *args)
+            return result
+        except Exception as err:
+            raise DriverError(f"MySQL: Unable to Execute: {err}")
+
+    async def test_connection(self, *args):
+        """Test Connnection.
+        Making a connection Test using the basic Query Method.
+        """
+        result = None
+        error = None
+        if self._test_query is None:
+            return [None, NotImplementedError()]
+        try:
+            result = await self.execute(self._test_query, *args)
+        except DriverError as err:
+            error = err
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+
+class mysql(SQLDriver, DBCursorBackend):
+    _provider = "mysql"
+    _syntax = "sql"
+    _test_query = "SELECT 1"
+
+    def __init__(self, dsn: str = "", loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs) -> None:
+        self._dsn = "mysql://{user}:{password}@{host}:{port}/{database}"
+        self._prepared = None
+        self._cursor = None
+        self._transaction = None
+        self._server_settings = {}
+        SQLDriver.__init__(self, dsn=dsn, loop=loop, params=params, **kwargs)
+        DBCursorBackend.__init__(self)
+        if "pool" in kwargs:
+            self._pool = kwargs["pool"]
+            self._loop = self._pool.get_loop()
+        ### SSL Support:
+        self.ssl: bool = False
+        if params and "ssl" in params:
+            ssloptions = params["ssl"]
+        elif "ssl" in kwargs:
+            ssloptions = kwargs["ssl"]
+        else:
+            ssloptions = None
+        if ssloptions:
+            self.ssl: bool = True
+            try:
+                check_hostname = ssloptions["check_hostname"]
+            except KeyError:
+                check_hostname = False
+            ### certificate Support:
+            try:
+                ca_file = ssloptions["cafile"]
+            except KeyError:
+                ca_file = None
+            args = {"cafile": ca_file}
+            self.sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH, **args)
+            # Certificate Chain:
+            try:
+                certs = {"certfile": ssloptions["certfile"], "keyfile": ssloptions["keyfile"]}
+            except KeyError:
+                certs = {"certfile": None, "keyfile": None}
+            if certs["certfile"]:
+                self.sslctx.load_cert_chain(**certs)
+            self.sslctx.check_hostname = check_hostname
+
+    async def close(self):
+        """
+        Closing a Connection
+        """
+        try:
+            if self._connection:
+                if self._pool:
+                    await self._pool.release(self._connection)
+                else:
+                    self._connection.close()
+        except Exception as err:
+            raise DriverError(f"Error on Close Connection: {err}")
+        finally:
+            self._connection = None
+            self._connected = False
+
+    def terminate(self):
+        self.terminate()
+
+    async def connection(self):
+        """
+        Get a connection
+        """
+        self._connection = None
+        self._connected = False
+        self._cursor = None
+        try:
+            if not self._pool:
+                params = {}
+                self._connection = await asyncmy.connect(
+                    host=self._params["host"],
+                    port=int(self._params["port"]),
+                    user=self._params["user"],
+                    password=self._params["password"],
+                    database=self._params["database"],
+                    connect_timeout=self._timeout,
+                    **params,
+                )
+            else:
+                self._connection = await self._pool.acquire()
+            if self._connection:
+                self._connected = True
+                self._initialized_on = time.time()
+        except Exception as err:
+            self._connection = None
+            self._cursor = None
+            raise DriverError(f"Connection Error: {err}")
+        finally:
+            return self
+
+    async def release(self):
+        """
+        Release a Connection
+        """
+        try:
+            if not await self._connection._closed:
+                if self._pool:
+                    release = asyncio.create_task(self._pool.release(self._connection, timeout=10))
+                    asyncio.ensure_future(release, loop=self._loop)
+                    return await release
+                else:
+                    self._connection.close()
+        except Exception as err:
+            raise DriverError(f"Release Error: {err}")
+        finally:
+            self._connected = False
+            self._connection = None
+
+    def prepared_statement(self):
+        return self._prepared
+
+    @property
+    def connected(self):
+        if self._pool:
+            return not self._pool._closed
+        elif self._connection:
+            return not self._connection._closed
+        else:
+            return False
+
+    async def prepare(self, sentence: str):
+        """
+        Preparing a sentence
+        """
+        raise NotImplementedError
+
+    async def query(self, sentence: str, size: int = None):
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            async with self._connection.cursor(cursor=DictCursor) as cursor:
+                await cursor.execute(sentence)
+                if not size:
+                    self._result = await cursor.fetchall()
+                else:
+                    self._result = await cursor.fetchmany(size)
+            if not self._result:
+                raise NoDataFound("MySQL: No Data was Found")
+        except NoDataFound:
+            error = "Mysql: No Data was Found"
+        except RuntimeError as err:
+            error = "Runtime Error: {}".format(str(err))
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+        finally:
+            self.generated_at()
+            if error:
+                return [None, error]
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def queryrow(self, sentence: str):
+        error = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            async with self._connection.cursor(cursor=DictCursor) as cursor:
+                await cursor.execute(sentence)
+                self._result = await cursor.fetchone()
+            if not self._result:
+                raise NoDataFound("MySQL: No Data was Found")
+        except NoDataFound:
+            error = "Mysql: No Data was Found"
+        except RuntimeError as err:
+            error = "Runtime Error: {}".format(str(err))
+        except Exception as err:
+            error = "Error on Query: {}".format(str(err))
+        finally:
+            self.generated_at()
+            if error:
+                return [None, error]
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def fetch_one(self, sentence: str):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            async with self._connection.cursor(cursor=DictCursor) as cursor:
+                await cursor.execute(sentence)
+                result = await cursor.fetchone()
+            if not result:
+                raise NoDataFound("MySQL: No Data was Found")
+            return result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(f"MySQL Runtime Error: {err}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Error on Query: {err}")
+        finally:
+            self.generated_at()
+
+    async def fetch_all(self, sentence: str):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            async with self._connection.cursor(cursor=DictCursor) as cursor:
+                await cursor.execute(sentence)
+                result = await cursor.fetchall()
+            if not result:
+                raise NoDataFound("MySQL: No Data was Found")
+            return result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(f"MySQL Runtime Error: {err}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Error on Query: {err}")
+        finally:
+            self.generated_at()
+
+    async def fetch_many(self, sentence: str, size: int = 1000):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            async with self._connection.cursor(cursor=DictCursor) as cursor:
+                await cursor.execute(sentence)
+                result = await cursor.fetchmany(size)
+            if not result:
+                raise NoDataFound("MySQL: No Data was Found")
+            return result
+        except NoDataFound:
+            raise
+        except RuntimeError as err:
+            raise DriverError(f"MySQL Runtime Error: {err}")
+        except Exception as err:
+            raise DriverError(f"MySQL: Error on Query: {err}")
+        finally:
+            self.generated_at()
+
+    async def execute(self, sentence: str):
+        """Execute a transaction
+        get a SQL sentence and execute
+        returns: results of the execution
+        """
+        error = None
+        result = None
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            async with self._connection.cursor() as cursor:
+                result = await cursor.execute(sentence)
+            return [result, None]
+        except Exception as err:
+            error = "Error on Execute: {}".format(str(err))
+        finally:
+            self.generated_at()
+            return [result, error]
+
+    async def executemany(self, sentence: str, args: Union[tuple, list]):
+        await self.valid_operation(sentence)
+        try:
+            self.start_timing()
+            async with self._connection.cursor(cursor=DictCursor) as cursor:
+                result = await cursor.executemany(sentence, args)
+            return result
+        except Exception as err:
+            raise DriverError(f"MySQL: Error on Execute: {err}")
+        finally:
+            self.generated_at()
+
+    execute_many = executemany
+
+    def tables(self, schema: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    def table(self, tablename: str = "") -> Iterable[Any]:
+        raise NotImplementedError
+
+    async def use(self, database: str):
+        raise NotImplementedError  # pragma: no cover
+
+    """
+    Cursor Iterator Context
+    """
+
+    def __aiter__(self):
+        return self
+
+    async def __anext__(self):
+        data = await self._cursor.fetchrow()
+        if data is not None:
+            return data
+        else:
+            raise StopAsyncIteration
```

## asyncdb/drivers/rethink.py

```diff
@@ -1,840 +1,842 @@
-""" RethinkDB async Provider.
-Notes on RethinkDB async Provider
---------------------
-TODO:
- * Index Manipulation
- * map reductions
- * slice (.slice(3,6).run(conn))
- * Group, aggregation, ungroup and reduce
- * to_json_string, to_json
-
-"""
-import asyncio
-import logging
-import time
-from typing import Any, Optional, Union
-from collections.abc import Iterable
-import rethinkdb
-from rethinkdb.errors import (
-    ReqlDriverError,
-    ReqlError,
-    ReqlNonExistenceError,
-    ReqlOpFailedError,
-    ReqlOpIndeterminateError,
-    ReqlResourceLimitError,
-    ReqlRuntimeError,
-)
-from rethinkdb import r
-from datamodel import BaseModel
-from asyncdb.interfaces import DBCursorBackend, CursorBackend
-from asyncdb.exceptions import DriverError, DataError, NoDataFound, StatementError
-from .abstract import InitDriver, BaseCursor
-
-
-class Point(BaseModel):
-    x: float
-    y: float
-
-    def as_point(self) -> Any:
-        return r.point(self.x, self.y)
-
-
-class rethinkCursor(BaseCursor):
-    """
-    Cursor Object for RethinkDB.
-    """
-
-    _provider: "rethink"
-
-    async def __aenter__(self) -> CursorBackend:
-        try:
-            self._cursor = await self._sentence.run(self._connection)
-        except Exception as err:  # pylint: disable=W0703
-            logging.exception(err)
-        return self
-
-    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
-        try:
-            return await self._cursor.close()
-        except Exception as err:  # pylint: disable=W0703
-            logging.exception(err)
-
-    async def __anext__(self):
-        """Use `cursor.fetchrow()` to provide an async iterable."""
-        try:
-            row = await self._cursor.next()
-        except AttributeError:
-            row = None
-        except rethinkdb.errors.ReqlCursorEmpty:
-            row = None
-        if row is not None:
-            return row
-        else:
-            raise StopAsyncIteration
-
-    async def fetch_one(self) -> Optional[dict]:
-        return await self._cursor.fetchone()
-
-    async def fetch_many(self, size: int = None) -> Iterable[dict]:
-        return await self._cursor.fetch(size)
-
-    async def fetch_all(self) -> Iterable[dict]:
-        return await self._cursor.fetchall()
-
-
-class rethink(InitDriver, DBCursorBackend):
-    _provider = "rethink"
-    _syntax = "rql"
-
-    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
-        self.conditions = {}
-        self.fields = []
-        self.conditions = {}
-        self.cond_definition = None
-        self.refresh = False
-        self.where = None
-        self.ordering = None
-        self.qry_options = None
-        self._group = None
-        self.distinct = None
-        InitDriver.__init__(self, loop=loop, params=params, **kwargs)
-        DBCursorBackend.__init__(self)
-        # set rt object
-        self._engine = r
-        # set asyncio type
-        self._engine.set_loop_type("asyncio")
-        asyncio.set_event_loop(self._loop)
-        # rethink understand "database" as db
-        try:
-            self.params["db"] = self.params["database"]
-            del self.params["database"]
-        except KeyError:
-            pass
-
-    async def connection(self):
-        self._logger.debug(f'RT Connection to host {self.params["host"]}:{self.params["port"]}')
-        self._connection = None
-        self.params["timeout"] = self._timeout
-        print(self.params)
-        try:
-            self._connection = await self._engine.connect(**self.params)
-            if self.params["db"]:
-                await self.db(self.params["db"])
-        except ReqlRuntimeError as err:
-            error = f"No database connection could be established: {err!s}"
-            raise DriverError(message=error) from err
-        except ReqlDriverError as err:
-            error = f"No database connection could be established: {err!s}"
-            raise DriverError(message=error) from err
-        except Exception as err:
-            error = f"Exception on RethinkDB: {err!s}"
-            raise DriverError(message=error) from err
-        finally:
-            if self._connection:
-                self._connected = True
-        return self
-
-    def engine(self):
-        return self._engine
-
-    async def close(self, timeout=10, wait=True):
-        try:
-            if self._connection:
-                await self._connection.close(noreply_wait=wait)
-        finally:
-            self._connection = None
-            self._connected = False
-
-    disconnect = close
-
-    async def release(self):
-        await self.close(wait=10)
-
-    ### Basic Methods
-    async def use(self, database: str):
-        self._db = database
-        try:
-            self._connection.use(self._db)
-        except ReqlError as err:
-            raise DriverError(message=f"Error connecting to database: {database}") from err
-        return self
-
-    db = use
-
-    async def createdb(self, database: str, use: bool = False):
-        """
-        CreateDB
-              create (if not exists) a new Database
-        ------
-        """
-        try:
-            if database not in await self._engine.db_list().run(self._connection):
-                self._db = database
-                await self._engine.db_create(self._db).run(self._connection)
-            if use is True:
-                self._connection.use(self._db)
-        except Exception as ex:
-            error = f"Unable to create database: {ex}"
-            logging.exception(error)
-            raise DriverError(error) from ex
-
-    create_database = createdb
-
-    async def dropdb(self, database: str):
-        """
-        Drop a database
-        """
-        try:
-            await self._engine.db_drop(database).run(self._connection)
-            return self
-        finally:
-            if database == self._db:  # current database
-                self._connection.use("test")
-
-    drop_database = dropdb
-
-    async def sync(self, table: str):
-        """
-        sync
-            ensures that writes on a given table are written to permanent storage
-        """
-        await self.valid_operation(table)
-        if table in await self._engine.db(self._db).table_list().run(self._connection):
-            return await self._engine.table(table).sync().run(self._connection)
-
-    async def createindex(self, table: str, field: str, name: str = "", fields: list = None, multi: bool = True):
-        """
-        CreateIndex
-              create and index into a field or multiple fields
-              --- r.table('comments').index_create('post_and_date', [r.row["post_id"], r.row["date"]]).run(conn)
-        """
-        await self.valid_operation(table)
-        if table in await self._engine.db(self._db).table_list().run(self._connection):
-            # check for a single index
-            if isinstance(fields, list) and len(fields) > 0:
-                idx = []
-                for f in fields:
-                    idx.append(self._engine.row(f))
-                try:
-                    return await self._engine.table(table).index_create(name, idx).run(self._connection)
-                except (ReqlDriverError, ReqlRuntimeError) as ex:
-                    logging.error(f"Failed to create index: {ex}")
-                    return False
-            else:
-                try:
-                    return await self._engine.table(table).index_create(field, multi=multi).run(self._connection)
-                except ReqlOpFailedError as ex:
-                    raise DriverError(f"Failed to create index: {ex}") from ex
-        else:
-            return False
-
-    create_index = createindex
-
-    async def create_table(self, table: str, pk: Union[str, list] = None):
-        """
-        create_table
-           Create a new table with optional primary key
-        """
-        try:
-            if pk:
-                return await self._engine.db(self._db).table_create(table, primary_key=pk).run(self._connection)
-            else:
-                return await self._engine.db(self._db).table_create(table).run(self._connection)
-        except ReqlOpFailedError as ex:
-            raise DriverError(f"Cannot create Table {table}, {ex}") from ex
-        except (ReqlDriverError, ReqlRuntimeError) as ex:
-            raise DriverError(f"Error crating Table {table}, {ex}") from ex
-        except Exception as err:
-            raise DriverError(f"Unknown ERROR on Table Creation: {err}") from err
-
-    async def clean(self, table: str, conditions: list = None):
-        """
-        clean
-           Clean a Table based on some conditions.
-        """
-        result = []
-        if self.conditions:
-            conditions = {**conditions, **self.conditions}
-        conditions.update((x, None) for (x, y) in conditions.items() if y == "null")
-        self._logger.debug(f"Conditions for clean Table {table}: {conditions!r}")
-        try:
-            if conditions["filterdate"] == "CURRENT_DATE":
-                conditions["filterdate"] = time.strftime("%Y-%m-%d")
-        except (KeyError, ValueError):
-            conditions["filterdate"] = time.strftime("%Y-%m-%d")
-        result = await self.delete(table, filter=conditions, changes=False)
-        return result
-
-    async def listdb(self):
-        if self._connection:
-            return await self._engine.db_list().run(self._connection)
-        else:
-            return []
-
-    list_databases = listdb
-
-    async def list_tables(self):
-        if self._connection:
-            tables = await self._engine.db(self._db).table_list().run(self._connection)
-            return tables
-        else:
-            return []
-
-    async def drop_table(self, table: str):
-        try:
-            return await self._engine.db(self._db).table_drop(table).run(self._connection)
-        except ReqlOpFailedError as ex:
-            raise DriverError(f"Cannot drop Table {table}, {ex}") from ex
-        except (ReqlDriverError, ReqlRuntimeError) as ex:
-            raise DriverError(f"Error dropping Table {table}, {ex}") from ex
-        except Exception as err:
-            raise DriverError(f"Unknown ERROR on Table Drop: {err}") from err
-
-    #### Derived Methods (mandatory)
-    async def test_connection(self, **kwargs):
-        result = None
-        error = None
-        try:
-            result = await self._engine.db_list().run(self._connection)
-        except Exception as err:  # pylint: disable=W0703
-            return [None, err]
-        finally:
-            return [result, error]  # pylint: disable=W0150
-
-    async def execute(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
-        raise NotImplementedError
-
-    async def execute_many(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
-        raise NotImplementedError
-
-    async def prepare(self, sentence: Any, **kwargs):
-        raise NotImplementedError
-
-    async def query(
-        self, table: str, columns: list = None, order_by: list = None, limit: int = None, **kwargs
-    ):  # pylint: disable=W0221,W0237
-        """
-        query
-            get all rows from a table
-        -----
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(table)
-        data = []
-        try:
-            self.start_timing()
-            _filter = kwargs.get("filter", kwargs)
-            # table:
-            table = self._engine.db(self._db).table(table)
-            if not columns:
-                self._columns = await self._engine.table(table).nth(0).default(None).keys().run(self._connection)
-            else:
-                self._columns = columns
-                table = table.with_fields(*columns)
-            if _filter:
-                result = table.filter(_filter)
-            else:
-                result = table
-            if isinstance(order_by, list):
-                order = [r.asc(o) for o in order_by]
-                result = result.order_by(*order)
-            if limit is not None:
-                result = result.limit(limit)
-            cursor = await result.run(self._connection)
-            if isinstance(cursor, list):
-                self._result = cursor
-            else:
-                while await cursor.fetch_next():
-                    row = await cursor.next()
-                    data.append(row)
-                if data:
-                    self._result = data
-                else:
-                    raise NoDataFound(message=f"RethinkDB: Empty Result on {table!s}", code=404)
-        except ReqlResourceLimitError as err:
-            error = f"Query Limit Error: {err!s}"
-        except ReqlOpIndeterminateError as err:
-            error = f"Operation indeterminated: {err!s}"
-        except ReqlNonExistenceError as err:
-            error = f"Object doesn't exist {table}: {err!s}"
-        except rethinkdb.errors.ReqlPermissionError as err:
-            error = f"Permission error over {table}: {err}"
-        except ReqlRuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Unknown RT error: {err}"
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def fetch_all(self, table: str, **kwargs):  # pylint: disable=W0221,W0237
-        """
-        query
-            get all rows from a table
-        -----
-        """
-        self._result = None
-        await self.valid_operation(table)
-        data = []
-        try:
-            self.start_timing()
-            _filter = kwargs.get("filter", kwargs)
-            self._columns = await self._engine.table(table).nth(0).default(None).keys().run(self._connection)
-            if not _filter:
-                cursor = await self._engine.db(self._db).table(table).run(self._connection)
-            else:
-                cursor = await self._engine.db(self._db).table(table).filter(_filter).run(self._connection)
-            while await cursor.fetch_next():
-                row = await cursor.next()
-                data.append(row)
-            if data:
-                return data
-            else:
-                raise NoDataFound(message=f"RethinkDB: Empty Result on {table!s}", code=404)
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-        finally:
-            self.generated_at()
-
-    fetchall = fetch_all
-
-    async def queryrow(self, table: str, columns: list = None, nth: int = 0, **kwargs):  # pylint: disable=W0221,W0237
-        """
-        queryrow
-            get only one row.
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(table)
-        try:
-            self.start_timing()
-            _filter = kwargs.get("filter", kwargs)
-            if not columns:
-                self._columns = await self._engine.table(table).nth(0).default(None).keys().run(self._connection)
-            else:
-                self._columns = columns
-            # table:
-            table = self._engine.db(self._db).table(table)
-            if columns:
-                table = table.with_fields(*columns)
-            if _filter:
-                result = table.filter(_filter)
-            else:
-                result = table
-            data = await result.nth(nth).run(self._connection)
-            if data:
-                self._result = data
-            else:
-                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
-        except ReqlResourceLimitError as err:
-            error = f"Query Limit Error: {err!s}"
-        except ReqlOpIndeterminateError as err:
-            error = f"Operation indeterminated: {err!s}"
-        except ReqlNonExistenceError as err:
-            error = f"Object doesn't exist {table}: {err!s}"
-        except rethinkdb.errors.ReqlPermissionError as err:
-            error = f"Permission error over {table}: {err}"
-        except ReqlRuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Unknown RT error: {err}"
-        finally:
-            self.generated_at()
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    query_row = queryrow
-
-    async def fetch_one(self, table: str, nth: int = 0, **kwargs):  # pylint: disable=W0221,W0237
-        """
-        fetch_one
-            get only one row.
-        """
-        self._result = None
-        await self.valid_operation(table)
-        try:
-            _filter = kwargs.get("filter", kwargs)
-            self.start_timing()
-            if kwargs:
-                data = await self._engine.table(table).filter(_filter).nth(nth).run(self._connection)
-            else:
-                data = await self._engine.table(table).nth(nth).run(self._connection)
-            if data:
-                return data
-            else:
-                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-
-    ### New Methods
-    async def get(self, table: str, idx: int = 0):
-        """
-        get
-           get only one row based on primary key or filtering,
-           Get a document by primary key.
-        -----
-        """
-        error = None
-        await self.valid_operation(table)
-        try:
-            data = await self._engine.table(table).get(idx).run(self._connection)
-            if data:
-                self._result = data
-            else:
-                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
-        except ReqlResourceLimitError as err:
-            error = f"Query Limit Error: {err!s}"
-        except ReqlOpIndeterminateError as err:
-            error = f"Operation indeterminated: {err!s}"
-        except ReqlNonExistenceError as err:
-            error = f"Object doesn't exist {table}: {err!s}"
-        except rethinkdb.errors.ReqlPermissionError as err:
-            error = f"Permission error over {table}: {err}"
-        except ReqlRuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Unknown RT error: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def get_all(self, table: str, index: str = None, **kwargs):
-        """
-        get_all.
-           get all rows where the given value matches the value of
-           the requested index.
-        -----
-        """
-        error = None
-        self._result = None
-        await self.valid_operation(table)
-        try:
-            _filter = kwargs.get("filter", kwargs)
-            if index:
-                cursor = await self._engine.table(table).get_all(_filter, index=index).run(self._connection)
-            else:
-                cursor = await self._engine.table(table).get_all(_filter).run(self._connection)
-            data = []
-            while await cursor.fetch_next():
-                item = await cursor.next()
-                data.append(item)
-            if data:
-                self._result = data
-            else:
-                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
-        except ReqlResourceLimitError as err:
-            error = f"Query Limit Error: {err!s}"
-        except ReqlOpIndeterminateError as err:
-            error = f"Operation indeterminated: {err!s}"
-        except ReqlNonExistenceError as err:
-            error = f"Object doesn't exist {table}: {err!s}"
-        except rethinkdb.errors.ReqlPermissionError as err:
-            error = f"Permission error over {table}: {err}"
-        except ReqlRuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Unknown RT error: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def match(self, table: str, field: str = "id", regexp="(?i)^[a-z]+$"):
-        """
-        match
-           get all rows where the given value matches with a regular expression
-        -----
-        """
-        self._result = None
-        error = None
-        await self.valid_operation(table)
-        try:
-            data = await self._engine.table(table).filter(lambda doc: doc[field].match(regexp)).run(self._connection)
-            if data:
-                self._result = data
-            else:
-                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
-        except ReqlResourceLimitError as err:
-            error = f"Query Limit Error: {err!s}"
-        except ReqlOpIndeterminateError as err:
-            error = f"Operation indeterminated: {err!s}"
-        except ReqlNonExistenceError as err:
-            error = f"Object doesn't exist {table}: {err!s}"
-        except rethinkdb.errors.ReqlPermissionError as err:
-            error = f"Permission error over {table}: {err}"
-        except ReqlRuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Unknown RT error: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    async def insert(self, table: str, data: dict, on_conflict: str = "replace", changes: bool = True):
-        """
-        insert.
-             create a record (insert)
-        -----
-        """
-        try:
-            inserted = (
-                await self._engine.table(table)
-                .insert(data, conflict=on_conflict, durability="soft", return_changes=changes)
-                .run(self._connection)
-            )
-            if inserted["errors"] > 0:
-                raise DriverError(f"INSERT Error: {inserted['first_error']}")
-            return inserted
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-
-    async def replace(self, table: str, data: dict, idx: int = 0):
-        """
-        replace
-             replace a record (insert, update or delete)
-        -----
-        """
-        try:
-            replaced = await self._engine.table(table).get(idx).replace(data, durability="soft").run(self._connection)
-            if replaced["errors"] > 0:
-                raise DriverError(f"REPLACE Error: {replaced['first_error']}")
-            return replaced
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-
-    async def update(self, table: str, data: dict, idx: str = None, **kwargs):
-        """
-        update
-             update a record based on filter match
-        -----
-        """
-        _filter = kwargs.get("filter", kwargs)
-        if idx:
-            sentence = self._engine.table(table).get(id).update(data)
-        elif isinstance(_filter, dict) and len(_filter) > 0:
-            sentence = self._engine.table(table).filter(_filter).update(data, return_changes=False, durability="soft")
-        else:
-            # update all documents in table
-            sentence = self._engine.table(table).update(data, durability="soft", return_changes=False)
-        try:
-            self._result = await sentence.run(self._connection)
-            return self._result
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-
-    async def literal(self, table: str, idx: int, field: str, data: dict):
-        """
-        literal
-            replace a field with another
-        """
-        try:
-            self._result = (
-                await self._engine.table(table)
-                .get(idx)
-                .update({field: self._engine.literal(data).run(self._connection)})
-            )
-            return self._result
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-
-    async def update_conditions(self, table: str, data: dict, field: str = "filterdate", **kwargs):
-        """
-        update_conditions
-             update a record based on a fieldname
-        -----
-        """
-        try:
-            _filter = kwargs.get("filter", kwargs)
-            self._result = (
-                await self._engine.table(table)
-                .filter(~self._engine.row.has_fields(field))
-                .filter(_filter)
-                .update(data, durability="soft", return_changes=False)
-                .run(self._connection)
-            )
-            return self._result
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-
-    async def delete(self, table: str, idx: str = None, changes: bool = True, **kwargs):
-        """
-        delete
-             delete a record based on id or filter search
-        -----
-        """
-        _filter = kwargs.get("filter", kwargs)
-        if idx:
-            sentence = self._engine.table(table).get(idx).delete(return_changes=changes, durability="soft")
-        elif isinstance(_filter, dict):
-            sentence = self._engine.table(table).filter(_filter).delete(return_changes=changes)
-        else:
-            sentence = self._engine.table(table).delete(return_changes=changes)
-        try:
-            self._result = await sentence.run(self._connection)
-            return self._result
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-
-    async def between(self, table: str, min: int = None, max: int = None, idx: str = None):
-        """
-        between.
-             Get all documents between two keys
-        -----
-        """
-        self._result = None
-        await self.valid_operation(table)
-        error = None
-        if min:
-            m = min
-        else:
-            m = self._engine.minval
-        if max:
-            mx = max
-        else:
-            mx = self._engine.maxval
-        try:
-            if idx:
-                cursor = (
-                    await self._engine.table(table).order_by(index=idx).between(m, mx, index=idx).run(self._connection)
-                )
-            else:
-                cursor = await self._engine.table(table).between(m, mx).run(self._connection)
-            data = []
-            while await cursor.fetch_next():
-                item = await cursor.next()
-                data.append(item)
-            if data:
-                self._result = data
-            else:
-                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}")
-        except ReqlResourceLimitError as err:
-            error = f"Query Limit Error: {err!s}"
-        except ReqlOpIndeterminateError as err:
-            error = f"Operation indeterminated: {err!s}"
-        except ReqlNonExistenceError as err:
-            error = f"Object doesn't exist {table}: {err!s}"
-        except rethinkdb.errors.ReqlPermissionError as err:
-            error = f"Permission error over {table}: {err}"
-        except ReqlRuntimeError as err:
-            error = f"Runtime Error: {err}"
-        except Exception as err:  # pylint: disable=W0703
-            error = f"Unknown RT error: {err}"
-        finally:
-            return await self._serializer(self._result, error)  # pylint: disable=W0150
-
-    # Cursors:
-    def cursor(self, table: str, params: Union[dict, list] = None, **kwargs):  # pylint: disable=W0237
-        """
-        cursor
-            get all rows from a table, returning a Cursor.
-        -----
-        """
-        self._result = None
-        try:
-            if not filter:
-                cursor = self._engine.db(self._db).table(table)
-            else:
-                cursor = self._engine.db(self._db).table(table).filter(params)
-            return self.__cursor__(provider=self, sentence=cursor)
-        except ReqlResourceLimitError as err:
-            raise StatementError(f"Query Limit Error: {err!s}") from err
-        except ReqlOpIndeterminateError as err:
-            raise StatementError(f"Operation indeterminated: {err!s}") from err
-        except ReqlNonExistenceError as err:
-            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
-        except rethinkdb.errors.ReqlPermissionError as err:
-            raise DataError(f"Permission error over {table}: {err}") from err
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
-
-    async def distance(self, p1: Point, p2: Point, unit: str = "km", geo: str = "WGS84") -> float:
-        if not isinstance(p1, Point):
-            raise TypeError(f"Invalid type for Point 1: {type(p1)}")
-        if not isinstance(p2, Point):
-            raise TypeError(f"Invalid type for Point 2: {type(p2)}")
-        try:
-            point1 = p1.as_point()
-            point2 = p2.as_point()
-            return await self._engine.distance(point1, point2, unit=unit, geo_system=geo).run(self._connection)
-        except ReqlRuntimeError as err:
-            raise DriverError(f"Runtime Error: {err}") from err
-        except Exception as err:  # pylint: disable=W0703
-            raise DriverError(f"Unknown RT error: {err}") from err
+""" RethinkDB async Provider.
+Notes on RethinkDB async Provider
+--------------------
+TODO:
+ * Index Manipulation
+ * map reductions
+ * slice (.slice(3,6).run(conn))
+ * Group, aggregation, ungroup and reduce
+ * to_json_string, to_json
+
+"""
+import asyncio
+import logging
+import time
+from typing import Any, Optional, Union
+from collections.abc import Iterable
+import rethinkdb
+from rethinkdb.errors import (
+    ReqlDriverError,
+    ReqlError,
+    ReqlNonExistenceError,
+    ReqlOpFailedError,
+    ReqlOpIndeterminateError,
+    ReqlResourceLimitError,
+    ReqlRuntimeError,
+)
+from rethinkdb import r
+from datamodel import BaseModel
+from ..interfaces import DBCursorBackend, CursorBackend
+from ..exceptions import DriverError, DataError, NoDataFound, StatementError
+from .abstract import InitDriver, BaseCursor
+
+
+class Point(BaseModel):
+    x: float
+    y: float
+
+    def as_point(self) -> Any:
+        return r.point(self.x, self.y)
+
+
+class rethinkCursor(BaseCursor):
+    """
+    Cursor Object for RethinkDB.
+    """
+
+    _provider: "rethink"
+
+    async def __aenter__(self) -> CursorBackend:
+        try:
+            self._cursor = await self._sentence.run(self._connection)
+        except Exception as err:  # pylint: disable=W0703
+            logging.exception(err)
+        return self
+
+    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
+        try:
+            return await self._cursor.close()
+        except Exception as err:  # pylint: disable=W0703
+            logging.exception(err)
+
+    async def __anext__(self):
+        """Use `cursor.fetchrow()` to provide an async iterable."""
+        try:
+            row = await self._cursor.next()
+        except AttributeError:
+            row = None
+        except rethinkdb.errors.ReqlCursorEmpty:
+            row = None
+        if row is not None:
+            return row
+        else:
+            raise StopAsyncIteration
+
+    async def fetch_one(self) -> Optional[dict]:
+        return await self._cursor.fetchone()
+
+    async def fetch_many(self, size: int = None) -> Iterable[dict]:
+        return await self._cursor.fetch(size)
+
+    async def fetch_all(self) -> Iterable[dict]:
+        return await self._cursor.fetchall()
+
+
+class rethink(InitDriver, DBCursorBackend):
+    _provider = "rethink"
+    _syntax = "rql"
+
+    def __init__(self, loop: asyncio.AbstractEventLoop = None, params: dict = None, **kwargs):
+        self.conditions = {}
+        self.fields = []
+        self.conditions = {}
+        self.cond_definition = None
+        self.refresh = False
+        self.where = None
+        self.ordering = None
+        self.qry_options = None
+        self._group = None
+        self.distinct = None
+        InitDriver.__init__(self, loop=loop, params=params, **kwargs)
+        DBCursorBackend.__init__(self)
+        # set rt object
+        self._engine = r
+        # set asyncio type
+        self._engine.set_loop_type("asyncio")
+        asyncio.set_event_loop(self._loop)
+        # rethink understand "database" as db
+        try:
+            self.params["db"] = self.params["database"]
+            del self.params["database"]
+        except KeyError:
+            pass
+
+    async def connection(self):
+        self._logger.debug(f'RT Connection to host {self.params["host"]}:{self.params["port"]}')
+        self._connection = None
+        self.params["timeout"] = self._timeout
+        print(self.params)
+        try:
+            self._connection = await self._engine.connect(**self.params)
+            if self.params["db"]:
+                await self.db(self.params["db"])
+        except ReqlRuntimeError as err:
+            error = f"No database connection could be established: {err!s}"
+            raise DriverError(message=error) from err
+        except ReqlDriverError as err:
+            error = f"No database connection could be established: {err!s}"
+            raise DriverError(message=error) from err
+        except Exception as err:
+            error = f"Exception on RethinkDB: {err!s}"
+            raise DriverError(message=error) from err
+        finally:
+            if self._connection:
+                self._connected = True
+        return self
+
+    def engine(self):
+        return self._engine
+
+    async def close(self, timeout=10, wait=True):
+        try:
+            if self._connection:
+                await self._connection.close(noreply_wait=wait)
+        finally:
+            self._connection = None
+            self._connected = False
+
+    disconnect = close
+
+    async def release(self):
+        await self.close(wait=10)
+
+    ### Basic Methods
+    async def use(self, database: str):
+        self._db = database
+        try:
+            self._connection.use(self._db)
+        except ReqlError as err:
+            raise DriverError(message=f"Error connecting to database: {database}") from err
+        return self
+
+    db = use
+
+    async def createdb(self, database: str, use: bool = False):
+        """
+        CreateDB
+              create (if not exists) a new Database
+        ------
+        """
+        try:
+            if database not in await self._engine.db_list().run(self._connection):
+                self._db = database
+                await self._engine.db_create(self._db).run(self._connection)
+            if use is True:
+                self._connection.use(self._db)
+        except Exception as ex:
+            error = f"Unable to create database: {ex}"
+            logging.exception(error)
+            raise DriverError(error) from ex
+
+    create_database = createdb
+
+    async def dropdb(self, database: str):
+        """
+        Drop a database
+        """
+        try:
+            await self._engine.db_drop(database).run(self._connection)
+            return self
+        finally:
+            if database == self._db:  # current database
+                self._connection.use("test")
+
+    drop_database = dropdb
+
+    async def sync(self, table: str):
+        """
+        sync
+            ensures that writes on a given table are written to permanent storage
+        """
+        await self.valid_operation(table)
+        if table in await self._engine.db(self._db).table_list().run(self._connection):
+            return await self._engine.table(table).sync().run(self._connection)
+
+    async def createindex(self, table: str, field: str, name: str = "", fields: list = None, multi: bool = True):
+        """
+        CreateIndex
+              create and index into a field or multiple fields
+              --- r.table('comments').index_create('post_and_date', [r.row["post_id"], r.row["date"]]).run(conn)
+        """
+        await self.valid_operation(table)
+        if table in await self._engine.db(self._db).table_list().run(self._connection):
+            # check for a single index
+            if isinstance(fields, list) and len(fields) > 0:
+                idx = []
+                for f in fields:
+                    idx.append(self._engine.row(f))
+                try:
+                    return await self._engine.table(table).index_create(name, idx).run(self._connection)
+                except (ReqlDriverError, ReqlRuntimeError) as ex:
+                    logging.error(f"Failed to create index: {ex}")
+                    return False
+            else:
+                try:
+                    return await self._engine.table(table).index_create(field, multi=multi).run(self._connection)
+                except ReqlOpFailedError as ex:
+                    raise DriverError(f"Failed to create index: {ex}") from ex
+        else:
+            return False
+
+    create_index = createindex
+
+    async def create_table(self, table: str, pk: Union[str, list] = None, exists_ok: bool = True):
+        """
+        create_table
+           Create a new table with optional primary key
+        """
+        try:
+            if pk:
+                return await self._engine.db(self._db).table_create(table, primary_key=pk).run(self._connection)
+            else:
+                return await self._engine.db(self._db).table_create(table).run(self._connection)
+        except ReqlOpFailedError as ex:
+            if 'already exists in' in str(ex):
+                return True
+            raise DriverError(f"Cannot create Table {table}, {ex}") from ex
+        except (ReqlDriverError, ReqlRuntimeError) as ex:
+            raise DriverError(f"Error crating Table {table}, {ex}") from ex
+        except Exception as err:
+            raise DriverError(f"Unknown ERROR on Table Creation: {err}") from err
+
+    async def clean(self, table: str, conditions: list = None):
+        """
+        clean
+           Clean a Table based on some conditions.
+        """
+        result = []
+        if self.conditions:
+            conditions = {**conditions, **self.conditions}
+        conditions.update((x, None) for (x, y) in conditions.items() if y == "null")
+        self._logger.debug(f"Conditions for clean Table {table}: {conditions!r}")
+        try:
+            if conditions["filterdate"] == "CURRENT_DATE":
+                conditions["filterdate"] = time.strftime("%Y-%m-%d")
+        except (KeyError, ValueError):
+            conditions["filterdate"] = time.strftime("%Y-%m-%d")
+        result = await self.delete(table, filter=conditions, changes=False)
+        return result
+
+    async def listdb(self):
+        if self._connection:
+            return await self._engine.db_list().run(self._connection)
+        else:
+            return []
+
+    list_databases = listdb
+
+    async def list_tables(self):
+        if self._connection:
+            tables = await self._engine.db(self._db).table_list().run(self._connection)
+            return tables
+        else:
+            return []
+
+    async def drop_table(self, table: str):
+        try:
+            return await self._engine.db(self._db).table_drop(table).run(self._connection)
+        except ReqlOpFailedError as ex:
+            raise DriverError(f"Cannot drop Table {table}, {ex}") from ex
+        except (ReqlDriverError, ReqlRuntimeError) as ex:
+            raise DriverError(f"Error dropping Table {table}, {ex}") from ex
+        except Exception as err:
+            raise DriverError(f"Unknown ERROR on Table Drop: {err}") from err
+
+    #### Derived Methods (mandatory)
+    async def test_connection(self, **kwargs):
+        result = None
+        error = None
+        try:
+            result = await self._engine.db_list().run(self._connection)
+        except Exception as err:  # pylint: disable=W0703
+            return [None, err]
+        finally:
+            return [result, error]  # pylint: disable=W0150
+
+    async def execute(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
+        raise NotImplementedError
+
+    async def execute_many(self, sentence: Any, *args, **kwargs) -> Optional[Any]:
+        raise NotImplementedError
+
+    async def prepare(self, sentence: Any, **kwargs):
+        raise NotImplementedError
+
+    async def query(
+        self, table: str, columns: list = None, order_by: list = None, limit: int = None, **kwargs
+    ):  # pylint: disable=W0221,W0237
+        """
+        query
+            get all rows from a table
+        -----
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(table)
+        data = []
+        try:
+            self.start_timing()
+            _filter = kwargs.get("filter", kwargs)
+            # table:
+            table = self._engine.db(self._db).table(table)
+            if not columns:
+                self._columns = await self._engine.table(table).nth(0).default(None).keys().run(self._connection)
+            else:
+                self._columns = columns
+                table = table.with_fields(*columns)
+            if _filter:
+                result = table.filter(_filter)
+            else:
+                result = table
+            if isinstance(order_by, list):
+                order = [r.asc(o) for o in order_by]
+                result = result.order_by(*order)
+            if limit is not None:
+                result = result.limit(limit)
+            cursor = await result.run(self._connection)
+            if isinstance(cursor, list):
+                self._result = cursor
+            else:
+                while await cursor.fetch_next():
+                    row = await cursor.next()
+                    data.append(row)
+                if data:
+                    self._result = data
+                else:
+                    raise NoDataFound(message=f"RethinkDB: Empty Result on {table!s}", code=404)
+        except ReqlResourceLimitError as err:
+            error = f"Query Limit Error: {err!s}"
+        except ReqlOpIndeterminateError as err:
+            error = f"Operation indeterminated: {err!s}"
+        except ReqlNonExistenceError as err:
+            error = f"Object doesn't exist {table}: {err!s}"
+        except rethinkdb.errors.ReqlPermissionError as err:
+            error = f"Permission error over {table}: {err}"
+        except ReqlRuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Unknown RT error: {err}"
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def fetch_all(self, table: str, **kwargs):  # pylint: disable=W0221,W0237
+        """
+        query
+            get all rows from a table
+        -----
+        """
+        self._result = None
+        await self.valid_operation(table)
+        data = []
+        try:
+            self.start_timing()
+            _filter = kwargs.get("filter", kwargs)
+            self._columns = await self._engine.table(table).nth(0).default(None).keys().run(self._connection)
+            if not _filter:
+                cursor = await self._engine.db(self._db).table(table).run(self._connection)
+            else:
+                cursor = await self._engine.db(self._db).table(table).filter(_filter).run(self._connection)
+            while await cursor.fetch_next():
+                row = await cursor.next()
+                data.append(row)
+            if data:
+                return data
+            else:
+                raise NoDataFound(message=f"RethinkDB: Empty Result on {table!s}", code=404)
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+        finally:
+            self.generated_at()
+
+    fetchall = fetch_all
+
+    async def queryrow(self, table: str, columns: list = None, nth: int = 0, **kwargs):  # pylint: disable=W0221,W0237
+        """
+        queryrow
+            get only one row.
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(table)
+        try:
+            self.start_timing()
+            _filter = kwargs.get("filter", kwargs)
+            if not columns:
+                self._columns = await self._engine.table(table).nth(0).default(None).keys().run(self._connection)
+            else:
+                self._columns = columns
+            # table:
+            table = self._engine.db(self._db).table(table)
+            if columns:
+                table = table.with_fields(*columns)
+            if _filter:
+                result = table.filter(_filter)
+            else:
+                result = table
+            data = await result.nth(nth).run(self._connection)
+            if data:
+                self._result = data
+            else:
+                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
+        except ReqlResourceLimitError as err:
+            error = f"Query Limit Error: {err!s}"
+        except ReqlOpIndeterminateError as err:
+            error = f"Operation indeterminated: {err!s}"
+        except ReqlNonExistenceError as err:
+            error = f"Object doesn't exist {table}: {err!s}"
+        except rethinkdb.errors.ReqlPermissionError as err:
+            error = f"Permission error over {table}: {err}"
+        except ReqlRuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Unknown RT error: {err}"
+        finally:
+            self.generated_at()
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    query_row = queryrow
+
+    async def fetch_one(self, table: str, nth: int = 0, **kwargs):  # pylint: disable=W0221,W0237
+        """
+        fetch_one
+            get only one row.
+        """
+        self._result = None
+        await self.valid_operation(table)
+        try:
+            _filter = kwargs.get("filter", kwargs)
+            self.start_timing()
+            if kwargs:
+                data = await self._engine.table(table).filter(_filter).nth(nth).run(self._connection)
+            else:
+                data = await self._engine.table(table).nth(nth).run(self._connection)
+            if data:
+                return data
+            else:
+                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+
+    ### New Methods
+    async def get(self, table: str, idx: int = 0):
+        """
+        get
+           get only one row based on primary key or filtering,
+           Get a document by primary key.
+        -----
+        """
+        error = None
+        await self.valid_operation(table)
+        try:
+            data = await self._engine.table(table).get(idx).run(self._connection)
+            if data:
+                self._result = data
+            else:
+                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
+        except ReqlResourceLimitError as err:
+            error = f"Query Limit Error: {err!s}"
+        except ReqlOpIndeterminateError as err:
+            error = f"Operation indeterminated: {err!s}"
+        except ReqlNonExistenceError as err:
+            error = f"Object doesn't exist {table}: {err!s}"
+        except rethinkdb.errors.ReqlPermissionError as err:
+            error = f"Permission error over {table}: {err}"
+        except ReqlRuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Unknown RT error: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def get_all(self, table: str, index: str = None, **kwargs):
+        """
+        get_all.
+           get all rows where the given value matches the value of
+           the requested index.
+        -----
+        """
+        error = None
+        self._result = None
+        await self.valid_operation(table)
+        try:
+            _filter = kwargs.get("filter", kwargs)
+            if index:
+                cursor = await self._engine.table(table).get_all(_filter, index=index).run(self._connection)
+            else:
+                cursor = await self._engine.table(table).get_all(_filter).run(self._connection)
+            data = []
+            while await cursor.fetch_next():
+                item = await cursor.next()
+                data.append(item)
+            if data:
+                self._result = data
+            else:
+                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
+        except ReqlResourceLimitError as err:
+            error = f"Query Limit Error: {err!s}"
+        except ReqlOpIndeterminateError as err:
+            error = f"Operation indeterminated: {err!s}"
+        except ReqlNonExistenceError as err:
+            error = f"Object doesn't exist {table}: {err!s}"
+        except rethinkdb.errors.ReqlPermissionError as err:
+            error = f"Permission error over {table}: {err}"
+        except ReqlRuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Unknown RT error: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def match(self, table: str, field: str = "id", regexp="(?i)^[a-z]+$"):
+        """
+        match
+           get all rows where the given value matches with a regular expression
+        -----
+        """
+        self._result = None
+        error = None
+        await self.valid_operation(table)
+        try:
+            data = await self._engine.table(table).filter(lambda doc: doc[field].match(regexp)).run(self._connection)
+            if data:
+                self._result = data
+            else:
+                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}", code=404)
+        except ReqlResourceLimitError as err:
+            error = f"Query Limit Error: {err!s}"
+        except ReqlOpIndeterminateError as err:
+            error = f"Operation indeterminated: {err!s}"
+        except ReqlNonExistenceError as err:
+            error = f"Object doesn't exist {table}: {err!s}"
+        except rethinkdb.errors.ReqlPermissionError as err:
+            error = f"Permission error over {table}: {err}"
+        except ReqlRuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Unknown RT error: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    async def insert(self, table: str, data: dict, on_conflict: str = "replace", changes: bool = True):
+        """
+        insert.
+             create a record (insert)
+        -----
+        """
+        try:
+            inserted = (
+                await self._engine.table(table)
+                .insert(data, conflict=on_conflict, durability="soft", return_changes=changes)
+                .run(self._connection)
+            )
+            if inserted["errors"] > 0:
+                raise DriverError(f"INSERT Error: {inserted['first_error']}")
+            return inserted
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+
+    async def replace(self, table: str, data: dict, idx: int = 0):
+        """
+        replace
+             replace a record (insert, update or delete)
+        -----
+        """
+        try:
+            replaced = await self._engine.table(table).get(idx).replace(data, durability="soft").run(self._connection)
+            if replaced["errors"] > 0:
+                raise DriverError(f"REPLACE Error: {replaced['first_error']}")
+            return replaced
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+
+    async def update(self, table: str, data: dict, idx: str = None, **kwargs):
+        """
+        update
+             update a record based on filter match
+        -----
+        """
+        _filter = kwargs.get("filter", kwargs)
+        if idx:
+            sentence = self._engine.table(table).get(id).update(data)
+        elif isinstance(_filter, dict) and len(_filter) > 0:
+            sentence = self._engine.table(table).filter(_filter).update(data, return_changes=False, durability="soft")
+        else:
+            # update all documents in table
+            sentence = self._engine.table(table).update(data, durability="soft", return_changes=False)
+        try:
+            self._result = await sentence.run(self._connection)
+            return self._result
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+
+    async def literal(self, table: str, idx: int, field: str, data: dict):
+        """
+        literal
+            replace a field with another
+        """
+        try:
+            self._result = (
+                await self._engine.table(table)
+                .get(idx)
+                .update({field: self._engine.literal(data).run(self._connection)})
+            )
+            return self._result
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+
+    async def update_conditions(self, table: str, data: dict, field: str = "filterdate", **kwargs):
+        """
+        update_conditions
+             update a record based on a fieldname
+        -----
+        """
+        try:
+            _filter = kwargs.get("filter", kwargs)
+            self._result = (
+                await self._engine.table(table)
+                .filter(~self._engine.row.has_fields(field))
+                .filter(_filter)
+                .update(data, durability="soft", return_changes=False)
+                .run(self._connection)
+            )
+            return self._result
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+
+    async def delete(self, table: str, idx: str = None, changes: bool = True, **kwargs):
+        """
+        delete
+             delete a record based on id or filter search
+        -----
+        """
+        _filter = kwargs.get("filter", kwargs)
+        if idx:
+            sentence = self._engine.table(table).get(idx).delete(return_changes=changes, durability="soft")
+        elif isinstance(_filter, dict):
+            sentence = self._engine.table(table).filter(_filter).delete(return_changes=changes)
+        else:
+            sentence = self._engine.table(table).delete(return_changes=changes)
+        try:
+            self._result = await sentence.run(self._connection)
+            return self._result
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+
+    async def between(self, table: str, min: int = None, max: int = None, idx: str = None):
+        """
+        between.
+             Get all documents between two keys
+        -----
+        """
+        self._result = None
+        await self.valid_operation(table)
+        error = None
+        if min:
+            m = min
+        else:
+            m = self._engine.minval
+        if max:
+            mx = max
+        else:
+            mx = self._engine.maxval
+        try:
+            if idx:
+                cursor = (
+                    await self._engine.table(table).order_by(index=idx).between(m, mx, index=idx).run(self._connection)
+                )
+            else:
+                cursor = await self._engine.table(table).between(m, mx).run(self._connection)
+            data = []
+            while await cursor.fetch_next():
+                item = await cursor.next()
+                data.append(item)
+            if data:
+                self._result = data
+            else:
+                raise NoDataFound(message=f"RethinkDB: Empty Row Result on {table!s}")
+        except ReqlResourceLimitError as err:
+            error = f"Query Limit Error: {err!s}"
+        except ReqlOpIndeterminateError as err:
+            error = f"Operation indeterminated: {err!s}"
+        except ReqlNonExistenceError as err:
+            error = f"Object doesn't exist {table}: {err!s}"
+        except rethinkdb.errors.ReqlPermissionError as err:
+            error = f"Permission error over {table}: {err}"
+        except ReqlRuntimeError as err:
+            error = f"Runtime Error: {err}"
+        except Exception as err:  # pylint: disable=W0703
+            error = f"Unknown RT error: {err}"
+        finally:
+            return await self._serializer(self._result, error)  # pylint: disable=W0150
+
+    # Cursors:
+    def cursor(self, table: str, params: Union[dict, list] = None, **kwargs):  # pylint: disable=W0237
+        """
+        cursor
+            get all rows from a table, returning a Cursor.
+        -----
+        """
+        self._result = None
+        try:
+            if not filter:
+                cursor = self._engine.db(self._db).table(table)
+            else:
+                cursor = self._engine.db(self._db).table(table).filter(params)
+            return self.__cursor__(provider=self, sentence=cursor)
+        except ReqlResourceLimitError as err:
+            raise StatementError(f"Query Limit Error: {err!s}") from err
+        except ReqlOpIndeterminateError as err:
+            raise StatementError(f"Operation indeterminated: {err!s}") from err
+        except ReqlNonExistenceError as err:
+            raise DriverError(f"Object doesn't exist {table}: {err!s}") from err
+        except rethinkdb.errors.ReqlPermissionError as err:
+            raise DataError(f"Permission error over {table}: {err}") from err
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
+
+    async def distance(self, p1: Point, p2: Point, unit: str = "km", geo: str = "WGS84") -> float:
+        if not isinstance(p1, Point):
+            raise TypeError(f"Invalid type for Point 1: {type(p1)}")
+        if not isinstance(p2, Point):
+            raise TypeError(f"Invalid type for Point 2: {type(p2)}")
+        try:
+            point1 = p1.as_point()
+            point2 = p2.as_point()
+            return await self._engine.distance(point1, point2, unit=unit, geo_system=geo).run(self._connection)
+        except ReqlRuntimeError as err:
+            raise DriverError(f"Runtime Error: {err}") from err
+        except Exception as err:  # pylint: disable=W0703
+            raise DriverError(f"Unknown RT error: {err}") from err
```

## asyncdb/drivers/outputs/record.py

```diff
@@ -1,33 +1,33 @@
-"""
-Record.
-
-Returning a asyncdb Record row Format.
-"""
-import logging
-from asyncdb.meta import Record
-from .base import OutputFormat
-
-
-class recordFormat(OutputFormat):
-    """
-    Returns a List of Records from a Resultset
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        self._result = None
-        if error:
-            return (None, error)
-        try:
-            if isinstance(result, list):
-                _set = [Record.from_dict(row) for row in result]
-            elif hasattr(result, "one"):
-                if callable(result.one):
-                    _set = [Record.from_dict(row) for row in result]
-            else:
-                _set = Record.from_dict(result)
-            self._result = _set
-        except (TypeError, ValueError, AttributeError) as err:
-            logging.exception(f"Record Serialization Error: {err}", stack_info=True)
-            error = Exception(f"recordFormat Error: {err}")
-        finally:
-            return (self._result, error)
+"""
+Record.
+
+Returning a asyncdb Record row Format.
+"""
+import logging
+from ...meta import Record
+from .base import OutputFormat
+
+
+class recordFormat(OutputFormat):
+    """
+    Returns a List of Records from a Resultset
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        self._result = None
+        if error:
+            return (None, error)
+        try:
+            if isinstance(result, list):
+                _set = [Record.from_dict(row) for row in result]
+            elif hasattr(result, "one"):
+                if callable(result.one):
+                    _set = [Record.from_dict(row) for row in result]
+            else:
+                _set = Record.from_dict(result)
+            self._result = _set
+        except (TypeError, ValueError, AttributeError) as err:
+            logging.exception(f"Record Serialization Error: {err}", stack_info=True)
+            error = Exception(f"recordFormat Error: {err}")
+        finally:
+            return (self._result, error)
```

## asyncdb/drivers/outputs/json.py

```diff
@@ -1,16 +1,16 @@
-from asyncdb.utils.encoders import DefaultEncoder
-from .base import OutputFormat
-
-
-class jsonFormat(OutputFormat):
-    """
-    Most Basic Definition of Format.
-    """
-
-    _encoder = DefaultEncoder()
-
-    async def serialize(self, result, error, *args, **kwargs):
-        if error:
-            return (None, error)
-        dump = [dict(r) for r in result]
-        return (self._encoder.dumps(dump), error)
+from ...utils.encoders import DefaultEncoder
+from .base import OutputFormat
+
+
+class jsonFormat(OutputFormat):
+    """
+    Most Basic Definition of Format.
+    """
+
+    _encoder = DefaultEncoder()
+
+    async def serialize(self, result, error, *args, **kwargs):
+        if error:
+            return (None, error)
+        dump = [dict(r) for r in result]
+        return (self._encoder.dumps(dump), error)
```

## asyncdb/drivers/outputs/csv.py

 * *Ordering differences only*

```diff
@@ -1,28 +1,28 @@
-from io import StringIO
-import pandas
-from .base import OutputFormat
-
-
-class csvFormat(OutputFormat):
-    """
-    Returns a CSV string from a Resultset
-    TODO: migrate to aiocsv
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        df = None
-        try:
-            df = pandas.DataFrame(data=result, **kwargs)
-            csv_buffer = StringIO()
-            df.to_csv(csv_buffer)
-            self._result = csv_buffer.getvalue()
-        except pandas.errors.EmptyDataError as err:
-            error = Exception(f"Error with Empty Data: error: {err}")
-        except pandas.errors.ParserError as err:
-            error = Exception(f"Error parsing Data: error: {err}")
-        except ValueError as err:
-            error = Exception(f"Error Parsing a Column, error: {err}")
-        except Exception as err:
-            error = Exception(f"PandasFormat: Error on Data: error: {err}")
-        finally:
-            return (self._result, error)
+from io import StringIO
+import pandas
+from .base import OutputFormat
+
+
+class csvFormat(OutputFormat):
+    """
+    Returns a CSV string from a Resultset
+    TODO: migrate to aiocsv
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        df = None
+        try:
+            df = pandas.DataFrame(data=result, **kwargs)
+            csv_buffer = StringIO()
+            df.to_csv(csv_buffer)
+            self._result = csv_buffer.getvalue()
+        except pandas.errors.EmptyDataError as err:
+            error = Exception(f"Error with Empty Data: error: {err}")
+        except pandas.errors.ParserError as err:
+            error = Exception(f"Error parsing Data: error: {err}")
+        except ValueError as err:
+            error = Exception(f"Error Parsing a Column, error: {err}")
+        except Exception as err:
+            error = Exception(f"PandasFormat: Error on Data: error: {err}")
+        finally:
+            return (self._result, error)
```

## asyncdb/drivers/outputs/dataclass.py

 * *Ordering differences only*

```diff
@@ -1,26 +1,26 @@
-"""
-DataClass Format.
-
-Output format returning a list of Dataclasses based on Data.
-"""
-from dataclasses import make_dataclass
-from .base import OutputFormat
-
-
-class dataclassFormat(OutputFormat):
-    """
-    Most Basic Definition of Format.
-    """
-
-    def __init__(self, **kwargs):
-        self._model = None
-        if "model" in kwargs:
-            self._model = kwargs["model"]
-        else:
-            # TODO: making analysis of resultset:
-            pass
-            # cls = make_dataclass('Output', )
-
-    async def serialize(self, result, error, *args, **kwargs):
-        lsgen = [self._model(**dict(row)) for row in result]
-        return (lsgen, error)
+"""
+DataClass Format.
+
+Output format returning a list of Dataclasses based on Data.
+"""
+from dataclasses import make_dataclass
+from .base import OutputFormat
+
+
+class dataclassFormat(OutputFormat):
+    """
+    Most Basic Definition of Format.
+    """
+
+    def __init__(self, **kwargs):
+        self._model = None
+        if "model" in kwargs:
+            self._model = kwargs["model"]
+        else:
+            # TODO: making analysis of resultset:
+            pass
+            # cls = make_dataclass('Output', )
+
+    async def serialize(self, result, error, *args, **kwargs):
+        lsgen = [self._model(**dict(row)) for row in result]
+        return (lsgen, error)
```

## asyncdb/drivers/outputs/base.py

 * *Ordering differences only*

```diff
@@ -1,16 +1,16 @@
-from abc import ABC, abstractmethod
-
-
-class OutputFormat(ABC):
-    """
-    Abstract Interface for different output formats.
-    """
-
-    @abstractmethod
-    async def serialize(self, result, error, *args, **kwargs):
-        """
-        Making the serialization of data.
-        """
-
-    async def __call__(self, result, error, *args, **kwargs):
-        return await self.serialize(result, error, *args, **kwargs)
+from abc import ABC, abstractmethod
+
+
+class OutputFormat(ABC):
+    """
+    Abstract Interface for different output formats.
+    """
+
+    @abstractmethod
+    async def serialize(self, result, error, *args, **kwargs):
+        """
+        Making the serialization of data.
+        """
+
+    async def __call__(self, result, error, *args, **kwargs):
+        return await self.serialize(result, error, *args, **kwargs)
```

## asyncdb/drivers/outputs/generator.py

 * *Ordering differences only*

```diff
@@ -1,18 +1,18 @@
-"""
-Generator.
-
-Output format returning a list of dictionaries as a generator
-"""
-from .base import OutputFormat
-
-
-class genFormat(OutputFormat):
-    """
-    Most Basic Definition of Format.
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        if error:
-            return (None, error)
-        lsgen = (dict(row) for row in result)
-        return (lsgen, error)
+"""
+Generator.
+
+Output format returning a list of dictionaries as a generator
+"""
+from .base import OutputFormat
+
+
+class genFormat(OutputFormat):
+    """
+    Most Basic Definition of Format.
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        if error:
+            return (None, error)
+        lsgen = (dict(row) for row in result)
+        return (lsgen, error)
```

## asyncdb/drivers/outputs/recordset.py

```diff
@@ -1,26 +1,26 @@
-"""
-Recordset.
-
-Returning a asyncdb Recordset Result Format.
-"""
-import logging
-from asyncdb.meta import Recordset
-from .base import OutputFormat
-
-
-class recordsetFormat(OutputFormat):
-    """
-    Returns a List of Records from a Resultset
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        self._result = None
-        if error:
-            return (None, error)
-        try:
-            self._result = Recordset.from_result(result)
-        except (TypeError, ValueError, AttributeError) as err:
-            logging.exception(f"Recordset Serialization Error: {err}", stack_info=True)
-            error = Exception(f"recordsetFormat: Error on Data: error: {err}")
-        finally:
-            return (self._result, error)
+"""
+Recordset.
+
+Returning a asyncdb Recordset Result Format.
+"""
+import logging
+from ...meta import Recordset
+from .base import OutputFormat
+
+
+class recordsetFormat(OutputFormat):
+    """
+    Returns a List of Records from a Resultset
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        self._result = None
+        if error:
+            return (None, error)
+        try:
+            self._result = Recordset.from_result(result)
+        except (TypeError, ValueError, AttributeError) as err:
+            logging.exception(f"Recordset Serialization Error: {err}", stack_info=True)
+            error = Exception(f"recordsetFormat: Error on Data: error: {err}")
+        finally:
+            return (self._result, error)
```

## asyncdb/drivers/outputs/dt.py

 * *Ordering differences only*

```diff
@@ -1,26 +1,26 @@
-import logging
-import datatable as dt
-from .base import OutputFormat
-
-
-class dtFormat(OutputFormat):
-    """
-    Returns a Pandas Dataframe from a Resultset
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        df = None
-        if error:
-            return (None, error)
-        try:
-            data = [dict(row) for row in result]
-            df = dt.Frame(data, **kwargs)
-            self._result = df
-        except ValueError as err:
-            print(err)
-            error = Exception(f"Error Parsing a Column, error: {err}")
-        except Exception as err:
-            logging.exception(f"Datatable Serialization Error: {err}", stack_info=True)
-            error = Exception(f"dtFormat: Error on Data: error: {err}")
-        finally:
-            return (df, error)
+import logging
+import datatable as dt
+from .base import OutputFormat
+
+
+class dtFormat(OutputFormat):
+    """
+    Returns a Pandas Dataframe from a Resultset
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        df = None
+        if error:
+            return (None, error)
+        try:
+            data = [dict(row) for row in result]
+            df = dt.Frame(data, **kwargs)
+            self._result = df
+        except ValueError as err:
+            print(err)
+            error = Exception(f"Error Parsing a Column, error: {err}")
+        except Exception as err:
+            logging.exception(f"Datatable Serialization Error: {err}", stack_info=True)
+            error = Exception(f"dtFormat: Error on Data: error: {err}")
+        finally:
+            return (df, error)
```

## asyncdb/drivers/outputs/arrow.py

 * *Ordering differences only*

```diff
@@ -1,24 +1,24 @@
-import logging
-import pyarrow as pa
-from .base import OutputFormat
-
-
-class arrowFormat(OutputFormat):
-    """
-    Returns an Apache Arrow Table from a Resultset
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        table = None
-        try:
-            names = result[0].keys()
-            table = pa.Table.from_arrays(result, names=names, **kwargs)
-            self._result = table
-        except ValueError as err:
-            logging.error(f"Arrow Serialization Error: {err}")
-            error = Exception(f"arrowFormat: Error Parsing Column: {err}")
-        except Exception as err:
-            logging.exception(f"Arrow Serialization Error: {err}", stack_info=True)
-            error = Exception(f"arrowFormat: Error on Data: error: {err}")
-        finally:
-            return (table, error)
+import logging
+import pyarrow as pa
+from .base import OutputFormat
+
+
+class arrowFormat(OutputFormat):
+    """
+    Returns an Apache Arrow Table from a Resultset
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        table = None
+        try:
+            names = result[0].keys()
+            table = pa.Table.from_arrays(result, names=names, **kwargs)
+            self._result = table
+        except ValueError as err:
+            logging.error(f"Arrow Serialization Error: {err}")
+            error = Exception(f"arrowFormat: Error Parsing Column: {err}")
+        except Exception as err:
+            logging.exception(f"Arrow Serialization Error: {err}", stack_info=True)
+            error = Exception(f"arrowFormat: Error on Data: error: {err}")
+        finally:
+            return (table, error)
```

## asyncdb/drivers/outputs/iter.py

 * *Ordering differences only*

```diff
@@ -1,22 +1,22 @@
-"""
-Iterable.
-
-Output format returning a simple list of dictionaries.
-"""
-from .base import OutputFormat
-
-
-class iterFormat(OutputFormat):
-    """
-    Most Basic Definition of Format.
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        try:
-            if isinstance(result, list):
-                data = [dict(row) for row in result]
-            else:
-                data = dict(result)
-        except (ValueError, TypeError):
-            return (result, error)
-        return (data, error)
+"""
+Iterable.
+
+Output format returning a simple list of dictionaries.
+"""
+from .base import OutputFormat
+
+
+class iterFormat(OutputFormat):
+    """
+    Most Basic Definition of Format.
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        try:
+            if isinstance(result, list):
+                data = [dict(row) for row in result]
+            else:
+                data = dict(result)
+        except (ValueError, TypeError):
+            return (result, error)
+        return (data, error)
```

## asyncdb/drivers/outputs/__init__.py

 * *Ordering differences only*

```diff
@@ -1,14 +1,14 @@
-from .output import OutputFactory
-from .json import jsonFormat
-from .record import recordFormat
-from .recordset import recordsetFormat
-from .generator import genFormat
-from .iter import iterFormat
-
-__all__ = ["OutputFactory"]
-
-OutputFactory.register_format("json", jsonFormat)
-OutputFactory.register_format("record", recordFormat)
-OutputFactory.register_format("recordset", recordsetFormat)
-OutputFactory.register_format("generator", genFormat)
-OutputFactory.register_format("iterable", iterFormat)
+from .output import OutputFactory
+from .json import jsonFormat
+from .record import recordFormat
+from .recordset import recordsetFormat
+from .generator import genFormat
+from .iter import iterFormat
+
+__all__ = ["OutputFactory"]
+
+OutputFactory.register_format("json", jsonFormat)
+OutputFactory.register_format("record", recordFormat)
+OutputFactory.register_format("recordset", recordsetFormat)
+OutputFactory.register_format("generator", genFormat)
+OutputFactory.register_format("iterable", iterFormat)
```

## asyncdb/drivers/outputs/polars.py

 * *Ordering differences only*

```diff
@@ -1,26 +1,26 @@
-import logging
-import pandas
-import polars as polar
-from .base import OutputFormat
-
-
-class polarsFormat(OutputFormat):
-    """
-    Returns a PyPolars Dataframe from a Resultset
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        df = None
-        try:
-            result = [dict(row) for row in result]
-            a = pandas.DataFrame(data=result, **kwargs)
-            df = polar.from_pandas(a, **kwargs)
-            self._result = df
-        except ValueError as err:
-            print(err)
-            error = Exception(f"PolarFormat: Error Parsing Column: {err}")
-        except Exception as err:
-            logging.exception(f"Polars Serialization Error: {err}", stack_info=True)
-            error = Exception(f"PolarFormat: Error on Data: error: {err}")
-        finally:
-            return (df, error)
+import logging
+import pandas
+import polars as polar
+from .base import OutputFormat
+
+
+class polarsFormat(OutputFormat):
+    """
+    Returns a PyPolars Dataframe from a Resultset
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        df = None
+        try:
+            result = [dict(row) for row in result]
+            a = pandas.DataFrame(data=result, **kwargs)
+            df = polar.from_pandas(a, **kwargs)
+            self._result = df
+        except ValueError as err:
+            print(err)
+            error = Exception(f"PolarFormat: Error Parsing Column: {err}")
+        except Exception as err:
+            logging.exception(f"Polars Serialization Error: {err}", stack_info=True)
+            error = Exception(f"PolarFormat: Error on Data: error: {err}")
+        finally:
+            return (df, error)
```

## asyncdb/drivers/outputs/pandas.py

 * *Ordering differences only*

```diff
@@ -1,29 +1,29 @@
-import logging
-import pandas
-from .base import OutputFormat
-
-
-class pandasFormat(OutputFormat):
-    """
-    Returns a Pandas Dataframe from a Resultset
-    """
-
-    async def serialize(self, result, error, *args, **kwargs):
-        df = None
-        try:
-            result = [dict(row) for row in result]
-            df = pandas.DataFrame(data=result, **kwargs)
-            self._result = df
-        except pandas.errors.EmptyDataError as err:
-            error = Exception(f"Error with Empty Data: error: {err}")
-        except pandas.errors.ParserError as err:
-            logging.error(error)
-            error = Exception(f"Error parsing Data: error: {err}")
-        except ValueError as err:
-            logging.error(error)
-            error = Exception(f"Error Parsing a Column, error: {err}")
-        except Exception as err:
-            logging.error(error)
-            error = Exception(f"PandasFormat: Error on Data: error: {err}")
-        finally:
-            return (df, error)
+import logging
+import pandas
+from .base import OutputFormat
+
+
+class pandasFormat(OutputFormat):
+    """
+    Returns a Pandas Dataframe from a Resultset
+    """
+
+    async def serialize(self, result, error, *args, **kwargs):
+        df = None
+        try:
+            result = [dict(row) for row in result]
+            df = pandas.DataFrame(data=result, **kwargs)
+            self._result = df
+        except pandas.errors.EmptyDataError as err:
+            error = Exception(f"Error with Empty Data: error: {err}")
+        except pandas.errors.ParserError as err:
+            logging.error(error)
+            error = Exception(f"Error parsing Data: error: {err}")
+        except ValueError as err:
+            logging.error(error)
+            error = Exception(f"Error Parsing a Column, error: {err}")
+        except Exception as err:
+            logging.error(error)
+            error = Exception(f"PandasFormat: Error on Data: error: {err}")
+        finally:
+            return (df, error)
```

## asyncdb/drivers/outputs/output.py

 * *Ordering differences only*

```diff
@@ -1,28 +1,28 @@
-"""
-All Output formats supported by asyncdb.
-"""
-from importlib import import_module
-
-
-class OutputFactory(object):
-    _format: dict = {}
-
-    def __new__(cls, driver, frmt: str, *args, **kwargs):
-        if frmt is None or frmt == "native":
-            return driver.output
-        else:
-            if frmt not in cls._format:
-                try:
-                    # dynamically load format:
-                    module_name = f"{frmt}Format"
-                    classpath = f"asyncdb.drivers.outputs.{frmt}"
-                    mdl = import_module(classpath, package=frmt)
-                    obj = getattr(mdl, module_name)
-                    cls._format[frmt] = obj
-                except ImportError as e:
-                    raise RuntimeError(f"Error Loading Output Format {module_name}: {e}") from e
-            return cls._format[frmt](*args, **kwargs)
-
-    @classmethod
-    def register_format(cls, frmt, obj):
-        cls._format[frmt] = obj
+"""
+All Output formats supported by asyncdb.
+"""
+from importlib import import_module
+
+
+class OutputFactory(object):
+    _format: dict = {}
+
+    def __new__(cls, driver, frmt: str, *args, **kwargs):
+        if frmt is None or frmt == "native":
+            return driver.output
+        else:
+            if frmt not in cls._format:
+                try:
+                    # dynamically load format:
+                    module_name = f"{frmt}Format"
+                    classpath = f"asyncdb.drivers.outputs.{frmt}"
+                    mdl = import_module(classpath, package=frmt)
+                    obj = getattr(mdl, module_name)
+                    cls._format[frmt] = obj
+                except ImportError as e:
+                    raise RuntimeError(f"Error Loading Output Format {module_name}: {e}") from e
+            return cls._format[frmt](*args, **kwargs)
+
+    @classmethod
+    def register_format(cls, frmt, obj):
+        cls._format[frmt] = obj
```

## asyncdb/drivers/outputs/pyspark.py

 * *Ordering differences only*

```diff
@@ -1,37 +1,37 @@
-"""
-PySpark Dataframe.
-
-Output format returning a PySpark Dataframe
-"""
-from pyspark.sql import SparkSession, Row
-from .base import OutputFormat
-
-
-class pysparkFormat(OutputFormat):
-    """
-    Most Basic Definition of Format.
-    """
-
-    def __init__(self, **kwargs) -> None:
-        if "appName" in kwargs:
-            self._spark = SparkSession.builder.appName(kwargs["appName"]).getOrCreate()
-        else:
-            self._spark = SparkSession.builder.getOrCreate()
-        super(pysparkFormat, self).__init__()
-
-    async def serialize(self, result, error, *args, **kwargs):
-        if isinstance(result, list):
-            row = result[0]
-        else:
-            row = result
-        if not row:
-            raise ValueError(f"PySpark Format Error: invalid Resulset: {result!r}")
-        try:
-            columns = list(row.keys())
-            data = [tuple(v) for v in result]
-            # rdd = self._spark.sparkContext.parallelize(data)
-            df = self._spark.createDataFrame(data).toDF(*columns)
-            # df = rdd.toDF(columns)
-            return (df, error)
-        except (ValueError, TypeError) as e:
-            raise RuntimeError(f"PySpark Output Error: {e}") from e
+"""
+PySpark Dataframe.
+
+Output format returning a PySpark Dataframe
+"""
+from pyspark.sql import SparkSession, Row
+from .base import OutputFormat
+
+
+class pysparkFormat(OutputFormat):
+    """
+    Most Basic Definition of Format.
+    """
+
+    def __init__(self, **kwargs) -> None:
+        if "appName" in kwargs:
+            self._spark = SparkSession.builder.appName(kwargs["appName"]).getOrCreate()
+        else:
+            self._spark = SparkSession.builder.getOrCreate()
+        super(pysparkFormat, self).__init__()
+
+    async def serialize(self, result, error, *args, **kwargs):
+        if isinstance(result, list):
+            row = result[0]
+        else:
+            row = result
+        if not row:
+            raise ValueError(f"PySpark Format Error: invalid Resulset: {result!r}")
+        try:
+            columns = list(row.keys())
+            data = [tuple(v) for v in result]
+            # rdd = self._spark.sparkContext.parallelize(data)
+            df = self._spark.createDataFrame(data).toDF(*columns)
+            # df = rdd.toDF(columns)
+            return (df, error)
+        except (ValueError, TypeError) as e:
+            raise RuntimeError(f"PySpark Output Error: {e}") from e
```

## asyncdb/meta/record.py

 * *Ordering differences only*

```diff
@@ -1,110 +1,110 @@
-"""
-Record Object.
-
-Physical representation of a row in a class-based object.
-"""
-from collections.abc import MutableMapping, Iterator
-from typing import Any, Union
-
-
-class Record(MutableMapping):
-    """
-    Record.
-        Class for Record object
-    ----
-      params:
-          row: any resultset
-    """
-
-    __slots__ = ("_row", "_columns")
-
-    def __init__(self, row: Any, columns: list = None):
-        self._row = row
-        self._columns = columns
-
-    def result(self, key: Union[str, Any]) -> Any:
-        if self._row:
-            try:
-                return self._row[key]
-            except KeyError:
-                print(f"Error on key: {key}")
-                return None
-        else:
-            return None
-
-    def get_result(self):
-        return self._row
-
-    @classmethod
-    def from_dict(cls, row: dict) -> "Record":
-        return cls(row=row, columns=row.keys())
-        # keys, values = zip(*row.items())
-        # return cls(row = values, columns = [[name] for name in keys])
-
-    @property
-    def row(self) -> Any:
-        return self._row
-
-    def columns(self) -> list:
-        return self._columns
-
-    def items(self) -> zip:  # type: ignore
-        return zip(self._columns, self._row)
-
-    def keys(self) -> list:
-        return self._columns
-
-    ### Section: Simple magic methods
-    def __len__(self) -> int:
-        return len(self._row)
-
-    def __str__(self) -> str:
-        return " ".join(f"{key}={val!r}" for key, val in self._row.items())
-
-    def __repr__(self) -> str:
-        return f"<Record {self._row!r}>"
-
-    def __contains__(self, key: str) -> bool:
-        return key in self._columns
-
-    def __delitem__(self, key) -> None:
-        if self._row:
-            del self._row[key]
-
-    def __getitem__(self, key: Union[str, int]) -> Any:
-        """
-        Sequence-like operators
-        """
-        try:
-            return self._row[key]
-        except (KeyError, TypeError):
-            return False
-
-    def __setitem__(self, key: Union[str, Any], value: Any) -> None:
-        # optional processing here
-        self._row[key] = value
-        super(Record, self).__setitem__(key, value)
-
-    def __getattr__(self, attr: str) -> Any:
-        """
-        Attributes for dict keys
-        """
-        if self._row:
-            try:
-                return self._row[attr]
-            except KeyError as err:
-                raise KeyError(f"Record Error: invalid column name {attr} on {self._row!r}") from err
-            except TypeError as err:
-                raise TypeError(f"Record Error: invalid Result on {self._row!r} for {attr}") from err
-        else:
-            return False
-
-    def __setattr__(self, key: Union[str, int], value: Any) -> None:
-        try:
-            super(Record, self).__setattr__(key, value)
-        except AttributeError:
-            self._row[key] = value
-
-    def __iter__(self) -> Iterator:
-        for value in self._row:
-            yield value
+"""
+Record Object.
+
+Physical representation of a row in a class-based object.
+"""
+from collections.abc import MutableMapping, Iterator
+from typing import Any, Union
+
+
+class Record(MutableMapping):
+    """
+    Record.
+        Class for Record object
+    ----
+      params:
+          row: any resultset
+    """
+
+    __slots__ = ("_row", "_columns")
+
+    def __init__(self, row: Any, columns: list = None):
+        self._row = row
+        self._columns = columns
+
+    def result(self, key: Union[str, Any]) -> Any:
+        if self._row:
+            try:
+                return self._row[key]
+            except KeyError:
+                print(f"Error on key: {key}")
+                return None
+        else:
+            return None
+
+    def get_result(self):
+        return self._row
+
+    @classmethod
+    def from_dict(cls, row: dict) -> "Record":
+        return cls(row=row, columns=row.keys())
+        # keys, values = zip(*row.items())
+        # return cls(row = values, columns = [[name] for name in keys])
+
+    @property
+    def row(self) -> Any:
+        return self._row
+
+    def columns(self) -> list:
+        return self._columns
+
+    def items(self) -> zip:  # type: ignore
+        return zip(self._columns, self._row)
+
+    def keys(self) -> list:
+        return self._columns
+
+    ### Section: Simple magic methods
+    def __len__(self) -> int:
+        return len(self._row)
+
+    def __str__(self) -> str:
+        return " ".join(f"{key}={val!r}" for key, val in self._row.items())
+
+    def __repr__(self) -> str:
+        return f"<Record {self._row!r}>"
+
+    def __contains__(self, key: str) -> bool:
+        return key in self._columns
+
+    def __delitem__(self, key) -> None:
+        if self._row:
+            del self._row[key]
+
+    def __getitem__(self, key: Union[str, int]) -> Any:
+        """
+        Sequence-like operators
+        """
+        try:
+            return self._row[key]
+        except (KeyError, TypeError):
+            return False
+
+    def __setitem__(self, key: Union[str, Any], value: Any) -> None:
+        # optional processing here
+        self._row[key] = value
+        super(Record, self).__setitem__(key, value)
+
+    def __getattr__(self, attr: str) -> Any:
+        """
+        Attributes for dict keys
+        """
+        if self._row:
+            try:
+                return self._row[attr]
+            except KeyError as err:
+                raise KeyError(f"Record Error: invalid column name {attr} on {self._row!r}") from err
+            except TypeError as err:
+                raise TypeError(f"Record Error: invalid Result on {self._row!r} for {attr}") from err
+        else:
+            return False
+
+    def __setattr__(self, key: Union[str, int], value: Any) -> None:
+        try:
+            super(Record, self).__setattr__(key, value)
+        except AttributeError:
+            self._row[key] = value
+
+    def __iter__(self) -> Iterator:
+        for value in self._row:
+            yield value
```

## asyncdb/meta/recordset.py

 * *Ordering differences only*

```diff
@@ -1,77 +1,77 @@
-"""
-Recordset.
-
-Sequence of Records.
-"""
-from collections.abc import Sequence, Iterator
-from typing import Any, Union
-from .record import Record
-
-
-class Recordset(Sequence):
-    """
-    Recordset.
-         Class for a Resultset Object
-    ----
-      params:
-          result: any resultset
-    """
-
-    __slots__ = ("_idx", "_columns", "_result")
-
-    def __init__(self, result: Any, columns: list = None):
-        self._columns = columns
-        self._result = result
-        self._idx = 0
-
-    def get_result(self) -> Any:
-        return self._result
-
-    @classmethod
-    def from_result(cls, result: Iterator) -> "Recordset":
-        cols = []
-        try:
-            if hasattr(result, "one"):  # Cassandra Resulset
-                if callable(result.one):
-                    cols = result.one().keys
-                    result = list(result)
-            else:
-                cols = result[0].keys()
-            return cls(result, columns=cols)
-        except Exception as err:
-            raise ValueError(f"Recordset: Invalid data set {err}") from err
-
-    ### Section: Simple magic methods
-    def __getitem__(self, key: Union[int, str]):
-        if isinstance(key, int):
-            if key >= len(self._result):
-                raise IndexError("Recordset: Result Index out of Range")
-            return self._result[key]
-        elif isinstance(key, slice):
-            # works with slices
-            # print(key, key.start, key.stop)
-            return self._result[key]
-        else:
-            raise TypeError(f"Recordset: Invalid request {key!s}")
-
-    def __repr__(self) -> str:
-        return f"<Recordset {self._columns!r}>"
-
-    def __len__(self) -> int:
-        return len(self._result)
-
-    def __iter__(self):
-        return self
-
-    def __next__(self):
-        """
-        Next: next object from iterator
-        :returns: a Record object.
-        :raises StopIteration: when end is reached.
-        """
-        if self._idx < len(self._result):
-            row = self._result[self._idx]
-            self._idx += 1
-            return Record(row, self._columns)
-        # End of Iteration
-        raise StopIteration
+"""
+Recordset.
+
+Sequence of Records.
+"""
+from collections.abc import Sequence, Iterator
+from typing import Any, Union
+from .record import Record
+
+
+class Recordset(Sequence):
+    """
+    Recordset.
+         Class for a Resultset Object
+    ----
+      params:
+          result: any resultset
+    """
+
+    __slots__ = ("_idx", "_columns", "_result")
+
+    def __init__(self, result: Any, columns: list = None):
+        self._columns = columns
+        self._result = result
+        self._idx = 0
+
+    def get_result(self) -> Any:
+        return self._result
+
+    @classmethod
+    def from_result(cls, result: Iterator) -> "Recordset":
+        cols = []
+        try:
+            if hasattr(result, "one"):  # Cassandra Resulset
+                if callable(result.one):
+                    cols = result.one().keys
+                    result = list(result)
+            else:
+                cols = result[0].keys()
+            return cls(result, columns=cols)
+        except Exception as err:
+            raise ValueError(f"Recordset: Invalid data set {err}") from err
+
+    ### Section: Simple magic methods
+    def __getitem__(self, key: Union[int, str]):
+        if isinstance(key, int):
+            if key >= len(self._result):
+                raise IndexError("Recordset: Result Index out of Range")
+            return self._result[key]
+        elif isinstance(key, slice):
+            # works with slices
+            # print(key, key.start, key.stop)
+            return self._result[key]
+        else:
+            raise TypeError(f"Recordset: Invalid request {key!s}")
+
+    def __repr__(self) -> str:
+        return f"<Recordset {self._columns!r}>"
+
+    def __len__(self) -> int:
+        return len(self._result)
+
+    def __iter__(self):
+        return self
+
+    def __next__(self):
+        """
+        Next: next object from iterator
+        :returns: a Record object.
+        :raises StopIteration: when end is reached.
+        """
+        if self._idx < len(self._result):
+            row = self._result[self._idx]
+            self._idx += 1
+            return Record(row, self._columns)
+        # End of Iteration
+        raise StopIteration
```

## asyncdb/meta/__init__.py

 * *Ordering differences only*

```diff
@@ -1,10 +1,10 @@
-"""
-Meta Objects for records and recordset for AsyncDB.
-"""
-from .record import Record
-from .recordset import Recordset
-
-__all__ = [
-    "Record",
-    "Recordset",
-]
+"""
+Meta Objects for records and recordset for AsyncDB.
+"""
+from .record import Record
+from .recordset import Recordset
+
+__all__ = [
+    "Record",
+    "Recordset",
+]
```

## asyncdb/models/model.py

 * *Ordering differences only*

```diff
@@ -1,473 +1,473 @@
-"""
-Basic, Abstract Model.
-"""
-from __future__ import annotations
-
-import inspect
-import logging
-import traceback
-from collections.abc import Awaitable
-from dataclasses import _MISSING_TYPE, MISSING, is_dataclass, make_dataclass
-from numpy import int64
-from datamodel import BaseModel, Field
-from datamodel.base import Meta
-from datamodel.exceptions import ValidationError
-from datamodel.types import MODEL_TYPES, DB_TYPES
-
-from asyncdb.exceptions import ConnectionMissing, NoDataFound, DriverError, ModelError, StatementError
-from asyncdb.utils.modules import module_exists
-
-DB_TYPES[int64] = "bigint"
-
-
-def is_missing(value):
-    if value == _MISSING_TYPE:
-        return True
-    elif value == MISSING:
-        return True
-    elif isinstance(value, _MISSING_TYPE):
-        return True
-    else:
-        return False
-
-
-class Model(BaseModel):
-    """
-    Model.
-
-    DataModel representing connection to databases.
-    """
-
-    def set_connection(self, connection: Awaitable) -> None:
-        """
-        Manually Set the connection of Dataclass.
-        """
-        try:
-            self.Meta.connection = connection
-        except Exception as err:
-            raise ModelError(f"{err}") from err
-
-    def get_connection(self) -> Awaitable:
-        """get_connection.
-        Getting a database connection and driver based on parameters
-        """
-        if self.Meta.datasource:
-            # TODO: making a connection using a DataSource.
-            pass
-        elif self.Meta.driver:
-            driver = self.Meta.driver
-            provider = f"asyncdb.drivers.{driver}"
-            try:
-                obj = module_exists(driver, provider)
-            except Exception as err:
-                raise ModelError(f"{err}") from err
-            if self.Meta.dsn is not None:
-                try:
-                    self.Meta.connection = obj(dsn=self.Meta.dsn)
-                except DriverError:
-                    raise
-                except Exception as err:
-                    logging.exception(err)
-                    raise ModelError(f"{err}") from err
-            elif hasattr(self.Meta, "credentials"):
-                params = self.Meta.credentials
-                try:
-                    self.Meta.connection = obj(params=params)
-                except DriverError:
-                    raise
-                except Exception as err:
-                    logging.exception(err)
-                    raise ModelError(f"{err}") from err
-        return self.Meta.connection
-
-    ###  Magic Methods
-    async def __aenter__(self) -> BaseModel:
-        if not self.Meta.connection:
-            self.get_connection()
-        await self.Meta.connection.connection()
-        return self
-
-    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
-        # clean up anything you need to clean up
-        return await self.close()
-
-    async def close(self):
-        """
-        Closing an existing database connection.
-        """
-        try:
-            await self.Meta.connection.close()
-        except Exception as err:
-            logging.exception(err)
-            raise RuntimeError(f"{err}") from err
-
-    ### Instance method for Dataclasses.
-    async def insert(self, **kwargs):
-        """
-        Insert a new Dataclass Model to Database.
-        """
-        if not self.Meta.connection:
-            self.get_connection()
-        if not self.Meta.connection.is_connected():
-            await self.Meta.connection.connection()
-        result = None
-        try:
-            result = await self.Meta.connection._insert_(_model=self, **kwargs)
-            return result
-        except StatementError:
-            raise
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error on INSERT {self.Meta.name}: {err}") from err
-
-    async def update(self, **kwargs):
-        """
-        Saving a Dataclass Model to Database.
-        """
-        if not self.Meta.connection:
-            self.get_connection()
-        if not self.Meta.connection.is_connected():
-            await self.Meta.connection.connection()
-        result = None
-        try:
-            result = await self.Meta.connection._update_(_model=self, **kwargs)
-            return result
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error on UPDATE {self.Meta.name}: {err}") from err
-
-    async def delete(self, _filter: dict = None, **kwargs):
-        """
-        Deleting a row Model based on Primary Key
-        """
-        if not self.Meta.connection:
-            self.get_connection()
-        if not self.Meta.connection.is_connected():
-            await self.Meta.connection.connection()
-        result = None
-        try:
-            result = await self.Meta.connection._delete_(_model=self, _filter=_filter, **kwargs)
-            return result
-        except StatementError:
-            raise
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error on DELETE {self.Meta.name}: {err}") from err
-
-    async def save(self, **kwargs):
-        """
-        Saving a Dataclass Model to Database.
-        """
-        if not self.Meta.connection:
-            self.get_connection()
-        if not self.Meta.connection.is_connected():
-            await self.Meta.connection.connection()
-        result = None
-        try:
-            result = await self.Meta.connection._save_(_model=self, **kwargs)
-            return result
-        except StatementError:
-            raise
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error on DELETE {self.Meta.name}: {err}") from err
-
-    async def fetch(self, **kwargs):
-        """
-        Return a new single record based on filter criteria
-        """
-        if not self.Meta.connection:
-            self.get_connection()
-        if not self.Meta.connection.is_connected():
-            await self.Meta.connection.connection()
-        try:
-            result = await self.Meta.connection._fetch_(_model=self, **kwargs)
-            if result:
-                for f, val in result.items():
-                    setattr(self, f, val)
-                return self
-            else:
-                raise NoDataFound(f"{self.Meta.name}: Data Not found")
-        except ValidationError:
-            raise
-        except NoDataFound:
-            raise
-        except (AttributeError, StatementError) as err:
-            raise StatementError(f"Error on Attribute {self.Meta.name}: {err}") from err
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error on get {self.Meta.name}: {err}") from err
-
-    ### Class-based methods for Dataclasses.
-    @classmethod
-    async def create(cls, records: list):
-        if not cls.Meta.connection:
-            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
-        # working always with native format:
-        cls.Meta.connection.output_format("native")
-        try:
-            result = await cls.Meta.connection._create_(_model=cls, rows=records)
-            if result:
-                return result
-        except ValidationError:
-            raise
-        except (AttributeError, StatementError) as err:
-            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error Updating Table {cls.Meta.name}: {err}") from err
-
-    @classmethod
-    async def remove(cls, **kwargs):
-        if not cls.Meta.connection:
-            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
-        result = []
-        try:
-            result = await cls.Meta.connection._remove_(_model=cls, **kwargs)
-            return result
-        except (AttributeError, StatementError) as err:
-            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error Deleting Table {cls.Meta.name}: {err}") from err
-
-    @classmethod
-    async def updating(cls, *args, _filter: dict = None, **kwargs):
-        if not cls.Meta.connection:
-            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
-        try:
-            result = await cls.Meta.connection._updating_(_model=cls, _filter=_filter, *args, **kwargs)
-            if result:
-                return result
-            else:
-                return []
-        except (AttributeError, StatementError) as err:
-            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
-        except DriverError:
-            raise
-        except Exception as err:
-            print(traceback.format_exc())
-            raise ModelError(f"Error Updating Table {cls.Meta.name}: {err}") from err
-
-    @classmethod
-    async def deleting(cls, *args, _filter: dict = None, **kwargs):
-        if not cls.Meta.connection:
-            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
-        try:
-            result = await cls.Meta.connection._deleting_(_model=cls, _filter=_filter, *args, **kwargs)
-            if result:
-                return result
-            else:
-                return []
-        except (AttributeError, StatementError) as err:
-            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
-        except DriverError:
-            raise
-        except Exception as err:
-            print(traceback.format_exc())
-            raise ModelError(f"Error Updating Table {cls.Meta.name}: {err}") from err
-
-    @classmethod
-    async def select(cls, *args, **kwargs):
-        """Select.
-        passing a where condition directly to model.
-        :raises DriverError, Exception
-        """
-        if not cls.Meta.connection:
-            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
-        result = []
-        try:
-            result = await cls.Meta.connection._select_(_model=cls, *args, **kwargs)
-            if result:
-                cls.reset_values(cls)
-                return [cls(**dict(r)) for r in result]
-            else:
-                return []
-        except ValidationError:
-            raise
-        except NoDataFound:
-            raise
-        except (AttributeError, StatementError) as err:
-            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error on Select {cls.Meta.name}: {err}") from err
-
-    @classmethod
-    async def filter(cls, *args, **kwargs):
-        """
-        Need to return a ***collection*** of nested DataClasses
-        """
-        if not cls.Meta.connection:
-            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
-        result = []
-        try:
-            result = await cls.Meta.connection._filter_(_model=cls, *args, **kwargs)
-            if result:
-                cls.reset_values(cls)
-                return [cls(**dict(r)) for r in result]
-            else:
-                return []
-        except ValidationError:
-            raise
-        except NoDataFound:
-            raise
-        except (AttributeError, StatementError) as err:
-            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
-        except DriverError:
-            raise
-        except Exception as err:
-            logging.debug(traceback.format_exc())
-            raise ModelError(f"Error on filter {cls.Meta.name}: {err}") from err
-
-    @classmethod
-    async def get(cls, **kwargs):
-        """
-        Return a new single record based on filter criteria
-        """
-        if not cls.Meta.connection:
-            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
-        try:
-            result = await cls.Meta.connection._get_(_model=cls, **kwargs)
-            if result:
-                fields = cls.get_fields(cls)
-                result = {k: v for k, v in dict(result).items() if k in fields}
-                cls.reset_values(cls)
-                return cls(**result)
-            else:
-                raise NoDataFound(message=f"Data not found over {cls.Meta.name!s}")
-        except ValidationError:
-            raise
-        except NoDataFound as e:
-            raise NoDataFound(message=f"Data not found over {cls.Meta.name!s}") from e
-        except AttributeError as err:
-            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
-        except (StatementError, DriverError) as err:
-            raise DriverError(f"Error on get {cls.Meta.name}: {err}") from err
-        except Exception as err:
-            print(traceback.format_exc())
-            raise ModelError(f"Error on get {cls.Meta.name}: {err}") from err
-
-    # get all data of a model
-    @classmethod
-    async def all(cls, **kwargs):
-        if not cls.Meta.connection:
-            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
-        try:
-            result = await cls.Meta.connection._all_(_model=cls, **kwargs)
-            cls.reset_values(cls)
-            return [cls(**dict(row)) for row in result]
-        except ValidationError:
-            raise
-        except StatementError:
-            raise
-        except DriverError:
-            raise
-        except Exception as err:
-            print(traceback.format_exc())
-            raise ModelError(f"Error on query_all over table {cls.Meta.name}: {err}") from err
-
-    @classmethod
-    async def makeModel(
-        cls,
-        name: str,
-        schema: str = "public",
-        fields: list = None,
-        db: Awaitable = None,
-    ):
-        """
-        Make Model.
-
-        Making a model from field tuples, a JSON schema or a Table.
-        """
-        tablename = f"{schema}.{name}"
-        if not fields:  # we need to look in to it.
-            colinfo = await db.column_info(tablename)
-            fields = []
-            for column in colinfo:
-                tp = column["type"]
-                col = Field(
-                    primary_key=column["is_primary"],
-                    notnull=column["notnull"],
-                    db_type=column["format_type"],
-                )
-                # get dtype from database type:
-                try:
-                    dtype = MODEL_TYPES[tp]
-                except KeyError:
-                    dtype = str
-                fields.append((column["name"], dtype, col))
-        parent = inspect.getmro(cls)
-        obj = make_dataclass(name, fields, bases=(parent[0],))
-        m = Meta()
-        m.name = name
-        m.schema = schema
-        m.app_label = schema
-        m.connection = db
-        m.frozen = False
-        obj.Meta = m
-        return obj
-
-    @classmethod
-    def model(cls, dialect: str = "sql") -> str:
-        clsname = cls.__name__
-        schema = cls.Meta.schema
-        table = cls.Meta.name if cls.Meta.name else clsname.lower()
-        columns = cls.columns(cls).items()
-        if dialect == "sql" or dialect == "SQL":
-            # TODO: using lexers to different types of SQL
-            # re-direct creation to backend driver.
-            # And db_types to translate dataclass types to DB types.
-            doc = f"CREATE TABLE IF NOT EXISTS {schema}.{table} (\n"
-            cols = []
-            pk = []
-            for _, field in columns:
-                # print(type(field), field)
-                key = field.name
-                default = None
-                try:
-                    default = field.metadata["db_default"]
-                except KeyError:
-                    if field.default is not None:
-                        default = f"{field.default!r}"
-                default = f"DEFAULT {default!s}" if isinstance(default, (str, int)) else ""
-                if is_dataclass(field.type):
-                    tp = "jsonb"
-                    nn = ""
-                else:
-                    try:
-                        tp = field.db_type()
-                    except (TypeError, ValueError, AttributeError):
-                        # print(err)
-                        tp = "varchar"
-                    nn = "NOT NULL" if field.required() is True else ""
-                if hasattr(field, "primary_key"):
-                    if field.primary_key is True:
-                        pk.append(key)
-                # print(key, tp, nn, default)
-                cols.append(f" {key} {tp} {nn} {default}")
-            doc = "{}{}".format(doc, ",\n".join(cols))
-            if len(pk) >= 1:
-                primary = ", ".join(pk)
-                cname = f"pk_{schema}_{table}_pkey"
-                doc = "{},\n{}".format(doc, f"CONSTRAINT {cname} PRIMARY KEY ({primary})")
-            doc = doc + "\n);"
-            return doc
-        else:
-            return super(Model, cls).model(dialect)
+"""
+Basic, Abstract Model.
+"""
+from __future__ import annotations
+
+import inspect
+import logging
+import traceback
+from collections.abc import Awaitable
+from dataclasses import _MISSING_TYPE, MISSING, is_dataclass, make_dataclass
+from numpy import int64
+from datamodel import BaseModel, Field
+from datamodel.base import Meta
+from datamodel.exceptions import ValidationError
+from datamodel.types import MODEL_TYPES, DB_TYPES
+
+from asyncdb.exceptions import ConnectionMissing, NoDataFound, DriverError, ModelError, StatementError
+from asyncdb.utils.modules import module_exists
+
+DB_TYPES[int64] = "bigint"
+
+
+def is_missing(value):
+    if value == _MISSING_TYPE:
+        return True
+    elif value == MISSING:
+        return True
+    elif isinstance(value, _MISSING_TYPE):
+        return True
+    else:
+        return False
+
+
+class Model(BaseModel):
+    """
+    Model.
+
+    DataModel representing connection to databases.
+    """
+
+    def set_connection(self, connection: Awaitable) -> None:
+        """
+        Manually Set the connection of Dataclass.
+        """
+        try:
+            self.Meta.connection = connection
+        except Exception as err:
+            raise ModelError(f"{err}") from err
+
+    def get_connection(self) -> Awaitable:
+        """get_connection.
+        Getting a database connection and driver based on parameters
+        """
+        if self.Meta.datasource:
+            # TODO: making a connection using a DataSource.
+            pass
+        elif self.Meta.driver:
+            driver = self.Meta.driver
+            provider = f"asyncdb.drivers.{driver}"
+            try:
+                obj = module_exists(driver, provider)
+            except Exception as err:
+                raise ModelError(f"{err}") from err
+            if self.Meta.dsn is not None:
+                try:
+                    self.Meta.connection = obj(dsn=self.Meta.dsn)
+                except DriverError:
+                    raise
+                except Exception as err:
+                    logging.exception(err)
+                    raise ModelError(f"{err}") from err
+            elif hasattr(self.Meta, "credentials"):
+                params = self.Meta.credentials
+                try:
+                    self.Meta.connection = obj(params=params)
+                except DriverError:
+                    raise
+                except Exception as err:
+                    logging.exception(err)
+                    raise ModelError(f"{err}") from err
+        return self.Meta.connection
+
+    ###  Magic Methods
+    async def __aenter__(self) -> BaseModel:
+        if not self.Meta.connection:
+            self.get_connection()
+        await self.Meta.connection.connection()
+        return self
+
+    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
+        # clean up anything you need to clean up
+        return await self.close()
+
+    async def close(self):
+        """
+        Closing an existing database connection.
+        """
+        try:
+            await self.Meta.connection.close()
+        except Exception as err:
+            logging.exception(err)
+            raise RuntimeError(f"{err}") from err
+
+    ### Instance method for Dataclasses.
+    async def insert(self, **kwargs):
+        """
+        Insert a new Dataclass Model to Database.
+        """
+        if not self.Meta.connection:
+            self.get_connection()
+        if not self.Meta.connection.is_connected():
+            await self.Meta.connection.connection()
+        result = None
+        try:
+            result = await self.Meta.connection._insert_(_model=self, **kwargs)
+            return result
+        except StatementError:
+            raise
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error on INSERT {self.Meta.name}: {err}") from err
+
+    async def update(self, **kwargs):
+        """
+        Saving a Dataclass Model to Database.
+        """
+        if not self.Meta.connection:
+            self.get_connection()
+        if not self.Meta.connection.is_connected():
+            await self.Meta.connection.connection()
+        result = None
+        try:
+            result = await self.Meta.connection._update_(_model=self, **kwargs)
+            return result
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error on UPDATE {self.Meta.name}: {err}") from err
+
+    async def delete(self, _filter: dict = None, **kwargs):
+        """
+        Deleting a row Model based on Primary Key
+        """
+        if not self.Meta.connection:
+            self.get_connection()
+        if not self.Meta.connection.is_connected():
+            await self.Meta.connection.connection()
+        result = None
+        try:
+            result = await self.Meta.connection._delete_(_model=self, _filter=_filter, **kwargs)
+            return result
+        except StatementError:
+            raise
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error on DELETE {self.Meta.name}: {err}") from err
+
+    async def save(self, **kwargs):
+        """
+        Saving a Dataclass Model to Database.
+        """
+        if not self.Meta.connection:
+            self.get_connection()
+        if not self.Meta.connection.is_connected():
+            await self.Meta.connection.connection()
+        result = None
+        try:
+            result = await self.Meta.connection._save_(_model=self, **kwargs)
+            return result
+        except StatementError:
+            raise
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error on DELETE {self.Meta.name}: {err}") from err
+
+    async def fetch(self, **kwargs):
+        """
+        Return a new single record based on filter criteria
+        """
+        if not self.Meta.connection:
+            self.get_connection()
+        if not self.Meta.connection.is_connected():
+            await self.Meta.connection.connection()
+        try:
+            result = await self.Meta.connection._fetch_(_model=self, **kwargs)
+            if result:
+                for f, val in result.items():
+                    setattr(self, f, val)
+                return self
+            else:
+                raise NoDataFound(f"{self.Meta.name}: Data Not found")
+        except ValidationError:
+            raise
+        except NoDataFound:
+            raise
+        except (AttributeError, StatementError) as err:
+            raise StatementError(f"Error on Attribute {self.Meta.name}: {err}") from err
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error on get {self.Meta.name}: {err}") from err
+
+    ### Class-based methods for Dataclasses.
+    @classmethod
+    async def create(cls, records: list):
+        if not cls.Meta.connection:
+            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
+        # working always with native format:
+        cls.Meta.connection.output_format("native")
+        try:
+            result = await cls.Meta.connection._create_(_model=cls, rows=records)
+            if result:
+                return result
+        except ValidationError:
+            raise
+        except (AttributeError, StatementError) as err:
+            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error Updating Table {cls.Meta.name}: {err}") from err
+
+    @classmethod
+    async def remove(cls, **kwargs):
+        if not cls.Meta.connection:
+            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
+        result = []
+        try:
+            result = await cls.Meta.connection._remove_(_model=cls, **kwargs)
+            return result
+        except (AttributeError, StatementError) as err:
+            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error Deleting Table {cls.Meta.name}: {err}") from err
+
+    @classmethod
+    async def updating(cls, *args, _filter: dict = None, **kwargs):
+        if not cls.Meta.connection:
+            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
+        try:
+            result = await cls.Meta.connection._updating_(_model=cls, _filter=_filter, *args, **kwargs)
+            if result:
+                return result
+            else:
+                return []
+        except (AttributeError, StatementError) as err:
+            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
+        except DriverError:
+            raise
+        except Exception as err:
+            print(traceback.format_exc())
+            raise ModelError(f"Error Updating Table {cls.Meta.name}: {err}") from err
+
+    @classmethod
+    async def deleting(cls, *args, _filter: dict = None, **kwargs):
+        if not cls.Meta.connection:
+            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
+        try:
+            result = await cls.Meta.connection._deleting_(_model=cls, _filter=_filter, *args, **kwargs)
+            if result:
+                return result
+            else:
+                return []
+        except (AttributeError, StatementError) as err:
+            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
+        except DriverError:
+            raise
+        except Exception as err:
+            print(traceback.format_exc())
+            raise ModelError(f"Error Updating Table {cls.Meta.name}: {err}") from err
+
+    @classmethod
+    async def select(cls, *args, **kwargs):
+        """Select.
+        passing a where condition directly to model.
+        :raises DriverError, Exception
+        """
+        if not cls.Meta.connection:
+            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
+        result = []
+        try:
+            result = await cls.Meta.connection._select_(_model=cls, *args, **kwargs)
+            if result:
+                cls.reset_values(cls)
+                return [cls(**dict(r)) for r in result]
+            else:
+                return []
+        except ValidationError:
+            raise
+        except NoDataFound:
+            raise
+        except (AttributeError, StatementError) as err:
+            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error on Select {cls.Meta.name}: {err}") from err
+
+    @classmethod
+    async def filter(cls, *args, **kwargs):
+        """
+        Need to return a ***collection*** of nested DataClasses
+        """
+        if not cls.Meta.connection:
+            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
+        result = []
+        try:
+            result = await cls.Meta.connection._filter_(_model=cls, *args, **kwargs)
+            if result:
+                cls.reset_values(cls)
+                return [cls(**dict(r)) for r in result]
+            else:
+                return []
+        except ValidationError:
+            raise
+        except NoDataFound:
+            raise
+        except (AttributeError, StatementError) as err:
+            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
+        except DriverError:
+            raise
+        except Exception as err:
+            logging.debug(traceback.format_exc())
+            raise ModelError(f"Error on filter {cls.Meta.name}: {err}") from err
+
+    @classmethod
+    async def get(cls, **kwargs):
+        """
+        Return a new single record based on filter criteria
+        """
+        if not cls.Meta.connection:
+            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
+        try:
+            result = await cls.Meta.connection._get_(_model=cls, **kwargs)
+            if result:
+                fields = cls.get_fields(cls)
+                result = {k: v for k, v in dict(result).items() if k in fields}
+                cls.reset_values(cls)
+                return cls(**result)
+            else:
+                raise NoDataFound(message=f"Data not found over {cls.Meta.name!s}")
+        except ValidationError:
+            raise
+        except NoDataFound as e:
+            raise NoDataFound(message=f"Data not found over {cls.Meta.name!s}") from e
+        except AttributeError as err:
+            raise StatementError(f"Error on Attribute {cls.Meta.name}: {err}") from err
+        except (StatementError, DriverError) as err:
+            raise DriverError(f"Error on get {cls.Meta.name}: {err}") from err
+        except Exception as err:
+            print(traceback.format_exc())
+            raise ModelError(f"Error on get {cls.Meta.name}: {err}") from err
+
+    # get all data of a model
+    @classmethod
+    async def all(cls, **kwargs):
+        if not cls.Meta.connection:
+            raise ConnectionMissing(f"Missing Connection for Model: {cls}")
+        try:
+            result = await cls.Meta.connection._all_(_model=cls, **kwargs)
+            cls.reset_values(cls)
+            return [cls(**dict(row)) for row in result]
+        except ValidationError:
+            raise
+        except StatementError:
+            raise
+        except DriverError:
+            raise
+        except Exception as err:
+            print(traceback.format_exc())
+            raise ModelError(f"Error on query_all over table {cls.Meta.name}: {err}") from err
+
+    @classmethod
+    async def makeModel(
+        cls,
+        name: str,
+        schema: str = "public",
+        fields: list = None,
+        db: Awaitable = None,
+    ):
+        """
+        Make Model.
+
+        Making a model from field tuples, a JSON schema or a Table.
+        """
+        tablename = f"{schema}.{name}"
+        if not fields:  # we need to look in to it.
+            colinfo = await db.column_info(tablename)
+            fields = []
+            for column in colinfo:
+                tp = column["type"]
+                col = Field(
+                    primary_key=column["is_primary"],
+                    notnull=column["notnull"],
+                    db_type=column["format_type"],
+                )
+                # get dtype from database type:
+                try:
+                    dtype = MODEL_TYPES[tp]
+                except KeyError:
+                    dtype = str
+                fields.append((column["name"], dtype, col))
+        parent = inspect.getmro(cls)
+        obj = make_dataclass(name, fields, bases=(parent[0],))
+        m = Meta()
+        m.name = name
+        m.schema = schema
+        m.app_label = schema
+        m.connection = db
+        m.frozen = False
+        obj.Meta = m
+        return obj
+
+    @classmethod
+    def model(cls, dialect: str = "sql") -> str:
+        clsname = cls.__name__
+        schema = cls.Meta.schema
+        table = cls.Meta.name if cls.Meta.name else clsname.lower()
+        columns = cls.columns(cls).items()
+        if dialect == "sql" or dialect == "SQL":
+            # TODO: using lexers to different types of SQL
+            # re-direct creation to backend driver.
+            # And db_types to translate dataclass types to DB types.
+            doc = f"CREATE TABLE IF NOT EXISTS {schema}.{table} (\n"
+            cols = []
+            pk = []
+            for _, field in columns:
+                # print(type(field), field)
+                key = field.name
+                default = None
+                try:
+                    default = field.metadata["db_default"]
+                except KeyError:
+                    if field.default is not None:
+                        default = f"{field.default!r}"
+                default = f"DEFAULT {default!s}" if isinstance(default, (str, int)) else ""
+                if is_dataclass(field.type):
+                    tp = "jsonb"
+                    nn = ""
+                else:
+                    try:
+                        tp = field.db_type()
+                    except (TypeError, ValueError, AttributeError):
+                        # print(err)
+                        tp = "varchar"
+                    nn = "NOT NULL" if field.required() is True else ""
+                if hasattr(field, "primary_key"):
+                    if field.primary_key is True:
+                        pk.append(key)
+                # print(key, tp, nn, default)
+                cols.append(f" {key} {tp} {nn} {default}")
+            doc = "{}{}".format(doc, ",\n".join(cols))
+            if len(pk) >= 1:
+                primary = ", ".join(pk)
+                cname = f"pk_{schema}_{table}_pkey"
+                doc = "{},\n{}".format(doc, f"CONSTRAINT {cname} PRIMARY KEY ({primary})")
+            doc = doc + "\n);"
+            return doc
+        else:
+            return super(Model, cls).model(dialect)
```

## asyncdb/models/__init__.py

 * *Ordering differences only*

```diff
@@ -1,15 +1,15 @@
-"""
-AsyncDB Models.
-
-AsyncDB Models is a simple library to use Dataclass-syntax for interacting with
-Databases, using the same syntax of Dataclass, users can write Python Objects
-and work with Data in the same way, no matter which is the DB Backend.
-
-AsyncDB Models are based on python Dataclasses and type annotations.
-"""
-from dataclasses import is_dataclass
-from datamodel import Field, Column
-from .model import Model, is_missing, DB_TYPES
-
-
-__all__ = ("Field", "Column", "Model", "is_dataclass", "is_missing", "DB_TYPES")
+"""
+AsyncDB Models.
+
+AsyncDB Models is a simple library to use Dataclass-syntax for interacting with
+Databases, using the same syntax of Dataclass, users can write Python Objects
+and work with Data in the same way, no matter which is the DB Backend.
+
+AsyncDB Models are based on python Dataclasses and type annotations.
+"""
+from dataclasses import is_dataclass
+from datamodel import Field, Column
+from .model import Model, is_missing, DB_TYPES
+
+
+__all__ = ("Field", "Column", "Model", "is_dataclass", "is_missing", "DB_TYPES")
```

## asyncdb/exceptions/handlers.py

```diff
@@ -1,72 +1,64 @@
-from typing import Any
-import asyncio
-import logging
-import uvloop
-
-
-asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
-uvloop.install()
-
-
-def handle_done_tasks(task: asyncio.Task, logger: logging.Logger, *args: tuple[Any, ...]) -> None:
-    try:
-        return task.result()
-    except asyncio.CancelledError:
-        return True  # Task cancellation should not be logged as an error.
-    except Exception as err:  # pylint: disable=broad-except
-        logger.exception(f"Exception raised by Task {task}, error: {err}", *args)
-        return None
-
-
-async def shutdown(loop: asyncio.AbstractEventLoop, signal=None):
-    """Cleanup tasks tied to the service's shutdown."""
-    if signal:
-        logging.info(f"Received exit signal {signal.name}...")
-    else:
-        logging.warning("Shutting NOT via signal")
-    logging.info("Closing all connections")
-    try:
-        tasks = [
-            task.cancel() for task in asyncio.all_tasks() if task is not asyncio.current_task() and not task.done()
-        ]
-        status = [task.cancel() for task in tasks]
-        logging.warning(f"Cancelling {len(tasks)} outstanding tasks: {status}")
-        await asyncio.gather(*tasks, return_exceptions=True)
-        logging.warning("Asyncio Shutdown: Done graceful shutdown of subtasks")
-    except asyncio.CancelledError:
-        pass
-    except Exception as ex:
-        logging.exception(ex, stack_info=True)
-        raise RuntimeError(f"Asyncio Shutdown Error: {ex}") from ex
-    finally:
-        loop.close()
-
-
-def default_exception_handler(loop: asyncio.AbstractEventLoop, context):
-    logging.debug(f"Asyncio Exception Handler Caught: {context!s}")
-    # first, handle with default handler
-    if isinstance(context, Exception):
-        # is a basic exception
-        logging.exception(f"Exception {context!s}", stack_info=True)
-        raise type(context)
-    exception = context.get("exception")
-    msg = context.get("message", None)
-    loop.default_exception_handler(context)
-    if exception:
-        logging.error(f"AsyncDB: Caught exception: {exception}")
-        if not isinstance(exception, asyncio.CancelledError):
-            task = context.get("task", context["future"])
-            exc = type(task.exception())
-            try:
-                logging.error(f"{exc.__name__!s}: *{msg}* over task {task}")
-            except Exception as ex:
-                logging.exception(ex, stack_info=True)
-                raise RuntimeError(f"Handler Error: {ex}") from ex
-    else:
-        logging.error(f"AsyncDB: Caught an error: {context}")
-        try:
-            task = context.get("task", context["future"])
-        except KeyError:
-            task = None
-        logging.exception(f"Exception raised by Task {task}, Error: {msg}")
-        raise RuntimeError(f"{msg}: task: {task}")
+from typing import Any
+import asyncio
+import logging
+
+def handle_done_tasks(task: asyncio.Task, logger: logging.Logger, *args: tuple[Any, ...]) -> None:
+    try:
+        return task.result()
+    except asyncio.CancelledError:
+        return True  # Task cancellation should not be logged as an error.
+    except Exception as err:  # pylint: disable=broad-except
+        logger.exception(
+            f"Exception raised by Task {task}, error: {err}"
+        )
+        return None
+
+
+async def shutdown(loop: asyncio.AbstractEventLoop, signal=None):
+    """Cleanup tasks tied to the service's shutdown."""
+    if signal:
+        logging.info(f"Received exit signal {signal.name}...")
+    else:
+        logging.warning("Shutting NOT via signal")
+    logging.info("Closing all connections")
+    try:
+        tasks = [
+            task.cancel() for task in asyncio.all_tasks() if task is not asyncio.current_task() and not task.done()
+        ]
+        status = [task.cancel() for task in tasks]
+        logging.warning(f"Cancelling {len(tasks)} outstanding tasks: {status}")
+        await asyncio.gather(*tasks, return_exceptions=True)
+        logging.warning("Asyncio Shutdown: Done graceful shutdown of subtasks")
+    except asyncio.CancelledError:
+        pass
+    except Exception as ex:
+        logging.exception(ex, stack_info=True)
+        raise RuntimeError(f"Asyncio Shutdown Error: {ex}") from ex
+    finally:
+        loop.close()
+
+
+def default_exception_handler(loop: asyncio.AbstractEventLoop, context):
+    logging.debug(f"Asyncio Exception Handler Caught: {context!s}")
+
+    exception = context.get("exception")
+    msg = context.get("message", "")
+    task = context.get("task") or context.get("future")
+
+    # Call the default exception handler
+    loop.default_exception_handler(context)
+
+    if exception:
+        logging.error(f"AsyncDB: Caught exception: {exception}")
+        if not isinstance(exception, asyncio.CancelledError):
+            try:
+                exc_name = type(exception).__name__
+                logging.error(f"{exc_name}: *{msg}* over task {task}")
+            except Exception as ex:
+                logging.exception("Handler Error", exc_info=True)
+                raise RuntimeError(f"Handler Error: {ex}") from ex
+    else:
+        logging.error(f"AsyncDB: Caught an error: {context}")
+        if task:
+            logging.exception(f"Exception raised by Task {task}, Error: {msg}")
+        raise RuntimeError(f"{msg}: task: {task}")
```

## asyncdb/exceptions/__init__.py

 * *Ordering differences only*

```diff
@@ -1,40 +1,40 @@
-"""Exception Handler for AsyncDB.
-"""
-from .exceptions import (
-    ProviderError,
-    DriverError,
-    DataError,
-    NotSupported,
-    UninitializedError,
-    ConnectionTimeout,
-    ConnectionMissing,
-    NoDataFound,
-    TooManyConnections,
-    EmptyStatement,
-    UnknownPropertyError,
-    StatementError,
-    ConditionsError,
-    ModelError,
-)
-from .handlers import default_exception_handler, handle_done_tasks, shutdown
-
-
-__all__ = (
-    "default_exception_handler",
-    "handle_done_tasks",
-    "shutdown",
-    "ProviderError",
-    "DriverError",
-    "DataError",
-    "NotSupported",
-    "UninitializedError",
-    "ConnectionTimeout",
-    "ConnectionMissing",
-    "NoDataFound",
-    "TooManyConnections",
-    "EmptyStatement",
-    "UnknownPropertyError",
-    "StatementError",
-    "ConditionsError",
-    "ModelError",
-)
+"""Exception Handler for AsyncDB.
+"""
+from .exceptions import (
+    ProviderError,
+    DriverError,
+    DataError,
+    NotSupported,
+    UninitializedError,
+    ConnectionTimeout,
+    ConnectionMissing,
+    NoDataFound,
+    TooManyConnections,
+    EmptyStatement,
+    UnknownPropertyError,
+    StatementError,
+    ConditionsError,
+    ModelError,
+)
+from .handlers import default_exception_handler, handle_done_tasks, shutdown
+
+
+__all__ = (
+    "default_exception_handler",
+    "handle_done_tasks",
+    "shutdown",
+    "ProviderError",
+    "DriverError",
+    "DataError",
+    "NotSupported",
+    "UninitializedError",
+    "ConnectionTimeout",
+    "ConnectionMissing",
+    "NoDataFound",
+    "TooManyConnections",
+    "EmptyStatement",
+    "UnknownPropertyError",
+    "StatementError",
+    "ConditionsError",
+    "ModelError",
+)
```

## asyncdb/utils/modules.py

 * *Ordering differences only*

```diff
@@ -1,19 +1,19 @@
-import logging
-from importlib import import_module
-
-
-### Module Loading
-def module_exists(module_name, classpath):
-    try:
-        # try to using importlib
-        module = import_module(classpath, package="providers")
-        obj = getattr(module, module_name)
-        return obj
-    except ImportError:
-        try:
-            # try to using __import__
-            obj = __import__(classpath, fromlist=[module_name])
-            return obj
-        except ImportError as e:
-            logging.exception(f"No Driver for provider {module_name} was found: {e}")
-            raise ImportError(f"No Provider {module_name} Found") from e
+import logging
+from importlib import import_module
+
+
+### Module Loading
+def module_exists(module_name, classpath):
+    try:
+        # try to using importlib
+        module = import_module(classpath, package="providers")
+        obj = getattr(module, module_name)
+        return obj
+    except ImportError:
+        try:
+            # try to using __import__
+            obj = __import__(classpath, fromlist=[module_name])
+            return obj
+        except ImportError as e:
+            logging.exception(f"No Driver for provider {module_name} was found: {e}")
+            raise ImportError(f"No Provider {module_name} Found") from e
```

## asyncdb/utils/__init__.py

 * *Ordering differences only*

```diff
@@ -1,8 +1,8 @@
-from .functions import Msg, cPrint
-from .uv import install_uvloop
-
-__all__ = (
-    "Msg",
-    "cPrint",
-    "install_uvloop",
-)
+from .functions import Msg, cPrint
+from .uv import install_uvloop
+
+__all__ = (
+    "Msg",
+    "cPrint",
+    "install_uvloop",
+)
```

## asyncdb/utils/uv.py

```diff
@@ -1,12 +1,11 @@
-import asyncio
-
-
-def install_uvloop():
-    """install uvloop and set as default loop for asyncio."""
-    try:
-        import uvloop
-
-        asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
-        uvloop.install()
-    except ImportError:
-        pass
+import asyncio
+
+
+def install_uvloop():
+    """install uvloop and set as default loop for asyncio."""
+    try:
+        import uvloop  # noqa # pylint: disable=import-outside-toplevel
+        asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
+        uvloop.install()
+    except ImportError:
+        pass
```

## asyncdb/utils/functions.py

```diff
@@ -1,82 +1,85 @@
-""" asyncDB utils.
-Various functions for asyncdb
-"""
-
-
-class colors:
-    """
-    Colors class.
-
-       reset all colors with colors.reset;
-       Use as colors.subclass.colorname.
-    i.e. colors.fg.red or colors.fg.greenalso, the generic bold, disable,
-    underline, reverse, strike through,
-    and invisible work with the main class i.e. colors.bold
-    """
-
-    reset = "\033[0m"
-    bold = "\033[01m"
-    disable = "\033[02m"
-    underline = "\033[04m"
-    reverse = "\033[07m"
-    strikethrough = "\033[09m"
-    invisible = "\033[08m"
-
-    class fg:
-        """
-        colors.fg.
-
-        Foreground Color subClass
-        """
-
-        black = "\033[30m"
-        red = "\033[31m"
-        green = "\033[32m"
-        orange = "\033[33m"
-        blue = "\033[34m"
-        purple = "\033[35m"
-        cyan = "\033[36m"
-        lightgrey = "\033[37m"
-        darkgrey = "\033[90m"
-        lightred = "\033[91m"
-        lightgreen = "\033[92m"
-        yellow = "\033[93m"
-        lightyellow = "\033[93;1m"
-        lightblue = "\033[94m"
-        pink = "\033[95m"
-        lightcyan = "\033[96m"
-
-
-class cPrint(object):
-    def __init__(self, message: str = "", level: str = "INFO"):
-        if level == "INFO" or level == "info":
-            coloring = colors.bold + colors.fg.green
-        elif level == "DEBUG" or level == "debug":
-            coloring = colors.fg.lightblue
-        elif level == "WARN" or level == "warning":
-            coloring = colors.bold + colors.fg.yellow
-        elif level == "ERROR":
-            coloring = colors.fg.lightred
-        elif level == "CRITICAL":
-            coloring = colors.bold + colors.fg.red
-        else:
-            coloring = colors.reset
-        print(coloring + message, colors.reset)
-
-    def __call__(self, message: str, *args, level: str = "INFO", **kwargs):
-        if level == "INFO" or level == "info":
-            coloring = colors.bold + colors.fg.green
-        elif level == "DEBUG" or level == "debug":
-            coloring = colors.fg.lightblue
-        elif level == "WARN" or level == "warning":
-            coloring = colors.bold + colors.fg.yellow
-        elif level == "ERROR":
-            coloring = colors.fg.lightred
-        elif level == "CRITICAL":
-            coloring = colors.bold + colors.fg.red
-        else:
-            coloring = colors.reset
-        print(coloring + message, colors.reset)
-
-
-Msg = cPrint
+""" asyncDB utils.
+Various functions for asyncdb
+"""
+
+
+class colors:
+    """
+    Colors class.
+
+       reset all colors with colors.reset;
+       Use as colors.subclass.colorname.
+    i.e. colors.fg.red or colors.fg.greenalso, the generic bold, disable,
+    underline, reverse, strike through,
+    and invisible work with the main class i.e. colors.bold
+    """
+
+    reset = "\033[0m"
+    bold = "\033[01m"
+    disable = "\033[02m"
+    underline = "\033[04m"
+    reverse = "\033[07m"
+    strikethrough = "\033[09m"
+    invisible = "\033[08m"
+
+    class fg:
+        """
+        colors.fg.
+
+        Foreground Color subClass
+        """
+
+        black = "\033[30m"
+        red = "\033[31m"
+        green = "\033[32m"
+        orange = "\033[33m"
+        blue = "\033[34m"
+        purple = "\033[35m"
+        cyan = "\033[36m"
+        lightgrey = "\033[37m"
+        darkgrey = "\033[90m"
+        lightred = "\033[91m"
+        lightgreen = "\033[92m"
+        yellow = "\033[93m"
+        lightyellow = "\033[93;1m"
+        lightblue = "\033[94m"
+        pink = "\033[95m"
+        lightcyan = "\033[96m"
+
+
+info_level = {"INFO", "info"}
+debug_level =  {"DEBUG", "debug"}
+warn_level = {"WARN", "warn", "WARNING", "warning"}
+class cPrint:
+    def __init__(self, message: str = "", level: str = "INFO"):
+        if level in info_level:
+            coloring = colors.bold + colors.fg.green
+        elif level in debug_level:
+            coloring = colors.fg.lightblue
+        elif level in warn_level:
+            coloring = colors.bold + colors.fg.yellow
+        elif level == "ERROR":
+            coloring = colors.fg.lightred
+        elif level == "CRITICAL":
+            coloring = colors.bold + colors.fg.red
+        else:
+            coloring = colors.reset
+        print(coloring + message, colors.reset)
+
+    def __call__(self, message: str, *args, level: str = "INFO", **kwargs):
+        if level in info_level:
+            coloring = colors.bold + colors.fg.green
+        elif level in debug_level:
+            coloring = colors.fg.lightblue
+        elif level in warn_level:
+            coloring = colors.bold + colors.fg.yellow
+        elif level == "ERROR":
+            coloring = colors.fg.lightred
+        elif level == "CRITICAL":
+            coloring = colors.bold + colors.fg.red
+        else:
+            coloring = colors.reset
+        print(coloring + message, colors.reset)
+
+
+Msg = cPrint
```

## asyncdb/utils/encoders/pg.py

 * *Ordering differences only*

```diff
@@ -1,41 +1,41 @@
-import json
-from datamodel.parsers.encoders import DefaultEncoder
-from asyncpg import Range
-from numpy import integer, int64, floating, ndarray
-
-
-class pgRangeEncoder(json.JSONEncoder):
-    def default(self, o):
-        if isinstance(o, Range):
-            return [o.lower, o.upper]
-        else:
-            return json.JSONEncoder.default(self, o)
-
-
-class IntRangeEncoder(json.JSONEncoder):
-    def default(self, o):
-        if isinstance(o, Range):
-            up = o.upper
-            if isinstance(o.upper, int):
-                up = o.upper - 1  # discrete representation
-            return [o.lower, up]
-        else:
-            return json.JSONEncoder.default(self, o)
-
-
-class DBEncoder(DefaultEncoder):
-    """
-    Basic Encoder for PostgreSQL
-    """
-
-    def default(self, obj):
-        if isinstance(obj, Range):
-            return [obj.lower, obj.upper]
-        elif isinstance(obj, (integer, int64)):
-            return int(obj)
-        elif isinstance(obj, floating):
-            return float(obj)
-        elif isinstance(obj, ndarray):
-            return obj.tolist()
-        else:
-            return super(DBEncoder, self).default(obj)
+import json
+from datamodel.parsers.encoders import DefaultEncoder
+from asyncpg import Range
+from numpy import integer, int64, floating, ndarray
+
+
+class pgRangeEncoder(json.JSONEncoder):
+    def default(self, o):
+        if isinstance(o, Range):
+            return [o.lower, o.upper]
+        else:
+            return json.JSONEncoder.default(self, o)
+
+
+class IntRangeEncoder(json.JSONEncoder):
+    def default(self, o):
+        if isinstance(o, Range):
+            up = o.upper
+            if isinstance(o.upper, int):
+                up = o.upper - 1  # discrete representation
+            return [o.lower, up]
+        else:
+            return json.JSONEncoder.default(self, o)
+
+
+class DBEncoder(DefaultEncoder):
+    """
+    Basic Encoder for PostgreSQL
+    """
+
+    def default(self, obj):
+        if isinstance(obj, Range):
+            return [obj.lower, obj.upper]
+        elif isinstance(obj, (integer, int64)):
+            return int(obj)
+        elif isinstance(obj, floating):
+            return float(obj)
+        elif isinstance(obj, ndarray):
+            return obj.tolist()
+        else:
+            return super(DBEncoder, self).default(obj)
```

## asyncdb/utils/encoders/__init__.py

 * *Ordering differences only*

```diff
@@ -1,9 +1,9 @@
-from datamodel.parsers.encoders import DefaultEncoder, BaseEncoder
-from datamodel.parsers.json import json_encoder, json_decoder
-
-__all__ = (
-    "DefaultEncoder",
-    "BaseEncoder",
-    "json_encoder",
-    "json_decoder",
-)
+from datamodel.parsers.encoders import DefaultEncoder, BaseEncoder
+from datamodel.parsers.json import json_encoder, json_decoder
+
+__all__ = (
+    "DefaultEncoder",
+    "BaseEncoder",
+    "json_encoder",
+    "json_decoder",
+)
```

## asyncdb/utils/encoders/numpy.py

 * *Ordering differences only*

```diff
@@ -1,20 +1,20 @@
-import json
-from numpy import integer, int64, floating, ndarray
-
-
-class NpEncoder(json.JSONEncoder):
-    """
-    npEncoder.
-
-       Numpy number encoder for json
-    """
-
-    def default(self, o):
-        if isinstance(o, (integer, int64)):
-            return int(o)
-        elif isinstance(o, floating):
-            return float(o)
-        elif isinstance(o, ndarray):
-            return o.tolist()
-        else:
-            return json.JSONEncoder.default(self, o)
+import json
+from numpy import integer, int64, floating, ndarray
+
+
+class NpEncoder(json.JSONEncoder):
+    """
+    npEncoder.
+
+       Numpy number encoder for json
+    """
+
+    def default(self, o):
+        if isinstance(o, (integer, int64)):
+            return int(o)
+        elif isinstance(o, floating):
+            return float(o)
+        elif isinstance(o, ndarray):
+            return o.tolist()
+        else:
+            return json.JSONEncoder.default(self, o)
```

## Comparing `asyncdb-2.6.9.dist-info/LICENSE` & `asyncdb-2.7.0.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-BSD License
-
-Copyright (c) 2015-present, Jesus Lara
-All rights reserved.
-
-Redistribution and use in source and binary forms, with or without modification,
-are permitted provided that the following conditions are met:
-
-* Redistributions of source code must retain the above copyright notice, this
-  list of conditions and the following disclaimer.
-
-* Redistributions in binary form must reproduce the above copyright notice, this
-  list of conditions and the following disclaimer in the documentation and/or
-  other materials provided with the distribution.
-
-* Neither the name of the copyright holder nor the names of its
-  contributors may be used to endorse or promote products derived from this
-  software without specific prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
-ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
-WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
-IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
-INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
-BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
-OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
-OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED
-OF THE POSSIBILITY OF SUCH DAMAGE.
+BSD License
+
+Copyright (c) 2015-present, Jesus Lara
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without modification,
+are permitted provided that the following conditions are met:
+
+* Redistributions of source code must retain the above copyright notice, this
+  list of conditions and the following disclaimer.
+
+* Redistributions in binary form must reproduce the above copyright notice, this
+  list of conditions and the following disclaimer in the documentation and/or
+  other materials provided with the distribution.
+
+* Neither the name of the copyright holder nor the names of its
+  contributors may be used to endorse or promote products derived from this
+  software without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
+INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED
+OF THE POSSIBILITY OF SUCH DAMAGE.
```

## Comparing `asyncdb-2.6.9.dist-info/RECORD` & `asyncdb-2.7.0.dist-info/RECORD`

 * *Files 18% similar despite different names*

```diff
@@ -1,70 +1,69 @@
-asyncdb-2.6.9.dist-info/WHEEL,sha256=uQ9JcPdAMEhlCRnfrhg6ydnbrPot9NaB8igB3QVnPX0,148
-asyncdb-2.6.9.dist-info/LICENSE,sha256=_zwlZBJY80ZD0yoNBtUsPvZz4hR2dE9f4JpHSW17nOY,1509
-asyncdb-2.6.9.dist-info/RECORD,,
-asyncdb-2.6.9.dist-info/top_level.txt,sha256=vMLK2jQFYyNY3ta7idY3krhSki0RPpQ8yVZCVa724JI,8
-asyncdb-2.6.9.dist-info/METADATA,sha256=-qcLevKNmemiyQAYZ56rrFxht5UCiG4UktUeqI5zyeQ,12512
-asyncdb/interfaces.py,sha256=S-B4T4ImTNRW9Gpn1YVN1eS4QOEjQcMKAcfYwqEWp7k,27360
-asyncdb/connections.py,sha256=cCRJPonYWUw_VhD-08MJZqKcbFNBZtids_o48k0mp6U,1254
-asyncdb/__init__.py,sha256=VgY54ejJUOSVL7FNGidk8LORQVFUoyfRW5nU9hF01EU,390
-asyncdb/version.py,sha256=gxlvcVcLFuIUXlAHMmGla0xdySD3utZpE56U62IQB4c,271
-asyncdb/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-asyncdb/drivers/bigquery.py,sha256=NlUbkAri9eQIFrTyxzn7pjfv5_m1Y-Vn5C_9RWqvEn4,12024
-asyncdb/drivers/jdbc.py,sha256=TQDp4xZ88xP2fgSjHznbHQxXZBJ05IAR-eQxEyFghN4,29046
-asyncdb/drivers/sa.py,sha256=T9JK4DxeKcDzOs-KEN0jiJK9-uOTAtxM6UF47M-LZbY,16372
-asyncdb/drivers/influx.py,sha256=nfWDi1HwtcqilIX8ESkZb9_S7laAaBmrELkGj8LoET4,20436
-asyncdb/drivers/memcache.py,sha256=-bR2ooYZJ338yJHUhDGCah_KggzALPhcU9sDl3B_EvI,9032
-asyncdb/drivers/scylladb.py,sha256=9StB7Zmx8UabZCZO9F2Lt4fmSsCsQdvxNhEJjKLKhvg,29146
-asyncdb/drivers/redis.py,sha256=9fXuYGYUtNBrJof21tmifySD7Vpc7CIYuVCAN72qGkw,19323
-asyncdb/drivers/delta.py,sha256=5_oKUCakjmHTSv6HI-olA6p1oAZfv9DI1IXj_qAp7YY,9903
-asyncdb/drivers/duckdb.py,sha256=mYPtHXtj1Ui4LWjtqctvWbbnQw6VUek-nXq-XhikdDU,9920
-asyncdb/drivers/cassandra.py,sha256=p89ChctxVHeFWOWKLAcqyWa9JJw1eWOLThClfhuAld0,17007
-asyncdb/drivers/pg.py,sha256=DsLi7wBR0vTOaowRB_RopljGVLvnSf1I7Xdc9yQ6NkU,59985
-asyncdb/drivers/mcache.py,sha256=CRSg5hCJa9vL1QHdMgJ10jQeaqLVAob-K-3NdGvasvw,6412
-asyncdb/drivers/postgres.py,sha256=iBTBw7JReoswFkqKiT6AXcilrrUXpOJ1xeFJhaa0BbA,22002
-asyncdb/drivers/dummy.py,sha256=HfwbN55mwSvPjWEGiybjOxoBf6b7eDuakp__VYYSWic,2049
-asyncdb/drivers/sqlite.py,sha256=sy00TF37fyukHymUnKhegF81-AIaWVdcBCsJomga7T8,25324
-asyncdb/drivers/__init__.py,sha256=LqWj_RjHeZZfyk6JSkKetRijJB_m9L0R1fYnbyGzLAM,25
-asyncdb/drivers/sqlserver.py,sha256=kF6m0XXJtKuaFWfz2NLOhy7n6jLRgU4xptpgF2JG4bA,14033
-asyncdb/drivers/mredis.py,sha256=3yBumnPM3il1V9KeMme2ndLAfCnZ9oErgLGLfECU7XA,19035
-asyncdb/drivers/mongo.py,sha256=jkl08KPkO55w4xeg1wEanX5IISjpKtf5_A-SUDCZMcU,3276
-asyncdb/drivers/sql.py,sha256=7Svosj0HaCYxmdbZ9kttaUAYg5ibYkbtUTQ0bY6AExE,2010
-asyncdb/drivers/oracle.py,sha256=D-BbzCasJw3PpbJ1EOJY-IXSiVTbZYjd9EtardVE9ss,4106
-asyncdb/drivers/mysqlclient.py,sha256=YNRCTTgxRtRE7WKYaAgYWAVxVu-eax7G9ocH5Se1JyM,18098
-asyncdb/drivers/hazel.py,sha256=z2rXFUnNcxwNokpk52v7kfwGT9nYjrxjkLMrIcg2wpo,12730
-asyncdb/drivers/abstract.py,sha256=uxgKB09B4exsj_C-Q9V3_j7izympk1CC-2UcsPcFifs,4361
-asyncdb/drivers/odbc.py,sha256=koB0j_L_5e0s-JWnWDwxXZvK0ED2TE8o3MRklfEwb40,7831
-asyncdb/drivers/mssql.py,sha256=sZGYeSze5BLUYgHwheCpFJZzCVDYoVc0r8UYsFYmXpc,15515
-asyncdb/drivers/mysql.py,sha256=B1CWZg6cCDGx_yTG3fGFDaA_CHoHzTKPOu5xfCFLK6k,15649
-asyncdb/drivers/rethink.py,sha256=2vf6VPG_-nU6iJu3jxqvtUeMTYCY7QtRiUu7CLhcryA,34256
-asyncdb/drivers/_sa.py,sha256=LMa5-0a16PyjA3yFClYrr7rhabL4XfoEnVoiMr3Hb3I,7376
-asyncdb/drivers/outputs/record.py,sha256=czyQmABmpNC0zug3n507yB_k09jXPoynP-04wFK8Eu4,1010
-asyncdb/drivers/outputs/json.py,sha256=bh1sYg1z3HJuqRNYYqd7PiwQEUtdX_ak-Mv0oEctXjo,407
-asyncdb/drivers/outputs/csv.py,sha256=8ejph7tPZpUUnAZKVivrs4A8Oh4qL24aJT8Y5aUpgjE,969
-asyncdb/drivers/outputs/dataclass.py,sha256=NORJd92VRzGBADnVKsQL1v2LUPVfzNHVeKwBc3TGd7g,667
-asyncdb/drivers/outputs/base.py,sha256=ahZK7AEczQFMm0eYJTnJ5XlI3dmFY32NPd8h7uZD_5Q,413
-asyncdb/drivers/outputs/generator.py,sha256=zdyROByiQK-93We7lcvlzSB5P4uy3TdcBeKQBdNNNNc,390
-asyncdb/drivers/outputs/recordset.py,sha256=Zi_GPHv2ky0wGmLomQwk9QirJZxnAx4PyphxD9LMsa0,749
-asyncdb/drivers/outputs/dt.py,sha256=VyyCKlrv42UJ_MqpmaoWkqK3GMPLZ-4aa1dsJrPNVsc,801
-asyncdb/drivers/outputs/arrow.py,sha256=2X11cPhB6DKyCPT9Cb3xKdcwyFfeEK1X4SdAVavpO3o,824
-asyncdb/drivers/outputs/iter.py,sha256=wez9Mx_bHPvIPpzwCfEXmHKHdtqACmfjCLBcak41DYI,521
-asyncdb/drivers/outputs/__init__.py,sha256=qkKcXFSKp6_4YmFRMryVR124gqDLvl_gMpFSnKhS5yw,499
-asyncdb/drivers/outputs/polars.py,sha256=_eqcO-EmMO5w1u_KY5-Sedm2Cx3kiz_lfmC6A9TYawE,838
-asyncdb/drivers/outputs/pandas.py,sha256=v6IqzhveI8Za6jtz2duEGJvcvjcpAT_ejJBhPL6V4k8,992
-asyncdb/drivers/outputs/output.py,sha256=Z3p0avcVa3yfJCjR7v65GNmOobFSIUMNcCn3e2R-VXo,958
-asyncdb/drivers/outputs/pyspark.py,sha256=Tz2H-jEeVxXx4TkdCgY-aUevGeuCtcCd5hv1OFjvPaY,1199
-asyncdb/meta/record.py,sha256=K2KVcFANNGXIAafZcwlljXHphTetb-k7CbT078ghxhM,2947
-asyncdb/meta/recordset.py,sha256=w5HQf9Qec89I-aLIv0-pjZpNsjPnj-I8K1j6tt23wlw,2144
-asyncdb/meta/__init__.py,sha256=L3Pj_ppq6upBpvh5YSZXkL0vuGKQ-Q2KLtZ0Zd67ihA,166
-asyncdb/models/model.py,sha256=lzowiJA3FuQJPTH7FbBj9GhnSD4VGjHN9iAL6Fy7cUc,17311
-asyncdb/models/__init__.py,sha256=4RewpiHpqGNg5w5TBb05almBAjtOfiR1QIR3RHDgvq8,527
-asyncdb/exceptions/exceptions.cpython-39-x86_64-linux-gnu.so,sha256=yPrpyeqYnvC3fFUG620JZLiZkAZXkmW0QQzup3VFG4k,1440552
-asyncdb/exceptions/handlers.py,sha256=YIQ71caDmoMufjKfaik3lU8FA_4WcSrpOVuHowsTi1Q,2801
-asyncdb/exceptions/__init__.py,sha256=ZNYfV-CmAZaLsBPAShtrtSNNVkAci9g8ka8wOVweVlA,827
-asyncdb/utils/modules.py,sha256=bbPRJTg2aeiKHQF8edn4cdNkN63NEwLsKMSawcu-qoc,636
-asyncdb/utils/__init__.py,sha256=Oit0DxSNrJuKosNUDnVyqLmTr0fD8N-hp8JcEylLQQg,128
-asyncdb/utils/uv.py,sha256=uLBWm0yJK4DOEw5ckEWbSL3vtP5gTNmwDh8hulFu1wE,259
-asyncdb/utils/functions.py,sha256=GRK4IworlVunMWH_oQHL_uPfen--OQNZ6tbT9DSKvKw,2389
-asyncdb/utils/types.cpython-39-x86_64-linux-gnu.so,sha256=M9hV-Wpk86srh_O0Bwg4J_1wjsvOQ268gKhXJB4sAcE,1021448
-asyncdb/utils/encoders/pg.py,sha256=AhvJI315H39KhV59d7a9gWw7YvaEO4xeELuT5NkOI-I,1154
-asyncdb/utils/encoders/__init__.py,sha256=GFGadNqNfn_Dm7yTB6411uXhgzbnWyPLhZ5Fd32dET4,225
-asyncdb/utils/encoders/numpy.py,sha256=72d-dbHQ_AKj0jsW0UzTeJcPskDJKZ35PJG4deeHdvM,467
+asyncdb/__init__.py,sha256=0udlaJRz2alek7XfmdLNCM_kLB6NPY9szC5j4nsu3CU,411
+asyncdb/connections.py,sha256=MN_pNS66VqA3E_1gwa-U7eRwgbgmAOwYIVW7eZnFdtw,1297
+asyncdb/interfaces.py,sha256=neAlRetp-gjwSSktJF-v3Z5vbJdgtODpTXgb1EKDIYk,25523
+asyncdb/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+asyncdb/version.py,sha256=u8T9I4a2qeDzLfKasOVT4cjgRpgh-q1vGZhDbGzbW1k,280
+asyncdb/drivers/__init__.py,sha256=okzf2s2YG3qjE5Co21sdcsRPHsCedCc7lmhQjqT3OCY,28
+asyncdb/drivers/abstract.py,sha256=DFTeAdUC98t5n-1ASIrFnZQFr0kD3HMVC5SFc9r--6U,4529
+asyncdb/drivers/bigquery.py,sha256=obTW_XoZzQnIhzC9CkoOUpcMKQgqe959OjD_CIyJZTE,12373
+asyncdb/drivers/cassandra.py,sha256=IVLklNnZ5IoZygL99zXyHLLEvfMkX_G6CQU1U3VaLtY,17209
+asyncdb/drivers/delta.py,sha256=laJLvumooUBlRRmobtS_TQLOI6lPhMGOopWX-v48s94,10172
+asyncdb/drivers/duckdb.py,sha256=Mp7pcCSpHcDaEUhYOaOQsovmaj2TjIXJVi1CFqujScg,10193
+asyncdb/drivers/dummy.py,sha256=hv4-_xDGc0vmYupoezxoA-afCJmTaSEn5jSTo12hGT8,2110
+asyncdb/drivers/hazel.py,sha256=aEXztGMbRJivEnIMeOn47KN1N5JLuVkbtUy9YE4q-Xg,13068
+asyncdb/drivers/influx.py,sha256=ag6hiy6cZP6qbXDWA3ax1_hjc4WYchvsKe5rYdaPLHU,20827
+asyncdb/drivers/jdbc.py,sha256=iUh4koHoEkK4nn2iE90Gqe4eRq-PtJo2TvXSZpdUFIQ,29764
+asyncdb/drivers/mcache.py,sha256=ZCta5ylKZwVvQZjAsKVwI90gRepHsqa2_CZ0bXIBj5s,6638
+asyncdb/drivers/memcache.py,sha256=9GYnWL5Q1hmBczQkiq_3jtcd-EnKeFmQqvFJvhnNE0Y,9336
+asyncdb/drivers/mongo.py,sha256=EvTlxjwoNQMu25QGM_MIwCAcf-bwpzBARVONspTrrHA,3316
+asyncdb/drivers/mredis.py,sha256=dbAtp1x810uS8WNJbhxwe3tl2kZA6oL-PrflxDDn0Pg,19474
+asyncdb/drivers/mssql.py,sha256=33i3N9S9_uqlbf_9cGTYA165WqQzXVFBHUWIGCF2iGs,15824
+asyncdb/drivers/mysql.py,sha256=mt24UPRfXwe39dOf9nLiLvI87HQ_IzCJaJy03fgX61k,16072
+asyncdb/drivers/mysqlclient.py,sha256=CE9TjoYi7C0uVHPvPPIGhCeefEUIHhlJd3qiKlqnSw4,18635
+asyncdb/drivers/odbc.py,sha256=xeGoxj7IsexhrV-J1tlKr5PYnIHHM-w6N5BIHES7g-M,8036
+asyncdb/drivers/oracle.py,sha256=x8NF4Obj021SUvYbNJdVHCxPTAHJ0EcfYrG_r4Fnaa8,4206
+asyncdb/drivers/pg.py,sha256=D-imbS02AGWjUp_RaaAQ4sP9-e9bLylsN94vmBmUXpQ,61614
+asyncdb/drivers/postgres.py,sha256=T2JXgMRHXeS11M7HhSP-xkyyg0U06sUcfu_a86qwTW8,22590
+asyncdb/drivers/redis.py,sha256=vqdJ4NCOkaZWtpDXz5hJA8Eu_hC90HFKa30aT80XV5U,19814
+asyncdb/drivers/rethink.py,sha256=Pnin62i2a46SnM0kyYz_lyGGAb434PkZ68WU4gqMG4U,35185
+asyncdb/drivers/sa.py,sha256=fBOgeYSkzPTjcAsOkvZVrvtpb_bDy1yYZpw5oIBkzV0,16815
+asyncdb/drivers/scylladb.py,sha256=nMNTZDJqd0uaj-YMK40Nwtc7TUZJzS0ivDegNM-yH60,56434
+asyncdb/drivers/sql.py,sha256=YxUQb61MJiALin-NsYgxcQgkg-WqXekAVfMiii0-M3E,2071
+asyncdb/drivers/sqlite.py,sha256=HtyIutxNF6pUqwaS6NezmQ-HMKoPoUT4ds-vRjzOcwA,25972
+asyncdb/drivers/sqlserver.py,sha256=xbjv-Rafm1aWcbfp2N8lqCXcY2Xb2tJr8eTZry1b4qI,14374
+asyncdb/drivers/outputs/__init__.py,sha256=jRYvaCZZQWmWkbf5sJATxLmsmoSA0cgJQrX6ZlNuNOo,513
+asyncdb/drivers/outputs/arrow.py,sha256=1FKK52vDM3ZzZViCO476mOkiM-QGrxFgFusUJrCZYEc,848
+asyncdb/drivers/outputs/base.py,sha256=UmePeAfWIt1XE_de9HdJFcKNFtPMw0eewVYQCpbhLQs,429
+asyncdb/drivers/outputs/csv.py,sha256=n-9-QWA-VmldleXmGCdCtStBdMN9Y3TuH70sHMcpp-o,997
+asyncdb/drivers/outputs/dataclass.py,sha256=vBdmwqEQSgQWatAS7IRFWpqGdhpvQ8lNyB5wfGTik8o,693
+asyncdb/drivers/outputs/dt.py,sha256=LoFzPGfyPgsJMAmJgTTFnOBoUntkvhhONBdsW9AYYWc,827
+asyncdb/drivers/outputs/generator.py,sha256=eG1vitklCqhdmdo7-WUQtjph7xjWj3cMkK7QAzCNMa4,408
+asyncdb/drivers/outputs/iter.py,sha256=Tg-G1_k1pUDNUoVKvCUT9rIALqpfpBwdrVNSi39Pd3M,543
+asyncdb/drivers/outputs/json.py,sha256=9iAJUHXc7hyMCc97GhwJUknwlyrsFRxqDTFi9YjycgY,418
+asyncdb/drivers/outputs/output.py,sha256=WgcgqrqwN0WSHpf4jTuTKftyH7Ov-KQjaWzAspR2TOc,986
+asyncdb/drivers/outputs/pandas.py,sha256=T94VGwsfQhq5P_o46TXTq6Av7E3vjPkxoBA4H4T4Z8k,1021
+asyncdb/drivers/outputs/polars.py,sha256=qJNPIu6AsBzSkSjMicLUwp20PnpvPA_Gx7fkHoPHtU4,864
+asyncdb/drivers/outputs/pyspark.py,sha256=ZoLiKGAcqO96NU2oapshn6rkxt-MKppeLlVWIsYq9IQ,1236
+asyncdb/drivers/outputs/record.py,sha256=sPFwhGgM9M1APINMzyQQJ6312MYqjNnauCVJWAbzC-A,1038
+asyncdb/drivers/outputs/recordset.py,sha256=oJpN0h2AaXmj6CbsOdN8uyUo3AC9YnD77GUqfAUOZsE,770
+asyncdb/exceptions/__init__.py,sha256=c6HhQu9AQcSn85Dp-jyvqiUUUVMK2gYJalN7gYdS008,867
+asyncdb/exceptions/exceptions.pypy39-pp73-win_amd64.pyd,sha256=JBJhZoL6KklwF3TjHU95li7NqnUcrG4nPwftWJPlyNA,158720
+asyncdb/exceptions/handlers.py,sha256=GEFCoNMkyXTBz9-tuJ3Y1Gsq2gcgAZcrQnzFZ4k_LVM,2539
+asyncdb/meta/__init__.py,sha256=Wl5uJSXic-gh52UKleUdEqdVaS2LTsSPsUOlh2nO3P8,176
+asyncdb/meta/record.py,sha256=bdKiYrlmX0FtBShvVw1rscMGfQq_CgDZwp194hHrCGg,3057
+asyncdb/meta/recordset.py,sha256=yRyKbCIg5kxDWgqsddMCTKQJctBfgvs6W9bOecaZg3k,2221
+asyncdb/models/__init__.py,sha256=I_v3ttQX7tdF6V2WlBh5bf6YUAxaukfHgiQmsE59cj8,542
+asyncdb/models/model.py,sha256=e02FQHXf2vEFOeMGpqO86mmzzNzHWOYMT6B2oXZP1No,17784
+asyncdb/utils/__init__.py,sha256=Bx7Kk7jHsVfVsNchJH5BdA4zDQFmvRxt9TnY0fd9qWo,136
+asyncdb/utils/functions.py,sha256=Pr5wkjacMvuG7vOSGGLF_CfKkVqTRZpnbJZcl6T2IpE,2484
+asyncdb/utils/modules.py,sha256=6tUulpoEUpitmoOd972JLdj_XiYx0xbHcAimZRZ81yE,655
+asyncdb/utils/types.pypy39-pp73-win_amd64.pyd,sha256=QSq3O7Hz01bP5zbyaRBvX80jJTyaUsJeBRa5vZW6GR0,111616
+asyncdb/utils/uv.py,sha256=r3HYjQmAAl4yOYQwvi2ghUGGJVWPqUFNqRWcjKWCNxs,319
+asyncdb/utils/encoders/__init__.py,sha256=YwtnLtxCmPm21EALjW1Y2upbyIHJiNWHjrchuetp4Fc,234
+asyncdb/utils/encoders/numpy.py,sha256=DkNoKLLA2haOG0qOm9J5RmRBkgiEZbcl9do5mBvIQbY,487
+asyncdb/utils/encoders/pg.py,sha256=i70nydH2S4XxAZUJdoJjXYsU_Ju6hAJbynLsztZSP10,1195
+asyncdb-2.7.0.dist-info/LICENSE,sha256=mThyqULh5pc9N8g3nfITEVMYcHOxzkPyJHQGWwFuQ_c,1538
+asyncdb-2.7.0.dist-info/METADATA,sha256=jvhYMIHS33yCUQ-tbfR3QcsL33J71R0doav-i21D9tQ,12674
+asyncdb-2.7.0.dist-info/WHEEL,sha256=1cqEyrKxUA_c-f0mOszCh_7q-AnzL9K6iMxWION_yb8,107
+asyncdb-2.7.0.dist-info/top_level.txt,sha256=vMLK2jQFYyNY3ta7idY3krhSki0RPpQ8yVZCVa724JI,8
+asyncdb-2.7.0.dist-info/RECORD,,
```

## Comparing `asyncdb-2.6.9.dist-info/METADATA` & `asyncdb-2.7.0.dist-info/METADATA`

 * *Files 8% similar despite different names*

```diff
@@ -1,329 +1,324 @@
-Metadata-Version: 2.1
-Name: asyncdb
-Version: 2.6.9
-Summary: Library for Asynchronous data source connections     Collection of asyncio drivers.
-Home-page: https://github.com/phenobarbital/asyncdb
-Author: Jesus Lara
-Author-email: jesuslarag@gmail.com
-License: BSD
-Project-URL: Source, https://github.com/phenobarbital/asyncdb
-Project-URL: Funding, https://paypal.me/phenobarbital
-Project-URL: Say Thanks!, https://saythanks.io/to/phenobarbital
-Keywords: asyncio,asyncpg,aioredis,aiomcache,cassandra
-Platform: POSIX
-Classifier: Development Status :: 4 - Beta
-Classifier: Intended Audience :: Developers
-Classifier: Operating System :: POSIX :: Linux
-Classifier: Environment :: Web Environment
-Classifier: License :: OSI Approved :: BSD License
-Classifier: Topic :: Software Development :: Build Tools
-Classifier: Topic :: Software Development :: Libraries :: Python Modules
-Classifier: Topic :: Database :: Front-Ends
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Programming Language :: Python :: 3.12
-Classifier: Programming Language :: Python :: 3 :: Only
-Classifier: Framework :: AsyncIO
-Requires-Python: >=3.9.13
-Description-Content-Type: text/markdown
-License-File: LICENSE
-Requires-Dist: numpy ==1.24.2
-Requires-Dist: cryptography ==41.0.7
-Requires-Dist: aiohttp ==3.9.1
-Requires-Dist: asyncpg ==0.29.0
-Requires-Dist: uvloop ==0.19.0
-Requires-Dist: asyncio ==3.4.3
-Requires-Dist: pandas ==2.1.1
-Requires-Dist: xlrd ==2.0.1
-Requires-Dist: openpyxl ==3.1.2
-Requires-Dist: lz4 ==4.3.2
-Requires-Dist: typing-extensions ==4.8.0
-Requires-Dist: charset-normalizer >=2.0.7
-Requires-Dist: iso8601 ==2.1.0
-Requires-Dist: pgpy ==0.6.0
-Requires-Dist: python-magic ==0.4.27
-Requires-Dist: dateparser ==1.1.8
-Requires-Dist: python-datamodel >=0.6.3
-Requires-Dist: aiosqlite >=0.18.0
-Requires-Dist: pendulum ==2.1.2
-Requires-Dist: looseversion ==1.3.0
-Requires-Dist: aiofiles ==23.2.1
-Provides-Extra: all
-Requires-Dist: dask ==2023.3.0 ; extra == 'all'
-Requires-Dist: datatable ==1.1.0 ; extra == 'all'
-Requires-Dist: python-datatable ==1.1.3 ; extra == 'all'
-Requires-Dist: polars ==0.20.4 ; extra == 'all'
-Requires-Dist: pyarrow ==14.0.2 ; extra == 'all'
-Requires-Dist: connectorx ==0.3.2 ; extra == 'all'
-Requires-Dist: aiosqlite >=0.18.0 ; extra == 'all'
-Requires-Dist: pylibmc ==1.6.3 ; extra == 'all'
-Requires-Dist: aiomcache ==0.8.1 ; extra == 'all'
-Requires-Dist: jsonpath-rw ==1.4.0 ; extra == 'all'
-Requires-Dist: jsonpath-rw-ext ==1.2.2 ; extra == 'all'
-Requires-Dist: aioredis ==2.0.1 ; extra == 'all'
-Requires-Dist: redis ==5.0.1 ; extra == 'all'
-Requires-Dist: objectpath ==0.6.1 ; extra == 'all'
-Requires-Dist: rethinkdb ==2.4.10 ; extra == 'all'
-Requires-Dist: aiopg ==1.4.0 ; extra == 'all'
-Requires-Dist: psycopg-binary >=3.1.8 ; extra == 'all'
-Requires-Dist: cassandra-driver ==3.28.0 ; extra == 'all'
-Requires-Dist: influxdb ==5.3.1 ; extra == 'all'
-Requires-Dist: influxdb-client ==1.36.1 ; extra == 'all'
-Requires-Dist: aioodbc ==0.3.3 ; extra == 'all'
-Requires-Dist: JayDeBeApi ==1.2.3 ; extra == 'all'
-Requires-Dist: pyodbc ==4.0.35 ; extra == 'all'
-Requires-Dist: sqlalchemy[asyncio] ==2.0.23 ; extra == 'all'
-Requires-Dist: elasticsearch[async] ==8.11.0 ; extra == 'all'
-Requires-Dist: pymongo ==4.6.1 ; extra == 'all'
-Requires-Dist: motor ==3.3.2 ; extra == 'all'
-Requires-Dist: pymssql ==2.2.11 ; extra == 'all'
-Requires-Dist: aiocouch ==3.0.0 ; extra == 'all'
-Requires-Dist: asyncmy ==0.2.9 ; extra == 'all'
-Requires-Dist: mysqlclient ==2.2.0 ; extra == 'all'
-Requires-Dist: aiomysql ==0.2.0 ; extra == 'all'
-Requires-Dist: pyspark ==3.5.0 ; extra == 'all'
-Requires-Dist: oracledb ==1.2.2 ; extra == 'all'
-Requires-Dist: hazelcast-python-client ==5.3.0 ; extra == 'all'
-Requires-Dist: duckdb ==0.9.2 ; extra == 'all'
-Requires-Dist: deltalake ==0.13.0 ; extra == 'all'
-Requires-Dist: botocore ==1.31.64 ; extra == 'all'
-Requires-Dist: aiobotocore ==2.7.0 ; extra == 'all'
-Requires-Dist: aioboto3 ==12.0.0 ; extra == 'all'
-Requires-Dist: acsylla ==0.1.8b0 ; extra == 'all'
-Requires-Dist: google-cloud-bigquery ==3.13.0 ; extra == 'all'
-Requires-Dist: pandas-gbq ==0.19.2 ; extra == 'all'
-Requires-Dist: tqdm ==4.66.1 ; extra == 'all'
-Provides-Extra: bigquery
-Requires-Dist: google-cloud-bigquery ==3.13.0 ; extra == 'bigquery'
-Requires-Dist: pandas-gbq ==0.19.2 ; extra == 'bigquery'
-Provides-Extra: boto3
-Requires-Dist: botocore ==1.31.64 ; extra == 'boto3'
-Requires-Dist: aiobotocore ==2.7.0 ; extra == 'boto3'
-Requires-Dist: aioboto3 ==12.0.0 ; extra == 'boto3'
-Provides-Extra: cassandra
-Requires-Dist: cassandra-driver ==3.28.0 ; extra == 'cassandra'
-Provides-Extra: couchdb
-Requires-Dist: aiocouch ==3.0.0 ; extra == 'couchdb'
-Provides-Extra: dataframe
-Requires-Dist: dask ==2023.3.0 ; extra == 'dataframe'
-Requires-Dist: datatable ==1.1.0 ; extra == 'dataframe'
-Requires-Dist: python-datatable ==1.1.3 ; extra == 'dataframe'
-Requires-Dist: polars ==0.20.4 ; extra == 'dataframe'
-Requires-Dist: pyarrow ==14.0.2 ; extra == 'dataframe'
-Requires-Dist: connectorx ==0.3.2 ; extra == 'dataframe'
-Requires-Dist: pyspark ==3.5.0 ; extra == 'dataframe'
-Requires-Dist: deltalake ==0.13.0 ; extra == 'dataframe'
-Provides-Extra: default
-Requires-Dist: aioredis ==2.0.1 ; extra == 'default'
-Requires-Dist: pylibmc ==1.6.3 ; extra == 'default'
-Requires-Dist: aiomcache ==0.8.1 ; extra == 'default'
-Requires-Dist: aiosqlite >=0.18.0 ; extra == 'default'
-Requires-Dist: cassandra-driver ==3.28.0 ; extra == 'default'
-Requires-Dist: rethinkdb ==2.4.10 ; extra == 'default'
-Requires-Dist: influxdb ==5.3.1 ; extra == 'default'
-Requires-Dist: influxdb-client[async] ==1.39.0 ; extra == 'default'
-Requires-Dist: pymssql ==2.2.11 ; extra == 'default'
-Requires-Dist: redis ==5.0.1 ; extra == 'default'
-Requires-Dist: duckdb ==0.9.2 ; extra == 'default'
-Requires-Dist: deltalake ==0.13.0 ; extra == 'default'
-Provides-Extra: elasticsearch
-Requires-Dist: elasticsearch[async] ==8.11.0 ; extra == 'elasticsearch'
-Provides-Extra: hazelcast
-Requires-Dist: hazelcast-python-client ==5.3.0 ; extra == 'hazelcast'
-Provides-Extra: influxdb
-Requires-Dist: influxdb ==5.3.1 ; extra == 'influxdb'
-Requires-Dist: influxdb-client[async] ==1.39.0 ; extra == 'influxdb'
-Provides-Extra: jdbc
-Requires-Dist: JayDeBeApi ==1.2.3 ; extra == 'jdbc'
-Provides-Extra: mariadb
-Requires-Dist: aiomysql ==0.2.0 ; extra == 'mariadb'
-Provides-Extra: memcache
-Requires-Dist: pylibmc ==1.6.3 ; extra == 'memcache'
-Requires-Dist: aiomcache ==0.8.1 ; extra == 'memcache'
-Provides-Extra: mongodb
-Requires-Dist: pymongo ==4.6.1 ; extra == 'mongodb'
-Requires-Dist: motor ==3.3.2 ; extra == 'mongodb'
-Provides-Extra: msqlserver
-Requires-Dist: pymssql ==2.2.11 ; extra == 'msqlserver'
-Provides-Extra: mysql
-Requires-Dist: asyncmy ==0.2.9 ; extra == 'mysql'
-Requires-Dist: mysqlclient ==2.2.0 ; extra == 'mysql'
-Provides-Extra: odbc
-Requires-Dist: aioodbc ==0.3.3 ; extra == 'odbc'
-Requires-Dist: pyodbc ==4.0.35 ; extra == 'odbc'
-Provides-Extra: oracle
-Requires-Dist: oracledb ==1.2.2 ; extra == 'oracle'
-Provides-Extra: postgres
-Requires-Dist: aiopg ==1.4.0 ; extra == 'postgres'
-Requires-Dist: psycopg-binary >=3.1.8 ; extra == 'postgres'
-Provides-Extra: postgresql
-Requires-Dist: asyncpg ==0.29.0 ; extra == 'postgresql'
-Provides-Extra: pyspark
-Requires-Dist: pyspark ==3.5.0 ; extra == 'pyspark'
-Provides-Extra: redis
-Requires-Dist: jsonpath-rw ==1.4.0 ; extra == 'redis'
-Requires-Dist: jsonpath-rw-ext ==1.2.2 ; extra == 'redis'
-Requires-Dist: redis ==5.0.1 ; extra == 'redis'
-Requires-Dist: aioredis ==2.0.1 ; extra == 'redis'
-Requires-Dist: hiredis ==2.2.3 ; extra == 'redis'
-Requires-Dist: objectpath ==0.6.1 ; extra == 'redis'
-Provides-Extra: rethinkdb
-Requires-Dist: rethinkdb ==2.4.10 ; extra == 'rethinkdb'
-Provides-Extra: scylla
-Requires-Dist: acsylla ==0.1.8b0 ; extra == 'scylla'
-Requires-Dist: scylla-driver ==3.26.3 ; extra == 'scylla'
-Requires-Dist: cqlsh ==6.1.2 ; extra == 'scylla'
-Provides-Extra: sqlalchemy
-Requires-Dist: sqlalchemy[asyncio] ==2.0.23 ; extra == 'sqlalchemy'
-Provides-Extra: sqlite
-Requires-Dist: aiosqlite >=0.18.0 ; extra == 'sqlite'
-
-# AsyncDB #
-
-AsyncDB is a collection of different Database Drivers using asyncio-based connections, binary-connectors (as asyncpg) but providing an abstraction layer to easily connect to different data sources, a high-level abstraction layer for various non-blocking database connectors,
-on other blocking connectors (like MS SQL Server) we are using ThreadPoolExecutors to run in a non-blocking manner.
-
-### Why AsyncDB? ###
-
-The finality of AsyncDB is to provide us a subset of drivers (connectors) for accessing different databases and data sources for data interaction.
-The main goal of AsyncDB is using asyncio-based technologies.
-
-### Getting Started ###
-
-## Requirements
-
-Python 3.8+
-
-## Installation
-
-<div class="termy">
-
-```console
-$ pip install asyncdb
----> 100%
-Successfully installed asyncdb
-```
-
-Can also install only drivers required like:
-```console
-$ pip install asyncdb[pg] # this install only asyncpg
-```
-Or install all supported drivers as:
-
-```console
-$ pip install asyncdb[all]
-```
-
-### Requirements ###
-
-* Python >= 3.8
-* asyncio (https://pypi.python.org/pypi/asyncio/)
-
-Currently AsyncDB supports the following databases:
-
-* PostgreSQL (supporting two different connectors: asyncpg or aiopg)
-* SQLite (requires aiosqlite)
-* mySQL/MariaDB (requires aiomysql and mysqlclient)
-* ODBC (using aioodbc)
-* JDBC(using JayDeBeApi and JPype)
-* RethinkDB (requires rethinkdb)
-* Redis (requires aioredis)
-* Memcache (requires aiomcache)
-* MS SQL Server (non-asyncio using freeTDS and pymssql)
-* Apache Cassandra (requires official cassandra driver)
-* InfluxDB (using influxdb)
-* CouchBase (using aiocouch)
-* MongoDB (using motor)
-* SQLAlchemy (requires sqlalchemy async (+3.14))
-
-### Quick Tutorial ###
-
-```python
-from asyncdb import AsyncDB
-
-db = AsyncDB('pg', dsn='postgres://user:password@localhost:5432/database')
-
-# Or you can also passing a dictionary with parameters like:
-params = {
-    "user": "user",
-    "password": "password",
-    "host": "localhost",
-    "port": "5432",
-    "database": "database",
-    "DEBUG": True,
-}
-db = AsyncDB('pg', params=params)
-
-async with await db.connection() as conn:
-    result, error = await conn.query('SELECT * FROM test')
-```
-And that's it!, we are using the same methods on all drivers, maintaining a consistent interface between all of them, facilitating the re-use of the same code for different databases.
-
-Every Driver has a simple name to call it:
-* pg: AsyncPG (PostgreSQL)
-* postgres: aiopg (PostgreSQL)
-* mysql: aiomysql (mySQL)
-* influx: influxdb (InfluxDB)
-* redis: aioredis (Redis)
-* mcache: aiomcache (Memcache)
-* odbc: aiodbc (ODBC)
-
-#### Future work: ####
-
-* Prometheus
-
-### Output Support ###
-
-With Output Support results can be returned into a wide-range of variants:
-
-```python
-from datamodel import BaseModel
-
-class Point(BaseModel):
-    col1: list
-    col2: list
-    col3: list
-
-db = AsyncDB('pg', dsn='postgres://user:password@localhost:5432/database')
-async with await d.connection() as conn:
-    # changing output format to Pandas:
-    conn.output_format('pandas')  # change output format to pandas
-    result, error = await conn.query('SELECT * FROM test')
-    conn.output_format('csv')  # change output format to CSV
-    result, _ = await conn.query('SELECT TEST')
-    conn.output_format('dataclass', model=Point)  # change output format to Dataclass Model
-    result, _ = await conn.query('SELECT * FROM test')
-```
-
-Currently AsyncDB supports the following Output Formats:
-
-* CSV (comma-separated or parametrized)
-* JSON (using orjson)
-* iterable (returns a generator)
-* Recordset (Internal meta-Object for list of Records)
-* Pandas (a pandas Dataframe)
-* Datatable (Dt Dataframe)
-* Dataclass (exporting data to a dataclass with -optionally- passing Dataclass instance)
-* PySpark Dataframe
-
-And others to come:
-* Apache Arrow (using pyarrow)
-* Polars (Using Python polars)
-* Dask Dataframe
-
-### Contribution guidelines ###
-
-Please have a look at the Contribution Guide
-
-* Writing tests
-* Code review
-
-### Who do I talk to? ###
-
-* Repo owner or admin
-* Other community or team contact
-
-### License ###
-
-AsyncDB is copyright of Jesus Lara (https://phenobarbital.info) and is licensed under BSD. I am providing code in this repository under an open source licenses, remember, this is my personal repository; the license that you receive is from me and not from my employeer.
+Metadata-Version: 2.1
+Name: asyncdb
+Version: 2.7.0
+Summary: Library for Asynchronous data source connections     Collection of asyncio drivers.
+Home-page: https://github.com/phenobarbital/asyncdb
+Author: Jesus Lara
+Author-email: jesuslarag@gmail.com
+License: BSD
+Project-URL: Source, https://github.com/phenobarbital/asyncdb
+Project-URL: Funding, https://paypal.me/phenobarbital
+Project-URL: Say Thanks!, https://saythanks.io/to/phenobarbital
+Keywords: asyncio,asyncpg,aioredis,aiomcache,cassandra,scylladb
+Platform: POSIX
+Classifier: Development Status :: 4 - Beta
+Classifier: Intended Audience :: Developers
+Classifier: Operating System :: POSIX :: Linux
+Classifier: Environment :: Web Environment
+Classifier: License :: OSI Approved :: BSD License
+Classifier: Topic :: Software Development :: Build Tools
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Classifier: Topic :: Database :: Front-Ends
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
+Classifier: Programming Language :: Python :: 3 :: Only
+Classifier: Framework :: AsyncIO
+Requires-Python: >=3.9.13
+Description-Content-Type: text/markdown
+License-File: LICENSE
+Requires-Dist: cryptography ==42.0.4
+Requires-Dist: aiohttp ==3.9.5
+Requires-Dist: asyncpg ==0.29.0
+Requires-Dist: uvloop ==0.19.0
+Requires-Dist: asyncio ==3.4.3
+Requires-Dist: pandas ==2.2.1
+Requires-Dist: xlrd ==2.0.1
+Requires-Dist: openpyxl ==3.1.2
+Requires-Dist: lz4 ==4.3.2
+Requires-Dist: charset-normalizer >=2.0.7
+Requires-Dist: iso8601 ==2.1.0
+Requires-Dist: pgpy ==0.6.0
+Requires-Dist: python-magic ==0.4.27
+Requires-Dist: dateparser ==1.1.8
+Requires-Dist: python-datamodel >=0.6.23
+Requires-Dist: aiosqlite >=0.18.0
+Requires-Dist: looseversion ==1.3.0
+Requires-Dist: aiofiles ==23.2.1
+Provides-Extra: all
+Requires-Dist: dask ==2023.3.0 ; extra == 'all'
+Requires-Dist: datatable ==1.1.0 ; extra == 'all'
+Requires-Dist: python-datatable ==1.1.3 ; extra == 'all'
+Requires-Dist: polars ==0.20.4 ; extra == 'all'
+Requires-Dist: pyarrow ==16.0.0 ; extra == 'all'
+Requires-Dist: connectorx ==0.2.3 ; extra == 'all'
+Requires-Dist: aiosqlite >=0.18.0 ; extra == 'all'
+Requires-Dist: pylibmc ==1.6.3 ; extra == 'all'
+Requires-Dist: aiomcache ==0.8.1 ; extra == 'all'
+Requires-Dist: jsonpath-rw ==1.4.0 ; extra == 'all'
+Requires-Dist: jsonpath-rw-ext ==1.2.2 ; extra == 'all'
+Requires-Dist: redis ==5.0.1 ; extra == 'all'
+Requires-Dist: objectpath ==0.6.1 ; extra == 'all'
+Requires-Dist: rethinkdb ==2.4.10.post1 ; extra == 'all'
+Requires-Dist: aiopg ==1.4.0 ; extra == 'all'
+Requires-Dist: psycopg-binary >=3.1.8 ; extra == 'all'
+Requires-Dist: cassandra-driver ==3.29.1 ; extra == 'all'
+Requires-Dist: scylla-driver ==3.26.8 ; extra == 'all'
+Requires-Dist: influxdb ==5.3.1 ; extra == 'all'
+Requires-Dist: influxdb-client ==1.39.0 ; extra == 'all'
+Requires-Dist: aioodbc ==0.5.0 ; extra == 'all'
+Requires-Dist: JayDeBeApi ==1.2.3 ; extra == 'all'
+Requires-Dist: pyodbc ==5.1.0 ; extra == 'all'
+Requires-Dist: sqlalchemy[asyncio] ==2.0.23 ; extra == 'all'
+Requires-Dist: elasticsearch[async] ==8.13.0 ; extra == 'all'
+Requires-Dist: pymongo ==4.6.1 ; extra == 'all'
+Requires-Dist: motor ==3.3.2 ; extra == 'all'
+Requires-Dist: pymssql ==2.2.11 ; extra == 'all'
+Requires-Dist: aiocouch ==3.0.0 ; extra == 'all'
+Requires-Dist: asyncmy ==0.2.9 ; extra == 'all'
+Requires-Dist: mysqlclient ==2.2.0 ; extra == 'all'
+Requires-Dist: aiomysql ==0.2.0 ; extra == 'all'
+Requires-Dist: pyspark ==3.5.0 ; extra == 'all'
+Requires-Dist: oracledb ==2.1.1 ; extra == 'all'
+Requires-Dist: hazelcast-python-client ==5.3.0 ; extra == 'all'
+Requires-Dist: duckdb ==0.10.1 ; extra == 'all'
+Requires-Dist: deltalake ==0.13.0 ; extra == 'all'
+Requires-Dist: botocore ==1.31.64 ; extra == 'all'
+Requires-Dist: aiobotocore ==2.7.0 ; extra == 'all'
+Requires-Dist: aioboto3 ==12.0.0 ; extra == 'all'
+Requires-Dist: google-cloud-bigquery ==3.13.0 ; extra == 'all'
+Requires-Dist: pandas-gbq ==0.19.2 ; extra == 'all'
+Requires-Dist: tqdm ==4.66.1 ; extra == 'all'
+Provides-Extra: bigquery
+Requires-Dist: google-cloud-bigquery ==3.13.0 ; extra == 'bigquery'
+Requires-Dist: pandas-gbq ==0.19.2 ; extra == 'bigquery'
+Provides-Extra: boto3
+Requires-Dist: botocore ==1.31.64 ; extra == 'boto3'
+Requires-Dist: aiobotocore ==2.7.0 ; extra == 'boto3'
+Requires-Dist: aioboto3 ==12.0.0 ; extra == 'boto3'
+Provides-Extra: cassandra
+Requires-Dist: cassandra-driver ==3.29.1 ; extra == 'cassandra'
+Provides-Extra: couchdb
+Requires-Dist: aiocouch ==3.0.0 ; extra == 'couchdb'
+Provides-Extra: dataframe
+Requires-Dist: dask ==2023.3.0 ; extra == 'dataframe'
+Requires-Dist: datatable ==1.1.0 ; extra == 'dataframe'
+Requires-Dist: python-datatable ==1.1.3 ; extra == 'dataframe'
+Requires-Dist: polars ==0.20.4 ; extra == 'dataframe'
+Requires-Dist: pyarrow ==16.0.0 ; extra == 'dataframe'
+Requires-Dist: connectorx ==0.2.3 ; extra == 'dataframe'
+Requires-Dist: pyspark ==3.5.0 ; extra == 'dataframe'
+Requires-Dist: deltalake ==0.13.0 ; extra == 'dataframe'
+Provides-Extra: default
+Requires-Dist: pylibmc ==1.6.3 ; extra == 'default'
+Requires-Dist: aiomcache ==0.8.1 ; extra == 'default'
+Requires-Dist: aiosqlite >=0.18.0 ; extra == 'default'
+Requires-Dist: cassandra-driver ==3.29.1 ; extra == 'default'
+Requires-Dist: rethinkdb ==2.4.10.post1 ; extra == 'default'
+Requires-Dist: influxdb ==5.3.1 ; extra == 'default'
+Requires-Dist: influxdb-client[async] ==1.39.0 ; extra == 'default'
+Requires-Dist: pymssql ==2.2.11 ; extra == 'default'
+Requires-Dist: redis ==5.0.1 ; extra == 'default'
+Requires-Dist: duckdb ==0.10.1 ; extra == 'default'
+Requires-Dist: deltalake ==0.13.0 ; extra == 'default'
+Provides-Extra: elasticsearch
+Requires-Dist: elasticsearch[async] ==8.13.0 ; extra == 'elasticsearch'
+Provides-Extra: hazelcast
+Requires-Dist: hazelcast-python-client ==5.3.0 ; extra == 'hazelcast'
+Provides-Extra: influxdb
+Requires-Dist: influxdb ==5.3.1 ; extra == 'influxdb'
+Requires-Dist: influxdb-client[async] ==1.39.0 ; extra == 'influxdb'
+Provides-Extra: jdbc
+Requires-Dist: JayDeBeApi ==1.2.3 ; extra == 'jdbc'
+Provides-Extra: mariadb
+Requires-Dist: aiomysql ==0.2.0 ; extra == 'mariadb'
+Provides-Extra: memcache
+Requires-Dist: pylibmc ==1.6.3 ; extra == 'memcache'
+Requires-Dist: aiomcache ==0.8.1 ; extra == 'memcache'
+Provides-Extra: mongodb
+Requires-Dist: pymongo ==4.6.1 ; extra == 'mongodb'
+Requires-Dist: motor ==3.3.2 ; extra == 'mongodb'
+Provides-Extra: msqlserver
+Requires-Dist: pymssql ==2.2.11 ; extra == 'msqlserver'
+Provides-Extra: mysql
+Requires-Dist: asyncmy ==0.2.9 ; extra == 'mysql'
+Requires-Dist: mysqlclient ==2.2.0 ; extra == 'mysql'
+Provides-Extra: odbc
+Requires-Dist: aioodbc ==0.5.0 ; extra == 'odbc'
+Requires-Dist: pyodbc ==5.1.0 ; extra == 'odbc'
+Provides-Extra: oracle
+Requires-Dist: oracledb ==2.1.1 ; extra == 'oracle'
+Provides-Extra: postgres
+Requires-Dist: aiopg ==1.4.0 ; extra == 'postgres'
+Requires-Dist: psycopg-binary >=3.1.8 ; extra == 'postgres'
+Provides-Extra: postgresql
+Requires-Dist: asyncpg ==0.29.0 ; extra == 'postgresql'
+Provides-Extra: pyspark
+Requires-Dist: pyspark ==3.5.0 ; extra == 'pyspark'
+Provides-Extra: redis
+Requires-Dist: jsonpath-rw ==1.4.0 ; extra == 'redis'
+Requires-Dist: jsonpath-rw-ext ==1.2.2 ; extra == 'redis'
+Requires-Dist: redis ==5.0.1 ; extra == 'redis'
+Requires-Dist: hiredis ==2.2.3 ; extra == 'redis'
+Requires-Dist: objectpath ==0.6.1 ; extra == 'redis'
+Provides-Extra: rethinkdb
+Requires-Dist: rethinkdb ==2.4.10.post1 ; extra == 'rethinkdb'
+Provides-Extra: scylla
+Requires-Dist: scylla-driver ==3.26.8 ; extra == 'scylla'
+Requires-Dist: cassandra-driver ==3.29.1 ; extra == 'scylla'
+Requires-Dist: acsylla ==0.1.8b0 ; extra == 'scylla'
+Requires-Dist: cqlsh ==6.1.2 ; extra == 'scylla'
+Provides-Extra: sqlalchemy
+Requires-Dist: sqlalchemy[asyncio] ==2.0.23 ; extra == 'sqlalchemy'
+Provides-Extra: sqlite
+Requires-Dist: aiosqlite >=0.18.0 ; extra == 'sqlite'
+
+# AsyncDB #
+
+AsyncDB is a collection of different Database Drivers using asyncio-based connections, binary-connectors (as asyncpg) but providing an abstraction layer to easily connect to different data sources, a high-level abstraction layer for various non-blocking database connectors,
+on other blocking connectors (like MS SQL Server) we are using ThreadPoolExecutors to run in a non-blocking manner.
+
+### Why AsyncDB? ###
+
+The finality of AsyncDB is to provide us a subset of drivers (connectors) for accessing different databases and data sources for data interaction.
+The main goal of AsyncDB is using asyncio-based technologies.
+
+### Getting Started ###
+
+## Requirements
+
+Python 3.9+
+
+## Installation
+
+<div class="termy">
+
+```console
+$ pip install asyncdb
+---> 100%
+Successfully installed asyncdb
+```
+
+Can also install only drivers required like:
+```console
+$ pip install asyncdb[pg] # this install only asyncpg
+```
+Or install all supported drivers as:
+
+```console
+$ pip install asyncdb[all]
+```
+
+### Requirements ###
+
+* Python >= 3.8
+* asyncio (https://pypi.python.org/pypi/asyncio/)
+
+Currently AsyncDB supports the following databases:
+
+* PostgreSQL (supporting two different connectors: asyncpg or aiopg)
+* SQLite (requires aiosqlite)
+* mySQL/MariaDB (requires aiomysql and mysqlclient)
+* ODBC (using aioodbc)
+* JDBC(using JayDeBeApi and JPype)
+* RethinkDB (requires rethinkdb)
+* Redis (requires aioredis)
+* Memcache (requires aiomcache)
+* MS SQL Server (non-asyncio using freeTDS and pymssql)
+* Apache Cassandra (requires official cassandra driver)
+* InfluxDB (using influxdb)
+* CouchBase (using aiocouch)
+* MongoDB (using motor)
+* SQLAlchemy (requires sqlalchemy async (+3.14))
+
+### Quick Tutorial ###
+
+```python
+from asyncdb import AsyncDB
+
+db = AsyncDB('pg', dsn='postgres://user:password@localhost:5432/database')
+
+# Or you can also passing a dictionary with parameters like:
+params = {
+    "user": "user",
+    "password": "password",
+    "host": "localhost",
+    "port": "5432",
+    "database": "database",
+    "DEBUG": True,
+}
+db = AsyncDB('pg', params=params)
+
+async with await db.connection() as conn:
+    result, error = await conn.query('SELECT * FROM test')
+```
+And that's it!, we are using the same methods on all drivers, maintaining a consistent interface between all of them, facilitating the re-use of the same code for different databases.
+
+Every Driver has a simple name to call it:
+* pg: AsyncPG (PostgreSQL)
+* postgres: aiopg (PostgreSQL)
+* mysql: aiomysql (mySQL)
+* influx: influxdb (InfluxDB)
+* redis: redis-py (Redis)
+* mcache: aiomcache (Memcache)
+* odbc: aiodbc (ODBC)
+
+#### Future work: ####
+
+* Prometheus
+
+### Output Support ###
+
+With Output Support results can be returned into a wide-range of variants:
+
+```python
+from datamodel import BaseModel
+
+class Point(BaseModel):
+    col1: list
+    col2: list
+    col3: list
+
+db = AsyncDB('pg', dsn='postgres://user:password@localhost:5432/database')
+async with await d.connection() as conn:
+    # changing output format to Pandas:
+    conn.output_format('pandas')  # change output format to pandas
+    result, error = await conn.query('SELECT * FROM test')
+    conn.output_format('csv')  # change output format to CSV
+    result, _ = await conn.query('SELECT TEST')
+    conn.output_format('dataclass', model=Point)  # change output format to Dataclass Model
+    result, _ = await conn.query('SELECT * FROM test')
+```
+
+Currently AsyncDB supports the following Output Formats:
+
+* CSV (comma-separated or parametrized)
+* JSON (using orjson)
+* iterable (returns a generator)
+* Recordset (Internal meta-Object for list of Records)
+* Pandas (a pandas Dataframe)
+* Datatable (Dt Dataframe)
+* Dataclass (exporting data to a dataclass with -optionally- passing Dataclass instance)
+* PySpark Dataframe
+
+And others to come:
+* Apache Arrow (using pyarrow)
+* Polars (Using Python polars)
+* Dask Dataframe
+
+### Contribution guidelines ###
+
+Please have a look at the Contribution Guide
+
+* Writing tests
+* Code review
+
+### Who do I talk to? ###
+
+* Repo owner or admin
+* Other community or team contact
+
+### License ###
+
+AsyncDB is copyright of Jesus Lara (https://phenobarbital.info) and is licensed under BSD. I am providing code in this repository under an open source licenses, remember, this is my personal repository; the license that you receive is from me and not from my employeer.
```

